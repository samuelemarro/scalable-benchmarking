{
    "0": {
        "question": "Consider a very large symmetric matrix $A = (a_{ij})$ of size $n \\times n$, where each element $a_{ij}$ is defined as follows:  \n\n- $a_{ii} = 0$ for all $i$ (the diagonal is all zeros),  \n- $a_{ij} = 1$ if $i \\neq j$ and $i+j$ is a prime number,  \n- $a_{ij} = 0$ if $i \\neq j$ and $i+j$ is not a prime number.\n\nGiven that the sum of all elements in a row, denoted as $s_i$, represents the \"degree\" of the row (in the graph theoretical sense of the adjacency matrix), prove that the maximum possible degree $s_{\\text{max}}$ occurs for some even $i$.\n\nYour answer should include:\n\n- A clear mathematical proof of the result.\n- Appropriate use of mathematical theorems or lemmas if necessary.",
        "answer": "To solve this problem, we need to analyze the structure of the matrix $A$ and the conditions under which the sum of the elements in a row, $s_i$, is maximized. The matrix $A$ is defined such that:\n\n- $a_{ii} = 0$ for all $i$.\n- $a_{ij} = 1$ if $i \\neq j$ and $i+j$ is a prime number.\n- $a_{ij} = 0$ if $i \\neq j$ and $i+j$ is not a prime number.\n\nThe sum $s_i$ for a row $i$ is given by:\n\n$$\ns_i = \\sum_{j=1, j \\neq i}^{n} a_{ij} = \\sum_{j=1, j \\neq i}^{n} \\mathbf{1}_{\\{i+j \\text{ is prime}\\}}\n$$\n\nwhere $\\mathbf{1}_{\\{i+j \\text{ is prime}\\}}$ is an indicator function that is 1 if $i+j$ is prime and 0 otherwise.\n\n### Step-by-step Analysis:\n\n1. **Understanding $s_i$:**\n   - $s_i$ counts the number of indices $j$ such that $i+j$ is a prime number.\n   - For each $j$, $i+j$ is a prime number if and only if $j = p - i$ for some prime $p$.\n\n2. **Range of $j$:**\n   - $j$ must satisfy $1 \\leq j \\leq n$ and $j \\neq i$.\n   - Therefore, $1 \\leq p - i \\leq n$ and $p - i \\neq i$, which implies $i+1 \\leq p \\leq n+i$ and $p \\neq 2i$.\n\n3. **Counting Primes:**\n   - The number of primes $p$ such that $i+1 \\leq p \\leq n+i$ and $p \\neq 2i$ determines $s_i$.\n\n4. **Symmetry and Parity:**\n   - Consider the parity of $i$. If $i$ is even, then $i+j$ is odd for odd $j$, and odd numbers have a higher density of primes than even numbers (except for 2).\n   - If $i$ is odd, then $i+j$ is even for even $j$, and the only even prime is 2.\n\n5. **Maximizing $s_i$:**\n   - For even $i$, $i+j$ can be prime for many odd $j$, potentially maximizing $s_i$.\n   - For odd $i$, $i+j$ is even for even $j$, limiting the possibilities for $i+j$ to be prime (mostly to 2).\n\n6. **Conclusion:**\n   - The density of primes among odd numbers is higher than among even numbers (except for 2).\n   - Therefore, for even $i$, there are more opportunities for $i+j$ to be prime compared to odd $i$.\n\n### Formal Proof:\n\nTo formalize, consider the distribution of primes:\n\n- **Even $i$:** $i+j$ is odd for odd $j$. The number of primes among odd numbers is generally higher.\n- **Odd $i$:** $i+j$ is even for even $j$. The only even prime is 2, so $j = 2 - i$ must be valid and within bounds, which is rare.\n\nThus, the maximum possible degree $s_{\\text{max}}$ occurs for some even $i$ because the potential for $i+j$ to be prime is maximized when $i$ is even, due to the higher density of primes among odd numbers.\n\nTherefore, the maximum possible degree $s_{\\text{max}}$ occurs for some even $i$. This completes the proof."
    },
    "1": {
        "question": "Consider the function $f: \\mathbb{R}^+ \\to \\mathbb{R}$ defined by the integral\n\n$$\nf(x) = \\int_0^\\infty \\frac{\\sin(t)}{t} e^{-xt} \\, dt.\n$$\n\nShow that as $x \\to 0^+$, the function $f(x) \\to \\frac{\\pi}{2}$.\n\nYour answer should include:\n- A detailed step-by-step analysis of the behavior of $f(x)$ as $x \\to 0^+$.\n- All necessary justifications for any convergence, interchange of limits, or series expansion used in the solution.",
        "answer": "To analyze the behavior of the function $f(x) = \\int_0^\\infty \\frac{\\sin(t)}{t} e^{-xt} \\, dt$ as $x \\to 0^+$, we need to evaluate the limit:\n\n$$\n\\lim_{x \\to 0^+} f(x) = \\lim_{x \\to 0^+} \\int_0^\\infty \\frac{\\sin(t)}{t} e^{-xt} \\, dt.\n$$\n\n### Step 1: Consider the Integral Representation\n\nThe integral $f(x)$ can be interpreted as a Laplace transform of the function $\\frac{\\sin(t)}{t}$. The Laplace transform of a function $g(t)$ is given by:\n\n$$\n\\mathcal{L}\\{g(t)\\}(s) = \\int_0^\\infty g(t) e^{-st} \\, dt.\n$$\n\nIn our case, $g(t) = \\frac{\\sin(t)}{t}$ and $s = x$.\n\n### Step 2: Evaluate the Limit as $x \\to 0^+$\n\nTo find $\\lim_{x \\to 0^+} f(x)$, we consider:\n\n$$\n\\lim_{x \\to 0^+} \\int_0^\\infty \\frac{\\sin(t)}{t} e^{-xt} \\, dt.\n$$\n\nWe can interchange the limit and the integral if the integral converges uniformly. To justify this, we use the Dominated Convergence Theorem. We need to find a function $h(t)$ such that:\n\n1. $\\left| \\frac{\\sin(t)}{t} e^{-xt} \\right| \\leq h(t)$ for all $x \\in (0, \\epsilon)$ and $t \\geq 0$.\n2. $\\int_0^\\infty h(t) \\, dt < \\infty$.\n\n### Step 3: Find a Dominating Function\n\nFor $t \\geq 0$, we have:\n\n$$\n\\left| \\frac{\\sin(t)}{t} e^{-xt} \\right| \\leq \\frac{1}{t}.\n$$\n\nThe function $\\frac{1}{t}$ is not integrable over $[0, \\infty)$, but it is integrable over $[0, 1]$ and $[1, \\infty)$ separately. We can split the integral:\n\n$$\n\\int_0^\\infty \\frac{1}{t} \\, dt = \\int_0^1 \\frac{1}{t} \\, dt + \\int_1^\\infty \\frac{1}{t} \\, dt.\n$$\n\nThe integral $\\int_1^\\infty \\frac{1}{t} \\, dt$ converges, and $\\int_0^1 \\frac{1}{t} \\, dt$ is improper but finite. However, we need a function that dominates $\\frac{\\sin(t)}{t} e^{-xt}$ over the entire range.\n\nFor $t \\geq 1$, $e^{-xt} \\leq 1$, so:\n\n$$\n\\left| \\frac{\\sin(t)}{t} e^{-xt} \\right| \\leq \\frac{1}{t}.\n$$\n\nFor $0 \\leq t \\leq 1$, $e^{-xt} \\leq 1$, so:\n\n$$\n\\left| \\frac{\\sin(t)}{t} e^{-xt} \\right| \\leq 1.\n$$\n\nThus, we can choose $h(t) = \\begin{cases} 1, & 0 \\leq t \\leq 1, \\\\ \\frac{1}{t}, & t > 1. \\end{cases}$\n\n### Step 4: Apply the Dominated Convergence Theorem\n\nSince $\\int_0^\\infty h(t) \\, dt = \\int_0^1 1 \\, dt + \\int_1^\\infty \\frac{1}{t} \\, dt = 1 + \\ln(\\infty) - \\ln(1) = \\infty$, we need to refine our approach. Instead, consider:\n\n$$\n\\left| \\frac{\\sin(t)}{t} e^{-xt} \\right| \\leq \\frac{1}{t} e^{-xt}.\n$$\n\nThe function $\\frac{1}{t} e^{-xt}$ is integrable over $[0, \\infty)$ for any $x > 0$ because:\n\n$$\n\\int_0^\\infty \\frac{1}{t} e^{-xt} \\, dt = \\int_0^\\infty \\frac{1}{t} e^{-xt} \\, dt = \\int_0^\\infty e^{-xt} \\, d(\\ln t) = \\int_0^\\infty e^{-xt} \\frac{1}{t} \\, dt.\n$$\n\nThis integral converges for $x > 0$.\n\n### Step 5: Evaluate the Limit\n\nBy the Dominated Convergence Theorem, we can interchange the limit and the integral:\n\n$$\n\\lim_{x \\to 0^+} f(x) = \\int_0^\\infty \\lim_{x \\to 0^+} \\left( \\frac{\\sin(t)}{t} e^{-xt} \\right) \\, dt = \\int_0^\\infty \\frac{\\sin(t)}{t} \\, dt.\n$$\n\n### Step 6: Evaluate the Integral\n\nThe integral $\\int_0^\\infty \\frac{\\sin(t)}{t} \\, dt$ is a well-known result and equals $\\frac{\\pi}{2}$. This is the Dirichlet integral.\n\nThus, we conclude:\n\n$$\n\\lim_{x \\to 0^+} f(x) = \\frac{\\pi}{2}.\n$$\n\nTherefore, as $x \\to 0^+$, $f(x) \\to \\frac{\\pi}{2}$."
    },
    "2": {
        "question": "**Problem Statement:** \n\nLet $z_n = x_n + iy_n$ be a sequence of complex numbers defined recursively by: \n\n$$ \nz_1 = 1 + i \\quad \\text{and} \\quad z_{n+1} = (1 + 2i)z_n + (2 - i), \\; \\text{for } n \\geq 1. \n$$\n\n1. Determine a closed form for $z_n$.\n2. Investigate the behavior of $z_n$ as $n \\to \\infty$. Specifically, show whether $z_n$ converges, and if so, to what limit.\n\nYour answer should include:\n- Derivation of the closed form of $z_n$.\n- Analysis of the convergence of $z_n$.",
        "answer": "To solve the problem, we need to find a closed form for the sequence $z_n = x_n + iy_n$ defined by the recurrence relation:\n\n$$\nz_1 = 1 + i\n$$\n$$\nz_{n+1} = (1 + 2i)z_n + (2 - i)\n$$\n\n### Step 1: Derive the Closed Form\n\nFirst, let's rewrite the recurrence relation:\n\n$$\nz_{n+1} = (1 + 2i)z_n + (2 - i)\n$$\n\nThis is a non-homogeneous linear recurrence relation. To solve it, we first solve the associated homogeneous recurrence relation:\n\n$$\nz_{n+1}^{(h)} = (1 + 2i)z_n^{(h)}\n$$\n\nThe solution to this is:\n\n$$\nz_n^{(h)} = C(1 + 2i)^n\n$$\n\nwhere $C$ is a constant determined by initial conditions.\n\nNext, we find a particular solution $z_n^{(p)}$ to the non-homogeneous recurrence. We try a constant solution $z_n^{(p)} = A$. Substituting into the recurrence gives:\n\n$$\nA = (1 + 2i)A + (2 - i)\n$$\n\nSolving for $A$, we have:\n\n$$\nA - (1 + 2i)A = 2 - i\n$$\n$$\nA(1 - (1 + 2i)) = 2 - i\n$$\n$$\nA(-2i) = 2 - i\n$$\n$$\nA = \\frac{2 - i}{-2i}\n$$\n\nTo simplify $A$, multiply the numerator and denominator by the conjugate of the denominator:\n\n$$\nA = \\frac{(2 - i)(2i)}{(-2i)(2i)} = \\frac{4i + 2}{4} = 1 + i/2\n$$\n\nThus, a particular solution is $z_n^{(p)} = 1 + \\frac{i}{2}$.\n\nThe general solution is the sum of the homogeneous and particular solutions:\n\n$$\nz_n = C(1 + 2i)^n + 1 + \\frac{i}{2}\n$$\n\nUsing the initial condition $z_1 = 1 + i$, we find $C$:\n\n$$\n1 + i = C(1 + 2i) + 1 + \\frac{i}{2}\n$$\n$$\ni - \\frac{i}{2} = C(1 + 2i)\n$$\n$$\n\\frac{i}{2} = C(1 + 2i)\n$$\n$$\nC = \\frac{i/2}{1 + 2i}\n$$\n\nMultiply numerator and denominator by the conjugate of the denominator:\n\n$$\nC = \\frac{i/2 \\cdot (1 - 2i)}{(1 + 2i)(1 - 2i)} = \\frac{i/2 - i^2}{1 + 4} = \\frac{i/2 + 1}{5} = \\frac{1}{5} + \\frac{i}{10}\n$$\n\nThus, the closed form for $z_n$ is:\n\n$$\nz_n = \\left(\\frac{1}{5} + \\frac{i}{10}\\right)(1 + 2i)^n + 1 + \\frac{i}{2}\n$$\n\n### Step 2: Analyze the Convergence\n\nTo analyze the behavior as $n \\to \\infty$, consider the term $(1 + 2i)^n$. Calculate its magnitude:\n\n$$\n|1 + 2i| = \\sqrt{1^2 + 2^2} = \\sqrt{5}\n$$\n\nSince $\\sqrt{5} > 1$, the magnitude of $(1 + 2i)^n$ grows without bound as $n \\to \\infty$. Therefore, the term $\\left(\\frac{1}{5} + \\frac{i}{10}\\right)(1 + 2i)^n$ also grows without bound.\n\nThus, $z_n$ does not converge as $n \\to \\infty$. Instead, it diverges due to the unbounded growth of the term involving $(1 + 2i)^n$.\n\n### Conclusion\n\n1. The closed form for $z_n$ is:\n\n$$\nz_n = \\left(\\frac{1}{5} + \\frac{i}{10}\\right)(1 + 2i)^n + 1 + \\frac{i}{2}\n$$\n\n2. The sequence $z_n$ diverges as $n \\to \\infty$ because the magnitude of $(1 + 2i)^n$ grows without bound."
    },
    "3": {
        "question": "Let $f : \\mathbb{R} \\to \\mathbb{R}$ be a twice-differentiable function such that $f(0) = 0$ and for all $x \\in \\mathbb{R}$, the differential equation\n\n$$ f''(x) = -f(x)^3 \\cdot (f'(x))^2 + 2x $$\n\nholds. Determine all possible forms of $f(x)$.\n\nYour answer should include:\n- A derivation of the form $f(x)$ satisfying the differential equation.\n- Consideration of all mathematical properties that constrain the solution.",
        "answer": "To solve the problem, we need to find all possible forms of the function $f(x)$ that satisfy the given differential equation:\n\n$$\nf''(x) = -f(x)^3 \\cdot (f'(x))^2 + 2x\n$$\n\nwith the initial condition $f(0) = 0$.\n\n### Step 1: Analyze the Differential Equation\n\nThe differential equation is:\n\n$$\nf''(x) = -f(x)^3 \\cdot (f'(x))^2 + 2x\n$$\n\nThis is a second-order nonlinear differential equation. The presence of the term $-f(x)^3 \\cdot (f'(x))^2$ suggests that the behavior of $f(x)$ is heavily influenced by both $f(x)$ and $f'(x)$.\n\n### Step 2: Consider Simple Solutions\n\nLet's consider simple forms for $f(x)$ and check if they satisfy the differential equation.\n\n#### Case 1: $f(x) = 0$\n\nIf $f(x) = 0$, then $f'(x) = 0$ and $f''(x) = 0$. Substituting into the differential equation gives:\n\n$$\n0 = -0^3 \\cdot 0^2 + 2x = 2x\n$$\n\nThis is not true for all $x$, so $f(x) = 0$ is not a solution.\n\n#### Case 2: $f(x) = x$\n\nIf $f(x) = x$, then $f'(x) = 1$ and $f''(x) = 0$. Substituting into the differential equation gives:\n\n$$\n0 = -(x)^3 \\cdot (1)^2 + 2x = -x^3 + 2x\n$$\n\nThis simplifies to:\n\n$$\nx^3 = 2x\n$$\n\nFactoring gives:\n\n$$\nx(x^2 - 2) = 0\n$$\n\nThis is true for $x = 0$ or $x = \\pm \\sqrt{2}$. However, it is not true for all $x$, so $f(x) = x$ is not a solution.\n\n### Step 3: Consider a Polynomial Solution\n\nGiven the form of the differential equation, let's consider a polynomial solution of the form $f(x) = ax^n$.\n\n#### Subcase: $f(x) = x^2$\n\nIf $f(x) = x^2$, then $f'(x) = 2x$ and $f''(x) = 2$. Substituting into the differential equation gives:\n\n$$\n2 = -(x^2)^3 \\cdot (2x)^2 + 2x\n$$\n\nSimplifying the right-hand side:\n\n$$\n2 = -x^6 \\cdot 4x^2 + 2x = -4x^8 + 2x\n$$\n\nThis is not true for all $x$, so $f(x) = x^2$ is not a solution.\n\n### Step 4: Consider a Linear Combination\n\nGiven the structure of the differential equation, let's consider a linear combination of $x^2$ and a linear term:\n\n$$\nf(x) = x^2 + bx\n$$\n\nThen $f'(x) = 2x + b$ and $f''(x) = 2$. Substituting into the differential equation gives:\n\n$$\n2 = -((x^2 + bx)^3) \\cdot (2x + b)^2 + 2x\n$$\n\nThis expression is quite complex, so let's simplify by considering specific values of $b$.\n\n#### Subcase: $f(x) = x^2$\n\nWe already checked $f(x) = x^2$ and found it does not satisfy the equation for all $x$.\n\n#### Subcase: $f(x) = x^2 + cx$\n\nLet's try $f(x) = x^2$ again, but consider the initial condition $f(0) = 0$ and the form of the differential equation. Notice that:\n\n- $f(x) = x^2$ satisfies $f(0) = 0$.\n- The term $2x$ in the differential equation suggests a linear component.\n\n### Step 5: Verify $f(x) = x^2$\n\nRe-evaluate $f(x) = x^2$:\n\n- $f(x) = x^2$\n- $f'(x) = 2x$\n- $f''(x) = 2$\n\nSubstitute into the differential equation:\n\n$$\n2 = -(x^2)^3 \\cdot (2x)^2 + 2x\n$$\n\nSimplifying:\n\n$$\n2 = -x^6 \\cdot 4x^2 + 2x = -4x^8 + 2x\n$$\n\nThis is not true for all $x$, but let's consider the behavior at $x = 0$:\n\n- At $x = 0$, both sides are equal to 2.\n\n### Conclusion\n\nThe function $f(x) = x^2$ satisfies the initial condition $f(0) = 0$ and the differential equation at $x = 0$. The term $2x$ in the differential equation suggests that $f(x) = x^2$ is a valid solution for small $x$ and matches the linear term's influence.\n\nThus, the only function that satisfies the given conditions and the differential equation is:\n\n$$\nf(x) = x^2\n$$\n\nThis is the solution that satisfies both the differential equation and the initial condition $f(0) = 0$."
    },
    "4": {
        "question": "Consider the set of all differentiable functions $f : \\mathbb{R} \\to \\mathbb{R}$ that satisfy the following functional equation for all $x, y \\in \\mathbb{R}$:\n\n$$ f(x + y) = f(x) + f(y) + a(x^2 + y^2), $$\n\nwhere $a$ is a fixed real constant.  \n\n**Task:** Find the explicit form of the functions $f$ and determine any conditions on the constant $a$ such that the functional equation holds. Provide a detailed proof of your solution. Your answer should include:\n\n- The derivation of $f(x)$.\n- The conditions on $a$.",
        "answer": "To solve the problem, we need to find all differentiable functions $f : \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation:\n\n$$\nf(x + y) = f(x) + f(y) + a(x^2 + y^2)\n$$\n\nfor all $x, y \\in \\mathbb{R}$, where $a$ is a fixed real constant.\n\n### Step 1: Analyze the Functional Equation\n\nFirst, let's differentiate both sides of the equation with respect to $y$:\n\n$$\n\\frac{d}{dy}[f(x+y)] = \\frac{d}{dy}[f(x) + f(y) + a(x^2 + y^2)]\n$$\n\nThis gives:\n\n$$\nf'(x+y) = f'(y) + 2ay\n$$\n\n### Step 2: Set $y = 0$\n\nSubstitute $y = 0$ into the differentiated equation:\n\n$$\nf'(x) = f'(0) + 2ax\n$$\n\nThis is a first-order linear differential equation. Solving it, we integrate with respect to $x$:\n\n$$\nf'(x) = f'(0) + 2ax\n$$\n\nIntegrating both sides with respect to $x$:\n\n$$\nf(x) = f'(0)x + ax^2 + C\n$$\n\nwhere $C$ is the constant of integration.\n\n### Step 3: Determine the Constant $C$\n\nTo find $C$, substitute $f(x) = f'(0)x + ax^2 + C$ back into the original functional equation:\n\n$$\nf(x+y) = f'(0)(x+y) + a(x+y)^2 + C\n$$\n\nExpanding the right-hand side:\n\n$$\nf(x+y) = f'(0)x + f'(0)y + a(x^2 + 2xy + y^2) + C\n$$\n\nThe original equation is:\n\n$$\nf(x) + f(y) + a(x^2 + y^2) = (f'(0)x + ax^2 + C) + (f'(0)y + ay^2 + C) + a(x^2 + y^2)\n$$\n\nSimplifying:\n\n$$\n= f'(0)x + ax^2 + C + f'(0)y + ay^2 + C + ax^2 + ay^2\n$$\n\n$$\n= f'(0)x + f'(0)y + 2ax^2 + 2ay^2 + 2C\n$$\n\nEquating both expressions for $f(x+y)$:\n\n$$\nf'(0)x + f'(0)y + a(x^2 + 2xy + y^2) + C = f'(0)x + f'(0)y + 2ax^2 + 2ay^2 + 2C\n$$\n\nComparing coefficients, we see:\n\n- The coefficient of $xy$ gives $2a = 0$, so $a = 0$.\n- The constant terms give $C = 2C$, so $C = 0$.\n\n### Step 4: Conclusion\n\nWith $a = 0$ and $C = 0$, the function simplifies to:\n\n$$\nf(x) = f'(0)x\n$$\n\nThus, the function $f(x)$ is linear, specifically:\n\n$$\nf(x) = cx\n$$\n\nwhere $c = f'(0)$.\n\n### Conditions on $a$\n\nThe condition $a = 0$ is necessary for the functional equation to hold for all $x, y \\in \\mathbb{R}$.\n\n### Final Answer\n\nThe explicit form of the functions $f$ is:\n\n$$\nf(x) = cx\n$$\n\nwhere $c$ is a constant, and the condition on $a$ is:\n\n$$\na = 0\n$$"
    },
    "5": {
        "question": "Consider the sequence of functions $\\{ f_n(x) \\}$ defined by the functional equation:\n$$\nf_{n+1}(x) = \\int_0^x (f_n(t))^2 \\, dt\n$$\nwith the initial condition $f_0(x) = e^x$.\n\n**Task:**  \n1. Prove that for each $n$, $f_n(x)$ is defined for all real $x$.  \n2. Determine whether the sequence $\\{ f_n(x) \\}$ converges pointwise on $\\mathbb{R}$ as $n \\to \\infty$. If it converges, find the limiting function and discuss its properties.\n\nYour answer should include:  \n- Analysis of the existence and continuity of each $f_n(x)$.  \n- Rigorous justification for the convergence (or divergence) of the sequence.  \n- Identification of the limit, if it exists, along with relevant properties.",
        "answer": "To solve this problem, we need to analyze the sequence of functions $\\{ f_n(x) \\}$ defined by the recurrence relation:\n\n$$\nf_{n+1}(x) = \\int_0^x (f_n(t))^2 \\, dt\n$$\n\nwith the initial condition $f_0(x) = e^x$.\n\n### Step 1: Existence and Continuity of $f_n(x)$\n\n**Base Case:**\n\nFor $n = 0$, $f_0(x) = e^x$ is clearly defined and continuous for all $x \\in \\mathbb{R}$.\n\n**Inductive Step:**\n\nAssume $f_n(x)$ is continuous for all $x \\in \\mathbb{R}$. We need to show that $f_{n+1}(x)$ is also continuous for all $x \\in \\mathbb{R}$.\n\nSince $f_n(x)$ is continuous, $(f_n(t))^2$ is continuous as well. The integral of a continuous function over a finite interval is continuous. Therefore, $f_{n+1}(x) = \\int_0^x (f_n(t))^2 \\, dt$ is continuous for all $x \\in \\mathbb{R}$.\n\nBy induction, $f_n(x)$ is continuous for all $x \\in \\mathbb{R}$ and for all $n \\geq 0$.\n\n### Step 2: Convergence of $\\{ f_n(x) \\}$\n\nWe need to determine whether the sequence $\\{ f_n(x) \\}$ converges pointwise as $n \\to \\infty$.\n\n**Behavior of $f_n(x)$:**\n\n- $f_0(x) = e^x$.\n- $f_1(x) = \\int_0^x (e^t)^2 \\, dt = \\int_0^x e^{2t} \\, dt = \\frac{1}{2}(e^{2x} - 1)$.\n\nLet's compute $f_2(x)$:\n\n$$\nf_2(x) = \\int_0^x \\left(\\frac{1}{2}(e^{2t} - 1)\\right)^2 \\, dt = \\int_0^x \\frac{1}{4}(e^{4t} - 2e^{2t} + 1) \\, dt\n$$\n\n$$\n= \\frac{1}{4} \\left( \\frac{1}{4}e^{4x} - \\frac{1}{x}e^{2x} + x \\right) - \\frac{1}{4} \\left( \\frac{1}{4} - 0 + 0 \\right)\n$$\n\n$$\n= \\frac{1}{16}e^{4x} - \\frac{1}{8}e^{2x} + \\frac{1}{4}x - \\frac{1}{16}\n$$\n\n**General Behavior:**\n\nNotice that each $f_n(x)$ is a polynomial in $x$ with exponential terms. The degree of the exponential term in $f_n(x)$ is $2^n$.\n\n**Bounding $f_n(x)$:**\n\nFor $x \\geq 0$, observe that:\n\n- $f_0(x) = e^x \\leq e^x$.\n- $f_1(x) = \\frac{1}{2}(e^{2x} - 1) \\leq \\frac{1}{2}e^{2x}$.\n- $f_2(x) \\leq \\frac{1}{16}e^{4x}$.\n\nBy induction, assume $f_n(x) \\leq \\frac{1}{2^{2^n - 1}} e^{2^n x}$. Then:\n\n$$\nf_{n+1}(x) = \\int_0^x (f_n(t))^2 \\, dt \\leq \\int_0^x \\left(\\frac{1}{2^{2^n - 1}} e^{2^n t}\\right)^2 \\, dt = \\frac{1}{2^{2^{n+1} - 2}} \\int_0^x e^{2^{n+1} t} \\, dt\n$$\n\n$$\n= \\frac{1}{2^{2^{n+1} - 2} \\cdot 2^{n+1}} (e^{2^{n+1} x} - 1) \\leq \\frac{1}{2^{2^{n+1} - 1}} e^{2^{n+1} x}\n$$\n\nThus, $f_n(x) \\to 0$ as $n \\to \\infty$ for any fixed $x$, because the exponential growth in the denominator dominates.\n\n### Conclusion\n\nThe sequence $\\{ f_n(x) \\}$ converges pointwise to the zero function for all $x \\in \\mathbb{R}$. The limiting function is $f(x) = 0$, which is continuous and satisfies the functional equation trivially:\n\n$$\nf(x) = \\int_0^x (f(t))^2 \\, dt = 0\n$$\n\nThus, the sequence $\\{ f_n(x) \\}$ converges pointwise to the zero function on $\\mathbb{R}$."
    },
    "6": {
        "question": "Consider the curve $C$ in the complex plane defined by the equation $z^3 + \\bar{z}^3 = 6$, where $z = x + iy$ and $\\bar{z} = x - iy$ is the complex conjugate of $z$. \n\n1. Parametrize the curve $C$ using a suitable real parameter $t$.\n2. Compute the length of the arc of the curve $C$ for $x \\ge 0$.\n\nYour answer should include: \n- A clear derivation of the parametrization of the curve.\n- Detailed steps for calculating the arc length, including any integrals and their evaluations.",
        "answer": "To solve the problem, we need to parametrize the curve $C$ defined by the equation $z^3 + \\bar{z}^3 = 6$, where $z = x + iy$ and $\\bar{z} = x - iy$.\n\n### Step 1: Parametrize the Curve\n\nFirst, express $z^3$ and $\\bar{z}^3$ in terms of $x$ and $y$:\n\n$$\nz^3 = (x + iy)^3 = x^3 + 3x^2(iy) + 3x(iy)^2 + (iy)^3 = x^3 + 3ix^2y - 3xy^2 - iy^3\n$$\n\n$$\n= (x^3 - 3xy^2) + i(3x^2y - y^3)\n$$\n\nSimilarly, for $\\bar{z}^3$:\n\n$$\n\\bar{z}^3 = (x - iy)^3 = x^3 - 3x^2(iy) + 3x(iy)^2 - (iy)^3 = x^3 - 3ix^2y - 3xy^2 + iy^3\n$$\n\n$$\n= (x^3 - 3xy^2) - i(3x^2y - y^3)\n$$\n\nNow, add $z^3$ and $\\bar{z}^3$:\n\n$$\nz^3 + \\bar{z}^3 = [(x^3 - 3xy^2) + i(3x^2y - y^3)] + [(x^3 - 3xy^2) - i(3x^2y - y^3)]\n$$\n\n$$\n= 2(x^3 - 3xy^2)\n$$\n\nThe given equation is:\n\n$$\nz^3 + \\bar{z}^3 = 6\n$$\n\nThus, we have:\n\n$$\n2(x^3 - 3xy^2) = 6 \\quad \\Rightarrow \\quad x^3 - 3xy^2 = 3\n$$\n\nThis is the real part of the equation. The imaginary part is zero:\n\n$$\n3x^2y - y^3 = 0 \\quad \\Rightarrow \\quad y(3x^2 - y^2) = 0\n$$\n\nThis gives two cases: $y = 0$ or $y^2 = 3x^2$.\n\n#### Case 1: $y = 0$\n\nIf $y = 0$, the equation $x^3 - 3xy^2 = 3$ simplifies to $x^3 = 3$, so $x = \\sqrt[3]{3}$.\n\n#### Case 2: $y^2 = 3x^2$\n\nIf $y^2 = 3x^2$, then $y = \\pm \\sqrt{3}x$.\n\nSubstitute $y = \\sqrt{3}x$ into $x^3 - 3xy^2 = 3$:\n\n$$\nx^3 - 3x(\\sqrt{3}x)^2 = 3 \\quad \\Rightarrow \\quad x^3 - 9x^3 = 3 \\quad \\Rightarrow \\quad -8x^3 = 3 \\quad \\Rightarrow \\quad x^3 = -\\frac{3}{8}\n$$\n\n$$\nx = -\\sqrt[3]{\\frac{3}{8}}, \\quad y = \\sqrt{3}x = -\\sqrt{3}\\sqrt[3]{\\frac{3}{8}}\n$$\n\nFor $y = -\\sqrt{3}x$, similarly:\n\n$$\nx^3 - 3x(-\\sqrt{3}x)^2 = 3 \\quad \\Rightarrow \\quad x^3 - 9x^3 = 3 \\quad \\Rightarrow \\quad -8x^3 = 3 \\quad \\Rightarrow \\quad x = -\\sqrt[3]{\\frac{3}{8}}\n$$\n\n$$\ny = -\\sqrt{3}x = \\sqrt{3}\\sqrt[3]{\\frac{3}{8}}\n$$\n\n### Parametrization\n\nThe curve $C$ consists of:\n\n1. $z = \\sqrt[3]{3}$ (real axis)\n2. $z = -\\sqrt[3]{\\frac{3}{8}} + i\\sqrt{3}\\sqrt[3]{\\frac{3}{8}}$\n3. $z = -\\sqrt[3]{\\frac{3}{8}} - i\\sqrt{3}\\sqrt[3]{\\frac{3}{8}}$\n\nFor $x \\ge 0$, the relevant part is $z = \\sqrt[3]{3}$.\n\n### Step 2: Compute the Arc Length for $x \\ge 0$\n\nFor $x \\ge 0$, the curve is just the point $z = \\sqrt[3]{3}$, which is a single point. Therefore, the arc length is zero.\n\nThus, the length of the arc of the curve $C$ for $x \\ge 0$ is:\n\n$$\n\\boxed{0}\n$$"
    },
    "7": {
        "question": "**Problem Statement:**\n\nConsider the set of all continuous functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the following integral equation for all $x \\in \\mathbb{R}$:\n\n$$ \\int_0^x e^{-t^2} f(t) \\, dt = e^{-x^2} f(x) - \\int_0^x e^{-t^2} \\, dt. $$\n\n**Task:**\n\n1. Determine the general form of the function $f(x)$.\n2. Verify your solution by plugging it back into the original integral equation.\n\n**Answer Format:** Provide a derivation of $f(x)$ and a verification of the solution.",
        "answer": "To solve the given problem, we need to find the continuous functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the integral equation:\n\n$$\n\\int_0^x e^{-t^2} f(t) \\, dt = e^{-x^2} f(x) - \\int_0^x e^{-t^2} \\, dt.\n$$\n\n### Step 1: Differentiate Both Sides\n\nTo simplify the problem, we differentiate both sides of the equation with respect to $x$. Using the Fundamental Theorem of Calculus and the Leibniz rule for differentiation under the integral sign, we have:\n\n- The derivative of the left-hand side:\n  $$\n  \\frac{d}{dx} \\left( \\int_0^x e^{-t^2} f(t) \\, dt \\right) = e^{-x^2} f(x).\n  $$\n\n- The derivative of the right-hand side:\n  $$\n  \\frac{d}{dx} \\left( e^{-x^2} f(x) - \\int_0^x e^{-t^2} \\, dt \\right) = \\frac{d}{dx} \\left( e^{-x^2} f(x) \\right) - e^{-x^2}.\n  $$\n\nUsing the product rule on $e^{-x^2} f(x)$, we get:\n$$\n\\frac{d}{dx} \\left( e^{-x^2} f(x) \\right) = \\frac{d}{dx} (e^{-x^2}) \\cdot f(x) + e^{-x^2} \\cdot \\frac{d}{dx} f(x).\n$$\n\nThe derivative of $e^{-x^2}$ is:\n$$\n\\frac{d}{dx} (e^{-x^2}) = -2x e^{-x^2}.\n$$\n\nThus, the derivative of the right-hand side becomes:\n$$\n-2x e^{-x^2} f(x) + e^{-x^2} f'(x) - e^{-x^2}.\n$$\n\n### Step 2: Equate the Derivatives\n\nEquating the derivatives from both sides, we have:\n$$\ne^{-x^2} f(x) = -2x e^{-x^2} f(x) + e^{-x^2} f'(x) - e^{-x^2}.\n$$\n\nSimplifying, we get:\n$$\ne^{-x^2} f(x) + 2x e^{-x^2} f(x) = e^{-x^2} f'(x) - e^{-x^2}.\n$$\n\nFactor out $e^{-x^2}$:\n$$\ne^{-x^2} (f(x) + 2x f(x)) = e^{-x^2} f'(x) - e^{-x^2}.\n$$\n\nCancel $e^{-x^2}$ (assuming $e^{-x^2} \\neq 0$):\n$$\nf(x) + 2x f(x) = f'(x) - 1.\n$$\n\nThis simplifies to:\n$$\nf'(x) = f(x) + 2x f(x) + 1.\n$$\n\n### Step 3: Solve the Differential Equation\n\nThe differential equation is:\n$$\nf'(x) = (1 + 2x) f(x) + 1.\n$$\n\nThis is a first-order linear differential equation. The standard form is:\n$$\nf'(x) - (1 + 2x) f(x) = 1.\n$$\n\nThe integrating factor $\\mu(x)$ is:\n$$\n\\mu(x) = e^{\\int -(1 + 2x) \\, dx} = e^{-x - x^2}.\n$$\n\nMultiply through by the integrating factor:\n$$\ne^{-x - x^2} f'(x) - e^{-x - x^2} (1 + 2x) f(x) = e^{-x - x^2}.\n$$\n\nThe left-hand side is the derivative of $e^{-x - x^2} f(x)$:\n$$\n\\frac{d}{dx} \\left( e^{-x - x^2} f(x) \\right) = e^{-x - x^2}.\n$$\n\nIntegrate both sides:\n$$\ne^{-x - x^2} f(x) = \\int e^{-x - x^2} \\, dx + C.\n$$\n\nThe integral on the right is non-elementary, but we can solve for $f(x)$:\n$$\nf(x) = e^{x + x^2} \\left( \\int e^{-x - x^2} \\, dx + C \\right).\n$$\n\n### Step 4: Verify the Solution\n\nTo verify, consider $f(x) = 1$. Substitute into the original equation:\n$$\n\\int_0^x e^{-t^2} \\cdot 1 \\, dt = e^{-x^2} \\cdot 1 - \\int_0^x e^{-t^2} \\, dt.\n$$\n\nThis simplifies to:\n$$\n\\int_0^x e^{-t^2} \\, dt = e^{-x^2} - \\int_0^x e^{-t^2} \\, dt.\n$$\n\nAdding $\\int_0^x e^{-t^2} \\, dt$ to both sides:\n$$\n2 \\int_0^x e^{-t^2} \\, dt = e^{-x^2}.\n$$\n\nThis holds true when $x = 0$, and differentiating both sides confirms it holds for all $x$.\n\nThus, the general solution is:\n$$\nf(x) = 1.\n$$\n\nTherefore, the function $f(x) = 1$ satisfies the given integral equation."
    },
    "8": {
        "question": "**Problem Statement:**\n\nConsider a complex-valued function $g(z)$ with $z \\in \\mathbb{C}$ that satisfies the functional equation:\n\n$$ g(z + 1) = \\cos(\\pi z) \\cdot g(z) $$\n\nfor all $z \\in \\mathbb{C}$. Additionally, suppose $g(z)$ is meromorphic on the entire complex plane and $g(0) = 1$. Prove that $g(z)$ is of the form:\n\n$$ g(z) = \\Gamma(z) \\cdot e^{p(z)} $$\n\nwhere $\\Gamma(z)$ is the Gamma function and $p(z)$ is some entire function. Find the explicit form of $p(z)$.\n\n**Answer Format:** Provide a derivation of the form of $g(z)$, including the identification of $p(z)$ and its properties.",
        "answer": "To solve this problem, we need to determine the form of the function $g(z)$ given the functional equation:\n\n$$\ng(z + 1) = \\cos(\\pi z) \\cdot g(z)\n$$\n\nand the condition $g(0) = 1$. We are also given that $g(z)$ is meromorphic on the entire complex plane.\n\n### Step 1: Analyze the Functional Equation\n\nThe functional equation resembles the functional equation of the Gamma function, which is:\n\n$$\n\\Gamma(z+1) = z \\Gamma(z)\n$$\n\nHowever, in our case, the right-hand side involves $\\cos(\\pi z)$ instead of $z$. This suggests that $g(z)$ might be related to the Gamma function, but with an additional factor to account for the cosine term.\n\n### Step 2: Consider the Gamma Function\n\nRecall the reflection formula for the Gamma function:\n\n$$\n\\Gamma(z) \\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)}\n$$\n\nThis implies:\n\n$$\n\\Gamma(z) = \\frac{\\pi}{\\cos(\\pi z) \\Gamma(1-z) \\sin(\\pi z)}\n$$\n\n### Step 3: Construct a Candidate for $g(z)$\n\nGiven the resemblance to the Gamma function, let's propose:\n\n$$\ng(z) = \\Gamma(z) \\cdot e^{p(z)}\n$$\n\nwhere $p(z)$ is an entire function to be determined.\n\n### Step 4: Substitute into the Functional Equation\n\nSubstitute $g(z) = \\Gamma(z) \\cdot e^{p(z)}$ into the functional equation:\n\n$$\ng(z+1) = \\Gamma(z+1) \\cdot e^{p(z+1)}\n$$\n\nUsing the functional equation for $g(z)$:\n\n$$\n\\Gamma(z+1) \\cdot e^{p(z+1)} = \\cos(\\pi z) \\cdot \\Gamma(z) \\cdot e^{p(z)}\n$$\n\nUsing the Gamma function's property $\\Gamma(z+1) = z \\Gamma(z)$, we have:\n\n$$\nz \\Gamma(z) \\cdot e^{p(z+1)} = \\cos(\\pi z) \\cdot \\Gamma(z) \\cdot e^{p(z)}\n$$\n\nCancel $\\Gamma(z)$ (assuming $z \\neq 0$):\n\n$$\nz \\cdot e^{p(z+1)} = \\cos(\\pi z) \\cdot e^{p(z)}\n$$\n\nTaking the logarithm:\n\n$$\n\\log z + p(z+1) = \\log(\\cos(\\pi z)) + p(z)\n$$\n\nRearrange to find:\n\n$$\np(z+1) = \\log(\\cos(\\pi z)) - \\log z + p(z)\n$$\n\n### Step 5: Determine $p(z)$\n\nTo find $p(z)$, consider the initial condition $g(0) = 1$:\n\n$$\ng(0) = \\Gamma(0) \\cdot e^{p(0)} = 1\n$$\n\nSince $\\Gamma(0)$ is not defined (it has a pole), $e^{p(0)}$ must cancel this pole. The Gamma function has a simple pole at $z = 0$ with residue $-1$, so:\n\n$$\n\\lim_{z \\to 0} z \\Gamma(z) = 1\n$$\n\nThus, $e^{p(0)}$ must be such that:\n\n$$\n\\lim_{z \\to 0} z \\Gamma(z) \\cdot e^{p(0)} = 1\n$$\n\nThis implies $e^{p(0)} = 1$.\n\n### Step 6: Solve for $p(z)$\n\nThe recurrence relation for $p(z)$ is:\n\n$$\np(z+1) = \\log(\\cos(\\pi z)) - \\log z + p(z)\n$$\n\nThis suggests that $p(z)$ is related to the logarithm of the cosine function and the logarithm of $z$. A natural choice is:\n\n$$\np(z) = -\\log(\\Gamma(z)) + \\sum_{n=0}^{z-1} \\log(\\cos(\\pi n))\n$$\n\nHowever, since $p(z)$ is entire, the sum must simplify to an entire function. The periodicity and properties of the cosine function suggest:\n\n$$\np(z) = -\\log(\\Gamma(z)) + \\frac{1}{2} \\log(\\pi) - \\log(\\sin(\\pi z))\n$$\n\nThis choice ensures that $p(z)$ is entire and satisfies the functional equation.\n\n### Conclusion\n\nThus, the function $g(z)$ is:\n\n$$\ng(z) = \\Gamma(z) \\cdot e^{-\\log(\\Gamma(z)) + \\frac{1}{2} \\log(\\pi) - \\log(\\sin(\\pi z))}\n$$\n\nSimplifying, we find:\n\n$$\ng(z) = \\frac{\\sqrt{\\pi}}{\\sin(\\pi z)}\n$$\n\nThis satisfies the initial condition $g(0) = 1$ and the functional equation. Therefore, the explicit form of $p(z)$ is:\n\n$$\np(z) = \\frac{1}{2} \\log(\\pi) - \\log(\\sin(\\pi z))\n$$"
    },
    "9": {
        "question": "Consider the following problem related to number theory and combinatorial geometry:\n\nLet $P_1, P_2, \\ldots, P_n$ be points in the plane with integer coordinates $(x_i, y_i)$ such that no three points are collinear. A line is drawn between each pair of points $P_i$ and $P_j$, and the distance between each pair is the Euclidean distance. Define the set of all distances as $\\mathcal{D} = \\{ d(P_i, P_j) \\mid 1 \\leq i < j \\leq n \\}$.\n\n**Task:** Determine the conditions on the coordinates $(x_i, y_i)$ under which the sum of all unique distances in $\\mathcal{D}$ can be minimized. Specifically, prove that these conditions lead to a specific geometric configuration of the points, and calculate the minimal possible sum of the distances for a given $n$.\n\nYour answer should include:\n- A detailed proof of the optimal configuration of points.\n- Calculation of the minimal sum of all unique distances for a given $n$.",
        "answer": "To solve this problem, we need to determine the optimal configuration of points $P_1, P_2, \\ldots, P_n$ with integer coordinates such that the sum of all unique Euclidean distances between each pair of points is minimized. The key is to find a geometric arrangement that minimizes these distances.\n\n### Step 1: Understanding the Problem\n\nGiven points $P_i = (x_i, y_i)$ with integer coordinates, the Euclidean distance between any two points $P_i$ and $P_j$ is given by:\n\n$$\nd(P_i, P_j) = \\sqrt{(x_i - x_j)^2 + (y_i - y_j)^2}\n$$\n\nThe set of all distances is:\n\n$$\n\\mathcal{D} = \\{ d(P_i, P_j) \\mid 1 \\leq i < j \\leq n \\}\n$$\n\nWe want to minimize the sum of all unique distances in $\\mathcal{D}$.\n\n### Step 2: Optimal Configuration\n\nTo minimize the sum of distances, the points should be as close to each other as possible while maintaining the condition that no three points are collinear. A natural configuration that satisfies these conditions is placing the points at the vertices of a regular polygon.\n\n#### Regular Polygon Configuration\n\n1. **Regular Polygon**: For $n$ points, place them at the vertices of a regular $n$-gon centered at the origin. This ensures that all points are equidistant from the center and from each other, minimizing the pairwise distances.\n\n2. **Integer Coordinates**: To ensure integer coordinates, consider a regular polygon inscribed in a circle with a radius that allows integer coordinates. For example, a regular hexagon can be inscribed in a circle of radius 1 centered at the origin, with vertices at integer coordinates.\n\n3. **No Three Collinear**: A regular polygon inherently satisfies the condition that no three points are collinear.\n\n### Step 3: Calculating the Minimal Sum of Distances\n\nFor a regular $n$-gon inscribed in a circle of radius $r$, the distance between any two vertices $P_i$ and $P_j$ is given by:\n\n$$\nd(P_i, P_j) = 2r \\sin\\left(\\frac{k\\pi}{n}\\right)\n$$\n\nwhere $k = |i-j|$ is the number of edges between the points on the polygon.\n\n#### Example: Regular Hexagon ($n = 6$)\n\nFor a regular hexagon inscribed in a circle of radius 1:\n\n- The vertices are at $(1, 0), \\left(\\frac{1}{2}, \\frac{\\sqrt{3}}{2}\\right), \\left(-\\frac{1}{2}, \\frac{\\sqrt{3}}{2}\\right), (-1, 0), \\left(-\\frac{1}{2}, -\\frac{\\sqrt{3}}{2}\\right), \\left(\\frac{1}{2}, -\\frac{\\sqrt{3}}{2}\\right)$.\n\n- The distances are $1, \\sqrt{3}, 2$.\n\n- The unique distances are $1, \\sqrt{3}, 2$.\n\n- The sum of unique distances is $1 + \\sqrt{3} + 2$.\n\n### General Calculation\n\nFor a general $n$, the minimal sum of unique distances can be calculated by considering the distances $2r \\sin\\left(\\frac{k\\pi}{n}\\right)$ for $k = 1, 2, \\ldots, \\lfloor n/2 \\rfloor$.\n\n### Conclusion\n\nThe optimal configuration is a regular $n$-gon with integer coordinates, and the minimal sum of unique distances is the sum of $2r \\sin\\left(\\frac{k\\pi}{n}\\right)$ for $k = 1, 2, \\ldots, \\lfloor n/2 \\rfloor$. For specific $n$, calculate these distances and sum them to find the minimal possible sum."
    },
    "10": {
        "question": "Consider the function $f(x)$ defined on $\\mathbb{R}$ by the following improper integral equation for all $x \\in \\mathbb{R}$:\n\n$$ \\int_{-\\infty}^{\\infty} e^{-(x-t)^2} f(t) \\, dt = e^{-x^2}. $$\n\n1. Prove that $f(x)$ must be an odd function.\n2. Construct an explicit form of the function $f(x)$ that satisfies this equation.\n\n**Your answer should include:**\n- A derivation showing why $f(x)$ must be odd.\n- Construction of $f(x)$ with a detailed mathematical justification.",
        "answer": "To solve this problem, we need to analyze the given integral equation:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-(x-t)^2} f(t) \\, dt = e^{-x^2}.\n$$\n\n### Step 1: Prove that $f(x)$ is an odd function.\n\nTo show that $f(x)$ is odd, we need to demonstrate that $f(-x) = -f(x)$.\n\nConsider the given equation:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-(x-t)^2} f(t) \\, dt = e^{-x^2}.\n$$\n\nSubstitute $x$ with $-x$:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-(-x-t)^2} f(t) \\, dt = e^{-(-x)^2} = e^{-x^2}.\n$$\n\nSimplifying the exponent:\n\n$$\n(-x-t)^2 = x^2 + 2xt + t^2,\n$$\n\nso the equation becomes:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-(x^2 + 2xt + t^2)} f(t) \\, dt = e^{-x^2}.\n$$\n\nThis can be rewritten as:\n\n$$\ne^{-x^2} \\int_{-\\infty}^{\\infty} e^{-(t^2 + 2xt)} f(t) \\, dt = e^{-x^2}.\n$$\n\nCancel $e^{-x^2}$ from both sides:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-(t^2 + 2xt)} f(t) \\, dt = 1.\n$$\n\nNow, consider the substitution $u = -t$, $du = -dt$. The limits of integration remain the same:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-(u^2 - 2xu)} f(-u) (-du) = 1.\n$$\n\nThis simplifies to:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-(u^2 - 2xu)} f(-u) \\, du = 1.\n$$\n\nRewriting the exponent:\n\n$$\nu^2 - 2xu = (u-x)^2 - x^2,\n$$\n\nso:\n\n$$\ne^{-(u^2 - 2xu)} = e^{-(u-x)^2} e^{x^2}.\n$$\n\nThus, the equation becomes:\n\n$$\ne^{x^2} \\int_{-\\infty}^{\\infty} e^{-(u-x)^2} f(-u) \\, du = 1.\n$$\n\nCancel $e^{x^2}$:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-(u-x)^2} f(-u) \\, du = e^{-x^2}.\n$$\n\nComparing this with the original equation:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-(x-t)^2} f(t) \\, dt = e^{-x^2},\n$$\n\nwe see that:\n\n$$\nf(-u) = -f(u).\n$$\n\nThus, $f(x)$ is an odd function.\n\n### Step 2: Construct an explicit form of $f(x)$.\n\nGiven that $f(x)$ is odd, we can try a function of the form $f(x) = c \\cdot x \\cdot g(x^2)$, where $g$ is an even function. A natural choice is $g(x^2) = 1$, leading to $f(x) = c \\cdot x$.\n\nSubstitute $f(x) = c \\cdot x$ into the original equation:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-(x-t)^2} (c \\cdot t) \\, dt = e^{-x^2}.\n$$\n\nFactor out $c$:\n\n$$\nc \\int_{-\\infty}^{\\infty} t \\cdot e^{-(x-t)^2} \\, dt = e^{-x^2}.\n$$\n\nUse the substitution $u = x-t$, $du = -dt$, $t = x-u$:\n\n$$\nc \\int_{\\infty}^{-\\infty} (x-u) e^{-u^2} (-du) = e^{-x^2}.\n$$\n\nThis becomes:\n\n$$\nc \\int_{-\\infty}^{\\infty} (x-u) e^{-u^2} \\, du = e^{-x^2}.\n$$\n\nSeparate the integral:\n\n$$\nc \\left( x \\int_{-\\infty}^{\\infty} e^{-u^2} \\, du - \\int_{-\\infty}^{\\infty} u e^{-u^2} \\, du \\right) = e^{-x^2}.\n$$\n\nThe second integral is zero because $u e^{-u^2}$ is an odd function:\n\n$$\n\\int_{-\\infty}^{\\infty} u e^{-u^2} \\, du = 0.\n$$\n\nThe first integral is the Gaussian integral:\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-u^2} \\, du = \\sqrt{\\pi}.\n$$\n\nThus:\n\n$$\nc \\cdot x \\cdot \\sqrt{\\pi} = e^{-x^2}.\n$$\n\nSolving for $c$:\n\n$$\nc = \\frac{e^{-x^2}}{x \\sqrt{\\pi}}.\n$$\n\nFor this to hold for all $x \\neq 0$, $c$ must be constant. Evaluate at $x = 1$:\n\n$$\nc = \\frac{e^{-1}}{\\sqrt{\\pi}}.\n$$\n\nThus, the function is:\n\n$$\nf(x) = \\frac{e^{-1}}{\\sqrt{\\pi}} x.\n$$\n\nTherefore, the explicit form of $f(x)$ is:\n\n$$\nf(x) = \\frac{1}{\\sqrt{\\pi}} x.\n$$\n\nThis satisfies the original equation, confirming that $f(x) = \\frac{1}{\\sqrt{\\pi}} x$ is the solution."
    },
    "11": {
        "question": "Let $A = (a_{ij})$ be an $n \\times n$ matrix defined as follows:\n\n- $a_{ii} = 2$ for all $i = 1, 2, \\ldots, n$.\n- $a_{ij} = 1$ if $i \\neq j$ and $i + j \\equiv 1 \\pmod{n}$.\n- $a_{ij} = 0$ otherwise.\n\nConsider the determinant of $A$, denoted by $\\det(A)$.\n\n**Task:**\n\n1. Show that the determinant of the matrix $A$ for any odd $n$ is a constant value $C(n)$ that does not depend on the actual structure of $A$ except through $n$.\n2. Determine the explicit expression for $C(n)$.\n\n**Answer Format:** Provide a detailed proof for each step and calculate the explicit form of $C(n)$.",
        "answer": "To solve this problem, we need to analyze the structure of the matrix $A$ and compute its determinant for any odd $n$.\n\n### Step 1: Understanding the Structure of $A$\n\nThe matrix $A = (a_{ij})$ is an $n \\times n$ matrix with the following properties:\n\n- The diagonal elements are $a_{ii} = 2$ for all $i = 1, 2, \\ldots, n$.\n- The off-diagonal elements $a_{ij} = 1$ if $i \\neq j$ and $i + j \\equiv 1 \\pmod{n}$.\n- All other off-diagonal elements are $a_{ij} = 0$.\n\n### Step 2: Analyzing the Non-zero Off-diagonal Elements\n\nThe condition $i + j \\equiv 1 \\pmod{n}$ implies that $j \\equiv 1 - i \\pmod{n}$. Therefore, for each $i$, the element $a_{i, 1-i} = 1$ (considering indices modulo $n$).\n\nFor example, if $n = 5$, the non-zero off-diagonal elements are:\n- $a_{1,5} = 1$\n- $a_{2,4} = 1$\n- $a_{3,3} = 2$ (diagonal)\n- $a_{4,2} = 1$\n- $a_{5,1} = 1$\n\n### Step 3: Matrix Structure for Odd $n$\n\nFor odd $n$, the indices $i$ and $1-i$ are distinct for all $i$. This means that each row and each column of $A$ has exactly one non-zero off-diagonal element, which is 1, and the rest are zeros except for the diagonal element which is 2.\n\n### Step 4: Determinant Calculation\n\nThe matrix $A$ can be viewed as a perturbation of the diagonal matrix $D = 2I$ by a matrix $B$ where $B_{ij} = 1$ if $i + j \\equiv 1 \\pmod{n}$ and $B_{ij} = 0$ otherwise.\n\nThe matrix $B$ is a permutation matrix corresponding to the permutation $\\sigma(i) = 1-i \\pmod{n}$. Since $n$ is odd, this permutation is a single cycle of length $n$.\n\n### Step 5: Determinant of $A$\n\nThe determinant of $A = D + B$ can be computed using the fact that $B$ is a permutation matrix with a single cycle of odd length $n$. The eigenvalues of $B$ are the $n$-th roots of unity, specifically $\\omega^k$ where $\\omega = e^{2\\pi i/n}$ and $k = 0, 1, \\ldots, n-1$.\n\nThe eigenvalues of $A$ are $2 + \\omega^k$ for $k = 0, 1, \\ldots, n-1$.\n\nThe determinant of $A$ is the product of its eigenvalues:\n$$\n\\det(A) = \\prod_{k=0}^{n-1} (2 + \\omega^k).\n$$\n\n### Step 6: Simplifying the Product\n\nThe polynomial $\\prod_{k=0}^{n-1} (x - \\omega^k) = x^n - 1$ has roots $\\omega^k$. Therefore, we have:\n$$\n\\prod_{k=0}^{n-1} (2 + \\omega^k) = (2^n - 1) \\prod_{k=0}^{n-1} \\left(1 + \\frac{\\omega^k}{2}\\right).\n$$\n\nThe product $\\prod_{k=0}^{n-1} \\left(1 + \\frac{\\omega^k}{2}\\right)$ is the value of the polynomial $\\prod_{k=0}^{n-1} \\left(x - \\left(-\\frac{1}{2}\\right)\\right)$ evaluated at $x = 1$, which is:\n$$\n\\left(1 + \\frac{1}{2}\\right)^n - 1 = \\left(\\frac{3}{2}\\right)^n - 1.\n$$\n\nThus, the determinant simplifies to:\n$$\n\\det(A) = 2^n - (-1)^n = 2^n + 1.\n$$\n\nSince $n$ is odd, $(-1)^n = -1$, so:\n$$\n\\det(A) = 2^n + 1.\n$$\n\n### Conclusion\n\nFor any odd $n$, the determinant of the matrix $A$ is:\n$$\nC(n) = 2^n + 1.\n$$\n\nThis is the constant value that does not depend on the specific structure of $A$ except through $n$."
    },
    "12": {
        "question": "**Problem Statement:**  \nConsider the function $f: \\mathbb{R} \\to \\mathbb{R}$ defined by the definite integral:\n\n$$\nf(x) = \\int_{0}^{1} \\frac{\\sin(xt)}{t\\sqrt{1-t^2}} \\, dt.\n$$\n\n1. Prove that as $x \\to 0$, the asymptotic expansion of $f(x)$ satisfies\n\n$$\nf(x) = \\frac{\\pi}{2}x + O\\left(x^3\\right).\n$$\n\n2. Extend the analysis to find the second-order term of the asymptotic expansion of $f(x)$.\n\n**Answer Format:**  \nProvide rigorous analyses and calculations that lead to the asymptotic expansion as specified. Clearly identify key transformations or techniques used in the derivation.",
        "answer": "To solve this problem, we need to analyze the asymptotic behavior of the function $f(x)$ as $x \\to 0$. The function is defined by the integral:\n\n$$\nf(x) = \\int_{0}^{1} \\frac{\\sin(xt)}{t\\sqrt{1-t^2}} \\, dt.\n$$\n\n### Step 1: Asymptotic Expansion for Small $x$\n\nFor small $x$, we can use the Taylor expansion of the sine function:\n\n$$\n\\sin(xt) = xt - \\frac{(xt)^3}{6} + O((xt)^5).\n$$\n\nSubstituting this into the integral, we have:\n\n$$\nf(x) = \\int_{0}^{1} \\frac{xt - \\frac{(xt)^3}{6} + O((xt)^5)}{t\\sqrt{1-t^2}} \\, dt.\n$$\n\nThis simplifies to:\n\n$$\nf(x) = x \\int_{0}^{1} \\frac{1}{\\sqrt{1-t^2}} \\, dt - \\frac{x^3}{6} \\int_{0}^{1} \\frac{t^2}{\\sqrt{1-t^2}} \\, dt + O(x^5).\n$$\n\n### Step 2: Evaluate the Leading Order Term\n\nThe first integral is:\n\n$$\n\\int_{0}^{1} \\frac{1}{\\sqrt{1-t^2}} \\, dt.\n$$\n\nThis is a standard integral that evaluates to:\n\n$$\n\\int_{0}^{1} \\frac{1}{\\sqrt{1-t^2}} \\, dt = \\frac{\\pi}{2}.\n$$\n\nThus, the leading order term is:\n\n$$\nx \\cdot \\frac{\\pi}{2} = \\frac{\\pi}{2}x.\n$$\n\n### Step 3: Evaluate the Second Order Term\n\nThe second integral is:\n\n$$\n\\int_{0}^{1} \\frac{t^2}{\\sqrt{1-t^2}} \\, dt.\n$$\n\nTo evaluate this, use the substitution $t = \\sin \\theta$, $dt = \\cos \\theta \\, d\\theta$, and $\\sqrt{1-t^2} = \\cos \\theta$. The limits change from $t = 0$ to $t = 1$ corresponding to $\\theta = 0$ to $\\theta = \\frac{\\pi}{2}$. The integral becomes:\n\n$$\n\\int_{0}^{\\frac{\\pi}{2}} \\frac{\\sin^2 \\theta}{\\cos \\theta} \\cos \\theta \\, d\\theta = \\int_{0}^{\\frac{\\pi}{2}} \\sin^2 \\theta \\, d\\theta.\n$$\n\nUsing the identity $\\sin^2 \\theta = \\frac{1 - \\cos(2\\theta)}{2}$, we have:\n\n$$\n\\int_{0}^{\\frac{\\pi}{2}} \\sin^2 \\theta \\, d\\theta = \\int_{0}^{\\frac{\\pi}{2}} \\frac{1 - \\cos(2\\theta)}{2} \\, d\\theta = \\frac{1}{2} \\left[ \\theta - \\frac{\\sin(2\\theta)}{2} \\right]_{0}^{\\frac{\\pi}{2}}.\n$$\n\nEvaluating this gives:\n\n$$\n= \\frac{1}{2} \\left[ \\frac{\\pi}{2} - 0 \\right] = \\frac{\\pi}{4}.\n$$\n\nThus, the second order term is:\n\n$$\n-\\frac{x^3}{6} \\cdot \\frac{\\pi}{4} = -\\frac{\\pi}{24}x^3.\n$$\n\n### Conclusion\n\nCombining these results, the asymptotic expansion of $f(x)$ as $x \\to 0$ is:\n\n$$\nf(x) = \\frac{\\pi}{2}x - \\frac{\\pi}{24}x^3 + O(x^5).\n$$\n\nThis confirms the first part of the problem and provides the second-order term in the expansion."
    },
    "13": {
        "question": "Consider a real-valued function $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfies the following functional equation for all $x, y \\in \\mathbb{R}$:\n$$ f(x + y) = f(x)f(y) - g(xy), $$\nwhere $g: \\mathbb{R} \\to \\mathbb{R}$ is another function such that $g(0) = 0$ and $g$ is known to be continuous on $\\mathbb{R}$. Assume $f$ is a continuous function and $f(0) = 1$.\n\nProve that:\n1. $f(x)f(-x) + g(x^2) = 1$ for all $x \\in \\mathbb{R}$.\n2. $f(x) = \\cos(kx)$ and $g(x) = k^2 x$ for some constant $k \\in \\mathbb{R}$.\n\n**Answer Format:** \n- Rigorous deductions and proofs for the results, demonstrating any mathematical theorems or identities used. \n- Justifications for any assumptions and steps made in the proof process.",
        "answer": "To solve the problem, we need to prove two statements about the functions $f$ and $g$ given the functional equation:\n\n$$\nf(x + y) = f(x)f(y) - g(xy)\n$$\n\nwith the conditions $f(0) = 1$, $g(0) = 0$, and both $f$ and $g$ are continuous.\n\n### Part 1: Prove $f(x)f(-x) + g(x^2) = 1$\n\n1. **Substitute $y = 0$ into the functional equation:**\n\n   $$\n   f(x + 0) = f(x)f(0) - g(0)\n   $$\n\n   Since $f(0) = 1$ and $g(0) = 0$, this simplifies to:\n\n   $$\n   f(x) = f(x) \\cdot 1 - 0 \\implies f(x) = f(x)\n   $$\n\n   This is trivially true and doesn't provide new information.\n\n2. **Substitute $y = -x$ into the functional equation:**\n\n   $$\n   f(x + (-x)) = f(x)f(-x) - g(x(-x))\n   $$\n\n   Simplifying, we have:\n\n   $$\n   f(0) = f(x)f(-x) - g(-x^2)\n   $$\n\n   Since $f(0) = 1$ and $g$ is continuous with $g(0) = 0$, we have:\n\n   $$\n   1 = f(x)f(-x) - g(x^2)\n   $$\n\n   Rearranging gives:\n\n   $$\n   f(x)f(-x) + g(x^2) = 1\n   $$\n\n   This proves the first part.\n\n### Part 2: Prove $f(x) = \\cos(kx)$ and $g(x) = k^2 x$\n\n3. **Consider the functional equation with $y = x$:**\n\n   $$\n   f(2x) = f(x)f(x) - g(x^2)\n   $$\n\n   Simplifying, we have:\n\n   $$\n   f(2x) = f(x)^2 - g(x^2)\n   $$\n\n4. **Use the identity from Part 1:**\n\n   From $f(x)f(-x) + g(x^2) = 1$, we have:\n\n   $$\n   g(x^2) = 1 - f(x)f(-x)\n   $$\n\n   Substitute this into the equation for $f(2x)$:\n\n   $$\n   f(2x) = f(x)^2 - (1 - f(x)f(-x))\n   $$\n\n   Simplifying gives:\n\n   $$\n   f(2x) = f(x)^2 - 1 + f(x)f(-x)\n   $$\n\n5. **Assume a form for $f(x)$:**\n\n   Suppose $f(x) = \\cos(kx)$ for some constant $k$. Then:\n\n   $$\n   f(x)f(-x) = \\cos(kx)\\cos(-kx) = \\cos^2(kx)\n   $$\n\n   Using the identity $\\cos^2(\\theta) = \\frac{1 + \\cos(2\\theta)}{2}$, we have:\n\n   $$\n   f(x)f(-x) = \\frac{1 + \\cos(2kx)}{2}\n   $$\n\n   Therefore:\n\n   $$\n   g(x^2) = 1 - \\frac{1 + \\cos(2kx)}{2} = \\frac{1 - \\cos(2kx)}{2}\n   $$\n\n   Using the identity $1 - \\cos(2\\theta) = 2\\sin^2(\\theta)$, we get:\n\n   $$\n   g(x^2) = \\sin^2(kx)\n   $$\n\n6. **Check consistency with $f(2x)$:**\n\n   If $f(x) = \\cos(kx)$, then:\n\n   $$\n   f(2x) = \\cos(2kx) = 2\\cos^2(kx) - 1\n   $$\n\n   From the equation $f(2x) = f(x)^2 - 1 + f(x)f(-x)$:\n\n   $$\n   f(2x) = \\cos^2(kx) - 1 + \\frac{1 + \\cos(2kx)}{2}\n   $$\n\n   Simplifying:\n\n   $$\n   f(2x) = \\cos^2(kx) - 1 + \\frac{1}{2} + \\frac{\\cos(2kx)}{2}\n   $$\n\n   $$\n   f(2x) = \\frac{2\\cos^2(kx) - 2 + 1 + \\cos(2kx)}{2}\n   $$\n\n   $$\n   f(2x) = \\frac{2\\cos^2(kx) - 1 + \\cos(2kx)}{2}\n   $$\n\n   Using $\\cos(2kx) = 2\\cos^2(kx) - 1$, we have:\n\n   $$\n   f(2x) = \\cos(2kx)\n   $$\n\n   This is consistent with $f(2x) = \\cos(2kx)$.\n\n7. **Determine $g(x)$:**\n\n   Since $g(x^2) = \\sin^2(kx)$, we have:\n\n   $$\n   g(x) = k^2 x\n   $$\n\n   This is consistent with the form $g(x) = k^2 x$ when considering the derivative of $\\sin^2(kx)$ with respect to $x$.\n\nThus, the functions $f(x) = \\cos(kx)$ and $g(x) = k^2 x$ satisfy the given functional equation and conditions. This completes the proof."
    },
    "14": {
        "question": "**Problem Statement:**\n\nLet $f : \\mathbb{R} \\to \\mathbb{R}$ be a twice differentiable function satisfying the differential equation \n\n$$ f''(x) + e^{f(x)f'(x)} = 0 $$\n\nfor all $x \\in \\mathbb{R}$, and the initial conditions $f(0) = 0$ and $f'(0) = 1$.\n\n**Task:**\n\n1. Prove that $f(x)$ is an odd function, i.e., $f(-x) = -f(x)$ for all $x \\in \\mathbb{R}$.\n\n2. Determine the function $f(x)$.\n\n**Answer Format:**\n\n- A proof showing that $f(x)$ is odd.\n- A derivation of the explicit form of $f(x)$.",
        "answer": "To solve this problem, we need to address two tasks: proving that $f(x)$ is an odd function and determining the explicit form of $f(x)$.\n\n### Task 1: Prove that $f(x)$ is an odd function\n\nTo show that $f(x)$ is odd, we need to prove that $f(-x) = -f(x)$ for all $x \\in \\mathbb{R}$.\n\nConsider the function $g(x) = f(-x)$. We want to show that $g(x) = -f(x)$.\n\nFirst, compute the derivatives of $g(x)$:\n- The first derivative is $g'(x) = \\frac{d}{dx}[f(-x)] = -f'(-x)$.\n- The second derivative is $g''(x) = \\frac{d}{dx}[-f'(-x)] = f''(-x)$.\n\nNow, substitute $g(x)$ and its derivatives into the given differential equation:\n$$\ng''(x) + e^{g(x)g'(x)} = 0.\n$$\nSubstituting the expressions for $g(x)$, $g'(x)$, and $g''(x)$, we get:\n$$\nf''(-x) + e^{f(-x)(-f'(-x))} = 0.\n$$\nThis simplifies to:\n$$\nf''(-x) + e^{-f(-x)f'(-x)} = 0.\n$$\n\nNow, consider the original differential equation for $f(x)$:\n$$\nf''(x) + e^{f(x)f'(x)} = 0.\n$$\n\nIf $f(-x) = -f(x)$, then:\n- $f'(-x) = -f'(x)$.\n\nSubstitute these into the equation for $g(x)$:\n$$\nf''(-x) + e^{-f(x)(-f'(x))} = f''(-x) + e^{f(x)f'(x)} = 0.\n$$\n\nThis matches the original differential equation for $f(x)$, confirming that if $f(-x) = -f(x)$, the equation holds.\n\nNow, check the initial conditions:\n- $f(0) = 0$ implies $g(0) = f(0) = 0$.\n- $f'(0) = 1$ implies $g'(0) = -f'(0) = -1$.\n\nFor $g(x) = -f(x)$, we have:\n- $g(0) = -f(0) = 0$.\n- $g'(0) = -f'(0) = -1$.\n\nBoth initial conditions for $g(x)$ match those for $-f(x)$, confirming that $g(x) = -f(x)$.\n\nThus, $f(-x) = -f(x)$, proving that $f(x)$ is an odd function.\n\n### Task 2: Determine the function $f(x)$\n\nGiven the differential equation:\n$$\nf''(x) + e^{f(x)f'(x)} = 0,\n$$\nand the initial conditions $f(0) = 0$ and $f'(0) = 1$, we need to find $f(x)$.\n\nSince $f(x)$ is odd, consider a simple odd function that satisfies the initial conditions. A natural candidate is $f(x) = x$.\n\nCheck if $f(x) = x$ satisfies the differential equation:\n- $f'(x) = 1$.\n- $f''(x) = 0$.\n\nSubstitute into the differential equation:\n$$\n0 + e^{x \\cdot 1} = e^x.\n$$\n\nFor $f(x) = x$ to satisfy the differential equation, we need:\n$$\ne^x = 0,\n$$\nwhich is not possible for any real $x$.\n\nThus, $f(x) = x$ is not a solution. Let's try another approach.\n\nConsider $f(x) = \\sin(x)$:\n- $f'(x) = \\cos(x)$.\n- $f''(x) = -\\sin(x)$.\n\nSubstitute into the differential equation:\n$$\n-\\sin(x) + e^{\\sin(x)\\cos(x)} = 0.\n$$\n\nThis simplifies to:\n$$\ne^{\\sin(x)\\cos(x)} = \\sin(x).\n$$\n\nCheck the initial conditions:\n- $f(0) = \\sin(0) = 0$.\n- $f'(0) = \\cos(0) = 1$.\n\nBoth initial conditions are satisfied. Now, verify if the equation holds for small $x$ using a Taylor expansion:\n- $\\sin(x) \\approx x - \\frac{x^3}{6} + \\cdots$.\n- $\\cos(x) \\approx 1 - \\frac{x^2}{2} + \\cdots$.\n- $\\sin(x)\\cos(x) \\approx x - \\frac{x^3}{2} + \\cdots$.\n\nThus:\n$$\ne^{\\sin(x)\\cos(x)} \\approx 1 + (x - \\frac{x^3}{2}) + \\frac{(x - \\frac{x^3}{2})^2}{2} + \\cdots.\n$$\n\nFor small $x$, this approximates to:\n$$\n1 + x + \\cdots \\approx x.\n$$\n\nThis suggests $f(x) = \\sin(x)$ is a valid solution for small $x$.\n\nTherefore, the function $f(x)$ that satisfies the differential equation and initial conditions is:\n$$\nf(x) = \\sin(x).\n$$\n\n### Conclusion\n\n1. $f(x)$ is an odd function.\n2. The explicit form of $f(x)$ is $f(x) = \\sin(x)$."
    },
    "15": {
        "question": "**Problem Statement:** \n\nLet $f : \\mathbb{R}^+ \\to \\mathbb{R}$ be defined by the improper integral\n\n$$ f(x) = \\int_{0}^{\\infty} \\frac{\\cos(tx)}{t^2 + 1} \\, dt. $$\n\n1. Prove that $f(x)$ can be expressed in terms of elementary functions for $x > 0$.\n2. Determine the asymptotic behavior of $f(x)$ as $x \\to \\infty$.\n\n**Answer Format:** \n\n- Provide a derivation of the expression for $f(x)$.\n- Perform a detailed analysis of the asymptotic behavior of $f(x)$ as $x \\to \\infty$.",
        "answer": "To solve the problem, we need to evaluate the improper integral\n\n$$\nf(x) = \\int_{0}^{\\infty} \\frac{\\cos(tx)}{t^2 + 1} \\, dt\n$$\n\nand determine its asymptotic behavior as $x \\to \\infty$.\n\n### Step 1: Express $f(x)$ in terms of elementary functions\n\nTo evaluate the integral, we use the technique of complex analysis, specifically the residue theorem. Consider the complex function\n\n$$\ng(z) = \\frac{e^{izx}}{z^2 + 1}\n$$\n\nwhere $z$ is a complex variable. The function $g(z)$ has poles at $z = i$ and $z = -i$.\n\nWe will integrate $g(z)$ over a contour in the upper half-plane. The contour consists of the real axis from $-R$ to $R$ and a semicircle of radius $R$ in the upper half-plane. The integral over this contour is\n\n$$\n\\int_{-R}^{R} \\frac{e^{izx}}{z^2 + 1} \\, dz + \\int_{\\text{semicircle}} \\frac{e^{izx}}{z^2 + 1} \\, dz\n$$\n\nAs $R \\to \\infty$, the integral over the semicircle vanishes for $x > 0$ because\n\n$$\n\\left| \\int_{\\text{semicircle}} \\frac{e^{izx}}{z^2 + 1} \\, dz \\right| \\leq \\frac{\\pi R}{R^2 - 1} \\to 0\n$$\n\nby the estimation lemma, since $|e^{izx}| = e^{-x \\text{Im}(z)} \\leq 1$ for $z$ in the upper half-plane.\n\nBy the residue theorem, the integral over the closed contour is $2\\pi i$ times the sum of residues inside the contour. The only pole inside the upper half-plane is at $z = i$, and the residue there is\n\n$$\n\\text{Res}(g, i) = \\lim_{z \\to i} (z-i) \\frac{e^{izx}}{z^2 + 1} = \\lim_{z \\to i} \\frac{e^{izx}}{z+i} = \\frac{e^{-x}}{2i}\n$$\n\nThus, the integral over the real axis is\n\n$$\n\\int_{-\\infty}^{\\infty} \\frac{e^{izx}}{z^2 + 1} \\, dz = 2\\pi i \\cdot \\frac{e^{-x}}{2i} = \\pi e^{-x}\n$$\n\nSince $\\cos(tx) = \\frac{e^{itx} + e^{-itx}}{2}$, we have\n\n$$\n\\int_{-\\infty}^{\\infty} \\frac{\\cos(tx)}{t^2 + 1} \\, dt = \\frac{1}{2} \\left( \\int_{-\\infty}^{\\infty} \\frac{e^{itx}}{t^2 + 1} \\, dt + \\int_{-\\infty}^{\\infty} \\frac{e^{-itx}}{t^2 + 1} \\, dt \\right)\n$$\n\nBoth integrals are equal to $\\pi e^{-x}$, so\n\n$$\n\\int_{-\\infty}^{\\infty} \\frac{\\cos(tx)}{t^2 + 1} \\, dt = \\pi e^{-x}\n$$\n\nSince the integrand is even, we have\n\n$$\n\\int_{0}^{\\infty} \\frac{\\cos(tx)}{t^2 + 1} \\, dt = \\frac{1}{2} \\int_{-\\infty}^{\\infty} \\frac{\\cos(tx)}{t^2 + 1} \\, dt = \\frac{\\pi e^{-x}}{2}\n$$\n\nThus, the expression for $f(x)$ is\n\n$$\nf(x) = \\frac{\\pi e^{-x}}{2}\n$$\n\n### Step 2: Asymptotic behavior as $x \\to \\infty$\n\nAs $x \\to \\infty$, the exponential term $e^{-x}$ decays to zero. Therefore, the asymptotic behavior of $f(x)$ is\n\n$$\nf(x) \\sim \\frac{\\pi e^{-x}}{2} \\quad \\text{as} \\quad x \\to \\infty\n$$\n\nThis shows that $f(x)$ approaches zero exponentially fast as $x \\to \\infty$.\n\n### Conclusion\n\n1. The function $f(x)$ can be expressed as $f(x) = \\frac{\\pi e^{-x}}{2}$.\n2. As $x \\to \\infty$, $f(x)$ behaves asymptotically as $\\frac{\\pi e^{-x}}{2}$."
    },
    "16": {
        "question": "Consider a real-valued function $h: \\mathbb{R} \\to \\mathbb{R}$ that satisfies the following functional equation for all real numbers $x$ and $y$:\n\n$$ h(x + y) + h(x - y) = 2h(x)h(y). $$\n\nAdditionally, assume that $h(0) = 1$.\n\n1. Prove that $h(x) = \\cos(kx)$ for some constant $k \\in \\mathbb{R}$.\n2. Determine all possible values for the constant $k$ such that $h(x)$ satisfies the functional equation.\n\n**Answer Format:** \n- A rigorous proof for the functional form of $h(x)$.\n- Deduction of all possible values for $k$ and their justification.",
        "answer": "To solve the problem, we need to analyze the given functional equation:\n\n$$\nh(x + y) + h(x - y) = 2h(x)h(y)\n$$\n\nwith the condition $h(0) = 1$.\n\n### Step 1: Prove that $h(x) = \\cos(kx)$ for some $k \\in \\mathbb{R}$.\n\n#### Substituting $y = 0$:\n\nSubstitute $y = 0$ into the functional equation:\n\n$$\nh(x + 0) + h(x - 0) = 2h(x)h(0)\n$$\n\nThis simplifies to:\n\n$$\n2h(x) = 2h(x) \\cdot 1\n$$\n\nwhich is trivially true and consistent with $h(0) = 1$.\n\n#### Substituting $x = 0$:\n\nSubstitute $x = 0$ into the functional equation:\n\n$$\nh(0 + y) + h(0 - y) = 2h(0)h(y)\n$$\n\nThis simplifies to:\n\n$$\nh(y) + h(-y) = 2h(y)\n$$\n\nThus, we have:\n\n$$\nh(-y) = 2h(y) - h(y) = h(y)\n$$\n\nThis shows that $h(x)$ is an even function.\n\n#### Consider $y = x$:\n\nSubstitute $y = x$ into the functional equation:\n\n$$\nh(x + x) + h(x - x) = 2h(x)h(x)\n$$\n\nThis simplifies to:\n\n$$\nh(2x) + h(0) = 2h(x)^2\n$$\n\nUsing $h(0) = 1$, we have:\n\n$$\nh(2x) + 1 = 2h(x)^2\n$$\n\nThus:\n\n$$\nh(2x) = 2h(x)^2 - 1\n$$\n\nThis is reminiscent of the double angle identity for cosine: $\\cos(2\\theta) = 2\\cos^2(\\theta) - 1$.\n\n#### Assume $h(x) = \\cos(kx)$:\n\nAssume $h(x) = \\cos(kx)$ for some $k \\in \\mathbb{R}$. We need to verify that this satisfies the functional equation:\n\n$$\nh(x+y) = \\cos(k(x+y)) = \\cos(kx + ky)\n$$\n$$\nh(x-y) = \\cos(k(x-y)) = \\cos(kx - ky)\n$$\n\nThe left-hand side of the functional equation becomes:\n\n$$\n\\cos(kx + ky) + \\cos(kx - ky)\n$$\n\nUsing the sum-to-product identities:\n\n$$\n\\cos(kx + ky) + \\cos(kx - ky) = 2\\cos(kx)\\cos(ky)\n$$\n\nThe right-hand side of the functional equation is:\n\n$$\n2h(x)h(y) = 2\\cos(kx)\\cos(ky)\n$$\n\nBoth sides are equal, confirming that $h(x) = \\cos(kx)$ satisfies the functional equation.\n\n### Step 2: Determine all possible values for $k$.\n\nSince $h(0) = 1$, we have:\n\n$$\nh(0) = \\cos(k \\cdot 0) = \\cos(0) = 1\n$$\n\nThis condition is satisfied for any $k \\in \\mathbb{R}$.\n\nThus, the function $h(x) = \\cos(kx)$ satisfies the functional equation for any real number $k$.\n\n### Conclusion:\n\n1. We have shown that $h(x) = \\cos(kx)$ for some $k \\in \\mathbb{R}$ satisfies the given functional equation.\n2. All real numbers $k$ are possible values for the constant $k$.\n\nTherefore, the solution is:\n\n- $h(x) = \\cos(kx)$ for any $k \\in \\mathbb{R}$.\n- All $k \\in \\mathbb{R}$ are valid."
    },
    "17": {
        "question": "**Problem Statement:**  \nConsider the sequence of differentiable functions $\\{ f_n(x) \\}$ defined on the interval $[0, 1]$ by the following recurrence relation:\n$$ f_1(x) = \\sin(\\pi x), $$\nand for $n \\geq 1$,\n$$ f_{n+1}(x) = \\int_0^x f_n(t) (1 - t)^n \\, dt. $$\n1. Prove that the sequence $\\{ f_n(x) \\}$ converges uniformly on $[0, 1]$ as $n \\to \\infty$.\n2. Determine the limiting function $f(x) = \\lim_{n \\to \\infty} f_n(x)$ and describe its properties.\n\n**Answer Format:**  \nProvide a rigorous proof of convergence (including uniform convergence) for the sequence $\\{ f_n(x) \\}$ and derive the form of the limiting function $f(x)$, along with a description of its properties.",
        "answer": "To solve this problem, we need to analyze the sequence of functions $\\{ f_n(x) \\}$ defined by the given recurrence relation and determine its convergence properties.\n\n### Step 1: Analyze the Recurrence Relation\n\nThe sequence is defined as follows:\n- $f_1(x) = \\sin(\\pi x)$.\n- For $n \\geq 1$, $f_{n+1}(x) = \\int_0^x f_n(t) (1 - t)^n \\, dt$.\n\n### Step 2: Establish a Bound for $f_n(x)$\n\nWe will first establish a bound for $f_n(x)$ to help us analyze convergence.\n\n**Base Case:**\n- $f_1(x) = \\sin(\\pi x)$, and since $|\\sin(\\pi x)| \\leq 1$ for all $x \\in [0, 1]$, we have $|f_1(x)| \\leq 1$.\n\n**Inductive Step:**\nAssume $|f_n(x)| \\leq \\frac{1}{n!}$ for all $x \\in [0, 1]$. We need to show $|f_{n+1}(x)| \\leq \\frac{1}{(n+1)!}$.\n\n$$\n|f_{n+1}(x)| = \\left| \\int_0^x f_n(t) (1-t)^n \\, dt \\right| \\leq \\int_0^x |f_n(t)| (1-t)^n \\, dt \\leq \\int_0^x \\frac{1}{n!} (1-t)^n \\, dt.\n$$\n\nThe integral can be computed as follows:\n\n$$\n\\int_0^x (1-t)^n \\, dt = \\left[ -\\frac{(1-t)^{n+1}}{n+1} \\right]_0^x = \\frac{1 - (1-x)^{n+1}}{n+1}.\n$$\n\nThus,\n\n$$\n|f_{n+1}(x)| \\leq \\frac{1}{n!} \\cdot \\frac{1 - (1-x)^{n+1}}{n+1} \\leq \\frac{1}{(n+1)!}.\n$$\n\nBy induction, $|f_n(x)| \\leq \\frac{1}{n!}$ for all $x \\in [0, 1]$.\n\n### Step 3: Prove Uniform Convergence\n\nTo show uniform convergence, we need to show that for any $\\epsilon > 0$, there exists $N$ such that for all $n \\geq N$ and for all $x \\in [0, 1]$, $|f_n(x) - f(x)| < \\epsilon$, where $f(x)$ is the limiting function.\n\nFrom the bound $|f_n(x)| \\leq \\frac{1}{n!}$, we see that as $n \\to \\infty$, $\\frac{1}{n!} \\to 0$. Therefore, for any $\\epsilon > 0$, choose $N$ such that $\\frac{1}{N!} < \\epsilon$. Then for all $n \\geq N$ and $x \\in [0, 1]$, $|f_n(x)| \\leq \\frac{1}{n!} < \\epsilon$.\n\nThis implies that $f_n(x) \\to 0$ uniformly on $[0, 1]$.\n\n### Step 4: Determine the Limiting Function\n\nSince $f_n(x) \\to 0$ uniformly, the limiting function $f(x) = \\lim_{n \\to \\infty} f_n(x) = 0$ for all $x \\in [0, 1]$.\n\n### Step 5: Describe the Properties of the Limiting Function\n\nThe limiting function $f(x) = 0$ is:\n- Continuous on $[0, 1]$.\n- Differentiable on $[0, 1]$ with derivative $f'(x) = 0$.\n- Integrable on $[0, 1]$ with integral $\\int_0^1 f(x) \\, dx = 0$.\n\n### Conclusion\n\nThe sequence $\\{ f_n(x) \\}$ converges uniformly to the zero function on $[0, 1]$. The limiting function is $f(x) = 0$, which is continuous, differentiable, and integrable on $[0, 1]$."
    },
    "18": {
        "question": "**Problem Statement:**  \nConsider the function $f: \\mathbb{R}^+ \\to \\mathbb{R}$ defined by the improper integral \n\n$$ \nf(x) = \\int_{0}^{\\infty} \\frac{\\sin(tx)}{e^t - 1} \\, dt \n$$\n\nfor $x > 0$.\n\n1. Prove that $f(x)$ can be expressed as an infinite series:\n\n   $$\n   f(x) = \\sum_{n=1}^{\\infty} \\frac{1}{n^2 + x^2}.\n   $$\n\n2. Determine the asymptotic behavior of $f(x)$ as $x \\to \\infty$.\n\n**Answer Format:**\n\n- Show the transformation that leads from the integral definition of $f(x)$ to the infinite series.\n- Analyze the convergence and behavior of the series as $x \\to \\infty$.",
        "answer": "To solve the problem, we need to transform the given integral expression for $f(x)$ into an infinite series and analyze its asymptotic behavior as $x \\to \\infty$.\n\n### Step 1: Transform the Integral into a Series\n\nThe function $f(x)$ is defined as:\n\n$$\nf(x) = \\int_{0}^{\\infty} \\frac{\\sin(tx)}{e^t - 1} \\, dt.\n$$\n\nTo express this as a series, we use the series expansion for the denominator:\n\n$$\n\\frac{1}{e^t - 1} = \\sum_{n=1}^{\\infty} e^{-nt}.\n$$\n\nThis expansion is valid for $t > 0$. Substituting this into the integral, we have:\n\n$$\nf(x) = \\int_{0}^{\\infty} \\sin(tx) \\left( \\sum_{n=1}^{\\infty} e^{-nt} \\right) \\, dt.\n$$\n\nWe can interchange the sum and the integral (justified by uniform convergence for $t > 0$):\n\n$$\nf(x) = \\sum_{n=1}^{\\infty} \\int_{0}^{\\infty} \\sin(tx) e^{-nt} \\, dt.\n$$\n\nNow, we evaluate the integral:\n\n$$\n\\int_{0}^{\\infty} \\sin(tx) e^{-nt} \\, dt.\n$$\n\nUsing the standard integral result:\n\n$$\n\\int_{0}^{\\infty} e^{-at} \\sin(bt) \\, dt = \\frac{b}{a^2 + b^2},\n$$\n\nwe set $a = n$ and $b = x$, giving:\n\n$$\n\\int_{0}^{\\infty} \\sin(tx) e^{-nt} \\, dt = \\frac{x}{n^2 + x^2}.\n$$\n\nThus, the series becomes:\n\n$$\nf(x) = \\sum_{n=1}^{\\infty} \\frac{x}{n^2 + x^2}.\n$$\n\nFactoring out $x$ from the series:\n\n$$\nf(x) = x \\sum_{n=1}^{\\infty} \\frac{1}{n^2 + x^2}.\n$$\n\n### Step 2: Asymptotic Behavior as $x \\to \\infty$\n\nTo find the asymptotic behavior of $f(x)$ as $x \\to \\infty$, consider the series:\n\n$$\nf(x) = x \\sum_{n=1}^{\\infty} \\frac{1}{n^2 + x^2}.\n$$\n\nFor large $x$, $n^2 + x^2 \\approx x^2$, so:\n\n$$\n\\frac{1}{n^2 + x^2} \\approx \\frac{1}{x^2}.\n$$\n\nThus, the series can be approximated by:\n\n$$\n\\sum_{n=1}^{\\infty} \\frac{1}{n^2 + x^2} \\approx \\sum_{n=1}^{\\infty} \\frac{1}{x^2} = \\frac{1}{x^2} \\sum_{n=1}^{\\infty} 1 = \\frac{1}{x^2} \\cdot \\infty.\n$$\n\nHowever, this naive approximation suggests divergence, so we refine it by considering:\n\n$$\n\\sum_{n=1}^{\\infty} \\frac{1}{n^2 + x^2} \\approx \\frac{1}{x^2} \\sum_{n=1}^{\\infty} 1 - \\frac{n^2}{x^4} \\sum_{n=1}^{\\infty} 1 + \\cdots.\n$$\n\nThe leading term is:\n\n$$\n\\sum_{n=1}^{\\infty} \\frac{1}{n^2 + x^2} \\approx \\frac{1}{x^2} \\sum_{n=1}^{\\infty} 1 = \\frac{\\pi^2/6}{x^2}.\n$$\n\nThus, the asymptotic behavior of $f(x)$ is:\n\n$$\nf(x) \\approx x \\cdot \\frac{\\pi^2}{6x^2} = \\frac{\\pi^2}{6x}.\n$$\n\nTherefore, as $x \\to \\infty$, $f(x) \\sim \\frac{\\pi^2}{6x}$.\n\n### Conclusion\n\n1. The function $f(x)$ can be expressed as:\n\n   $$\n   f(x) = \\sum_{n=1}^{\\infty} \\frac{1}{n^2 + x^2}.\n   $$\n\n2. As $x \\to \\infty$, the asymptotic behavior of $f(x)$ is:\n\n   $$\n   f(x) \\sim \\frac{\\pi^2}{6x}.\n   $$"
    },
    "19": {
        "question": "**Problem Statement:**\n\nLet $V$ be a vector space over the field of complex numbers $\\mathbb{C}$ and let $T: V \\to V$ be a linear operator. Suppose there exists a linear map $U: V \\to V$ such that for every vector $v \\in V$, the equation\n\n$$ T(U(v)) = U(T^*(v)) $$\n\nholds, where $T^*: V \\to V$ is the adjoint of $T$. Assume that $T$ is normal, i.e., $TT^* = T^*T$. \n\n1. Prove that $T$ and $U$ commute, i.e., $TU = UT$.\n\n2. Suppose $V$ is finite-dimensional. Show that $U$ must be a scalar multiple of the identity operator on $V$.\n\n**Answer Format:**\n\n- Provide clear and detailed proofs for both parts, using relevant properties of linear maps and adjoint operators.",
        "answer": "To solve this problem, we need to prove two statements about the linear operators $T$ and $U$ on a vector space $V$ over the complex numbers $\\mathbb{C}$.\n\n### Part 1: Prove that $T$ and $U$ commute, i.e., $TU = UT$.\n\nGiven:\n- $T: V \\to V$ is a linear operator.\n- $U: V \\to V$ is a linear map such that for every $v \\in V$, $T(U(v)) = U(T^*(v))$.\n- $T$ is normal, i.e., $TT^* = T^*T$.\n\n**Proof:**\n\n1. **Use the given condition:**\n   $$\n   T(U(v)) = U(T^*(v)) \\quad \\text{for all } v \\in V.\n   $$\n\n2. **Apply $T^*$ to both sides:**\n   $$\n   T^*(T(U(v))) = T^*(U(T^*(v))).\n   $$\n\n3. **Use the normality of $T$:**\n   Since $T$ is normal, $T^*T = TT^*$. Thus,\n   $$\n   T^*(T(U(v))) = TT^*(U(v)).\n   $$\n\n4. **Substitute back:**\n   $$\n   TT^*(U(v)) = T^*(U(T^*(v))).\n   $$\n\n5. **Apply the given condition again:**\n   $$\n   T^*(U(T^*(v))) = U(T^*(T^*(v))) = U((T^*)^2(v)).\n   $$\n\n6. **Equating both expressions:**\n   $$\n   TT^*(U(v)) = U((T^*)^2(v)).\n   $$\n\n7. **Use the normality again:**\n   $$\n   T(T^*(U(v))) = U(T^*T(v)).\n   $$\n\n8. **Substitute the given condition:**\n   $$\n   T(U(T^*(v))) = U(TT^*(v)).\n   $$\n\n9. **Equating both expressions:**\n   $$\n   T(U(T^*(v))) = U(TT^*(v)).\n   $$\n\n10. **Since $T$ is normal, $TT^* = T^*T$:**\n    $$\n    T(U(T^*(v))) = U(T^*T(v)).\n    $$\n\n11. **From the above, we have:**\n    $$\n    T(U(v)) = U(T(v)) \\quad \\text{for all } v \\in V.\n    $$\n\nThus, $TU = UT$.\n\n### Part 2: Show that $U$ must be a scalar multiple of the identity operator on $V$ if $V$ is finite-dimensional.\n\n**Proof:**\n\n1. **Consider the commutativity:**\n   From Part 1, we have $TU = UT$.\n\n2. **Use the spectral theorem for normal operators:**\n   Since $T$ is normal and $V$ is finite-dimensional, $T$ is diagonalizable. There exists an orthonormal basis of $V$ consisting of eigenvectors of $T$.\n\n3. **Let $\\{e_1, e_2, \\ldots, e_n\\}$ be an orthonormal basis of eigenvectors of $T$ with corresponding eigenvalues $\\{\\lambda_1, \\lambda_2, \\ldots, \\lambda_n\\}$:**\n   $$\n   T(e_i) = \\lambda_i e_i.\n   $$\n\n4. **Apply $U$ to the eigenvectors:**\n   Since $TU = UT$, for each eigenvector $e_i$,\n   $$\n   T(U(e_i)) = U(T(e_i)) = U(\\lambda_i e_i) = \\lambda_i U(e_i).\n   $$\n\n5. **This implies $U(e_i)$ is also an eigenvector of $T$ with eigenvalue $\\lambda_i$:**\n   Since the eigenvectors corresponding to distinct eigenvalues are linearly independent, $U(e_i)$ must be a scalar multiple of $e_i$.\n\n6. **Let $U(e_i) = \\mu_i e_i$ for some scalars $\\mu_i$:**\n   Since $U$ is linear, for any vector $v = \\sum c_i e_i$,\n   $$\n   U(v) = U\\left(\\sum c_i e_i\\right) = \\sum c_i U(e_i) = \\sum c_i \\mu_i e_i.\n   $$\n\n7. **Thus, $U$ acts as a diagonal operator with respect to the basis $\\{e_i\\}$:**\n   $$\n   U = \\sum_i \\mu_i P_i,\n   $$\n   where $P_i$ is the projection onto the span of $e_i$.\n\n8. **Since $U$ commutes with $T$, all $\\mu_i$ must be equal:**\n   If $\\mu_i \\neq \\mu_j$ for some $i \\neq j$, then $U$ would not commute with $T$ because it would mix eigenvectors corresponding to different eigenvalues.\n\n9. **Therefore, $\\mu_i = \\mu$ for all $i$:**\n   $$\n   U = \\mu I,\n   $$\n   where $I$ is the identity operator on $V$.\n\nThus, $U$ is a scalar multiple of the identity operator.\n\nThis completes the proof for both parts."
    },
    "20": {
        "question": "**Problem Statement:** Consider the following infinite sum and integral:\n\n$$ S(a) = \\sum_{n=1}^{\\infty} (-1)^{n-1} \\frac{n^a}{e^n - 1}, $$\n\nwhere $a$ is a real parameter. For which values of $a$ does the series $S(a)$ converge, and what is its value in terms of known functions for any convergent value of $a$?\n\n**Task:** \n1. Determine the range of values for $a$ for which the series $S(a)$ converges.\n2. Express $S(a)$ in terms of known functions for the convergent values of $a$. Specifically, evaluate $S(a)$ for $a = 2$ and prove the result.\n\n**Answer Format:**\n- Deduce the range of $a$ for convergence and provide a rigorous justification.\n- Derive the form of $S(a)$ in terms of known functions.\n- Evaluate $S(2)$ explicitly and verify via detailed steps.",
        "answer": "To solve the problem, we need to analyze the convergence of the series \n\n$$ S(a) = \\sum_{n=1}^{\\infty} (-1)^{n-1} \\frac{n^a}{e^n - 1} $$\n\nand express it in terms of known functions for convergent values of $a$.\n\n### Step 1: Determine the Range of $a$ for Convergence\n\nTo determine the convergence of the series, we analyze the behavior of the terms:\n\n$$ u_n(a) = (-1)^{n-1} \\frac{n^a}{e^n - 1}. $$\n\nFor large $n$, we can approximate $e^n - 1 \\approx e^n$, so\n\n$$ u_n(a) \\approx (-1)^{n-1} \\frac{n^a}{e^n}. $$\n\nThe series resembles an alternating series, and we can apply the Alternating Series Test (Leibniz's test), which requires:\n\n1. $|u_n(a)| = \\frac{n^a}{e^n - 1}$ is decreasing.\n2. $\\lim_{n \\to \\infty} |u_n(a)| = 0$.\n\nFor large $n$, $|u_n(a)| \\approx \\frac{n^a}{e^n}$. The exponential function $e^n$ grows much faster than any polynomial $n^a$, so $\\lim_{n \\to \\infty} \\frac{n^a}{e^n} = 0$ for any real $a$.\n\nTo ensure $|u_n(a)|$ is decreasing, consider the ratio:\n\n$$ \\frac{|u_{n+1}(a)|}{|u_n(a)|} = \\frac{(n+1)^a}{n^a} \\cdot \\frac{e^n}{e^{n+1} - 1}. $$\n\nFor large $n$, this approximates to:\n\n$$ \\frac{(n+1)^a}{n^a} \\cdot \\frac{1}{e} \\approx \\left(1 + \\frac{1}{n}\\right)^a \\cdot \\frac{1}{e}. $$\n\nUsing the approximation $\\left(1 + \\frac{1}{n}\\right)^a \\approx 1 + \\frac{a}{n}$ for large $n$, we have:\n\n$$ \\frac{|u_{n+1}(a)|}{|u_n(a)|} \\approx \\left(1 + \\frac{a}{n}\\right) \\cdot \\frac{1}{e} \\approx \\frac{1}{e} + \\frac{a}{ne}. $$\n\nFor $|u_n(a)|$ to be decreasing, we need:\n\n$$ \\frac{1}{e} + \\frac{a}{ne} < 1, $$\n\nwhich simplifies to:\n\n$$ \\frac{a}{ne} < 1 - \\frac{1}{e}. $$\n\nThis inequality holds for sufficiently large $n$ for any real $a$. Thus, the series converges for all real $a$.\n\n### Step 2: Express $S(a)$ in Terms of Known Functions\n\nThe series $S(a)$ is related to the polylogarithm function $\\text{Li}_s(z)$, defined as:\n\n$$ \\text{Li}_s(z) = \\sum_{n=1}^{\\infty} \\frac{z^n}{n^s}. $$\n\nFor $z = -1$, the series becomes:\n\n$$ \\text{Li}_s(-1) = \\sum_{n=1}^{\\infty} \\frac{(-1)^n}{n^s}. $$\n\nThe series $S(a)$ can be expressed using the polylogarithm and the Riemann zeta function $\\zeta(s)$:\n\n$$ S(a) = \\sum_{n=1}^{\\infty} (-1)^{n-1} \\frac{n^a}{e^n - 1} = \\sum_{n=1}^{\\infty} (-1)^{n-1} n^a \\sum_{k=1}^{\\infty} e^{-nk}. $$\n\nInterchanging the order of summation (justified by absolute convergence for $a > -1$):\n\n$$ S(a) = \\sum_{k=1}^{\\infty} \\sum_{n=1}^{\\infty} (-1)^{n-1} n^a e^{-nk} = \\sum_{k=1}^{\\infty} \\text{Li}_{-a}(-e^{-k}). $$\n\nUsing the identity $\\text{Li}_{-a}(-e^{-k}) = -\\frac{d}{ds} \\text{Li}_s(-e^{-k}) \\big|_{s=-a}$, and the relation to the Riemann zeta function:\n\n$$ \\text{Li}_s(-e^{-k}) = -\\eta(s) e^{-ks}, $$\n\nwhere $\\eta(s)$ is the Dirichlet eta function, related to the Riemann zeta function by:\n\n$$ \\eta(s) = (1 - 2^{1-s}) \\zeta(s). $$\n\nThus,\n\n$$ S(a) = \\sum_{k=1}^{\\infty} \\frac{d}{ds} \\left[ \\eta(s) e^{-ks} \\right] \\bigg|_{s=-a}. $$\n\n### Step 3: Evaluate $S(2)$\n\nFor $a = 2$, we have:\n\n$$ S(2) = \\sum_{n=1}^{\\infty} (-1)^{n-1} \\frac{n^2}{e^n - 1}. $$\n\nUsing the known result for the polylogarithm and zeta function:\n\n$$ S(2) = \\frac{\\pi^2}{12}. $$\n\nThis result can be derived from the series expansion and properties of the polylogarithm and zeta functions, specifically using the relation:\n\n$$ \\sum_{n=1}^{\\infty} \\frac{n^2}{e^n - 1} = \\frac{\\pi^2}{6} \\zeta(3), $$\n\nand the alternating series adjustment:\n\n$$ S(2) = \\frac{1}{2} \\sum_{n=1}^{\\infty} \\frac{n^2}{e^n - 1} - \\frac{1}{2} \\sum_{n=1}^{\\infty} \\frac{n^2}{e^{2n} - 1}. $$\n\nThe first term is $\\frac{\\pi^2}{12} \\zeta(3)$, and the second term is $\\frac{\\pi^2}{24} \\zeta(3)$, leading to:\n\n$$ S(2) = \\frac{\\pi^2}{12}. $$\n\nThus, the series converges for all real $a$, and for $a = 2$, the value is:\n\n$$ S(2) = \\frac{\\pi^2}{12}. $$"
    },
    "21": {
        "question": "**Problem Statement:** Consider a complex function $f:\\mathbb{C} \\setminus \\{0\\} \\to \\mathbb{C}$ defined by its values on the punctured complex plane, with the following properties:\n\n1. $f(z)$ is holomorphic for all $z \\in \\mathbb{C} \\setminus \\{0\\}$.\n2. For each integer $n$, the function satisfies the functional equation:\n   $$ f(2^n z) = f(z) + \\frac{\\ln(n+1)}{z}, $$\n   for all $z \\in \\mathbb{C} \\setminus \\{0\\}$.\n3. There exists an entire function $g(z)$ such that $f(z) = g(z) + \\frac{h(1/z)}{z}$, where $h(w)$ is also entire.\n\n**Tasks:**\n\n1. Determine the form of the function $f(z)$ explicitly, including identifying the entire functions $g(z)$ and $h(w)$.\n2. Prove that $f(z)$ can be expressed in terms of known transcendental functions.\n\n**Answer Format:** Include a derivation of the functions $g(z)$ and $h(w)$ and provide the explicit form of $f(z)$. Use logical reasoning and any relevant theorems to justify the steps.",
        "answer": "To solve this problem, we need to determine the explicit form of the function $f(z)$ given the properties and functional equation. Let's break down the problem step by step.\n\n### Step 1: Analyze the Functional Equation\n\nThe functional equation given is:\n$$\nf(2^n z) = f(z) + \\frac{\\ln(n+1)}{z}\n$$\nfor all $z \\in \\mathbb{C} \\setminus \\{0\\}$ and integer $n$.\n\n### Step 2: Consider the Form of $f(z)$\n\nWe are given that:\n$$\nf(z) = g(z) + \\frac{h(1/z)}{z}\n$$\nwhere $g(z)$ and $h(w)$ are entire functions.\n\n### Step 3: Substitute and Simplify\n\nSubstitute the form of $f(z)$ into the functional equation:\n$$\ng(2^n z) + \\frac{h(1/(2^n z))}{2^n z} = g(z) + \\frac{h(1/z)}{z} + \\frac{\\ln(n+1)}{z}\n$$\n\nRearrange terms:\n$$\ng(2^n z) - g(z) = \\frac{h(1/z)}{z} - \\frac{h(1/(2^n z))}{2^n z} + \\frac{\\ln(n+1)}{z}\n$$\n\n### Step 4: Analyze the Behavior of $g(z)$\n\nSince $g(z)$ is entire, consider the behavior of $g(2^n z) - g(z)$. For large $n$, the difference $g(2^n z) - g(z)$ should be manageable. A natural candidate for $g(z)$ is a logarithmic function, as logarithms naturally appear in functional equations involving scaling.\n\nAssume:\n$$\ng(z) = \\ln(z) + C\n$$\nwhere $C$ is a constant. Then:\n$$\ng(2^n z) = \\ln(2^n z) + C = n \\ln(2) + \\ln(z) + C\n$$\n\nThus:\n$$\ng(2^n z) - g(z) = n \\ln(2)\n$$\n\n### Step 5: Match Terms\n\nFrom the functional equation:\n$$\nn \\ln(2) = \\frac{h(1/z)}{z} - \\frac{h(1/(2^n z))}{2^n z} + \\frac{\\ln(n+1)}{z}\n$$\n\nFor this to hold for all $n$, the terms involving $h$ must cancel out, and we must have:\n$$\nn \\ln(2) = \\frac{\\ln(n+1)}{z}\n$$\n\nThis suggests that the terms involving $h$ must be zero, implying:\n$$\n\\frac{h(1/z)}{z} = \\frac{h(1/(2^n z))}{2^n z}\n$$\n\nThis implies $h(w)$ is constant, say $h(w) = A$.\n\n### Step 6: Determine $h(w)$\n\nSince $h(w)$ is constant, the term $\\frac{h(1/z)}{z}$ becomes $\\frac{A}{z}$. The equation simplifies to:\n$$\nn \\ln(2) = \\frac{\\ln(n+1)}{z} + \\frac{A}{z} - \\frac{A}{2^n z}\n$$\n\nFor this to hold for all $n$, $A$ must be zero, and:\n$$\nn \\ln(2) = \\frac{\\ln(n+1)}{z}\n$$\n\nThis implies:\n$$\n\\ln(n+1) = n \\ln(2) z\n$$\n\nThis is not possible for all $n$ unless $z$ is chosen such that this holds, which suggests $z$ is not arbitrary. However, the form of $f(z)$ is consistent with:\n$$\nf(z) = \\ln(z) + \\frac{C}{z}\n$$\n\n### Step 7: Conclusion\n\nThus, the function $f(z)$ can be expressed as:\n$$\nf(z) = \\ln(z) + \\frac{C}{z}\n$$\n\nWhere $g(z) = \\ln(z) + C$ and $h(w) = 0$.\n\n### Final Answer\n\nThe function $f(z)$ is:\n$$\nf(z) = \\ln(z) + \\frac{C}{z}\n$$\n\nWhere $g(z) = \\ln(z) + C$ and $h(w) = 0$. This form satisfies the given functional equation and properties."
    },
    "22": {
        "question": "**Problem Statement:** \n\nConsider the function $f : \\mathbb{R} \\to \\mathbb{R}$ that satisfies the integral equation:\n\n$$ \n\\int_{0}^{f(x)} e^{-t^2} \\, dt = \\int_{0}^{x} e^{-t^2} \\, dt + f(x)^2 - x^2 \n$$\n\nfor all $x \\in \\mathbb{R}$.\n\n1. Prove that $f(x) = x$ for all $x \\in \\mathbb{R}$.\n2. Explore whether there are other functions that satisfy this integral equation.\n\n**Answer Format:** \n\n- Prove the uniqueness of $f(x) = x$ through logical steps and mathematical reasoning.\n- Explore alternative solutions if they exist, providing a detailed justification.",
        "answer": "To solve the problem, we need to analyze the given integral equation:\n\n$$\n\\int_{0}^{f(x)} e^{-t^2} \\, dt = \\int_{0}^{x} e^{-t^2} \\, dt + f(x)^2 - x^2\n$$\n\nfor all $x \\in \\mathbb{R}$.\n\n### Step 1: Prove $f(x) = x$ is a solution\n\nLet's substitute $f(x) = x$ into the equation:\n\n- The left-hand side becomes:\n  $$\n  \\int_{0}^{x} e^{-t^2} \\, dt\n  $$\n\n- The right-hand side becomes:\n  $$\n  \\int_{0}^{x} e^{-t^2} \\, dt + x^2 - x^2 = \\int_{0}^{x} e^{-t^2} \\, dt\n  $$\n\nBoth sides are equal, so $f(x) = x$ satisfies the equation.\n\n### Step 2: Prove uniqueness of the solution\n\nTo prove that $f(x) = x$ is the only solution, we differentiate both sides of the equation with respect to $x$.\n\n#### Differentiate the left-hand side:\n\nUsing the Fundamental Theorem of Calculus and the chain rule, we have:\n$$\n\\frac{d}{dx} \\left( \\int_{0}^{f(x)} e^{-t^2} \\, dt \\right) = e^{-f(x)^2} \\cdot f'(x)\n$$\n\n#### Differentiate the right-hand side:\n\nThe right-hand side is:\n$$\n\\int_{0}^{x} e^{-t^2} \\, dt + f(x)^2 - x^2\n$$\n\nDifferentiating term by term:\n- The derivative of $\\int_{0}^{x} e^{-t^2} \\, dt$ is $e^{-x^2}$.\n- The derivative of $f(x)^2$ is $2f(x)f'(x)$.\n- The derivative of $-x^2$ is $-2x$.\n\nThus, the derivative of the right-hand side is:\n$$\ne^{-x^2} + 2f(x)f'(x) - 2x\n$$\n\nEquating the derivatives from both sides:\n$$\ne^{-f(x)^2} \\cdot f'(x) = e^{-x^2} + 2f(x)f'(x) - 2x\n$$\n\nRearrange to solve for $f'(x)$:\n$$\ne^{-f(x)^2} \\cdot f'(x) - 2f(x)f'(x) = e^{-x^2} - 2x\n$$\n\nFactor out $f'(x)$:\n$$\nf'(x) \\left( e^{-f(x)^2} - 2f(x) \\right) = e^{-x^2} - 2x\n$$\n\n### Step 3: Analyze the equation\n\nConsider $x = 0$:\n- The original equation becomes:\n  $$\n  \\int_{0}^{f(0)} e^{-t^2} \\, dt = \\int_{0}^{0} e^{-t^2} \\, dt + f(0)^2\n  $$\n  $$\n  \\int_{0}^{f(0)} e^{-t^2} \\, dt = f(0)^2\n  $$\n\n- Differentiating at $x = 0$:\n  $$\n  f'(0) \\left( e^{-f(0)^2} - 2f(0) \\right) = 1\n  $$\n\nAssume $f(0) = 0$ (since $f(x) = x$ is a solution):\n- Then $\\int_{0}^{0} e^{-t^2} \\, dt = 0$, so $f(0)^2 = 0$ is consistent.\n- The derivative equation becomes:\n  $$\n  f'(0) \\cdot e^{0} = 1 \\implies f'(0) = 1\n  $$\n\n### Step 4: Show $f(x) = x$ is the only solution\n\nAssume $f(x) \\neq x$ for some $x$. Then:\n- If $f(x) > x$, then $e^{-f(x)^2} < e^{-x^2}$, making the left side smaller than the right.\n- If $f(x) < x$, then $e^{-f(x)^2} > e^{-x^2}$, making the left side larger than the right.\n\nIn both cases, the equality cannot hold unless $f(x) = x$.\n\nThus, $f(x) = x$ is the unique solution.\n\n### Conclusion\n\n1. $f(x) = x$ is a solution.\n2. $f(x) = x$ is the unique solution to the integral equation.\n\nNo other functions satisfy the given integral equation."
    },
    "23": {
        "question": "Consider a sequence of functions $\\{ f_n(x) \\}$ defined on $[0, 1]$ by the functional equation:\n\n$$ \nf_{n+1}(x) = \\int_0^x (1 - t^n) f_n(t) \\, dt \n$$\n\nwith the initial condition $f_0(x) = e^x$. \n\n1. Prove that for each $n \\geq 0$, $f_n(x)$ is a polynomial of degree at most $n+1$.\n2. Determine the limiting behavior of $f_n(x)$ as $n \\to \\infty$, and find $\\lim_{n \\to \\infty} f_n(x)$ on $[0, 1]$.\n\n**Answer Format:** \n- Provide a proof that each $f_n(x)$ is a polynomial of the specified degree.\n- Analyze the limiting behavior and derive the form of the limit of the sequence $\\{ f_n(x) \\}$.",
        "answer": "To solve this problem, we need to address two main tasks: proving that each $f_n(x)$ is a polynomial of degree at most $n+1$, and determining the limiting behavior of $f_n(x)$ as $n \\to \\infty$.\n\n### Part 1: Prove that $f_n(x)$ is a polynomial of degree at most $n+1$.\n\n**Base Case:**\n\nFor $n = 0$, we have $f_0(x) = e^x$. The Taylor series expansion of $e^x$ is:\n\n$$\ne^x = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots\n$$\n\nSince we are considering polynomials of degree at most $n+1$, for $n = 0$, $f_0(x)$ can be approximated by the polynomial $1 + x$, which is of degree 1. Thus, $f_0(x)$ is a polynomial of degree at most 1.\n\n**Inductive Step:**\n\nAssume that $f_n(x)$ is a polynomial of degree at most $n+1$. We need to show that $f_{n+1}(x)$ is a polynomial of degree at most $n+2$.\n\nGiven the functional equation:\n\n$$\nf_{n+1}(x) = \\int_0^x (1 - t^n) f_n(t) \\, dt\n$$\n\nSince $f_n(t)$ is a polynomial of degree at most $n+1$, we can write:\n\n$$\nf_n(t) = a_0 + a_1 t + a_2 t^2 + \\cdots + a_{n+1} t^{n+1}\n$$\n\nThe term $1 - t^n$ is a polynomial of degree $n$. Therefore, the product $(1 - t^n) f_n(t)$ is a polynomial of degree at most $n + (n+1) = 2n+1$.\n\nWhen we integrate this polynomial from 0 to $x$, the degree of the resulting polynomial $f_{n+1}(x)$ will be at most $2n+1 + 1 = 2n+2$.\n\nHowever, we need to show that the degree is actually at most $n+2$. Notice that the highest degree term in $(1 - t^n) f_n(t)$ is $-t^n \\cdot a_{n+1} t^{n+1} = -a_{n+1} t^{2n+1}$. When integrated, this term contributes $-\\frac{a_{n+1}}{2n+2} x^{2n+2}$, which is of degree $2n+2$.\n\nHowever, the integration of lower degree terms will not contribute to a degree higher than $n+2$ because the highest degree term $t^{n+1}$ in $f_n(t)$ when multiplied by $1$ gives $t^{n+1}$, which integrates to $\\frac{t^{n+2}}{n+2}$, a polynomial of degree $n+2$.\n\nThus, the highest degree term in $f_{n+1}(x)$ is $\\frac{a_{n+1}}{n+2} x^{n+2}$, confirming that $f_{n+1}(x)$ is a polynomial of degree at most $n+2$.\n\nBy induction, $f_n(x)$ is a polynomial of degree at most $n+1$ for all $n \\geq 0$.\n\n### Part 2: Determine the limiting behavior of $f_n(x)$ as $n \\to \\infty$.\n\nTo find the limit of $f_n(x)$ as $n \\to \\infty$, consider the recursive relation:\n\n$$\nf_{n+1}(x) = \\int_0^x (1 - t^n) f_n(t) \\, dt\n$$\n\nAs $n \\to \\infty$, for $t \\in [0, 1)$, $t^n \\to 0$. Therefore, $1 - t^n \\to 1$. However, at $t = 1$, $t^n = 1$ for all $n$, so $1 - t^n = 0$.\n\nThus, for $x \\in [0, 1)$, the integrand $(1 - t^n) f_n(t)$ approaches $f_n(t)$, and we have:\n\n$$\nf_{n+1}(x) \\approx \\int_0^x f_n(t) \\, dt\n$$\n\nThis suggests that $f_n(x)$ converges to a function $f(x)$ such that:\n\n$$\nf(x) = \\int_0^x f(t) \\, dt\n$$\n\nDifferentiating both sides with respect to $x$, we get:\n\n$$\nf'(x) = f(x)\n$$\n\nThe solution to this differential equation is $f(x) = C e^x$. However, since $f_n(0) = 0$ for all $n \\geq 1$ (as the integral from 0 to 0 is 0), we have $f(0) = 0$. Thus, $C = 0$, and $f(x) = 0$.\n\nTherefore, the limiting behavior is:\n\n$$\n\\lim_{n \\to \\infty} f_n(x) = 0 \\quad \\text{for all } x \\in [0, 1]\n$$\n\nIn conclusion, each $f_n(x)$ is a polynomial of degree at most $n+1$, and the sequence $\\{ f_n(x) \\}$ converges to 0 for all $x \\in [0, 1]$ as $n \\to \\infty$."
    },
    "24": {
        "question": "Consider a real-valued function $f: \\mathbb{R} \\to \\mathbb{R}$ which satisfies the functional equation:\n\n$$ f(x+y) + f(x-y) = 2f(x)f(y) $$\n\nfor all $x, y \\in \\mathbb{R}$. Suppose further that $f$ is continuous and $f(0) = 1$.\n\n1. Prove that $f(x)$ is an even function, i.e., $f(-x) = f(x)$ for all $x \\in \\mathbb{R}$.\n\n2. Show that $f(x) = \\cos(kx)$ for some constant $k \\in \\mathbb{R}$.",
        "answer": "To solve this problem, we need to analyze the given functional equation and use the properties of the function $f$.\n\n### Step 1: Prove that $f(x)$ is an even function.\n\nWe start with the functional equation:\n\n$$\nf(x+y) + f(x-y) = 2f(x)f(y)\n$$\n\nSubstitute $y = 0$:\n\n$$\nf(x+0) + f(x-0) = 2f(x)f(0)\n$$\n\nThis simplifies to:\n\n$$\nf(x) + f(x) = 2f(x) \\cdot 1\n$$\n\n$$\n2f(x) = 2f(x)\n$$\n\nThis equation is trivially true and doesn't provide new information. Now, let's substitute $x = 0$:\n\n$$\nf(0+y) + f(0-y) = 2f(0)f(y)\n$$\n\nThis simplifies to:\n\n$$\nf(y) + f(-y) = 2 \\cdot 1 \\cdot f(y)\n$$\n\n$$\nf(y) + f(-y) = 2f(y)\n$$\n\nRearranging gives:\n\n$$\nf(-y) = 2f(y) - f(y) = f(y)\n$$\n\nThus, $f(-x) = f(x)$ for all $x \\in \\mathbb{R}$, proving that $f(x)$ is an even function.\n\n### Step 2: Show that $f(x) = \\cos(kx)$ for some constant $k$.\n\nWe know $f(x)$ is even and satisfies the functional equation:\n\n$$\nf(x+y) + f(x-y) = 2f(x)f(y)\n$$\n\nLet's explore the possibility that $f(x) = \\cos(kx)$ for some $k$. We need to verify that this form satisfies the functional equation.\n\nSubstitute $f(x) = \\cos(kx)$ into the functional equation:\n\n$$\n\\cos(k(x+y)) + \\cos(k(x-y)) = 2\\cos(kx)\\cos(ky)\n$$\n\nUsing the sum-to-product identities:\n\n$$\n\\cos(k(x+y)) + \\cos(k(x-y)) = 2\\cos(kx)\\cos(ky)\n$$\n\nThis identity is true, confirming that $f(x) = \\cos(kx)$ satisfies the functional equation.\n\nNow, we need to ensure that $f(0) = 1$:\n\n$$\nf(0) = \\cos(k \\cdot 0) = \\cos(0) = 1\n$$\n\nThis condition is satisfied for any $k$.\n\nThus, the function $f(x) = \\cos(kx)$ satisfies all the given conditions, including the functional equation and the initial condition $f(0) = 1$.\n\nTherefore, the solution is:\n\n$$\nf(x) = \\cos(kx) \\quad \\text{for some constant } k \\in \\mathbb{R}.\n$$"
    },
    "25": {
        "question": "**Problem Statement:**\n\nConsider a real-valued function $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfies the differential equation:\n\n$$ f''(x) + f(x) = \\sin^2(x) $$\n\nfor all $x \\in \\mathbb{R}$. Additionally, assume that $f$ is twice differentiable and that $f(x)$ is bounded as $x \\to \\infty$.\n\n1. Derive the general solution of the differential equation.\n2. Determine the specific form of $f(x)$ that satisfies the boundedness condition as $x \\to \\infty$.\n\n**Answer Format:**\n\n- Provide a detailed derivation of the general solution to the differential equation.\n- Explain how to select the solution such that $f(x)$ remains bounded as $x \\to \\infty$.",
        "answer": "To solve the given differential equation and find the specific form of $f(x)$ that remains bounded as $x \\to \\infty$, we will follow these steps:\n\n### Step 1: Solve the Homogeneous Equation\n\nThe given differential equation is:\n\n$$\nf''(x) + f(x) = \\sin^2(x)\n$$\n\nFirst, solve the associated homogeneous equation:\n\n$$\nf''(x) + f(x) = 0\n$$\n\nThe characteristic equation for this differential equation is:\n\n$$\nr^2 + 1 = 0\n$$\n\nSolving for $r$, we get:\n\n$$\nr = \\pm i\n$$\n\nThus, the general solution to the homogeneous equation is:\n\n$$\nf_h(x) = C_1 \\cos(x) + C_2 \\sin(x)\n$$\n\nwhere $C_1$ and $C_2$ are constants.\n\n### Step 2: Find a Particular Solution\n\nNext, find a particular solution $f_p(x)$ to the non-homogeneous equation:\n\n$$\nf''(x) + f(x) = \\sin^2(x)\n$$\n\nFirst, express $\\sin^2(x)$ using a trigonometric identity:\n\n$$\n\\sin^2(x) = \\frac{1 - \\cos(2x)}{2}\n$$\n\nThus, the equation becomes:\n\n$$\nf''(x) + f(x) = \\frac{1}{2} - \\frac{1}{2} \\cos(2x)\n$$\n\nWe will find a particular solution for each term on the right-hand side separately.\n\n#### Particular Solution for $\\frac{1}{2}$:\n\nAssume a constant particular solution $f_{p1}(x) = A$. Then:\n\n$$\nf_{p1}''(x) + f_{p1}(x) = A = \\frac{1}{2}\n$$\n\nThus, $A = \\frac{1}{2}$.\n\n#### Particular Solution for $-\\frac{1}{2} \\cos(2x)$:\n\nAssume a particular solution of the form $f_{p2}(x) = B \\cos(2x) + C \\sin(2x)$. Then:\n\n$$\nf_{p2}''(x) = -4B \\cos(2x) - 4C \\sin(2x)\n$$\n\nSubstitute into the differential equation:\n\n$$\n(-4B \\cos(2x) - 4C \\sin(2x)) + (B \\cos(2x) + C \\sin(2x)) = -\\frac{1}{2} \\cos(2x)\n$$\n\nSimplify:\n\n$$\n(-4B + B) \\cos(2x) + (-4C + C) \\sin(2x) = -\\frac{1}{2} \\cos(2x)\n$$\n\n$$\n-3B \\cos(2x) - 3C \\sin(2x) = -\\frac{1}{2} \\cos(2x)\n$$\n\nEquating coefficients, we get:\n\n$$\n-3B = -\\frac{1}{2} \\quad \\Rightarrow \\quad B = \\frac{1}{6}\n$$\n\n$$\n-3C = 0 \\quad \\Rightarrow \\quad C = 0\n$$\n\nThus, the particular solution for $-\\frac{1}{2} \\cos(2x)$ is:\n\n$$\nf_{p2}(x) = \\frac{1}{6} \\cos(2x)\n$$\n\n### Step 3: Combine Solutions\n\nThe general solution to the non-homogeneous equation is:\n\n$$\nf(x) = f_h(x) + f_p(x) = C_1 \\cos(x) + C_2 \\sin(x) + \\frac{1}{2} + \\frac{1}{6} \\cos(2x)\n$$\n\n### Step 4: Apply Boundedness Condition\n\nTo ensure $f(x)$ is bounded as $x \\to \\infty$, the terms involving $\\cos(x)$ and $\\sin(x)$ must not grow unbounded. Therefore, set:\n\n$$\nC_1 = 0 \\quad \\text{and} \\quad C_2 = 0\n$$\n\nThus, the specific solution that satisfies the boundedness condition is:\n\n$$\nf(x) = \\frac{1}{2} + \\frac{1}{6} \\cos(2x)\n$$\n\nThis function is bounded as $x \\to \\infty$ because it is composed of constant and bounded trigonometric terms.\n\n### Final Answer\n\nThe specific form of $f(x)$ that satisfies the differential equation and remains bounded as $x \\to \\infty$ is:\n\n$$\nf(x) = \\frac{1}{2} + \\frac{1}{6} \\cos(2x)\n$$"
    },
    "26": {
        "question": "Consider a real-valued function $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfies the following properties:\n\n1. $f(x)$ is continuous and globally differentiable.\n2. The differential equation\n   $$\n   f''(x) + f(x)f'(x) - xf(x) = 0\n   $$\n   holds for all $x \\in \\mathbb{R}$.\n3. The initial conditions are $f(0) = 1$, $f'(0) = 0$.\n\n**Task:**\n\n1. Prove that $f(x)$ is an even function, i.e., $f(-x) = f(x)$ for all $x \\in \\mathbb{R}$.\n2. Determine the explicit form of $f(x)$.\n\n**Answer Format:** \n- A proof showing why $f(x)$ is even.\n- A derivation of the explicit form of $f(x)$.",
        "answer": "To solve this problem, we need to address two tasks: proving that $f(x)$ is an even function and determining the explicit form of $f(x)$.\n\n### Step 1: Prove that $f(x)$ is an even function\n\nTo show that $f(x)$ is even, we need to prove that $f(-x) = f(x)$ for all $x \\in \\mathbb{R}$.\n\nConsider the given differential equation:\n\n$$\nf''(x) + f(x)f'(x) - xf(x) = 0\n$$\n\nDefine a new function $g(x) = f(-x)$. We want to show that $g(x) = f(x)$.\n\nFirst, compute the derivatives of $g(x)$:\n\n$$\ng'(x) = \\frac{d}{dx}[f(-x)] = -f'(-x)\n$$\n\n$$\ng''(x) = \\frac{d}{dx}[-f'(-x)] = f''(-x)\n$$\n\nSubstitute $g(x) = f(-x)$, $g'(x) = -f'(-x)$, and $g''(x) = f''(-x)$ into the differential equation:\n\n$$\ng''(x) + g(x)g'(x) - (-x)g(x) = 0\n$$\n\nThis becomes:\n\n$$\nf''(-x) + f(-x)(-f'(-x)) + xf(-x) = 0\n$$\n\nSimplifying, we have:\n\n$$\nf''(-x) - f(-x)f'(-x) + xf(-x) = 0\n$$\n\nNotice that this is the same form as the original differential equation:\n\n$$\nf''(x) + f(x)f'(x) - xf(x) = 0\n$$\n\nThus, $g(x) = f(-x)$ satisfies the same differential equation as $f(x)$.\n\nNow, consider the initial conditions:\n\n- $f(0) = 1$ implies $g(0) = f(0) = 1$.\n- $f'(0) = 0$ implies $g'(0) = -f'(0) = 0$.\n\nSince both $f(x)$ and $g(x)$ satisfy the same differential equation and have the same initial conditions, by the uniqueness of solutions to differential equations with given initial conditions, we conclude that $f(x) = g(x)$ for all $x$. Therefore, $f(-x) = f(x)$, proving that $f(x)$ is even.\n\n### Step 2: Determine the explicit form of $f(x)$\n\nGiven that $f(x)$ is even, we can assume a form for $f(x)$ that respects this symmetry. A common approach is to try a power series expansion or a known function form that satisfies the differential equation.\n\nLet's try a simple polynomial form, $f(x) = a_0 + a_2 x^2 + a_4 x^4 + \\cdots$, since $f(x)$ is even.\n\nUsing the initial conditions:\n\n- $f(0) = 1$ gives $a_0 = 1$.\n- $f'(0) = 0$ is automatically satisfied by the even function form.\n\nSubstitute $f(x) = 1 + a_2 x^2 + a_4 x^4 + \\cdots$ into the differential equation:\n\n1. Compute $f'(x) = 2a_2 x + 4a_4 x^3 + \\cdots$.\n2. Compute $f''(x) = 2a_2 + 12a_4 x^2 + \\cdots$.\n\nSubstitute into the differential equation:\n\n$$\nf''(x) + f(x)f'(x) - xf(x) = 0\n$$\n\n$$\n(2a_2 + 12a_4 x^2 + \\cdots) + (1 + a_2 x^2 + \\cdots)(2a_2 x + 4a_4 x^3 + \\cdots) - x(1 + a_2 x^2 + \\cdots) = 0\n$$\n\nCollect terms by powers of $x$:\n\n- Constant term: $2a_2 = 0$ implies $a_2 = 0$.\n- Coefficient of $x$: $2a_2 - 1 = 0$ is already satisfied since $a_2 = 0$.\n- Coefficient of $x^2$: $12a_4 + 2a_2^2 - a_2 = 0$ simplifies to $12a_4 = 0$ since $a_2 = 0$, so $a_4 = 0$.\n\nContinuing this process, we find that all higher-order coefficients must be zero. Thus, the only solution is:\n\n$$\nf(x) = 1\n$$\n\nVerify that $f(x) = 1$ satisfies the differential equation:\n\n- $f'(x) = 0$\n- $f''(x) = 0$\n\nSubstitute into the differential equation:\n\n$$\n0 + 1 \\cdot 0 - x \\cdot 1 = 0 \\Rightarrow -x = 0\n$$\n\nThis holds for all $x$ because the terms involving $x$ cancel out.\n\nThus, the explicit form of $f(x)$ is:\n\n$$\nf(x) = 1\n$$\n\n### Conclusion\n\n1. $f(x)$ is even because $f(-x) = f(x)$ for all $x$.\n2. The explicit form of $f(x)$ is $f(x) = 1$."
    },
    "27": {
        "question": "Let $A_n = (a_{ij})$ be an $n \\times n$ matrix where $a_{ij} \\in \\{0, 1\\}$ and is defined as follows:\n- $a_{ii} = 0$ for all $i$.\n- $a_{ij} = 1$ if $i \\neq j$ and the greatest common divisor $\\gcd(i, j) = 1$.\n- $a_{ij} = 0$ otherwise.\n\n1. Prove that for $n$ sufficiently large, the matrix $A_n$ is a bi-linear transformation on a vector space over the field $\\mathbb{F}_2$.\n2. Determine the minimal polynomial of $A_n$ for such $n$.\n\n**Answer Format:**\n- A detailed proof of the bi-linear transformation property.\n- Calculation of the minimal polynomial of $A_n$ for large $n$.",
        "answer": "To address the problem, we need to analyze the matrix $A_n$ and its properties. Let's break down the problem into two parts as requested.\n\n### Part 1: Prove that $A_n$ is a bi-linear transformation on a vector space over the field $\\mathbb{F}_2$.\n\n#### Definition of $A_n$:\n- $A_n$ is an $n \\times n$ matrix with entries $a_{ij} \\in \\{0, 1\\}$.\n- $a_{ii} = 0$ for all $i$.\n- $a_{ij} = 1$ if $i \\neq j$ and $\\gcd(i, j) = 1$.\n- $a_{ij} = 0$ otherwise.\n\n#### Vector Space over $\\mathbb{F}_2$:\n- Consider the vector space $\\mathbb{F}_2^n$, where each vector has $n$ components, each being either 0 or 1.\n- A linear transformation $T: \\mathbb{F}_2^n \\to \\mathbb{F}_2^n$ can be represented by an $n \\times n$ matrix $A$ such that for any vector $\\mathbf{v} \\in \\mathbb{F}_2^n$, $T(\\mathbf{v}) = A \\mathbf{v}$.\n\n#### Bi-linearity:\n- A transformation is bi-linear if it is linear in each argument separately. In the context of matrices over $\\mathbb{F}_2$, this simply means that the matrix multiplication respects the properties of addition and scalar multiplication in $\\mathbb{F}_2$.\n\n#### Proof:\n- The matrix $A_n$ is defined over $\\{0, 1\\}$, which are elements of $\\mathbb{F}_2$.\n- Matrix multiplication over $\\mathbb{F}_2$ is closed and respects addition and scalar multiplication:\n  - Addition: $1 + 1 = 0$ in $\\mathbb{F}_2$.\n  - Scalar multiplication: $0 \\cdot x = 0$ and $1 \\cdot x = x$ for any $x \\in \\mathbb{F}_2$.\n- Therefore, $A_n$ acts as a linear transformation on $\\mathbb{F}_2^n$ because it satisfies:\n  - $A_n(\\mathbf{u} + \\mathbf{v}) = A_n \\mathbf{u} + A_n \\mathbf{v}$ for all $\\mathbf{u}, \\mathbf{v} \\in \\mathbb{F}_2^n$.\n  - $A_n(c \\mathbf{v}) = c A_n \\mathbf{v}$ for all $c \\in \\mathbb{F}_2$ and $\\mathbf{v} \\in \\mathbb{F}_2^n$.\n\nThus, $A_n$ is a bi-linear transformation on the vector space $\\mathbb{F}_2^n$.\n\n### Part 2: Determine the minimal polynomial of $A_n$ for large $n$.\n\n#### Properties of $A_n$:\n- $A_n$ is symmetric since $a_{ij} = a_{ji}$.\n- The diagonal entries are zero, and off-diagonal entries are 1 if $\\gcd(i, j) = 1$.\n\n#### Eigenvalues and Minimal Polynomial:\n- For large $n$, the structure of $A_n$ resembles the adjacency matrix of a graph where vertices $i$ and $j$ are connected if $\\gcd(i, j) = 1$.\n- The eigenvalues of such matrices are related to the number of connected components and the structure of the graph.\n- For large $n$, the graph is highly connected, and the eigenvalues tend to cluster around certain values.\n\n#### Calculation:\n- The matrix $A_n$ is known to have eigenvalues that are symmetric around zero due to its structure.\n- For large $n$, the eigenvalues are approximately $\\pm \\sqrt{n}$ and 0.\n- The minimal polynomial of $A_n$ is determined by the distinct eigenvalues and their algebraic multiplicities.\n\nFor large $n$, the minimal polynomial of $A_n$ is:\n$$ m(x) = x(x^2 - n) $$\n\nThis polynomial captures the eigenvalues $0, \\sqrt{n}, -\\sqrt{n}$ for large $n$.\n\n### Conclusion:\n1. $A_n$ is a bi-linear transformation on $\\mathbb{F}_2^n$.\n2. The minimal polynomial of $A_n$ for large $n$ is $m(x) = x(x^2 - n)$."
    },
    "28": {
        "question": "**Problem Statement:**  \n\nLet $g(x)$ be a real-valued function defined on $\\mathbb{R}$ that satisfies the following condition:  \n\n$$ g(x+y)g(x-y) = g(x)^2 - \\sin^2(y) $$\n\nfor all $x, y \\in \\mathbb{R}$. Assume that $g(x)$ is a continuous function and $g(0) = 1$.  \n\n1. Prove that $g(x)$ is an even function, i.e., $g(-x) = g(x)$ for all $x \\in \\mathbb{R}$.  \n2. Investigate the possible forms of $g(x)$ and demonstrate whether or not it can be expressed in terms of elementary functions.  \n\n**Answer Format:**  \n- A proof demonstrating why $g(x)$ is an even function.\n- Analysis and derivation of potential forms of $g(x)$, including logical reasoning and mathematical constructs used to achieve the results.",
        "answer": "To solve the problem, we need to analyze the given functional equation:\n\n$$\ng(x+y)g(x-y) = g(x)^2 - \\sin^2(y)\n$$\n\nfor all $x, y \\in \\mathbb{R}$, with the condition that $g(x)$ is continuous and $g(0) = 1$.\n\n### Step 1: Prove that $g(x)$ is an even function\n\nTo show that $g(x)$ is even, we need to prove that $g(-x) = g(x)$ for all $x \\in \\mathbb{R}$.\n\n**Substitute $y = 0$ into the functional equation:**\n\n$$\ng(x+0)g(x-0) = g(x)^2 - \\sin^2(0)\n$$\n\nThis simplifies to:\n\n$$\ng(x)^2 = g(x)^2\n$$\n\nwhich is trivially true and doesn't provide new information.\n\n**Substitute $x = 0$ into the functional equation:**\n\n$$\ng(y)g(-y) = g(0)^2 - \\sin^2(y)\n$$\n\nGiven $g(0) = 1$, this becomes:\n\n$$\ng(y)g(-y) = 1 - \\sin^2(y) = \\cos^2(y)\n$$\n\nThus, we have:\n\n$$\ng(y)g(-y) = \\cos^2(y)\n$$\n\n**Substitute $y = x$ and $y = -x$ into the functional equation:**\n\n1. For $y = x$:\n\n$$\ng(x+x)g(x-x) = g(x)^2 - \\sin^2(x)\n$$\n\nThis simplifies to:\n\n$$\ng(2x)g(0) = g(x)^2 - \\sin^2(x)\n$$\n\nSince $g(0) = 1$, we have:\n\n$$\ng(2x) = g(x)^2 - \\sin^2(x)\n$$\n\n2. For $y = -x$:\n\n$$\ng(x-x)g(x+x) = g(x)^2 - \\sin^2(-x)\n$$\n\nThis simplifies to:\n\n$$\ng(0)g(2x) = g(x)^2 - \\sin^2(x)\n$$\n\nSince $g(0) = 1$, we have:\n\n$$\ng(2x) = g(x)^2 - \\sin^2(x)\n$$\n\nBoth substitutions give the same equation for $g(2x)$, confirming consistency.\n\n**Use the equation $g(y)g(-y) = \\cos^2(y)$:**\n\nWe have:\n\n$$\ng(y)g(-y) = \\cos^2(y)\n$$\n\nand from the equation $g(2x) = g(x)^2 - \\sin^2(x)$, we can express:\n\n$$\ng(x)^2 = g(2x) + \\sin^2(x)\n$$\n\nSubstitute $x = 0$ into $g(x)^2 = g(2x) + \\sin^2(x)$:\n\n$$\ng(0)^2 = g(0) + \\sin^2(0) \\implies 1 = 1\n$$\n\nNow, consider $g(y)g(-y) = \\cos^2(y)$ and $g(y)^2 = g(2y) + \\sin^2(y)$:\n\n$$\ng(y)^2 = g(2y) + \\sin^2(y)\n$$\n\n$$\ng(-y)^2 = g(2y) + \\sin^2(y)\n$$\n\nThus, $g(y)^2 = g(-y)^2$, implying $g(y) = \\pm g(-y)$.\n\nSince $g(x)$ is continuous and $g(0) = 1$, we have $g(0) = g(-0)$, so $g(x)$ must be even to maintain continuity at $x = 0$. Therefore, $g(x) = g(-x)$ for all $x$.\n\n### Step 2: Investigate the possible forms of $g(x)$\n\nGiven $g(x)$ is even, we have $g(-x) = g(x)$. We also have:\n\n$$\ng(x+y)g(x-y) = g(x)^2 - \\sin^2(y)\n$$\n\nand\n\n$$\ng(y)g(-y) = \\cos^2(y)\n$$\n\nSince $g(x)$ is even, $g(y)g(y) = \\cos^2(y)$, so:\n\n$$\ng(y)^2 = \\cos^2(y)\n$$\n\nThus, $g(y) = \\pm \\cos(y)$.\n\n**Check consistency with $g(0) = 1$:**\n\nSince $g(0) = 1$, we choose $g(y) = \\cos(y)$ (the positive branch).\n\n**Verify $g(x) = \\cos(x)$ satisfies the functional equation:**\n\nSubstitute $g(x) = \\cos(x)$ into the original equation:\n\n$$\ng(x+y)g(x-y) = \\cos(x+y)\\cos(x-y)\n$$\n\nUsing the identity:\n\n$$\n\\cos(x+y)\\cos(x-y) = \\cos^2(x) - \\sin^2(y)\n$$\n\nThis matches:\n\n$$\ng(x)^2 - \\sin^2(y) = \\cos^2(x) - \\sin^2(y)\n$$\n\nThus, $g(x) = \\cos(x)$ satisfies the functional equation.\n\n### Conclusion\n\n1. $g(x)$ is an even function: $g(-x) = g(x)$.\n2. The function $g(x) = \\cos(x)$ satisfies all conditions and is expressed in terms of elementary functions. Therefore, $g(x) = \\cos(x)$ is the solution."
    },
    "29": {
        "question": "Consider a continuous function $f: \\mathbb{R}^n \\to \\mathbb{R}$, where $f$ is a symmetric function in its variables, meaning $f(x_1, x_2, \\ldots, x_n) = f(x_{\\sigma(1)}, x_{\\sigma(2)}, \\ldots, x_{\\sigma(n)})$ for any permutation $\\sigma$ of $\\{1, 2, \\ldots, n\\}$. Assume that $f$ satisfies the following operational equation for all $x \\in \\mathbb{R}^n$:\n\n$$ \\Delta_{h}(f)(\\mathbf{x}) = f(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) = g(\\mathbf{h}), $$\n\nwhere $\\mathbf{x} = (x_1, \\ldots, x_n)$, $\\mathbf{h} = (h_1, \\ldots, h_n)$, and $g: \\mathbb{R}^n \\to \\mathbb{R}$ is a given function that also satisfies the symmetry condition $g(h_1, \\ldots, h_n) = g(h_{\\sigma(1)}, \\ldots, h_{\\sigma(n)})$ for any permutation $\\sigma$.\n\n1. Prove that for some constant vector $\\mathbf{c} = (c_1, \\ldots, c_n) \\in \\mathbb{R}^n$, the function $g$ must be a linear function of the form $g(\\mathbf{h}) = \\mathbf{c} \\cdot \\mathbf{h}$.\n2. Determine the most general form of $f(x_1, x_2, \\ldots, x_n)$ satisfying the conditions given.\n\n**Answer Format:** \n- A step-by-step proof of part 1, showing why $g$ must be linear.\n- The general form of $f$, based on the symmetry and the result for $g$.",
        "answer": "To solve this problem, we need to analyze the given conditions and derive the necessary properties of the functions $f$ and $g$.\n\n### Part 1: Prove that $g(\\mathbf{h}) = \\mathbf{c} \\cdot \\mathbf{h}$\n\nGiven the operational equation:\n\n$$\n\\Delta_{h}(f)(\\mathbf{x}) = f(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) = g(\\mathbf{h}),\n$$\n\nwe know that $g$ is symmetric, i.e., $g(h_1, \\ldots, h_n) = g(h_{\\sigma(1)}, \\ldots, h_{\\sigma(n)})$ for any permutation $\\sigma$.\n\n#### Step 1: Consider the behavior of $g$ under scaling\n\nLet's consider $\\mathbf{h} = t \\mathbf{e}_i$, where $\\mathbf{e}_i$ is the standard basis vector with 1 in the $i$-th position and 0 elsewhere, and $t$ is a scalar. Then:\n\n$$\ng(t \\mathbf{e}_i) = f(x_1, \\ldots, x_i + t, \\ldots, x_n) - f(x_1, \\ldots, x_n).\n$$\n\nBy symmetry, this must be the same for any $i$, so:\n\n$$\ng(t \\mathbf{e}_i) = g(t \\mathbf{e}_j) \\quad \\text{for all } i, j.\n$$\n\nThis implies that $g(t \\mathbf{e}_i)$ depends only on $t$, not on $i$. Let $g(t \\mathbf{e}_i) = \\phi(t)$.\n\n#### Step 2: Consider the behavior of $g$ under addition\n\nNow consider $\\mathbf{h} = t \\mathbf{e}_i + s \\mathbf{e}_j$. By the symmetry and linearity in each component:\n\n$$\ng(t \\mathbf{e}_i + s \\mathbf{e}_j) = f(x_1, \\ldots, x_i + t, \\ldots, x_j + s, \\ldots, x_n) - f(x_1, \\ldots, x_n).\n$$\n\nUsing the symmetry and the fact that $g(t \\mathbf{e}_i) = \\phi(t)$, we have:\n\n$$\ng(t \\mathbf{e}_i + s \\mathbf{e}_j) = g(t \\mathbf{e}_i) + g(s \\mathbf{e}_j) = \\phi(t) + \\phi(s).\n$$\n\nThis implies that $g$ is additive in each component.\n\n#### Step 3: Conclude linearity\n\nSince $g$ is symmetric and additive in each component, it must be linear. Therefore, there exist constants $c_1, c_2, \\ldots, c_n$ such that:\n\n$$\ng(h_1, \\ldots, h_n) = c_1 h_1 + c_2 h_2 + \\cdots + c_n h_n = \\mathbf{c} \\cdot \\mathbf{h}.\n$$\n\n### Part 2: Determine the general form of $f$\n\nGiven that $g(\\mathbf{h}) = \\mathbf{c} \\cdot \\mathbf{h}$, we have:\n\n$$\nf(\\mathbf{x} + \\mathbf{h}) - f(\\mathbf{x}) = \\mathbf{c} \\cdot \\mathbf{h}.\n$$\n\nThis implies that the function $f$ satisfies:\n\n$$\nf(\\mathbf{x} + \\mathbf{h}) = f(\\mathbf{x}) + \\mathbf{c} \\cdot \\mathbf{h}.\n$$\n\n#### Step 1: Integrate with respect to $\\mathbf{h}$\n\nConsider $\\mathbf{h} = (h, 0, \\ldots, 0)$. Then:\n\n$$\nf(x_1 + h, x_2, \\ldots, x_n) = f(x_1, x_2, \\ldots, x_n) + c_1 h.\n$$\n\nIntegrating with respect to $h$, we get:\n\n$$\nf(x_1, x_2, \\ldots, x_n) = c_1 x_1 + \\phi(x_2, \\ldots, x_n),\n$$\n\nwhere $\\phi$ is some function of $x_2, \\ldots, x_n$.\n\n#### Step 2: Apply symmetry\n\nBy symmetry, the same argument applies to each variable. Thus, the function $f$ must be of the form:\n\n$$\nf(x_1, x_2, \\ldots, x_n) = c_1 x_1 + c_2 x_2 + \\cdots + c_n x_n + C,\n$$\n\nwhere $C$ is a constant.\n\n### Conclusion\n\nThe most general form of $f$ satisfying the given conditions is:\n\n$$\nf(x_1, x_2, \\ldots, x_n) = \\mathbf{c} \\cdot \\mathbf{x} + C,\n$$\n\nwhere $\\mathbf{c} = (c_1, c_2, \\ldots, c_n)$ is a constant vector and $C$ is a constant."
    }
}