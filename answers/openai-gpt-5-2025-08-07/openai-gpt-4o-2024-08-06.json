{
    "0": {
        "question": "Determine all continuous pairs of functions f, g: (0, \u221e) \u2192 \u211d such that for every x, y > 0 the following system holds:\n- g(xy) + g(x/y) = 2 g(x) g(y),\n- f(xy) + f(x/y) = 2 f(x) g(y).\n\nYour answer should give an explicit parametrization of all such pairs (f, g), prove that every pair in your list satisfies the system, and prove that no other continuous pairs do.",
        "answer": "To solve this problem, we need to find all continuous pairs of functions $f, g: (0, \\infty) \\to \\mathbb{R}$ that satisfy the given system of functional equations for all $x, y > 0$:\n\n1. $g(xy) + g(x/y) = 2 g(x) g(y)$\n2. $f(xy) + f(x/y) = 2 f(x) g(y)$\n\n### Step 1: Analyze the first equation\n\nThe first equation is a functional equation for $g$. Let's analyze it:\n\n$$ g(xy) + g(x/y) = 2 g(x) g(y) $$\n\nThis equation resembles a form of the Cauchy functional equation, but with a multiplicative structure. A common solution to such equations is $g(x) = x^c$ for some constant $c$. Let's test this form:\n\nSubstitute $g(x) = x^c$ into the equation:\n\n$$ (xy)^c + (x/y)^c = 2 (x^c)(y^c) $$\n\nThis simplifies to:\n\n$$ x^c y^c + x^c y^{-c} = 2 x^c y^c $$\n\nDivide through by $x^c$:\n\n$$ y^c + y^{-c} = 2 y^c $$\n\nRearrange:\n\n$$ y^{-c} = y^c $$\n\nThis implies $y^{-2c} = 1$, so $y^{2c} = 1$ for all $y > 0$. The only continuous solution is $c = 0$, which gives $g(x) = 1$.\n\n### Step 2: Analyze the second equation with $g(x) = 1$\n\nSubstitute $g(x) = 1$ into the second equation:\n\n$$ f(xy) + f(x/y) = 2 f(x) $$\n\nThis is a form of the d'Alembert functional equation. A known continuous solution to this equation is $f(x) = A \\log x$ for some constant $A$.\n\n### Step 3: Verify the solutions\n\nLet's verify that $g(x) = 1$ and $f(x) = A \\log x$ satisfy both equations:\n\n1. For the first equation:\n\n   $$ g(xy) + g(x/y) = 1 + 1 = 2 = 2 \\cdot 1 \\cdot 1 = 2 g(x) g(y) $$\n\n   This holds true.\n\n2. For the second equation:\n\n   $$ f(xy) + f(x/y) = A \\log(xy) + A \\log(x/y) = A (\\log x + \\log y) + A (\\log x - \\log y) = 2A \\log x = 2 f(x) $$\n\n   This holds true.\n\n### Conclusion\n\nThe continuous solutions to the system are:\n\n- $g(x) = 1$\n- $f(x) = A \\log x$ for some constant $A$.\n\nThese are the only continuous solutions because the form of the equations and the requirement of continuity restrict $g(x)$ to be constant and $f(x)$ to be a logarithmic function. Thus, the explicit parametrization of all such pairs is:\n\n$$ (f(x), g(x)) = (A \\log x, 1) $$\n\nfor any real constant $A$."
    },
    "1": {
        "question": "Compute the exact number of spanning trees of the d-dimensional hypercube Q_d, for each integer d \u2265 1.\n\nDefinitions:\n- The d-dimensional hypercube graph Q_d has vertex set V = {0,1}^d; two vertices are adjacent iff they differ in exactly one coordinate. Thus |V| = 2^d and Q_d is d-regular.\n- A spanning tree of a connected graph G is a tree subgraph containing all vertices of G.\n\nYour task:\n- Derive a closed-form product formula for the number \u03c4(Q_d) of spanning trees of Q_d in terms of d and binomial coefficients.\n- Your solution must include a rigorous derivation. You may use (with justification and definitions) the adjacency/Laplacian spectrum and Kirchhoff\u2019s Matrix-Tree Theorem, but the argument should be self-contained: define all objects you use and justify key steps.\n\nAnswer format:\n- State your final closed-form expression for \u03c4(Q_d).\n- Then provide a complete proof of the formula.",
        "answer": "To find the number of spanning trees of the d-dimensional hypercube $Q_d$, we will use Kirchhoff's Matrix-Tree Theorem, which relates the number of spanning trees of a graph to the eigenvalues of its Laplacian matrix.\n\n### Step 1: Define the Laplacian Matrix\n\nFor a graph $G$ with $n$ vertices, the Laplacian matrix $L$ is defined as $L = D - A$, where $D$ is the degree matrix (a diagonal matrix where each diagonal entry is the degree of the corresponding vertex) and $A$ is the adjacency matrix of $G$.\n\nFor the d-dimensional hypercube $Q_d$:\n- The number of vertices is $|V| = 2^d$.\n- Each vertex has degree $d$, so $D = dI$ where $I$ is the identity matrix of size $2^d \\times 2^d$.\n- The adjacency matrix $A$ has entries $A_{uv} = 1$ if vertices $u$ and $v$ differ in exactly one coordinate, and $A_{uv} = 0$ otherwise.\n\nThus, the Laplacian matrix $L$ is given by:\n$$ L = dI - A. $$\n\n### Step 2: Eigenvalues of the Laplacian\n\nThe eigenvalues of the adjacency matrix $A$ of $Q_d$ are known to be $\\lambda_k = d - 2k$ for $k = 0, 1, \\ldots, d$, with multiplicity $\\binom{d}{k}$. Therefore, the eigenvalues of the Laplacian $L = dI - A$ are:\n$$ \\mu_k = d - (d - 2k) = 2k, $$\nwith multiplicity $\\binom{d}{k}$.\n\n### Step 3: Apply Kirchhoff's Matrix-Tree Theorem\n\nKirchhoff's Matrix-Tree Theorem states that the number of spanning trees $\\tau(G)$ of a graph $G$ is equal to any cofactor of its Laplacian matrix $L$. This is equivalent to:\n$$ \\tau(G) = \\frac{1}{n} \\prod_{i=2}^{n} \\mu_i, $$\nwhere $\\mu_1 = 0$ is the smallest eigenvalue of $L$ (corresponding to the all-ones vector), and $\\mu_2, \\ldots, \\mu_n$ are the non-zero eigenvalues.\n\nFor $Q_d$, the number of vertices $n = 2^d$, and the non-zero eigenvalues of $L$ are $2k$ for $k = 1, 2, \\ldots, d$, each with multiplicity $\\binom{d}{k}$.\n\nThus, the number of spanning trees is:\n$$ \\tau(Q_d) = \\frac{1}{2^d} \\prod_{k=1}^{d} (2k)^{\\binom{d}{k}}. $$\n\n### Step 4: Simplify the Expression\n\nThe expression can be simplified by recognizing that:\n$$ \\prod_{k=1}^{d} (2k)^{\\binom{d}{k}} = 2^{\\sum_{k=1}^{d} \\binom{d}{k}} \\prod_{k=1}^{d} k^{\\binom{d}{k}}. $$\n\nSince $\\sum_{k=0}^{d} \\binom{d}{k} = 2^d$, we have:\n$$ \\sum_{k=1}^{d} \\binom{d}{k} = 2^d - 1. $$\n\nThus:\n$$ \\tau(Q_d) = \\frac{1}{2^d} \\cdot 2^{2^d - 1} \\cdot \\prod_{k=1}^{d} k^{\\binom{d}{k}} = 2^{2^d - d - 1} \\prod_{k=1}^{d} k^{\\binom{d}{k}}. $$\n\n### Final Result\n\nThe exact number of spanning trees of the d-dimensional hypercube $Q_d$ is:\n$$ \\tau(Q_d) = 2^{2^d - d - 1} \\prod_{k=1}^{d} k^{\\binom{d}{k}}. $$\n\nThis completes the derivation of the closed-form expression for the number of spanning trees of the d-dimensional hypercube."
    },
    "2": {
        "question": "Prove the Cauchy determinant identity in full generality and use it to compute the determinant of the Hilbert matrix.\n\nLet n \u2265 1 be an integer, and let x_1, ..., x_n and y_1, ..., y_n be complex numbers such that:\n- x_i + y_j \u2260 0 for all i, j,\n- x_i \u2260 x_j for i \u2260 j, and y_i \u2260 y_j for i \u2260 j.\n\nDefine the n \u00d7 n Cauchy matrix C = [c_{ij}] by c_{ij} = 1/(x_i + y_j).\n\nTasks:\n1) Prove that\ndet C = (\u220f_{1 \u2264 i < j \u2264 n} (x_j \u2212 x_i)) (\u220f_{1 \u2264 i < j \u2264 n} (y_j \u2212 y_i)) / (\u220f_{i=1}^n \u220f_{j=1}^n (x_i + y_j)).\n\nYour proof must be self-contained and rigorous. You may use standard properties of determinants, but you should not assume the identity itself or invoke heavy machinery.\n\n2) Let H_n denote the n \u00d7 n Hilbert matrix with entries (H_n)_{ij} = 1/(i + j \u2212 1) for 1 \u2264 i, j \u2264 n. Use part (1) to obtain a closed-form product formula for det(H_n). Present your final answer in a compact product form, for example\ndet(H_n) = [\u220f_{k=1}^{n-1} (k!)^4] / [\u220f_{k=1}^{2n-1} k^{2n-k}],\nand justify this (or an equivalent) form from first principles.\n\nAnswer format:\n- State the final formula for det C.\n- Provide a complete proof of (1).\n- State the final closed form for det(H_n).\n- Derive it cleanly from (1), including any necessary combinatorial product identities.",
        "answer": "To solve this problem, we need to prove the Cauchy determinant identity and then use it to compute the determinant of the Hilbert matrix.\n\n### Part 1: Prove the Cauchy Determinant Identity\n\n**Statement:**\nFor an $n \\times n$ Cauchy matrix $C = [c_{ij}]$ with $c_{ij} = \\frac{1}{x_i + y_j}$, the determinant is given by:\n\n$$\n\\det C = \\frac{\\prod_{1 \\le i < j \\le n} (x_j - x_i) \\prod_{1 \\le i < j \\le n} (y_j - y_i)}{\\prod_{i=1}^n \\prod_{j=1}^n (x_i + y_j)}\n$$\n\n**Proof:**\n\n1. **Matrix Definition and Properties:**\n   - The Cauchy matrix $C$ is defined by $c_{ij} = \\frac{1}{x_i + y_j}$.\n   - The determinant of a matrix is a multilinear alternating function of its rows (or columns).\n\n2. **Construct the Matrix:**\n   - Consider the matrix $C = [c_{ij}]$ where $c_{ij} = \\frac{1}{x_i + y_j}$.\n\n3. **Use the Vandermonde Determinant:**\n   - The Vandermonde determinant for a set of variables $z_1, z_2, \\ldots, z_n$ is given by:\n     $$\n     \\det(V) = \\prod_{1 \\le i < j \\le n} (z_j - z_i)\n     $$\n   - We will use this property for both $x_i$ and $y_j$.\n\n4. **Transform the Matrix:**\n   - Consider the transformation of the matrix $C$ by multiplying each row $i$ by $\\prod_{k \\neq i} (x_i - x_k)$ and each column $j$ by $\\prod_{l \\neq j} (y_j - y_l)$.\n   - This results in a new matrix $C'$ where each entry is:\n     $$\n     c'_{ij} = \\frac{\\prod_{k \\neq i} (x_i - x_k) \\prod_{l \\neq j} (y_j - y_l)}{x_i + y_j}\n     $$\n\n5. **Calculate the Determinant:**\n   - The determinant of $C'$ is the product of the determinants of the row and column transformations times the determinant of $C$.\n   - The determinant of the row transformation is $\\prod_{1 \\le i < j \\le n} (x_j - x_i)$ and similarly for the column transformation.\n   - Therefore, the determinant of $C'$ is:\n     $$\n     \\det(C') = \\left(\\prod_{1 \\le i < j \\le n} (x_j - x_i)\\right)^2 \\left(\\prod_{1 \\le i < j \\le n} (y_j - y_i)\\right)^2 \\det(C)\n     $$\n\n6. **Simplify:**\n   - The matrix $C'$ is a diagonal matrix with diagonal entries:\n     $$\n     c'_{ii} = \\prod_{k \\neq i} (x_i - x_k) \\prod_{l \\neq i} (y_i - y_l)\n     $$\n   - The determinant of $C'$ is the product of its diagonal entries:\n     $$\n     \\det(C') = \\prod_{i=1}^n \\prod_{k \\neq i} (x_i - x_k) \\prod_{l \\neq i} (y_i - y_l)\n     $$\n\n7. **Final Expression:**\n   - Equating the two expressions for $\\det(C')$, we have:\n     $$\n     \\left(\\prod_{1 \\le i < j \\le n} (x_j - x_i)\\right)^2 \\left(\\prod_{1 \\le i < j \\le n} (y_j - y_i)\\right)^2 \\det(C) = \\prod_{i=1}^n \\prod_{k \\neq i} (x_i - x_k) \\prod_{l \\neq i} (y_i - y_l)\n     $$\n   - Solving for $\\det(C)$, we get:\n     $$\n     \\det(C) = \\frac{\\prod_{1 \\le i < j \\le n} (x_j - x_i) \\prod_{1 \\le i < j \\le n} (y_j - y_i)}{\\prod_{i=1}^n \\prod_{j=1}^n (x_i + y_j)}\n     $$\n\n### Part 2: Compute the Determinant of the Hilbert Matrix\n\n**Hilbert Matrix:**\nThe $n \\times n$ Hilbert matrix $H_n$ has entries $(H_n)_{ij} = \\frac{1}{i + j - 1}$.\n\n**Using the Cauchy Determinant Identity:**\n\n1. **Identify Parameters:**\n   - Set $x_i = i$ and $y_j = j - 1$ for the Hilbert matrix.\n   - The entries become $c_{ij} = \\frac{1}{i + (j - 1)} = \\frac{1}{i + j - 1}$.\n\n2. **Apply the Cauchy Determinant Formula:**\n   - The determinant of the Hilbert matrix is:\n     $$\n     \\det(H_n) = \\frac{\\prod_{1 \\le i < j \\le n} (j - i) \\prod_{1 \\le i < j \\le n} ((j - 1) - (i - 1))}{\\prod_{i=1}^n \\prod_{j=1}^n (i + j - 1)}\n     $$\n\n3. **Simplify:**\n   - The numerator simplifies to:\n     $$\n     \\prod_{1 \\le i < j \\le n} (j - i)^2\n     $$\n   - The denominator is:\n     $$\n     \\prod_{i=1}^n \\prod_{j=1}^n (i + j - 1)\n     $$\n\n4. **Final Expression:**\n   - The determinant of the Hilbert matrix is:\n     $$\n     \\det(H_n) = \\frac{\\prod_{1 \\le i < j \\le n} (j - i)^2}{\\prod_{i=1}^n \\prod_{j=1}^n (i + j - 1)}\n     $$\n\n5. **Closed Form:**\n   - The closed form for the determinant of the Hilbert matrix is:\n     $$\n     \\det(H_n) = \\frac{[1! \\cdot 2! \\cdot \\ldots \\cdot (n-1)!]^4}{[1 \\cdot 2 \\cdot \\ldots \\cdot (2n-1)]^{2n}}\n     $$\n\nThis completes the proof and computation of the determinant of the Hilbert matrix using the Cauchy determinant identity."
    },
    "3": {
        "question": "Prove the Combinatorial Nullstellensatz and use it to establish the Erd\u0151s\u2013Heilbronn restricted sumset inequality over a prime field.\n\nDefinitions:\n- Let F be a field. For a polynomial f \u2208 F[x_1,\u2026,x_n], define its total degree deg f as the maximum, over all monomials x_1^{\u03b1_1}\u22efx_n^{\u03b1_n} with nonzero coefficient in f, of \u03b1_1+\u22ef+\u03b1_n. For a multi-index t = (t_1,\u2026,t_n) of nonnegative integers, denote by [x_1^{t_1}\u22efx_n^{t_n}] f the coefficient of that monomial in f.\n- For a prime p, write F_p for the field Z/pZ. For A \u2282 F_p finite, define the restricted sumset A \u2295 A = {a+b : a,b \u2208 A, a \u2260 b}.\n\nTasks:\n1) Combinatorial Nullstellensatz (CNS). Prove the following.\nLet f \u2208 F[x_1,\u2026,x_n] be a polynomial and suppose there exist nonnegative integers t_1,\u2026,t_n with t_1+\u22ef+t_n = deg f such that c := [x_1^{t_1}\u22efx_n^{t_n}] f \u2260 0. If S_1,\u2026,S_n \u2282 F are finite sets with |S_i| > t_i for all i, then there exist s_i \u2208 S_i such that f(s_1,\u2026,s_n) \u2260 0.\n\nYou should give a complete, self-contained proof. You may use basic univariate Lagrange interpolation, but no external theorems.\n\n2) Erd\u0151s\u2013Heilbronn (restricted sumset over F_p). Let p be prime and let A \u2282 F_p have size m \u2265 2. Prove that\n|A \u2295 A| \u2265 min{p, 2m \u2212 3}.\nYour proof must be self-contained and rigorous and must use part (1). Hints for the hard case p \u2265 2m \u2212 3: argue by contradiction, cover A \u2295 A by a small set C and consider the polynomial\nG(x,y) = (x \u2212 y) \u220f_{c\u2208C} (x + y \u2212 c)\non S_1 = S_2 = A; compute a specific top-degree coefficient of G and apply CNS with suitable (t_1,t_2). For the complementary case 2m \u2212 3 > p, finish by a direct combinatorial argument (e.g., intersect A with translates of itself).\n\nAnswer format:\n- State and prove the Combinatorial Nullstellensatz.\n- Then prove the Erd\u0151s\u2013Heilbronn inequality in full, handling the cases p \u2265 2m \u2212 3 and p < 2m \u2212 3.\n- Clearly identify the crucial coefficient you compute in G and why it is nonzero in F_p in the CNS step.",
        "answer": "To solve this problem, we will first prove the Combinatorial Nullstellensatz (CNS) and then use it to establish the Erd\u0151s\u2013Heilbronn restricted sumset inequality over a prime field.\n\n### 1) Combinatorial Nullstellensatz (CNS)\n\n**Statement:**\nLet $f \\in F[x_1, \\ldots, x_n]$ be a polynomial. Suppose there exist nonnegative integers $t_1, \\ldots, t_n$ with $t_1 + \\cdots + t_n = \\deg f$ such that the coefficient $c = [x_1^{t_1} \\cdots x_n^{t_n}] f \\neq 0$. If $S_1, \\ldots, S_n \\subset F$ are finite sets with $|S_i| > t_i$ for all $i$, then there exist $s_i \\in S_i$ such that $f(s_1, \\ldots, s_n) \\neq 0$.\n\n**Proof:**\nWe will use induction on the number of variables $n$.\n\n**Base Case ($n = 1$):**\nFor a univariate polynomial $f(x)$ of degree $d$ with leading coefficient $c \\neq 0$, if $S \\subset F$ with $|S| > d$, then $f$ cannot vanish on all of $S$. This follows from the fact that a polynomial of degree $d$ can have at most $d$ roots.\n\n**Inductive Step:**\nAssume the statement holds for $n-1$ variables. Consider $f(x_1, \\ldots, x_n)$ with $\\deg f = t_1 + \\cdots + t_n$ and $c = [x_1^{t_1} \\cdots x_n^{t_n}] f \\neq 0$.\n\nFix $x_2, \\ldots, x_n$ and consider $f(x_1, x_2, \\ldots, x_n)$ as a polynomial in $x_1$. Its degree in $x_1$ is at most $t_1$. The leading coefficient of this polynomial, when considered as a polynomial in $x_1$, is a polynomial in $x_2, \\ldots, x_n$ with degree $t_2 + \\cdots + t_n$ and nonzero coefficient for the term $x_2^{t_2} \\cdots x_n^{t_n}$.\n\nBy the inductive hypothesis, since $|S_i| > t_i$ for $i = 2, \\ldots, n$, there exist $s_2 \\in S_2, \\ldots, s_n \\in S_n$ such that the leading coefficient of $f(x_1, s_2, \\ldots, s_n)$ as a polynomial in $x_1$ is nonzero. Thus, $f(x_1, s_2, \\ldots, s_n)$ is a nonzero polynomial of degree at most $t_1$ in $x_1$, and since $|S_1| > t_1$, there exists $s_1 \\in S_1$ such that $f(s_1, s_2, \\ldots, s_n) \\neq 0$.\n\nThis completes the induction and proves the CNS.\n\n### 2) Erd\u0151s\u2013Heilbronn Inequality\n\n**Statement:**\nLet $p$ be a prime and $A \\subset F_p$ with size $m \\geq 2$. Prove that $|A \\oplus A| \\geq \\min\\{p, 2m - 3\\}$.\n\n**Proof:**\n\n**Case 1: $p \\geq 2m - 3$:**\n\nAssume for contradiction that $|A \\oplus A| < 2m - 3$. Let $C \\subset F_p$ be a set such that $A \\oplus A \\subset C$ and $|C| < 2m - 3$.\n\nConsider the polynomial:\n$$\nG(x, y) = (x - y) \\prod_{c \\in C} (x + y - c).\n$$\nThe degree of $G$ is $1 + |C| < 2m - 2$.\n\nApply CNS with $S_1 = S_2 = A$. We have $|S_1| = |S_2| = m$. Choose $t_1 = t_2 = m - 1$ so that $t_1 + t_2 = 2m - 2$, which matches the degree of $G$.\n\nThe crucial coefficient is the one of $x^{m-1} y^{m-1}$ in $G(x, y)$. This coefficient is:\n$$\n(-1)^{m-1} \\cdot (m-1)! \\cdot (m-1)! \\cdot [x^{m-1} y^{m-1}] \\prod_{c \\in C} (x + y - c).\n$$\nThe term $[x^{m-1} y^{m-1}] \\prod_{c \\in C} (x + y - c)$ is nonzero because the polynomial $\\prod_{c \\in C} (x + y - c)$ has degree less than $2m - 2$ and cannot have all its coefficients vanish.\n\nThus, by CNS, there exist $a, b \\in A$ with $a \\neq b$ such that $G(a, b) \\neq 0$, contradicting $A \\oplus A \\subset C$.\n\n**Case 2: $2m - 3 > p$:**\n\nIn this case, $|A \\oplus A| \\leq p$ trivially, and we need to show $|A \\oplus A| \\geq p$. Since $A \\subset F_p$, $|A \\oplus A|$ can be at most $p$, and the inequality $|A \\oplus A| \\geq p$ is trivially satisfied.\n\nThus, in both cases, we have $|A \\oplus A| \\geq \\min\\{p, 2m - 3\\}$, completing the proof."
    },
    "4": {
        "question": "Title: Kronecker\u2013Chebyshev classification of algebraic integers with all conjugates in [\u22122,2], and a cyclotomic factorization of Chebyshev polynomials\n\nLet \u03b1 be an algebraic integer. Recall:\n- An algebraic integer is a complex number that is a root of a monic polynomial with integer coefficients.\n- The Galois conjugates of \u03b1 are the images of \u03b1 under all embeddings of Q(\u03b1) into C; equivalently, they are the roots of the minimal polynomial of \u03b1 over Q.\n- A root of unity is a complex number \u03b6 with \u03b6^n = 1 for some n \u2265 1.\n- The nth cyclotomic polynomial \u03a6_n(z) is the monic polynomial with roots the primitive nth roots of unity; deg \u03a6_n = \u03c6(n), Euler\u2019s totient.\n- The Chebyshev polynomials of the first kind T_m are the unique polynomials with T_m(cos \u03b8) = cos(m\u03b8) for all real \u03b8.\n\nDefine, for n \u2265 1, the real cyclotomic polynomial C_n(x) to be the minimal polynomial over Q of 2 cos(2\u03c0/n). Convention: C_1(x) = x \u2212 2, C_2(x) = x + 2. For n \u2265 3, its degree is \u03c6(n)/2.\n\nTasks:\n1) Kronecker\u2019s unit-disk lemma (self-contained). Prove: If \u03b2 is an algebraic integer and all its Galois conjugates satisfy |\u03b2'| \u2264 1, then \u03b2 = 0 or \u03b2 is a root of unity.\n\n2) Classification in [\u22122,2]. Prove: If \u03b1 is an algebraic integer and all of its conjugates lie in [\u22122,2], then \u03b1 = \u03b6 + \u03b6^{-1} for some root of unity \u03b6 (equivalently, \u03b1 = 2 cos(2\u03c0 a/n) for integers a, n with gcd(a,n) = 1). In particular, the minimal polynomial of \u03b1 equals C_n(x) for some n, and C_n(x) \u2208 Z[x].\n\n3) Cyclotomic\u2013real cyclotomic identity. For n \u2265 3, prove the identity\n\u03a6_n(z) = z^{\u03c6(n)/2} C_n(z + z^{-1}).\nHandle n = 1, 2 separately by the conventions above.\n\n4) Classification of integer polynomials with spectrum in [\u22122,2]. Show that a monic polynomial P \u2208 Z[x] has all complex roots in [\u22122,2] if and only if P is a product (with multiplicities) of the polynomials C_n(x), n \u2265 1.\n\n5) Chebyshev factorization. Prove the explicit factorization, valid for every integer m \u2265 1:\n2(T_m(x/2) \u2212 1) = C_1(x) C_2(x)^{\u03b5(m)} \u220f_{d | m, d \u2265 3} C_d(x)^2,\nwhere \u03b5(m) = 1 if 2 | m and \u03b5(m) = 0 otherwise.\n\nAnswer format:\n- Provide a complete, rigorous proof of each task, self-contained (you may use only what is defined above).\n- Clearly indicate where you use Task (1).\n- For Task (3), justify integrality and monicity of both sides and identify their sets of roots.\n- For Task (5), derive the factorization from Task (3) and the identity T_m((z + z^{-1})/2) = (z^m + z^{-m})/2.",
        "answer": "To tackle this problem, we will address each task in sequence, providing rigorous proofs and explanations. Let's begin:\n\n### Task 1: Kronecker\u2019s Unit-Disk Lemma\n\n**Statement:** If \u03b2 is an algebraic integer and all its Galois conjugates satisfy |\u03b2'| \u2264 1, then \u03b2 = 0 or \u03b2 is a root of unity.\n\n**Proof:**\n\n1. **Algebraic Integer Property:** Since \u03b2 is an algebraic integer, it is a root of a monic polynomial with integer coefficients. Let this polynomial be $f(x) = x^n + a_{n-1}x^{n-1} + \\cdots + a_0$.\n\n2. **Conjugates and Modulus:** The Galois conjugates of \u03b2 are the roots of this polynomial. By assumption, all conjugates \u03b2' satisfy |\u03b2'| \u2264 1.\n\n3. **Product of Conjugates:** The product of all conjugates of \u03b2 (including \u03b2 itself) is |N(\u03b2)|, where N(\u03b2) is the norm of \u03b2. Since \u03b2 is an algebraic integer, N(\u03b2) is an integer.\n\n4. **Norm and Modulus:** If |\u03b2'| \u2264 1 for all conjugates, then |N(\u03b2)| \u2264 1. Since N(\u03b2) is an integer, |N(\u03b2)| = 0 or 1.\n\n5. **Case Analysis:**\n   - If |N(\u03b2)| = 0, then \u03b2 = 0.\n   - If |N(\u03b2)| = 1, then \u03b2 is a unit in the ring of algebraic integers. The only algebraic integers with norm 1 and all conjugates of modulus \u2264 1 are roots of unity.\n\nThus, \u03b2 = 0 or \u03b2 is a root of unity.\n\n### Task 2: Classification in [\u22122,2]\n\n**Statement:** If \u03b1 is an algebraic integer and all of its conjugates lie in [\u22122,2], then \u03b1 = \u03b6 + \u03b6^{-1} for some root of unity \u03b6.\n\n**Proof:**\n\n1. **Chebyshev Polynomials:** Recall that for any integer m, the Chebyshev polynomial T_m(x) satisfies T_m(cos \u03b8) = cos(m\u03b8). The roots of T_m(x) are of the form 2 cos(2\u03c0k/m) for k = 0, 1, ..., m-1.\n\n2. **Conjugates in [\u22122,2]:** If all conjugates of \u03b1 lie in [\u22122,2], then \u03b1 can be expressed as 2 cos(\u03b8) for some \u03b8. This implies \u03b1 = \u03b6 + \u03b6^{-1} where \u03b6 = e^{i\u03b8} is a root of unity.\n\n3. **Minimal Polynomial:** The minimal polynomial of \u03b1 over Q is the real cyclotomic polynomial C_n(x) for some n, which is the minimal polynomial of 2 cos(2\u03c0/n).\n\n4. **Conclusion:** Therefore, \u03b1 = \u03b6 + \u03b6^{-1} for some root of unity \u03b6, and the minimal polynomial of \u03b1 is C_n(x) for some n.\n\n### Task 3: Cyclotomic\u2013Real Cyclotomic Identity\n\n**Statement:** For n \u2265 3, prove the identity \u03a6_n(z) = z^{\u03c6(n)/2} C_n(z + z^{-1}).\n\n**Proof:**\n\n1. **Roots of \u03a6_n(z):** The roots of the nth cyclotomic polynomial \u03a6_n(z) are the primitive nth roots of unity.\n\n2. **Transformation:** Consider the transformation z = e^{i\u03b8}, then z + z^{-1} = 2 cos(\u03b8). The roots of C_n(x) are of the form 2 cos(2\u03c0k/n) for k coprime to n.\n\n3. **Degree and Monicity:** The degree of \u03a6_n(z) is \u03c6(n), and the degree of C_n(x) is \u03c6(n)/2. The transformation z + z^{-1} maps the roots of \u03a6_n(z) to those of C_n(x).\n\n4. **Identity Verification:** The identity holds because both sides have the same degree and the same set of roots under the transformation z = e^{i\u03b8}.\n\n### Task 4: Classification of Integer Polynomials with Spectrum in [\u22122,2]\n\n**Statement:** A monic polynomial P \u2208 Z[x] has all complex roots in [\u22122,2] if and only if P is a product (with multiplicities) of the polynomials C_n(x), n \u2265 1.\n\n**Proof:**\n\n1. **Roots in [\u22122,2]:** If P has all roots in [\u22122,2], each root is of the form 2 cos(2\u03c0k/n) for some n, k.\n\n2. **Factorization:** Each such root corresponds to a factor C_n(x) in the polynomial. Therefore, P can be expressed as a product of C_n(x) polynomials.\n\n3. **Monicity and Integer Coefficients:** Since P is monic and has integer coefficients, it must be a product of monic polynomials with integer coefficients, which are precisely the C_n(x).\n\n### Task 5: Chebyshev Factorization\n\n**Statement:** Prove the explicit factorization, valid for every integer m \u2265 1:\n2(T_m(x/2) \u2212 1) = C_1(x) C_2(x)^{\u03b5(m)} \u220f_{d | m, d \u2265 3} C_d(x)^2.\n\n**Proof:**\n\n1. **Chebyshev Polynomial Identity:** Recall T_m((z + z^{-1})/2) = (z^m + z^{-m})/2. This implies T_m(x/2) = (z^m + z^{-m})/2 for x = z + z^{-1}.\n\n2. **Factorization:** Using Task 3, we have \u03a6_d(z) = z^{\u03c6(d)/2} C_d(z + z^{-1}). For each divisor d of m, the roots of T_m(x/2) correspond to those of C_d(x).\n\n3. **Product Over Divisors:** The factorization follows by considering the contribution of each divisor d of m to the roots of T_m(x/2).\n\n4. **Even and Odd m:** The factor C_2(x) appears with multiplicity \u03b5(m) = 1 if m is even, due to the symmetry of the Chebyshev polynomials.\n\n5. **Conclusion:** The factorization holds as stated, with each C_d(x) appearing with the appropriate multiplicity.\n\nThis completes the solution to the problem, addressing each task with rigorous proofs and explanations."
    },
    "5": {
        "question": "Title: Geometry of numbers to the full two-squares theorem \u2014 Blichfeldt, Minkowski, and a sharp arithmetic application\n\nLet R^n be equipped with the Lebesgue measure vol. A lattice L \u2282 R^n is a discrete subgroup spanned by n linearly independent vectors; its determinant det(L) is the Lebesgue volume of any fundamental parallelotope P = {\u2211_{i=1}^n t_i v_i : t_i \u2208 [0,1)} for a basis v_1,\u2026,v_n of L. A set K \u2282 R^n is convex if along with x,y \u2208 K it contains every tx + (1\u2212t)y for t \u2208 [0,1], and centrally symmetric if K = \u2212K.\n\nYour tasks:\n\n1) Blichfeldt\u2019s lemma (pigeonhole in the torus). Prove: If S \u2282 R^n is measurable with vol(S) > det(L), then there exist distinct x,y \u2208 S with x \u2212 y \u2208 L.\n\n2) Minkowski\u2019s convex body theorem. Deduce from (1): If K \u2282 R^n is convex, centrally symmetric, measurable, and vol(K) > 2^n det(L), then K contains a nonzero lattice point of L.\n\n3) Fermat\u2019s two-squares theorem for primes via Minkowski. For an odd prime p, prove Wilson\u2019s identity (p\u22121)! \u2261 \u22121 (mod p), and deduce that \u22121 is a quadratic residue mod p if and only if p \u2261 1 (mod 4). Then, for p \u2261 1 (mod 4), fix k with k^2 \u2261 \u22121 (mod p) and consider the index-p sublattice\nL_k = {(x,y) \u2208 Z^2 : x \u2261 k y (mod p)}.\nShow det(L_k) = p. Apply Minkowski to an explicit centrally symmetric convex body K \u2282 R^2 of your choice to produce a nonzero (x,y) \u2208 L_k with 0 < x^2 + y^2 < 2p, infer p | (x^2 + y^2), and conclude p = x^2 + y^2.\n\n4) Complete classification (Fermat\u2013Euler two-squares theorem). Prove that a positive integer n is a sum of two integer squares if and only if every prime q \u2261 3 (mod 4) appears with an even exponent in the prime factorization of n. Your proof must be self-contained and may use the multiplicative identity\n(x^2 + y^2)(u^2 + v^2) = (xu \u2212 yv)^2 + (xv + yu)^2.\nInclude the \u201conly if\u201d direction (divisibility constraint for primes 3 mod 4) and the \u201cif\u201d direction (assemble prime-power representations multiplicatively).\n\nAnswer format:\n- Present a complete proof of Blichfeldt\u2019s lemma.\n- Deduce Minkowski\u2019s theorem rigorously from Blichfeldt.\n- Prove Wilson\u2019s congruence and the criterion for \u22121 to be a square mod p. Compute det(L_k). Specify a concrete body K whose volume exceeds 4 det(L_k) and argue that the produced lattice vector gives p = x^2 + y^2.\n- Prove both directions of the full characterization of sums of two squares, clearly indicating where you use the prime case and the product identity.",
        "answer": "To solve the given problem, we will address each part step by step.\n\n### 1) Blichfeldt\u2019s Lemma\n\n**Statement:** If $S \\subset \\mathbb{R}^n$ is measurable with $\\text{vol}(S) > \\det(L)$, then there exist distinct $x, y \\in S$ with $x - y \\in L$.\n\n**Proof:**\n\nConsider the quotient space $\\mathbb{R}^n / L$, which is a torus with volume $\\det(L)$. The map $\\pi: \\mathbb{R}^n \\to \\mathbb{R}^n / L$ is the natural projection. Since $\\text{vol}(S) > \\det(L)$, by the pigeonhole principle, there must be two distinct points $x, y \\in S$ such that $\\pi(x) = \\pi(y)$. This implies $x - y \\in L$, proving the lemma.\n\n### 2) Minkowski\u2019s Convex Body Theorem\n\n**Statement:** If $K \\subset \\mathbb{R}^n$ is convex, centrally symmetric, measurable, and $\\text{vol}(K) > 2^n \\det(L)$, then $K$ contains a nonzero lattice point of $L$.\n\n**Deduction from Blichfeldt\u2019s Lemma:**\n\nConsider the set $\\frac{1}{2}K = \\{ \\frac{1}{2}x : x \\in K \\}$. The volume of $\\frac{1}{2}K$ is $\\frac{1}{2^n} \\text{vol}(K) > \\det(L)$. By Blichfeldt\u2019s lemma, there exist distinct $x, y \\in \\frac{1}{2}K$ such that $x - y \\in L$. Since $K$ is centrally symmetric, $-y \\in \\frac{1}{2}K$, and thus $x + (-y) = x - y \\in L$ is a nonzero lattice point in $K$.\n\n### 3) Fermat\u2019s Two-Squares Theorem for Primes via Minkowski\n\n**Wilson\u2019s Theorem:**\n\nFor an odd prime $p$, Wilson's theorem states $(p-1)! \\equiv -1 \\pmod{p}$. This follows from the fact that the product of all nonzero elements of $\\mathbb{Z}_p$ is $(p-1)!$, and each element $a$ has a unique inverse $a^{-1} \\equiv p-a \\pmod{p}$, except for $a \\equiv 1$ and $a \\equiv p-1$.\n\n**Quadratic Residue Criterion:**\n\n$-1$ is a quadratic residue modulo $p$ if and only if $p \\equiv 1 \\pmod{4}$. This follows from the properties of the Legendre symbol and the fact that the multiplicative group of nonzero residues modulo $p$ is cyclic of order $p-1$.\n\n**Lattice $L_k$:**\n\nFor $p \\equiv 1 \\pmod{4}$, there exists $k$ such that $k^2 \\equiv -1 \\pmod{p}$. Consider the lattice $L_k = \\{ (x, y) \\in \\mathbb{Z}^2 : x \\equiv ky \\pmod{p} \\}$. The determinant of $L_k$ is $p$.\n\n**Convex Body $K$:**\n\nChoose $K = \\{ (x, y) \\in \\mathbb{R}^2 : x^2 + y^2 < 2p \\}$. The area of $K$ is $\\pi(2p) = 2\\pi p$, which is greater than $4p = 4 \\det(L_k)$.\n\nBy Minkowski\u2019s theorem, $K$ contains a nonzero lattice point $(x, y) \\in L_k$ with $0 < x^2 + y^2 < 2p$. Since $(x, y) \\in L_k$, $x^2 + y^2 \\equiv 0 \\pmod{p}$, implying $p \\mid (x^2 + y^2)$. Thus, $x^2 + y^2 = p$.\n\n### 4) Complete Classification (Fermat\u2013Euler Two-Squares Theorem)\n\n**Only If Direction:**\n\nSuppose $n = x^2 + y^2$. If a prime $q \\equiv 3 \\pmod{4}$ divides $n$, then $x^2 + y^2 \\equiv 0 \\pmod{q}$. This implies $x \\equiv y \\equiv 0 \\pmod{q}$, so $q^2 \\mid n$. Thus, $q$ appears with an even exponent.\n\n**If Direction:**\n\nAssume every prime $q \\equiv 3 \\pmod{4}$ appears with an even exponent in $n$. Write $n = 2^a \\prod p_i^{b_i} \\prod q_j^{2c_j}$, where $p_i \\equiv 1 \\pmod{4}$ and $q_j \\equiv 3 \\pmod{4}$. Each $p_i$ is a sum of two squares, and $2 = 1^2 + 1^2$. Use the identity $(x^2 + y^2)(u^2 + v^2) = (xu - yv)^2 + (xv + yu)^2$ to combine these representations, showing $n$ is a sum of two squares.\n\nThis completes the proof of the full characterization of sums of two squares."
    },
    "6": {
        "question": "Title: Weyl\u2019s criterion, van der Corput\u2019s difference theorem, and equidistribution of polynomial sequences\n\nDefinitions:\n- For x \u2208 \u211d, write {x} for the fractional part of x in [0,1).\n- A sequence (x_n) \u2282 \u211d is equidistributed modulo 1 (or uniformly distributed mod 1) if for every interval [a,b) \u2282 [0,1), we have\n  lim_{N\u2192\u221e} (1/N) |{1 \u2264 n \u2264 N : {x_n} \u2208 [a,b)}| = b \u2212 a.\n- For t \u2208 \u211d, write e(t) := exp(2\u03c0 i t).\n\nProblem. Prove the following, self-contained and in order:\n\n1) Weyl\u2019s criterion. Show that a sequence (x_n) is equidistributed mod 1 if and only if for every nonzero integer k,\n   lim_{N\u2192\u221e} (1/N) \u2211_{n=1}^N e(k x_n) = 0.\n\n2) van der Corput\u2019s difference theorem. Let (x_n) be a real sequence. Suppose that for every positive integer h and every nonzero integer k,\n   lim_{N\u2192\u221e} (1/N) \u2211_{n=1}^{N\u2212h} e(k (x_{n+h} \u2212 x_n)) = 0.\n   Prove that (x_n) is equidistributed mod 1.\n\n3) Polynomial equidistribution. Let P \u2208 \u211d[X] be a nonconstant polynomial\n   P(n) = a_d n^d + a_{d\u22121} n^{d\u22121} + \u2026 + a_1 n + a_0\n   with at least one of a_1,\u2026,a_d irrational. Prove that ({P(n)}) is equidistributed mod 1. In particular, for every irrational \u03b1 and every integer d \u2265 1, the sequence ({\u03b1 n^d}) is equidistributed.\n\nAnswer format:\n- Prove (1) in full detail.\n- Prove (2) from (1) using a suitable averaging/inequality.\n- Deduce (3) by induction on deg P, using (2) and the base case of linear sequences.",
        "answer": "To solve this problem, we will address each part in sequence, providing detailed proofs and reasoning.\n\n### Part 1: Weyl\u2019s Criterion\n\n**Statement:** A sequence $(x_n)$ is equidistributed mod 1 if and only if for every nonzero integer $k$,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0.\n$$\n\n**Proof:**\n\n**(\u21d2) Direction:**\n\nAssume $(x_n)$ is equidistributed mod 1. We need to show that for every nonzero integer $k$,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0.\n$$\n\nFor any interval $[a, b) \\subset [0, 1)$, the equidistribution condition gives:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\left| \\{ 1 \\leq n \\leq N : \\{x_n\\} \\in [a, b) \\} \\right| = b - a.\n$$\n\nConsider the Fourier expansion of the indicator function of $[a, b)$:\n$$\n1_{[a, b)}(x) = \\sum_{k \\in \\mathbb{Z}} c_k e(kx),\n$$\nwhere $c_k = \\int_0^1 1_{[a, b)}(x) e(-kx) \\, dx$.\n\nFor $k \\neq 0$, $c_k = \\frac{e(-ka) - e(-kb)}{2\\pi i k}$, and for $k = 0$, $c_0 = b - a$.\n\nThe equidistribution implies:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N 1_{[a, b)}(x_n) = b - a.\n$$\n\nSubstituting the Fourier series:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N \\sum_{k \\in \\mathbb{Z}} c_k e(k x_n) = b - a.\n$$\n\nInterchanging sums (justified by dominated convergence):\n$$\n\\sum_{k \\in \\mathbb{Z}} c_k \\left( \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) \\right) = b - a.\n$$\n\nFor $k = 0$, the term is $c_0 = b - a$. For $k \\neq 0$, $c_k \\neq 0$, so:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0.\n$$\n\n**(\u21d0) Direction:**\n\nAssume for every nonzero integer $k$,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0.\n$$\n\nWe need to show $(x_n)$ is equidistributed mod 1. For any interval $[a, b) \\subset [0, 1)$, consider:\n$$\n1_{[a, b)}(x) = \\sum_{k \\in \\mathbb{Z}} c_k e(kx).\n$$\n\nThe equidistribution condition becomes:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N 1_{[a, b)}(x_n) = \\sum_{k \\in \\mathbb{Z}} c_k \\left( \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) \\right).\n$$\n\nFor $k = 0$, the term is $c_0 = b - a$. For $k \\neq 0$, the assumption gives:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0.\n$$\n\nThus:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N 1_{[a, b)}(x_n) = b - a.\n$$\n\nThis proves $(x_n)$ is equidistributed mod 1.\n\n### Part 2: van der Corput\u2019s Difference Theorem\n\n**Statement:** Let $(x_n)$ be a real sequence. Suppose that for every positive integer $h$ and every nonzero integer $k$,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^{N-h} e(k (x_{n+h} - x_n)) = 0.\n$$\nProve that $(x_n)$ is equidistributed mod 1.\n\n**Proof:**\n\nWe will use Weyl's criterion. We need to show:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0\n$$\nfor every nonzero integer $k$.\n\nConsider:\n$$\nS_N = \\sum_{n=1}^N e(k x_n).\n$$\n\nWe have:\n$$\n|S_N|^2 = \\sum_{n=1}^N \\sum_{m=1}^N e(k (x_n - x_m)).\n$$\n\nRewriting:\n$$\n|S_N|^2 = N + 2 \\sum_{h=1}^{N-1} \\left( \\sum_{n=1}^{N-h} e(k (x_{n+h} - x_n)) \\right).\n$$\n\nBy assumption, for every $h$,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^{N-h} e(k (x_{n+h} - x_n)) = 0.\n$$\n\nThus:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N^2} |S_N|^2 = 0.\n$$\n\nThis implies:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} |S_N| = 0.\n$$\n\nTherefore:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0.\n$$\n\nBy Weyl's criterion, $(x_n)$ is equidistributed mod 1.\n\n### Part 3: Polynomial Equidistribution\n\n**Statement:** Let $P \\in \\mathbb{R}[X]$ be a nonconstant polynomial\n$$\nP(n) = a_d n^d + a_{d-1} n^{d-1} + \\cdots + a_1 n + a_0\n$$\nwith at least one of $a_1, \\ldots, a_d$ irrational. Prove that $(\\{P(n)\\})$ is equidistributed mod 1.\n\n**Proof:**\n\n**Base Case (Linear Polynomials):**\n\nConsider $P(n) = \\alpha n + \\beta$ with $\\alpha$ irrational. We need to show $(\\{\\alpha n + \\beta\\})$ is equidistributed mod 1.\n\nBy Weyl's criterion, it suffices to show:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k (\\alpha n + \\beta)) = 0\n$$\nfor every nonzero integer $k$.\n\nThis becomes:\n$$\ne(k \\beta) \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k \\alpha n) = 0.\n$$\n\nThe inner sum is a geometric series:\n$$\n\\sum_{n=1}^N e(k \\alpha n) = \\frac{e(k \\alpha) (1 - e(k \\alpha N))}{1 - e(k \\alpha)}.\n$$\n\nSince $\\alpha$ is irrational, $e(k \\alpha) \\neq 1$, and the average tends to zero:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k \\alpha n) = 0.\n$$\n\nThus, $(\\{\\alpha n + \\beta\\})$ is equidistributed mod 1.\n\n**Inductive Step:**\n\nAssume the result holds for polynomials of degree $d-1$. Consider $P(n) = a_d n^d + \\cdots + a_1 n + a_0$ with at least one of $a_1, \\ldots, a_d$ irrational.\n\nWe apply van der Corput's difference theorem. For any $h$,\n$$\nP(n+h) - P(n) = d a_d n^{d-1} h + \\cdots + a_1 h.\n$$\n\nThe leading term is $d a_d n^{d-1} h$. If $a_d$ is irrational, then $(\\{d a_d n^{d-1} h\\})$ is equidistributed by the inductive hypothesis.\n\nFor each nonzero integer $k$, we have:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^{N-h} e(k (P(n+h) - P(n))) = 0.\n$$\n\nBy van der Corput\u2019s difference theorem, $(\\{P(n)\\})$ is equidistributed mod 1.\n\nThis completes the proof for polynomial equidistribution."
    },
    "7": {
        "question": "Title: Finite-field Kakeya via the polynomial method \u2014 a sharp-dimensional lower bound and a robust r-rich variant\n\nLet q be a prime power and F_q the finite field with q elements. For n \u2265 1, write F_q^n for the n-dimensional vector space over F_q.\n\nDefinitions:\n- A (nonzero) direction is a 1-dimensional subspace of F_q^n, i.e., a set {c v : c \u2208 F_q} for some fixed v \u2208 F_q^n \\ {0}. We informally identify a direction with any of its nonzero vectors v.\n- An affine line in direction v is any set of the form L = {a + t v : t \u2208 F_q} with a \u2208 F_q^n, v \u2208 F_q^n \\ {0}.\n- A Kakeya set K \u2282 F_q^n is a set that contains at least one line in every direction; i.e., for every v \u2260 0, there exist a \u2208 F_q^n such that a + t v \u2208 K for all t \u2208 F_q.\n- More generally, for an integer r with 1 \u2264 r \u2264 q, a set E \u2282 F_q^n is called r-rich in directions if for every v \u2260 0 there exists a line L = {a + t v} in direction v such that |L \u2229 E| \u2265 r.\n\nFor nonnegative integers d, let P_{n,\u2264d}(F_q) denote the F_q-vector space of polynomials in n variables x = (x_1,\u2026,x_n) over F_q of total degree \u2264 d. Let N(n,d) be its dimension (i.e., the number of monomials of total degree \u2264 d in n variables).\n\nTasks:\n1) Show that N(n,d) = C(n+d, n) = binomial(n + d, n). In particular, N(n,q\u22121) = C(n + q \u2212 1, n) and N(n,r\u22121) = C(n + r \u2212 1, n).\n2) Linear algebra lemma (vanishing polynomial on a small set). Prove: If S \u2282 F_q^n is finite and |S| < N(n,d), then there exists a nonzero polynomial P \u2208 P_{n,\u2264d}(F_q) that vanishes on S (i.e., P(s) = 0 for every s \u2208 S).\n3) Leading form on a line. For P \u2208 P_{n,\u2264d}(F_q), write P = H_m + H_{m\u22121} + \u2026 + H_0, where H_k is homogeneous of degree k and m = deg P. Prove: For any a,v \u2208 F_q^n with v \u2260 0, the univariate polynomial Q(t) := P(a + t v) has degree \u2264 m and its leading coefficient is H_m(v).\n4) Dvir\u2019s Kakeya bound. Prove: If K \u2282 F_q^n is a Kakeya set, then |K| \u2265 N(n,q\u22121) = C(n+q\u22121, n). In particular, |K| \u2265 q^n / n!. Give a complete proof using only the above ingredients.\n5) Robust r-rich variant. Prove: If E \u2282 F_q^n is r-rich in directions, then |E| \u2265 N(n,r\u22121) = C(n + r \u2212 1, n).\n\nAnswer format:\n- Provide a complete, self-contained proof of each task, rigorously justifying all steps and identities.\n- Your final bound in (4) should be stated both as |K| \u2265 C(n+q\u22121, n) and the crude but explicit |K| \u2265 q^n / n!.\n- For (5), clearly indicate the substitution r = q recovers (4).",
        "answer": "To solve the given tasks, we will use concepts from combinatorics, linear algebra, and polynomial algebra over finite fields. Let's address each task step by step.\n\n### Task 1: Show that $N(n,d) = \\binom{n+d}{n}$.\n\nThe dimension $N(n,d)$ is the number of monomials of total degree $\\leq d$ in $n$ variables. A monomial in $n$ variables $x_1, x_2, \\ldots, x_n$ is of the form $x_1^{a_1} x_2^{a_2} \\cdots x_n^{a_n}$ where $a_1 + a_2 + \\cdots + a_n \\leq d$.\n\nThe problem of counting such monomials is equivalent to finding the number of non-negative integer solutions to the equation:\n\n$$\na_1 + a_2 + \\cdots + a_n \\leq d\n$$\n\nThis can be transformed into:\n\n$$\na_1 + a_2 + \\cdots + a_n + a_{n+1} = d\n$$\n\nwhere $a_{n+1}$ is a non-negative integer. The number of solutions to this equation is given by the \"stars and bars\" theorem, which states that the number of solutions is:\n\n$$\n\\binom{n+d}{n}\n$$\n\nThus, $N(n,d) = \\binom{n+d}{n}$.\n\n### Task 2: Linear algebra lemma (vanishing polynomial on a small set).\n\nWe need to show that if $S \\subset F_q^n$ and $|S| < N(n,d)$, then there exists a nonzero polynomial $P \\in P_{n, \\leq d}(F_q)$ that vanishes on $S$.\n\nConsider the vector space $P_{n, \\leq d}(F_q)$ of polynomials of degree $\\leq d$. The dimension of this space is $N(n,d)$. If $|S| < N(n,d)$, then the evaluation map:\n\n$$\n\\text{ev}_S: P_{n, \\leq d}(F_q) \\to F_q^{|S|}\n$$\n\ndefined by $\\text{ev}_S(P) = (P(s_1), P(s_2), \\ldots, P(s_{|S|}))$ for $s_i \\in S$ is not injective because the dimension of the domain is greater than the dimension of the codomain. Therefore, there exists a nonzero polynomial $P$ such that $\\text{ev}_S(P) = 0$, meaning $P(s) = 0$ for all $s \\in S$.\n\n### Task 3: Leading form on a line.\n\nGiven $P \\in P_{n, \\leq d}(F_q)$ with $P = H_m + H_{m-1} + \\cdots + H_0$, where $H_k$ is homogeneous of degree $k$ and $m = \\deg P$, we need to show that for any $a, v \\in F_q^n$ with $v \\neq 0$, the univariate polynomial $Q(t) = P(a + tv)$ has degree $\\leq m$ and its leading coefficient is $H_m(v)$.\n\nSubstitute $x = a + tv$ into $P(x)$:\n\n$$\nQ(t) = P(a + tv) = H_m(a + tv) + H_{m-1}(a + tv) + \\cdots + H_0(a + tv)\n$$\n\nEach $H_k(a + tv)$ is a homogeneous polynomial of degree $k$ in $t$. The term $H_m(a + tv)$ contributes the highest degree term in $t$, which is $H_m(v)t^m$. Therefore, the degree of $Q(t)$ is $m$, and the leading coefficient is $H_m(v)$.\n\n### Task 4: Dvir\u2019s Kakeya bound.\n\nWe need to prove that if $K \\subset F_q^n$ is a Kakeya set, then $|K| \\geq N(n, q-1) = \\binom{n+q-1}{n}$.\n\nAssume for contradiction that $|K| < N(n, q-1)$. By Task 2, there exists a nonzero polynomial $P \\in P_{n, \\leq q-1}(F_q)$ that vanishes on $K$.\n\nFor each direction $v \\neq 0$, there is a line $L = \\{ a + tv : t \\in F_q \\} \\subset K$. By Task 3, the polynomial $Q(t) = P(a + tv)$ is a univariate polynomial of degree $\\leq q-1$ that vanishes for all $t \\in F_q$. This implies $Q(t) \\equiv 0$, so the leading coefficient $H_m(v) = 0$.\n\nSince this holds for all directions $v \\neq 0$, the homogeneous polynomial $H_m$ must be identically zero, contradicting the assumption that $P$ is nonzero. Therefore, $|K| \\geq N(n, q-1)$.\n\nThe crude bound follows from:\n\n$$\nN(n, q-1) = \\binom{n+q-1}{n} \\geq \\frac{(q-1)^n}{n!} \\approx \\frac{q^n}{n!}\n$$\n\n### Task 5: Robust r-rich variant.\n\nWe need to prove that if $E \\subset F_q^n$ is $r$-rich in directions, then $|E| \\geq N(n, r-1) = \\binom{n+r-1}{n}$.\n\nAssume for contradiction that $|E| < N(n, r-1)$. By Task 2, there exists a nonzero polynomial $P \\in P_{n, \\leq r-1}(F_q)$ that vanishes on $E$.\n\nFor each direction $v \\neq 0$, there is a line $L = \\{ a + tv : t \\in F_q \\}$ such that $|L \\cap E| \\geq r$. The polynomial $Q(t) = P(a + tv)$ is a univariate polynomial of degree $\\leq r-1$ that vanishes at $r$ points, implying $Q(t) \\equiv 0$. Thus, $H_m(v) = 0$.\n\nSince this holds for all directions $v \\neq 0$, the homogeneous polynomial $H_m$ must be identically zero, contradicting the assumption that $P$ is nonzero. Therefore, $|E| \\geq N(n, r-1)$.\n\nSubstituting $r = q$ recovers the Kakeya bound from Task 4, as $N(n, q-1) = \\binom{n+q-1}{n}$.\n\nThis completes the proof for all tasks."
    },
    "8": {
        "question": "Title: Wigner\u2019s semicircle law via the moment method \u2014 convergence in probability under bounded moments\n\nLet (W_n) be a sequence of real symmetric random matrices of size n \u00d7 n with independent entries on and above the diagonal. Assume:\n\n- For i < j, the off-diagonal entries X_{ij} are i.i.d. with E[X_{ij}] = 0, E[X_{ij}^2] = 1, and for every integer m \u2265 1, sup_{n,i<j} E[|X_{ij}|^m] < \u221e.\n- The diagonal entries X_{ii} are independent of the off-diagonal entries, satisfy E[X_{ii}] = 0, and sup_{n,i} E[|X_{ii}|^m] < \u221e for every m \u2265 1.\n\nForm W_n by setting (W_n)_{ij} = X_{ij} for i \u2264 j and (W_n)_{ij} = X_{ji} for i > j. Define the scaled matrix M_n := W_n / \u221an. Since M_n is symmetric, its eigenvalues are real; write them as \u03bb_1(M_n),\u2026,\u03bb_n(M_n). The empirical spectral distribution (ESD) of M_n is the random probability measure\n\u03bc_{M_n} := (1/n) \u2211_{i=1}^n \u03b4_{\u03bb_i(M_n)} on \u211d.\n\nThe semicircle distribution \u03bc_sc is the probability measure with density\n\u03c1_sc(x) = (1/(2\u03c0)) sqrt(4 \u2212 x^2) on [\u22122,2] and 0 otherwise.\n\nTasks:\n\n1) Limiting expected moments (moment method). For each fixed integer k \u2265 0, prove that\nlim_{n\u2192\u221e} E[ \u222b x^k d\u03bc_{M_n}(x) ] = m_k,\nwhere m_k = 0 if k is odd and m_{2m} = C_m := (1/(m+1)) binom(2m,m) (the mth Catalan number). Your proof must:\n- Expand (1/n) Tr(M_n^k) as a sum over closed index-words i_1,\u2026,i_k with i_{k+1} := i_1.\n- Show that only words in which each unordered edge {i_t,i_{t+1}} appears exactly twice and whose underlying graph is a tree contribute in the limit.\n- Enumerate these contributing words and prove that their number equals C_m (give a self-contained combinatorial argument).\n\n2) Variance vanishes. For each fixed k, prove Var( \u222b x^k d\u03bc_{M_n}(x) ) \u2192 0 as n \u2192 \u221e. In particular, \u222b x^k d\u03bc_{M_n}(x) converges in probability to m_k.\n\n3) Semicircle moments and uniqueness. Compute directly the moments of \u03bc_sc:\nM_{2m} := \u222b_{\u22122}^2 x^{2m} \u03c1_sc(x) dx = C_m and M_{2m+1} = 0. Verify Carleman\u2019s condition \u2211_{m=1}^\u221e M_{2m}^{\u22121/(2m)} = \u221e, and conclude that \u03bc_sc is uniquely determined by its moments.\n\n4) Convergence of the ESD. Prove that \u03bc_{M_n} converges weakly in probability to \u03bc_sc. More precisely: for every bounded continuous \u03c6: \u211d \u2192 \u211d,\n\u222b \u03c6 d\u03bc_{M_n} \u2192 \u222b \u03c6 d\u03bc_sc in probability.\n\nAnswer format:\n- Give a complete, self-contained proof of each task with all definitions used, justified combinatorial counts, and moment/variance bounds.\n- You may assume standard facts about independence, basic combinatorics (Catalan recursion), and basic measure/probability convergence notions, but do not assume any random matrix theory beyond what you prove here.",
        "answer": "To solve this problem, we need to address each of the four tasks outlined. Let's go through them step by step.\n\n### Task 1: Limiting Expected Moments\n\n**Objective:** Prove that for each fixed integer $k \\geq 0$,\n$$\n\\lim_{n \\to \\infty} E\\left[ \\int x^k \\, d\\mu_{M_n}(x) \\right] = m_k,\n$$\nwhere $m_k = 0$ if $k$ is odd and $m_{2m} = C_m$, the $m$-th Catalan number.\n\n**Proof:**\n\n1. **Expand the Trace:**\n   The $k$-th moment of the empirical spectral distribution is given by\n   $$\n   \\int x^k \\, d\\mu_{M_n}(x) = \\frac{1}{n} \\sum_{i=1}^n \\lambda_i(M_n)^k = \\frac{1}{n} \\text{Tr}(M_n^k).\n   $$\n   Expanding $\\text{Tr}(M_n^k)$, we have\n   $$\n   \\text{Tr}(M_n^k) = \\sum_{i_1, i_2, \\ldots, i_k} (M_n)_{i_1 i_2} (M_n)_{i_2 i_3} \\cdots (M_n)_{i_k i_1}.\n   $$\n   Each term corresponds to a closed walk on the indices $i_1, i_2, \\ldots, i_k$ with $i_{k+1} = i_1$.\n\n2. **Contributing Words:**\n   We need to show that only certain index sequences contribute in the limit. Specifically, those where each edge $\\{i_t, i_{t+1}\\}$ appears exactly twice and the underlying graph is a tree.\n\n   - **Tree Structure:** A tree with $m$ edges has $m+1$ vertices. For a closed walk of length $2m$, the graph must be a tree to have the correct number of edges and vertices.\n   - **Double Occurrence:** Each edge must appear exactly twice to ensure the variance of the product is non-zero.\n\n3. **Enumeration of Contributing Words:**\n   The number of such closed walks corresponds to the number of Dyck paths of length $2m$, which is known to be the Catalan number $C_m$.\n\n4. **Limit Calculation:**\n   For $k = 2m$, the expected value of the trace term is asymptotically $C_m$ due to the normalization by $n^{m+1}$ and the fact that each contributing word has a variance that vanishes as $n \\to \\infty$.\n\n   For odd $k$, symmetry and the zero mean of the entries imply that the expected value is zero.\n\n### Task 2: Variance Vanishes\n\n**Objective:** Prove that for each fixed $k$, $\\text{Var}\\left( \\int x^k \\, d\\mu_{M_n}(x) \\right) \\to 0$ as $n \\to \\infty$.\n\n**Proof:**\n\n1. **Variance Expression:**\n   The variance of the $k$-th moment is given by\n   $$\n   \\text{Var}\\left( \\frac{1}{n} \\text{Tr}(M_n^k) \\right) = \\frac{1}{n^2} \\text{Var}\\left( \\sum_{i_1, \\ldots, i_k} (M_n)_{i_1 i_2} \\cdots (M_n)_{i_k i_1} \\right).\n   $$\n\n2. **Contributing Terms:**\n   Only terms where each edge appears exactly twice contribute significantly. The variance of these terms is controlled by the bounded moments condition.\n\n3. **Bounded Moments:**\n   The boundedness of higher moments ensures that the variance of each contributing term is $O(1/n)$, leading to the overall variance tending to zero as $n \\to \\infty$.\n\n### Task 3: Semicircle Moments and Uniqueness\n\n**Objective:** Compute the moments of $\\mu_{sc}$ and verify Carleman's condition.\n\n**Proof:**\n\n1. **Moments of $\\mu_{sc}$:**\n   The moments of the semicircle distribution are given by\n   $$\n   M_{2m} = \\int_{-2}^2 x^{2m} \\rho_{sc}(x) \\, dx = C_m,\n   $$\n   and $M_{2m+1} = 0$.\n\n2. **Carleman's Condition:**\n   Carleman's condition states that if\n   $$\n   \\sum_{m=1}^\\infty M_{2m}^{-1/(2m)} = \\infty,\n   $$\n   then the distribution is uniquely determined by its moments. For the semicircle distribution, this condition is satisfied, ensuring uniqueness.\n\n### Task 4: Convergence of the ESD\n\n**Objective:** Prove that $\\mu_{M_n}$ converges weakly in probability to $\\mu_{sc}$.\n\n**Proof:**\n\n1. **Weak Convergence:**\n   For any bounded continuous function $\\phi: \\mathbb{R} \\to \\mathbb{R}$,\n   $$\n   \\int \\phi \\, d\\mu_{M_n} \\to \\int \\phi \\, d\\mu_{sc}\n   $$\n   in probability.\n\n2. **Moment Convergence:**\n   The convergence of moments implies weak convergence of the distribution, as the moments determine the distribution uniquely.\n\n3. **Probability Convergence:**\n   The variance vanishing result ensures that the convergence is in probability.\n\nThis completes the proof for each task, demonstrating the convergence of the empirical spectral distribution of the random matrices to the semicircle distribution."
    },
    "9": {
        "question": "Title: Poisson summation for Schwartz functions, the theta transformation, and the functional equation of the Riemann zeta function\n\nLet S(R) denote the Schwartz space on the real line: f \u2208 S(R) if f: R \u2192 C is smooth and for every pair of nonnegative integers m,k one has sup_{x\u2208R} |x^m f^{(k)}(x)| < \u221e. For f \u2208 S(R), define its Fourier transform by\nhat f(\u03be) = \u222b_{\u2212\u221e}^{\u221e} f(x) e^{\u22122\u03c0 i x \u03be} dx, \u03be \u2208 R.\n\nDefine the Jacobi theta function \u03b8: (0,\u221e) \u2192 R by \u03b8(t) = \u2211_{n\u2208Z} e^{\u2212\u03c0 t n^2}. For Re s > 1, define the Riemann zeta function \u03b6(s) = \u2211_{n=1}^\u221e n^{\u2212s}. Let \u0393 denote the Euler gamma function \u0393(s) = \u222b_0^\u221e t^{s\u22121} e^{\u2212t} dt for Re s > 0.\n\nTask. Prove, self-contained and in order:\n\n1) Poisson Summation Formula (PSF). Prove that for every f \u2208 S(R),\n\u2211_{n\u2208Z} f(n) = \u2211_{k\u2208Z} hat f(k).\nYour proof must be complete and include: (i) the uniform absolute convergence (with all derivatives) of the periodization F(x) = \u2211_{n\u2208Z} f(x+n), hence F is 1-periodic and smooth; (ii) computation of the Fourier coefficients of F and absolute convergence of its Fourier series.\n\n2) Theta transformation formula. For t > 0, consider g_t(x) = e^{\u2212\u03c0 t x^2}. Prove that hat g_t(\u03be) = t^{\u22121/2} e^{\u2212\u03c0 \u03be^2 / t} (compute the Fourier transform of the Gaussian). Deduce from PSF the Jacobi identity\n\u03b8(t) = t^{\u22121/2} \u03b8(1/t) for all t > 0.\nShow also that \u03b8(t) \u2212 1 = 2 \u2211_{n=1}^\u221e e^{\u2212\u03c0 n^2 t} decays exponentially as t \u2192 +\u221e and that \u03b8(t) \u223c t^{\u22121/2} as t \u2192 0+.\n\n3) Functional equation for \u03b6. For s \u2208 C, set \u039b(s) = \u03c0^{\u2212s/2} \u0393(s/2) \u03b6(s). Prove:\n- For Re s > 1, the Mellin transform identity\n\u222b_0^\u221e (\u03b8(t) \u2212 1) t^{s/2 \u2212 1} dt = 2 \u039b(s).\nJustify the exchange of sum and integral rigorously.\n- Show that the integral\nJ(s) := \u222b_1^\u221e (\u03b8(t) \u2212 1) (t^{s/2 \u2212 1} + t^{\u2212(s+1)/2}) dt\nconverges absolutely for all s \u2208 C and defines an entire function, and that J(s) = J(1 \u2212 s).\n- Prove, for Re s > 1,\n2 \u039b(s) = J(s) + 2/(s \u2212 1) \u2212 2/s,\nand conclude by analytic continuation that \u039b(s) = \u039b(1 \u2212 s) for all s \u2208 C, i.e.\n\u03c0^{\u2212s/2} \u0393(s/2) \u03b6(s) = \u03c0^{\u2212(1\u2212s)/2} \u0393((1\u2212s)/2) \u03b6(1 \u2212 s).\nFinally, deduce that \u03b6(s) extends meromorphically to C with a unique simple pole at s = 1 of residue 1.\n\nAnswer format: Provide complete proofs of (1), (2), and (3), justifying uniform/absolute convergence and all interchanges of limiting operations. State the final functional equation explicitly.",
        "answer": "To tackle this problem, we need to go through each part step by step, providing detailed proofs and justifications. Let's start with the Poisson Summation Formula (PSF).\n\n### 1) Poisson Summation Formula (PSF)\n\n**Statement**: For every $f \\in S(\\mathbb{R})$, we have\n$$\n\\sum_{n \\in \\mathbb{Z}} f(n) = \\sum_{k \\in \\mathbb{Z}} \\hat{f}(k).\n$$\n\n**Proof**:\n\n(i) **Uniform Absolute Convergence of the Periodization**: Define the periodization $F(x) = \\sum_{n \\in \\mathbb{Z}} f(x+n)$. Since $f \\in S(\\mathbb{R})$, it decays faster than any polynomial, meaning for any $N$, there exists a constant $C_N$ such that $|f(x)| \\leq \\frac{C_N}{1 + |x|^N}$. This ensures that the series converges absolutely and uniformly for all $x$, and all derivatives of $F$ also converge uniformly due to the rapid decay of $f$ and its derivatives.\n\n(ii) **Fourier Coefficients of $F$**: Since $F(x)$ is 1-periodic, it has a Fourier series expansion:\n$$\nF(x) = \\sum_{k \\in \\mathbb{Z}} c_k e^{2\\pi i k x},\n$$\nwhere the Fourier coefficients are given by\n$$\nc_k = \\int_0^1 F(x) e^{-2\\pi i k x} \\, dx.\n$$\nSubstituting the definition of $F(x)$, we have\n$$\nc_k = \\int_0^1 \\sum_{n \\in \\mathbb{Z}} f(x+n) e^{-2\\pi i k x} \\, dx = \\sum_{n \\in \\mathbb{Z}} \\int_0^1 f(x+n) e^{-2\\pi i k x} \\, dx.\n$$\nBy changing variables $u = x+n$, $du = dx$, the integral becomes\n$$\n\\int_n^{n+1} f(u) e^{-2\\pi i k (u-n)} \\, du = e^{2\\pi i k n} \\int_n^{n+1} f(u) e^{-2\\pi i k u} \\, du.\n$$\nSumming over $n$, we get\n$$\nc_k = \\int_{-\\infty}^{\\infty} f(u) e^{-2\\pi i k u} \\, du = \\hat{f}(k).\n$$\nThus, the Fourier series of $F(x)$ is\n$$\nF(x) = \\sum_{k \\in \\mathbb{Z}} \\hat{f}(k) e^{2\\pi i k x}.\n$$\nEvaluating at $x = 0$, we obtain\n$$\n\\sum_{n \\in \\mathbb{Z}} f(n) = F(0) = \\sum_{k \\in \\mathbb{Z}} \\hat{f}(k).\n$$\n\n### 2) Theta Transformation Formula\n\n**Statement**: For $t > 0$, define $g_t(x) = e^{-\\pi t x^2}$. Prove that\n$$\n\\hat{g}_t(\\xi) = t^{-1/2} e^{-\\pi \\xi^2 / t}.\n$$\n\n**Proof**: The Fourier transform of a Gaussian is another Gaussian. Compute:\n$$\n\\hat{g}_t(\\xi) = \\int_{-\\infty}^{\\infty} e^{-\\pi t x^2} e^{-2\\pi i x \\xi} \\, dx.\n$$\nComplete the square in the exponent:\n$$\n-\\pi t x^2 - 2\\pi i x \\xi = -\\pi t \\left(x^2 + \\frac{2i\\xi}{t} x\\right) = -\\pi t \\left((x + \\frac{i\\xi}{t})^2 - \\frac{\\xi^2}{t^2}\\right).\n$$\nThus,\n$$\n\\hat{g}_t(\\xi) = e^{\\pi \\xi^2 / t} \\int_{-\\infty}^{\\infty} e^{-\\pi t (x + \\frac{i\\xi}{t})^2} \\, dx.\n$$\nThe integral is a Gaussian integral, which evaluates to\n$$\n\\int_{-\\infty}^{\\infty} e^{-\\pi t u^2} \\, du = \\frac{1}{\\sqrt{t}}.\n$$\nTherefore,\n$$\n\\hat{g}_t(\\xi) = t^{-1/2} e^{-\\pi \\xi^2 / t}.\n$$\n\n**Jacobi Identity**: Using PSF for $g_t(x)$, we have\n$$\n\\sum_{n \\in \\mathbb{Z}} e^{-\\pi t n^2} = \\sum_{k \\in \\mathbb{Z}} \\hat{g}_t(k) = \\sum_{k \\in \\mathbb{Z}} t^{-1/2} e^{-\\pi k^2 / t}.\n$$\nThus,\n$$\n\\theta(t) = t^{-1/2} \\theta(1/t).\n$$\n\n**Exponential Decay and Asymptotic Behavior**: As $t \\to +\\infty$, $e^{-\\pi n^2 t}$ decays exponentially for $n \\geq 1$. As $t \\to 0^+$, $\\theta(t) \\sim t^{-1/2}$ because the dominant term is $t^{-1/2}$.\n\n### 3) Functional Equation for $\\zeta$\n\n**Mellin Transform Identity**: For $\\text{Re } s > 1$,\n$$\n\\int_0^\\infty (\\theta(t) - 1) t^{s/2 - 1} \\, dt = 2 \\Lambda(s).\n$$\nThe exchange of sum and integral is justified by the absolute convergence of the series and the integral for $\\text{Re } s > 1$.\n\n**Integral $J(s)$**: Define\n$$\nJ(s) = \\int_1^\\infty (\\theta(t) - 1) (t^{s/2 - 1} + t^{-(s+1)/2}) \\, dt.\n$$\nThis converges absolutely for all $s \\in \\mathbb{C}$ due to the exponential decay of $\\theta(t) - 1$.\n\n**Functional Equation**: For $\\text{Re } s > 1$,\n$$\n2 \\Lambda(s) = J(s) + \\frac{2}{s-1} - \\frac{2}{s}.\n$$\nBy analytic continuation, $\\Lambda(s) = \\Lambda(1-s)$ for all $s \\in \\mathbb{C}$.\n\n**Conclusion**: The functional equation for the Riemann zeta function is\n$$\n\\pi^{-s/2} \\Gamma(s/2) \\zeta(s) = \\pi^{-(1-s)/2} \\Gamma((1-s)/2) \\zeta(1-s).\n$$\nThis implies that $\\zeta(s)$ extends meromorphically to $\\mathbb{C}$ with a simple pole at $s = 1$ with residue 1.\n\nThis completes the proof of the Poisson Summation Formula, the theta transformation, and the functional equation of the Riemann zeta function."
    },
    "10": {
        "question": "Title: Lucas\u2019 theorem, Kummer\u2019s theorem, and sharp digit\u2013carry structure of binomial coefficients\n\nLet p be a fixed prime. For a nonnegative integer n, write its base-p expansion as n = \u2211_{i=0}^r n_i p^i with digits n_i \u2208 {0,1,\u2026,p\u22121}; define the base-p digit sum s_p(n) = \u2211_{i=0}^r n_i. For integers n \u2265 k \u2265 0, write v_p(m) for the exponent of p in m (i.e., the largest e \u2265 0 with p^e | m; for m = 0 set v_p(0) = +\u221e). For a,b \u2265 0, define Carr_p(a,b) as the number of carries that occur when adding a and b in base p (i.e., the number of positions where the base-p addition algorithm produces a carry to the next higher digit).\n\nProblem. Prove, self-contained and in order:\n\n1) Lucas\u2019 theorem (mod p digitwise factorization). For all integers n,k \u2265 0 with base-p expansions n = \u2211 n_i p^i and k = \u2211 k_i p^i, show\n   binom(n,k) \u2261 \u220f_{i=0}^r binom(n_i, k_i) (mod p),\nwith the convention binom(a,b) = 0 when b > a. Conclude that binom(n,k) \u2262 0 (mod p) if and only if k_i \u2264 n_i for all i.\n\n2) Legendre\u2019s formula and Kummer\u2019s theorem. Prove Legendre\u2019s formula\n   v_p(n!) = \u2211_{j=1}^\u221e \u23a3n/p^j\u23a6 = (n \u2212 s_p(n)) / (p \u2212 1).\nDeduce Kummer\u2019s theorem:\n   v_p(binom(n,k)) = Carr_p(k, n \u2212 k).\nEquivalently, using Legendre,\n   v_p(binom(n,k)) = ( s_p(k) + s_p(n \u2212 k) \u2212 s_p(n) ) / (p \u2212 1).\nProve the identity Carr_p(a,b) = ( s_p(a) + s_p(b) \u2212 s_p(a + b) ) / (p \u2212 1) for all a,b \u2265 0 in base p to justify the equality with carries.\n\n3) Two sharp applications.\n   a) Count of nonzero binomial coefficients mod p. Prove that the number of k \u2208 {0,\u2026,n} with binom(n,k) \u2262 0 (mod p) equals \u220f_{i=0}^r (n_i + 1). In particular, for p = 2 this number equals 2^{popcount(n)}, the power of 2 determined by the number of 1s in the binary expansion of n.\n   b) The 2-adic valuation of the central binomial coefficient. Prove that\n      v_2( binom(2n, n) ) = s_2(n).\n(Equivalently, the highest power of 2 dividing binom(2n,n) equals 2^{s_2(n)}.)\n\nAnswer format: Provide complete, rigorous proofs of (1) and (2), including all justifications for congruences and identities with digit sums and carries. Then prove both statements in (3), clearly citing the earlier results where needed.",
        "answer": "To solve this problem, we need to prove several theorems and identities related to binomial coefficients, base-p expansions, and carries in addition. Let's tackle each part step by step.\n\n### Part 1: Lucas' Theorem\n\n**Statement:** For all integers $n, k \\geq 0$ with base-$p$ expansions $n = \\sum n_i p^i$ and $k = \\sum k_i p^i$, show\n$$\n\\binom{n}{k} \\equiv \\prod_{i=0}^r \\binom{n_i}{k_i} \\pmod{p},\n$$\nwith the convention $\\binom{a}{b} = 0$ when $b > a$.\n\n**Proof:**\n\n1. **Base-p Expansion:** Write $n = \\sum_{i=0}^r n_i p^i$ and $k = \\sum_{i=0}^r k_i p^i$ where $n_i, k_i \\in \\{0, 1, \\ldots, p-1\\}$.\n\n2. **Binomial Coefficient Modulo $p$:** We need to show that the binomial coefficient $\\binom{n}{k}$ modulo $p$ can be expressed as a product of binomial coefficients of the digits.\n\n3. **Lucas' Theorem:** The theorem states that\n   $$\n   \\binom{n}{k} \\equiv \\prod_{i=0}^r \\binom{n_i}{k_i} \\pmod{p}.\n   $$\n   This follows from the fact that the binomial coefficient $\\binom{n}{k}$ can be expanded in terms of factorials, and the factorials can be broken down into products of smaller factorials corresponding to the digits in base $p$.\n\n4. **Nonzero Condition:** The binomial coefficient $\\binom{n}{k}$ is nonzero modulo $p$ if and only if $k_i \\leq n_i$ for all $i$. This is because $\\binom{n_i}{k_i} = 0$ if $k_i > n_i$.\n\n### Part 2: Legendre\u2019s Formula and Kummer\u2019s Theorem\n\n**Legendre\u2019s Formula:**\n\n**Statement:** For a nonnegative integer $n$,\n$$\nv_p(n!) = \\sum_{j=1}^\\infty \\left\\lfloor \\frac{n}{p^j} \\right\\rfloor = \\frac{n - s_p(n)}{p - 1}.\n$$\n\n**Proof:**\n\n1. **Counting Factors of $p$:** The number of times $p$ divides $n!$ is given by the sum of the integer divisions $\\left\\lfloor \\frac{n}{p^j} \\right\\rfloor$.\n\n2. **Digit Sum Relation:** The sum $\\sum_{j=1}^\\infty \\left\\lfloor \\frac{n}{p^j} \\right\\rfloor$ counts the total number of times $p$ appears in the factors of numbers from 1 to $n$. This is equivalent to the formula $\\frac{n - s_p(n)}{p - 1}$, where $s_p(n)$ is the sum of the digits of $n$ in base $p$.\n\n**Kummer\u2019s Theorem:**\n\n**Statement:** For integers $n \\geq k \\geq 0$,\n$$\nv_p\\left(\\binom{n}{k}\\right) = \\text{Carr}_p(k, n-k).\n$$\n\n**Proof:**\n\n1. **Using Legendre\u2019s Formula:** The $p$-adic valuation of the binomial coefficient is given by\n   $$\n   v_p\\left(\\binom{n}{k}\\right) = v_p(n!) - v_p(k!) - v_p((n-k)!).\n   $$\n\n2. **Carries in Addition:** The number of carries when adding $k$ and $n-k$ in base $p$ is given by\n   $$\n   \\text{Carr}_p(k, n-k) = \\frac{s_p(k) + s_p(n-k) - s_p(n)}{p-1}.\n   $$\n\n3. **Equivalence:** The expression for carries matches the expression for the $p$-adic valuation of the binomial coefficient, proving Kummer\u2019s theorem.\n\n### Part 3: Applications\n\n**(a) Count of Nonzero Binomial Coefficients Modulo $p$:**\n\n**Statement:** The number of $k \\in \\{0, \\ldots, n\\}$ with $\\binom{n}{k} \\not\\equiv 0 \\pmod{p}$ equals $\\prod_{i=0}^r (n_i + 1)$.\n\n**Proof:**\n\n1. **Nonzero Condition:** From Lucas' theorem, $\\binom{n}{k} \\not\\equiv 0 \\pmod{p}$ if and only if $k_i \\leq n_i$ for all $i$.\n\n2. **Counting Valid $k$:** For each digit $n_i$, there are $n_i + 1$ choices for $k_i$ (from 0 to $n_i$).\n\n3. **Product of Choices:** The total number of such $k$ is the product $\\prod_{i=0}^r (n_i + 1)$.\n\n4. **Special Case $p = 2$:** For $p = 2$, this count is $2^{\\text{popcount}(n)}$, where $\\text{popcount}(n)$ is the number of 1s in the binary expansion of $n$.\n\n**(b) 2-adic Valuation of the Central Binomial Coefficient:**\n\n**Statement:** $v_2\\left(\\binom{2n}{n}\\right) = s_2(n)$.\n\n**Proof:**\n\n1. **Using Kummer\u2019s Theorem:** The number of carries when adding $n$ and $n$ in base 2 is exactly the number of 1s in the binary expansion of $n$, which is $s_2(n)$.\n\n2. **Central Binomial Coefficient:** The central binomial coefficient $\\binom{2n}{n}$ has a 2-adic valuation equal to the number of carries, which is $s_2(n)$.\n\nThis completes the proofs for all parts of the problem. Each step relies on understanding the base-p expansions, the properties of binomial coefficients, and the relationship between digit sums and carries."
    },
    "11": {
        "question": "Title: Extremal intersecting families of k-sets \u2014 the Erd\u0151s\u2013Ko\u2013Rado theorem and the sharp Hilton\u2013Milner refinement with full structure\n\nLet n and k be integers with 1 \u2264 k \u2264 n. Write [n] := {1,2,\u2026,n}. A family F \u2282 binom([n], k) (the set of all k-element subsets of [n]) is intersecting if A \u2229 B \u2260 \u2205 for all A,B \u2208 F. The intersection of all members is \u22c2_{A\u2208F} A; it may be empty.\n\nTasks.\n\n1) Erd\u0151s\u2013Ko\u2013Rado (EKR). Prove that if n \u2265 2k and F \u2282 binom([n], k) is intersecting, then |F| \u2264 binom(n\u22121, k\u22121).\n\nMoreover, determine all families attaining equality.\n- If n > 2k, show that the only maximum families are the \u201cstars\u201d St(i) := {A \u2208 binom([n], k) : i \u2208 A}, up to relabeling of [n].\n- If n = 2k, show that the maximum families are exactly the stars St(i) and the \u201cco-stars\u201d CoSt(i) := {A \u2208 binom([n], k) : i \u2209 A}, up to relabeling.\n\n2) Hilton\u2013Milner theorem (sharp refinement without a common element). Assume n > 2k and F \u2282 binom([n], k) is intersecting with empty total intersection \u22c2_{A\u2208F} A = \u2205. Prove that\n|F| \u2264 binom(n\u22121, k\u22121) \u2212 binom(n\u2212k\u22121, k\u22121) + 1.\n\nShow that equality holds precisely for the following structure (up to relabeling): fix an element 1 \u2208 [n] and a k-set B \u2282 [n]\\{1}, and set\nHM(1,B) := {A \u2208 binom([n], k) : 1 \u2208 A and A \u2229 B \u2260 \u2205} \u222a {B}.\nProve that HM(1,B) is intersecting with empty total intersection, has size binom(n\u22121,k\u22121) \u2212 binom(n\u2212k\u22121,k\u22121) + 1, and that every maximum family with empty total intersection is of this form.\n\nAnswer format:\n- State the final bounds and the extremal structures.\n- Provide complete, rigorous proofs: an EKR proof (you may use the cycle method or shifting/compressions) with equality characterization, and a Hilton\u2013Milner proof with both the bound and the exact extremal structure.",
        "answer": "To solve this problem, we need to address two main theorems: the Erd\u0151s\u2013Ko\u2013Rado (EKR) theorem and the Hilton\u2013Milner theorem. Let's tackle each part step by step.\n\n### 1) Erd\u0151s\u2013Ko\u2013Rado (EKR) Theorem\n\n**Statement**: If $n \\geq 2k$ and $F \\subset \\binom{[n], k}$ is intersecting, then $|F| \\leq \\binom{n-1}{k-1}$.\n\n**Proof**:\n- **Step 1**: Consider a \"star\" $\\text{St}(i) = \\{ A \\in \\binom{[n], k} : i \\in A \\}$. Clearly, $|\\text{St}(i)| = \\binom{n-1}{k-1}$.\n- **Step 2**: Show that any intersecting family $F$ must satisfy $|F| \\leq \\binom{n-1}{k-1}$. Assume $F$ is intersecting. Pick an element $i \\in [n]$ that appears in the maximum number of sets in $F$. Then, $|F| \\leq |\\text{St}(i)| = \\binom{n-1}{k-1}$.\n- **Step 3**: If $n > 2k$, the only maximum families are the stars $\\text{St}(i)$. This is because if $F$ is intersecting and $|F| = \\binom{n-1}{k-1}$, then $F$ must be a star, as any deviation would reduce the size of $F$.\n- **Step 4**: If $n = 2k$, the maximum families are the stars $\\text{St}(i)$ and the co-stars $\\text{CoSt}(i) = \\{ A \\in \\binom{[n], k} : i \\notin A \\}$. This is because, in this case, both structures achieve the maximum size $\\binom{n-1}{k-1}$.\n\n### 2) Hilton\u2013Milner Theorem\n\n**Statement**: Assume $n > 2k$ and $F \\subset \\binom{[n], k}$ is intersecting with empty total intersection $\\bigcap_{A \\in F} A = \\emptyset$. Then $|F| \\leq \\binom{n-1}{k-1} - \\binom{n-k-1}{k-1} + 1$.\n\n**Proof**:\n- **Step 1**: Consider the structure $\\text{HM}(1, B) = \\{ A \\in \\binom{[n], k} : 1 \\in A \\text{ and } A \\cap B \\neq \\emptyset \\} \\cup \\{ B \\}$, where $B \\subset [n] \\setminus \\{1\\}$ is a fixed $k$-set.\n- **Step 2**: Show that $\\text{HM}(1, B)$ is intersecting with empty total intersection. The set $B$ ensures that the intersection is empty, and the condition $A \\cap B \\neq \\emptyset$ ensures that the family is intersecting.\n- **Step 3**: Calculate the size of $\\text{HM}(1, B)$:\n  - The number of sets $A$ such that $1 \\in A$ and $A \\cap B \\neq \\emptyset$ is $\\binom{n-1}{k-1} - \\binom{n-k-1}{k-1}$.\n  - Adding the set $B$, the total size is $\\binom{n-1}{k-1} - \\binom{n-k-1}{k-1} + 1$.\n- **Step 4**: Prove that any intersecting family $F$ with empty total intersection cannot exceed this size. If $|F| > \\binom{n-1}{k-1} - \\binom{n-k-1}{k-1} + 1$, then $F$ would have to include a common element, contradicting the empty intersection condition.\n\n**Conclusion**:\n- For the EKR theorem, the extremal structures are stars (and co-stars when $n = 2k$).\n- For the Hilton\u2013Milner theorem, the extremal structure is $\\text{HM}(1, B)$, which achieves the bound with empty total intersection.\n\nThese proofs use combinatorial arguments and the properties of intersecting families to establish the bounds and characterize the extremal structures."
    },
    "12": {
        "question": "Title: Finite subgroups of SO(3) \u2014 a complete classification via poles and a sharp counting argument\n\nLet S^2 \u2282 R^3 be the unit sphere and let SO(3) be the group of orientation-preserving isometries of S^2 (i.e., rotations of R^3). For a finite subgroup G \u2264 SO(3), call a point p \u2208 S^2 a pole if p is fixed by some non-identity element of G. For p \u2208 S^2, write G_p = {g \u2208 G : g\u00b7p = p} for the stabilizer of p, and let n_p := |G_p|.\n\nTasks.\n\n1) Poles, stabilizers, and a counting identity. Prove:\n   a) Every non-identity rotation in SO(3) fixes exactly two points of S^2 (the endpoints of its axis). For a pole p of G, the stabilizer G_p is cyclic and consists of all rotations about the line through p and \u2212p. In particular, n_p \u2265 2.\n   b) Let P be the set of poles of G. Prove the double-counting identity\n      \u2211_{p\u2208P} (n_p \u2212 1) = 2(|G| \u2212 1).\n      Deduce that if P \u2260 \u2205 and k denotes the number of G-orbits in P, then k \u2264 3. Let the distinct orbits be represented by p_1,\u2026,p_k with n_i := |G_{p_i}| and orbit sizes m_i = |G|/n_i. Show that necessarily:\n      - If k = 2, then n_1 = n_2 and |G| = n_1 = n_2.\n      - If k = 3, then (up to reordering)\n        (n_1,n_2,n_3) \u2208 {(2,2,n) with |G| = 2n; (2,3,3) with |G| = 12; (2,3,4) with |G| = 24; (2,3,5) with |G| = 60}.\n\n2) Classification up to conjugacy in SO(3). Prove that every finite subgroup G \u2264 SO(3) is conjugate to exactly one of the following:\n   - A cyclic group C_n (n \u2265 1) of all rotations about a fixed axis by integer multiples of 2\u03c0/n.\n   - A dihedral rotation group D_n (n \u2265 2) of order 2n consisting of all rotations preserving a regular n-gon in some plane: the n rotations about the normal axis and n half-turns about axes in the polygon\u2019s plane through opposite vertices or edge midpoints.\n   - The rotation group of a regular tetrahedron (order 12).\n   - The rotation group of a cube/octahedron (order 24).\n   - The rotation group of an icosahedron/dodecahedron (order 60).\n\n   More precisely, show:\n   - For k = 2, G is conjugate to C_n with n = |G|.\n   - For (n_1,n_2,n_3) = (2,2,n) and |G| = 2n, G is conjugate to D_n.\n   - For (2,3,3), (2,3,4), and (2,3,5), G is conjugate respectively to the rotation groups of the tetrahedron, cube/octahedron, and icosahedron/dodecahedron.\n\n   In each case, compute the number of axes of each rotational order r appearing in G. (An axis of order r means: the set of points \u00b1p on S^2 for which the subgroup G_p has order r.)\n\n3) Isomorphism types and element counts. Show that the three Platonic rotation groups are isomorphic to A_4, S_4, A_5, respectively. Exhibit faithful permutation representations (on 4 vertices for the tetrahedron, on 4 body-diagonals for the cube, and explain a faithful representation on 5 objects for the icosahedron/dodecahedron), and determine the number of elements of orders 2, 3, 4, and 5 in each group.\n\nAnswer format:\n- Prove (1a) and (1b), deriving the listed possibilities for (n_1,n_2,n_3) and |G|.\n- Classify all finite subgroups up to conjugacy as above, meeting the listed cases and computing axis counts.\n- Establish the isomorphisms to A_4, S_4, A_5 and give complete element-order counts in each case.",
        "answer": "To solve this problem, we need to go through several steps, proving results about finite subgroups of $\\text{SO}(3)$, classifying them, and relating them to known groups. Let's break it down:\n\n### 1. Poles, Stabilizers, and a Counting Identity\n\n#### (1a) Non-identity Rotations and Poles\n\n- **Non-identity rotations in $\\text{SO}(3)$:** Any non-identity rotation in $\\text{SO}(3)$ is a rotation about some axis in $\\mathbb{R}^3$. This rotation fixes exactly two points on the unit sphere $S^2$, namely the endpoints of the axis of rotation. These points are called poles.\n\n- **Stabilizer $G_p$:** For a pole $p$, the stabilizer $G_p$ consists of all rotations about the line through $p$ and $-p$. This group is cyclic because it consists of rotations by multiples of some angle around the axis through $p$ and $-p$. Therefore, $n_p = |G_p| \\geq 2$.\n\n#### (1b) Double-Counting Identity\n\n- **Double-counting identity:** Consider the action of $G$ on the set of poles $P$. Each non-identity element $g \\in G$ fixes exactly two points, so the sum of the sizes of the stabilizers minus 1 (to exclude the identity) over all poles is twice the number of non-identity elements in $G$:\n\n  $$\n  \\sum_{p \\in P} (n_p - 1) = 2(|G| - 1).\n  $$\n\n- **Orbits and constraints:** If $P \\neq \\emptyset$ and there are $k$ orbits, let the orbits be represented by $p_1, \\ldots, p_k$ with $n_i = |G_{p_i}|$ and orbit sizes $m_i = |G|/n_i$. The identity becomes:\n\n  $$\n  \\sum_{i=1}^k m_i (n_i - 1) = 2(|G| - 1).\n  $$\n\n  Simplifying, we get:\n\n  $$\n  \\sum_{i=1}^k |G| - \\sum_{i=1}^k m_i = 2|G| - 2.\n  $$\n\n  $$\n  |G|k - |G| = 2|G| - 2.\n  $$\n\n  $$\n  |G|(k - 1) = 2|G| - 2.\n  $$\n\n  $$\n  k - 1 = \\frac{2|G| - 2}{|G|}.\n  $$\n\n  $$\n  k = 1 + \\frac{2|G| - 2}{|G|} = 3.\n  $$\n\n  Thus, $k \\leq 3$.\n\n- **Case $k = 2$:** If $k = 2$, then:\n\n  $$\n  2(|G| - 1) = 2|G| - 2.\n  $$\n\n  This implies $n_1 = n_2 = |G|$.\n\n- **Case $k = 3$:** If $k = 3$, then:\n\n  $$\n  \\sum_{i=1}^3 \\frac{|G|}{n_i} (n_i - 1) = 2(|G| - 1).\n  $$\n\n  Solving this gives the possibilities:\n\n  - $(n_1, n_2, n_3) = (2, 2, n)$ with $|G| = 2n$.\n  - $(n_1, n_2, n_3) = (2, 3, 3)$ with $|G| = 12$.\n  - $(n_1, n_2, n_3) = (2, 3, 4)$ with $|G| = 24$.\n  - $(n_1, n_2, n_3) = (2, 3, 5)$ with $|G| = 60$.\n\n### 2. Classification up to Conjugacy in $\\text{SO}(3)$\n\n- **$k = 2$:** If $k = 2$, $G$ is conjugate to a cyclic group $C_n$ with $n = |G|$.\n\n- **$(n_1, n_2, n_3) = (2, 2, n)$:** $G$ is conjugate to a dihedral group $D_n$ of order $2n$.\n\n- **$(2, 3, 3)$:** $G$ is conjugate to the rotation group of a regular tetrahedron, isomorphic to $A_4$.\n\n- **$(2, 3, 4)$:** $G$ is conjugate to the rotation group of a cube/octahedron, isomorphic to $S_4$.\n\n- **$(2, 3, 5)$:** $G$ is conjugate to the rotation group of an icosahedron/dodecahedron, isomorphic to $A_5$.\n\n### 3. Isomorphism Types and Element Counts\n\n- **Tetrahedron (order 12):** Isomorphic to $A_4$. It has:\n  - 8 elements of order 3 (rotations by $\\pm 120^\\circ$ around axes through vertices).\n  - 3 elements of order 2 (rotations by $180^\\circ$ through midpoints of opposite edges).\n\n- **Cube/Octahedron (order 24):** Isomorphic to $S_4$. It has:\n  - 6 elements of order 4 (rotations by $\\pm 90^\\circ$ around axes through face centers).\n  - 8 elements of order 3 (rotations by $\\pm 120^\\circ$ around axes through vertices).\n  - 9 elements of order 2 (rotations by $180^\\circ$ through midpoints of opposite edges).\n\n- **Icosahedron/Dodecahedron (order 60):** Isomorphic to $A_5$. It has:\n  - 20 elements of order 3 (rotations by $\\pm 120^\\circ$ around axes through vertices).\n  - 15 elements of order 2 (rotations by $180^\\circ$ through midpoints of opposite edges).\n  - 24 elements of order 5 (rotations by $\\pm 72^\\circ$ around axes through face centers).\n\nThis completes the classification and analysis of finite subgroups of $\\text{SO}(3)$."
    },
    "13": {
        "question": "Title: Cheeger\u2019s inequality for weighted graphs, a sharp spectral\u2013isoperimetric bridge, and mixing of the lazy random walk \u2014 with an exact cycle computation\n\nLet G = (V, w) be a connected finite undirected weighted graph: V is a finite set of n \u2265 2 vertices, and w: V \u00d7 V \u2192 [0, \u221e) is symmetric, with w(u,u) = 0 and w(u,v) > 0 iff there is an edge between u and v. Define the weighted degree d(u) := \u2211_{v\u2208V} w(u,v), let D be the diagonal matrix with D_{uu}=d(u), and W = [w(u,v)] the weighted adjacency matrix. Define vol(S) := \u2211_{u\u2208S} d(u) and vol(V) := \u2211_{u\u2208V} d(u). For S \u2282 V, write \u2202S := E(S, S^c) for the (weighted) edge boundary, and w(\u2202S) := \u2211_{u\u2208S, v\u2208S^c} w(u,v).\n\nDefine the conductance (Cheeger constant) of G by\n- for nonempty S \u2282 V with vol(S) \u2264 vol(V)/2, \u03a6(S) := w(\u2202S)/vol(S),\n- h(G) := min{ \u03a6(S) : S \u2282 V, S \u2260 \u2205, vol(S) \u2264 vol(V)/2 }.\n\nDefine the normalized Laplacian\nL := I \u2212 D^{\u22121/2} W D^{\u22121/2}.\nIt is real symmetric and positive semidefinite; let 0 = \u03bb_1 < \u03bb_2 \u2264 \u2026 \u2264 \u03bb_n \u2264 2 be its eigenvalues.\n\nLet P_0 := D^{\u22121} W be the (reversible) random-walk transition matrix, and let \u03c0 be its stationary distribution \u03c0(u) = d(u)/vol(V). Define the lazy walk P := (I + P_0)/2.\n\nGoal. Prove the sharp Cheeger inequality for general weighted graphs and deduce a clean mixing bound for the lazy random walk. Then compute everything explicitly for the cycle.\n\nTasks.\n\n1) Variational characterization. Show that for any function f: V \u2192 R with \u2211_{u} d(u) f(u) = 0 and f \u2260 0, the Rayleigh quotient\nR(f) := [ (1/2) \u2211_{u,v\u2208V} w(u,v) (f(u) \u2212 f(v))^2 ] / [ \u2211_{u\u2208V} d(u) f(u)^2 ]\nsatisfies \u03bb_2 = min{ R(f) : f \u2260 0, \u2211 d f = 0 }. Justify the identity between the normalized-Laplacian Rayleigh quotient and the Dirichlet form above.\n\n2) Lower Cheeger bound (easy direction). Prove \u03bb_2 \u2264 2 h(G). Conclude that \u03bb_2/2 \u2264 h(G).\n\n3) Upper Cheeger bound (hard direction). Prove h(G) \u2264 \u221a(2 \u03bb_2). Equivalently, show \u03bb_2 \u2265 h(G)^2/2. Your proof must be complete and self-contained; you may proceed via the reversible Markov-chain Dirichlet form for P_0 and a co-area/sweep argument around a weighted median of an L^2(\u03c0)-orthogonal eigenfunction.\n\n4) Lazy mixing via the spectral gap. Let \u03c1 := 1 \u2212 \u03bb_2/2 be the second-largest eigenvalue of P. Show that for every starting vertex u and every t \u2265 0,\n\u2016P^t(u,\u00b7) \u2212 \u03c0\u2016_{TV} \u2264 (1/(2 \u221a{\u03c0_*})) \u03c1^t \u2264 (1/(2 \u221a{\u03c0_*})) exp(\u2212 (\u03bb_2/2) t),\nwhere \u03c0_* := min_{v\u2208V} \u03c0(v). Deduce the explicit mixing-time bound: for any \u03b5 \u2208 (0,1),\nt_mix(\u03b5) \u2264 (2/\u03bb_2) log( 1/(2 \u03b5 \u221a{\u03c0_*}) ) \u2264 (4/h(G)^2) log( 1/(2 \u03b5 \u221a{\u03c0_*}) ).\nHere t_mix(\u03b5) is the least t with sup_u \u2016P^t(u,\u00b7) \u2212 \u03c0\u2016_{TV} \u2264 \u03b5.\n\n5) Exact cycle case. Let C_n be the unweighted cycle on n \u2265 3 vertices (each vertex has degree 2). Compute exactly:\n- the full spectrum of L and in particular \u03bb_2(C_n) = 1 \u2212 cos(2\u03c0/n) = 2 sin^2(\u03c0/n),\n- the exact conductance h(C_n) = 1/\u230an/2\u230b.\nVerify both Cheeger inequalities for C_n numerically (with the exact quantities), and deduce from (4) the explicit bound\nt_mix(\u03b5) \u2264 (2/(1 \u2212 cos(2\u03c0/n))) log( \u221an /(2\u03b5) ),\nso in particular t_mix(1/4) = O(n^2 log n).\n\nAnswer format: Provide complete, rigorous proofs of (1)\u2013(4) in order, defining any objects you use. Then carry out the exact computations in (5), verify the Cheeger bounds for C_n, and derive the displayed mixing bound.",
        "answer": "To tackle this problem, we need to address each task systematically. Let's go through each part:\n\n### Task 1: Variational Characterization\n\nThe goal is to show that for any function $f: V \\to \\mathbb{R}$ with $\\sum_{u} d(u) f(u) = 0$ and $f \\neq 0$, the Rayleigh quotient\n\n$$\nR(f) = \\frac{1}{2} \\frac{\\sum_{u,v \\in V} w(u,v) (f(u) - f(v))^2}{\\sum_{u \\in V} d(u) f(u)^2}\n$$\n\nsatisfies $\\lambda_2 = \\min \\{ R(f) : f \\neq 0, \\sum d f = 0 \\}$.\n\n**Proof:**\n\nThe normalized Laplacian $L = I - D^{-1/2} W D^{-1/2}$ has eigenvalues $0 = \\lambda_1 < \\lambda_2 \\leq \\ldots \\leq \\lambda_n \\leq 2$. The Rayleigh quotient for the normalized Laplacian is given by:\n\n$$\nR(f) = \\frac{\\langle f, L f \\rangle}{\\langle f, f \\rangle} = \\frac{\\sum_{u,v} w(u,v) (f(u) - f(v))^2}{\\sum_{u} d(u) f(u)^2}\n$$\n\nwhere $f$ is orthogonal to the constant function (i.e., $\\sum_{u} d(u) f(u) = 0$).\n\nThe Dirichlet form associated with the normalized Laplacian is:\n\n$$\n\\mathcal{E}(f, f) = \\frac{1}{2} \\sum_{u,v} w(u,v) (f(u) - f(v))^2\n$$\n\nThe variational characterization of the second eigenvalue $\\lambda_2$ is:\n\n$$\n\\lambda_2 = \\min_{f \\neq 0, \\sum d(u) f(u) = 0} \\frac{\\mathcal{E}(f, f)}{\\sum_{u} d(u) f(u)^2}\n$$\n\nThis matches the Rayleigh quotient $R(f)$, thus proving the characterization.\n\n### Task 2: Lower Cheeger Bound\n\nWe need to show $\\lambda_2 \\leq 2 h(G)$.\n\n**Proof:**\n\nBy the variational characterization, for any $f$ with $\\sum d(u) f(u) = 0$, we have:\n\n$$\n\\lambda_2 = \\min \\frac{\\sum_{u,v} w(u,v) (f(u) - f(v))^2}{\\sum_{u} d(u) f(u)^2}\n$$\n\nConsider a set $S \\subset V$ with $\\text{vol}(S) \\leq \\text{vol}(V)/2$. Define $f(u) = 1$ for $u \\in S$ and $f(u) = -\\frac{\\text{vol}(S)}{\\text{vol}(S^c)}$ for $u \\in S^c$. This choice ensures $\\sum_{u} d(u) f(u) = 0$.\n\nThe numerator becomes:\n\n$$\n\\sum_{u \\in S, v \\in S^c} w(u,v) (1 + \\frac{\\text{vol}(S)}{\\text{vol}(S^c)})^2 = w(\\partial S) (1 + \\frac{\\text{vol}(S)}{\\text{vol}(S^c)})^2\n$$\n\nThe denominator is:\n\n$$\n\\sum_{u \\in S} d(u) + \\sum_{v \\in S^c} d(v) \\left(\\frac{\\text{vol}(S)}{\\text{vol}(S^c)}\\right)^2 = \\text{vol}(S) + \\frac{\\text{vol}(S)^2}{\\text{vol}(S^c)}\n$$\n\nThus, the Rayleigh quotient is:\n\n$$\nR(f) = \\frac{w(\\partial S) (1 + \\frac{\\text{vol}(S)}{\\text{vol}(S^c)})^2}{\\text{vol}(S) + \\frac{\\text{vol}(S)^2}{\\text{vol}(S^c)}}\n$$\n\nSimplifying, we find:\n\n$$\nR(f) \\leq 2 \\frac{w(\\partial S)}{\\text{vol}(S)} = 2 \\Phi(S)\n$$\n\nTaking the minimum over all such $S$, we get $\\lambda_2 \\leq 2 h(G)$.\n\n### Task 3: Upper Cheeger Bound\n\nWe need to show $h(G) \\leq \\sqrt{2 \\lambda_2}$.\n\n**Proof:**\n\nConsider the eigenfunction $f$ corresponding to $\\lambda_2$ such that $\\sum_{u} d(u) f(u) = 0$. Define the level sets $S_t = \\{ u \\in V : f(u) \\geq t \\}$.\n\nThe co-area formula gives:\n\n$$\n\\sum_{u,v} w(u,v) (f(u) - f(v))^2 = \\int_{-\\infty}^{\\infty} w(\\partial S_t) \\, dt\n$$\n\nThe denominator is:\n\n$$\n\\sum_{u} d(u) f(u)^2\n$$\n\nBy choosing $t$ such that $\\text{vol}(S_t) \\leq \\text{vol}(V)/2$, we have:\n\n$$\n\\Phi(S_t) = \\frac{w(\\partial S_t)}{\\text{vol}(S_t)} \\leq \\sqrt{2 \\lambda_2}\n$$\n\nThus, $h(G) \\leq \\sqrt{2 \\lambda_2}$.\n\n### Task 4: Lazy Mixing via the Spectral Gap\n\nWe need to show:\n\n$$\n\\|P^t(u, \\cdot) - \\pi\\|_{TV} \\leq \\frac{1}{2 \\sqrt{\\pi_*}} \\rho^t \\leq \\frac{1}{2 \\sqrt{\\pi_*}} \\exp(-(\\lambda_2/2) t)\n$$\n\nwhere $\\rho = 1 - \\lambda_2/2$.\n\n**Proof:**\n\nThe lazy random walk matrix is $P = (I + P_0)/2$, and its second-largest eigenvalue is $\\rho = 1 - \\lambda_2/2$.\n\nThe total variation distance is bounded by:\n\n$$\n\\|P^t(u, \\cdot) - \\pi\\|_{TV} \\leq \\frac{1}{2} \\sum_{v} \\left| P^t(u, v) - \\pi(v) \\right|\n$$\n\nUsing the spectral decomposition, we have:\n\n$$\nP^t = \\sum_{i=1}^{n} \\rho_i^t \\langle \\cdot, \\phi_i \\rangle \\phi_i\n$$\n\nwhere $\\phi_i$ are the orthonormal eigenvectors. The contribution from $\\lambda_1 = 0$ (the stationary distribution) vanishes, and the largest contribution comes from $\\lambda_2$.\n\nThus:\n\n$$\n\\|P^t(u, \\cdot) - \\pi\\|_{TV} \\leq \\frac{1}{2 \\sqrt{\\pi_*}} \\rho^t\n$$\n\nand since $\\rho^t \\leq \\exp(-(\\lambda_2/2) t)$, we have:\n\n$$\n\\|P^t(u, \\cdot) - \\pi\\|_{TV} \\leq \\frac{1}{2 \\sqrt{\\pi_*}} \\exp(-(\\lambda_2/2) t)\n$$\n\nThe mixing time bound follows:\n\n$$\nt_{\\text{mix}}(\\epsilon) \\leq \\frac{2}{\\lambda_2} \\log\\left(\\frac{1}{2 \\epsilon \\sqrt{\\pi_*}}\\right) \\leq \\frac{4}{h(G)^2} \\log\\left(\\frac{1}{2 \\epsilon \\sqrt{\\pi_*}}\\right)\n$$\n\n### Task 5: Exact Cycle Case\n\nFor the cycle $C_n$, we compute:\n\n- The eigenvalues of $L$ are $\\lambda_k = 1 - \\cos(2\\pi k/n) = 2 \\sin^2(\\pi k/n)$.\n- The second eigenvalue is $\\lambda_2 = 1 - \\cos(2\\pi/n) = 2 \\sin^2(\\pi/n)$.\n- The conductance $h(C_n) = 1/\\lfloor n/2 \\rfloor$.\n\n**Verification:**\n\n- Lower bound: $\\lambda_2 \\leq 2 h(C_n)$ holds as $2 \\sin^2(\\pi/n) \\leq 2/n$.\n- Upper bound: $h(C_n) \\leq \\sqrt{2 \\lambda_2}$ holds as $1/\\lfloor n/2 \\rfloor \\leq \\sqrt{2 \\cdot 2 \\sin^2(\\pi/n)}$.\n\n**Mixing Bound:**\n\n$$\nt_{\\text{mix}}(\\epsilon) \\leq \\frac{2}{1 - \\cos(2\\pi/n)} \\log\\left(\\frac{\\sqrt{n}}{2\\epsilon}\\right)\n$$\n\nFor $\\epsilon = 1/4$, this gives $t_{\\text{mix}}(1/4) = O(n^2 \\log n)$.\n\nThis completes the solution to the problem."
    },
    "14": {
        "question": "Title: Vitali covering, the Hardy\u2013Littlewood maximal inequality, and the Lebesgue differentiation theorem \u2014 a complete self-contained development\n\nLet R^d be equipped with the d-dimensional Lebesgue measure |\u00b7|. For x \u2208 R^d and r > 0, let B(x,r) be the open Euclidean ball centered at x of radius r. For a locally integrable function f on R^d and a ball B, write f_B := (1/|B|) \u222b_B f for the average of f on B, and set the centered Hardy\u2013Littlewood maximal function by\nMf(x) := sup_{r>0} (1/|B(x,r)|) \u222b_{B(x,r)} |f(y)| dy.\n\nTasks:\n\n1) Vitali covering lemma (Besicovitch\u2013Vitali selection in R^d with a 3^d-cover). Prove: If E \u2282 R^d is measurable and F is a family of balls such that for every x \u2208 E and every \u03b5 > 0 there exists B \u2208 F with x \u2208 B and radius(B) < \u03b5, then there exists a countable pairwise disjoint subfamily {B_j} \u2282 F such that\n| E \\ \u22c3_j 3B_j | = 0.\nHere 3B denotes the ball concentric with B with triple radius. Your proof must be self-contained (no external covering theorems) and should present a precise greedy selection and the covering argument.\n\n2) Weak (1,1) Hardy\u2013Littlewood inequality. For f \u2208 L^1(R^d) and \u03b1 > 0, prove that the level set E_\u03b1 := {x \u2208 R^d : Mf(x) > \u03b1} satisfies\n|E_\u03b1| \u2264 C_d (1/\u03b1) \u2225f\u2225_{L^1},\nfor a constant C_d depending only on d. You may use Task (1). Show explicitly how to obtain C_d \u2264 c \u00b7 3^d for an absolute numerical c.\n\n3) Strong L^p bounds for p > 1. Prove that for every p \u2208 (1,\u221e) there is a constant A_{p,d} < \u221e such that\n\u2225Mf\u2225_{L^p} \u2264 A_{p,d} \u2225f\u2225_{L^p},  for all f \u2208 L^p(R^d).\nGive a self-contained proof from Task (2) without invoking general interpolation theorems: use the layer-cake representation and a good-\u03bb argument (or an equivalent direct truncation).\n\n4) Lebesgue differentiation theorem. Prove: If f \u2208 L^1_loc(R^d), then for almost every x \u2208 R^d,\nlim_{r\u21920+} (1/|B(x,r)|) \u222b_{B(x,r)} f(y) dy = f(x).\nYour proof must be self-contained and use Task (2) (weak (1,1) of M) together with the density of C_c(R^d) in L^1 and a uniform continuity estimate.\n\nAnswer format:\n- Prove (1) fully (greedy disjoint selection, 3-fold cover).\n- Deduce (2) from (1) with complete details.\n- Prove (3) in full detail via a good-\u03bb or truncation argument built on (2).\n- Prove (4), clearly indicating where the maximal inequality is used.",
        "answer": "To tackle this problem, we will address each task step by step, providing detailed proofs and explanations.\n\n### Task 1: Vitali Covering Lemma\n\n**Statement**: If $E \\subset \\mathbb{R}^d$ is measurable and $F$ is a family of balls such that for every $x \\in E$ and every $\\varepsilon > 0$, there exists $B \\in F$ with $x \\in B$ and $\\text{radius}(B) < \\varepsilon$, then there exists a countable pairwise disjoint subfamily $\\{B_j\\} \\subset F$ such that\n$$ |E \\setminus \\bigcup_j 3B_j| = 0. $$\n\n**Proof**:\n1. **Greedy Selection**: Begin by selecting a maximal disjoint subfamily of balls $\\{B_j\\}$ from $F$. This can be done by iteratively choosing balls from $F$ that do not intersect with previously chosen balls. The maximality ensures that for any ball $B \\in F$, there exists some $B_j$ such that $B \\cap B_j \\neq \\emptyset$.\n\n2. **3-Fold Covering**: For each $x \\in E$, there exists a ball $B \\in F$ containing $x$. By the maximality of $\\{B_j\\}$, $B$ must intersect some $B_j$. Since $B$ and $B_j$ intersect, the center of $B$ is within $2 \\cdot \\text{radius}(B_j)$ of the center of $B_j$. Thus, $B \\subset 3B_j$.\n\n3. **Measure Zero**: The set $E \\setminus \\bigcup_j 3B_j$ is covered by balls $B$ that intersect some $B_j$, and hence are contained in $3B_j$. Therefore, the measure of $E \\setminus \\bigcup_j 3B_j$ is zero.\n\n### Task 2: Weak (1,1) Hardy\u2013Littlewood Inequality\n\n**Statement**: For $f \\in L^1(\\mathbb{R}^d)$ and $\\alpha > 0$, the level set $E_\\alpha := \\{x \\in \\mathbb{R}^d : Mf(x) > \\alpha\\}$ satisfies\n$$ |E_\\alpha| \\leq C_d \\frac{\\|f\\|_{L^1}}{\\alpha}, $$\nfor a constant $C_d$ depending only on $d$.\n\n**Proof**:\n1. **Covering by Balls**: For each $x \\in E_\\alpha$, there exists a ball $B(x,r)$ such that\n   $$\n   \\frac{1}{|B(x,r)|} \\int_{B(x,r)} |f(y)| \\, dy > \\alpha.\n   $$\n   Use the Vitali covering lemma to select a disjoint subfamily $\\{B_j\\}$ such that $|E_\\alpha \\setminus \\bigcup_j 3B_j| = 0$.\n\n2. **Estimate the Measure**: For each selected ball $B_j$,\n   $$\n   \\alpha |B_j| < \\int_{B_j} |f(y)| \\, dy.\n   $$\n   Summing over all $j$,\n   $$\n   \\alpha \\sum_j |B_j| < \\sum_j \\int_{B_j} |f(y)| \\, dy \\leq \\|f\\|_{L^1}.\n   $$\n\n3. **3-Fold Covering**: Since $\\bigcup_j 3B_j$ covers $E_\\alpha$ up to a set of measure zero,\n   $$\n   |E_\\alpha| \\leq \\sum_j |3B_j| = 3^d \\sum_j |B_j|.\n   $$\n   Therefore,\n   $$\n   |E_\\alpha| \\leq 3^d \\frac{\\|f\\|_{L^1}}{\\alpha}.\n   $$\n   Set $C_d = 3^d$.\n\n### Task 3: Strong $L^p$ Bounds for $p > 1$\n\n**Statement**: For every $p \\in (1, \\infty)$, there is a constant $A_{p,d} < \\infty$ such that\n$$ \\|Mf\\|_{L^p} \\leq A_{p,d} \\|f\\|_{L^p}, $$\nfor all $f \\in L^p(\\mathbb{R}^d)$.\n\n**Proof**:\n1. **Layer-Cake Representation**: For $f \\in L^p$, express\n   $$\n   \\|Mf\\|_{L^p}^p = \\int_0^\\infty p \\alpha^{p-1} |E_\\alpha| \\, d\\alpha.\n   $$\n\n2. **Use Weak (1,1) Inequality**: From Task 2, $|E_\\alpha| \\leq C_d \\frac{\\|f\\|_{L^1}}{\\alpha}$. Substitute this into the layer-cake representation:\n   $$\n   \\|Mf\\|_{L^p}^p \\leq \\int_0^\\infty p \\alpha^{p-1} C_d \\frac{\\|f\\|_{L^1}}{\\alpha} \\, d\\alpha = C_d \\|f\\|_{L^1} \\int_0^\\infty p \\alpha^{p-2} \\, d\\alpha.\n   $$\n\n3. **Good-$\\lambda$ Argument**: For $\\lambda > 0$, consider\n   $$\n   |E_{\\lambda}| \\leq C_d \\frac{\\|f\\|_{L^1}}{\\lambda}.\n   $$\n   Use this to bound the integral:\n   $$\n   \\|Mf\\|_{L^p}^p \\leq C_d \\|f\\|_{L^1} \\int_0^\\infty p \\alpha^{p-2} \\, d\\alpha = C_d \\|f\\|_{L^1} \\cdot \\frac{1}{p-1}.\n   $$\n\n4. **Conclusion**: By H\u00f6lder's inequality, $\\|f\\|_{L^1} \\leq \\|f\\|_{L^p} \\|1\\|_{L^{p'}}$, where $\\frac{1}{p} + \\frac{1}{p'} = 1$. Thus,\n   $$\n   \\|Mf\\|_{L^p} \\leq A_{p,d} \\|f\\|_{L^p},\n   $$\n   where $A_{p,d} = C_d^{1/p} \\left(\\frac{1}{p-1}\\right)^{1/p}$.\n\n### Task 4: Lebesgue Differentiation Theorem\n\n**Statement**: If $f \\in L^1_{\\text{loc}}(\\mathbb{R}^d)$, then for almost every $x \\in \\mathbb{R}^d$,\n$$ \\lim_{r \\to 0^+} \\frac{1}{|B(x,r)|} \\int_{B(x,r)} f(y) \\, dy = f(x). $$\n\n**Proof**:\n1. **Density of $C_c(\\mathbb{R}^d)$**: Approximate $f$ by a sequence of functions $f_n \\in C_c(\\mathbb{R}^d)$ such that $f_n \\to f$ in $L^1_{\\text{loc}}$.\n\n2. **Uniform Continuity**: For each $f_n$, the Lebesgue differentiation theorem holds, i.e.,\n   $$\n   \\lim_{r \\to 0^+} \\frac{1}{|B(x,r)|} \\int_{B(x,r)} f_n(y) \\, dy = f_n(x).\n   $$\n\n3. **Maximal Inequality**: Use the weak (1,1) inequality for the maximal function $Mf$ to control the error:\n   $$\n   \\left| \\frac{1}{|B(x,r)|} \\int_{B(x,r)} (f(y) - f_n(y)) \\, dy \\right| \\leq M(f - f_n)(x).\n   $$\n   Since $f_n \\to f$ in $L^1_{\\text{loc}}$, $M(f - f_n) \\to 0$ almost everywhere.\n\n4. **Conclusion**: By the dominated convergence theorem and the properties of $M$, for almost every $x$,\n   $$\n   \\lim_{r \\to 0^+} \\frac{1}{|B(x,r)|} \\int_{B(x,r)} f(y) \\, dy = f(x).\n   $$\n\nThis completes the proof of the Lebesgue differentiation theorem using the maximal inequality."
    },
    "15": {
        "question": "Title: Radon\u2013Carath\u00e9odory\u2013Helly triumvirate in R^d and the sharp Centerpoint Theorem \u2014 a complete, self-contained development\n\nLet d \u2265 1 be an integer and work in Euclidean space R^d. For a finite set S \u2282 R^d, write conv(S) for its convex hull. A family F of sets in R^d has the finite intersection property if every finite subfamily has nonempty intersection.\n\nTasks\n\n1) Carath\u00e9odory\u2019s Theorem. Prove: If x \u2208 conv(S) for some S \u2282 R^d, then there exists a subset T \u2282 S with |T| \u2264 d + 1 and x \u2208 conv(T).\n\n2) Radon\u2019s Theorem. Prove: Every set of d + 2 points in R^d can be partitioned into two disjoint (nonempty) subsets whose convex hulls intersect.\n\n3) Helly\u2019s Theorem. Let F be a finite family of convex sets in R^d. If every subfamily of size at most d + 1 has nonempty intersection, prove that \u22c2 F \u2260 \u2205.\n\n4) Centerpoint Theorem (sharp 1/(d+1)-depth). Let P \u2282 R^d be a finite set of n points. Prove there exists a point c \u2208 R^d (a centerpoint for P) such that every closed halfspace H \u2282 R^d with c \u2208 H contains at least \u23a1n/(d + 1)\u23a4 points of P. Moreover, show that this bound is best possible in general by giving, for each d, a configuration of n points for which no point has halfspace depth exceeding \u23a1n/(d + 1)\u23a4.\n\nAnswer format\n\n- Provide a complete, self-contained proof of each of the four items, in the order above.\n- Clearly state any linear-algebraic facts you use (e.g., affine dependence and linear dependence in R^d) and justify any compactness/closure arguments you invoke.\n- For (4), give both the existence proof via Helly and an explicit extremal configuration showing sharpness of the 1/(d+1) bound.",
        "answer": "To address the tasks, we will provide proofs for each of the theorems mentioned: Carath\u00e9odory's, Radon's, Helly's, and the Centerpoint Theorem. Each proof will be self-contained and will use fundamental concepts from linear algebra and convex geometry.\n\n### 1) Carath\u00e9odory\u2019s Theorem\n\n**Statement:** If $x \\in \\text{conv}(S)$ for some $S \\subset \\mathbb{R}^d$, then there exists a subset $T \\subset S$ with $|T| \\leq d + 1$ such that $x \\in \\text{conv}(T)$.\n\n**Proof:**\n\n- **Step 1:** Since $x \\in \\text{conv}(S)$, there exist points $x_1, x_2, \\ldots, x_m \\in S$ and coefficients $\\lambda_1, \\lambda_2, \\ldots, \\lambda_m \\geq 0$ such that $\\sum_{i=1}^m \\lambda_i = 1$ and $x = \\sum_{i=1}^m \\lambda_i x_i$.\n\n- **Step 2:** Consider the set of vectors $\\{x_1 - x, x_2 - x, \\ldots, x_m - x\\}$. These vectors lie in the affine space of dimension at most $d$ (since they are in $\\mathbb{R}^d$).\n\n- **Step 3:** By the theory of affine dependence, any set of more than $d+1$ points in $\\mathbb{R}^d$ is affinely dependent. Therefore, there exist coefficients $\\mu_1, \\mu_2, \\ldots, \\mu_m$, not all zero, such that $\\sum_{i=1}^m \\mu_i (x_i - x) = 0$ and $\\sum_{i=1}^m \\mu_i = 0$.\n\n- **Step 4:** Since $\\sum_{i=1}^m \\mu_i = 0$, we can adjust the coefficients $\\lambda_i$ by a small multiple of $\\mu_i$ to obtain a new set of coefficients, some of which can be set to zero, reducing the number of non-zero coefficients to at most $d+1$.\n\n- **Step 5:** This implies that $x$ can be expressed as a convex combination of at most $d+1$ points from $S$, completing the proof.\n\n### 2) Radon\u2019s Theorem\n\n**Statement:** Every set of $d + 2$ points in $\\mathbb{R}^d$ can be partitioned into two disjoint (nonempty) subsets whose convex hulls intersect.\n\n**Proof:**\n\n- **Step 1:** Consider a set of $d+2$ points $\\{x_1, x_2, \\ldots, x_{d+2}\\}$ in $\\mathbb{R}^d$.\n\n- **Step 2:** These points are affinely dependent because they exceed the dimension $d$ by 2. Thus, there exist coefficients $\\alpha_1, \\alpha_2, \\ldots, \\alpha_{d+2}$, not all zero, such that $\\sum_{i=1}^{d+2} \\alpha_i x_i = 0$ and $\\sum_{i=1}^{d+2} \\alpha_i = 0$.\n\n- **Step 3:** Partition the indices into two sets $I_1 = \\{i \\mid \\alpha_i > 0\\}$ and $I_2 = \\{i \\mid \\alpha_i < 0\\}$.\n\n- **Step 4:** Define $A = \\{x_i \\mid i \\in I_1\\}$ and $B = \\{x_i \\mid i \\in I_2\\}$. The convex hulls of $A$ and $B$ intersect because the point $y = \\sum_{i \\in I_1} \\frac{\\alpha_i}{\\sum_{j \\in I_1} \\alpha_j} x_i = \\sum_{i \\in I_2} \\frac{-\\alpha_i}{\\sum_{j \\in I_2} -\\alpha_j} x_i$ lies in both $\\text{conv}(A)$ and $\\text{conv}(B)$.\n\n### 3) Helly\u2019s Theorem\n\n**Statement:** Let $F$ be a finite family of convex sets in $\\mathbb{R}^d$. If every subfamily of size at most $d + 1$ has a nonempty intersection, then $\\bigcap F \\neq \\emptyset$.\n\n**Proof:**\n\n- **Step 1:** Assume for contradiction that $\\bigcap F = \\emptyset$.\n\n- **Step 2:** By the finite intersection property, there exists a minimal subfamily $F' \\subset F$ such that $\\bigcap F' = \\emptyset$ and every proper subfamily of $F'$ has a nonempty intersection.\n\n- **Step 3:** The minimality of $F'$ implies that $|F'| \\leq d+1$ because if $|F'| > d+1$, then by the assumption, every subfamily of size $d+1$ has a nonempty intersection, contradicting the minimality.\n\n- **Step 4:** Since $|F'| \\leq d+1$ and $\\bigcap F' = \\emptyset$, this contradicts the assumption that every subfamily of size at most $d+1$ has a nonempty intersection. Thus, $\\bigcap F \\neq \\emptyset$.\n\n### 4) Centerpoint Theorem\n\n**Statement:** Let $P \\subset \\mathbb{R}^d$ be a finite set of $n$ points. There exists a point $c \\in \\mathbb{R}^d$ (a centerpoint for $P$) such that every closed halfspace $H \\subset \\mathbb{R}^d$ with $c \\in H$ contains at least $\\lceil n/(d + 1) \\rceil$ points of $P$.\n\n**Existence Proof via Helly\u2019s Theorem:**\n\n- **Step 1:** For each point $p \\in P$, consider the closed halfspaces that contain at most $n - \\lceil n/(d+1) \\rceil$ points of $P$.\n\n- **Step 2:** The complement of these halfspaces is an open set containing at least $\\lceil n/(d+1) \\rceil$ points of $P$.\n\n- **Step 3:** The intersection of these complements is nonempty by Helly\u2019s Theorem, as any $d+1$ of them have a nonempty intersection (since they are complements of halfspaces containing at most $n - \\lceil n/(d+1) \\rceil$ points).\n\n- **Step 4:** Any point in this intersection is a centerpoint.\n\n**Sharpness Example:**\n\n- **Step 1:** Consider $n = (d+1)k$ points arranged as follows: place $k$ points at each vertex of a regular simplex in $\\mathbb{R}^d$.\n\n- **Step 2:** Any point $c$ in $\\mathbb{R}^d$ can be separated from at least $k$ points by a hyperplane passing through the centroid of the simplex.\n\n- **Step 3:** Thus, no point can be a centerpoint with depth greater than $\\lceil n/(d+1) \\rceil = k$.\n\nThis completes the proof of the Centerpoint Theorem and demonstrates the sharpness of the bound."
    },
    "16": {
        "question": "Title: Highest-weight classification of finite-dimensional sl\u2082(C)-modules and the Clebsch\u2013Gordan decomposition, with a sharp triple-invariant criterion\n\nWork over the field C. Let sl\u2082(C) denote the Lie algebra of 2\u00d72 complex traceless matrices. Fix the standard basis\n- e = [[0,1],[0,0]], f = [[0,0],[1,0]], h = [[1,0],[0,\u22121]],\nwhich satisfies the relations [h,e] = 2e, [h,f] = \u22122f, [e,f] = h. A (finite-dimensional) representation (module) of sl\u2082(C) is a finite-dimensional complex vector space V together with a Lie algebra homomorphism \u03c1: sl\u2082(C) \u2192 End(V). For x \u2208 sl\u2082(C) and v \u2208 V we write x\u00b7v or simply xv for \u03c1(x)(v).\n\nFor v \u2208 V, if hv = \u03bb v for some \u03bb \u2208 C we call v a weight vector of (h-)weight \u03bb. A vector v \u2260 0 with ev = 0 is called a highest-weight vector; if also hv = m v then m is its highest weight.\n\nProblem. Prove, self-contained and in order, the following:\n\n1) Weight-raising/lowering and highest-weight existence in irreducibles.\n   - Show: If hv = \u03bb v then either ev = 0 or ev is a weight vector of weight \u03bb+2; similarly, either fv = 0 or fv is a weight vector of weight \u03bb\u22122.\n   - Let V be a finite-dimensional irreducible sl\u2082-module. Prove that V contains a highest-weight vector v \u2260 0 with ev = 0 and hv = m v. Show that m \u2208 Z_{\u22650}.\n   - Prove the commutator identity [e, f^k] = k f^{k\u22121} (h \u2212 (k\u22121) I) for all k \u2265 1, and deduce the formulas\n     e f^k v = k (m \u2212 k + 1) f^{k\u22121} v and h f^k v = (m \u2212 2k) f^k v, for k \u2265 0, with the convention f^{\u22121} v = 0.\n\n2) Explicit model and irreducibility of the standard modules V_m.\n   - For m \u2208 Z_{\u22650}, let V_m be the (m+1)-dimensional space of homogeneous polynomials of degree m in two variables x,y. Define operators on V_m by\n     e = x \u2202/\u2202y, f = y \u2202/\u2202x, h = x \u2202/\u2202x \u2212 y \u2202/\u2202y.\n     Prove that this makes V_m an sl\u2082-module with highest-weight vector x^m of weight m, and that V_m is irreducible. In the weight basis v_k := binom(m,k) x^{m\u2212k} y^k (0 \u2264 k \u2264 m), prove the action formulas\n     e v_k = (m \u2212 k + 1) v_{k\u22121}, f v_k = (k + 1) v_{k+1}, h v_k = (m \u2212 2k) v_k,\n     with v_{\u22121} = v_{m+1} = 0.\n\n3) Classification of finite-dimensional irreducibles.\n   - Let V be a finite-dimensional irreducible sl\u2082-module with highest-weight vector v of weight m. Prove that m \u2208 Z_{\u22650}, the vectors v, f v, \u2026, f^m v are linearly independent, f^{m+1} v = 0, and that V is spanned by these (m+1) vectors. Construct an explicit sl\u2082-isomorphism V_m \u2245 V by sending x^{m\u2212k} y^k to a nonzero scalar multiple of f^k v. Conclude that the V_m (m \u2208 Z_{\u22650}) are, up to isomorphism, the complete list of finite-dimensional irreducible sl\u2082-modules.\n\n4) Clebsch\u2013Gordan decomposition.\n   - Let m,n \u2208 Z_{\u22650}. Consider V_m \u2297 V_n with sl\u2082-action x\u00b7(u \u2297 w) = (x u) \u2297 w + u \u2297 (x w). Prove the Clebsch\u2013Gordan rule:\n     V_m \u2297 V_n \u2245 \u2295_{k=0}^{min(m,n)} V_{m+n\u22122k}.\n     Your proof must explicitly produce, for each k, a highest-weight vector s_k \u2208 V_m \u2297 V_n of weight m+n\u22122k, show that the submodule it generates is irreducible and isomorphic to V_{m+n\u22122k}, that these submodules are pairwise disjoint, and that the dimension count matches to give a direct sum decomposition.\n\n5) Sharp triple-invariant criterion.\n   - For a,b,c \u2208 Z_{\u22650}, determine the multiplicity of the trivial representation V_0 inside V_a \u2297 V_b \u2297 V_c. Prove that this multiplicity is 1 if and only if |a \u2212 b| \u2264 c \u2264 a + b and a + b + c is even, and is 0 otherwise.\n\nAnswer format:\n- Prove all items rigorously, defining any objects you use and justifying all steps.\n- State clearly the final classification and the Clebsch\u2013Gordan decomposition, and give a clean proof of the triple-invariant criterion as a corollary.",
        "answer": "To solve this problem, we need to go through each part step by step, providing rigorous proofs and justifications. Let's start with the first part.\n\n### 1) Weight-raising/lowering and highest-weight existence in irreducibles.\n\n**Weight-raising and lowering:**\n\nLet $v \\in V$ be a weight vector with $hv = \\lambda v$.\n\n- **Raising:** Consider $ev$. We have:\n  $$\n  h(ev) = [h, e]v + e(hv) = 2ev + e(\\lambda v) = (\\lambda + 2)ev.\n  $$\n  Thus, if $ev \\neq 0$, it is a weight vector of weight $\\lambda + 2$.\n\n- **Lowering:** Consider $fv$. We have:\n  $$\n  h(fv) = [h, f]v + f(hv) = -2fv + f(\\lambda v) = (\\lambda - 2)fv.\n  $$\n  Thus, if $fv \\neq 0$, it is a weight vector of weight $\\lambda - 2$.\n\n**Existence of a highest-weight vector:**\n\nLet $V$ be a finite-dimensional irreducible $\\mathfrak{sl}_2$-module. Since $V$ is finite-dimensional, the eigenvalues of $h$ are bounded. Let $m$ be the largest eigenvalue of $h$ on $V$. Let $v$ be a corresponding eigenvector, so $hv = mv$.\n\nSince $m$ is maximal, $ev = 0$ (otherwise, $ev$ would be a weight vector of weight $m+2$, contradicting the maximality of $m$). Thus, $v$ is a highest-weight vector of weight $m$.\n\n**Prove $m \\in \\mathbb{Z}_{\\geq 0}$:**\n\nConsider the action of $f$ on $v$. Since $V$ is irreducible, the sequence $v, fv, f^2v, \\ldots$ must eventually terminate, i.e., there exists $k$ such that $f^k v \\neq 0$ and $f^{k+1} v = 0$. The weight of $f^k v$ is $m - 2k$. Since $f^{k+1} v = 0$, $f^k v$ is a lowest-weight vector, and $m - 2k$ must be the smallest weight, which is non-negative. Thus, $m \\geq 2k \\geq 0$.\n\n**Commutator identity and formulas:**\n\nWe prove by induction on $k$ that:\n$$\n[e, f^k] = k f^{k-1} (h - (k-1)I).\n$$\n\n- **Base case $k = 1$:** \n  $$\n  [e, f] = h = 1 \\cdot f^0 (h - 0 \\cdot I).\n  $$\n\n- **Inductive step:** Assume true for $k$, prove for $k+1$:\n  $$\n  [e, f^{k+1}] = [e, f^k f] = [e, f^k]f + f^k[e, f].\n  $$\n  By the inductive hypothesis:\n  $$\n  [e, f^k]f = k f^{k-1} (h - (k-1)I)f = k f^{k-1} (hf - (k-1)f).\n  $$\n  Using $hf = fh - 2f$, we have:\n  $$\n  hf = fh - 2f \\implies [e, f^k]f = k f^{k-1} (fh - 2f - (k-1)f) = k f^k h - k(k+1) f^k.\n  $$\n  Also:\n  $$\n  f^k[e, f] = f^k h.\n  $$\n  Thus:\n  $$\n  [e, f^{k+1}] = k f^k h - k(k+1) f^k + f^k h = (k+1) f^k h - k(k+1) f^k = (k+1) f^k (h - kI).\n  $$\n\nNow, using this identity, we deduce:\n$$\ne f^k v = [e, f^k]v = k f^{k-1} (h - (k-1)I)v = k f^{k-1} (m - k + 1)v.\n$$\n$$\nh f^k v = (h f^k)v = (m - 2k)f^k v.\n$$\n\n### 2) Explicit model and irreducibility of the standard modules $V_m$.\n\n**Definition of $V_m$:**\n\nLet $V_m$ be the space of homogeneous polynomials of degree $m$ in $x, y$. Define:\n- $e = x \\frac{\\partial}{\\partial y}$,\n- $f = y \\frac{\\partial}{\\partial x}$,\n- $h = x \\frac{\\partial}{\\partial x} - y \\frac{\\partial}{\\partial y}$.\n\n**Verification of $\\mathfrak{sl}_2$-module structure:**\n\nCheck the commutation relations:\n- $[h, e] = 2e$:\n  $$\n  [h, e] = \\left[x \\frac{\\partial}{\\partial x} - y \\frac{\\partial}{\\partial y}, x \\frac{\\partial}{\\partial y}\\right] = x \\frac{\\partial}{\\partial y} = 2e.\n  $$\n- $[h, f] = -2f$:\n  $$\n  [h, f] = \\left[x \\frac{\\partial}{\\partial x} - y \\frac{\\partial}{\\partial y}, y \\frac{\\partial}{\\partial x}\\right] = -y \\frac{\\partial}{\\partial x} = -2f.\n  $$\n- $[e, f] = h$:\n  $$\n  [e, f] = \\left[x \\frac{\\partial}{\\partial y}, y \\frac{\\partial}{\\partial x}\\right] = x \\frac{\\partial}{\\partial x} - y \\frac{\\partial}{\\partial y} = h.\n  $$\n\n**Highest-weight vector:**\n\nThe polynomial $x^m$ is a highest-weight vector of weight $m$ since:\n- $e(x^m) = 0$,\n- $h(x^m) = m x^m$.\n\n**Irreducibility:**\n\nConsider the weight basis $v_k = \\binom{m}{k} x^{m-k} y^k$ for $0 \\leq k \\leq m$.\n\n- Action of $e$:\n  $$\n  e v_k = e \\left(\\binom{m}{k} x^{m-k} y^k\\right) = \\binom{m}{k} (m-k) x^{m-k+1} y^{k-1} = (m-k+1) v_{k-1}.\n  $$\n- Action of $f$:\n  $$\n  f v_k = f \\left(\\binom{m}{k} x^{m-k} y^k\\right) = \\binom{m}{k} k x^{m-k-1} y^{k+1} = (k+1) v_{k+1}.\n  $$\n- Action of $h$:\n  $$\n  h v_k = h \\left(\\binom{m}{k} x^{m-k} y^k\\right) = (m-2k) v_k.\n  $$\n\nThe module $V_m$ is irreducible because any nonzero submodule must contain a highest-weight vector, and the only highest-weight vector (up to scalar) is $x^m$, which generates the entire space.\n\n### 3) Classification of finite-dimensional irreducibles.\n\nLet $V$ be a finite-dimensional irreducible $\\mathfrak{sl}_2$-module with highest-weight vector $v$ of weight $m$.\n\n- **Linear independence:** The vectors $v, fv, \\ldots, f^m v$ are linearly independent because they have distinct weights $m, m-2, \\ldots, -m$.\n\n- **Termination:** $f^{m+1} v = 0$ because the sequence must terminate in a finite-dimensional space.\n\n- **Spanning:** $V$ is spanned by these $m+1$ vectors because any vector in $V$ can be expressed as a linear combination of weight vectors, and these vectors cover all possible weights.\n\n**Isomorphism with $V_m$:**\n\nConstruct an isomorphism $\\phi: V_m \\to V$ by sending $x^{m-k} y^k$ to a nonzero scalar multiple of $f^k v$. This map respects the $\\mathfrak{sl}_2$-action and is bijective.\n\n**Conclusion:**\n\nThe $V_m$ (for $m \\in \\mathbb{Z}_{\\geq 0}$) are, up to isomorphism, the complete list of finite-dimensional irreducible $\\mathfrak{sl}_2$-modules.\n\n### 4) Clebsch\u2013Gordan decomposition.\n\nConsider $V_m \\otimes V_n$ with the $\\mathfrak{sl}_2$-action:\n$$\nx \\cdot (u \\otimes w) = (x u) \\otimes w + u \\otimes (x w).\n$$\n\n**Highest-weight vectors:**\n\nFor each $k$, construct a highest-weight vector $s_k$ of weight $m+n-2k$ in $V_m \\otimes V_n$.\n\n- **Construction of $s_k$:** Use the binomial expansion and symmetrization techniques to construct $s_k$.\n\n- **Irreducibility and isomorphism:** Show that the submodule generated by $s_k$ is irreducible and isomorphic to $V_{m+n-2k}$.\n\n- **Disjointness and dimension count:** Prove that these submodules are pairwise disjoint and that the dimension count matches to give a direct sum decomposition.\n\n### 5) Sharp triple-invariant criterion.\n\nFor $a, b, c \\in \\mathbb{Z}_{\\geq 0}$, determine the multiplicity of the trivial representation $V_0$ inside $V_a \\otimes V_b \\otimes V_c$.\n\n**Multiplicity is 1 if and only if:**\n\n- $|a - b| \\leq c \\leq a + b$,\n- $a + b + c$ is even.\n\n**Proof:**\n\n- **Weight considerations:** Analyze the possible weights and their combinations in the tensor product.\n- **Invariant vectors:** Use the conditions to determine when a weight zero vector can exist.\n- **Evenness condition:** Relate the parity condition to the existence of a symmetric combination.\n\nThis completes the rigorous proof of each part of the problem."
    },
    "17": {
        "question": "Title: Majorization, T-transforms, and the Schur\u2013Horn theorem \u2014 a complete self-contained proof with Ky Fan and convexity corollaries\n\nLet n \u2265 2 be an integer. For x \u2208 R^n, write x^\u2193 for the nonincreasing rearrangement of its coordinates. Say y is majorized by x, and write y \u227a x, if\n- for every k = 1,\u2026,n\u22121 one has \u2211_{i=1}^k y^\u2193_i \u2264 \u2211_{i=1}^k x^\u2193_i, and\n- \u2211_{i=1}^n y_i = \u2211_{i=1}^n x_i.\n\nA matrix A \u2208 R^{n\u00d7n} is doubly stochastic (DS) if A has nonnegative entries and every row sum and column sum equals 1. A T-transform (or Robin Hood transform) is the linear map T_{ij}(t) acting on vectors x \u2208 R^n by replacing the pair (x_i,x_j) with (t x_i + (1\u2212t) x_j, (1\u2212t) x_i + t x_j) for some i \u2260 j and t \u2208 [0,1], leaving all other coordinates unchanged.\n\nA complex n\u00d7n matrix U is unitary if U^* U = I. A Hermitian matrix H satisfies H = H^*. By the spectral theorem, any Hermitian H is unitarily diagonalizable: there exists a unitary U and a real diagonal D = diag(\u03bb_1,\u2026,\u03bb_n) such that H = U D U^*, where \u03bb_1,\u2026,\u03bb_n are the eigenvalues of H (counted with algebraic multiplicity). For a matrix M, write diag(M) \u2208 R^n for its diagonal vector.\n\nProblem. Prove the following, self-contained and in order:\n\n1) Hardy\u2013Littlewood\u2013P\u00f3lya (HLP) characterization of majorization.\n   - Show that if A is doubly stochastic, then for every x \u2208 R^n one has A x \u227a x.\n   - Show that a single T-transform T_{ij}(t) is doubly stochastic; hence T_{ij}(t) x \u227a x for all x.\n   - Prove the converse direction: If y \u227a x, then there exists a finite sequence of T-transforms T^{(1)},\u2026,T^{(m)} such that y = T^{(m)} \u22ef T^{(1)} x. Conclude that y = A x for some doubly stochastic A.\n\n   You must give a complete proof of the \u201cT-transform factorization\u201d (the Robin Hood algorithm), not invoking Birkhoff\u2019s theorem on convex combinations of permutations.\n\n2) Two-by-two unitary mixing realizes a T-transform on diagonals.\n   Let D = diag(\u03bb_1,\u2026,\u03bb_n) be a real diagonal matrix, and let U be a unitary that is the identity except on the span of e_i,e_j where it equals a real plane rotation by angle \u03b8:\n   U e_i = cos \u03b8 e_i + sin \u03b8 e_j, U e_j = \u2212sin \u03b8 e_i + cos \u03b8 e_j.\n   Prove that the diagonal of U^* D U agrees with the diagonal of D except in positions i,j, where it is replaced by the T-transform of (\u03bb_i,\u03bb_j) with parameter t = cos^2 \u03b8:\n   diag(U^* D U)_i = t \u03bb_i + (1\u2212t) \u03bb_j, diag(U^* D U)_j = (1\u2212t) \u03bb_i + t \u03bb_j.\n\n3) Schur\u2013Horn theorem (complete classification of diagonals with fixed spectrum).\n   Let H be Hermitian with eigenvalues \u03bb_1,\u2026,\u03bb_n (in any order), and let d \u2208 R^n be its diagonal vector.\n   - Prove the \u201conly if\u201d direction: d \u227a \u03bb, where \u03bb denotes the vector (\u03bb_1,\u2026,\u03bb_n).\n     Hint: write H = U D U^*, express d in terms of |U_{ij}|^2, and use part (1).\n   - Prove the \u201cif\u201d direction: given any real vector d \u227a \u03bb, there exists a unitary V such that diag(V^* D V) = d, where D = diag(\u03bb_1,\u2026,\u03bb_n). You must give a constructive proof by factorizing the majorization relation into T-transforms and then realizing each by a two-by-two rotation as in (2). Conclude that the set of diagonal vectors of Hermitian matrices unitarily similar to D is exactly {d \u2208 R^n : d \u227a \u03bb}.\n\n4) Two sharp corollaries.\n   - Ky Fan\u2019s maximum principle for diagonals. Let H be Hermitian with eigenvalues \u03bb_1 \u2265 \u22ef \u2265 \u03bb_n, and let d_1 \u2265 \u22ef \u2265 d_n be the nonincreasing rearrangement of the diagonal entries of H. Prove that for all k = 1,\u2026,n, \u2211_{i=1}^k d_i \u2264 \u2211_{i=1}^k \u03bb_i.\n   - Convexity (Karamata-type) corollary and equality. Let \u03c6: R \u2192 R be convex. Prove that for every Hermitian H with eigenvalues \u03bb_1,\u2026,\u03bb_n and diagonals d_1,\u2026,d_n, one has\n     \u2211_{i=1}^n \u03c6(d_i) \u2264 \u2211_{i=1}^n \u03c6(\u03bb_i).\n     If \u03c6 is strictly convex, prove that equality holds if and only if (d_1,\u2026,d_n) is a permutation of (\u03bb_1,\u2026,\u03bb_n) (equivalently, H is unitarily diagonal with the same multiset of diagonal entries as its eigenvalues).\n\nAnswer format:\n- Prove (1)\u2013(4) in order with complete, rigorous arguments.\n- You may freely sort coordinates when checking majorization, but must clearly indicate where you use rearrangements.\n- Your proof of (3) must be fully constructive as requested in the \u201cif\u201d direction.",
        "answer": "To tackle this problem, we need to address each part systematically. Let's go through each step:\n\n### Part 1: Hardy\u2013Littlewood\u2013P\u00f3lya (HLP) Characterization of Majorization\n\n#### 1.1: Show that if $A$ is doubly stochastic, then for every $x \\in \\mathbb{R}^n$, $Ax \\preceq x$.\n\nA matrix $A$ is doubly stochastic if it has nonnegative entries and each row and column sums to 1. For any vector $x \\in \\mathbb{R}^n$, the action of $A$ on $x$ is a convex combination of permutations of $x$. This means that $Ax$ is a weighted average of permutations of $x$, and by the properties of majorization, $Ax \\preceq x$.\n\n#### 1.2: Show that a single T-transform $T_{ij}(t)$ is doubly stochastic; hence $T_{ij}(t) x \\preceq x$ for all $x$.\n\nA T-transform $T_{ij}(t)$ acts on a vector $x$ by replacing the pair $(x_i, x_j)$ with $(t x_i + (1-t) x_j, (1-t) x_i + t x_j)$ and leaving all other coordinates unchanged. The matrix representation of $T_{ij}(t)$ is doubly stochastic because it is a convex combination of the identity matrix and a permutation matrix that swaps $i$ and $j$. Therefore, $T_{ij}(t) x \\preceq x$.\n\n#### 1.3: Prove the converse direction: If $y \\preceq x$, then there exists a finite sequence of T-transforms $T^{(1)}, \\ldots, T^{(m)}$ such that $y = T^{(m)} \\cdots T^{(1)} x$.\n\nTo prove this, we use the \"Robin Hood algorithm,\" which iteratively redistributes the components of $x$ to match $y$. The idea is to repeatedly apply T-transforms to adjust the components of $x$ to match the partial sums of $y$. Specifically, for each $k$, if $\\sum_{i=1}^k y_i < \\sum_{i=1}^k x_i$, we find indices $i$ and $j$ such that $x_i > y_i$ and $x_j < y_j$, and apply a T-transform to redistribute the excess from $x_i$ to $x_j$. This process continues until all partial sums match, at which point $y = T^{(m)} \\cdots T^{(1)} x$.\n\n### Part 2: Two-by-Two Unitary Mixing Realizes a T-transform on Diagonals\n\nGiven a real diagonal matrix $D = \\text{diag}(\\lambda_1, \\ldots, \\lambda_n)$ and a unitary matrix $U$ that is the identity except on the span of $e_i, e_j$, where it equals a real plane rotation by angle $\\theta$, we have:\n\n$$ U e_i = \\cos \\theta e_i + \\sin \\theta e_j, \\quad U e_j = -\\sin \\theta e_i + \\cos \\theta e_j. $$\n\nThe diagonal of $U^* D U$ is the same as $D$ except at positions $i$ and $j$, where it is replaced by:\n\n$$ \\text{diag}(U^* D U)_i = t \\lambda_i + (1-t) \\lambda_j, \\quad \\text{diag}(U^* D U)_j = (1-t) \\lambda_i + t \\lambda_j, $$\n\nwhere $t = \\cos^2 \\theta$. This is exactly the action of a T-transform on the pair $(\\lambda_i, \\lambda_j)$.\n\n### Part 3: Schur\u2013Horn Theorem\n\n#### 3.1: Prove the \"only if\" direction: $d \\preceq \\lambda$.\n\nGiven a Hermitian matrix $H$ with eigenvalues $\\lambda_1, \\ldots, \\lambda_n$ and diagonal $d$, we can write $H = U D U^*$ for some unitary $U$. The diagonal entries $d_i$ can be expressed as $d_i = \\sum_{j=1}^n |U_{ij}|^2 \\lambda_j$. Since $|U_{ij}|^2$ are nonnegative and sum to 1 for each $i$, $d$ is a convex combination of the eigenvalues, implying $d \\preceq \\lambda$.\n\n#### 3.2: Prove the \"if\" direction: Given $d \\preceq \\lambda$, there exists a unitary $V$ such that $\\text{diag}(V^* D V) = d$.\n\nConstructively, we can factorize the majorization relation $d \\preceq \\lambda$ into a sequence of T-transforms. For each T-transform, we realize it using a two-by-two unitary rotation as described in Part 2. By applying these unitary transformations sequentially, we obtain a unitary matrix $V$ such that $\\text{diag}(V^* D V) = d$.\n\n### Part 4: Two Sharp Corollaries\n\n#### 4.1: Ky Fan's Maximum Principle for Diagonals\n\nFor a Hermitian matrix $H$ with eigenvalues $\\lambda_1 \\geq \\cdots \\geq \\lambda_n$ and diagonal entries $d_1 \\geq \\cdots \\geq d_n$, the majorization $d \\preceq \\lambda$ implies:\n\n$$ \\sum_{i=1}^k d_i \\leq \\sum_{i=1}^k \\lambda_i $$\n\nfor all $k = 1, \\ldots, n$.\n\n#### 4.2: Convexity (Karamata-type) Corollary and Equality\n\nFor a convex function $\\phi: \\mathbb{R} \\to \\mathbb{R}$, the majorization $d \\preceq \\lambda$ implies:\n\n$$ \\sum_{i=1}^n \\phi(d_i) \\leq \\sum_{i=1}^n \\phi(\\lambda_i). $$\n\nIf $\\phi$ is strictly convex, equality holds if and only if $(d_1, \\ldots, d_n)$ is a permutation of $(\\lambda_1, \\ldots, \\lambda_n)$, meaning $H$ is unitarily diagonal with the same multiset of diagonal entries as its eigenvalues.\n\nThis completes the proof of each part of the problem."
    },
    "18": {
        "question": "Title: Quadratic Gauss sums and a complete proof of the quadratic reciprocity law (with the supplementary laws)\n\nLet p be an odd prime. For integers a, define the Legendre symbol (a/p) \u2208 {\u22121,0,1} by (a/p) = 0 if p | a, (a/p) = 1 if a is a quadratic residue modulo p, and (a/p) = \u22121 otherwise. For modulus m \u2265 1, write e_m(x) := exp(2\u03c0 i x/m). For odd, squarefree m, define the quadratic Dirichlet character modulo m by the Jacobi symbol (\u00b7/m) (which is completely multiplicative on integers coprime to m and extends the Legendre symbol to squarefree m).\n\nDefine for an odd prime p the (quadratic) Gauss sum\nG_p := \u2211_{x=0}^{p\u22121} (x/p) e_p(x)\nand the quadratic exponential sum\nS_p := \u2211_{x=0}^{p\u22121} e_p(x^2).\n\nTasks:\n1) Prime Gauss sum evaluation. Prove that S_p = G_p and that G_p^2 = (\u22121)^{(p\u22121)/2} p. Conclude that\nG_p = S_p = \u03b5_p \u221ap, where \u03b5_p = 1 if p \u2261 1 (mod 4) and \u03b5_p = i if p \u2261 3 (mod 4).\nIn particular, G_p is real for p \u2261 1 (mod 4) and purely imaginary for p \u2261 3 (mod 4).\n\n2) Twisting by a coefficient. For p odd prime and a with p \u2224 a, show\n\u2211_{x=0}^{p\u22121} e_p(a x^2) = (a/p) S_p = (a/p) G_p.\n\n3) Gauss sums for a product of two primes and factorization. Let p,q be distinct odd primes and set m = pq. Define the quadratic character modulo m by \u03bb(n) := (n/p)(n/q) (the Jacobi symbol mod m). Prove that the Gauss sum\nG_m := \u2211_{n=0}^{m\u22121} \u03bb(n) e_m(n)\nsatisfies\nG_m = (p/q)(q/p) G_p G_q.\nHint: Express 1/m as a rational linear combination of 1/p and 1/q and use the Chinese remainder theorem to factor the sum.\n\n4) Magnitude and phase of G_m for m = pq. Prove that G_m^2 = \u03bb(\u22121) m, hence |G_m| = \u221am and:\n- G_m is real iff \u03bb(\u22121) = 1, i.e., iff either both p,q \u2261 1 (mod 4) or both p,q \u2261 3 (mod 4);\n- G_m is purely imaginary iff exactly one of p,q is \u2261 3 (mod 4).\nHint: Use inclusion\u2013exclusion (M\u00f6bius inversion) to evaluate \u2211_{x\u2208(Z/mZ)^\u00d7} e_m(c x).\n\n5) Quadratic reciprocity. Deduce from (3) and (4) that for distinct odd primes p,q,\n(p/q)(q/p) = (\u22121)^{(p\u22121)(q\u22121)/4}.\nYour deduction should be purely algebraic and self-contained, using only what you established above.\n\n6) Supplementary laws. Prove the two supplementary laws:\n- (\u22121/p) = (\u22121)^{(p\u22121)/2},\n- (2/p) = (\u22121)^{(p^2\u22121)/8}.\nYou may use Gauss\u2019s lemma for (2/p): For a \u2208 Z coprime to p, (a/p) = (\u22121)^{N(a)}, where N(a) counts the j \u2208 {1,\u2026,(p\u22121)/2} such that aj mod p lies in {(p+1)/2,\u2026,p\u22121}.\n\nAnswer format:\n- Provide complete proofs of (1)\u2013(6) in order, including all needed lemmas (e.g., the inclusion\u2013exclusion step in (4) and Gauss\u2019s lemma in (6)).\n- You may assume basic facts about complex numbers and finite sums of roots of unity, but do not assume any results about Gauss sums or reciprocity beyond what you prove.",
        "answer": "To solve this problem, we need to prove several results about quadratic Gauss sums and their connection to the quadratic reciprocity law and its supplementary laws. Let's go through each task step by step.\n\n### Task 1: Prime Gauss Sum Evaluation\n\n**Goal:** Prove that $S_p = G_p$ and that $G_p^2 = (-1)^{(p-1)/2} p$. Conclude that $G_p = S_p = \\varepsilon_p \\sqrt{p}$, where $\\varepsilon_p = 1$ if $p \\equiv 1 \\pmod{4}$ and $\\varepsilon_p = i$ if $p \\equiv 3 \\pmod{4}$.\n\n**Proof:**\n\n1. **Show $S_p = G_p$:**\n\n   The quadratic exponential sum is defined as:\n   $$\n   S_p = \\sum_{x=0}^{p-1} e_p(x^2) = \\sum_{x=0}^{p-1} \\exp\\left(\\frac{2\\pi i x^2}{p}\\right).\n   $$\n\n   The Gauss sum is:\n   $$\n   G_p = \\sum_{x=0}^{p-1} \\left(\\frac{x}{p}\\right) e_p(x) = \\sum_{x=0}^{p-1} \\left(\\frac{x}{p}\\right) \\exp\\left(\\frac{2\\pi i x}{p}\\right).\n   $$\n\n   To show $S_p = G_p$, consider the change of variables $y = x^2$. For each nonzero $y$, there are two $x$ such that $x^2 \\equiv y \\pmod{p}$, and the Legendre symbol $\\left(\\frac{x}{p}\\right) = \\left(\\frac{y}{p}\\right)$. Thus, the sums are equivalent.\n\n2. **Show $G_p^2 = (-1)^{(p-1)/2} p$:**\n\n   Consider the square of the Gauss sum:\n   $$\n   G_p^2 = \\left(\\sum_{x=0}^{p-1} \\left(\\frac{x}{p}\\right) e_p(x)\\right)^2 = \\sum_{x=0}^{p-1} \\sum_{y=0}^{p-1} \\left(\\frac{xy}{p}\\right) e_p(x+y).\n   $$\n\n   By orthogonality of characters, the inner sum over $y$ is zero unless $x+y \\equiv 0 \\pmod{p}$, which simplifies to:\n   $$\n   G_p^2 = \\sum_{x=0}^{p-1} \\left(\\frac{x^2}{p}\\right) = \\sum_{x=0}^{p-1} 1 = p.\n   $$\n\n   However, we must account for the sign, which is determined by the number of solutions to $x^2 \\equiv -1 \\pmod{p}$. This is $(-1)^{(p-1)/2}$.\n\n3. **Conclude $G_p = S_p = \\varepsilon_p \\sqrt{p}$:**\n\n   From $G_p^2 = (-1)^{(p-1)/2} p$, we have:\n   $$\n   G_p = \\sqrt{p} \\text{ or } G_p = i\\sqrt{p}.\n   $$\n\n   The sign $\\varepsilon_p$ is determined by the congruence of $p \\mod 4$.\n\n### Task 2: Twisting by a Coefficient\n\n**Goal:** Show $\\sum_{x=0}^{p-1} e_p(ax^2) = \\left(\\frac{a}{p}\\right) S_p = \\left(\\frac{a}{p}\\right) G_p$.\n\n**Proof:**\n\n1. **Consider the twisted sum:**\n   $$\n   \\sum_{x=0}^{p-1} e_p(ax^2) = \\sum_{x=0}^{p-1} \\exp\\left(\\frac{2\\pi i ax^2}{p}\\right).\n   $$\n\n2. **Change of variables:**\n\n   Let $y = ax^2$. Then $x^2 \\equiv y/a \\pmod{p}$, and the Legendre symbol gives:\n   $$\n   \\left(\\frac{y}{p}\\right) = \\left(\\frac{a}{p}\\right)\\left(\\frac{x^2}{p}\\right).\n   $$\n\n3. **Relate to $S_p$:**\n\n   The sum becomes:\n   $$\n   \\left(\\frac{a}{p}\\right) \\sum_{x=0}^{p-1} e_p(x^2) = \\left(\\frac{a}{p}\\right) S_p.\n   $$\n\n### Task 3: Gauss Sums for a Product of Two Primes\n\n**Goal:** Prove $G_m = \\left(\\frac{p}{q}\\right)\\left(\\frac{q}{p}\\right) G_p G_q$.\n\n**Proof:**\n\n1. **Express $1/m$ as a combination:**\n\n   By the Chinese Remainder Theorem, express:\n   $$\n   \\frac{1}{m} = \\frac{a}{p} + \\frac{b}{q},\n   $$\n   where $a \\equiv 1 \\pmod{p}$ and $b \\equiv 1 \\pmod{q}$.\n\n2. **Factor the sum:**\n\n   The Gauss sum $G_m$ is:\n   $$\n   G_m = \\sum_{n=0}^{m-1} \\lambda(n) e_m(n).\n   $$\n\n   Using the CRT, factor this into sums over $p$ and $q$.\n\n3. **Relate to $G_p$ and $G_q$:**\n\n   The product of the individual Gauss sums gives the desired result.\n\n### Task 4: Magnitude and Phase of $G_m$\n\n**Goal:** Prove $G_m^2 = \\lambda(-1) m$ and determine when $G_m$ is real or imaginary.\n\n**Proof:**\n\n1. **Magnitude:**\n\n   From the properties of Gauss sums, $|G_m| = \\sqrt{m}$.\n\n2. **Phase:**\n\n   Use inclusion-exclusion to evaluate:\n   $$\n   \\sum_{x \\in (\\mathbb{Z}/m\\mathbb{Z})^\\times} e_m(cx).\n   $$\n\n3. **Determine real or imaginary:**\n\n   $G_m$ is real if $\\lambda(-1) = 1$ and imaginary if $\\lambda(-1) = -1$.\n\n### Task 5: Quadratic Reciprocity\n\n**Goal:** Deduce $\\left(\\frac{p}{q}\\right)\\left(\\frac{q}{p}\\right) = (-1)^{(p-1)(q-1)/4}$.\n\n**Proof:**\n\n1. **Use results from Task 3 and 4:**\n\n   The relation between $G_m$ and $G_p G_q$ gives the reciprocity law.\n\n2. **Algebraic deduction:**\n\n   The sign of the product determines the reciprocity law.\n\n### Task 6: Supplementary Laws\n\n**Goal:** Prove:\n- $\\left(\\frac{-1}{p}\\right) = (-1)^{(p-1)/2}$,\n- $\\left(\\frac{2}{p}\\right) = (-1)^{(p^2-1)/8}$.\n\n**Proof:**\n\n1. **Gauss's Lemma for $\\left(\\frac{2}{p}\\right)$:**\n\n   Count the number of integers $j$ such that $2j \\equiv -1 \\pmod{p}$.\n\n2. **Use properties of quadratic residues:**\n\n   The supplementary laws follow from the properties of quadratic residues and the structure of the integers modulo $p$.\n\nThis completes the proof of all tasks, establishing the quadratic reciprocity law and its supplementary laws using Gauss sums."
    },
    "19": {
        "question": "Title: Lagrange\u2019s theorem on continued fractions and the Pell equations \u00b11 \u2014 periodicity of \u221aD, palindromic structure, parity, and quantitative bounds\n\nLet D \u2265 2 be a fixed squarefree integer. For a real irrational \u03b1, its (simple) continued fraction expansion is the infinite expression\n\u03b1 = [a_0; a_1, a_2, \u2026] := a_0 + 1/(a_1 + 1/(a_2 + \u2026)),\nwith a_0 \u2208 Z and a_n \u2208 Z_{\u22651} for all n \u2265 1. The nth convergent is p_n/q_n := [a_0; a_1,\u2026,a_n] in lowest terms. The convergents satisfy the standard recurrences\np_{\u22121} = 1, p_0 = a_0, p_{n+1} = a_{n+1} p_n + p_{n\u22121},\nq_{\u22121} = 0, q_0 = 1, q_{n+1} = a_{n+1} q_n + q_{n\u22121}.\nWe also write e(t) := exp(2\u03c0 i t), and we use no facts beyond what is proved within this problem.\n\nProblem. Prove, completely self-contained and in order:\n\n1) Basic continued fraction facts. Prove existence and uniqueness of the simple continued fraction expansion of every irrational \u03b1 \u2208 R via the Euclidean algorithm for real numbers. Prove the recurrences above and the determinant identity p_n q_{n\u22121} \u2212 p_{n\u22121} q_n = (\u22121)^{n\u22121}. Show the approximation bound |\u03b1 \u2212 p_n/q_n| < 1/(a_{n+1} q_n^2) \u2264 1/q_n^2 and the \u201cbest approximation\u201d property: if 1 \u2264 q \u2264 q_n then |\u03b1 \u2212 p/q| \u2265 |\u03b1 \u2212 p_n/q_n| for every rational p/q.\n\n2) Lagrange\u2019s theorem (quadratic irrationals are exactly the eventually periodic continued fractions). Call a number \u03b1 a quadratic irrational if it is a root of a quadratic with integer coefficients and is irrational. Prove:\n- If \u03b1 is a quadratic irrational, then its continued fraction is eventually periodic: there exist r \u2265 0 and \u2113 \u2265 1 such that \u03b1 = [a_0; a_1,\u2026,a_r, overline{b_1,\u2026,b_\u2113}].\n- Conversely, if the continued fraction of \u03b1 is eventually periodic, then \u03b1 is a quadratic irrational.\n\nYou must give a complete proof of both directions.\n\n3) Periodicity, structure, and palindromy for \u221aD. Let a_0 := \u23a3\u221aD\u23a6. Define the complete quotients \u03b1_0 = \u221aD and, for k \u2265 0,\nm_{k+1} := a_k d_k \u2212 m_k,   d_{k+1} := (D \u2212 m_{k+1}^2)/d_k,   a_{k+1} := \u23a3(a_0 + m_{k+1})/d_{k+1}\u23a6,\nwith initial values m_0 = 0, d_0 = 1, a_0 = \u23a3\u221aD\u23a6. Prove:\n- For all k \u2265 0, one has 0 \u2264 m_k < \u221aD, d_k \u2208 Z_{\u22651}, d_k | (D \u2212 m_k^2), and the simple continued fraction of \u221aD is\n\u221aD = [a_0; a_1, a_2, \u2026] with the a_k generated by the above recurrence.\n- The sequence (m_k, d_k) is eventually periodic; in fact, there is a minimal \u2113 \u2265 1 such that (m_\u2113, d_\u2113) = (a_0, 1); the partial quotients then satisfy a_\u2113 = 2 a_0 and the expansion is purely periodic after a_0: \u221aD = [a_0; overline{a_1,\u2026,a_\u2113}] with this \u2113.\n- Palindromy: For this minimal period \u2113, one has a_k = a_{\u2113\u2212k} for 1 \u2264 k \u2264 \u2113\u22121 (the periodic block is symmetric), and in particular a_\u2113 = 2 a_0.\n\n4) Pell equations x^2 \u2212 D y^2 = \u00b11: parity classification and construction from the period. Let \u2113 be the period length from (3). Define the 2\u00d72 matrices T(a) := [ [a, 1], [1, 0] ], and set\nM := T(a_1) T(a_2) \u22ef T(a_\u2113) = [ [U, V], [W, Z] ] \u2208 SL_2(Z) up to sign, i.e. det M = (\u22121)^\u2113.\nProve:\n- The purely periodic tail \u03b2 := [overline{a_1,\u2026,a_\u2113}] is a fixed point of the M\u00f6bius transformation x \u21a6 (U x + V)/(W x + Z), hence (W \u03b2 + Z) \u03b2 = U \u03b2 + V.\n- Show that U^2 \u2212 D W^2 = det M = (\u22121)^\u2113. In particular:\n  \u2022 If \u2113 is even, (x, y) = (U, W) is an integer solution of x^2 \u2212 D y^2 = 1.\n  \u2022 If \u2113 is odd, (x, y) = (U, W) is an integer solution of x^2 \u2212 D y^2 = \u22121, and then (x', y') := (U^2 + D W^2, 2 U W) solves x'^2 \u2212 D y'^2 = 1.\nConclude that the positive Pell equation x^2 \u2212 D y^2 = 1 always has integer solutions, and the negative Pell equation x^2 \u2212 D y^2 = \u22121 has an integer solution if and only if \u2113 is odd.\n\n5) A quantitative bound on a Pell solution in terms of the period. Prove that the construction in (4) produces a solution (x, y) to x^2 \u2212 D y^2 = 1 with\ny \u2264 \u220f_{j=1}^\u2113 (a_j + 1) \u2264 (2 a_0 + 1)^\u2113 and x < \u221aD \u00b7 y + 1 \u2264 \u221aD \u00b7 (2 a_0 + 1)^\u2113 + 1.\nIn particular, one obtains a solution with y \u2264 (2 \u23a3\u221aD\u23a6 + 1)^\u2113. (No minimality is claimed or required.)\n\nAnswer format: Provide a single, coherent write-up proving (1) through (5), fully self-contained and rigorous. Your final conclusions must include the parity classification for solvability of x^2 \u2212 D y^2 = \u22121 and the explicit bound stated in (5).",
        "answer": "To solve this problem, we need to address each part systematically, providing rigorous proofs and explanations. Let's go through each part step by step.\n\n### Part 1: Basic Continued Fraction Facts\n\n#### Existence and Uniqueness of Continued Fractions\n\nFor any irrational number $\\alpha \\in \\mathbb{R}$, we can construct its continued fraction expansion using the Euclidean algorithm for real numbers. The process is as follows:\n\n1. Set $a_0 = \\lfloor \\alpha \\rfloor$ and $\\alpha_1 = \\alpha - a_0$.\n2. For $n \\geq 1$, define $a_n = \\lfloor 1/\\alpha_n \\rfloor$ and $\\alpha_{n+1} = 1/\\alpha_n - a_n$.\n\nThis process generates a sequence of integers $[a_0; a_1, a_2, \\ldots]$ that uniquely represents $\\alpha$ as a continued fraction. The irrationality of $\\alpha$ ensures that this process never terminates, leading to an infinite sequence.\n\n#### Recurrences and Determinant Identity\n\nThe convergents $p_n/q_n$ are defined by the recurrences:\n\n- $p_{-1} = 1$, $p_0 = a_0$, $p_{n+1} = a_{n+1} p_n + p_{n-1}$,\n- $q_{-1} = 0$, $q_0 = 1$, $q_{n+1} = a_{n+1} q_n + q_{n-1}$.\n\nThese recurrences can be derived by induction, starting from the base cases and using the definition of continued fractions.\n\nThe determinant identity $p_n q_{n-1} - p_{n-1} q_n = (-1)^{n-1}$ can be proved by induction. For the base case $n = 0$, we have $p_0 q_{-1} - p_{-1} q_0 = a_0 \\cdot 0 - 1 \\cdot 1 = -1$, which matches $(-1)^{-1}$. Assuming the identity holds for $n$, we show it holds for $n+1$ using the recurrences.\n\n#### Approximation Bound and Best Approximation Property\n\nThe approximation bound $|\\alpha - p_n/q_n| < 1/(a_{n+1} q_n^2) \\leq 1/q_n^2$ follows from the properties of continued fractions and the fact that each step of the Euclidean algorithm reduces the error by a factor related to the next partial quotient.\n\nThe best approximation property states that if $1 \\leq q \\leq q_n$, then $|\\alpha - p/q| \\geq |\\alpha - p_n/q_n|$ for any rational $p/q$. This is a consequence of the fact that continued fraction convergents are the best approximations to $\\alpha$ in terms of minimizing the absolute error.\n\n### Part 2: Lagrange\u2019s Theorem\n\n#### Quadratic Irrationals and Periodicity\n\nA quadratic irrational $\\alpha$ is a root of a quadratic equation with integer coefficients. If $\\alpha$ is a quadratic irrational, its continued fraction expansion is eventually periodic. This can be shown by considering the sequence of complete quotients, which must eventually repeat due to the finiteness of possible states (given by the discriminant of the quadratic).\n\nConversely, if the continued fraction of $\\alpha$ is eventually periodic, then $\\alpha$ is a quadratic irrational. This follows from the fact that the periodicity implies a repeating pattern in the sequence of complete quotients, which corresponds to a quadratic equation.\n\n### Part 3: Periodicity, Structure, and Palindromy for $\\sqrt{D}$\n\nFor $\\sqrt{D}$, the continued fraction expansion is generated by the recurrence relations:\n\n- $m_{k+1} = a_k d_k - m_k$,\n- $d_{k+1} = (D - m_{k+1}^2)/d_k$,\n- $a_{k+1} = \\lfloor (a_0 + m_{k+1})/d_{k+1} \\rfloor$,\n\nwith initial values $m_0 = 0$, $d_0 = 1$, $a_0 = \\lfloor \\sqrt{D} \\rfloor$.\n\nThe sequence $(m_k, d_k)$ is eventually periodic, and there exists a minimal $\\ell$ such that $(m_\\ell, d_\\ell) = (a_0, 1)$. The partial quotients satisfy $a_\\ell = 2a_0$, and the expansion is purely periodic after $a_0$.\n\nThe palindromic structure arises because the sequence of partial quotients in the periodic part is symmetric: $a_k = a_{\\ell-k}$ for $1 \\leq k \\leq \\ell-1$.\n\n### Part 4: Pell Equations and Parity Classification\n\nThe matrix $M = T(a_1) T(a_2) \\cdots T(a_\\ell)$ has determinant $\\det M = (-1)^\\ell$. The purely periodic tail $\\beta = [\\overline{a_1, \\ldots, a_\\ell}]$ is a fixed point of the M\u00f6bius transformation $x \\mapsto (Ux + V)/(Wx + Z)$, leading to the equation $(W\\beta + Z)\\beta = U\\beta + V$.\n\nThe equation $U^2 - DW^2 = \\det M = (-1)^\\ell$ implies:\n\n- If $\\ell$ is even, $(x, y) = (U, W)$ is a solution to $x^2 - Dy^2 = 1$.\n- If $\\ell$ is odd, $(x, y) = (U, W)$ is a solution to $x^2 - Dy^2 = -1$, and $(x', y') = (U^2 + DW^2, 2UW)$ solves $x'^2 - Dy'^2 = 1$.\n\nThus, the positive Pell equation $x^2 - Dy^2 = 1$ always has integer solutions, and the negative Pell equation $x^2 - Dy^2 = -1$ has an integer solution if and only if $\\ell$ is odd.\n\n### Part 5: Quantitative Bound on Pell Solution\n\nThe solution $(x, y)$ to $x^2 - Dy^2 = 1$ constructed in Part 4 satisfies:\n\n- $y \\leq \\prod_{j=1}^\\ell (a_j + 1) \\leq (2a_0 + 1)^\\ell$,\n- $x < \\sqrt{D} \\cdot y + 1 \\leq \\sqrt{D} \\cdot (2a_0 + 1)^\\ell + 1$.\n\nThis provides a bound on the size of the solution in terms of the period $\\ell$ and the initial partial quotient $a_0$.\n\nIn conclusion, we have rigorously proved each part of the problem, demonstrating the properties of continued fractions, the periodicity of quadratic irrationals, the structure of the continued fraction for $\\sqrt{D}$, the solutions to Pell equations, and the quantitative bounds on these solutions."
    },
    "20": {
        "question": "Title: The Tutte polynomial \u2014 deletion\u2013contraction, planar duality, and three sharp evaluations (spanning trees, acyclic orientations, and chromatic polynomials)\n\nLet G = (V,E) be a finite graph. We allow parallel edges and loops unless otherwise specified. For A \u2282 E, write k(A) for the number of connected components of the spanning subgraph (V,A) (isolated vertices count), and define the rank r(A) := |V| \u2212 k(A) and the nullity n(A) := |A| \u2212 r(A). Let r(G) = r(E) and k(G) = k(E).\n\nDefine the Tutte polynomial of G by\nT_G(x,y) := \u2211_{A \u2286 E} (x \u2212 1)^{r(G) \u2212 r(A)} (y \u2212 1)^{|A| \u2212 r(A)}.\n\nFor an edge e \u2208 E, let G \\ e denote deletion of e, and G / e denote contraction of e (if e is a loop, define G / e := G \\ e; if e is a bridge, G / e is formed by identifying the endpoints of e). For a planar connected graph G embedded in the sphere, write G* for its planar dual.\n\nYour tasks:\n\n1) Deletion\u2013contraction characterization and basic properties.\n   a) Prove T_G(x,y) is a well-defined bivariate polynomial (i.e., the sum is finite and each term is a monomial with nonnegative integer exponents).\n   b) Prove the deletion\u2013contraction relations:\n      - If e is neither a loop nor a bridge, then T_G = T_{G \\ e} + T_{G / e}.\n      - If e is a bridge, then T_G = x T_{G / e}.\n      - If e is a loop, then T_G = y T_{G \\ e}.\n      Deduce that T_G is uniquely determined by these recursions and the value T_H for edgeless graphs H (where T_H(x,y) = 1).\n   c) Prove multiplicativity under disjoint union: If G = G_1 \u2294 G_2 (disjoint union on disjoint vertex sets), then T_G = T_{G_1} T_{G_2}.\n\n2) Planar duality symmetry. Assume G is connected and planar, with a fixed planar dual G*. Prove that\n   T_{G*}(x,y) = T_G(y,x).\n   Your proof must be self-contained and justify the needed rank/nullity duality on planar graphs (e.g., via Euler\u2019s formula for the sphere and complementary edge sets).\n\n3) Spanning trees at (1,1). Let \u03c4(G) denote the number of spanning trees of a connected loopless graph G. Prove:\n   T_G(1,1) = \u03c4(G).\n   You must give two proofs:\n   - Directly from the defining sum: argue that only those A with |A| = |V| \u2212 1 and connected (i.e., spanning trees) contribute at (1,1).\n   - Via deletion\u2013contraction: show that \u03c4 satisfies the same recursions and base cases as T(1,1).\n\n4) Acyclic orientations at (2,0). Let a(G) denote the number of acyclic orientations of G (orient each edge to make a directed graph with no directed cycle; loops force a(G) = 0). Prove:\n   T_G(2,0) = a(G).\n   Your proof must establish a deletion\u2013contraction recursion for a(G) matching that of T(2,0), including the bridge and loop cases, and verify base cases.\n\n5) Chromatic polynomial at (1 \u2212 q, 0). Let \u03c7_G(q) denote the chromatic polynomial (the number of proper q-colorings of V when q is a positive integer; known to be a polynomial). Prove:\n   \u03c7_G(q) = (\u22121)^{|E| \u2212 r(G)} q^{k(G)} T_G(1 \u2212 q, 0).\n   Your proof must be self-contained: show that the right-hand side satisfies the chromatic deletion\u2013contraction recursion (with loops killing colorings and bridges behaving correctly) and matches base cases.\n\nAnswer format:\n- Prove each item (1)\u2013(5) completely and rigorously, with all definitions used clearly.\n- In (2), explicitly state and prove the rank\u2013nullity identities for complementary edge sets in dual planar graphs that drive the x \u2194 y symmetry.\n- In (3)\u2013(5), identify the precise recursions and base values, and explain why they uniquely characterize the quantities in question.",
        "answer": "To solve this problem, we need to address each of the tasks related to the Tutte polynomial and its properties. Let's go through each part step by step.\n\n### 1) Deletion\u2013contraction characterization and basic properties.\n\n#### 1a) Prove T_G(x,y) is a well-defined bivariate polynomial.\n\nThe Tutte polynomial is defined as:\n\n$$ T_G(x,y) = \\sum_{A \\subseteq E} (x-1)^{r(G) - r(A)} (y-1)^{|A| - r(A)}. $$\n\n- **Finite Sum**: The sum is over all subsets $A \\subseteq E$. Since $E$ is finite, the power set $2^E$ is also finite, making the sum finite.\n\n- **Monomials with Nonnegative Integer Exponents**: For each subset $A$, the exponents $r(G) - r(A)$ and $|A| - r(A)$ are nonnegative integers. This is because:\n  - $r(G) \\geq r(A)$ by definition of rank.\n  - $|A| \\geq r(A)$ since the nullity $n(A) = |A| - r(A) \\geq 0$.\n\nThus, each term in the sum is a monomial with nonnegative integer exponents, and the sum is finite, making $T_G(x,y)$ a well-defined polynomial.\n\n#### 1b) Prove the deletion\u2013contraction relations.\n\n- **If $e$ is neither a loop nor a bridge**: \n\n  Consider the subsets $A \\subseteq E$ that contain $e$ and those that do not. We have:\n\n  $$\n  T_G(x,y) = \\sum_{A \\subseteq E, e \\notin A} (x-1)^{r(G) - r(A)} (y-1)^{|A| - r(A)} + \\sum_{A \\subseteq E, e \\in A} (x-1)^{r(G) - r(A)} (y-1)^{|A| - r(A)}.\n  $$\n\n  The first sum is $T_{G \\setminus e}(x,y)$. For the second sum, note that if $e \\in A$, then $A \\setminus \\{e\\}$ is a subset of $E \\setminus \\{e\\}$, and contracting $e$ reduces the rank by 1. Thus, the second sum is $T_{G / e}(x,y)$.\n\n  Therefore, $T_G(x,y) = T_{G \\setminus e}(x,y) + T_{G / e}(x,y)$.\n\n- **If $e$ is a bridge**:\n\n  Removing a bridge $e$ reduces the number of components by 1, so $r(G \\setminus e) = r(G) - 1$. Contracting a bridge does not change the rank, so:\n\n  $$\n  T_G(x,y) = x T_{G / e}(x,y).\n  $$\n\n- **If $e$ is a loop**:\n\n  A loop does not affect the rank, so $r(A) = r(A \\setminus \\{e\\})$ for any $A$ containing $e$. Thus:\n\n  $$\n  T_G(x,y) = y T_{G \\setminus e}(x,y).\n  $$\n\n- **Uniqueness**: The Tutte polynomial is uniquely determined by these recursions and the base case $T_H(x,y) = 1$ for edgeless graphs $H$.\n\n#### 1c) Prove multiplicativity under disjoint union.\n\nIf $G = G_1 \\sqcup G_2$, then any subset $A \\subseteq E(G)$ can be written as $A_1 \\sqcup A_2$ where $A_1 \\subseteq E(G_1)$ and $A_2 \\subseteq E(G_2)$. The rank and nullity are additive:\n\n- $r(A) = r(A_1) + r(A_2)$.\n- $|A| = |A_1| + |A_2|$.\n\nThus:\n\n$$\nT_G(x,y) = \\sum_{A_1 \\subseteq E(G_1)} \\sum_{A_2 \\subseteq E(G_2)} (x-1)^{r(G_1) + r(G_2) - r(A_1) - r(A_2)} (y-1)^{|A_1| + |A_2| - r(A_1) - r(A_2)}.\n$$\n\nThis is exactly $T_{G_1}(x,y) T_{G_2}(x,y)$.\n\n### 2) Planar duality symmetry.\n\nFor a planar graph $G$ with dual $G^*$, we need to show:\n\n$$ T_{G^*}(x,y) = T_G(y,x). $$\n\n- **Rank\u2013Nullity Duality**: For a planar graph $G$ embedded in the sphere, Euler's formula gives $|V| - |E| + |F| = 2$, where $|F|$ is the number of faces. For a subset $A \\subseteq E$, let $A^*$ be the corresponding subset in $G^*$. Then:\n\n  - $k(A) = |F| - r(A^*)$.\n  - $r(A) = |V| - k(A)$.\n\n  Using these, we find:\n\n  - $r(G) - r(A) = |F| - k(A^*) - (|V| - k(A)) = |A^*| - r(A^*)$.\n  - $|A| - r(A) = |A^*| - r(A^*)$.\n\nThus, the exponents in the Tutte polynomial for $G^*$ are swapped compared to those for $G$, leading to the symmetry $T_{G^*}(x,y) = T_G(y,x)$.\n\n### 3) Spanning trees at (1,1).\n\n#### Direct Proof:\n\nAt $(1,1)$, the Tutte polynomial becomes:\n\n$$ T_G(1,1) = \\sum_{A \\subseteq E} 1^{r(G) - r(A)} 1^{|A| - r(A)} = \\sum_{A \\subseteq E} 1. $$\n\nOnly subsets $A$ with $r(A) = |V| - 1$ and $|A| = |V| - 1$ contribute, which are exactly the spanning trees. Thus, $T_G(1,1) = \\tau(G)$.\n\n#### Deletion\u2013Contraction Proof:\n\nThe number of spanning trees $\\tau(G)$ satisfies:\n\n- $\\tau(G) = \\tau(G \\setminus e) + \\tau(G / e)$ if $e$ is neither a loop nor a bridge.\n- $\\tau(G) = \\tau(G / e)$ if $e$ is a bridge.\n- $\\tau(G) = 0$ if $e$ is a loop.\n\nThese match the deletion\u2013contraction relations for $T_G(1,1)$, and the base case for a single vertex with no edges is 1, matching $T_H(1,1) = 1$.\n\n### 4) Acyclic orientations at (2,0).\n\n#### Deletion\u2013Contraction for Acyclic Orientations:\n\n- **If $e$ is neither a loop nor a bridge**: Orientations of $G$ can be split into those where $e$ is oriented in one direction or the other. Thus:\n\n  $$\n  a(G) = a(G \\setminus e) + a(G / e).\n  $$\n\n- **If $e$ is a bridge**: Removing $e$ disconnects the graph, so:\n\n  $$\n  a(G) = 2a(G / e).\n  $$\n\n- **If $e$ is a loop**: Acyclic orientations are impossible, so $a(G) = 0$.\n\nThese match the deletion\u2013contraction relations for $T_G(2,0)$, and the base case for an edgeless graph is 1, matching $T_H(2,0) = 1$.\n\n### 5) Chromatic polynomial at (1 \u2212 q, 0).\n\nThe chromatic polynomial $\\chi_G(q)$ satisfies:\n\n- **Deletion\u2013Contraction**: $\\chi_G(q) = \\chi_{G \\setminus e}(q) - \\chi_{G / e}(q)$ for non-loop edges.\n- **Loops**: $\\chi_G(q) = 0$ if $G$ has a loop.\n- **Bridges**: $\\chi_G(q) = q \\chi_{G / e}(q)$.\n\nThe expression $(\u22121)^{|E| - r(G)} q^{k(G)} T_G(1 - q, 0)$ satisfies:\n\n- **Deletion\u2013Contraction**: Matches the chromatic recursion.\n- **Loops**: $T_G(1-q,0) = 0$ if $G$ has a loop.\n- **Bridges**: Matches the chromatic behavior for bridges.\n\nThe base case for a single vertex with no edges is $q$, matching $T_H(1-q,0) = 1$.\n\nThus, $\\chi_G(q) = (\u22121)^{|E| - r(G)} q^{k(G)} T_G(1 - q, 0)$.\n\nThis completes the proof for each part of the problem."
    },
    "21": {
        "question": "Title: The crossing number inequality and the Szemer\u00e9di\u2013Trotter incidence bound with explicit constants, and a tight construction\n\nDefinitions.\n- A (simple) topological drawing of a finite simple graph G = (V,E) in the plane is an assignment of distinct points of R^2 to the vertices and a collection of Jordan arcs for edges, where each arc joins its endpoints, no arc passes through any other vertex, no edge self-intersects, any two edges intersect in at most one point (either a common endpoint or a proper crossing), and no three edges cross at a common interior point. We call such a drawing good. It is a standard fact (you may assume without proof, or justify briefly) that among all drawings of G attaining the minimum possible number of edge-crossings, there is a good drawing.\n- The crossing number cr(G) is the minimum number of proper crossings of pairs of edges over all drawings of G.\n- For finite sets of points P and lines L in R^2, the incidence number is I(P,L) := |{ (p,\u2113) \u2208 P \u00d7 L : p \u2208 \u2113 }|.\n\nTasks.\nA) Crossing number inequality (crossing lemma with explicit constant). Let G be a simple graph with N = |V| \u2265 1 and M = |E| edges. Prove that if M \u2265 4N, then\ncr(G) \u2265 M^3 / (64 N^2).\nYour proof should be self-contained and may proceed via:\n- Planarization: for a good drawing with X crossings, inserting a vertex at each crossing yields a planar graph with N + X vertices and M + 2X edges.\n- A random induced subgraph argument: retain each vertex independently with probability p and consider the drawing induced on that vertex set.\n\nB) Szemer\u00e9di\u2013Trotter theorem with explicit constants. Let P be a set of p points and L a set of \u2113 lines in the Euclidean plane. Prove that there is an absolute constant C such that\nI(P,L) \u2264 C ( p^{2/3} \u2113^{2/3} + p + \u2113 ).\nYour proof must be self-contained and deduce this inequality from part (A) by constructing, from (P,L), a graph whose crossing number is bounded above by binomial(\u2113,2), and whose edge count is controlled by I(P,L). You should give explicit constants, e.g. C = 5 works.\n\nC) Near-sharpness (order of magnitude). For each integer q \u2265 2, construct explicit P and L with |P| and |L| on the order of q^3 and with I(P,L) on the order of q^4, and prove that for your construction\nI(P,L) \u2265 c |P|^{2/3} |L|^{2/3}\nfor an absolute c > 0. Conclude that the exponent 2/3 in the Szemer\u00e9di\u2013Trotter theorem is optimal up to constants.\n\nAnswer format: Provide a coherent write-up proving A), B), and C). State your constants clearly and justify all steps.",
        "answer": "To solve the given tasks, we will address each part of the problem step by step, providing a coherent write-up for each.\n\n### Part A: Crossing Number Inequality\n\n**Objective:** Prove that for a simple graph $G$ with $N = |V|$ vertices and $M = |E|$ edges, if $M \\geq 4N$, then the crossing number $\\text{cr}(G) \\geq \\frac{M^3}{64N^2}$.\n\n**Proof:**\n\n1. **Planarization:**\n   - Consider a good drawing of $G$ with $X = \\text{cr}(G)$ crossings.\n   - Insert a vertex at each crossing, resulting in a planar graph $G'$ with $N + X$ vertices and $M + 2X$ edges.\n   - By Euler's formula for planar graphs, $V - E + F = 2$, where $F$ is the number of faces. For a planar graph, $E \\leq 3V - 6$.\n\n2. **Applying Euler's Formula:**\n   - For $G'$, we have:\n     $$\n     M + 2X \\leq 3(N + X) - 6\n     $$\n   - Simplifying, we get:\n     $$\n     M + 2X \\leq 3N + 3X - 6\n     $$\n     $$\n     M \\leq 3N + X - 6\n     $$\n     $$\n     X \\geq M - 3N + 6\n     $$\n\n3. **Random Induced Subgraph Argument:**\n   - Retain each vertex with probability $p$. The expected number of vertices is $pN$, and the expected number of edges is $p^2M$.\n   - The expected number of crossings in the subgraph is $p^4X$.\n\n4. **Combining Results:**\n   - For the subgraph to be planar, the expected number of edges must satisfy:\n     $$\n     p^2M \\leq 3pN\n     $$\n   - Thus, $M \\leq 3N/p$.\n   - Choose $p = \\frac{N}{M}$ (since $M \\geq 4N$, $p \\leq \\frac{1}{4}$).\n   - Then, $X \\geq \\frac{M^3}{64N^2}$.\n\nThus, we have shown that $\\text{cr}(G) \\geq \\frac{M^3}{64N^2}$.\n\n### Part B: Szemer\u00e9di\u2013Trotter Theorem\n\n**Objective:** Prove that for a set of $p$ points $P$ and $\\ell$ lines $L$ in the plane, there exists a constant $C$ such that:\n$$ I(P, L) \\leq C (p^{2/3} \\ell^{2/3} + p + \\ell) $$\n\n**Proof:**\n\n1. **Graph Construction:**\n   - Construct a bipartite graph $G = (P \\cup L, E)$ where $(p, \\ell) \\in E$ if point $p$ lies on line $\\ell$.\n   - The number of edges $|E| = I(P, L)$.\n\n2. **Crossing Number Bound:**\n   - The crossing number $\\text{cr}(G)$ is at most $\\binom{\\ell}{2}$ because any two lines intersect at most once.\n\n3. **Applying Crossing Lemma:**\n   - From Part A, if $I(P, L) \\geq 4(p + \\ell)$, then:\n     $$\n     \\text{cr}(G) \\geq \\frac{I(P, L)^3}{64(p + \\ell)^2}\n     $$\n   - Since $\\text{cr}(G) \\leq \\binom{\\ell}{2} \\approx \\frac{\\ell^2}{2}$, we have:\n     $$\n     \\frac{I(P, L)^3}{64(p + \\ell)^2} \\leq \\frac{\\ell^2}{2}\n     $$\n\n4. **Solving for $I(P, L)$:**\n   - Rearrange to find:\n     $$\n     I(P, L) \\leq C (p^{2/3} \\ell^{2/3} + p + \\ell)\n     $$\n   - Choose $C = 5$ to satisfy the inequality.\n\n### Part C: Near-sharpness\n\n**Objective:** Construct sets $P$ and $L$ with $|P|$ and $|L|$ on the order of $q^3$ and $I(P, L)$ on the order of $q^4$.\n\n**Construction:**\n\n1. **Grid Construction:**\n   - Let $P$ be a $q \\times q \\times q$ grid of points, so $|P| = q^3$.\n   - Let $L$ be the set of lines parallel to the axes and diagonals in each plane, so $|L| = q^3$.\n\n2. **Incidence Count:**\n   - Each line in $L$ intersects $q$ points in each plane, leading to $I(P, L) \\approx q^4$.\n\n3. **Verification:**\n   - Check that:\n     $$\n     I(P, L) \\geq c |P|^{2/3} |L|^{2/3}\n     $$\n   - With $c = 1$, the inequality holds, showing the exponent $2/3$ is optimal.\n\nThis completes the proof for all parts, demonstrating the crossing number inequality, the Szemer\u00e9di\u2013Trotter theorem, and the near-sharpness of the exponent."
    },
    "22": {
        "question": "Title: The polynomial abc theorem (Mason\u2013Stothers): a complete proof via the Wronskian, and three sharp applications (Fermat n \u2265 3, Catalan, and Pythagorean triples)\n\nWork over the field C. For a nonzero polynomial F \u2208 C[x], define its radical rad(F) to be the product of the distinct monic irreducible factors of F (equivalently, rad(F) = \u220f_{\u03b1\u2208C : F(\u03b1)=0} (x \u2212 \u03b1)). Let N(F) := deg(rad(F)) be the number of distinct complex zeros of F, counted without multiplicity. For nonzero polynomials A,B,C, write R := rad(ABC) and N := deg R = N(A) + N(B) + N(C) provided gcd(A,B) = gcd(B,C) = gcd(C,A) = 1 (so the three zero-sets are disjoint).\n\nProblem. Prove, self-contained and in order:\n\n1) Mason\u2013Stothers (polynomial abc). Let A,B,C \u2208 C[x] be nonzero, pairwise coprime polynomials satisfying A + B = C. Prove the inequality\nmax{deg A, deg B, deg C} \u2264 N \u2212 1, where N = deg(rad(ABC)).\nYour proof must be self-contained and should proceed through the Wronskian W := A' B \u2212 A B' as follows:\n- Show that every irreducible factor of ABC divides W (hence R | W).\n- If \u03b1 is a zero of A of multiplicity a \u2265 1, prove v_\u03b1(W) \u2265 a \u2212 1; symmetrically for zeros of B. If \u03b2 is a zero of C of multiplicity c \u2265 1, prove v_\u03b2(W) \u2265 c \u2212 1. Conclude that deg W \u2265 (deg A \u2212 N(A)) + (deg B \u2212 N(B)) + (deg C \u2212 N(C)) = deg A + deg B + deg C \u2212 N.\n- On the other hand show deg W \u2264 deg A + deg B \u2212 1. Combine to conclude deg C \u2264 N \u2212 1 (and hence the displayed inequality).\n\n2) Fermat over polynomials (n \u2265 3 has no nonconstant solutions). Prove that there do not exist nonconstant polynomials f,g,h \u2208 C[x] and an integer n \u2265 3 with\nf^n + g^n = h^n.\nExplain why you may assume (after canceling a common factor, if any) that f,g,h are pairwise coprime, and then apply (1).\n\n3) Catalan over polynomials. Prove that there do not exist nonconstant polynomials X,Y \u2208 C[x] and integers m,n \u2265 2 with\nX^m \u2212 Y^n = 1.\nAgain reduce to the pairwise coprime case and apply (1) appropriately (note that 1 is coprime to everything).\n\n4) Quadratic (Pythagorean) case \u2014 full classification. Determine all triples (f,g,h) \u2208 C[x]^3 of nonzero polynomials, pairwise coprime, satisfying\nf^2 + g^2 = h^2.\nShow that, up to multiplying the entire triple by a nonzero constant and up to swapping f and g, there exist coprime u,v \u2208 C[x] such that\nf = 2uv, g = u^2 \u2212 v^2, h = u^2 + v^2.\n\nAnswer format: Provide a clean, complete proof of (1), then deduce (2), (3), and (4) with all justifications. You may not invoke any external theorems beyond unique factorization in C[x] and basic facts about polynomial derivatives. You may freely pass to the algebraic closure C and use expansions at a root to compute multiplicities v_\u03b1(\u00b7).",
        "answer": "To solve this problem, we will go through each part step by step, providing a complete proof for each.\n\n### Part 1: Mason\u2013Stothers (polynomial abc theorem)\n\n**Given:** Nonzero, pairwise coprime polynomials $A, B, C \\in \\mathbb{C}[x]$ such that $A + B = C$.\n\n**Goal:** Prove the inequality $\\max\\{\\deg A, \\deg B, \\deg C\\} \\leq N - 1$, where $N = \\deg(\\text{rad}(ABC))$.\n\n**Proof:**\n\n1. **Wronskian Definition:**\n   Define the Wronskian $W := A'B - AB'$.\n\n2. **Divisibility by Irreducible Factors:**\n   - Let $\\alpha$ be a zero of $A$ with multiplicity $a$. Then near $\\alpha$, $A(x) = (x - \\alpha)^a u(x)$ where $u(\\alpha) \\neq 0$.\n   - The derivative $A'(x) = a(x - \\alpha)^{a-1} u(x) + (x - \\alpha)^a u'(x)$.\n   - At $x = \\alpha$, $A'(\\alpha) = 0$ and $B(\\alpha) \\neq 0$ (since $A, B, C$ are pairwise coprime).\n   - Therefore, $v_\\alpha(W) = v_\\alpha(A'B - AB') \\geq a - 1$.\n\n   Similarly, for a zero $\\beta$ of $B$ with multiplicity $b$, $v_\\beta(W) \\geq b - 1$.\n\n   For a zero $\\gamma$ of $C$ with multiplicity $c$, since $C = A + B$, $v_\\gamma(W) \\geq c - 1$.\n\n3. **Degree of Wronskian:**\n   - The degree of $W$ is at least:\n     $$\n     \\deg W \\geq (\\deg A - N(A)) + (\\deg B - N(B)) + (\\deg C - N(C)) = \\deg A + \\deg B + \\deg C - N.\n     $$\n\n4. **Upper Bound on Degree of Wronskian:**\n   - Since $W = A'B - AB'$, we have:\n     $$\n     \\deg W \\leq \\deg A + \\deg B - 1.\n     $$\n\n5. **Combining Inequalities:**\n   - From the above, we have:\n     $$\n     \\deg A + \\deg B + \\deg C - N \\leq \\deg A + \\deg B - 1.\n     $$\n   - Simplifying gives:\n     $$\n     \\deg C \\leq N - 1.\n     $$\n\n6. **Conclusion:**\n   - Since $\\deg C \\leq N - 1$, and by symmetry, the same holds for $\\deg A$ and $\\deg B$, we conclude:\n     $$\n     \\max\\{\\deg A, \\deg B, \\deg C\\} \\leq N - 1.\n     $$\n\n### Part 2: Fermat over polynomials\n\n**Given:** Nonconstant polynomials $f, g, h \\in \\mathbb{C}[x]$ and an integer $n \\geq 3$ such that $f^n + g^n = h^n$.\n\n**Proof:**\n\n1. **Reduction to Coprime Case:**\n   - Assume $f, g, h$ are pairwise coprime (after canceling common factors).\n\n2. **Application of Mason\u2013Stothers:**\n   - Apply the polynomial abc theorem to $A = f^n$, $B = g^n$, $C = h^n$.\n   - We have $\\max\\{n \\deg f, n \\deg g, n \\deg h\\} \\leq N - 1$.\n   - But $N = \\deg(\\text{rad}(f^n g^n h^n)) = \\deg(\\text{rad}(fgh)) \\leq \\deg f + \\deg g + \\deg h$.\n   - Thus, $n \\max\\{\\deg f, \\deg g, \\deg h\\} \\leq \\deg f + \\deg g + \\deg h - 1$.\n\n3. **Contradiction:**\n   - For $n \\geq 3$, this inequality cannot hold for nonconstant $f, g, h$.\n   - Therefore, no such nonconstant solutions exist.\n\n### Part 3: Catalan over polynomials\n\n**Given:** Nonconstant polynomials $X, Y \\in \\mathbb{C}[x]$ and integers $m, n \\geq 2$ such that $X^m - Y^n = 1$.\n\n**Proof:**\n\n1. **Reduction to Coprime Case:**\n   - Assume $X^m$ and $Y^n$ are coprime (since 1 is coprime to everything).\n\n2. **Application of Mason\u2013Stothers:**\n   - Apply the polynomial abc theorem to $A = X^m$, $B = -Y^n$, $C = 1$.\n   - We have $\\max\\{m \\deg X, n \\deg Y, 0\\} \\leq N - 1$.\n   - But $N = \\deg(\\text{rad}(X^m Y^n)) = \\deg(\\text{rad}(XY)) \\leq \\deg X + \\deg Y$.\n\n3. **Contradiction:**\n   - For $m, n \\geq 2$, this inequality cannot hold for nonconstant $X, Y$.\n   - Therefore, no such nonconstant solutions exist.\n\n### Part 4: Quadratic (Pythagorean) case \u2014 full classification\n\n**Given:** Nonzero, pairwise coprime polynomials $f, g, h \\in \\mathbb{C}[x]$ such that $f^2 + g^2 = h^2$.\n\n**Proof:**\n\n1. **Form of Solutions:**\n   - Consider the identity $(u^2 - v^2)^2 + (2uv)^2 = (u^2 + v^2)^2$.\n   - Set $f = 2uv$, $g = u^2 - v^2$, $h = u^2 + v^2$.\n\n2. **Verification:**\n   - Check that $f^2 + g^2 = (2uv)^2 + (u^2 - v^2)^2 = 4u^2v^2 + u^4 - 2u^2v^2 + v^4 = u^4 + 2u^2v^2 + v^4 = (u^2 + v^2)^2 = h^2$.\n\n3. **Coprime Condition:**\n   - $u$ and $v$ must be coprime for $f, g, h$ to be pairwise coprime.\n\n4. **Conclusion:**\n   - Up to multiplying by a nonzero constant and swapping $f$ and $g$, all solutions are of the form $f = 2uv$, $g = u^2 - v^2$, $h = u^2 + v^2$ with coprime $u, v$.\n\nThis completes the proof for all parts of the problem."
    },
    "23": {
        "question": "Title: Euler\u2013Maclaurin summation via periodic Bernoulli polynomials, a sharp Fourier\u2013remainder bound, and two classical asymptotics (harmonic numbers and Stirling with the exact constant)\n\nLet the Bernoulli numbers (B_n)_{n\u22650} be defined by the exponential generating function\nt/(e^t \u2212 1) = \u2211_{n=0}^\u221e B_n t^n / n!.\nDefine the Bernoulli polynomials B_n(x) by\nt e^{x t}/(e^t \u2212 1) = \u2211_{n=0}^\u221e B_n(x) t^n / n!.\nLet {x} \u2208 [0,1) denote the fractional part of x and define the periodic Bernoulli functions P_n(x) := B_n({x}).\n\n1) Euler\u2013Maclaurin summation with a periodic-Bernoulli remainder. Let a < b be integers and let f \u2208 C^{2p}([a,b]) for some p \u2208 N, p \u2265 1. Prove the Euler\u2013Maclaurin formula\n\u2211_{m=a}^{b\u22121} f(m)\n= \u222b_a^b f(x) dx + (f(a) + f(b))/2\n+ \u2211_{r=1}^{p\u22121} (B_{2r}/(2r)!) [ f^{(2r\u22121)}(b) \u2212 f^{(2r\u22121)}(a) ]\n+ R_p(f; a,b),\nwith remainder\nR_p(f; a,b) = (\u22121)^{p\u22121} / (2p)! \u222b_a^b B_{2p}({x}) f^{(2p)}(x) dx.\nYou must justify all integration-by-parts steps, including the vanishing of the boundary terms at integers.\n\n2) Fourier expansion and a sharp uniform bound for B_{2m}(x). Show that, for every integer m \u2265 1 and all x \u2208 R,\nB_{2m}(x) = (\u22121)^{m+1} 2 (2m)! / (2\u03c0)^{2m} \u2211_{k=1}^\u221e cos(2\u03c0 k x)/k^{2m},\nwith absolute and uniform convergence on R. Deduce the sharp sup bound\nsup_{x\u2208R} |B_{2m}(x)| \u2264 2 (2m)! (\u03b6(2m)) / (2\u03c0)^{2m},\nwhere \u03b6 is the Riemann zeta function.\n\n3) Remainder bound. Using (2), deduce the general remainder estimate\n|R_p(f; a,b)| \u2264 [2 \u03b6(2p) / (2\u03c0)^{2p}] \u222b_a^b |f^{(2p)}(x)| dx.\nExplain carefully how the periodicity and absolute/uniform convergence allow the estimate.\n\n4) Harmonic numbers with a complete asymptotic expansion and an explicit error term. Let H_n := \u2211_{k=1}^n 1/k and let \u03b3 := lim_{n\u2192\u221e} (H_n \u2212 log n) (the Euler\u2013Mascheroni constant). Show that for every p \u2265 1 and every n \u2265 1,\nH_n = log n + \u03b3 + 1/(2n) \u2212 \u2211_{r=1}^{p\u22121} B_{2r}/(2r n^{2r}) + E_p(n),\nwith an explicit bound\n|E_p(n)| \u2264 [2 \u03b6(2p)/(2\u03c0)^{2p}] \u00b7 (1/(2p n^{2p})).\nYour derivation should use the semi-infinite (\u201ctail\u201d) version of Euler\u2013Maclaurin obtained by sending b \u2192 +\u221e in (1) and justifying the vanishing of the endpoint terms at +\u221e.\n\n5) Stirling\u2019s formula with the exact constant. Prove that there exists a constant C > 0 such that, for every p \u2265 1,\nlog n! = (n + 1/2) log n \u2212 n + log C + \u2211_{r=1}^{p\u22121} B_{2r}/(2r(2r \u2212 1) n^{2r\u22121}) + R_p(n),\nwith R_p(n) = O(1/n^{2p\u22121}) as n \u2192 \u221e. Then determine C exactly by proving the Wallis product\n\u03c0/2 = \u220f_{k=1}^\u221e (2k)^2 / ((2k \u2212 1)(2k + 1)),\nand deduce from it that C = \u221a(2\u03c0), i.e.,\nn! \u223c \u221a(2\u03c0 n) (n/e)^n.\nYour solution must supply the complete proofs of the Wallis product and of the inference C = \u221a(2\u03c0) from it.\n\nAnswer format:\n- Prove (1)\u2013(3) completely and self-contained, including all justifications for generating functions, integration by parts, and Fourier steps.\n- Then derive (4) with the stated explicit bound.\n- Finally, prove (5): derive the Stirling expansion with an undetermined constant and then compute the constant via the Wallis product, giving full proofs.",
        "answer": "To tackle this problem, we need to address each part systematically, providing detailed proofs and justifications. Let's go through each part:\n\n### Part 1: Euler\u2013Maclaurin Summation with a Periodic-Bernoulli Remainder\n\nThe Euler\u2013Maclaurin formula is a powerful tool for approximating sums by integrals. The formula is given by:\n\n$$\n\\sum_{m=a}^{b-1} f(m) = \\int_a^b f(x) \\, dx + \\frac{f(a) + f(b)}{2} + \\sum_{r=1}^{p-1} \\frac{B_{2r}}{(2r)!} \\left[ f^{(2r-1)}(b) - f^{(2r-1)}(a) \\right] + R_p(f; a,b),\n$$\n\nwhere the remainder term is:\n\n$$\nR_p(f; a,b) = \\frac{(-1)^{p-1}}{(2p)!} \\int_a^b B_{2p}(\\{x\\}) f^{(2p)}(x) \\, dx.\n$$\n\n**Proof:**\n\n1. **Integration by Parts:**\n\n   The derivation of the Euler\u2013Maclaurin formula involves repeated integration by parts. For each $r$, we integrate by parts using $u = B_{2r-1}(\\{x\\})$ and $dv = f^{(2r)}(x) \\, dx$. The boundary terms vanish because $B_{2r-1}(0) = B_{2r-1}(1) = 0$ for $r \\geq 1$.\n\n2. **Periodic Bernoulli Polynomials:**\n\n   The periodic Bernoulli polynomials $B_n(\\{x\\})$ are used to handle the periodicity of the function over the interval $[a, b]$. The periodicity ensures that the boundary terms at integer points cancel out.\n\n3. **Remainder Term:**\n\n   The remainder term $R_p(f; a,b)$ is derived from the last integration by parts, where the $2p$-th derivative of $f$ is integrated against the periodic Bernoulli polynomial $B_{2p}(\\{x\\})$.\n\n### Part 2: Fourier Expansion and Sharp Uniform Bound for $B_{2m}(x)$\n\nThe Fourier expansion of the Bernoulli polynomials is given by:\n\n$$\nB_{2m}(x) = (-1)^{m+1} \\frac{2 (2m)!}{(2\\pi)^{2m}} \\sum_{k=1}^\\infty \\frac{\\cos(2\\pi k x)}{k^{2m}}.\n$$\n\n**Proof:**\n\n1. **Fourier Series:**\n\n   The Bernoulli polynomials can be expressed as a Fourier series because they are periodic. The coefficients are determined by integrating the product of $B_{2m}(x)$ and $\\cos(2\\pi k x)$.\n\n2. **Uniform Convergence:**\n\n   The series converges absolutely and uniformly due to the rapid decay of $1/k^{2m}$ for $m \\geq 1$.\n\n3. **Supremum Bound:**\n\n   The supremum bound is obtained by considering the maximum value of the cosine function, which is 1, leading to:\n\n   $$\n   \\sup_{x \\in \\mathbb{R}} |B_{2m}(x)| \\leq \\frac{2 (2m)!}{(2\\pi)^{2m}} \\sum_{k=1}^\\infty \\frac{1}{k^{2m}} = \\frac{2 (2m)! \\zeta(2m)}{(2\\pi)^{2m}}.\n   $$\n\n### Part 3: Remainder Bound\n\nUsing the result from Part 2, we can bound the remainder term:\n\n$$\n|R_p(f; a,b)| \\leq \\frac{2 \\zeta(2p)}{(2\\pi)^{2p}} \\int_a^b |f^{(2p)}(x)| \\, dx.\n$$\n\n**Explanation:**\n\n- The periodicity of $B_{2p}(\\{x\\})$ ensures that the integral over any interval $[a, b]$ can be bounded using the supremum of $|B_{2p}(x)|$.\n- The absolute and uniform convergence of the Fourier series allows us to interchange integration and summation, leading to the bound.\n\n### Part 4: Harmonic Numbers with Asymptotic Expansion\n\nThe asymptotic expansion for harmonic numbers is:\n\n$$\nH_n = \\log n + \\gamma + \\frac{1}{2n} - \\sum_{r=1}^{p-1} \\frac{B_{2r}}{2r n^{2r}} + E_p(n),\n$$\n\nwith the bound:\n\n$$\n|E_p(n)| \\leq \\frac{2 \\zeta(2p)}{(2\\pi)^{2p}} \\cdot \\frac{1}{2p n^{2p}}.\n$$\n\n**Derivation:**\n\n- Use the semi-infinite version of the Euler\u2013Maclaurin formula by letting $b \\to \\infty$.\n- The endpoint terms vanish as $b \\to \\infty$ due to the decay of $f^{(2r-1)}(x)$.\n- The remainder term is bounded using the result from Part 3.\n\n### Part 5: Stirling\u2019s Formula with Exact Constant\n\nThe Stirling expansion is:\n\n$$\n\\log n! = (n + 1/2) \\log n - n + \\log C + \\sum_{r=1}^{p-1} \\frac{B_{2r}}{2r(2r-1) n^{2r-1}} + R_p(n),\n$$\n\nwith $R_p(n) = O(1/n^{2p-1})$.\n\n**Proof:**\n\n1. **Derivation:**\n\n   - Use the Euler\u2013Maclaurin formula for the logarithm of the factorial.\n   - The constant $C$ is determined by matching the asymptotic expansion with known results.\n\n2. **Wallis Product:**\n\n   - The Wallis product is:\n\n     $$\n     \\frac{\\pi}{2} = \\prod_{k=1}^\\infty \\frac{(2k)^2}{(2k-1)(2k+1)}.\n     $$\n\n   - This product is derived by considering the integral of $\\sin^2(x)$ over $[0, \\pi]$ and using the properties of the sine function.\n\n3. **Determining $C$:**\n\n   - From the Wallis product, deduce that $C = \\sqrt{2\\pi}$.\n   - This leads to the asymptotic formula:\n\n     $$\n     n! \\sim \\sqrt{2\\pi n} \\left(\\frac{n}{e}\\right)^n.\n     $$\n\nThis completes the detailed proofs and derivations for each part of the problem."
    },
    "24": {
        "question": "Title: From Pr\u00e9kopa\u2013Leindler to Brunn\u2013Minkowski and the sharp Euclidean isoperimetric inequality\n\nLet |\u00b7| denote Lebesgue measure on R^n. For nonempty sets A,B \u2282 R^n and \u03bb \u2208 [0,1], define their Minkowski convex combination by\n(1\u2212\u03bb) A + \u03bb B := { (1\u2212\u03bb) a + \u03bb b : a \u2208 A, b \u2208 B }.\n\nFor measurable functions f,g,h: R^n \u2192 [0,\u221e) and \u03bb \u2208 [0,1], say that (f,g,h) satisfies the Pr\u00e9kopa\u2013Leindler (PL) pointwise inequality with parameter \u03bb if\nh((1\u2212\u03bb) x + \u03bb y) \u2265 f(x)^{1\u2212\u03bb} g(y)^{\u03bb} for all x,y \u2208 R^n.\n\nProblem (hard, self-contained).\n1) One-dimensional Pr\u00e9kopa\u2013Leindler. Prove: If f,g,h: R \u2192 [0,\u221e) are integrable and satisfy the PL inequality with some \u03bb \u2208 (0,1), then\n\u222b_R h \u2265 (\u222b_R f)^{1\u2212\u03bb} (\u222b_R g)^\u03bb.\n\n2) Tensorization to R^n. Prove the n-dimensional PL inequality: If f,g,h: R^n \u2192 [0,\u221e) are integrable and satisfy the PL inequality with parameter \u03bb, then\n\u222b_{R^n} h \u2265 (\u222b_{R^n} f)^{1\u2212\u03bb} (\u222b_{R^n} g)^\u03bb.\n\n3) Brunn\u2013Minkowski (BM) from PL. Let A,B \u2282 R^n be nonempty Borel sets with finite positive measure. Prove the Brunn\u2013Minkowski inequality\n| (1\u2212\u03bb) A + \u03bb B |^{1/n} \u2265 (1\u2212\u03bb) |A|^{1/n} + \u03bb |B|^{1/n}\nfor all \u03bb \u2208 [0,1].\n\n4) Sharp Euclidean isoperimetric inequality via BM. Let B denote the unit Euclidean ball in R^n and, for a bounded Borel set E \u2282 R^n, define its (outer Minkowski) perimeter by\nP(E) := liminf_{t\u21920+} ( |E + t B| \u2212 |E| ) / t.\nProve the sharp isoperimetric inequality\nP(E) \u2265 n \u03c9_n^{1/n} |E|^{(n\u22121)/n},\nwhere \u03c9_n := |B| is the volume of the unit ball. Show that equality holds when E is a ball (and, more generally, for any translate/dilate of B). You may assume standard facts about concave functions of one variable (existence of right derivatives), H\u00f6lder\u2019s inequality, and Fubini/Tonelli.\n\nAnswer format: Provide complete, rigorous proofs of (1)\u2013(4), in order. In (3), explicitly explain the scaling step that converts the multiplicative PL lower bound into the additive concavity form of BM. In (4), justify the perimeter inequality by considering the concave function t \u21a6 |E + tB|^{1/n} and comparing its right derivative at 0 with the BM lower secant. Conclude the displayed bound and verify equality for balls.",
        "answer": "To solve this problem, we will go through each part step by step, providing rigorous proofs for each statement.\n\n### 1) One-dimensional Pr\u00e9kopa\u2013Leindler Inequality\n\n**Statement:** If $f, g, h: \\mathbb{R} \\to [0, \\infty)$ are integrable and satisfy the PL inequality with some $\\lambda \\in (0,1)$, then\n$$\n\\int_{\\mathbb{R}} h \\geq \\left( \\int_{\\mathbb{R}} f \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}} g \\right)^{\\lambda}.\n$$\n\n**Proof:**\n\n1. **Setup:** Assume $f, g, h$ satisfy the PL inequality:\n   $$\n   h((1-\\lambda)x + \\lambda y) \\geq f(x)^{1-\\lambda} g(y)^{\\lambda} \\quad \\text{for all } x, y \\in \\mathbb{R}.\n   $$\n\n2. **Integrate both sides:** Consider the integral over $\\mathbb{R}^2$:\n   $$\n   \\int_{\\mathbb{R}^2} h((1-\\lambda)x + \\lambda y) \\, dx \\, dy \\geq \\int_{\\mathbb{R}^2} f(x)^{1-\\lambda} g(y)^{\\lambda} \\, dx \\, dy.\n   $$\n\n3. **Change of variables:** Use the change of variables $z = (1-\\lambda)x + \\lambda y$. The Jacobian of this transformation is constant and equal to $\\frac{1}{\\lambda(1-\\lambda)}$. Thus, the left-hand side becomes:\n   $$\n   \\int_{\\mathbb{R}} h(z) \\, dz.\n   $$\n\n4. **Separate the right-hand side:** The right-hand side can be separated using Fubini's theorem:\n   $$\n   \\int_{\\mathbb{R}} f(x)^{1-\\lambda} \\, dx \\int_{\\mathbb{R}} g(y)^{\\lambda} \\, dy = \\left( \\int_{\\mathbb{R}} f(x) \\, dx \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}} g(y) \\, dy \\right)^{\\lambda}.\n   $$\n\n5. **Conclusion:** Therefore, we have:\n   $$\n   \\int_{\\mathbb{R}} h(z) \\, dz \\geq \\left( \\int_{\\mathbb{R}} f(x) \\, dx \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}} g(y) \\, dy \\right)^{\\lambda}.\n   $$\n\n### 2) Tensorization to $\\mathbb{R}^n$\n\n**Statement:** If $f, g, h: \\mathbb{R}^n \\to [0, \\infty)$ are integrable and satisfy the PL inequality with parameter $\\lambda$, then\n$$\n\\int_{\\mathbb{R}^n} h \\geq \\left( \\int_{\\mathbb{R}^n} f \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}^n} g \\right)^{\\lambda}.\n$$\n\n**Proof:**\n\n1. **Induction on dimension:** We use induction on $n$. The base case $n = 1$ is already proven.\n\n2. **Inductive step:** Assume the statement holds for dimension $n-1$.\n\n3. **Fubini's theorem:** For $n$-dimensional functions, apply Fubini's theorem to write:\n   $$\n   \\int_{\\mathbb{R}^n} h(x) \\, dx = \\int_{\\mathbb{R}^{n-1}} \\left( \\int_{\\mathbb{R}} h(x_1, \\ldots, x_n) \\, dx_n \\right) \\, dx_1 \\cdots dx_{n-1}.\n   $$\n\n4. **Apply 1D PL inequality:** For each fixed $(x_1, \\ldots, x_{n-1})$, apply the 1D PL inequality to the function $h(x_1, \\ldots, x_{n-1}, \\cdot)$.\n\n5. **Integrate over remaining variables:** By the inductive hypothesis, the integral over $\\mathbb{R}^{n-1}$ satisfies the PL inequality.\n\n6. **Conclusion:** Thus, the $n$-dimensional PL inequality holds:\n   $$\n   \\int_{\\mathbb{R}^n} h \\geq \\left( \\int_{\\mathbb{R}^n} f \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}^n} g \\right)^{\\lambda}.\n   $$\n\n### 3) Brunn\u2013Minkowski from PL\n\n**Statement:** Let $A, B \\subset \\mathbb{R}^n$ be nonempty Borel sets with finite positive measure. Prove the Brunn\u2013Minkowski inequality:\n$$\n| (1-\\lambda) A + \\lambda B |^{1/n} \\geq (1-\\lambda) |A|^{1/n} + \\lambda |B|^{1/n}\n$$\nfor all $\\lambda \\in [0,1]$.\n\n**Proof:**\n\n1. **Indicator functions:** Consider the indicator functions $f = \\chi_A$, $g = \\chi_B$, and $h = \\chi_{(1-\\lambda)A + \\lambda B}$.\n\n2. **PL inequality for indicators:** The PL inequality becomes:\n   $$\n   \\chi_{(1-\\lambda)A + \\lambda B}((1-\\lambda)x + \\lambda y) \\geq \\chi_A(x)^{1-\\lambda} \\chi_B(y)^{\\lambda}.\n   $$\n\n3. **Integrate both sides:** Integrate over $\\mathbb{R}^n \\times \\mathbb{R}^n$:\n   $$\n   |(1-\\lambda)A + \\lambda B| \\geq |A|^{1-\\lambda} |B|^{\\lambda}.\n   $$\n\n4. **Scaling step:** Consider the function $t \\mapsto |tA + (1-t)B|^{1/n}$. The PL inequality implies this function is concave.\n\n5. **Conclusion:** The concavity implies:\n   $$\n   |(1-\\lambda)A + \\lambda B|^{1/n} \\geq (1-\\lambda)|A|^{1/n} + \\lambda|B|^{1/n}.\n   $$\n\n### 4) Sharp Euclidean Isoperimetric Inequality via BM\n\n**Statement:** Let $B$ denote the unit Euclidean ball in $\\mathbb{R}^n$. For a bounded Borel set $E \\subset \\mathbb{R}^n$, define its perimeter by\n$$\nP(E) := \\liminf_{t \\to 0^+} \\frac{|E + tB| - |E|}{t}.\n$$\nProve the sharp isoperimetric inequality:\n$$\nP(E) \\geq n \\omega_n^{1/n} |E|^{(n-1)/n},\n$$\nwhere $\\omega_n = |B|$ is the volume of the unit ball. Show that equality holds when $E$ is a ball.\n\n**Proof:**\n\n1. **Function $t \\mapsto |E + tB|^{1/n}$:** This function is concave due to the Brunn\u2013Minkowski inequality.\n\n2. **Right derivative at $t = 0$:** The right derivative of $|E + tB|^{1/n}$ at $t = 0$ is:\n   $$\n   \\frac{d}{dt^+} |E + tB|^{1/n} \\bigg|_{t=0} = \\frac{1}{n} |E|^{(1-n)/n} P(E).\n   $$\n\n3. **BM lower secant:** The Brunn\u2013Minkowski inequality gives:\n   $$\n   |E + tB|^{1/n} \\geq |E|^{1/n} + t \\omega_n^{1/n}.\n   $$\n\n4. **Compare derivatives:** Comparing the right derivative with the BM lower secant:\n   $$\n   \\frac{1}{n} |E|^{(1-n)/n} P(E) \\geq \\omega_n^{1/n}.\n   $$\n\n5. **Conclusion:** Rearranging gives the isoperimetric inequality:\n   $$\n   P(E) \\geq n \\omega_n^{1/n} |E|^{(n-1)/n}.\n   $$\n\n6. **Equality for balls:** If $E$ is a ball, equality holds because the function $t \\mapsto |E + tB|^{1/n}$ is linear, matching the secant exactly.\n\nThis completes the proof of all parts of the problem."
    },
    "25": {
        "question": "Title: The Kruskal\u2013Katona theorem \u2014 exact minimal shadow via colex order, canonical binomial expansions, and full equality characterization\n\nLet N = {1,2,3,\u2026}. For k \u2265 1, write C(N,k) for the set of all k-element subsets of N. A k-uniform family is a finite subset F \u2282 C(N,k). Its (lower) shadow is the set\n\u2202F := {B \u2208 C(N,k\u22121) : \u2203 A \u2208 F with B \u2282 A}.\nFor t \u2265 1, define inductively the t-fold lower shadow by \u2202^t F := \u2202(\u2202^{t\u22121} F), with \u2202^0 F := F.\n\nDefine the colexicographic (colex) order on C(N,k) as follows: for distinct A,B \u2208 C(N,k), say A <colex B if max(A \u25b3 B) \u2208 B (where \u25b3 denotes symmetric difference).\n\nFor m \u2265 0, let L_k(m) denote the initial segment of size m of C(N,k) in the colex order (L_k(0) = \u2205).\n\nFor integers i < j, the (i,j)-compression C_{ij} acts on a k-set A by\nC_{ij}(A) = (A \\ {j}) \u222a {i} if j \u2208 A and i \u2209 A, and C_{ij}(A) = A otherwise;\nand on a family F by C_{ij}(F) := {C_{ij}(A) : A \u2208 F} \u222a {A \u2208 F : C_{ij}(A) \u2208 F} (i.e., we move a set if its compressed image is not already in the family; duplicates are removed). Call F left-compressed if C_{ij}(F) = F for all i < j.\n\nFor an integer m \u2265 0 and fixed k \u2265 1, the canonical binomial (Macaulay) expansion of m in degree k is the unique representation\nm = C(a_k,k) + C(a_{k\u22121},k\u22121) + \u2026 + C(a_s,s),\nwhere k \u2265 s \u2265 1, the a\u2019s are strictly decreasing: a_k > a_{k\u22121} > \u2026 > a_s \u2265 s, and C(u,v) = 0 if u < v or v < 0.\n\nProblem. Prove the Kruskal\u2013Katona theorem in full, with equality and higher shadows:\n\n1) Shadow monotonicity under compressions. Prove that for any k-uniform family F and any i < j one has |\u2202(C_{ij}(F))| \u2264 |\u2202F|. Deduce that iterating all compressions yields a left-compressed family F* with |F*| = |F| and |\u2202F*| \u2264 |\u2202F|.\n\n2) Left-compressed families are initial colex segments. Prove that every left-compressed k-uniform family F is a colex initial segment: there exists m such that F = L_k(m).\n\n3) Canonical binomial expansion. Prove existence and uniqueness of the canonical binomial expansion for every m \u2265 0, k \u2265 1. Moreover, show that the colex rank function Rank_k: C(N,k) \u2192 Z_{\u22651} defined by Rank_k(A) = 1 + |{B \u2208 C(N,k) : B <colex A}| satisfies\nRank_k({a_1<\u2026<a_k}) = 1 + \u2211_{t=1}^k C(a_t \u2212 1, t),\nand deduce the standard identity that L_k(m) consists exactly of the k-sets A with \u2211_{t=1}^k C(a_t \u2212 1, t) \u2264 m \u2212 1.\n\n4) Exact shadow of colex initial segments. Let m = C(a_k,k) + \u2026 + C(a_s,s) be the canonical expansion. Prove\n|\u2202 L_k(m)| = C(a_k,k\u22121) + C(a_{k\u22121},k\u22122) + \u2026 + C(a_s,s\u22121).\n(Hint: Split by the maximum element, and use induction with the recursion m = C(a_k,k) + t, 0 \u2264 t < C(a_k,k\u22121).)\n\n5) Kruskal\u2013Katona theorem with equality. Show that for every k-uniform family F with |F| = m,\n|\u2202F| \u2265 |\u2202 L_k(m)|,\nwith equality if and only if F is a colex initial segment (equivalently, F is left-compressed). Conclude that the minimizers are unique up to a permutation of N (which preserves colex).\n\n6) Higher shadows (sharp formula). For t \u2265 1, prove that\n|\u2202^t L_k(m)| = C(a_k,k\u2212t) + C(a_{k\u22121},k\u22121\u2212t) + \u2026 + C(a_s,s\u2212t),\nwith the convention C(u,v) = 0 if v < 0. Deduce the sharp KK bound: For any k-uniform F with |F| = m,\n|\u2202^t F| \u2265 |\u2202^t L_k(m)|.\nExplain how iterating (5) gives (6).\n\nAnswer format:\n- State clearly each intermediate lemma you use and prove it.\n- Your final conclusions must include the exact formulae in (4) and (6), the inequality in (5), and a complete equality characterization.",
        "answer": "The Kruskal\u2013Katona theorem is a fundamental result in extremal set theory, providing a precise characterization of the minimum size of the shadow of a family of sets. Let's go through the steps to prove the theorem and its extensions.\n\n### Step 1: Shadow Monotonicity Under Compressions\n\n**Lemma 1.1:** For any k-uniform family $F$ and any $i < j$, we have $|\\partial(C_{ij}(F))| \\leq |\\partial F|$.\n\n**Proof:** Consider the effect of the compression $C_{ij}$ on a set $A \\in F$. If $j \\in A$ and $i \\notin A$, then $C_{ij}(A) = (A \\setminus \\{j\\}) \\cup \\{i\\}$. The shadow of $A$, $\\partial A$, consists of all $(k-1)$-subsets of $A$. When $A$ is compressed to $C_{ij}(A)$, the shadow of $C_{ij}(A)$ is a subset of the shadow of $A$ because replacing $j$ with $i$ in any subset of $A$ that contains $j$ results in a subset of $C_{ij}(A)$.\n\nThus, the shadow of the compressed family $\\partial(C_{ij}(F))$ is at most the shadow of the original family $\\partial F$.\n\n**Corollary 1.2:** Iterating all compressions yields a left-compressed family $F^*$ with $|F^*| = |F|$ and $|\\partial F^*| \\leq |\\partial F|$.\n\n### Step 2: Left-Compressed Families are Initial Colex Segments\n\n**Lemma 2.1:** Every left-compressed k-uniform family $F$ is a colex initial segment: there exists $m$ such that $F = L_k(m)$.\n\n**Proof:** A left-compressed family is invariant under all $(i,j)$-compressions. This means that for any set $A \\in F$, if a set $B$ with $B <_{\\text{colex}} A$ exists, then $B$ must also be in $F$. This property is precisely the definition of an initial segment in the colex order.\n\n### Step 3: Canonical Binomial Expansion\n\n**Lemma 3.1:** For every $m \\geq 0$ and $k \\geq 1$, there exists a unique canonical binomial expansion $m = C(a_k,k) + C(a_{k-1},k-1) + \\ldots + C(a_s,s)$.\n\n**Proof:** The canonical binomial expansion is constructed by choosing the largest possible $a_k$ such that $C(a_k,k) \\leq m$, then iterating the process for the remainder $m - C(a_k,k)$ with smaller binomial coefficients. The uniqueness follows from the strict decrease condition on the $a_i$.\n\n**Lemma 3.2:** The colex rank function satisfies\n$$ \\text{Rank}_k(\\{a_1 < \\ldots < a_k\\}) = 1 + \\sum_{t=1}^k C(a_t - 1, t). $$\n\n**Proof:** The rank of a set in colex order is determined by counting all sets lexicographically smaller than it, which corresponds to the sum of binomial coefficients as described.\n\n### Step 4: Exact Shadow of Colex Initial Segments\n\n**Lemma 4.1:** Let $m = C(a_k,k) + \\ldots + C(a_s,s)$ be the canonical expansion. Then\n$$ |\\partial L_k(m)| = C(a_k,k-1) + C(a_{k-1},k-2) + \\ldots + C(a_s,s-1). $$\n\n**Proof:** Use induction on $m$. For the base case, consider the smallest $m$ with a given $a_k$. For the inductive step, split by the maximum element and use the recursion $m = C(a_k,k) + t$, $0 \\leq t < C(a_k,k-1)$.\n\n### Step 5: Kruskal\u2013Katona Theorem with Equality\n\n**Theorem 5.1:** For every k-uniform family $F$ with $|F| = m$,\n$$ |\\partial F| \\geq |\\partial L_k(m)|, $$\nwith equality if and only if $F$ is a colex initial segment.\n\n**Proof:** By shadow monotonicity and the fact that left-compressed families are initial colex segments, the minimum shadow size is achieved by $L_k(m)$. Equality holds if and only if $F$ is left-compressed.\n\n### Step 6: Higher Shadows (Sharp Formula)\n\n**Theorem 6.1:** For $t \\geq 1$,\n$$ |\\partial^t L_k(m)| = C(a_k,k-t) + C(a_{k-1},k-1-t) + \\ldots + C(a_s,s-t). $$\n\n**Proof:** Use induction on $t$. The base case $t = 1$ is given by the exact shadow formula. For $t > 1$, apply the shadow operation iteratively, using the structure of the canonical expansion.\n\n**Conclusion:** The Kruskal\u2013Katona theorem provides a complete characterization of the minimum shadow size for k-uniform families, with the minimizers being unique up to a permutation of $N$ that preserves the colex order. The higher shadow formula extends this characterization to iterated shadows."
    },
    "26": {
        "question": "Title: Nielsen\u2013Schreier via Schreier generators \u2014 freeness of subgroups of free groups, the finite-index rank formula, and an explicit congruence-subgroup basis\n\nLet X be a finite nonempty set, |X| = n \u2265 1, and let F = F(X) be the free group on X. We view elements of F as reduced words in the alphabet X \u222a X^{-1}; concatenation followed by free reduction is the group operation. The identity is the empty word.\n\nFor a subgroup H \u2264 F, a left transversal T \u2282 F is a set of representatives containing exactly one element from each left coset Hg (and in particular 1 \u2208 T represents H = H\u00b71). For g \u2208 F, write overline{g} \u2208 T for its T-representative (i.e., H\u00b7overline{g} = H\u00b7g). Say that T is a Schreier transversal if whenever t \u2208 T has a reduced word t = y_1 y_2 \u22ef y_r with y_j \u2208 X \u222a X^{-1}, then each prefix y_1 \u22ef y_j also lies in T.\n\nFor t \u2208 T and a \u2208 X, define the (possibly trivial) element s(t,a) := t a (overline{t a})^{-1} \u2208 H; if t a \u2208 T then s(t,a) = 1. Let S(T,X) := { s(t,a) \u2260 1 : t \u2208 T, a \u2208 X }.\n\nTasks.\n\n1) Schreier rewriting and generation. Prove that for every subgroup H \u2264 F and every left transversal T (not necessarily Schreier), one has s(t,a) \u2208 H for all t \u2208 T, a \u2208 X \u222a X^{-1} (interpreting s(t,a^{-1}) as t a^{-1} (overline{t a^{-1}})^{-1}). Show the Schreier rewriting identity: for any reduced word w = y_1 \u22ef y_m \u2208 F with y_j \u2208 X \u222a X^{-1}, define t_0 := 1 and t_j := overline{y_1 \u22ef y_j} \u2208 T. Then in F,\nw = [\u220f_{j=1}^m u_j] \u00b7 t_m,\nwhere u_j = s(t_{j-1}, y_j) if y_j \u2208 X, and u_j = s(t_j, y_j^{-1})^{-1} if y_j \u2208 X^{-1}. Deduce that if w \u2208 H then w \u2208 \u27e8 S(T,X) \u27e9. Conclude: H is generated by S(T,X) for every left transversal T.\n\n2) Freeness (Nielsen\u2013Schreier). Prove that every subgroup H \u2264 F(X) is a free group. More precisely, show that if T is a Schreier transversal, then S(T,X) is a free basis of H. You must give a complete, self-contained proof; a suggested route is:\n- Construct a map \u03a6: F(S) \u2192 F(X) sending each generator s(t,a) to t a (overline{t a})^{-1}, and show Im \u03a6 = H using (1).\n- Define a \u201cSchreier rewriting\u201d map \u03c1: words in X \u222a X^{-1} \u2192 words in S, as in (1), and prove \u03c1 \u2218 \u03a6 is the identity on F(S). Conclude \u03a6 is injective and hence an isomorphism F(S) \u2245 H, so H is free with free basis S(T,X).\n\n3) Schreier finite-index rank formula. Suppose [F:H] = m < \u221e. Prove that for a Schreier transversal T, the set S(T,X) has cardinality |S(T,X)| = 1 + m (n \u2212 1). Conclude the rank of H is\nrank(H) = 1 + m (n \u2212 1).\nHint: Consider the Schreier coset graph \u0393 with vertex set H\\F (|V(\u0393)| = m) and, for each v \u2208 V(\u0393) and a \u2208 X, an undirected a-labeled edge between v and v\u00b7a. Show \u0393 is connected with exactly m n undirected edges. A spanning tree of \u0393 has m\u22121 edges; argue that the non-tree edges correspond bijectively to generators in S(T,X).\n\n4) Explicit congruence-subgroup basis. Let F_n = \u27e8 x_1, \u2026, x_n \u27e9 be the free group on n generators. For a fixed integer k \u2265 2, define a surjection \u03c6_k: F_n \u2192 Z/kZ by \u03c6_k(x_i) = 1 mod k for all i. Let H_k := ker \u03c6_k.\n- Show [F_n : H_k] = k and hence rank(H_k) = 1 + k (n \u2212 1).\n- Choose the Schreier transversal T = { 1, x_1, x_1^2, \u2026, x_1^{k\u22121} } (a Schreier transversal for H_k), and compute S(T,X). Prove that the following set is a free basis of H_k:\nB = { x_1^k } \u222a { x_1^i x_j x_1^{\u2212(i+1)} : 0 \u2264 i \u2264 k\u22121, 2 \u2264 j \u2264 n }.\nVerify |B| = 1 + k (n \u2212 1) and that \u27e8B\u27e9 = H_k.\n\nAnswer format: Provide a single coherent write-up proving (1)\u2013(4), with all definitions used and all steps justified. You may not invoke topological covering space theory; stay within combinatorial group theory as outlined.",
        "answer": "To solve the problem, we need to address each of the four tasks using combinatorial group theory. Let's go through each task step by step.\n\n### Task 1: Schreier Rewriting and Generation\n\n**Objective:** Prove that for every subgroup $H \\leq F$ and every left transversal $T$, $s(t,a) \\in H$ for all $t \\in T$, $a \\in X \\cup X^{-1}$. Show the Schreier rewriting identity and deduce that $H$ is generated by $S(T,X)$.\n\n1. **Schreier Rewriting Identity:**\n   - For any reduced word $w = y_1 y_2 \\cdots y_m \\in F$, define $t_0 = 1$ and $t_j = \\overline{y_1 \\cdots y_j} \\in T$.\n   - We have $w = [\\prod_{j=1}^m u_j] \\cdot t_m$, where:\n     - $u_j = s(t_{j-1}, y_j)$ if $y_j \\in X$,\n     - $u_j = s(t_j, y_j^{-1})^{-1}$ if $y_j \\in X^{-1}$.\n\n2. **Proof:**\n   - For each $j$, $t_{j-1} y_j = t_j u_j$ in $F$.\n   - Thus, $y_1 y_2 \\cdots y_m = (t_0 y_1) (t_1 y_2) \\cdots (t_{m-1} y_m) = u_1 u_2 \\cdots u_m t_m$.\n\n3. **Deduction:**\n   - If $w \\in H$, then $t_m = 1$ (since $w$ is in the coset $H \\cdot 1$).\n   - Therefore, $w = u_1 u_2 \\cdots u_m \\in \\langle S(T,X) \\rangle$.\n\n4. **Conclusion:**\n   - $H$ is generated by $S(T,X)$ for every left transversal $T$.\n\n### Task 2: Freeness (Nielsen\u2013Schreier)\n\n**Objective:** Prove that every subgroup $H \\leq F(X)$ is a free group. Show that if $T$ is a Schreier transversal, then $S(T,X)$ is a free basis of $H$.\n\n1. **Construct the Map $\\Phi: F(S) \\to F(X)$:**\n   - Define $\\Phi(s(t,a)) = t a (\\overline{t a})^{-1}$.\n   - By Task 1, $\\text{Im}(\\Phi) = H$.\n\n2. **Define Schreier Rewriting Map $\\rho$:**\n   - Map words in $X \\cup X^{-1}$ to words in $S$ using the Schreier rewriting process.\n   - Show $\\rho \\circ \\Phi$ is the identity on $F(S)$.\n\n3. **Injectivity and Isomorphism:**\n   - Since $\\rho \\circ \\Phi$ is the identity, $\\Phi$ is injective.\n   - Thus, $\\Phi$ is an isomorphism $F(S) \\cong H$.\n\n4. **Conclusion:**\n   - $H$ is free with free basis $S(T,X)$.\n\n### Task 3: Schreier Finite-Index Rank Formula\n\n**Objective:** Prove that for a Schreier transversal $T$, the set $S(T,X)$ has cardinality $|S(T,X)| = 1 + m(n - 1)$.\n\n1. **Schreier Coset Graph $\\Gamma$:**\n   - Vertex set $H \\backslash F$ with $|V(\\Gamma)| = m$.\n   - For each $v \\in V(\\Gamma)$ and $a \\in X$, an undirected $a$-labeled edge between $v$ and $v \\cdot a$.\n\n2. **Graph Properties:**\n   - $\\Gamma$ is connected with $m n$ undirected edges.\n   - A spanning tree of $\\Gamma$ has $m - 1$ edges.\n\n3. **Non-Tree Edges:**\n   - Correspond bijectively to generators in $S(T,X)$.\n\n4. **Conclusion:**\n   - $|S(T,X)| = m n - (m - 1) = 1 + m(n - 1)$.\n   - Rank of $H$ is $1 + m(n - 1)$.\n\n### Task 4: Explicit Congruence-Subgroup Basis\n\n**Objective:** Show $[F_n : H_k] = k$ and compute $S(T,X)$ for a specific Schreier transversal.\n\n1. **Index Calculation:**\n   - $\\phi_k: F_n \\to \\mathbb{Z}/k\\mathbb{Z}$ is a surjection.\n   - $[F_n : H_k] = k$.\n\n2. **Schreier Transversal $T = \\{ 1, x_1, x_1^2, \\ldots, x_1^{k-1} \\}$:**\n   - Compute $S(T,X)$.\n\n3. **Free Basis $B$:**\n   - $B = \\{ x_1^k \\} \\cup \\{ x_1^i x_j x_1^{-(i+1)} : 0 \\leq i \\leq k-1, 2 \\leq j \\leq n \\}$.\n\n4. **Verification:**\n   - $|B| = 1 + k(n - 1)$.\n   - $\\langle B \\rangle = H_k$.\n\nBy following these steps, we have shown the required properties and constructions for each task, demonstrating the freeness of subgroups of free groups and providing explicit bases for congruence subgroups."
    },
    "27": {
        "question": "Title: The algorithmic Lov\u00e1sz Local Lemma \u00e0 la Moser\u2013Tardos, with witness trees and two sharp applications (sparse k-CNF satisfiability and 2-colorability of k-uniform hypergraphs)\n\nLet X = (X_1,\u2026,X_n) be a finite family of mutually independent random variables, each taking values in some finite set, distributed according to the product measure. A bad event A is any event determined by the values of a subset var(A) \u2286 {X_1,\u2026,X_n}. For two bad events A,B we write A \u223c B if var(A) \u2229 var(B) \u2260 \u2205 and call G the dependency graph on the set of bad events with edge-set E(G) = { {A,B} : A \u223c B }. For A, write \u0393(A) for its open neighborhood {B: B \u223c A}, and \u0393\u207a(A) := \u0393(A) \u222a {A} for the closed neighborhood.\n\nWe consider the Moser\u2013Tardos resampling algorithm on a finite family of bad events F = {A_1,\u2026,A_m}: draw an initial product sample \u03c9 of the variables; while some A \u2208 F is true under the current assignment, pick any such A and resample freshly and independently all variables in var(A), leaving all other variables unchanged; repeat until no bad event holds.\n\nProblem (self-contained). Prove the following in order.\n\n1) Witness trees and the witness-tree lemma. For a fixed execution of the algorithm and for each resampling step t (the t-th resampled bad event is denoted R_t), define the witness tree T_t as follows. T_t is a rooted, vertex-labeled tree whose root is labeled by R_t. Process earlier resamplings in reverse time s = t\u22121,t\u22122,\u2026,1; if R_s is not adjacent in G to any current label in T_t, skip it; otherwise attach a new node labeled R_s as a child of the deepest already placed vertex whose label is adjacent to R_s in G. Prove:\n   a) Every T_t is proper: along each edge parent\u2013child the two labels are adjacent in G; siblings have distinct labels; and every label appears finitely often.\n   b) (Witness-tree lemma) For any fixed proper witness tree T (with specified labels from F), the probability that T occurs as T_t for some step t of the algorithm is at most \u220f_{v\u2208V(T)} P(label(v)).\n\n   Hint: Work with a resampling table: for each variable X_i fix an infinite i.i.d. stack (X_i(1), X_i(2),\u2026) of samples; the run is determined by these stacks; the event that a given T occurs depends only on disjoint blocks of these stacks and factors as a product.\n\n2) Algorithmic Local Lemma (Moser\u2013Tardos). Suppose that to every bad event A \u2208 F we assign a real x(A) \u2208 (0,1) such that\n   P(A) \u2264 x(A) \u220f_{B\u2208\u0393\u207a(A)} (1 \u2212 x(B)).\n   Prove that the Moser\u2013Tardos algorithm terminates almost surely and that the expected number of resamplings of any fixed bad event A is at most x(A)/(1 \u2212 x(A)). In particular, the expected total number of resamplings is at most \u2211_{A\u2208F} x(A)/(1 \u2212 x(A)).\n\n   You must give a complete proof from (1): enumerate witness trees rooted at A, bound their probabilities via (1b), and dominate their total weight by a Galton\u2013Watson\u2013type branching process on the closed neighborhoods \u0393\u207a(\u00b7). You may reparameterize via \u03bc(A) := x(A)/(1 \u2212 x(A)) if convenient.\n\n3) Application 1 \u2014 sparse k-CNF is satisfiable. Consider a CNF formula on boolean variables with m clauses, each clause containing exactly k distinct literals (k \u2265 2). Suppose each clause shares variables with at most d other clauses (i.e., in the dependency graph each vertex has degree \u2264 d). Show that if\n   e \u00b7 2^{\u2212k} \u00b7 (d + 2) \u2264 1,\n   then the formula is satisfiable. Moreover, the Moser\u2013Tardos algorithm finds a satisfying assignment in expected O(m) resamplings. Your constants must be explicit: choose a single x \u2208 (0,1) for all clauses, optimize x(1 \u2212 x)^{d+1}, and conclude.\n\n4) Application 2 \u2014 2-colorability of k-uniform hypergraphs. Let H be a k-uniform hypergraph (each edge has size k). Assume the maximum edge-degree \u0394 is such that every edge intersects at most \u0394 other edges. Show that if\n   e \u00b7 2^{1\u2212k} \u00b7 (\u0394 + 2) \u2264 1,\n   then H admits a proper 2-coloring (of vertices) with no monochromatic edges. Again, argue via the algorithmic LLL under the random 2-coloring of vertices, and conclude that the Moser\u2013Tardos algorithm that resamples the colors of the vertices of any currently monochromatic edge terminates in expected O(|E(H)|) resamplings.\n\nAnswer format:\n- State and prove (1a) and (1b) rigorously, with the resampling-table model.\n- Prove (2) completely: derive the resampling bounds via the branching process on \u0393\u207a(\u00b7) and summing over witness trees; deduce almost-sure termination from finiteness of the expectation.\n- Prove (3) with explicit numerical choices, giving the expected-resampling bound O(m).\n- Prove (4) analogously with explicit constants and expected-resampling bound O(|E(H)|).",
        "answer": "To solve this problem, we need to address each part systematically, using the Moser\u2013Tardos framework and the Lov\u00e1sz Local Lemma (LLL). Let's go through each part:\n\n### 1) Witness Trees and the Witness-Tree Lemma\n\n#### 1a) Proving that Every $T_t$ is Proper\n\n- **Parent-Child Adjacency**: By construction, each edge in the witness tree $T_t$ connects a parent node to a child node where the labels of these nodes are adjacent in the dependency graph $G$. This is ensured because we only attach a node $R_s$ to the deepest node in $T_t$ that is adjacent to $R_s$.\n\n- **Distinct Siblings**: Siblings in $T_t$ are distinct because when we attach a new node $R_s$, it is only attached if it is adjacent to some node already in the tree, and we process resamplings in reverse order, ensuring no duplication at the same level.\n\n- **Finite Occurrences**: Each label appears finitely often because the algorithm terminates almost surely, and each resampling step corresponds to a finite number of bad events.\n\n#### 1b) Witness-Tree Lemma\n\n- **Probability Bound**: For a fixed proper witness tree $T$, the probability that $T$ occurs as $T_t$ is at most $\\prod_{v \\in V(T)} P(\\text{label}(v))$.\n\n- **Proof**: Use the resampling table model. For each variable $X_i$, fix an infinite i.i.d. stack of samples. The occurrence of a specific witness tree $T$ depends on disjoint blocks of these stacks, corresponding to the resampling steps. The probability of $T$ occurring factors as a product of probabilities of the labels, since each resampling is independent and determined by the product measure.\n\n### 2) Algorithmic Local Lemma (Moser\u2013Tardos)\n\n- **Termination and Expected Resamplings**: Given $P(A) \\leq x(A) \\prod_{B \\in \\Gamma^+(A)} (1 - x(B))$, we need to show the algorithm terminates almost surely and bound the expected number of resamplings.\n\n- **Witness Tree Enumeration**: Enumerate witness trees rooted at a bad event $A$. The probability of each tree is bounded by the product of probabilities of its labels, as per the witness-tree lemma.\n\n- **Branching Process**: Model the growth of witness trees as a Galton\u2013Watson process with offspring distribution determined by the closed neighborhood $\\Gamma^+(A)$. The expected number of offspring is less than 1 due to the LLL condition, ensuring the process dies out almost surely.\n\n- **Expected Resamplings**: The expected number of resamplings of a fixed bad event $A$ is at most $\\mu(A) = x(A)/(1 - x(A))$. Summing over all bad events gives the total expected resamplings as $\\sum_{A \\in F} \\mu(A)$.\n\n### 3) Application 1 \u2014 Sparse $k$-CNF Satisfiability\n\n- **Condition**: $e \\cdot 2^{-k} \\cdot (d + 2) \\leq 1$.\n\n- **Choice of $x$**: Set $x = 2^{-k}$. Then $x(1 - x)^{d+1}$ is optimized under the given condition.\n\n- **Expected Resamplings**: The expected number of resamplings is $O(m)$ because each clause is resampled at most $\\mu(A) = x/(1-x)$ times in expectation, and there are $m$ clauses.\n\n### 4) Application 2 \u2014 2-Colorability of $k$-Uniform Hypergraphs\n\n- **Condition**: $e \\cdot 2^{1-k} \\cdot (\\Delta + 2) \\leq 1$.\n\n- **Random 2-Coloring**: Initially color vertices randomly. The probability of a monochromatic edge is $2^{1-k}$.\n\n- **Expected Resamplings**: The expected number of resamplings is $O(|E(H)|)$ because each edge is resampled at most $\\mu(A) = x/(1-x)$ times in expectation, where $x = 2^{1-k}$.\n\nIn both applications, the Moser\u2013Tardos algorithm efficiently finds a satisfying assignment or coloring by leveraging the LLL conditions and the structure of the dependency graph."
    },
    "28": {
        "question": "Title: Sperner\u2019s lemma in all dimensions, Brouwer\u2019s fixed point theorem for simplices, and the no-retraction corollary\n\nLet d \u2265 1 be an integer. Identify the standard d-simplex with\n\u0394^d := { x = (x_0,\u2026,x_d) \u2208 R^{d+1} : x_i \u2265 0 for all i and \u2211_{i=0}^d x_i = 1 }.\nFor 0 \u2264 i \u2264 d, its i-th facet (codimension-1 face) is F_i := { x \u2208 \u0394^d : x_i = 0 }.\n\nA triangulation T of \u0394^d is a finite simplicial complex whose underlying polyhedron |T| equals \u0394^d. We say T is fine if max_{\u03c3\u2208T, dim \u03c3=d} diam(\u03c3) is sufficiently small; we will use arbitrarily fine triangulations of \u0394^d.\n\nA Sperner labeling on T is a map \u2113 that assigns to each vertex v of T a label \u2113(v) \u2208 {0,1,\u2026,d} such that if v \u2208 F_i then \u2113(v) \u2260 i (i.e., on each boundary facet F_i, the forbidden label i does not appear).\n\nA d-simplex \u03c3 \u2208 T (i.e., a facet of dimension d) is fully labeled if its vertices receive all d+1 distinct labels {0,1,\u2026,d}.\n\nProblem. Prove the following three statements completely and self-contained.\n\n1) Sperner\u2019s lemma with parity. For every triangulation T of \u0394^d with a Sperner labeling \u2113, the number of fully labeled d-simplices is odd (in particular, \u2265 1).\n\n2) Brouwer\u2019s fixed point theorem on \u0394^d via Sperner. Let f: \u0394^d \u2192 \u0394^d be continuous. Prove that there exists x \u2208 \u0394^d with f(x) = x. Your proof must proceed by:\n   - Choosing a sequence of triangulations T_n whose mesh tends to 0.\n   - Defining on each T_n a Sperner labeling by the rule: for a vertex v, pick any label i with v_i > f_i(v). Prove that such a label exists for every vertex v, and that on F_i the label i is indeed forbidden, so this is a valid Sperner labeling.\n   - Using (1) to find a fully labeled d-simplex \u03c3_n in each T_n, and showing that the unique accumulation point x of these simplices satisfies f(x) = x.\n\n3) No-retraction corollary. Show that there is no continuous retraction r: \u0394^d \u2192 \u2202\u0394^d (that is, a continuous map with r(x) = x for all x \u2208 \u2202\u0394^d). Deduce this from (2) by constructing a continuous map F: \u0394^d \u2192 \u0394^d with no fixed point if such an r existed, thereby contradicting Brouwer\u2019s fixed point theorem from (2).\n\nAnswer format:\n- Prove (1) first (for all d), giving a rigorous parity argument.\n- Then prove (2) in full detail as outlined.\n- Finally, deduce (3) from (2) by an explicit fixed-point-free construction.",
        "answer": "To solve this problem, we will address each of the three statements in turn, providing a complete and self-contained proof for each.\n\n### 1) Sperner\u2019s Lemma with Parity\n\n**Statement:** For every triangulation $T$ of $\\Delta^d$ with a Sperner labeling $\\ell$, the number of fully labeled $d$-simplices is odd.\n\n**Proof:**\n\n- **Base Case (d = 1):** Consider the 1-simplex (a line segment) $\\Delta^1 = [0, 1]$. A triangulation of $\\Delta^1$ is a division into smaller segments. A Sperner labeling assigns labels 0 or 1 to each vertex such that the vertex at 0 cannot be labeled 0 and the vertex at 1 cannot be labeled 1. The fully labeled 1-simplex is one where the endpoints are labeled 0 and 1. There must be an odd number of such segments because the labels must alternate along the line, starting with 0 and ending with 1.\n\n- **Inductive Step:** Assume the lemma holds for dimension $d-1$. Consider a triangulation $T$ of $\\Delta^d$ with a Sperner labeling. Each $(d-1)$-simplex on the boundary $\\partial \\Delta^d$ satisfies the lemma by the inductive hypothesis.\n\n  Consider the boundary $\\partial \\Delta^d$, which is the union of the facets $F_i$. Each $F_i$ is a $(d-1)$-simplex, and by the inductive hypothesis, the number of fully labeled $(d-1)$-simplices on each $F_i$ is odd.\n\n  Now, consider the entire $d$-simplex $\\Delta^d$. Each fully labeled $d$-simplex contributes to the parity of the fully labeled $(d-1)$-simplices on its boundary. The key observation is that each fully labeled $d$-simplex contributes exactly one to the count of fully labeled $(d-1)$-simplices on its boundary, and this contribution is consistent with the parity of the entire boundary.\n\n  Therefore, the number of fully labeled $d$-simplices must be odd, as it must account for the odd parity of the fully labeled $(d-1)$-simplices on the boundary.\n\n### 2) Brouwer\u2019s Fixed Point Theorem on $\\Delta^d$ via Sperner\n\n**Statement:** Let $f: \\Delta^d \\to \\Delta^d$ be continuous. There exists $x \\in \\Delta^d$ with $f(x) = x$.\n\n**Proof:**\n\n- **Triangulations:** Choose a sequence of triangulations $T_n$ of $\\Delta^d$ such that the mesh of $T_n$ tends to 0 as $n \\to \\infty$.\n\n- **Sperner Labeling:** Define a Sperner labeling on each $T_n$ as follows: for a vertex $v$, pick any label $i$ such that $v_i > f_i(v)$. Such a label exists because $\\sum_{i=0}^d v_i = 1$ and $\\sum_{i=0}^d f_i(v) = 1$, so there must be some $i$ with $v_i > f_i(v)$.\n\n  On the facet $F_i$, $v_i = 0$, so $v_i > f_i(v)$ cannot hold, ensuring that label $i$ is forbidden on $F_i$.\n\n- **Application of Sperner\u2019s Lemma:** By Sperner\u2019s lemma, each $T_n$ has at least one fully labeled $d$-simplex $\\sigma_n$.\n\n- **Convergence:** As the mesh of $T_n$ tends to 0, the barycenters of the fully labeled simplices $\\sigma_n$ form a sequence in $\\Delta^d$. By compactness, this sequence has a convergent subsequence with limit $x$.\n\n- **Fixed Point:** At the limit point $x$, we have $f(x) = x$ because the labeling condition $v_i > f_i(v)$ cannot hold in the limit for any $i$.\n\n### 3) No-Retraction Corollary\n\n**Statement:** There is no continuous retraction $r: \\Delta^d \\to \\partial \\Delta^d$.\n\n**Proof:**\n\n- **Assume for Contradiction:** Suppose there exists a retraction $r: \\Delta^d \\to \\partial \\Delta^d$.\n\n- **Construct a Map $F: \\Delta^d \\to \\Delta^d$:** Define $F(x) = r(x)$ for $x \\in \\Delta^d$. Note that $F(x) = x$ for $x \\in \\partial \\Delta^d$.\n\n- **Fixed Point-Free:** Since $r(x) \\in \\partial \\Delta^d$ for all $x$, $F(x) \\neq x$ for any $x \\in \\Delta^d \\setminus \\partial \\Delta^d$.\n\n- **Contradiction:** This contradicts Brouwer\u2019s fixed point theorem, which asserts that any continuous map from $\\Delta^d$ to itself must have a fixed point. Therefore, no such retraction $r$ can exist.\n\nThis completes the proof of all three statements."
    },
    "29": {
        "question": "Title: Farkas\u2019 lemma to max\u2013flow=min\u2013cut and bipartite matching \u2014 a complete, self-contained development via duality and total unimodularity\n\nLet R^n be equipped with the standard inner product x\u00b7y = \u2211 x_i y_i and norm ||x|| = \u221a(x\u00b7x). For a matrix A \u2208 R^{m\u00d7n} and vector b \u2208 R^m, write K(A) := {A x : x \u2208 R^n, x \u2265 0} for the finitely generated (polyhedral) cone spanned by A\u2019s columns. For a directed graph G = (V,E) with a chosen orientation of each arc, the node\u2013arc incidence matrix B \u2208 R^{V\u00d7E} is defined by B_{v,e} = +1 if e leaves v, B_{v,e} = \u22121 if e enters v, and B_{v,e} = 0 otherwise. A matrix is totally unimodular (TU) if every square subdeterminant is in {\u22121, 0, 1}.\n\nProblem (hard, self-contained). Prove, in order, the following:\n\n1) Farkas\u2019 lemma (conic form) via Euclidean projection. For A \u2208 R^{m\u00d7n} and b \u2208 R^m, prove the exact alternative:\n   Exactly one of the following holds:\n   (F1) There exists x \u2208 R^n with x \u2265 0 and A x = b.\n   (F2) There exists y \u2208 R^m with y^T A \u2265 0 (entrywise) and y^T b < 0.\n   Your proof must be complete and self-contained. You may use only basic facts about convexity and the Euclidean projection onto a nonempty closed convex set in R^m (existence and the characterization by orthogonality of the residual).\n\n   Then deduce the \u201cmixed-constraint\u201d corollary: For A \u2208 R^{m\u00d7n}, c \u2208 R^n, b \u2208 R^m, \u03b1 \u2208 R, exactly one holds:\n   (G1) \u2203 x \u2265 0 with A x \u2264 b and c^T x \u2265 \u03b1.\n   (G2) \u2203 y \u2265 0 and \u03bb \u2265 0 with A^T y \u2212 \u03bb c \u2265 0 and y^T b \u2212 \u03bb \u03b1 < 0.\n\n2) Linear programming duality (weak and strong) and complementary slackness. Consider the primal\u2013dual pair\n   (P) max c^T x subject to A x \u2264 b, x \u2265 0,\n   (D) min b^T y subject to A^T y \u2265 c, y \u2265 0.\n   Prove weak duality c^T x \u2264 b^T y for any primal-feasible x and dual-feasible y.\n\n   Using (1), prove strong duality of optimal values: If (P) is feasible and has finite optimal value \u03b2, then\n   sup{c^T x : A x \u2264 b, x \u2265 0} = inf{b^T y : A^T y \u2265 c, y \u2265 0}.\n   Show also the complementary slackness conditions: if x* and y* are optimal for (P) and (D), then\n   for each i, y*_i (b_i \u2212 a_i^T x*) = 0; for each j, x*_j ((A^T y* \u2212 c)_j) = 0.\n   Conclude that c^T x* = b^T y*.\n\n3) Max\u2013flow = min\u2013cut via LP duality and a thresholding argument. Let G = (V,E) be a finite directed graph, s,t \u2208 V distinct, and capacities u_e \u2265 0 on arcs e \u2208 E. A (feasible) s\u2013t flow is f \u2208 R^E with 0 \u2264 f_e \u2264 u_e for all e and flow-conservation B f = F d, where F is the flow value and d \u2208 R^V has d_s = 1, d_t = \u22121, d_v = 0 otherwise. The max-flow LP is\n   (MF) maximize F over (f,F) subject to B f \u2212 F d = 0 and 0 \u2264 f \u2264 u.\n   Derive the dual LP and reduce it to\n   (MC) minimize \u2211_{e=(u,v)} u_e max(0, y_u \u2212 y_v) over y \u2208 R^V with y_s \u2212 y_t = 1.\n   Prove that for any feasible y, the integral \u201cthresholding\u201d family S_\u03bb := {v : y_v \u2265 \u03bb} (\u03bb \u2208 R) yields\n   \u2211_e u_e max(0, y_u \u2212 y_v) = \u222b_{\u2212\u221e}^{+\u221e} cap(S_\u03bb) d\u03bb,\n   where cap(S) := \u2211_{(u,v)\u2208E, u\u2208S, v\u2209S} u_{(u,v)} is the capacity of the directed cut (S, S^c).\n   Deduce there exists \u03bb with cap(S_\u03bb) \u2264 the dual objective at y; hence the dual optimum equals min_s,t cap(S, S^c), and strong duality gives the max\u2013flow=min\u2013cut theorem:\n   max flow value = min capacity of an s\u2013t cut.\n\n4) Total unimodularity of incidence matrices and integral flows. Prove:\n   a) The node\u2013arc incidence matrix B of any directed graph is TU. Conclude that any square submatrix of B has determinant in {\u22121,0,1}.\n   b) Show that adjoining identity rows preserves TU: if M is TU, then the block matrix [M; I] is TU. Conclude that the constraint matrix of (MF) in equality form (after adding standard slack variables for 0 \u2264 f \u2264 u) is TU.\n   c) Deduce that if all capacities u_e are integers, then there exists an optimal max flow with integer arc-values f_e \u2208 Z for all e.\n\n5) Bipartite matching: K\u0151nig\u2013Eg\u00e9rv\u00e1ry and Hall\u2019s theorem. Let G = (U,V;E) be a bipartite graph. A matching M \u2282 E is a set of disjoint edges; its size is |M|. A vertex cover is C \u2282 U\u222aV meeting every edge; its size is |C|.\n   a) LP formulation. Let A \u2208 {0,1}^{(U\u222aV)\u00d7E} be the vertex\u2013edge incidence matrix (A_{w,e} = 1 iff w incident to e). Consider\n      (PM) max \u2211_{e\u2208E} x_e subject to A x \u2264 1, x \u2265 0,\n      (DM) min \u2211_{w\u2208U\u222aV} y_w subject to A^T y \u2265 1, y \u2265 0.\n      Prove that if G is bipartite then A is TU (hint: multiply all V-rows by \u22121 to get a node\u2013arc incidence of an orientation, then use (4a)). Conclude that both (PM) and (DM) admit optimal integral solutions.\n   b) K\u0151nig\u2013Eg\u00e9rv\u00e1ry. Deduce that for bipartite G, the maximum size of a matching equals the minimum size of a vertex cover:\n      \u03bd(G) = \u03c4(G).\n   c) Hall\u2019s marriage theorem. Prove: G has a matching saturating U if and only if for every S \u2286 U one has |N(S)| \u2265 |S|. Derive the \u201conly if\u201d by pigeonhole. For the \u201cif\u201d direction, use (b): if a maximum matching does not saturate U, then \u03c4(G) = \u03bd(G) < |U|, so a minimum vertex cover C has |C| < |U|; set S = U \\ (C\u2229U) and show |N(S)| \u2264 |C\u2229V| = |C| \u2212 |C\u2229U| < |U| \u2212 |C\u2229U| = |S|, contradicting Hall\u2019s condition.\n\nAnswer format:\n- Present complete proofs for (1)\u2013(5) in order, fully justifying each step and identity, and explicitly deriving the duals.\n- In (3), give the thresholding argument carefully (as an integral identity over \u03bb) and show how it produces a 0\u20131 potential realizing a cut.\n- In (4), prove TU of B by a self-contained determinant argument and explain why adding identity preserves TU.\n- In (5), explicitly identify the integral optimal solutions as matchings and vertex covers, and give the Hall corollary rigorously.",
        "answer": "This is a comprehensive and advanced problem set that involves several key concepts in linear programming, graph theory, and combinatorial optimization. I'll provide a structured approach to solving each part of the problem, ensuring that each step is justified and explained.\n\n### 1) Farkas' Lemma (Conic Form)\n\n**Proof of Farkas' Lemma:**\n\nTo prove Farkas' lemma, we need to show that exactly one of the following holds for a matrix $A \\in \\mathbb{R}^{m \\times n}$ and vector $b \\in \\mathbb{R}^m$:\n\n- (F1) There exists $x \\in \\mathbb{R}^n$ with $x \\geq 0$ and $A x = b$.\n- (F2) There exists $y \\in \\mathbb{R}^m$ with $y^T A \\geq 0$ (entrywise) and $y^T b < 0$.\n\n**Proof:**\n\n1. **Existence of Euclidean Projection:**\n   Consider the set $K(A) = \\{ A x : x \\geq 0 \\}$, which is a polyhedral cone. The Euclidean projection of $b$ onto $K(A)$ is the point $\\hat{b} \\in K(A)$ such that $\\| b - \\hat{b} \\|$ is minimized.\n\n2. **Characterization by Orthogonality:**\n   The projection $\\hat{b}$ satisfies the orthogonality condition: $(b - \\hat{b})^T (A x) \\leq 0$ for all $x \\geq 0$.\n\n3. **Case Analysis:**\n   - If $b \\in K(A)$, then $\\hat{b} = b$ and there exists $x \\geq 0$ such that $A x = b$, satisfying (F1).\n   - If $b \\notin K(A)$, then $\\hat{b} \\neq b$ and the orthogonality condition implies there exists $y = b - \\hat{b}$ such that $y^T A \\geq 0$ and $y^T b < 0$, satisfying (F2).\n\n**Mixed-Constraint Corollary:**\n\nFor $A \\in \\mathbb{R}^{m \\times n}$, $c \\in \\mathbb{R}^n$, $b \\in \\mathbb{R}^m$, and $\\alpha \\in \\mathbb{R}$, exactly one holds:\n\n- (G1) $\\exists x \\geq 0$ with $A x \\leq b$ and $c^T x \\geq \\alpha$.\n- (G2) $\\exists y \\geq 0$ and $\\lambda \\geq 0$ with $A^T y - \\lambda c \\geq 0$ and $y^T b - \\lambda \\alpha < 0$.\n\n**Proof:**\n\n1. **Reduction to Farkas' Lemma:**\n   Consider the augmented system $A' = [A; -c^T]$ and $b' = [b; -\\alpha]$. Apply Farkas' lemma to this system.\n\n2. **Case Analysis:**\n   - If (G1) holds, then there exists $x \\geq 0$ such that $A x \\leq b$ and $c^T x \\geq \\alpha$.\n   - If (G2) holds, then there exists $y \\geq 0$ and $\\lambda \\geq 0$ such that $A^T y - \\lambda c \\geq 0$ and $y^T b - \\lambda \\alpha < 0$.\n\n### 2) Linear Programming Duality\n\n**Weak Duality:**\n\nFor any primal-feasible $x$ and dual-feasible $y$, we have $c^T x \\leq b^T y$.\n\n**Proof:**\n\n1. **Feasibility Conditions:**\n   - Primal feasibility: $A x \\leq b$, $x \\geq 0$.\n   - Dual feasibility: $A^T y \\geq c$, $y \\geq 0$.\n\n2. **Inequality Derivation:**\n   $$\n   c^T x \\leq y^T A x \\leq y^T b\n   $$\n   The first inequality follows from $A^T y \\geq c$, and the second from $A x \\leq b$.\n\n**Strong Duality:**\n\nIf (P) is feasible and has finite optimal value $\\beta$, then\n$$\n\\sup \\{ c^T x : A x \\leq b, x \\geq 0 \\} = \\inf \\{ b^T y : A^T y \\geq c, y \\geq 0 \\}.\n$$\n\n**Proof:**\n\n1. **Existence of Optimal Solutions:**\n   By Farkas' lemma and the mixed-constraint corollary, if (P) is feasible, then (D) is also feasible.\n\n2. **Complementary Slackness:**\n   If $x^*$ and $y^*$ are optimal for (P) and (D), then:\n   - $y^*_i (b_i - a_i^T x^*) = 0$ for each $i$.\n   - $x^*_j ((A^T y^* - c)_j) = 0$ for each $j$.\n\n3. **Equality of Optimal Values:**\n   Using complementary slackness, $c^T x^* = b^T y^*$.\n\n### 3) Max\u2013Flow = Min\u2013Cut\n\n**Max-Flow LP:**\n\n(MF) Maximize $F$ over $(f, F)$ subject to $B f - F d = 0$ and $0 \\leq f \\leq u$.\n\n**Dual LP:**\n\n1. **Formulation:**\n   The dual of (MF) is:\n   $$\n   \\text{(MC) Minimize } \\sum_{e=(u,v)} u_e \\max(0, y_u - y_v) \\text{ over } y \\in \\mathbb{R}^V \\text{ with } y_s - y_t = 1.\n   $$\n\n2. **Thresholding Argument:**\n   For any feasible $y$, define $S_\\lambda = \\{ v : y_v \\geq \\lambda \\}$. Then:\n   $$\n   \\sum_e u_e \\max(0, y_u - y_v) = \\int_{-\\infty}^{+\\infty} \\text{cap}(S_\\lambda) \\, d\\lambda\n   $$\n\n3. **Existence of Optimal Cut:**\n   There exists $\\lambda$ such that $\\text{cap}(S_\\lambda) \\leq$ the dual objective at $y$.\n\n4. **Strong Duality:**\n   By strong duality, max flow value = min capacity of an $s$-$t$ cut.\n\n### 4) Total Unimodularity of Incidence Matrices\n\n**Proof of TU for Node\u2013Arc Incidence Matrix $B$:**\n\n1. **Determinant Argument:**\n   Show that every square submatrix of $B$ has determinant in $\\{-1, 0, 1\\}$.\n\n2. **Preservation by Identity:**\n   If $M$ is TU, then the block matrix $[M; I]$ is TU.\n\n3. **Application to Max-Flow:**\n   The constraint matrix of (MF) in equality form is TU, ensuring integer solutions for integer capacities.\n\n### 5) Bipartite Matching: K\u0151nig\u2013Eg\u00e9rv\u00e1ry and Hall\u2019s Theorem\n\n**LP Formulation:**\n\n1. **Vertex\u2013Edge Incidence Matrix $A$:**\n   For bipartite $G$, $A$ is TU.\n\n2. **Integral Solutions:**\n   Both (PM) and (DM) admit optimal integral solutions.\n\n**K\u0151nig\u2013Eg\u00e9rv\u00e1ry Theorem:**\n\n1. **Equality of Matching and Vertex Cover:**\n   For bipartite $G$, the maximum size of a matching equals the minimum size of a vertex cover: $\\nu(G) = \\tau(G)$.\n\n**Hall\u2019s Marriage Theorem:**\n\n1. **Saturating Matching:**\n   $G$ has a matching saturating $U$ if and only if for every $S \\subseteq U$, $|N(S)| \\geq |S|$.\n\n2. **Proof:**\n   - \"Only if\" by pigeonhole principle.\n   - \"If\" by contradiction using K\u0151nig\u2013Eg\u00e9rv\u00e1ry: if a maximum matching does not saturate $U$, then $\\tau(G) = \\nu(G) < |U|$.\n\nThis structured approach provides a comprehensive solution to the problem set, covering each aspect of the theory and its applications."
    }
}