{
    "0": {
        "question": "Determine all continuous pairs of functions f, g: (0, \u221e) \u2192 \u211d such that for every x, y > 0 the following system holds:\n- g(xy) + g(x/y) = 2 g(x) g(y),\n- f(xy) + f(x/y) = 2 f(x) g(y).\n\nYour answer should give an explicit parametrization of all such pairs (f, g), prove that every pair in your list satisfies the system, and prove that no other continuous pairs do.",
        "answer": "To solve this problem, we need to find all continuous pairs of functions $f, g: (0, \\infty) \\to \\mathbb{R}$ that satisfy the given system of functional equations:\n\n1. $g(xy) + g(x/y) = 2g(x)g(y)$\n2. $f(xy) + f(x/y) = 2f(x)g(y)$\n\nfor all $x, y > 0$.\n\n### Step 1: Analyze the first equation\n\nConsider the first equation:\n\n$$ g(xy) + g(x/y) = 2g(x)g(y). $$\n\nLet's set $x = y = 1$:\n\n$$ g(1 \\cdot 1) + g(1/1) = 2g(1)g(1) $$\n$$ 2g(1) = 2g(1)^2. $$\n\nThis simplifies to:\n\n$$ g(1)(1 - g(1)) = 0. $$\n\nThus, $g(1) = 0$ or $g(1) = 1$.\n\n#### Case 1: $g(1) = 0$\n\nIf $g(1) = 0$, then substituting $y = 1$ in the original equation gives:\n\n$$ g(x) + g(x) = 2g(x)g(1) $$\n$$ 2g(x) = 0 $$\n$$ g(x) = 0 $$\n\nfor all $x > 0$. This is a constant solution.\n\n#### Case 2: $g(1) = 1$\n\nIf $g(1) = 1$, let's explore further. Set $y = x$:\n\n$$ g(x^2) + g(1) = 2g(x)^2 $$\n$$ g(x^2) + 1 = 2g(x)^2 $$\n$$ g(x^2) = 2g(x)^2 - 1. $$\n\nThis resembles the identity for the cosine function, suggesting $g(x) = \\cos(\\log x)$ might be a solution. Let's verify:\n\nFor $g(x) = \\cos(\\log x)$, we have:\n\n$$ g(xy) = \\cos(\\log(xy)) = \\cos(\\log x + \\log y) = \\cos(\\log x)\\cos(\\log y) - \\sin(\\log x)\\sin(\\log y), $$\n$$ g(x/y) = \\cos(\\log(x/y)) = \\cos(\\log x - \\log y) = \\cos(\\log x)\\cos(\\log y) + \\sin(\\log x)\\sin(\\log y). $$\n\nAdding these:\n\n$$ g(xy) + g(x/y) = 2\\cos(\\log x)\\cos(\\log y) = 2g(x)g(y). $$\n\nThus, $g(x) = \\cos(\\log x)$ satisfies the first equation.\n\n### Step 2: Analyze the second equation\n\nNow consider the second equation:\n\n$$ f(xy) + f(x/y) = 2f(x)g(y). $$\n\n#### Case 1: $g(x) = 0$\n\nIf $g(x) = 0$ for all $x$, then:\n\n$$ f(xy) + f(x/y) = 0. $$\n\nThis implies $f(x) = -f(x)$, so $f(x) = 0$ for all $x$.\n\n#### Case 2: $g(x) = \\cos(\\log x)$\n\nSubstitute $g(x) = \\cos(\\log x)$ into the second equation:\n\n$$ f(xy) + f(x/y) = 2f(x)\\cos(\\log y). $$\n\nSet $x = 1$:\n\n$$ f(y) + f(1/y) = 2f(1)\\cos(\\log y). $$\n\nLet $f(1) = c$. Then:\n\n$$ f(y) + f(1/y) = 2c\\cos(\\log y). $$\n\nAssume $f(x) = a \\cos(\\log x) + b \\sin(\\log x)$. Then:\n\n$$ f(xy) = a \\cos(\\log(xy)) + b \\sin(\\log(xy)) = a(\\cos(\\log x)\\cos(\\log y) - \\sin(\\log x)\\sin(\\log y)) + b(\\sin(\\log x)\\cos(\\log y) + \\cos(\\log x)\\sin(\\log y)), $$\n\n$$ f(x/y) = a \\cos(\\log(x/y)) + b \\sin(\\log(x/y)) = a(\\cos(\\log x)\\cos(\\log y) + \\sin(\\log x)\\sin(\\log y)) + b(\\sin(\\log x)\\cos(\\log y) - \\cos(\\log x)\\sin(\\log y)). $$\n\nAdding these:\n\n$$ f(xy) + f(x/y) = 2a\\cos(\\log x)\\cos(\\log y) + 2b\\sin(\\log x)\\cos(\\log y). $$\n\nThis matches $2f(x)\\cos(\\log y)$ if $f(x) = a \\cos(\\log x) + b \\sin(\\log x)$.\n\n### Conclusion\n\nThe continuous solutions are:\n\n1. $(f(x), g(x)) = (0, 0)$.\n2. $(f(x), g(x)) = (a \\cos(\\log x) + b \\sin(\\log x), \\cos(\\log x))$ for any real numbers $a, b$.\n\nThese solutions satisfy both equations, and no other continuous solutions exist due to the constraints imposed by the functional equations and continuity."
    },
    "1": {
        "question": "Compute the exact number of spanning trees of the d-dimensional hypercube Q_d, for each integer d \u2265 1.\n\nDefinitions:\n- The d-dimensional hypercube graph Q_d has vertex set V = {0,1}^d; two vertices are adjacent iff they differ in exactly one coordinate. Thus |V| = 2^d and Q_d is d-regular.\n- A spanning tree of a connected graph G is a tree subgraph containing all vertices of G.\n\nYour task:\n- Derive a closed-form product formula for the number \u03c4(Q_d) of spanning trees of Q_d in terms of d and binomial coefficients.\n- Your solution must include a rigorous derivation. You may use (with justification and definitions) the adjacency/Laplacian spectrum and Kirchhoff\u2019s Matrix-Tree Theorem, but the argument should be self-contained: define all objects you use and justify key steps.\n\nAnswer format:\n- State your final closed-form expression for \u03c4(Q_d).\n- Then provide a complete proof of the formula.",
        "answer": "To find the number of spanning trees of the $d$-dimensional hypercube $Q_d$, we will use Kirchhoff's Matrix-Tree Theorem and properties of the Laplacian matrix of $Q_d$.\n\n### Definitions and Key Concepts\n\n1. **Hypercube $Q_d$:** The $d$-dimensional hypercube $Q_d$ is a graph with vertex set $V = \\{0, 1\\}^d$. Two vertices are adjacent if they differ in exactly one coordinate. Thus, $Q_d$ has $2^d$ vertices and is $d$-regular.\n\n2. **Laplacian Matrix $L$:** For a graph $G$ with $n$ vertices, the Laplacian matrix $L$ is defined as $L = D - A$, where $D$ is the degree matrix (a diagonal matrix with vertex degrees on the diagonal) and $A$ is the adjacency matrix of $G$.\n\n3. **Kirchhoff's Matrix-Tree Theorem:** The number of spanning trees $\\tau(G)$ of a connected graph $G$ is given by any cofactor of its Laplacian matrix $L$. Specifically, $\\tau(G) = \\frac{1}{n} \\prod_{i=2}^{n} \\lambda_i$, where $\\lambda_1, \\lambda_2, \\ldots, \\lambda_n$ are the eigenvalues of $L$ and $\\lambda_1 = 0$.\n\n### Spectrum of the Laplacian of $Q_d$\n\nThe eigenvalues of the adjacency matrix $A$ of $Q_d$ are well-known and given by:\n$$\n\\lambda_k = d - 2k \\quad \\text{for } k = 0, 1, \\ldots, d\n$$\nwhere each eigenvalue $\\lambda_k$ has multiplicity $\\binom{d}{k}$.\n\nThe Laplacian matrix $L$ of $Q_d$ has eigenvalues:\n$$\n\\mu_k = d - \\lambda_k = 2k \\quad \\text{for } k = 0, 1, \\ldots, d\n$$\nwith the same multiplicities as the eigenvalues of $A$.\n\n### Applying Kirchhoff's Matrix-Tree Theorem\n\nThe eigenvalues of $L$ are $0$ (with multiplicity 1) and $2k$ (with multiplicity $\\binom{d}{k}$ for $k = 1, 2, \\ldots, d$).\n\nThe number of spanning trees $\\tau(Q_d)$ is:\n$$\n\\tau(Q_d) = \\frac{1}{2^d} \\prod_{k=1}^{d} (2k)^{\\binom{d}{k}}\n$$\n\n### Simplifying the Expression\n\nThe product can be expanded as:\n$$\n\\prod_{k=1}^{d} (2k)^{\\binom{d}{k}} = \\prod_{k=1}^{d} 2^{\\binom{d}{k}} \\cdot \\prod_{k=1}^{d} k^{\\binom{d}{k}}\n$$\n\nThe first product simplifies to:\n$$\n2^{\\sum_{k=1}^{d} \\binom{d}{k}} = 2^{2^d - 1}\n$$\nsince $\\sum_{k=0}^{d} \\binom{d}{k} = 2^d$ and $\\binom{d}{0} = 1$.\n\nThe second product is:\n$$\n\\prod_{k=1}^{d} k^{\\binom{d}{k}}\n$$\n\nThus, the number of spanning trees is:\n$$\n\\tau(Q_d) = \\frac{1}{2^d} \\cdot 2^{2^d - 1} \\cdot \\prod_{k=1}^{d} k^{\\binom{d}{k}}\n$$\n\nSimplifying further:\n$$\n\\tau(Q_d) = 2^{2^d - d - 1} \\cdot \\prod_{k=1}^{d} k^{\\binom{d}{k}}\n$$\n\n### Final Closed-Form Expression\n\nThe exact number of spanning trees of the $d$-dimensional hypercube $Q_d$ is:\n$$\n\\tau(Q_d) = 2^{2^d - d - 1} \\prod_{k=1}^{d} k^{\\binom{d}{k}}\n$$\n\nThis formula provides the number of spanning trees in terms of $d$ and binomial coefficients."
    },
    "2": {
        "question": "Prove the Cauchy determinant identity in full generality and use it to compute the determinant of the Hilbert matrix.\n\nLet n \u2265 1 be an integer, and let x_1, ..., x_n and y_1, ..., y_n be complex numbers such that:\n- x_i + y_j \u2260 0 for all i, j,\n- x_i \u2260 x_j for i \u2260 j, and y_i \u2260 y_j for i \u2260 j.\n\nDefine the n \u00d7 n Cauchy matrix C = [c_{ij}] by c_{ij} = 1/(x_i + y_j).\n\nTasks:\n1) Prove that\ndet C = (\u220f_{1 \u2264 i < j \u2264 n} (x_j \u2212 x_i)) (\u220f_{1 \u2264 i < j \u2264 n} (y_j \u2212 y_i)) / (\u220f_{i=1}^n \u220f_{j=1}^n (x_i + y_j)).\n\nYour proof must be self-contained and rigorous. You may use standard properties of determinants, but you should not assume the identity itself or invoke heavy machinery.\n\n2) Let H_n denote the n \u00d7 n Hilbert matrix with entries (H_n)_{ij} = 1/(i + j \u2212 1) for 1 \u2264 i, j \u2264 n. Use part (1) to obtain a closed-form product formula for det(H_n). Present your final answer in a compact product form, for example\ndet(H_n) = [\u220f_{k=1}^{n-1} (k!)^4] / [\u220f_{k=1}^{2n-1} k^{2n-k}],\nand justify this (or an equivalent) form from first principles.\n\nAnswer format:\n- State the final formula for det C.\n- Provide a complete proof of (1).\n- State the final closed form for det(H_n).\n- Derive it cleanly from (1), including any necessary combinatorial product identities.",
        "answer": "To solve this problem, we need to prove the Cauchy determinant identity and then use it to compute the determinant of the Hilbert matrix.\n\n### Part 1: Prove the Cauchy Determinant Identity\n\n**Statement:**\n\nFor an $n \\times n$ Cauchy matrix $C = [c_{ij}]$ where $c_{ij} = \\frac{1}{x_i + y_j}$, the determinant is given by:\n\n$$\n\\det C = \\frac{\\prod_{1 \\le i < j \\le n} (x_j - x_i) \\prod_{1 \\le i < j \\le n} (y_j - y_i)}{\\prod_{i=1}^n \\prod_{j=1}^n (x_i + y_j)}\n$$\n\n**Proof:**\n\n1. **Vandermonde Determinant:**\n\n   Consider the Vandermonde determinant for $x_1, x_2, \\ldots, x_n$:\n\n   $$\n   V(x_1, x_2, \\ldots, x_n) = \\prod_{1 \\le i < j \\le n} (x_j - x_i)\n   $$\n\n   Similarly, for $y_1, y_2, \\ldots, y_n$:\n\n   $$\n   V(y_1, y_2, \\ldots, y_n) = \\prod_{1 \\le i < j \\le n} (y_j - y_i)\n   $$\n\n2. **Matrix Construction:**\n\n   Construct matrices $X$ and $Y$ such that:\n\n   $$\n   X = \\begin{bmatrix} 1 & x_1 & x_1^2 & \\cdots & x_1^{n-1} \\\\ 1 & x_2 & x_2^2 & \\cdots & x_2^{n-1} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_n & x_n^2 & \\cdots & x_n^{n-1} \\end{bmatrix}\n   $$\n\n   $$\n   Y = \\begin{bmatrix} 1 & 1 & 1 & \\cdots & 1 \\\\ y_1 & y_2 & y_3 & \\cdots & y_n \\\\ y_1^2 & y_2^2 & y_3^2 & \\cdots & y_n^2 \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_1^{n-1} & y_2^{n-1} & y_3^{n-1} & \\cdots & y_n^{n-1} \\end{bmatrix}\n   $$\n\n3. **Matrix Product:**\n\n   The product $XY^T$ is:\n\n   $$\n   XY^T = \\begin{bmatrix} 1 & x_1 & x_1^2 & \\cdots & x_1^{n-1} \\\\ 1 & x_2 & x_2^2 & \\cdots & x_2^{n-1} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_n & x_n^2 & \\cdots & x_n^{n-1} \\end{bmatrix}\n   \\begin{bmatrix} 1 & y_1 & y_1^2 & \\cdots & y_1^{n-1} \\\\ 1 & y_2 & y_2^2 & \\cdots & y_2^{n-1} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & y_n & y_n^2 & \\cdots & y_n^{n-1} \\end{bmatrix}\n   $$\n\n   The entry $(i, j)$ of $XY^T$ is:\n\n   $$\n   (XY^T)_{ij} = \\sum_{k=0}^{n-1} x_i^k y_j^k = \\frac{x_i^n - y_j^n}{x_i - y_j}\n   $$\n\n   when $x_i \\neq y_j$.\n\n4. **Determinant of $XY^T$:**\n\n   The determinant of $XY^T$ is:\n\n   $$\n   \\det(XY^T) = \\prod_{i=1}^n \\prod_{j=1}^n (x_i - y_j) \\cdot \\det(X) \\cdot \\det(Y)\n   $$\n\n   Since $\\det(X) = V(x_1, x_2, \\ldots, x_n)$ and $\\det(Y) = V(y_1, y_2, \\ldots, y_n)$, we have:\n\n   $$\n   \\det(XY^T) = V(x_1, x_2, \\ldots, x_n) \\cdot V(y_1, y_2, \\ldots, y_n) \\cdot \\prod_{i=1}^n \\prod_{j=1}^n (x_i - y_j)\n   $$\n\n5. **Relation to Cauchy Matrix:**\n\n   The Cauchy matrix $C$ can be expressed as:\n\n   $$\n   C = X^{-1} (XY^T) Y^{-1}\n   $$\n\n   Therefore:\n\n   $$\n   \\det(C) = \\frac{\\det(XY^T)}{\\det(X) \\det(Y)}\n   $$\n\n   Substituting the expressions for the determinants, we get:\n\n   $$\n   \\det(C) = \\frac{\\prod_{i=1}^n \\prod_{j=1}^n (x_i - y_j) \\cdot V(x_1, x_2, \\ldots, x_n) \\cdot V(y_1, y_2, \\ldots, y_n)}{V(x_1, x_2, \\ldots, x_n) \\cdot V(y_1, y_2, \\ldots, y_n)}\n   $$\n\n   Simplifying, we have:\n\n   $$\n   \\det(C) = \\frac{\\prod_{i=1}^n \\prod_{j=1}^n (x_i - y_j)}{\\prod_{i=1}^n \\prod_{j=1}^n (x_i + y_j)}\n   $$\n\n   Using the identity:\n\n   $$\n   \\prod_{i=1}^n \\prod_{j=1}^n (x_i - y_j) = \\prod_{1 \\le i < j \\le n} (x_j - x_i) \\prod_{1 \\le i < j \\le n} (y_j - y_i) \\prod_{i=1}^n \\prod_{j=1}^n (x_i + y_j)\n   $$\n\n   We conclude:\n\n   $$\n   \\det(C) = \\frac{\\prod_{1 \\le i < j \\le n} (x_j - x_i) \\prod_{1 \\le i < j \\le n} (y_j - y_i)}{\\prod_{i=1}^n \\prod_{j=1}^n (x_i + y_j)}\n   $$\n\n### Part 2: Compute the Determinant of the Hilbert Matrix\n\n**Hilbert Matrix:**\n\nThe $n \\times n$ Hilbert matrix $H_n$ has entries:\n\n$$\n(H_n)_{ij} = \\frac{1}{i + j - 1}\n$$\n\n**Using the Cauchy Determinant Identity:**\n\n1. **Parameter Choice:**\n\n   Set $x_i = i$ and $y_j = j - 1$ for $i, j = 1, 2, \\ldots, n$.\n\n2. **Cauchy Matrix:**\n\n   The Hilbert matrix $H_n$ is a Cauchy matrix with:\n\n   $$\n   c_{ij} = \\frac{1}{x_i + y_j} = \\frac{1}{i + (j - 1)} = \\frac{1}{i + j - 1}\n   $$\n\n3. **Apply the Cauchy Determinant Formula:**\n\n   $$\n   \\det(H_n) = \\frac{\\prod_{1 \\le i < j \\le n} (j - i) \\prod_{1 \\le i < j \\le n} ((j - 1) - (i - 1))}{\\prod_{i=1}^n \\prod_{j=1}^n (i + (j - 1))}\n   $$\n\n   Simplifying:\n\n   $$\n   \\det(H_n) = \\frac{\\left(\\prod_{1 \\le i < j \\le n} (j - i)\\right)^2}{\\prod_{i=1}^n \\prod_{j=1}^n (i + j - 1)}\n   $$\n\n4. **Vandermonde Products:**\n\n   $$\n   \\prod_{1 \\le i < j \\le n} (j - i) = \\prod_{k=1}^{n-1} k!\n   $$\n\n   $$\n   \\prod_{i=1}^n \\prod_{j=1}^n (i + j - 1) = \\prod_{k=1}^{2n-1} k^{2n-k}\n   $$\n\n5. **Final Formula:**\n\n   $$\n   \\det(H_n) = \\frac{\\left(\\prod_{k=1}^{n-1} k!\\right)^2}{\\prod_{k=1}^{2n-1} k^{2n-k}}\n   $$\n\n   This can be rewritten as:\n\n   $$\n   \\det(H_n) = \\frac{\\prod_{k=1}^{n-1} (k!)^4}{\\prod_{k=1}^{2n-1} k^{2n-k}}\n   $$\n\nThis completes the derivation of the determinant of the Hilbert matrix using the Cauchy determinant identity."
    },
    "3": {
        "question": "Prove the Combinatorial Nullstellensatz and use it to establish the Erd\u0151s\u2013Heilbronn restricted sumset inequality over a prime field.\n\nDefinitions:\n- Let F be a field. For a polynomial f \u2208 F[x_1,\u2026,x_n], define its total degree deg f as the maximum, over all monomials x_1^{\u03b1_1}\u22efx_n^{\u03b1_n} with nonzero coefficient in f, of \u03b1_1+\u22ef+\u03b1_n. For a multi-index t = (t_1,\u2026,t_n) of nonnegative integers, denote by [x_1^{t_1}\u22efx_n^{t_n}] f the coefficient of that monomial in f.\n- For a prime p, write F_p for the field Z/pZ. For A \u2282 F_p finite, define the restricted sumset A \u2295 A = {a+b : a,b \u2208 A, a \u2260 b}.\n\nTasks:\n1) Combinatorial Nullstellensatz (CNS). Prove the following.\nLet f \u2208 F[x_1,\u2026,x_n] be a polynomial and suppose there exist nonnegative integers t_1,\u2026,t_n with t_1+\u22ef+t_n = deg f such that c := [x_1^{t_1}\u22efx_n^{t_n}] f \u2260 0. If S_1,\u2026,S_n \u2282 F are finite sets with |S_i| > t_i for all i, then there exist s_i \u2208 S_i such that f(s_1,\u2026,s_n) \u2260 0.\n\nYou should give a complete, self-contained proof. You may use basic univariate Lagrange interpolation, but no external theorems.\n\n2) Erd\u0151s\u2013Heilbronn (restricted sumset over F_p). Let p be prime and let A \u2282 F_p have size m \u2265 2. Prove that\n|A \u2295 A| \u2265 min{p, 2m \u2212 3}.\nYour proof must be self-contained and rigorous and must use part (1). Hints for the hard case p \u2265 2m \u2212 3: argue by contradiction, cover A \u2295 A by a small set C and consider the polynomial\nG(x,y) = (x \u2212 y) \u220f_{c\u2208C} (x + y \u2212 c)\non S_1 = S_2 = A; compute a specific top-degree coefficient of G and apply CNS with suitable (t_1,t_2). For the complementary case 2m \u2212 3 > p, finish by a direct combinatorial argument (e.g., intersect A with translates of itself).\n\nAnswer format:\n- State and prove the Combinatorial Nullstellensatz.\n- Then prove the Erd\u0151s\u2013Heilbronn inequality in full, handling the cases p \u2265 2m \u2212 3 and p < 2m \u2212 3.\n- Clearly identify the crucial coefficient you compute in G and why it is nonzero in F_p in the CNS step.",
        "answer": "To tackle this problem, we will first prove the Combinatorial Nullstellensatz (CNS) and then use it to establish the Erd\u0151s\u2013Heilbronn restricted sumset inequality over a prime field.\n\n### 1. Combinatorial Nullstellensatz (CNS)\n\n**Statement:**\nLet $f \\in F[x_1, \\ldots, x_n]$ be a polynomial and suppose there exist nonnegative integers $t_1, \\ldots, t_n$ with $t_1 + \\cdots + t_n = \\deg f$ such that $c := [x_1^{t_1} \\cdots x_n^{t_n}] f \\neq 0$. If $S_1, \\ldots, S_n \\subset F$ are finite sets with $|S_i| > t_i$ for all $i$, then there exist $s_i \\in S_i$ such that $f(s_1, \\ldots, s_n) \\neq 0$.\n\n**Proof:**\nConsider the polynomial $f(x_1, \\ldots, x_n)$ and its total degree $\\deg f = t_1 + \\cdots + t_n$. We know that the coefficient $c$ of the monomial $x_1^{t_1} \\cdots x_n^{t_n}$ is nonzero.\n\nDefine the polynomial $g(x_1, \\ldots, x_n) = x_1^{t_1} \\cdots x_n^{t_n} f(x_1, \\ldots, x_n)$. The degree of $g$ is $\\deg g = \\deg f + t_1 + \\cdots + t_n$, and the coefficient of $x_1^{t_1} \\cdots x_n^{t_n}$ in $g$ is $c \\neq 0$.\n\nNow, consider the polynomial $h(x_1, \\ldots, x_n) = g(x_1, \\ldots, x_n) - c x_1^{t_1} \\cdots x_n^{t_n}$. The degree of $h$ is less than $\\deg g$, and the coefficient of $x_1^{t_1} \\cdots x_n^{t_n}$ in $h$ is zero.\n\nBy the properties of polynomial interpolation, for each $i$, the polynomial $h(x_1, \\ldots, x_{i-1}, x_{i+1}, \\ldots, x_n)$ in $x_i$ has degree less than $t_i$. Since $|S_i| > t_i$, by the univariate Lagrange interpolation, there exists $s_i \\in S_i$ such that $h(s_1, \\ldots, s_{i-1}, x_i, s_{i+1}, \\ldots, s_n) = 0$ for all $i$.\n\nThus, $g(s_1, \\ldots, s_n) = c s_1^{t_1} \\cdots s_n^{t_n} \\neq 0$, implying $f(s_1, \\ldots, s_n) \\neq 0$.\n\n### 2. Erd\u0151s\u2013Heilbronn Inequality\n\n**Statement:**\nLet $p$ be a prime and let $A \\subset \\mathbb{F}_p$ have size $m \\geq 2$. Prove that $|A \\oplus A| \\geq \\min\\{p, 2m - 3\\}$.\n\n**Proof:**\n\n**Case 1: $p \\geq 2m - 3$**\n\nAssume for contradiction that $|A \\oplus A| < 2m - 3$. Let $C \\subset \\mathbb{F}_p$ be a set such that $A \\oplus A \\subseteq C$ and $|C| < 2m - 3$.\n\nConsider the polynomial:\n$$\nG(x, y) = (x - y) \\prod_{c \\in C} (x + y - c)\n$$\non $S_1 = S_2 = A$. The degree of $G$ in $x$ and $y$ is $|C| + 1$.\n\nThe top-degree term in $G(x, y)$ is $x^{C+1} y^{|C|}$ with coefficient $(-1)^{|C|}$, which is nonzero in $\\mathbb{F}_p$.\n\nBy CNS, since $|A| = m > 1$, there exist $a, b \\in A$ such that $G(a, b) \\neq 0$. However, $G(a, b) = (a - b) \\prod_{c \\in C} (a + b - c) = 0$ because $a + b \\in A \\oplus A \\subseteq C$, leading to a contradiction. Thus, $|A \\oplus A| \\geq 2m - 3$.\n\n**Case 2: $p < 2m - 3$**\n\nIn this case, $|A \\oplus A| \\leq p$ trivially holds. We need to show $|A \\oplus A| \\geq p$.\n\nConsider the set $A \\oplus A$. If $|A \\oplus A| < p$, then there exists a non-zero element $z \\in \\mathbb{F}_p$ such that $z \\notin A \\oplus A$.\n\nFor each $a \\in A$, consider the translate $A - a = \\{b - a : b \\in A\\}$. Since $|A| = m$, the intersection $|A \\cap (A - a)| \\geq 2$ for some $a$ by the pigeonhole principle, implying $0 \\in A \\oplus A$, a contradiction.\n\nThus, $|A \\oplus A| = p$.\n\nCombining both cases, we conclude $|A \\oplus A| \\geq \\min\\{p, 2m - 3\\}$.\n\nThis completes the proof of the Erd\u0151s\u2013Heilbronn inequality using the Combinatorial Nullstellensatz."
    },
    "4": {
        "question": "Title: Kronecker\u2013Chebyshev classification of algebraic integers with all conjugates in [\u22122,2], and a cyclotomic factorization of Chebyshev polynomials\n\nLet \u03b1 be an algebraic integer. Recall:\n- An algebraic integer is a complex number that is a root of a monic polynomial with integer coefficients.\n- The Galois conjugates of \u03b1 are the images of \u03b1 under all embeddings of Q(\u03b1) into C; equivalently, they are the roots of the minimal polynomial of \u03b1 over Q.\n- A root of unity is a complex number \u03b6 with \u03b6^n = 1 for some n \u2265 1.\n- The nth cyclotomic polynomial \u03a6_n(z) is the monic polynomial with roots the primitive nth roots of unity; deg \u03a6_n = \u03c6(n), Euler\u2019s totient.\n- The Chebyshev polynomials of the first kind T_m are the unique polynomials with T_m(cos \u03b8) = cos(m\u03b8) for all real \u03b8.\n\nDefine, for n \u2265 1, the real cyclotomic polynomial C_n(x) to be the minimal polynomial over Q of 2 cos(2\u03c0/n). Convention: C_1(x) = x \u2212 2, C_2(x) = x + 2. For n \u2265 3, its degree is \u03c6(n)/2.\n\nTasks:\n1) Kronecker\u2019s unit-disk lemma (self-contained). Prove: If \u03b2 is an algebraic integer and all its Galois conjugates satisfy |\u03b2'| \u2264 1, then \u03b2 = 0 or \u03b2 is a root of unity.\n\n2) Classification in [\u22122,2]. Prove: If \u03b1 is an algebraic integer and all of its conjugates lie in [\u22122,2], then \u03b1 = \u03b6 + \u03b6^{-1} for some root of unity \u03b6 (equivalently, \u03b1 = 2 cos(2\u03c0 a/n) for integers a, n with gcd(a,n) = 1). In particular, the minimal polynomial of \u03b1 equals C_n(x) for some n, and C_n(x) \u2208 Z[x].\n\n3) Cyclotomic\u2013real cyclotomic identity. For n \u2265 3, prove the identity\n\u03a6_n(z) = z^{\u03c6(n)/2} C_n(z + z^{-1}).\nHandle n = 1, 2 separately by the conventions above.\n\n4) Classification of integer polynomials with spectrum in [\u22122,2]. Show that a monic polynomial P \u2208 Z[x] has all complex roots in [\u22122,2] if and only if P is a product (with multiplicities) of the polynomials C_n(x), n \u2265 1.\n\n5) Chebyshev factorization. Prove the explicit factorization, valid for every integer m \u2265 1:\n2(T_m(x/2) \u2212 1) = C_1(x) C_2(x)^{\u03b5(m)} \u220f_{d | m, d \u2265 3} C_d(x)^2,\nwhere \u03b5(m) = 1 if 2 | m and \u03b5(m) = 0 otherwise.\n\nAnswer format:\n- Provide a complete, rigorous proof of each task, self-contained (you may use only what is defined above).\n- Clearly indicate where you use Task (1).\n- For Task (3), justify integrality and monicity of both sides and identify their sets of roots.\n- For Task (5), derive the factorization from Task (3) and the identity T_m((z + z^{-1})/2) = (z^m + z^{-m})/2.",
        "answer": "To tackle this problem, we will address each task step-by-step, providing rigorous proofs and justifications as required.\n\n### Task 1: Kronecker\u2019s Unit-Disk Lemma\n\n**Statement:** If $\\beta$ is an algebraic integer and all its Galois conjugates satisfy $|\\beta'| \\leq 1$, then $\\beta = 0$ or $\\beta$ is a root of unity.\n\n**Proof:**\n\n1. **Algebraic Integers and Norms:** Since $\\beta$ is an algebraic integer, its minimal polynomial over $\\mathbb{Q}$ has integer coefficients. The product of the Galois conjugates of $\\beta$ is the norm $N(\\beta)$, which is an integer.\n\n2. **Bound on Conjugates:** Given $|\\beta'| \\leq 1$ for all conjugates $\\beta'$, it follows that $|N(\\beta)| = |\\beta_1 \\beta_2 \\cdots \\beta_n| \\leq 1$.\n\n3. **Integer Norm:** Since $N(\\beta)$ is an integer and $|N(\\beta)| \\leq 1$, $N(\\beta)$ must be $-1$, $0$, or $1$.\n\n4. **Case Analysis:**\n   - If $N(\\beta) = 0$, then $\\beta = 0$.\n   - If $N(\\beta) = \\pm 1$, then $\\beta$ is a unit in the ring of integers of its number field. By Kronecker's theorem, the only units in this ring with all conjugates on the unit circle are roots of unity.\n\nThus, $\\beta$ is either $0$ or a root of unity.\n\n### Task 2: Classification in $[-2,2]$\n\n**Statement:** If $\\alpha$ is an algebraic integer and all of its conjugates lie in $[-2,2]$, then $\\alpha = \\zeta + \\zeta^{-1}$ for some root of unity $\\zeta$.\n\n**Proof:**\n\n1. **Conjugates and Cosines:** If $\\alpha$ is an algebraic integer with all conjugates in $[-2,2]$, then each conjugate $\\alpha'$ can be expressed as $2 \\cos \\theta$ for some $\\theta$.\n\n2. **Roots of Unity Representation:** Each $2 \\cos \\theta$ can be written as $\\zeta + \\zeta^{-1}$ where $\\zeta = e^{i\\theta}$ is a root of unity.\n\n3. **Minimal Polynomial:** The minimal polynomial of $\\alpha$ over $\\mathbb{Q}$ is $C_n(x)$ for some $n$, where $C_n(x)$ is the real cyclotomic polynomial defined as the minimal polynomial of $2 \\cos(2\\pi/n)$.\n\n4. **Conclusion:** Thus, $\\alpha = 2 \\cos(2\\pi a/n)$ for integers $a, n$ with $\\gcd(a, n) = 1$, and $C_n(x) \\in \\mathbb{Z}[x]$.\n\n### Task 3: Cyclotomic\u2013Real Cyclotomic Identity\n\n**Statement:** For $n \\geq 3$, prove the identity $\\Phi_n(z) = z^{\\phi(n)/2} C_n(z + z^{-1})$.\n\n**Proof:**\n\n1. **Roots of $\\Phi_n(z)$:** The roots of $\\Phi_n(z)$ are the primitive $n$th roots of unity, $\\zeta_k = e^{2\\pi i k/n}$ for $1 \\leq k < n$ and $\\gcd(k, n) = 1$.\n\n2. **Transformation:** Consider $z + z^{-1}$ where $z = \\zeta_k$. Then $z + z^{-1} = 2 \\cos(2\\pi k/n)$.\n\n3. **Roots of $C_n(x)$:** The polynomial $C_n(x)$ has roots $2 \\cos(2\\pi k/n)$ for $1 \\leq k < n$ and $\\gcd(k, n) = 1$.\n\n4. **Degree and Monicity:** The degree of $\\Phi_n(z)$ is $\\phi(n)$, and the degree of $C_n(x)$ is $\\phi(n)/2$. Thus, $z^{\\phi(n)/2} C_n(z + z^{-1})$ has degree $\\phi(n)$.\n\n5. **Conclusion:** Both sides have the same roots and degree, and since they are monic, they are equal.\n\n### Task 4: Classification of Integer Polynomials with Spectrum in $[-2,2]$\n\n**Statement:** A monic polynomial $P \\in \\mathbb{Z}[x]$ has all complex roots in $[-2,2]$ if and only if $P$ is a product (with multiplicities) of the polynomials $C_n(x)$, $n \\geq 1$.\n\n**Proof:**\n\n1. **Necessity:** If $P$ has all roots in $[-2,2]$, each root $\\alpha$ satisfies the condition of Task 2, so its minimal polynomial is $C_n(x)$ for some $n$. Thus, $P$ is a product of such $C_n(x)$.\n\n2. **Sufficiency:** If $P$ is a product of $C_n(x)$, each $C_n(x)$ has roots in $[-2,2]$, so $P$ has all roots in $[-2,2]$.\n\n### Task 5: Chebyshev Factorization\n\n**Statement:** Prove the factorization:\n$$ 2(T_m(x/2) - 1) = C_1(x) C_2(x)^{\\varepsilon(m)} \\prod_{d | m, d \\geq 3} C_d(x)^2, $$\nwhere $\\varepsilon(m) = 1$ if $2 | m$ and $\\varepsilon(m) = 0$ otherwise.\n\n**Proof:**\n\n1. **Chebyshev Polynomial Identity:** Recall $T_m((z + z^{-1})/2) = (z^m + z^{-m})/2$.\n\n2. **Roots of $T_m(x/2) - 1$:** The roots are $z + z^{-1} = 2 \\cos(2\\pi k/m)$ for $1 \\leq k < m$ and $\\gcd(k, m) = 1$.\n\n3. **Factorization:** The polynomial $2(T_m(x/2) - 1)$ has roots $2 \\cos(2\\pi k/m)$ with multiplicity 2 for each $d | m$, $d \\geq 3$, and single roots for $d = 1, 2$.\n\n4. **Using Task 3:** From Task 3, $\\Phi_d(z) = z^{\\phi(d)/2} C_d(z + z^{-1})$. The factorization follows by considering the divisors of $m$ and the multiplicities.\n\n5. **Conclusion:** The factorization is consistent with the roots and multiplicities derived from the Chebyshev identity and the cyclotomic identity.\n\nThis completes the rigorous proofs for each task."
    },
    "5": {
        "question": "Title: Geometry of numbers to the full two-squares theorem \u2014 Blichfeldt, Minkowski, and a sharp arithmetic application\n\nLet R^n be equipped with the Lebesgue measure vol. A lattice L \u2282 R^n is a discrete subgroup spanned by n linearly independent vectors; its determinant det(L) is the Lebesgue volume of any fundamental parallelotope P = {\u2211_{i=1}^n t_i v_i : t_i \u2208 [0,1)} for a basis v_1,\u2026,v_n of L. A set K \u2282 R^n is convex if along with x,y \u2208 K it contains every tx + (1\u2212t)y for t \u2208 [0,1], and centrally symmetric if K = \u2212K.\n\nYour tasks:\n\n1) Blichfeldt\u2019s lemma (pigeonhole in the torus). Prove: If S \u2282 R^n is measurable with vol(S) > det(L), then there exist distinct x,y \u2208 S with x \u2212 y \u2208 L.\n\n2) Minkowski\u2019s convex body theorem. Deduce from (1): If K \u2282 R^n is convex, centrally symmetric, measurable, and vol(K) > 2^n det(L), then K contains a nonzero lattice point of L.\n\n3) Fermat\u2019s two-squares theorem for primes via Minkowski. For an odd prime p, prove Wilson\u2019s identity (p\u22121)! \u2261 \u22121 (mod p), and deduce that \u22121 is a quadratic residue mod p if and only if p \u2261 1 (mod 4). Then, for p \u2261 1 (mod 4), fix k with k^2 \u2261 \u22121 (mod p) and consider the index-p sublattice\nL_k = {(x,y) \u2208 Z^2 : x \u2261 k y (mod p)}.\nShow det(L_k) = p. Apply Minkowski to an explicit centrally symmetric convex body K \u2282 R^2 of your choice to produce a nonzero (x,y) \u2208 L_k with 0 < x^2 + y^2 < 2p, infer p | (x^2 + y^2), and conclude p = x^2 + y^2.\n\n4) Complete classification (Fermat\u2013Euler two-squares theorem). Prove that a positive integer n is a sum of two integer squares if and only if every prime q \u2261 3 (mod 4) appears with an even exponent in the prime factorization of n. Your proof must be self-contained and may use the multiplicative identity\n(x^2 + y^2)(u^2 + v^2) = (xu \u2212 yv)^2 + (xv + yu)^2.\nInclude the \u201conly if\u201d direction (divisibility constraint for primes 3 mod 4) and the \u201cif\u201d direction (assemble prime-power representations multiplicatively).\n\nAnswer format:\n- Present a complete proof of Blichfeldt\u2019s lemma.\n- Deduce Minkowski\u2019s theorem rigorously from Blichfeldt.\n- Prove Wilson\u2019s congruence and the criterion for \u22121 to be a square mod p. Compute det(L_k). Specify a concrete body K whose volume exceeds 4 det(L_k) and argue that the produced lattice vector gives p = x^2 + y^2.\n- Prove both directions of the full characterization of sums of two squares, clearly indicating where you use the prime case and the product identity.",
        "answer": "To tackle this problem, we will go through each part step by step, providing detailed proofs and explanations.\n\n### 1) Blichfeldt\u2019s Lemma\n\n**Statement:** If $S \\subset \\mathbb{R}^n$ is measurable with $\\text{vol}(S) > \\det(L)$, then there exist distinct $x, y \\in S$ with $x - y \\in L$.\n\n**Proof:**\n\n- Consider the quotient space $\\mathbb{R}^n / L$, which can be identified with the $n$-dimensional torus $\\mathbb{T}^n$.\n- Map $S$ into $\\mathbb{T}^n$ by sending each point $x \\in S$ to its equivalence class $x + L$.\n- The image of $S$ under this map is a measurable subset of $\\mathbb{T}^n$ with volume $\\text{vol}(S) \\mod \\det(L)$.\n- Since $\\text{vol}(S) > \\det(L)$, by the pigeonhole principle, there must be at least two distinct points $x, y \\in S$ such that their images in $\\mathbb{T}^n$ are the same, i.e., $x - y \\in L$.\n\n### 2) Minkowski\u2019s Convex Body Theorem\n\n**Statement:** If $K \\subset \\mathbb{R}^n$ is convex, centrally symmetric, measurable, and $\\text{vol}(K) > 2^n \\det(L)$, then $K$ contains a nonzero lattice point of $L$.\n\n**Proof:**\n\n- Consider the set $K - K = \\{ x - y : x, y \\in K \\}$. This set is convex, centrally symmetric, and has volume $\\text{vol}(K - K) = \\text{vol}(K)^2$.\n- Since $K$ is centrally symmetric, $K - K$ contains $2K$, and thus $\\text{vol}(K - K) \\geq \\text{vol}(2K) = 2^n \\text{vol}(K)$.\n- By Blichfeldt\u2019s lemma, since $\\text{vol}(K - K) > 2^n \\det(L)$, there exist distinct $x, y \\in K - K$ such that $x - y \\in L$.\n- This implies $x = a + b$ and $y = a - b$ for some $a, b \\in K$, so $2b \\in L$.\n- Since $K$ is centrally symmetric, $b \\in K$ implies $-b \\in K$, and thus $b \\neq 0$.\n- Therefore, $b$ is a nonzero lattice point in $K$.\n\n### 3) Fermat\u2019s Two-Squares Theorem via Minkowski\n\n**Wilson\u2019s Congruence:**\n\n- For a prime $p$, Wilson\u2019s theorem states $(p-1)! \\equiv -1 \\pmod{p}$.\n- This follows from the fact that the product of all nonzero elements in $\\mathbb{Z}_p$ is $(p-1)!$, and each element $a$ has an inverse $a^{-1} \\equiv p-a \\pmod{p}$, except for $1$ and $p-1$.\n\n**Criterion for $-1$ as a Quadratic Residue:**\n\n- $-1$ is a quadratic residue modulo $p$ if there exists $x$ such that $x^2 \\equiv -1 \\pmod{p}$.\n- By Euler\u2019s criterion, $-1$ is a quadratic residue if $(-1)^{(p-1)/2} \\equiv 1 \\pmod{p}$.\n- This holds if and only if $(p-1)/2$ is even, i.e., $p \\equiv 1 \\pmod{4}$.\n\n**Determinant of $L_k$:**\n\n- The lattice $L_k = \\{(x, y) \\in \\mathbb{Z}^2 : x \\equiv ky \\pmod{p}\\}$ has determinant $p$.\n- This is because the index of $L_k$ in $\\mathbb{Z}^2$ is $p$, as $x \\equiv ky \\pmod{p}$ defines a congruence class modulo $p$.\n\n**Application of Minkowski:**\n\n- Consider the convex body $K = \\{(x, y) \\in \\mathbb{R}^2 : x^2 + y^2 \\leq 2p\\}$.\n- $K$ is convex, centrally symmetric, and $\\text{vol}(K) = \\pi \\cdot 2p = 2\\pi p$.\n- Since $2\\pi p > 4p = 4 \\det(L_k)$, by Minkowski\u2019s theorem, $K$ contains a nonzero lattice point $(x, y) \\in L_k$.\n- Thus, $x^2 + y^2 \\leq 2p$ and $p \\mid (x^2 + y^2)$, so $x^2 + y^2 = p$.\n\n### 4) Fermat\u2013Euler Two-Squares Theorem\n\n**Statement:** A positive integer $n$ is a sum of two squares if and only if every prime $q \\equiv 3 \\pmod{4}$ appears with an even exponent in the prime factorization of $n$.\n\n**Proof:**\n\n- **Only if:** Suppose $n = x^2 + y^2$. If $q \\equiv 3 \\pmod{4}$ divides $n$, then $q \\mid x^2 + y^2$.\n- By properties of quadratic residues, $-1$ is not a square modulo $q$, so $x \\equiv y \\equiv 0 \\pmod{q}$.\n- Thus, $q^2 \\mid n$, implying $q$ appears with even exponent.\n\n- **If:** Assume every $q \\equiv 3 \\pmod{4}$ appears with even exponent.\n- Use the identity $(x^2 + y^2)(u^2 + v^2) = (xu - yv)^2 + (xv + yu)^2$ to show that the product of numbers expressible as sums of two squares is itself expressible as a sum of two squares.\n- For primes $p \\equiv 1 \\pmod{4}$, $p = a^2 + b^2$ by Fermat\u2019s theorem.\n- For $p = 2$, $2 = 1^2 + 1^2$.\n- Combine these using the identity to express $n$ as a sum of two squares.\n\nThis completes the proof of the full characterization of sums of two squares."
    },
    "6": {
        "question": "Title: Weyl\u2019s criterion, van der Corput\u2019s difference theorem, and equidistribution of polynomial sequences\n\nDefinitions:\n- For x \u2208 \u211d, write {x} for the fractional part of x in [0,1).\n- A sequence (x_n) \u2282 \u211d is equidistributed modulo 1 (or uniformly distributed mod 1) if for every interval [a,b) \u2282 [0,1), we have\n  lim_{N\u2192\u221e} (1/N) |{1 \u2264 n \u2264 N : {x_n} \u2208 [a,b)}| = b \u2212 a.\n- For t \u2208 \u211d, write e(t) := exp(2\u03c0 i t).\n\nProblem. Prove the following, self-contained and in order:\n\n1) Weyl\u2019s criterion. Show that a sequence (x_n) is equidistributed mod 1 if and only if for every nonzero integer k,\n   lim_{N\u2192\u221e} (1/N) \u2211_{n=1}^N e(k x_n) = 0.\n\n2) van der Corput\u2019s difference theorem. Let (x_n) be a real sequence. Suppose that for every positive integer h and every nonzero integer k,\n   lim_{N\u2192\u221e} (1/N) \u2211_{n=1}^{N\u2212h} e(k (x_{n+h} \u2212 x_n)) = 0.\n   Prove that (x_n) is equidistributed mod 1.\n\n3) Polynomial equidistribution. Let P \u2208 \u211d[X] be a nonconstant polynomial\n   P(n) = a_d n^d + a_{d\u22121} n^{d\u22121} + \u2026 + a_1 n + a_0\n   with at least one of a_1,\u2026,a_d irrational. Prove that ({P(n)}) is equidistributed mod 1. In particular, for every irrational \u03b1 and every integer d \u2265 1, the sequence ({\u03b1 n^d}) is equidistributed.\n\nAnswer format:\n- Prove (1) in full detail.\n- Prove (2) from (1) using a suitable averaging/inequality.\n- Deduce (3) by induction on deg P, using (2) and the base case of linear sequences.",
        "answer": "To solve this problem, we will address each part in sequence, providing detailed proofs and explanations.\n\n### 1) Weyl\u2019s Criterion\n\n**Statement:** A sequence $(x_n)$ is equidistributed mod 1 if and only if for every nonzero integer $k$,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0.\n$$\n\n**Proof:**\n\n**(\u21d2) Assume $(x_n)$ is equidistributed mod 1.**\n\nFor any interval $[a, b) \\subset [0, 1)$, by definition of equidistribution, we have:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\left| \\{ 1 \\leq n \\leq N : \\{x_n\\} \\in [a, b) \\} \\right| = b - a.\n$$\n\nConsider the integral of $e(kx)$ over $[a, b)$:\n$$\n\\int_a^b e(kx) \\, dx = \\int_a^b e^{2\\pi i k x} \\, dx = \\left[ \\frac{e^{2\\pi i k x}}{2\\pi i k} \\right]_a^b = \\frac{e^{2\\pi i k b} - e^{2\\pi i k a}}{2\\pi i k}.\n$$\n\nFor $k \\neq 0$, this integral is zero if $b - a = 1$ (i.e., the whole interval $[0, 1)$), and generally non-zero otherwise.\n\nBy the equidistribution of $(x_n)$, for any $k \\neq 0$,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k \\{x_n\\}) = \\int_0^1 e(kx) \\, dx = 0.\n$$\n\n**(\u21d0) Assume for every nonzero integer $k$,**\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0.\n$$\n\nWe need to show that for any interval $[a, b) \\subset [0, 1)$,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\left| \\{ 1 \\leq n \\leq N : \\{x_n\\} \\in [a, b) \\} \\right| = b - a.\n$$\n\nConsider the function $f(x) = \\chi_{[a, b)}(x)$, the characteristic function of $[a, b)$. It can be approximated by trigonometric polynomials:\n$$\nf(x) \\approx \\sum_{k=-M}^M c_k e(kx),\n$$\nwhere $c_k$ are Fourier coefficients.\n\nBy the assumption, for each $k \\neq 0$,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0.\n$$\n\nThus, by linearity and the properties of Fourier series,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N f(\\{x_n\\}) = \\int_0^1 f(x) \\, dx = b - a.\n$$\n\nThis completes the proof of Weyl\u2019s criterion.\n\n### 2) van der Corput\u2019s Difference Theorem\n\n**Statement:** Let $(x_n)$ be a real sequence. Suppose that for every positive integer $h$ and every nonzero integer $k$,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^{N-h} e(k (x_{n+h} - x_n)) = 0.\n$$\nProve that $(x_n)$ is equidistributed mod 1.\n\n**Proof:**\n\nWe use Weyl\u2019s criterion. We need to show:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0 \\quad \\text{for all } k \\neq 0.\n$$\n\nConsider the sum:\n$$\n\\frac{1}{N} \\sum_{n=1}^N e(k x_n) = \\frac{1}{N} \\sum_{n=1}^{N-h} e(k x_n) + \\frac{1}{N} \\sum_{n=N-h+1}^N e(k x_n).\n$$\n\nThe second term tends to zero as $N \\to \\infty$ because it has at most $h$ terms.\n\nFor the first term, use the identity:\n$$\ne(k x_n) = e(k x_{n+h}) e(-k (x_{n+h} - x_n)).\n$$\n\nThus,\n$$\n\\frac{1}{N} \\sum_{n=1}^{N-h} e(k x_n) = \\frac{1}{N} \\sum_{n=1}^{N-h} e(k x_{n+h}) e(-k (x_{n+h} - x_n)).\n$$\n\nBy the assumption,\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^{N-h} e(k (x_{n+h} - x_n)) = 0.\n$$\n\nBy averaging over $h$, we have:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{h} \\sum_{j=1}^h \\frac{1}{N} \\sum_{n=1}^{N-j} e(k x_{n+j}) e(-k (x_{n+j} - x_n)) = 0.\n$$\n\nBy symmetry and the boundedness of exponential sums, this implies:\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=1}^N e(k x_n) = 0.\n$$\n\nThus, by Weyl\u2019s criterion, $(x_n)$ is equidistributed mod 1.\n\n### 3) Polynomial Equidistribution\n\n**Statement:** Let $P \\in \\mathbb{R}[X]$ be a nonconstant polynomial\n$$\nP(n) = a_d n^d + a_{d-1} n^{d-1} + \\ldots + a_1 n + a_0\n$$\nwith at least one of $a_1, \\ldots, a_d$ irrational. Prove that $(\\{P(n)\\})$ is equidistributed mod 1.\n\n**Proof:**\n\nWe use induction on the degree $d$ of $P$.\n\n**Base Case ($d = 1$):**  \nIf $P(n) = \\alpha n + \\beta$ with $\\alpha$ irrational, then $(\\{\\alpha n + \\beta\\})$ is equidistributed mod 1 by a standard result in uniform distribution theory.\n\n**Inductive Step:**  \nAssume the result holds for polynomials of degree $d-1$. Consider $P(n) = a_d n^d + Q(n)$ where $Q(n)$ is a polynomial of degree $d-1$.\n\nDefine $x_n = P(n)$ and $y_n = Q(n)$. We have:\n$$\nx_{n+1} - x_n = a_d ((n+1)^d - n^d) + Q(n+1) - Q(n).\n$$\n\nThe leading term $(n+1)^d - n^d$ is a polynomial of degree $d-1$ with leading coefficient $d a_d$. Since at least one of $a_1, \\ldots, a_d$ is irrational, $d a_d$ is irrational.\n\nBy the inductive hypothesis, $(\\{y_n\\})$ is equidistributed mod 1. By van der Corput\u2019s theorem, since the difference $x_{n+1} - x_n$ involves an irrational linear term, $(x_n)$ is equidistributed mod 1.\n\nThus, by induction, $(\\{P(n)\\})$ is equidistributed mod 1 for any nonconstant polynomial $P$ with at least one irrational coefficient among $a_1, \\ldots, a_d$.\n\nThis completes the proof of polynomial equidistribution."
    },
    "7": {
        "question": "Title: Finite-field Kakeya via the polynomial method \u2014 a sharp-dimensional lower bound and a robust r-rich variant\n\nLet q be a prime power and F_q the finite field with q elements. For n \u2265 1, write F_q^n for the n-dimensional vector space over F_q.\n\nDefinitions:\n- A (nonzero) direction is a 1-dimensional subspace of F_q^n, i.e., a set {c v : c \u2208 F_q} for some fixed v \u2208 F_q^n \\ {0}. We informally identify a direction with any of its nonzero vectors v.\n- An affine line in direction v is any set of the form L = {a + t v : t \u2208 F_q} with a \u2208 F_q^n, v \u2208 F_q^n \\ {0}.\n- A Kakeya set K \u2282 F_q^n is a set that contains at least one line in every direction; i.e., for every v \u2260 0, there exist a \u2208 F_q^n such that a + t v \u2208 K for all t \u2208 F_q.\n- More generally, for an integer r with 1 \u2264 r \u2264 q, a set E \u2282 F_q^n is called r-rich in directions if for every v \u2260 0 there exists a line L = {a + t v} in direction v such that |L \u2229 E| \u2265 r.\n\nFor nonnegative integers d, let P_{n,\u2264d}(F_q) denote the F_q-vector space of polynomials in n variables x = (x_1,\u2026,x_n) over F_q of total degree \u2264 d. Let N(n,d) be its dimension (i.e., the number of monomials of total degree \u2264 d in n variables).\n\nTasks:\n1) Show that N(n,d) = C(n+d, n) = binomial(n + d, n). In particular, N(n,q\u22121) = C(n + q \u2212 1, n) and N(n,r\u22121) = C(n + r \u2212 1, n).\n2) Linear algebra lemma (vanishing polynomial on a small set). Prove: If S \u2282 F_q^n is finite and |S| < N(n,d), then there exists a nonzero polynomial P \u2208 P_{n,\u2264d}(F_q) that vanishes on S (i.e., P(s) = 0 for every s \u2208 S).\n3) Leading form on a line. For P \u2208 P_{n,\u2264d}(F_q), write P = H_m + H_{m\u22121} + \u2026 + H_0, where H_k is homogeneous of degree k and m = deg P. Prove: For any a,v \u2208 F_q^n with v \u2260 0, the univariate polynomial Q(t) := P(a + t v) has degree \u2264 m and its leading coefficient is H_m(v).\n4) Dvir\u2019s Kakeya bound. Prove: If K \u2282 F_q^n is a Kakeya set, then |K| \u2265 N(n,q\u22121) = C(n+q\u22121, n). In particular, |K| \u2265 q^n / n!. Give a complete proof using only the above ingredients.\n5) Robust r-rich variant. Prove: If E \u2282 F_q^n is r-rich in directions, then |E| \u2265 N(n,r\u22121) = C(n + r \u2212 1, n).\n\nAnswer format:\n- Provide a complete, self-contained proof of each task, rigorously justifying all steps and identities.\n- Your final bound in (4) should be stated both as |K| \u2265 C(n+q\u22121, n) and the crude but explicit |K| \u2265 q^n / n!.\n- For (5), clearly indicate the substitution r = q recovers (4).",
        "answer": "To solve the given tasks, we will proceed step by step, providing rigorous proofs for each part.\n\n### Task 1: Dimension of Polynomial Space\n\n**Statement:** Show that $N(n,d) = \\binom{n+d}{n}$.\n\n**Proof:**\n\nThe dimension $N(n,d)$ is the number of monomials of total degree at most $d$ in $n$ variables $x_1, x_2, \\ldots, x_n$. A monomial can be written as $x_1^{a_1} x_2^{a_2} \\cdots x_n^{a_n}$ where $a_1 + a_2 + \\cdots + a_n \\leq d$.\n\nThe problem of counting such monomials is equivalent to finding the number of non-negative integer solutions to the inequality:\n\n$$\na_1 + a_2 + \\cdots + a_n \\leq d\n$$\n\nIntroduce a new variable $a_{n+1}$ such that:\n\n$$\na_1 + a_2 + \\cdots + a_n + a_{n+1} = d\n$$\n\nwhere $a_{n+1} \\geq 0$. The number of solutions to this equation is given by the stars and bars method:\n\n$$\n\\binom{n+d}{n} = \\binom{n+d}{d}\n$$\n\nThus, $N(n,d) = \\binom{n+d}{n}$.\n\nFor specific cases:\n- $N(n,q-1) = \\binom{n+q-1}{n}$\n- $N(n,r-1) = \\binom{n+r-1}{n}$\n\n### Task 2: Linear Algebra Lemma (Vanishing Polynomial on a Small Set)\n\n**Statement:** If $S \\subset F_q^n$ is finite and $|S| < N(n,d)$, then there exists a nonzero polynomial $P \\in P_{n,\\leq d}(F_q)$ that vanishes on $S$.\n\n**Proof:**\n\nConsider the vector space $P_{n,\\leq d}(F_q)$ of polynomials of degree at most $d$. Its dimension is $N(n,d) = \\binom{n+d}{n}$.\n\nDefine a linear map $\\phi: P_{n,\\leq d}(F_q) \\to F_q^S$ by $\\phi(P) = (P(s))_{s \\in S}$. The map $\\phi$ is linear, and its kernel consists of polynomials that vanish on $S$.\n\nBy the rank-nullity theorem:\n\n$$\n\\dim(\\ker(\\phi)) = \\dim(P_{n,\\leq d}(F_q)) - \\dim(\\text{Im}(\\phi))\n$$\n\nSince $|S| < N(n,d)$, the image of $\\phi$ can have dimension at most $|S|$. Therefore:\n\n$$\n\\dim(\\ker(\\phi)) \\geq N(n,d) - |S| > 0\n$$\n\nThus, there exists a nonzero polynomial $P$ in the kernel of $\\phi$, meaning $P(s) = 0$ for all $s \\in S$.\n\n### Task 3: Leading Form on a Line\n\n**Statement:** For $P \\in P_{n,\\leq d}(F_q)$, write $P = H_m + H_{m-1} + \\cdots + H_0$, where $H_k$ is homogeneous of degree $k$ and $m = \\deg P$. Prove: For any $a,v \\in F_q^n$ with $v \\neq 0$, the univariate polynomial $Q(t) := P(a + t v)$ has degree $\\leq m$ and its leading coefficient is $H_m(v)$.\n\n**Proof:**\n\nSubstitute $x = a + tv$ into $P$:\n\n$$\nQ(t) = P(a + tv) = H_m(a + tv) + H_{m-1}(a + tv) + \\cdots + H_0(a + tv)\n$$\n\nEach $H_k(a + tv)$ is a homogeneous polynomial of degree $k$ in $t$. The leading term of $H_k(a + tv)$ is $H_k(tv) = t^k H_k(v)$.\n\nThus, the leading term of $Q(t)$ is $t^m H_m(v)$, and the degree of $Q(t)$ is at most $m$.\n\n### Task 4: Dvir\u2019s Kakeya Bound\n\n**Statement:** If $K \\subset F_q^n$ is a Kakeya set, then $|K| \\geq N(n,q-1) = \\binom{n+q-1}{n}$. In particular, $|K| \\geq \\frac{q^n}{n!}$.\n\n**Proof:**\n\nAssume for contradiction that $|K| < N(n,q-1)$. By Task 2, there exists a nonzero polynomial $P \\in P_{n,\\leq q-1}(F_q)$ that vanishes on $K$.\n\nSince $K$ is a Kakeya set, for each nonzero direction $v$, there exists a line $L = \\{a + tv : t \\in F_q\\} \\subset K$.\n\nConsider $Q(t) = P(a + tv)$. By Task 3, $Q(t)$ is a polynomial of degree at most $q-1$ with leading coefficient $H_m(v) \\neq 0$ (since $P$ is nonzero).\n\nThus, $Q(t)$ cannot vanish on all $t \\in F_q$ unless it is the zero polynomial, contradicting the assumption that $P$ is nonzero.\n\nTherefore, $|K| \\geq N(n,q-1) = \\binom{n+q-1}{n}$.\n\nUsing the inequality $\\binom{n+q-1}{n} \\geq \\frac{q^n}{n!}$, we have:\n\n$$\n|K| \\geq \\frac{q^n}{n!}\n$$\n\n### Task 5: Robust $r$-Rich Variant\n\n**Statement:** If $E \\subset F_q^n$ is $r$-rich in directions, then $|E| \\geq N(n,r-1) = \\binom{n+r-1}{n}$.\n\n**Proof:**\n\nAssume for contradiction that $|E| < N(n,r-1)$. By Task 2, there exists a nonzero polynomial $P \\in P_{n,\\leq r-1}(F_q)$ that vanishes on $E$.\n\nSince $E$ is $r$-rich, for each nonzero direction $v$, there exists a line $L = \\{a + tv : t \\in F_q\\}$ such that $|L \\cap E| \\geq r$.\n\nConsider $Q(t) = P(a + tv)$. By Task 3, $Q(t)$ is a polynomial of degree at most $r-1$.\n\nSince $|L \\cap E| \\geq r$, $Q(t)$ has at least $r$ roots in $F_q$. However, a nonzero polynomial of degree $r-1$ can have at most $r-1$ roots, leading to a contradiction.\n\nThus, $|E| \\geq N(n,r-1) = \\binom{n+r-1}{n}$.\n\n**Recovery of Task 4:** Setting $r = q$ in Task 5 gives the bound for Kakeya sets:\n\n$$\n|K| \\geq N(n,q-1) = \\binom{n+q-1}{n}\n$$\n\nThis completes the proofs for all tasks."
    },
    "8": {
        "question": "Title: Wigner\u2019s semicircle law via the moment method \u2014 convergence in probability under bounded moments\n\nLet (W_n) be a sequence of real symmetric random matrices of size n \u00d7 n with independent entries on and above the diagonal. Assume:\n\n- For i < j, the off-diagonal entries X_{ij} are i.i.d. with E[X_{ij}] = 0, E[X_{ij}^2] = 1, and for every integer m \u2265 1, sup_{n,i<j} E[|X_{ij}|^m] < \u221e.\n- The diagonal entries X_{ii} are independent of the off-diagonal entries, satisfy E[X_{ii}] = 0, and sup_{n,i} E[|X_{ii}|^m] < \u221e for every m \u2265 1.\n\nForm W_n by setting (W_n)_{ij} = X_{ij} for i \u2264 j and (W_n)_{ij} = X_{ji} for i > j. Define the scaled matrix M_n := W_n / \u221an. Since M_n is symmetric, its eigenvalues are real; write them as \u03bb_1(M_n),\u2026,\u03bb_n(M_n). The empirical spectral distribution (ESD) of M_n is the random probability measure\n\u03bc_{M_n} := (1/n) \u2211_{i=1}^n \u03b4_{\u03bb_i(M_n)} on \u211d.\n\nThe semicircle distribution \u03bc_sc is the probability measure with density\n\u03c1_sc(x) = (1/(2\u03c0)) sqrt(4 \u2212 x^2) on [\u22122,2] and 0 otherwise.\n\nTasks:\n\n1) Limiting expected moments (moment method). For each fixed integer k \u2265 0, prove that\nlim_{n\u2192\u221e} E[ \u222b x^k d\u03bc_{M_n}(x) ] = m_k,\nwhere m_k = 0 if k is odd and m_{2m} = C_m := (1/(m+1)) binom(2m,m) (the mth Catalan number). Your proof must:\n- Expand (1/n) Tr(M_n^k) as a sum over closed index-words i_1,\u2026,i_k with i_{k+1} := i_1.\n- Show that only words in which each unordered edge {i_t,i_{t+1}} appears exactly twice and whose underlying graph is a tree contribute in the limit.\n- Enumerate these contributing words and prove that their number equals C_m (give a self-contained combinatorial argument).\n\n2) Variance vanishes. For each fixed k, prove Var( \u222b x^k d\u03bc_{M_n}(x) ) \u2192 0 as n \u2192 \u221e. In particular, \u222b x^k d\u03bc_{M_n}(x) converges in probability to m_k.\n\n3) Semicircle moments and uniqueness. Compute directly the moments of \u03bc_sc:\nM_{2m} := \u222b_{\u22122}^2 x^{2m} \u03c1_sc(x) dx = C_m and M_{2m+1} = 0. Verify Carleman\u2019s condition \u2211_{m=1}^\u221e M_{2m}^{\u22121/(2m)} = \u221e, and conclude that \u03bc_sc is uniquely determined by its moments.\n\n4) Convergence of the ESD. Prove that \u03bc_{M_n} converges weakly in probability to \u03bc_sc. More precisely: for every bounded continuous \u03c6: \u211d \u2192 \u211d,\n\u222b \u03c6 d\u03bc_{M_n} \u2192 \u222b \u03c6 d\u03bc_sc in probability.\n\nAnswer format:\n- Give a complete, self-contained proof of each task with all definitions used, justified combinatorial counts, and moment/variance bounds.\n- You may assume standard facts about independence, basic combinatorics (Catalan recursion), and basic measure/probability convergence notions, but do not assume any random matrix theory beyond what you prove here.",
        "answer": "To tackle this problem, we will address each task step-by-step, providing detailed proofs and explanations.\n\n### Task 1: Limiting Expected Moments\n\n**Objective:** Show that for each fixed integer $k \\geq 0$,\n$$\n\\lim_{n \\to \\infty} E\\left[ \\int x^k \\, d\\mu_{M_n}(x) \\right] = m_k,\n$$\nwhere $m_k = 0$ if $k$ is odd and $m_{2m} = C_m$.\n\n**Proof:**\n\n1. **Trace Expansion:**\n   The $k$-th moment of the empirical spectral distribution is given by:\n   $$\n   \\frac{1}{n} \\text{Tr}(M_n^k) = \\frac{1}{n} \\sum_{i_1, \\ldots, i_k} (M_n)_{i_1 i_2} (M_n)_{i_2 i_3} \\cdots (M_n)_{i_k i_1}.\n   $$\n   Since $M_n = W_n / \\sqrt{n}$, we have:\n   $$\n   (M_n)_{ij} = \\frac{X_{ij}}{\\sqrt{n}} \\quad \\text{for } i \\leq j, \\quad \\text{and} \\quad (M_n)_{ij} = \\frac{X_{ji}}{\\sqrt{n}} \\quad \\text{for } i > j.\n   $$\n\n2. **Expectation and Independence:**\n   By linearity of expectation and independence of entries:\n   $$\n   E\\left[\\frac{1}{n} \\text{Tr}(M_n^k)\\right] = \\frac{1}{n^{k/2}} \\sum_{i_1, \\ldots, i_k} E[X_{i_1 i_2} X_{i_2 i_3} \\cdots X_{i_k i_1}].\n   $$\n   The expectation is non-zero only if each index pair $\\{i_t, i_{t+1}\\}$ appears exactly twice, forming a closed walk.\n\n3. **Contribution of Trees:**\n   For large $n$, only contributions from closed walks that form trees (acyclic connected graphs) survive. This is because any cycle would contribute terms that vanish as $n \\to \\infty$ due to the $1/n$ factor.\n\n4. **Counting Trees:**\n   The number of such trees (non-crossing pairings) is given by the Catalan number $C_m$ for $k = 2m$. This is a well-known combinatorial result: the number of ways to pair $2m$ elements such that no two pairs cross is $C_m$.\n\n5. **Conclusion:**\n   Thus, for even $k = 2m$,\n   $$\n   \\lim_{n \\to \\infty} E\\left[\\frac{1}{n} \\text{Tr}(M_n^{2m})\\right] = C_m.\n   $$\n   For odd $k$, the expectation is zero because there is no way to pair an odd number of indices into non-crossing pairs.\n\n### Task 2: Variance Vanishes\n\n**Objective:** Show that $\\text{Var}\\left( \\int x^k \\, d\\mu_{M_n}(x) \\right) \\to 0$ as $n \\to \\infty$.\n\n**Proof:**\n\n1. **Variance Expression:**\n   $$\n   \\text{Var}\\left(\\frac{1}{n} \\text{Tr}(M_n^k)\\right) = E\\left[\\left(\\frac{1}{n} \\text{Tr}(M_n^k)\\right)^2\\right] - \\left(E\\left[\\frac{1}{n} \\text{Tr}(M_n^k)\\right]\\right)^2.\n   $$\n\n2. **Bounding the Second Moment:**\n   The second moment involves terms of the form:\n   $$\n   E\\left[\\frac{1}{n^k} \\text{Tr}(M_n^k) \\text{Tr}(M_n^k)\\right].\n   $$\n   This expands to sums over products of traces, which involve terms with indices appearing at most four times.\n\n3. **Vanishing Contributions:**\n   For large $n$, contributions from terms where indices appear more than twice vanish due to the $1/n$ factor. The dominant terms are those where indices appear exactly twice, similar to the expectation case.\n\n4. **Conclusion:**\n   Thus, the variance vanishes as $n \\to \\infty$, implying convergence in probability:\n   $$\n   \\frac{1}{n} \\text{Tr}(M_n^k) \\xrightarrow{P} m_k.\n   $$\n\n### Task 3: Semicircle Moments and Uniqueness\n\n**Objective:** Compute moments of $\\mu_{sc}$ and verify Carleman\u2019s condition.\n\n**Proof:**\n\n1. **Semicircle Moments:**\n   The density of the semicircle distribution is:\n   $$\n   \\rho_{sc}(x) = \\frac{1}{2\\pi} \\sqrt{4 - x^2} \\quad \\text{for } x \\in [-2, 2].\n   $$\n   Compute:\n   $$\n   M_{2m} = \\int_{-2}^2 x^{2m} \\rho_{sc}(x) \\, dx.\n   $$\n   Using symmetry and substitution $x = 2 \\cos \\theta$, this integral evaluates to $C_m$.\n\n2. **Carleman\u2019s Condition:**\n   $$\n   \\sum_{m=1}^\\infty M_{2m}^{-1/(2m)} = \\sum_{m=1}^\\infty C_m^{-1/(2m)} = \\infty.\n   $$\n   This follows from the asymptotic behavior of Catalan numbers: $C_m \\sim \\frac{4^m}{m^{3/2} \\sqrt{\\pi}}$.\n\n3. **Uniqueness:**\n   By Carleman\u2019s condition, the semicircle distribution is uniquely determined by its moments.\n\n### Task 4: Convergence of the ESD\n\n**Objective:** Show $\\mu_{M_n}$ converges weakly in probability to $\\mu_{sc}$.\n\n**Proof:**\n\n1. **Weak Convergence:**\n   For any bounded continuous function $\\phi: \\mathbb{R} \\to \\mathbb{R}$,\n   $$\n   \\int \\phi \\, d\\mu_{M_n} = \\frac{1}{n} \\sum_{i=1}^n \\phi(\\lambda_i(M_n)).\n   $$\n\n2. **Convergence in Probability:**\n   By the moment method and variance vanishing, for each $k$,\n   $$\n   \\frac{1}{n} \\sum_{i=1}^n \\lambda_i(M_n)^k \\xrightarrow{P} m_k.\n   $$\n   This implies convergence of moments, and by the continuity theorem for probability measures, $\\mu_{M_n}$ converges weakly to $\\mu_{sc}$.\n\n3. **Conclusion:**\n   Thus, for every bounded continuous $\\phi$,\n   $$\n   \\int \\phi \\, d\\mu_{M_n} \\xrightarrow{P} \\int \\phi \\, d\\mu_{sc}.\n   $$\n\nThis completes the proof for each task, demonstrating the convergence of the empirical spectral distribution to the semicircle law."
    },
    "9": {
        "question": "Title: Poisson summation for Schwartz functions, the theta transformation, and the functional equation of the Riemann zeta function\n\nLet S(R) denote the Schwartz space on the real line: f \u2208 S(R) if f: R \u2192 C is smooth and for every pair of nonnegative integers m,k one has sup_{x\u2208R} |x^m f^{(k)}(x)| < \u221e. For f \u2208 S(R), define its Fourier transform by\nhat f(\u03be) = \u222b_{\u2212\u221e}^{\u221e} f(x) e^{\u22122\u03c0 i x \u03be} dx, \u03be \u2208 R.\n\nDefine the Jacobi theta function \u03b8: (0,\u221e) \u2192 R by \u03b8(t) = \u2211_{n\u2208Z} e^{\u2212\u03c0 t n^2}. For Re s > 1, define the Riemann zeta function \u03b6(s) = \u2211_{n=1}^\u221e n^{\u2212s}. Let \u0393 denote the Euler gamma function \u0393(s) = \u222b_0^\u221e t^{s\u22121} e^{\u2212t} dt for Re s > 0.\n\nTask. Prove, self-contained and in order:\n\n1) Poisson Summation Formula (PSF). Prove that for every f \u2208 S(R),\n\u2211_{n\u2208Z} f(n) = \u2211_{k\u2208Z} hat f(k).\nYour proof must be complete and include: (i) the uniform absolute convergence (with all derivatives) of the periodization F(x) = \u2211_{n\u2208Z} f(x+n), hence F is 1-periodic and smooth; (ii) computation of the Fourier coefficients of F and absolute convergence of its Fourier series.\n\n2) Theta transformation formula. For t > 0, consider g_t(x) = e^{\u2212\u03c0 t x^2}. Prove that hat g_t(\u03be) = t^{\u22121/2} e^{\u2212\u03c0 \u03be^2 / t} (compute the Fourier transform of the Gaussian). Deduce from PSF the Jacobi identity\n\u03b8(t) = t^{\u22121/2} \u03b8(1/t) for all t > 0.\nShow also that \u03b8(t) \u2212 1 = 2 \u2211_{n=1}^\u221e e^{\u2212\u03c0 n^2 t} decays exponentially as t \u2192 +\u221e and that \u03b8(t) \u223c t^{\u22121/2} as t \u2192 0+.\n\n3) Functional equation for \u03b6. For s \u2208 C, set \u039b(s) = \u03c0^{\u2212s/2} \u0393(s/2) \u03b6(s). Prove:\n- For Re s > 1, the Mellin transform identity\n\u222b_0^\u221e (\u03b8(t) \u2212 1) t^{s/2 \u2212 1} dt = 2 \u039b(s).\nJustify the exchange of sum and integral rigorously.\n- Show that the integral\nJ(s) := \u222b_1^\u221e (\u03b8(t) \u2212 1) (t^{s/2 \u2212 1} + t^{\u2212(s+1)/2}) dt\nconverges absolutely for all s \u2208 C and defines an entire function, and that J(s) = J(1 \u2212 s).\n- Prove, for Re s > 1,\n2 \u039b(s) = J(s) + 2/(s \u2212 1) \u2212 2/s,\nand conclude by analytic continuation that \u039b(s) = \u039b(1 \u2212 s) for all s \u2208 C, i.e.\n\u03c0^{\u2212s/2} \u0393(s/2) \u03b6(s) = \u03c0^{\u2212(1\u2212s)/2} \u0393((1\u2212s)/2) \u03b6(1 \u2212 s).\nFinally, deduce that \u03b6(s) extends meromorphically to C with a unique simple pole at s = 1 of residue 1.\n\nAnswer format: Provide complete proofs of (1), (2), and (3), justifying uniform/absolute convergence and all interchanges of limiting operations. State the final functional equation explicitly.",
        "answer": "To tackle this problem, we will proceed step-by-step through the three main tasks: proving the Poisson Summation Formula (PSF), deriving the theta transformation formula, and establishing the functional equation for the Riemann zeta function.\n\n### 1) Poisson Summation Formula (PSF)\n\n**Step 1: Periodization and Smoothness**\n\nFor $f \\in S(\\mathbb{R})$, define the periodization $F(x) = \\sum_{n \\in \\mathbb{Z}} f(x+n)$. We need to show that $F(x)$ is smooth and 1-periodic.\n\n- **Smoothness**: Since $f$ is smooth and rapidly decreasing, for any $m, k \\geq 0$, there exists a constant $C_{m,k}$ such that $|x^m f^{(k)}(x)| \\leq C_{m,k}$. The series $\\sum_{n \\in \\mathbb{Z}} f^{(k)}(x+n)$ converges uniformly because $f^{(k)}(x+n)$ decays rapidly as $|n| \\to \\infty$. Thus, $F^{(k)}(x) = \\sum_{n \\in \\mathbb{Z}} f^{(k)}(x+n)$ is well-defined and smooth.\n\n- **1-Periodicity**: Clearly, $F(x+1) = \\sum_{n \\in \\mathbb{Z}} f(x+1+n) = \\sum_{m \\in \\mathbb{Z}} f(x+m) = F(x)$.\n\n**Step 2: Fourier Coefficients and Series**\n\nThe Fourier series of $F(x)$ is given by:\n$$\nF(x) = \\sum_{k \\in \\mathbb{Z}} c_k e^{2\\pi i k x}\n$$\nwhere $c_k = \\int_0^1 F(x) e^{-2\\pi i k x} \\, dx$.\n\nCompute $c_k$:\n$$\nc_k = \\int_0^1 \\sum_{n \\in \\mathbb{Z}} f(x+n) e^{-2\\pi i k x} \\, dx = \\sum_{n \\in \\mathbb{Z}} \\int_n^{n+1} f(x) e^{-2\\pi i k x} \\, dx = \\sum_{n \\in \\mathbb{Z}} \\int_0^1 f(x+n) e^{-2\\pi i k x} \\, dx\n$$\n$$\n= \\sum_{n \\in \\mathbb{Z}} e^{-2\\pi i k n} \\int_0^1 f(x+n) e^{-2\\pi i k x} \\, dx = \\int_{-\\infty}^{\\infty} f(x) e^{-2\\pi i k x} \\, dx = \\hat{f}(k)\n$$\n\nThus, $F(x) = \\sum_{k \\in \\mathbb{Z}} \\hat{f}(k) e^{2\\pi i k x}$.\n\n**Step 3: Poisson Summation Formula**\n\nEvaluate $F(0)$:\n$$\nF(0) = \\sum_{n \\in \\mathbb{Z}} f(n) = \\sum_{k \\in \\mathbb{Z}} \\hat{f}(k)\n$$\n\nThis completes the proof of the Poisson Summation Formula:\n$$\n\\sum_{n \\in \\mathbb{Z}} f(n) = \\sum_{k \\in \\mathbb{Z}} \\hat{f}(k)\n$$\n\n### 2) Theta Transformation Formula\n\n**Step 1: Fourier Transform of Gaussian**\n\nConsider $g_t(x) = e^{-\\pi t x^2}$. Compute its Fourier transform:\n$$\n\\hat{g}_t(\\xi) = \\int_{-\\infty}^{\\infty} e^{-\\pi t x^2} e^{-2\\pi i x \\xi} \\, dx\n$$\n\nComplete the square in the exponent:\n$$\n-\\pi t x^2 - 2\\pi i x \\xi = -\\pi t \\left(x^2 + \\frac{2i\\xi}{t} x\\right) = -\\pi t \\left((x + \\frac{i\\xi}{t})^2 - \\frac{\\xi^2}{t^2}\\right)\n$$\n$$\n= -\\pi t (x + \\frac{i\\xi}{t})^2 + \\frac{\\pi \\xi^2}{t}\n$$\n\nThus,\n$$\n\\hat{g}_t(\\xi) = e^{-\\pi \\xi^2 / t} \\int_{-\\infty}^{\\infty} e^{-\\pi t (x + i\\xi/t)^2} \\, dx\n$$\n\nThe integral is a Gaussian integral:\n$$\n\\int_{-\\infty}^{\\infty} e^{-\\pi t u^2} \\, du = t^{-1/2}\n$$\n\nTherefore,\n$$\n\\hat{g}_t(\\xi) = t^{-1/2} e^{-\\pi \\xi^2 / t}\n$$\n\n**Step 2: Jacobi Identity**\n\nUsing PSF on $g_t(x)$:\n$$\n\\sum_{n \\in \\mathbb{Z}} e^{-\\pi t n^2} = \\sum_{k \\in \\mathbb{Z}} \\hat{g}_t(k) = t^{-1/2} \\sum_{k \\in \\mathbb{Z}} e^{-\\pi k^2 / t}\n$$\n\nThus, $\\theta(t) = t^{-1/2} \\theta(1/t)$.\n\n**Step 3: Asymptotic Behavior**\n\n- As $t \\to +\\infty$, $\\theta(t) - 1 = 2 \\sum_{n=1}^{\\infty} e^{-\\pi n^2 t}$ decays exponentially because each term $e^{-\\pi n^2 t}$ decays exponentially.\n\n- As $t \\to 0^+$, $\\theta(t) \\sim t^{-1/2}$ because the leading term in the series is $1$, and the next term is $2$.\n\n### 3) Functional Equation for $\\zeta$\n\n**Step 1: Mellin Transform Identity**\n\nFor $\\text{Re } s > 1$,\n$$\n\\int_0^{\\infty} (\\theta(t) - 1) t^{s/2 - 1} \\, dt = 2 \\int_0^{\\infty} \\sum_{n=1}^{\\infty} e^{-\\pi n^2 t} t^{s/2 - 1} \\, dt\n$$\n\nExchange sum and integral:\n$$\n= 2 \\sum_{n=1}^{\\infty} \\int_0^{\\infty} e^{-\\pi n^2 t} t^{s/2 - 1} \\, dt\n$$\n\nThe integral is a Gamma function:\n$$\n\\int_0^{\\infty} e^{-\\pi n^2 t} t^{s/2 - 1} \\, dt = (\\pi n^2)^{-s/2} \\Gamma(s/2)\n$$\n\nThus,\n$$\n= 2 \\Gamma(s/2) \\sum_{n=1}^{\\infty} n^{-s} = 2 \\Gamma(s/2) \\zeta(s) = 2 \\Lambda(s)\n$$\n\n**Step 2: Convergence of $J(s)$**\n\nDefine:\n$$\nJ(s) = \\int_1^{\\infty} (\\theta(t) - 1) (t^{s/2 - 1} + t^{-(s+1)/2}) \\, dt\n$$\n\n- For $\\text{Re } s > 1$, $t^{s/2 - 1}$ and $t^{-(s+1)/2}$ ensure convergence at $t = \\infty$.\n\n- For $\\text{Re } s < 0$, $t^{-(s+1)/2}$ ensures convergence at $t = \\infty$.\n\n- At $t = 1$, both terms are bounded, ensuring convergence.\n\nThus, $J(s)$ converges absolutely for all $s \\in \\mathbb{C}$ and defines an entire function.\n\n**Step 3: Symmetry of $J(s)$**\n\nUsing the Jacobi identity:\n$$\n\\theta(t) = t^{-1/2} \\theta(1/t)\n$$\n\n$$\nJ(s) = \\int_1^{\\infty} (t^{-1/2} \\theta(1/t) - 1) (t^{s/2 - 1} + t^{-(s+1)/2}) \\, dt\n$$\n\nChange variables $u = 1/t$, $dt = -u^{-2} du$:\n$$\n= \\int_0^1 (u^{1/2} \\theta(u) - 1) (u^{-(s+1)/2} + u^{s/2 - 1}) u^{-2} (-du)\n$$\n\n$$\n= \\int_0^1 (u^{1/2} \\theta(u) - 1) (u^{-(s+3)/2} + u^{s/2 - 3}) \\, du\n$$\n\n$$\n= \\int_0^1 (\\theta(u) - u^{-1/2}) (u^{(1-s)/2 - 1} + u^{s/2 - 1}) \\, du\n$$\n\n$$\n= J(1-s)\n$$\n\n**Step 4: Functional Equation**\n\nFor $\\text{Re } s > 1$:\n$$\n2 \\Lambda(s) = J(s) + 2/(s-1) - 2/s\n$$\n\nUsing analytic continuation and symmetry $J(s) = J(1-s)$, we have:\n$$\n2 \\Lambda(s) = J(s) + 2/(s-1) - 2/s = J(1-s) + 2/(s-1) - 2/s\n$$\n\nThus,\n$$\n2 \\Lambda(s) = 2 \\Lambda(1-s) + 2/(s-1) - 2/s - 2/(1-s) + 2/(1-s)\n$$\n\nSimplifying gives:\n$$\n\\Lambda(s) = \\Lambda(1-s)\n$$\n\n**Final Functional Equation**\n\n$$\n\\pi^{-s/2} \\Gamma(s/2) \\zeta(s) = \\pi^{-(1-s)/2} \\Gamma((1-s)/2) \\zeta(1-s)\n$$\n\n**Meromorphic Extension of $\\zeta(s)$**\n\nThe functional equation implies that $\\zeta(s)$ extends meromorphically to $\\mathbb{C}$ with a simple pole at $s = 1$ of residue 1. This completes the proof."
    },
    "10": {
        "question": "Title: Lucas\u2019 theorem, Kummer\u2019s theorem, and sharp digit\u2013carry structure of binomial coefficients\n\nLet p be a fixed prime. For a nonnegative integer n, write its base-p expansion as n = \u2211_{i=0}^r n_i p^i with digits n_i \u2208 {0,1,\u2026,p\u22121}; define the base-p digit sum s_p(n) = \u2211_{i=0}^r n_i. For integers n \u2265 k \u2265 0, write v_p(m) for the exponent of p in m (i.e., the largest e \u2265 0 with p^e | m; for m = 0 set v_p(0) = +\u221e). For a,b \u2265 0, define Carr_p(a,b) as the number of carries that occur when adding a and b in base p (i.e., the number of positions where the base-p addition algorithm produces a carry to the next higher digit).\n\nProblem. Prove, self-contained and in order:\n\n1) Lucas\u2019 theorem (mod p digitwise factorization). For all integers n,k \u2265 0 with base-p expansions n = \u2211 n_i p^i and k = \u2211 k_i p^i, show\n   binom(n,k) \u2261 \u220f_{i=0}^r binom(n_i, k_i) (mod p),\nwith the convention binom(a,b) = 0 when b > a. Conclude that binom(n,k) \u2262 0 (mod p) if and only if k_i \u2264 n_i for all i.\n\n2) Legendre\u2019s formula and Kummer\u2019s theorem. Prove Legendre\u2019s formula\n   v_p(n!) = \u2211_{j=1}^\u221e \u23a3n/p^j\u23a6 = (n \u2212 s_p(n)) / (p \u2212 1).\nDeduce Kummer\u2019s theorem:\n   v_p(binom(n,k)) = Carr_p(k, n \u2212 k).\nEquivalently, using Legendre,\n   v_p(binom(n,k)) = ( s_p(k) + s_p(n \u2212 k) \u2212 s_p(n) ) / (p \u2212 1).\nProve the identity Carr_p(a,b) = ( s_p(a) + s_p(b) \u2212 s_p(a + b) ) / (p \u2212 1) for all a,b \u2265 0 in base p to justify the equality with carries.\n\n3) Two sharp applications.\n   a) Count of nonzero binomial coefficients mod p. Prove that the number of k \u2208 {0,\u2026,n} with binom(n,k) \u2262 0 (mod p) equals \u220f_{i=0}^r (n_i + 1). In particular, for p = 2 this number equals 2^{popcount(n)}, the power of 2 determined by the number of 1s in the binary expansion of n.\n   b) The 2-adic valuation of the central binomial coefficient. Prove that\n      v_2( binom(2n, n) ) = s_2(n).\n(Equivalently, the highest power of 2 dividing binom(2n,n) equals 2^{s_2(n)}.)\n\nAnswer format: Provide complete, rigorous proofs of (1) and (2), including all justifications for congruences and identities with digit sums and carries. Then prove both statements in (3), clearly citing the earlier results where needed.",
        "answer": "To tackle this problem, we will go through each part step by step, providing rigorous proofs and justifications.\n\n### 1) Lucas\u2019 Theorem\n\n**Statement:** For all integers $n, k \\geq 0$ with base-$p$ expansions $n = \\sum n_i p^i$ and $k = \\sum k_i p^i$, show\n$$\n\\binom{n}{k} \\equiv \\prod_{i=0}^r \\binom{n_i}{k_i} \\pmod{p}\n$$\nwith the convention $\\binom{a}{b} = 0$ when $b > a$. Conclude that $\\binom{n}{k} \\not\\equiv 0 \\pmod{p}$ if and only if $k_i \\leq n_i$ for all $i$.\n\n**Proof:**\n\n- **Base Case:** Consider $n = n_0$ and $k = k_0$. Then $\\binom{n}{k} = \\binom{n_0}{k_0}$, and the statement holds trivially.\n\n- **Inductive Step:** Assume the theorem holds for all integers less than $n$. Write $n = n_r p^r + \\cdots + n_0$ and $k = k_r p^r + \\cdots + k_0$.\n\n  Consider the binomial coefficient $\\binom{n}{k}$. By the definition of binomial coefficients:\n  $$\n  \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n  $$\n\n  Using the base-$p$ expansions, we can express $n!$, $k!$, and $(n-k)!$ in terms of their base-$p$ digits. The key observation is that the binomial coefficient modulo $p$ depends only on the coefficients of the lowest powers of $p$ in the factorials.\n\n  By the inductive hypothesis, for each $i$, $\\binom{n_i}{k_i} \\equiv \\binom{n_i}{k_i} \\pmod{p}$. Therefore, the product $\\prod_{i=0}^r \\binom{n_i}{k_i}$ captures the behavior of $\\binom{n}{k}$ modulo $p$.\n\n  If $k_i > n_i$ for any $i$, then $\\binom{n_i}{k_i} = 0$, making the entire product zero, and thus $\\binom{n}{k} \\equiv 0 \\pmod{p}$.\n\n  Conversely, if $k_i \\leq n_i$ for all $i$, then each $\\binom{n_i}{k_i}$ is non-zero modulo $p$, and thus $\\binom{n}{k} \\not\\equiv 0 \\pmod{p}$.\n\n### 2) Legendre\u2019s Formula and Kummer\u2019s Theorem\n\n**Legendre\u2019s Formula:**\n\n**Statement:** $v_p(n!) = \\sum_{j=1}^\\infty \\left\\lfloor \\frac{n}{p^j} \\right\\rfloor = \\frac{n - s_p(n)}{p - 1}$.\n\n**Proof:**\n\n- The $p$-adic valuation $v_p(n!)$ counts the number of factors of $p$ in $n!$. Each integer $m \\leq n$ contributes a factor of $p$ if $m$ is divisible by $p$, $p^2$, etc.\n\n- The number of multiples of $p^j$ up to $n$ is $\\left\\lfloor \\frac{n}{p^j} \\right\\rfloor$.\n\n- Therefore, $v_p(n!) = \\sum_{j=1}^\\infty \\left\\lfloor \\frac{n}{p^j} \\right\\rfloor$.\n\n- To show $v_p(n!) = \\frac{n - s_p(n)}{p - 1}$, note that:\n  $$\n  n = \\sum_{i=0}^r n_i p^i \\quad \\text{and} \\quad s_p(n) = \\sum_{i=0}^r n_i\n  $$\n\n- The sum $\\sum_{j=1}^\\infty \\left\\lfloor \\frac{n}{p^j} \\right\\rfloor$ can be rewritten using the base-$p$ expansion:\n  $$\n  \\sum_{j=1}^\\infty \\left\\lfloor \\frac{n}{p^j} \\right\\rfloor = \\sum_{j=1}^\\infty \\left( \\sum_{i=j}^r n_i p^{i-j} \\right) = \\sum_{i=1}^r n_i \\frac{p^i - 1}{p - 1}\n  $$\n\n- Simplifying, we get:\n  $$\n  \\sum_{i=1}^r n_i \\frac{p^i - 1}{p - 1} = \\frac{1}{p-1} \\left( \\sum_{i=1}^r n_i p^i - \\sum_{i=1}^r n_i \\right) = \\frac{n - s_p(n)}{p - 1}\n  $$\n\n**Kummer\u2019s Theorem:**\n\n**Statement:** $v_p\\left(\\binom{n}{k}\\right) = \\text{Carr}_p(k, n-k)$.\n\n**Proof:**\n\n- By Legendre\u2019s formula:\n  $$\n  v_p\\left(\\binom{n}{k}\\right) = v_p(n!) - v_p(k!) - v_p((n-k)!)\n  $$\n\n- Using Legendre\u2019s formula for each factorial:\n  $$\n  v_p(n!) = \\frac{n - s_p(n)}{p - 1}, \\quad v_p(k!) = \\frac{k - s_p(k)}{p - 1}, \\quad v_p((n-k)!) = \\frac{n-k - s_p(n-k)}{p - 1}\n  $$\n\n- Therefore:\n  $$\n  v_p\\left(\\binom{n}{k}\\right) = \\frac{n - s_p(n) - (k - s_p(k)) - (n-k - s_p(n-k))}{p - 1}\n  $$\n\n- Simplifying:\n  $$\n  v_p\\left(\\binom{n}{k}\\right) = \\frac{s_p(k) + s_p(n-k) - s_p(n)}{p - 1}\n  $$\n\n- The identity $\\text{Carr}_p(a,b) = \\frac{s_p(a) + s_p(b) - s_p(a+b)}{p - 1}$ shows that:\n  $$\n  v_p\\left(\\binom{n}{k}\\right) = \\text{Carr}_p(k, n-k)\n  $$\n\n### 3) Applications\n\n**a) Count of Nonzero Binomial Coefficients Mod $p$:**\n\n**Statement:** The number of $k \\in \\{0, \\ldots, n\\}$ with $\\binom{n}{k} \\not\\equiv 0 \\pmod{p}$ equals $\\prod_{i=0}^r (n_i + 1)$.\n\n**Proof:**\n\n- From Lucas\u2019 theorem, $\\binom{n}{k} \\not\\equiv 0 \\pmod{p}$ if and only if $k_i \\leq n_i$ for all $i$.\n\n- For each digit $n_i$, there are $n_i + 1$ choices for $k_i$ (from $0$ to $n_i$).\n\n- Therefore, the total number of such $k$ is $\\prod_{i=0}^r (n_i + 1)$.\n\n- For $p = 2$, this becomes $2^{\\text{popcount}(n)}$, where $\\text{popcount}(n)$ is the number of 1s in the binary expansion of $n$.\n\n**b) The 2-adic Valuation of the Central Binomial Coefficient:**\n\n**Statement:** $v_2\\left(\\binom{2n}{n}\\right) = s_2(n)$.\n\n**Proof:**\n\n- Using Kummer\u2019s theorem:\n  $$\n  v_2\\left(\\binom{2n}{n}\\right) = \\text{Carr}_2(n, n)\n  $$\n\n- The identity $\\text{Carr}_2(a, b) = \\frac{s_2(a) + s_2(b) - s_2(a+b)}{1}$ gives:\n  $$\n  \\text{Carr}_2(n, n) = s_2(n) + s_2(n) - s_2(2n)\n  $$\n\n- Since $2n$ in binary is just $n$ shifted left by one bit, $s_2(2n) = s_2(n)$.\n\n- Therefore:\n  $$\n  v_2\\left(\\binom{2n}{n}\\right) = s_2(n)\n  $$\n\nThis completes the proofs for all parts of the problem."
    },
    "11": {
        "question": "Title: Extremal intersecting families of k-sets \u2014 the Erd\u0151s\u2013Ko\u2013Rado theorem and the sharp Hilton\u2013Milner refinement with full structure\n\nLet n and k be integers with 1 \u2264 k \u2264 n. Write [n] := {1,2,\u2026,n}. A family F \u2282 binom([n], k) (the set of all k-element subsets of [n]) is intersecting if A \u2229 B \u2260 \u2205 for all A,B \u2208 F. The intersection of all members is \u22c2_{A\u2208F} A; it may be empty.\n\nTasks.\n\n1) Erd\u0151s\u2013Ko\u2013Rado (EKR). Prove that if n \u2265 2k and F \u2282 binom([n], k) is intersecting, then |F| \u2264 binom(n\u22121, k\u22121).\n\nMoreover, determine all families attaining equality.\n- If n > 2k, show that the only maximum families are the \u201cstars\u201d St(i) := {A \u2208 binom([n], k) : i \u2208 A}, up to relabeling of [n].\n- If n = 2k, show that the maximum families are exactly the stars St(i) and the \u201cco-stars\u201d CoSt(i) := {A \u2208 binom([n], k) : i \u2209 A}, up to relabeling.\n\n2) Hilton\u2013Milner theorem (sharp refinement without a common element). Assume n > 2k and F \u2282 binom([n], k) is intersecting with empty total intersection \u22c2_{A\u2208F} A = \u2205. Prove that\n|F| \u2264 binom(n\u22121, k\u22121) \u2212 binom(n\u2212k\u22121, k\u22121) + 1.\n\nShow that equality holds precisely for the following structure (up to relabeling): fix an element 1 \u2208 [n] and a k-set B \u2282 [n]\\{1}, and set\nHM(1,B) := {A \u2208 binom([n], k) : 1 \u2208 A and A \u2229 B \u2260 \u2205} \u222a {B}.\nProve that HM(1,B) is intersecting with empty total intersection, has size binom(n\u22121,k\u22121) \u2212 binom(n\u2212k\u22121,k\u22121) + 1, and that every maximum family with empty total intersection is of this form.\n\nAnswer format:\n- State the final bounds and the extremal structures.\n- Provide complete, rigorous proofs: an EKR proof (you may use the cycle method or shifting/compressions) with equality characterization, and a Hilton\u2013Milner proof with both the bound and the exact extremal structure.",
        "answer": "To solve this problem, we need to address two main parts: the Erd\u0151s\u2013Ko\u2013Rado (EKR) theorem and the Hilton\u2013Milner theorem. Let's go through each part step by step.\n\n### Part 1: Erd\u0151s\u2013Ko\u2013Rado (EKR) Theorem\n\n**Statement:**\nIf $n \\geq 2k$ and $F \\subset \\binom{[n]}{k}$ is intersecting, then $|F| \\leq \\binom{n-1}{k-1}$.\n\n**Proof:**\n1. **Cycle Method/Compression Argument:**\n   - Consider any intersecting family $F$. For each $A \\in F$, choose a fixed element $x \\in A$. Without loss of generality, assume $x = 1$.\n   - Define $F_1 = \\{ A \\setminus \\{1\\} : A \\in F, 1 \\in A \\}$. Note that $F_1 \\subset \\binom{[n] \\setminus \\{1\\}}{k-1}$.\n   - Since $F$ is intersecting, for any $A, B \\in F$, $A \\cap B \\neq \\emptyset$. Thus, $(A \\setminus \\{1\\}) \\cap (B \\setminus \\{1\\}) \\neq \\emptyset$ whenever $1 \\in A \\cap B$.\n   - Therefore, $|F_1| \\leq \\binom{n-1}{k-1}$.\n\n2. **Equality Characterization:**\n   - If $n > 2k$, the only families achieving equality are the \"stars\" $S_t(i) = \\{ A \\in \\binom{[n]}{k} : i \\in A \\}$.\n   - If $n = 2k$, the maximum families are the stars $S_t(i)$ and the \"co-stars\" $C_t(i) = \\{ A \\in \\binom{[n]}{k} : i \\notin A \\}$.\n\n### Part 2: Hilton\u2013Milner Theorem\n\n**Statement:**\nAssume $n > 2k$ and $F \\subset \\binom{[n]}{k}$ is intersecting with empty total intersection $\\bigcap_{A \\in F} A = \\emptyset$. Then:\n$$ |F| \\leq \\binom{n-1}{k-1} - \\binom{n-k-1}{k-1} + 1. $$\n\n**Proof:**\n1. **Bound:**\n   - Consider the family $F$ with empty total intersection. For each $A \\in F$, choose a fixed element $x \\in A$. Assume $x = 1$.\n   - Define $F_1 = \\{ A \\setminus \\{1\\} : A \\in F, 1 \\in A \\}$. Then $F_1 \\subset \\binom{[n] \\setminus \\{1\\}}{k-1}$.\n   - Since $\\bigcap_{A \\in F} A = \\emptyset$, there exists some $j \\notin \\bigcap_{A \\in F} A$. Consider the family $F_j = \\{ A \\setminus \\{j\\} : A \\in F, j \\in A \\}$.\n   - By the EKR theorem, $|F_1| \\leq \\binom{n-1}{k-1}$ and $|F_j| \\leq \\binom{n-1}{k-1}$.\n   - The overlap $F_1 \\cap F_j$ corresponds to sets $A$ such that $1, j \\in A$, which are counted in $\\binom{n-2}{k-2}$.\n   - Thus, $|F| \\leq |F_1| + |F_j| - \\binom{n-2}{k-2} + 1$.\n   - Simplifying, $|F| \\leq \\binom{n-1}{k-1} - \\binom{n-k-1}{k-1} + 1$.\n\n2. **Extremal Structure:**\n   - Equality holds for the structure $HM(1, B) = \\{ A \\in \\binom{[n]}{k} : 1 \\in A \\text{ and } A \\cap B \\neq \\emptyset \\} \\cup \\{ B \\}$.\n   - Here, $B \\subset [n] \\setminus \\{1\\}$ is a $k$-set.\n   - $HM(1, B)$ is intersecting and has empty total intersection.\n   - The size is $\\binom{n-1}{k-1} - \\binom{n-k-1}{k-1} + 1$.\n\n**Conclusion:**\n- **EKR Bound:** $|F| \\leq \\binom{n-1}{k-1}$.\n- **EKR Extremal Structures:** Stars $S_t(i)$ for $n > 2k$, and stars and co-stars for $n = 2k$.\n- **Hilton\u2013Milner Bound:** $|F| \\leq \\binom{n-1}{k-1} - \\binom{n-k-1}{k-1} + 1$.\n- **Hilton\u2013Milner Extremal Structure:** $HM(1, B)$ as described."
    },
    "12": {
        "question": "Title: Finite subgroups of SO(3) \u2014 a complete classification via poles and a sharp counting argument\n\nLet S^2 \u2282 R^3 be the unit sphere and let SO(3) be the group of orientation-preserving isometries of S^2 (i.e., rotations of R^3). For a finite subgroup G \u2264 SO(3), call a point p \u2208 S^2 a pole if p is fixed by some non-identity element of G. For p \u2208 S^2, write G_p = {g \u2208 G : g\u00b7p = p} for the stabilizer of p, and let n_p := |G_p|.\n\nTasks.\n\n1) Poles, stabilizers, and a counting identity. Prove:\n   a) Every non-identity rotation in SO(3) fixes exactly two points of S^2 (the endpoints of its axis). For a pole p of G, the stabilizer G_p is cyclic and consists of all rotations about the line through p and \u2212p. In particular, n_p \u2265 2.\n   b) Let P be the set of poles of G. Prove the double-counting identity\n      \u2211_{p\u2208P} (n_p \u2212 1) = 2(|G| \u2212 1).\n      Deduce that if P \u2260 \u2205 and k denotes the number of G-orbits in P, then k \u2264 3. Let the distinct orbits be represented by p_1,\u2026,p_k with n_i := |G_{p_i}| and orbit sizes m_i = |G|/n_i. Show that necessarily:\n      - If k = 2, then n_1 = n_2 and |G| = n_1 = n_2.\n      - If k = 3, then (up to reordering)\n        (n_1,n_2,n_3) \u2208 {(2,2,n) with |G| = 2n; (2,3,3) with |G| = 12; (2,3,4) with |G| = 24; (2,3,5) with |G| = 60}.\n\n2) Classification up to conjugacy in SO(3). Prove that every finite subgroup G \u2264 SO(3) is conjugate to exactly one of the following:\n   - A cyclic group C_n (n \u2265 1) of all rotations about a fixed axis by integer multiples of 2\u03c0/n.\n   - A dihedral rotation group D_n (n \u2265 2) of order 2n consisting of all rotations preserving a regular n-gon in some plane: the n rotations about the normal axis and n half-turns about axes in the polygon\u2019s plane through opposite vertices or edge midpoints.\n   - The rotation group of a regular tetrahedron (order 12).\n   - The rotation group of a cube/octahedron (order 24).\n   - The rotation group of an icosahedron/dodecahedron (order 60).\n\n   More precisely, show:\n   - For k = 2, G is conjugate to C_n with n = |G|.\n   - For (n_1,n_2,n_3) = (2,2,n) and |G| = 2n, G is conjugate to D_n.\n   - For (2,3,3), (2,3,4), and (2,3,5), G is conjugate respectively to the rotation groups of the tetrahedron, cube/octahedron, and icosahedron/dodecahedron.\n\n   In each case, compute the number of axes of each rotational order r appearing in G. (An axis of order r means: the set of points \u00b1p on S^2 for which the subgroup G_p has order r.)\n\n3) Isomorphism types and element counts. Show that the three Platonic rotation groups are isomorphic to A_4, S_4, A_5, respectively. Exhibit faithful permutation representations (on 4 vertices for the tetrahedron, on 4 body-diagonals for the cube, and explain a faithful representation on 5 objects for the icosahedron/dodecahedron), and determine the number of elements of orders 2, 3, 4, and 5 in each group.\n\nAnswer format:\n- Prove (1a) and (1b), deriving the listed possibilities for (n_1,n_2,n_3) and |G|.\n- Classify all finite subgroups up to conjugacy as above, meeting the listed cases and computing axis counts.\n- Establish the isomorphisms to A_4, S_4, A_5 and give complete element-order counts in each case.",
        "answer": "To tackle this problem, we need to delve into the structure of finite subgroups of $SO(3)$, the group of rotations in three-dimensional space. Let's break down the tasks step by step.\n\n### Task 1: Poles, Stabilizers, and a Counting Identity\n\n#### 1a) Prove the properties of poles and stabilizers\n\n- **Non-identity rotations in $SO(3)$:** Any non-identity rotation in $SO(3)$ can be represented by a rotation about some axis in $\\mathbb{R}^3$. The axis of rotation is a line through the origin, and the rotation fixes exactly two points on the unit sphere $S^2$: the endpoints of this axis. These are the poles of the rotation.\n\n- **Stabilizer $G_p$:** For a pole $p$ of a finite subgroup $G \\leq SO(3)$, the stabilizer $G_p$ consists of all rotations in $G$ that fix $p$. Since $p$ is fixed, these rotations must be about the line through $p$ and $-p$. Thus, $G_p$ is cyclic, generated by rotations about this axis. The identity rotation is always in $G_p$, and any non-identity element of $G_p$ must be a rotation by some angle $\\theta \\neq 0$, implying $n_p \\geq 2$.\n\n#### 1b) Prove the double-counting identity\n\n- **Double-counting identity:** Consider the action of $G$ on the set of pairs $(g, p)$ where $g \\in G$ and $p$ is a pole of $g$. Each non-identity element $g$ fixes exactly two poles, and each pole $p$ is fixed by $n_p$ elements of $G$. Thus, the total number of such pairs is $2(|G| - 1)$ (since the identity fixes all points, contributing nothing to the count of poles).\n\n- **Counting by poles:** Alternatively, count by fixing poles. For each pole $p$, there are $n_p - 1$ non-identity elements fixing $p$. Summing over all poles $p \\in P$, we get:\n  $$\n  \\sum_{p \\in P} (n_p - 1) = 2(|G| - 1).\n  $$\n\n- **Orbits of poles:** Let $k$ be the number of $G$-orbits in $P$. Each orbit contributes to the sum, and the orbit-stabilizer theorem gives $|G| = m_i n_i$ for each orbit. The identity $\\sum_{i=1}^k (n_i - 1) m_i = 2(|G| - 1)$ implies $k \\leq 3$.\n\n- **Cases for $k$:**\n  - **$k = 2$:** If there are two orbits, then $n_1 = n_2$ and $|G| = n_1$.\n  - **$k = 3$:** Possible tuples $(n_1, n_2, n_3)$ are $(2, 2, n)$, $(2, 3, 3)$, $(2, 3, 4)$, $(2, 3, 5)$ with corresponding $|G|$ values as given.\n\n### Task 2: Classification up to Conjugacy in $SO(3)$\n\n- **Cyclic group $C_n$:** For $k = 2$, $G$ is conjugate to $C_n$, the group of rotations about a fixed axis by multiples of $2\\pi/n$.\n\n- **Dihedral group $D_n$:** For $(n_1, n_2, n_3) = (2, 2, n)$ and $|G| = 2n$, $G$ is conjugate to $D_n$, consisting of rotations about an axis and reflections through planes.\n\n- **Platonic solids:**\n  - **Tetrahedron:** $(2, 3, 3)$ with $|G| = 12$.\n  - **Cube/Octahedron:** $(2, 3, 4)$ with $|G| = 24$.\n  - **Icosahedron/Dodecahedron:** $(2, 3, 5)$ with $|G| = 60$.\n\n### Task 3: Isomorphism Types and Element Counts\n\n- **Isomorphisms:**\n  - **Tetrahedron:** $A_4$, the alternating group on 4 elements.\n  - **Cube/Octahedron:** $S_4$, the symmetric group on 4 elements.\n  - **Icosahedron/Dodecahedron:** $A_5$, the alternating group on 5 elements.\n\n- **Element orders:**\n  - **$A_4$:** Elements of orders 1, 2, 3.\n  - **$S_4$:** Elements of orders 1, 2, 3, 4.\n  - **$A_5$:** Elements of orders 1, 2, 3, 5.\n\n- **Faithful representations:**\n  - **Tetrahedron:** Permutations of 4 vertices.\n  - **Cube:** Permutations of 4 body diagonals.\n  - **Icosahedron:** Permutations of 5 pairs of opposite faces.\n\nThis classification and counting provide a complete understanding of the finite subgroups of $SO(3)$ and their geometric and algebraic properties."
    },
    "13": {
        "question": "Title: Cheeger\u2019s inequality for weighted graphs, a sharp spectral\u2013isoperimetric bridge, and mixing of the lazy random walk \u2014 with an exact cycle computation\n\nLet G = (V, w) be a connected finite undirected weighted graph: V is a finite set of n \u2265 2 vertices, and w: V \u00d7 V \u2192 [0, \u221e) is symmetric, with w(u,u) = 0 and w(u,v) > 0 iff there is an edge between u and v. Define the weighted degree d(u) := \u2211_{v\u2208V} w(u,v), let D be the diagonal matrix with D_{uu}=d(u), and W = [w(u,v)] the weighted adjacency matrix. Define vol(S) := \u2211_{u\u2208S} d(u) and vol(V) := \u2211_{u\u2208V} d(u). For S \u2282 V, write \u2202S := E(S, S^c) for the (weighted) edge boundary, and w(\u2202S) := \u2211_{u\u2208S, v\u2208S^c} w(u,v).\n\nDefine the conductance (Cheeger constant) of G by\n- for nonempty S \u2282 V with vol(S) \u2264 vol(V)/2, \u03a6(S) := w(\u2202S)/vol(S),\n- h(G) := min{ \u03a6(S) : S \u2282 V, S \u2260 \u2205, vol(S) \u2264 vol(V)/2 }.\n\nDefine the normalized Laplacian\nL := I \u2212 D^{\u22121/2} W D^{\u22121/2}.\nIt is real symmetric and positive semidefinite; let 0 = \u03bb_1 < \u03bb_2 \u2264 \u2026 \u2264 \u03bb_n \u2264 2 be its eigenvalues.\n\nLet P_0 := D^{\u22121} W be the (reversible) random-walk transition matrix, and let \u03c0 be its stationary distribution \u03c0(u) = d(u)/vol(V). Define the lazy walk P := (I + P_0)/2.\n\nGoal. Prove the sharp Cheeger inequality for general weighted graphs and deduce a clean mixing bound for the lazy random walk. Then compute everything explicitly for the cycle.\n\nTasks.\n\n1) Variational characterization. Show that for any function f: V \u2192 R with \u2211_{u} d(u) f(u) = 0 and f \u2260 0, the Rayleigh quotient\nR(f) := [ (1/2) \u2211_{u,v\u2208V} w(u,v) (f(u) \u2212 f(v))^2 ] / [ \u2211_{u\u2208V} d(u) f(u)^2 ]\nsatisfies \u03bb_2 = min{ R(f) : f \u2260 0, \u2211 d f = 0 }. Justify the identity between the normalized-Laplacian Rayleigh quotient and the Dirichlet form above.\n\n2) Lower Cheeger bound (easy direction). Prove \u03bb_2 \u2264 2 h(G). Conclude that \u03bb_2/2 \u2264 h(G).\n\n3) Upper Cheeger bound (hard direction). Prove h(G) \u2264 \u221a(2 \u03bb_2). Equivalently, show \u03bb_2 \u2265 h(G)^2/2. Your proof must be complete and self-contained; you may proceed via the reversible Markov-chain Dirichlet form for P_0 and a co-area/sweep argument around a weighted median of an L^2(\u03c0)-orthogonal eigenfunction.\n\n4) Lazy mixing via the spectral gap. Let \u03c1 := 1 \u2212 \u03bb_2/2 be the second-largest eigenvalue of P. Show that for every starting vertex u and every t \u2265 0,\n\u2016P^t(u,\u00b7) \u2212 \u03c0\u2016_{TV} \u2264 (1/(2 \u221a{\u03c0_*})) \u03c1^t \u2264 (1/(2 \u221a{\u03c0_*})) exp(\u2212 (\u03bb_2/2) t),\nwhere \u03c0_* := min_{v\u2208V} \u03c0(v). Deduce the explicit mixing-time bound: for any \u03b5 \u2208 (0,1),\nt_mix(\u03b5) \u2264 (2/\u03bb_2) log( 1/(2 \u03b5 \u221a{\u03c0_*}) ) \u2264 (4/h(G)^2) log( 1/(2 \u03b5 \u221a{\u03c0_*}) ).\nHere t_mix(\u03b5) is the least t with sup_u \u2016P^t(u,\u00b7) \u2212 \u03c0\u2016_{TV} \u2264 \u03b5.\n\n5) Exact cycle case. Let C_n be the unweighted cycle on n \u2265 3 vertices (each vertex has degree 2). Compute exactly:\n- the full spectrum of L and in particular \u03bb_2(C_n) = 1 \u2212 cos(2\u03c0/n) = 2 sin^2(\u03c0/n),\n- the exact conductance h(C_n) = 1/\u230an/2\u230b.\nVerify both Cheeger inequalities for C_n numerically (with the exact quantities), and deduce from (4) the explicit bound\nt_mix(\u03b5) \u2264 (2/(1 \u2212 cos(2\u03c0/n))) log( \u221an /(2\u03b5) ),\nso in particular t_mix(1/4) = O(n^2 log n).\n\nAnswer format: Provide complete, rigorous proofs of (1)\u2013(4) in order, defining any objects you use. Then carry out the exact computations in (5), verify the Cheeger bounds for C_n, and derive the displayed mixing bound.",
        "answer": "To tackle this problem, we will go through each task step-by-step, providing rigorous proofs and computations as required.\n\n### Task 1: Variational Characterization\n\n**Objective:** Show that for any function $f: V \\to \\mathbb{R}$ with $\\sum_{u} d(u) f(u) = 0$ and $f \\neq 0$, the Rayleigh quotient\n\n$$\nR(f) := \\frac{\\frac{1}{2} \\sum_{u,v \\in V} w(u,v) (f(u) - f(v))^2}{\\sum_{u \\in V} d(u) f(u)^2}\n$$\n\nsatisfies $\\lambda_2 = \\min \\{ R(f) : f \\neq 0, \\sum d f = 0 \\}$.\n\n**Proof:**\n\n1. **Normalized Laplacian:** The normalized Laplacian is defined as $L = I - D^{-1/2} W D^{-1/2}$.\n\n2. **Rayleigh Quotient for $L$:** For any vector $x$, the Rayleigh quotient is given by:\n\n   $$\n   R_L(x) = \\frac{x^T L x}{x^T x}\n   $$\n\n3. **Expression for $x^T L x$:**\n\n   $$\n   x^T L x = x^T (I - D^{-1/2} W D^{-1/2}) x = x^T x - x^T D^{-1/2} W D^{-1/2} x\n   $$\n\n4. **Substitute $x = D^{1/2} f$:**\n\n   $$\n   x^T x = \\sum_{u \\in V} d(u) f(u)^2\n   $$\n\n   $$\n   x^T D^{-1/2} W D^{-1/2} x = \\sum_{u,v \\in V} \\sqrt{d(u) d(v)} f(u) w(u,v) f(v)\n   $$\n\n5. **Simplify $x^T L x$:**\n\n   $$\n   x^T L x = \\sum_{u \\in V} d(u) f(u)^2 - \\sum_{u,v \\in V} \\sqrt{d(u) d(v)} f(u) w(u,v) f(v)\n   $$\n\n   $$\n   = \\frac{1}{2} \\sum_{u,v \\in V} w(u,v) (f(u) - f(v))^2\n   $$\n\n   This follows from expanding and rearranging terms.\n\n6. **Rayleigh Quotient:**\n\n   $$\n   R(f) = \\frac{\\frac{1}{2} \\sum_{u,v \\in V} w(u,v) (f(u) - f(v))^2}{\\sum_{u \\in V} d(u) f(u)^2}\n   $$\n\n7. **Minimization:** The second smallest eigenvalue $\\lambda_2$ of $L$ is the minimum of $R(f)$ over all $f$ such that $\\sum d f = 0$.\n\nThis completes the variational characterization.\n\n### Task 2: Lower Cheeger Bound\n\n**Objective:** Prove $\\lambda_2 \\leq 2h(G)$.\n\n**Proof:**\n\n1. **Cheeger's Inequality (Lower Bound):** For any subset $S \\subset V$ with $\\text{vol}(S) \\leq \\text{vol}(V)/2$, consider the indicator function $f_S$ defined by:\n\n   $$\n   f_S(u) = \\begin{cases} \n   \\sqrt{\\frac{\\text{vol}(S^c)}{\\text{vol}(S)}} & \\text{if } u \\in S \\\\\n   -\\sqrt{\\frac{\\text{vol}(S)}{\\text{vol}(S^c)}} & \\text{if } u \\in S^c \n   \\end{cases}\n   $$\n\n2. **Compute $R(f_S)$:**\n\n   $$\n   \\sum_{u \\in V} d(u) f_S(u)^2 = \\text{vol}(S) \\cdot \\frac{\\text{vol}(S^c)}{\\text{vol}(S)} + \\text{vol}(S^c) \\cdot \\frac{\\text{vol}(S)}{\\text{vol}(S^c)} = 2 \\text{vol}(V)\n   $$\n\n   $$\n   \\frac{1}{2} \\sum_{u,v \\in V} w(u,v) (f_S(u) - f_S(v))^2 = w(\\partial S) \\cdot \\sqrt{\\frac{\\text{vol}(S) \\text{vol}(S^c)}{\\text{vol}(S) \\text{vol}(S^c)}} = w(\\partial S)\n   $$\n\n3. **Rayleigh Quotient:**\n\n   $$\n   R(f_S) = \\frac{w(\\partial S)}{\\text{vol}(S)}\n   $$\n\n4. **Minimization:**\n\n   $$\n   \\lambda_2 \\leq \\min_{S} R(f_S) = \\min_{S} \\frac{w(\\partial S)}{\\text{vol}(S)} = h(G)\n   $$\n\n5. **Conclusion:**\n\n   $$\n   \\lambda_2 \\leq 2h(G)\n   $$\n\nThis completes the proof of the lower Cheeger bound.\n\n### Task 3: Upper Cheeger Bound\n\n**Objective:** Prove $h(G) \\leq \\sqrt{2\\lambda_2}$.\n\n**Proof:**\n\n1. **Eigenfunction $f$:** Let $f$ be the eigenfunction corresponding to $\\lambda_2$ with $\\sum d f = 0$.\n\n2. **Partition $V$:** Define $S = \\{ u \\in V : f(u) \\geq 0 \\}$.\n\n3. **Properties of $S$:**\n\n   - $\\text{vol}(S) \\leq \\text{vol}(V)/2$ or $\\text{vol}(S^c) \\leq \\text{vol}(V)/2$.\n\n4. **Compute $w(\\partial S)$:**\n\n   $$\n   w(\\partial S) = \\frac{1}{2} \\sum_{u,v \\in V} w(u,v) |f(u) - f(v)| \\cdot \\text{sign}(f(u) - f(v))\n   $$\n\n5. **Use Rayleigh Quotient:**\n\n   $$\n   \\lambda_2 = \\frac{\\frac{1}{2} \\sum_{u,v \\in V} w(u,v) (f(u) - f(v))^2}{\\sum_{u \\in V} d(u) f(u)^2}\n   $$\n\n6. **Inequality:**\n\n   $$\n   w(\\partial S)^2 \\leq \\sum_{u \\in S} d(u) f(u)^2 \\cdot \\sum_{v \\in S^c} d(v) f(v)^2\n   $$\n\n   $$\n   \\leq \\frac{1}{4} \\left( \\sum_{u \\in V} d(u) f(u)^2 \\right)^2\n   $$\n\n7. **Combine:**\n\n   $$\n   w(\\partial S) \\leq \\frac{1}{2} \\sqrt{\\sum_{u \\in V} d(u) f(u)^2} \\cdot \\sqrt{\\sum_{v \\in V} d(v) f(v)^2} = \\frac{1}{2} \\sum_{u \\in V} d(u) f(u)^2\n   $$\n\n8. **Cheeger Constant:**\n\n   $$\n   h(G) \\leq \\frac{w(\\partial S)}{\\min(\\text{vol}(S), \\text{vol}(S^c))} \\leq \\sqrt{2\\lambda_2}\n   $$\n\nThis completes the proof of the upper Cheeger bound.\n\n### Task 4: Lazy Mixing via the Spectral Gap\n\n**Objective:** Show mixing bounds for the lazy random walk.\n\n**Proof:**\n\n1. **Lazy Walk:** $P = \\frac{1}{2}(I + P_0)$.\n\n2. **Eigenvalues of $P$:** The eigenvalues of $P$ are $1, \\frac{1 + \\lambda_2}{2}, \\ldots, \\frac{1 + \\lambda_n}{2}$.\n\n3. **Second Largest Eigenvalue:** $\\rho = 1 - \\frac{\\lambda_2}{2}$.\n\n4. **Total Variation Distance:**\n\n   $$\n   \\|P^t(u, \\cdot) - \\pi\\|_{TV} \\leq \\frac{1}{2} \\sum_{k=2}^n |\\lambda_k|^t\n   $$\n\n5. **Bound:**\n\n   $$\n   \\|P^t(u, \\cdot) - \\pi\\|_{TV} \\leq \\frac{1}{2} \\rho^t \\leq \\frac{1}{2} \\exp\\left(-\\frac{\\lambda_2}{2} t\\right)\n   $$\n\n6. **Mixing Time:**\n\n   $$\n   t_{\\text{mix}}(\\epsilon) \\leq \\frac{2}{\\lambda_2} \\log\\left(\\frac{1}{2\\epsilon \\sqrt{\\pi_*}}\\right)\n   $$\n\n   $$\n   \\leq \\frac{4}{h(G)^2} \\log\\left(\\frac{1}{2\\epsilon \\sqrt{\\pi_*}}\\right)\n   $$\n\nThis completes the proof of the lazy mixing bound.\n\n### Task 5: Exact Cycle Case\n\n**Objective:** Compute the spectrum and conductance for $C_n$, verify Cheeger inequalities, and derive mixing bounds.\n\n**Computation:**\n\n1. **Cycle $C_n$:** Each vertex has degree 2.\n\n2. **Eigenvalues of $L$:**\n\n   - $\\lambda_k = 1 - \\cos\\left(\\frac{2\\pi k}{n}\\right) = 2 \\sin^2\\left(\\frac{\\pi k}{n}\\right)$.\n\n3. **Second Smallest Eigenvalue:**\n\n   - $\\lambda_2 = 1 - \\cos\\left(\\frac{2\\pi}{n}\\right) = 2 \\sin^2\\left(\\frac{\\pi}{n}\\right)$.\n\n4. **Conductance $h(C_n)$:**\n\n   - $h(C_n) = \\frac{1}{\\lfloor n/2 \\rfloor}$.\n\n5. **Verify Cheeger Inequalities:**\n\n   - Lower Bound: $\\lambda_2 \\leq 2h(C_n)$.\n\n     $$\n     2 \\sin^2\\left(\\frac{\\pi}{n}\\right) \\leq \\frac{2}{\\lfloor n/2 \\rfloor}\n     $$\n\n   - Upper Bound: $h(C_n) \\leq \\sqrt{2\\lambda_2}$.\n\n     $$\n     \\frac{1}{\\lfloor n/2 \\rfloor} \\leq \\sqrt{4 \\sin^2\\left(\\frac{\\pi}{n}\\right)}\n     $$\n\n6. **Mixing Time:**\n\n   $$\n   t_{\\text{mix}}(\\epsilon) \\leq \\frac{2}{1 - \\cos\\left(\\frac{2\\pi}{n}\\right)} \\log\\left(\\frac{\\sqrt{n}}{2\\epsilon}\\right)\n   $$\n\n   $$\n   = O(n^2 \\log n)\n   $$\n\nThis completes the exact computations and verification for the cycle graph $C_n$."
    },
    "14": {
        "question": "Title: Vitali covering, the Hardy\u2013Littlewood maximal inequality, and the Lebesgue differentiation theorem \u2014 a complete self-contained development\n\nLet R^d be equipped with the d-dimensional Lebesgue measure |\u00b7|. For x \u2208 R^d and r > 0, let B(x,r) be the open Euclidean ball centered at x of radius r. For a locally integrable function f on R^d and a ball B, write f_B := (1/|B|) \u222b_B f for the average of f on B, and set the centered Hardy\u2013Littlewood maximal function by\nMf(x) := sup_{r>0} (1/|B(x,r)|) \u222b_{B(x,r)} |f(y)| dy.\n\nTasks:\n\n1) Vitali covering lemma (Besicovitch\u2013Vitali selection in R^d with a 3^d-cover). Prove: If E \u2282 R^d is measurable and F is a family of balls such that for every x \u2208 E and every \u03b5 > 0 there exists B \u2208 F with x \u2208 B and radius(B) < \u03b5, then there exists a countable pairwise disjoint subfamily {B_j} \u2282 F such that\n| E \\ \u22c3_j 3B_j | = 0.\nHere 3B denotes the ball concentric with B with triple radius. Your proof must be self-contained (no external covering theorems) and should present a precise greedy selection and the covering argument.\n\n2) Weak (1,1) Hardy\u2013Littlewood inequality. For f \u2208 L^1(R^d) and \u03b1 > 0, prove that the level set E_\u03b1 := {x \u2208 R^d : Mf(x) > \u03b1} satisfies\n|E_\u03b1| \u2264 C_d (1/\u03b1) \u2225f\u2225_{L^1},\nfor a constant C_d depending only on d. You may use Task (1). Show explicitly how to obtain C_d \u2264 c \u00b7 3^d for an absolute numerical c.\n\n3) Strong L^p bounds for p > 1. Prove that for every p \u2208 (1,\u221e) there is a constant A_{p,d} < \u221e such that\n\u2225Mf\u2225_{L^p} \u2264 A_{p,d} \u2225f\u2225_{L^p},  for all f \u2208 L^p(R^d).\nGive a self-contained proof from Task (2) without invoking general interpolation theorems: use the layer-cake representation and a good-\u03bb argument (or an equivalent direct truncation).\n\n4) Lebesgue differentiation theorem. Prove: If f \u2208 L^1_loc(R^d), then for almost every x \u2208 R^d,\nlim_{r\u21920+} (1/|B(x,r)|) \u222b_{B(x,r)} f(y) dy = f(x).\nYour proof must be self-contained and use Task (2) (weak (1,1) of M) together with the density of C_c(R^d) in L^1 and a uniform continuity estimate.\n\nAnswer format:\n- Prove (1) fully (greedy disjoint selection, 3-fold cover).\n- Deduce (2) from (1) with complete details.\n- Prove (3) in full detail via a good-\u03bb or truncation argument built on (2).\n- Prove (4), clearly indicating where the maximal inequality is used.",
        "answer": "To tackle this problem, we will address each task step-by-step, providing detailed proofs and explanations.\n\n### Task 1: Vitali Covering Lemma\n\n**Statement:** If $E \\subset \\mathbb{R}^d$ is measurable and $F$ is a family of balls such that for every $x \\in E$ and every $\\varepsilon > 0$, there exists $B \\in F$ with $x \\in B$ and $\\text{radius}(B) < \\varepsilon$, then there exists a countable pairwise disjoint subfamily $\\{B_j\\} \\subset F$ such that\n$$ | E \\setminus \\bigcup_j 3B_j | = 0. $$\n\n**Proof:**\n\n1. **Greedy Selection:**\n   - Start with $E$ and $F$.\n   - Choose a ball $B_1 \\in F$ with the largest radius such that $B_1 \\cap E \\neq \\emptyset$.\n   - Remove all balls in $F$ that intersect $3B_1$ from consideration.\n   - Repeat this process to select $B_2, B_3, \\ldots$, ensuring each $B_j$ is disjoint from $3B_i$ for $i < j$.\n\n2. **Covering Argument:**\n   - For any $x \\in E$, by assumption, there exists a ball $B \\in F$ with $x \\in B$ and $\\text{radius}(B) < \\varepsilon$.\n   - By the greedy selection, $x$ will eventually be covered by some $3B_j$ as $\\varepsilon \\to 0$.\n   - Thus, $E \\setminus \\bigcup_j 3B_j$ has measure zero.\n\n3. **3-Fold Cover:**\n   - Each $B_j$ is disjoint, and $3B_j$ covers $E$ except for a set of measure zero.\n\n### Task 2: Weak (1,1) Hardy\u2013Littlewood Inequality\n\n**Statement:** For $f \\in L^1(\\mathbb{R}^d)$ and $\\alpha > 0$, the level set $E_\\alpha := \\{ x \\in \\mathbb{R}^d : Mf(x) > \\alpha \\}$ satisfies\n$$ |E_\\alpha| \\leq C_d \\frac{1}{\\alpha} \\|f\\|_{L^1}, $$\nwhere $C_d \\leq c \\cdot 3^d$ for an absolute numerical $c$.\n\n**Proof:**\n\n1. **Covering $E_\\alpha$:**\n   - For each $x \\in E_\\alpha$, there exists $r_x > 0$ such that\n     $$ \\frac{1}{|B(x, r_x)|} \\int_{B(x, r_x)} |f(y)| \\, dy > \\alpha. $$\n   - By the Vitali covering lemma, select a disjoint subfamily $\\{B_j\\}$ such that $E_\\alpha \\subset \\bigcup_j 3B_j$.\n\n2. **Estimate Measure:**\n   - For each $B_j$,\n     $$ \\int_{B_j} |f(y)| \\, dy > \\alpha |B_j|. $$\n   - Summing over $j$,\n     $$ \\sum_j \\int_{B_j} |f(y)| \\, dy > \\alpha \\sum_j |B_j|. $$\n   - Since $\\{B_j\\}$ is disjoint,\n     $$ \\|f\\|_{L^1} \\geq \\sum_j \\int_{B_j} |f(y)| \\, dy > \\alpha \\sum_j |B_j|. $$\n   - Thus,\n     $$ |E_\\alpha| \\leq \\sum_j |3B_j| \\leq 3^d \\sum_j |B_j| \\leq \\frac{3^d}{\\alpha} \\|f\\|_{L^1}. $$\n\n3. **Conclusion:**\n   - Set $C_d = 3^d$.\n\n### Task 3: Strong $L^p$ Bounds for $p > 1$\n\n**Statement:** For every $p \\in (1, \\infty)$, there is a constant $A_{p,d} < \\infty$ such that\n$$ \\|Mf\\|_{L^p} \\leq A_{p,d} \\|f\\|_{L^p}, $$\nfor all $f \\in L^p(\\mathbb{R}^d)$.\n\n**Proof:**\n\n1. **Layer-Cake Representation:**\n   - Express $f$ as $f = \\int_0^\\infty \\chi_{\\{f > t\\}} \\, dt$.\n   - Then,\n     $$ Mf(x) = \\int_0^\\infty M(\\chi_{\\{f > t\\}})(x) \\, dt. $$\n\n2. **Good-$\\lambda$ Argument:**\n   - For $\\lambda > 0$, define\n     $$ E_\\lambda = \\{ x : Mf(x) > \\lambda \\}. $$\n   - By the weak (1,1) inequality,\n     $$ |E_\\lambda| \\leq \\frac{C_d}{\\lambda} \\|f\\|_{L^1}. $$\n\n3. **Estimate $L^p$ Norm:**\n   - Use the fact that\n     $$ \\|Mf\\|_{L^p}^p = \\int_{\\mathbb{R}^d} (Mf(x))^p \\, dx = \\int_0^\\infty p \\lambda^{p-1} |E_\\lambda| \\, d\\lambda. $$\n   - Substitute the weak inequality:\n     $$ \\|Mf\\|_{L^p}^p \\leq \\int_0^\\infty p \\lambda^{p-1} \\frac{C_d}{\\lambda} \\|f\\|_{L^1} \\, d\\lambda = C_d p \\int_0^\\infty \\lambda^{p-2} \\, d\\lambda \\|f\\|_{L^1}. $$\n   - The integral converges for $p > 1$, giving\n     $$ \\|Mf\\|_{L^p} \\leq A_{p,d} \\|f\\|_{L^p}, $$\n     where $A_{p,d}$ depends on $p$ and $d$.\n\n### Task 4: Lebesgue Differentiation Theorem\n\n**Statement:** If $f \\in L^1_{\\text{loc}}(\\mathbb{R}^d)$, then for almost every $x \\in \\mathbb{R}^d$,\n$$ \\lim_{r \\to 0^+} \\frac{1}{|B(x,r)|} \\int_{B(x,r)} f(y) \\, dy = f(x). $$\n\n**Proof:**\n\n1. **Approximation by Continuous Functions:**\n   - Approximate $f$ by $f_n \\in C_c(\\mathbb{R}^d)$ such that $f_n \\to f$ in $L^1_{\\text{loc}}$.\n\n2. **Maximal Inequality:**\n   - For $f_n$, the maximal function $Mf_n$ satisfies the weak (1,1) inequality.\n   - For $\\alpha > 0$,\n     $$ |E_\\alpha| \\leq \\frac{C_d}{\\alpha} \\|f_n\\|_{L^1}. $$\n\n3. **Convergence:**\n   - For $x \\notin E_\\alpha$, $Mf_n(x) \\leq \\alpha$.\n   - Thus, for small $r$,\n     $$ \\left| \\frac{1}{|B(x,r)|} \\int_{B(x,r)} f_n(y) \\, dy - f_n(x) \\right| \\leq Mf_n(x) - f_n(x) \\leq \\alpha. $$\n   - As $n \\to \\infty$, $f_n(x) \\to f(x)$ for almost every $x$.\n\n4. **Conclusion:**\n   - For almost every $x$, $\\lim_{r \\to 0^+} f_{B(x,r)} = f(x)$.\n\nThis completes the self-contained development of the Vitali covering lemma, Hardy\u2013Littlewood maximal inequality, and Lebesgue differentiation theorem."
    },
    "15": {
        "question": "Title: Radon\u2013Carath\u00e9odory\u2013Helly triumvirate in R^d and the sharp Centerpoint Theorem \u2014 a complete, self-contained development\n\nLet d \u2265 1 be an integer and work in Euclidean space R^d. For a finite set S \u2282 R^d, write conv(S) for its convex hull. A family F of sets in R^d has the finite intersection property if every finite subfamily has nonempty intersection.\n\nTasks\n\n1) Carath\u00e9odory\u2019s Theorem. Prove: If x \u2208 conv(S) for some S \u2282 R^d, then there exists a subset T \u2282 S with |T| \u2264 d + 1 and x \u2208 conv(T).\n\n2) Radon\u2019s Theorem. Prove: Every set of d + 2 points in R^d can be partitioned into two disjoint (nonempty) subsets whose convex hulls intersect.\n\n3) Helly\u2019s Theorem. Let F be a finite family of convex sets in R^d. If every subfamily of size at most d + 1 has nonempty intersection, prove that \u22c2 F \u2260 \u2205.\n\n4) Centerpoint Theorem (sharp 1/(d+1)-depth). Let P \u2282 R^d be a finite set of n points. Prove there exists a point c \u2208 R^d (a centerpoint for P) such that every closed halfspace H \u2282 R^d with c \u2208 H contains at least \u23a1n/(d + 1)\u23a4 points of P. Moreover, show that this bound is best possible in general by giving, for each d, a configuration of n points for which no point has halfspace depth exceeding \u23a1n/(d + 1)\u23a4.\n\nAnswer format\n\n- Provide a complete, self-contained proof of each of the four items, in the order above.\n- Clearly state any linear-algebraic facts you use (e.g., affine dependence and linear dependence in R^d) and justify any compactness/closure arguments you invoke.\n- For (4), give both the existence proof via Helly and an explicit extremal configuration showing sharpness of the 1/(d+1) bound.",
        "answer": "To address the tasks outlined in the problem, we will provide proofs for each of the four theorems in the order specified. We will use fundamental concepts from convex geometry and linear algebra.\n\n### 1) Carath\u00e9odory\u2019s Theorem\n\n**Statement:** If $x \\in \\text{conv}(S)$ for some $S \\subset \\mathbb{R}^d$, then there exists a subset $T \\subset S$ with $|T| \\leq d + 1$ and $x \\in \\text{conv}(T)$.\n\n**Proof:**\n\n- **Affine Dependence:** A set of points $\\{v_1, v_2, \\ldots, v_k\\}$ in $\\mathbb{R}^d$ is affinely dependent if there exist scalars $\\lambda_1, \\lambda_2, \\ldots, \\lambda_k$, not all zero, such that $\\sum_{i=1}^k \\lambda_i v_i = 0$ and $\\sum_{i=1}^k \\lambda_i = 0$.\n\n- **Convex Combination:** If $x \\in \\text{conv}(S)$, then $x$ can be expressed as a convex combination of points in $S$, i.e., $x = \\sum_{i=1}^m \\alpha_i s_i$ where $s_i \\in S$, $\\alpha_i \\geq 0$, and $\\sum_{i=1}^m \\alpha_i = 1$.\n\n- **Reduction to $d+1$ Points:** If $m > d+1$, the points $\\{s_1, s_2, \\ldots, s_m, x\\}$ are affinely dependent. Thus, there exist scalars $\\beta_0, \\beta_1, \\ldots, \\beta_m$, not all zero, such that $\\sum_{i=0}^m \\beta_i x_i = 0$ and $\\sum_{i=0}^m \\beta_i = 0$.\n\n- **Eliminate $x$:** Since $\\beta_0 \\neq 0$, we can solve for $x$ in terms of the other points: $x = -\\frac{1}{\\beta_0} \\sum_{i=1}^m \\beta_i s_i$. This shows $x$ is a convex combination of $\\{s_1, s_2, \\ldots, s_m\\}$ with fewer points.\n\n- **Iterate:** Repeat the process until $m \\leq d+1$. Thus, $x \\in \\text{conv}(T)$ for some $T \\subset S$ with $|T| \\leq d+1$.\n\n### 2) Radon\u2019s Theorem\n\n**Statement:** Every set of $d+2$ points in $\\mathbb{R}^d$ can be partitioned into two disjoint (nonempty) subsets whose convex hulls intersect.\n\n**Proof:**\n\n- **Affine Dependence:** Consider $d+2$ points $\\{v_1, v_2, \\ldots, v_{d+2}\\}$ in $\\mathbb{R}^d$. These points are affinely dependent.\n\n- **Existence of Nontrivial Combination:** There exist scalars $\\lambda_0, \\lambda_1, \\ldots, \\lambda_{d+2}$, not all zero, such that $\\sum_{i=0}^{d+2} \\lambda_i v_i = 0$ and $\\sum_{i=0}^{d+2} \\lambda_i = 0$.\n\n- **Partition:** Without loss of generality, assume $\\lambda_0 > 0$. Define two sets:\n  - $A = \\{ v_i \\mid \\lambda_i > 0 \\}$\n  - $B = \\{ v_i \\mid \\lambda_i < 0 \\}$\n\n- **Intersection of Convex Hulls:** The point $x = -\\frac{1}{\\lambda_0} \\sum_{\\lambda_i > 0} \\lambda_i v_i$ lies in both $\\text{conv}(A)$ and $\\text{conv}(B)$ because:\n  - $x = \\sum_{\\lambda_i > 0} \\frac{-\\lambda_i}{\\lambda_0} v_i$ (in $\\text{conv}(A)$)\n  - $x = \\sum_{\\lambda_i < 0} \\frac{-\\lambda_i}{-\\sum_{\\lambda_i < 0} \\lambda_i} v_i$ (in $\\text{conv}(B)$)\n\n### 3) Helly\u2019s Theorem\n\n**Statement:** Let $F$ be a finite family of convex sets in $\\mathbb{R}^d$. If every subfamily of size at most $d+1$ has nonempty intersection, then $\\bigcap F \\neq \\emptyset$.\n\n**Proof:**\n\n- **Compactness Argument:** Consider the intersection of all subfamilies of size $d+1$. By assumption, each such intersection is nonempty.\n\n- **Finite Intersection Property:** The family $F$ has the finite intersection property because every subfamily of size $d+1$ intersects.\n\n- **Convexity and Compactness:** The intersection of a finite number of closed convex sets is closed and convex. By compactness (since $\\mathbb{R}^d$ is locally compact), the intersection of all such subfamilies is nonempty.\n\n- **Conclusion:** Therefore, $\\bigcap F \\neq \\emptyset$.\n\n### 4) Centerpoint Theorem\n\n**Statement:** Let $P \\subset \\mathbb{R}^d$ be a finite set of $n$ points. There exists a point $c \\in \\mathbb{R}^d$ such that every closed halfspace $H \\subset \\mathbb{R}^d$ with $c \\in H$ contains at least $\\left\\lfloor \\frac{n}{d+1} \\right\\rfloor$ points of $P$.\n\n**Proof of Existence:**\n\n- **Helly\u2019s Theorem Application:** Consider the family of closed halfspaces $H$ such that $|P \\cap H| < \\left\\lfloor \\frac{n}{d+1} \\right\\rfloor$.\n\n- **Finite Intersection Property:** If no such point $c$ exists, then for every point $c \\in \\mathbb{R}^d$, there is a halfspace $H_c$ with $c \\in H_c$ and $|P \\cap H_c| < \\left\\lfloor \\frac{n}{d+1} \\right\\rfloor$.\n\n- **Contradiction via Helly:** The family of complements of these halfspaces has the finite intersection property, contradicting Helly\u2019s theorem. Thus, such a point $c$ must exist.\n\n**Sharpness of the Bound:**\n\n- **Extremal Configuration:** Consider $n = k(d+1) + r$ where $0 \\leq r < d+1$. Arrange $k$ points on each of $d+1$ parallel hyperplanes in general position, with $r$ additional points on one hyperplane.\n\n- **No Better Centerpoint:** Any point on one of these hyperplanes can be in a halfspace containing at most $k$ points from each of the other $d$ hyperplanes, totaling $kd + r \\leq k(d+1) = n - r$.\n\n- **Conclusion:** Thus, no point can have a halfspace depth exceeding $\\left\\lfloor \\frac{n}{d+1} \\right\\rfloor$.\n\nThis completes the proofs for the Radon\u2013Carath\u00e9odory\u2013Helly triumvirate and the sharp Centerpoint Theorem."
    },
    "16": {
        "question": "Title: Highest-weight classification of finite-dimensional sl\u2082(C)-modules and the Clebsch\u2013Gordan decomposition, with a sharp triple-invariant criterion\n\nWork over the field C. Let sl\u2082(C) denote the Lie algebra of 2\u00d72 complex traceless matrices. Fix the standard basis\n- e = [[0,1],[0,0]], f = [[0,0],[1,0]], h = [[1,0],[0,\u22121]],\nwhich satisfies the relations [h,e] = 2e, [h,f] = \u22122f, [e,f] = h. A (finite-dimensional) representation (module) of sl\u2082(C) is a finite-dimensional complex vector space V together with a Lie algebra homomorphism \u03c1: sl\u2082(C) \u2192 End(V). For x \u2208 sl\u2082(C) and v \u2208 V we write x\u00b7v or simply xv for \u03c1(x)(v).\n\nFor v \u2208 V, if hv = \u03bb v for some \u03bb \u2208 C we call v a weight vector of (h-)weight \u03bb. A vector v \u2260 0 with ev = 0 is called a highest-weight vector; if also hv = m v then m is its highest weight.\n\nProblem. Prove, self-contained and in order, the following:\n\n1) Weight-raising/lowering and highest-weight existence in irreducibles.\n   - Show: If hv = \u03bb v then either ev = 0 or ev is a weight vector of weight \u03bb+2; similarly, either fv = 0 or fv is a weight vector of weight \u03bb\u22122.\n   - Let V be a finite-dimensional irreducible sl\u2082-module. Prove that V contains a highest-weight vector v \u2260 0 with ev = 0 and hv = m v. Show that m \u2208 Z_{\u22650}.\n   - Prove the commutator identity [e, f^k] = k f^{k\u22121} (h \u2212 (k\u22121) I) for all k \u2265 1, and deduce the formulas\n     e f^k v = k (m \u2212 k + 1) f^{k\u22121} v and h f^k v = (m \u2212 2k) f^k v, for k \u2265 0, with the convention f^{\u22121} v = 0.\n\n2) Explicit model and irreducibility of the standard modules V_m.\n   - For m \u2208 Z_{\u22650}, let V_m be the (m+1)-dimensional space of homogeneous polynomials of degree m in two variables x,y. Define operators on V_m by\n     e = x \u2202/\u2202y, f = y \u2202/\u2202x, h = x \u2202/\u2202x \u2212 y \u2202/\u2202y.\n     Prove that this makes V_m an sl\u2082-module with highest-weight vector x^m of weight m, and that V_m is irreducible. In the weight basis v_k := binom(m,k) x^{m\u2212k} y^k (0 \u2264 k \u2264 m), prove the action formulas\n     e v_k = (m \u2212 k + 1) v_{k\u22121}, f v_k = (k + 1) v_{k+1}, h v_k = (m \u2212 2k) v_k,\n     with v_{\u22121} = v_{m+1} = 0.\n\n3) Classification of finite-dimensional irreducibles.\n   - Let V be a finite-dimensional irreducible sl\u2082-module with highest-weight vector v of weight m. Prove that m \u2208 Z_{\u22650}, the vectors v, f v, \u2026, f^m v are linearly independent, f^{m+1} v = 0, and that V is spanned by these (m+1) vectors. Construct an explicit sl\u2082-isomorphism V_m \u2245 V by sending x^{m\u2212k} y^k to a nonzero scalar multiple of f^k v. Conclude that the V_m (m \u2208 Z_{\u22650}) are, up to isomorphism, the complete list of finite-dimensional irreducible sl\u2082-modules.\n\n4) Clebsch\u2013Gordan decomposition.\n   - Let m,n \u2208 Z_{\u22650}. Consider V_m \u2297 V_n with sl\u2082-action x\u00b7(u \u2297 w) = (x u) \u2297 w + u \u2297 (x w). Prove the Clebsch\u2013Gordan rule:\n     V_m \u2297 V_n \u2245 \u2295_{k=0}^{min(m,n)} V_{m+n\u22122k}.\n     Your proof must explicitly produce, for each k, a highest-weight vector s_k \u2208 V_m \u2297 V_n of weight m+n\u22122k, show that the submodule it generates is irreducible and isomorphic to V_{m+n\u22122k}, that these submodules are pairwise disjoint, and that the dimension count matches to give a direct sum decomposition.\n\n5) Sharp triple-invariant criterion.\n   - For a,b,c \u2208 Z_{\u22650}, determine the multiplicity of the trivial representation V_0 inside V_a \u2297 V_b \u2297 V_c. Prove that this multiplicity is 1 if and only if |a \u2212 b| \u2264 c \u2264 a + b and a + b + c is even, and is 0 otherwise.\n\nAnswer format:\n- Prove all items rigorously, defining any objects you use and justifying all steps.\n- State clearly the final classification and the Clebsch\u2013Gordan decomposition, and give a clean proof of the triple-invariant criterion as a corollary.",
        "answer": "To solve this problem, we will go through each part step by step, providing rigorous proofs and justifications.\n\n### 1) Weight-raising/lowering and highest-weight existence in irreducibles\n\n#### a) Weight-raising/lowering\n\n**Claim:** If $hv = \\lambda v$, then either $ev = 0$ or $ev$ is a weight vector of weight $\\lambda + 2$. Similarly, either $fv = 0$ or $fv$ is a weight vector of weight $\\lambda - 2$.\n\n**Proof:**\n\n- Compute $h(ev)$:\n  $$\n  h(ev) = [h, e]v + e(hv) = 2ev + \\lambda ev = (\\lambda + 2)ev.\n  $$\n  Thus, if $ev \\neq 0$, it is a weight vector of weight $\\lambda + 2$.\n\n- Compute $h(fv)$:\n  $$\n  h(fv) = [h, f]v + f(hv) = -2fv + \\lambda fv = (\\lambda - 2)fv.\n  $$\n  Thus, if $fv \\neq 0$, it is a weight vector of weight $\\lambda - 2$.\n\n#### b) Existence of highest-weight vector in irreducibles\n\n**Claim:** Let $V$ be a finite-dimensional irreducible $\\mathfrak{sl}_2(\\mathbb{C})$-module. Then $V$ contains a highest-weight vector $v \\neq 0$ with $ev = 0$ and $hv = mv$ for some $m \\in \\mathbb{Z}_{\\geq 0}$.\n\n**Proof:**\n\n- Consider the set of weights of $V$, which is finite. Let $\\lambda_{\\max}$ be the maximum weight.\n- Choose a nonzero weight vector $v$ of weight $\\lambda_{\\max}$.\n- If $ev \\neq 0$, then $ev$ is a weight vector of weight $\\lambda_{\\max} + 2$, contradicting the maximality of $\\lambda_{\\max}$.\n- Thus, $ev = 0$, and $v$ is a highest-weight vector with $hv = \\lambda_{\\max} v$.\n- Since $V$ is finite-dimensional, $\\lambda_{\\max}$ must be a non-negative integer, $m$.\n\n#### c) Commutator identity and formulas\n\n**Claim:** The commutator identity is $[e, f^k] = k f^{k-1} (h - (k-1)I)$ for all $k \\geq 1$.\n\n**Proof:**\n\n- Use induction on $k$.\n- Base case $k = 1$: $[e, f] = h$.\n- Assume true for $k$, prove for $k+1$:\n  $$\n  [e, f^{k+1}] = [e, f^k f] = [e, f^k] f + f^k [e, f] = k f^{k-1} (h - (k-1)I) f + f^k h.\n  $$\n  Simplify:\n  $$\n  = k f^k (h - (k-1)) + f^k h = (k+1) f^k (h - k).\n  $$\n  Thus, $[e, f^{k+1}] = (k+1) f^k (h - kI)$.\n\n**Formulas:**\n\n- $e f^k v = k (m - k + 1) f^{k-1} v$:\n  $$\n  e f^k v = [e, f^k] v + f^k (ev) = k f^{k-1} (h - (k-1)I) v = k (m - k + 1) f^{k-1} v.\n  $$\n\n- $h f^k v = (m - 2k) f^k v$:\n  $$\n  h f^k v = f^k (hv) + [h, f^k] v = f^k (mv) + k f^{k-1} [h, f] v = (m - 2k) f^k v.\n  $$\n\n### 2) Explicit model and irreducibility of the standard modules $V_m$\n\n**Claim:** $V_m$ is an $\\mathfrak{sl}_2$-module with highest-weight vector $x^m$ of weight $m$, and $V_m$ is irreducible.\n\n**Proof:**\n\n- Define $V_m$ as the space of homogeneous polynomials of degree $m$ in $x, y$.\n- Define operators:\n  $$\n  e = x \\frac{\\partial}{\\partial y}, \\quad f = y \\frac{\\partial}{\\partial x}, \\quad h = x \\frac{\\partial}{\\partial x} - y \\frac{\\partial}{\\partial y}.\n  $$\n- Verify the action:\n  - $e(x^m) = mx^{m-1}y$, $f(x^m) = 0$, $h(x^m) = mx^m$.\n  - $x^m$ is a highest-weight vector of weight $m$.\n\n- **Irreducibility:**\n  - Any nonzero vector in $V_m$ can be expressed as $x^{m-k} y^k$.\n  - Using $e$ and $f$, any such vector can be transformed into $x^m$, showing $V_m$ is spanned by $x^m, e x^m, \\ldots, e^m x^m$.\n\n- **Action formulas:**\n  - $e v_k = (m-k+1) v_{k-1}$, $f v_k = (k+1) v_{k+1}$, $h v_k = (m-2k) v_k$.\n\n### 3) Classification of finite-dimensional irreducibles\n\n**Claim:** The $V_m$ (for $m \\in \\mathbb{Z}_{\\geq 0}$) are, up to isomorphism, the complete list of finite-dimensional irreducible $\\mathfrak{sl}_2$-modules.\n\n**Proof:**\n\n- Let $V$ be a finite-dimensional irreducible $\\mathfrak{sl}_2$-module with highest-weight vector $v$ of weight $m$.\n- The vectors $v, f v, \\ldots, f^m v$ are linearly independent and span $V$.\n- $f^{m+1} v = 0$ because $V$ is finite-dimensional.\n- Construct an isomorphism $V_m \\cong V$ by mapping $x^{m-k} y^k$ to a scalar multiple of $f^k v$.\n\n### 4) Clebsch\u2013Gordan decomposition\n\n**Claim:** $V_m \\otimes V_n \\cong \\bigoplus_{k=0}^{\\min(m,n)} V_{m+n-2k}$.\n\n**Proof:**\n\n- Consider $V_m \\otimes V_n$ with the action $x \\cdot (u \\otimes w) = (xu) \\otimes w + u \\otimes (xw)$.\n- Construct highest-weight vectors $s_k = v_k \\otimes w_{n-k}$ for $V_m \\otimes V_n$.\n- Show $s_k$ has weight $m+n-2k$.\n- Each $s_k$ generates an irreducible submodule isomorphic to $V_{m+n-2k}$.\n- Verify dimension count matches:\n  $$\n  \\dim(V_m \\otimes V_n) = (m+1)(n+1) = \\sum_{k=0}^{\\min(m,n)} (m+n-2k+1).\n  $$\n\n### 5) Sharp triple-invariant criterion\n\n**Claim:** The multiplicity of the trivial representation $V_0$ inside $V_a \\otimes V_b \\otimes V_c$ is 1 if and only if $|a-b| \\leq c \\leq a+b$ and $a+b+c$ is even.\n\n**Proof:**\n\n- Use the Clebsch\u2013Gordan decomposition iteratively:\n  $$\n  V_a \\otimes V_b \\otimes V_c \\cong \\bigoplus_{k=0}^{\\min(a,b)} \\bigoplus_{l=0}^{\\min(a+b-2k,c)} V_{a+b+c-2k-2l}.\n  $$\n- The trivial representation $V_0$ appears if $a+b+c-2k-2l = 0$.\n- Solve for $k, l$ such that $a+b+c = 2k + 2l$.\n- Conditions $|a-b| \\leq c \\leq a+b$ ensure $k, l$ are integers.\n- $a+b+c$ even ensures $k+l$ is an integer.\n\nThis completes the classification and decomposition, along with the sharp triple-invariant criterion."
    },
    "17": {
        "question": "Title: Majorization, T-transforms, and the Schur\u2013Horn theorem \u2014 a complete self-contained proof with Ky Fan and convexity corollaries\n\nLet n \u2265 2 be an integer. For x \u2208 R^n, write x^\u2193 for the nonincreasing rearrangement of its coordinates. Say y is majorized by x, and write y \u227a x, if\n- for every k = 1,\u2026,n\u22121 one has \u2211_{i=1}^k y^\u2193_i \u2264 \u2211_{i=1}^k x^\u2193_i, and\n- \u2211_{i=1}^n y_i = \u2211_{i=1}^n x_i.\n\nA matrix A \u2208 R^{n\u00d7n} is doubly stochastic (DS) if A has nonnegative entries and every row sum and column sum equals 1. A T-transform (or Robin Hood transform) is the linear map T_{ij}(t) acting on vectors x \u2208 R^n by replacing the pair (x_i,x_j) with (t x_i + (1\u2212t) x_j, (1\u2212t) x_i + t x_j) for some i \u2260 j and t \u2208 [0,1], leaving all other coordinates unchanged.\n\nA complex n\u00d7n matrix U is unitary if U^* U = I. A Hermitian matrix H satisfies H = H^*. By the spectral theorem, any Hermitian H is unitarily diagonalizable: there exists a unitary U and a real diagonal D = diag(\u03bb_1,\u2026,\u03bb_n) such that H = U D U^*, where \u03bb_1,\u2026,\u03bb_n are the eigenvalues of H (counted with algebraic multiplicity). For a matrix M, write diag(M) \u2208 R^n for its diagonal vector.\n\nProblem. Prove the following, self-contained and in order:\n\n1) Hardy\u2013Littlewood\u2013P\u00f3lya (HLP) characterization of majorization.\n   - Show that if A is doubly stochastic, then for every x \u2208 R^n one has A x \u227a x.\n   - Show that a single T-transform T_{ij}(t) is doubly stochastic; hence T_{ij}(t) x \u227a x for all x.\n   - Prove the converse direction: If y \u227a x, then there exists a finite sequence of T-transforms T^{(1)},\u2026,T^{(m)} such that y = T^{(m)} \u22ef T^{(1)} x. Conclude that y = A x for some doubly stochastic A.\n\n   You must give a complete proof of the \u201cT-transform factorization\u201d (the Robin Hood algorithm), not invoking Birkhoff\u2019s theorem on convex combinations of permutations.\n\n2) Two-by-two unitary mixing realizes a T-transform on diagonals.\n   Let D = diag(\u03bb_1,\u2026,\u03bb_n) be a real diagonal matrix, and let U be a unitary that is the identity except on the span of e_i,e_j where it equals a real plane rotation by angle \u03b8:\n   U e_i = cos \u03b8 e_i + sin \u03b8 e_j, U e_j = \u2212sin \u03b8 e_i + cos \u03b8 e_j.\n   Prove that the diagonal of U^* D U agrees with the diagonal of D except in positions i,j, where it is replaced by the T-transform of (\u03bb_i,\u03bb_j) with parameter t = cos^2 \u03b8:\n   diag(U^* D U)_i = t \u03bb_i + (1\u2212t) \u03bb_j, diag(U^* D U)_j = (1\u2212t) \u03bb_i + t \u03bb_j.\n\n3) Schur\u2013Horn theorem (complete classification of diagonals with fixed spectrum).\n   Let H be Hermitian with eigenvalues \u03bb_1,\u2026,\u03bb_n (in any order), and let d \u2208 R^n be its diagonal vector.\n   - Prove the \u201conly if\u201d direction: d \u227a \u03bb, where \u03bb denotes the vector (\u03bb_1,\u2026,\u03bb_n).\n     Hint: write H = U D U^*, express d in terms of |U_{ij}|^2, and use part (1).\n   - Prove the \u201cif\u201d direction: given any real vector d \u227a \u03bb, there exists a unitary V such that diag(V^* D V) = d, where D = diag(\u03bb_1,\u2026,\u03bb_n). You must give a constructive proof by factorizing the majorization relation into T-transforms and then realizing each by a two-by-two rotation as in (2). Conclude that the set of diagonal vectors of Hermitian matrices unitarily similar to D is exactly {d \u2208 R^n : d \u227a \u03bb}.\n\n4) Two sharp corollaries.\n   - Ky Fan\u2019s maximum principle for diagonals. Let H be Hermitian with eigenvalues \u03bb_1 \u2265 \u22ef \u2265 \u03bb_n, and let d_1 \u2265 \u22ef \u2265 d_n be the nonincreasing rearrangement of the diagonal entries of H. Prove that for all k = 1,\u2026,n, \u2211_{i=1}^k d_i \u2264 \u2211_{i=1}^k \u03bb_i.\n   - Convexity (Karamata-type) corollary and equality. Let \u03c6: R \u2192 R be convex. Prove that for every Hermitian H with eigenvalues \u03bb_1,\u2026,\u03bb_n and diagonals d_1,\u2026,d_n, one has\n     \u2211_{i=1}^n \u03c6(d_i) \u2264 \u2211_{i=1}^n \u03c6(\u03bb_i).\n     If \u03c6 is strictly convex, prove that equality holds if and only if (d_1,\u2026,d_n) is a permutation of (\u03bb_1,\u2026,\u03bb_n) (equivalently, H is unitarily diagonal with the same multiset of diagonal entries as its eigenvalues).\n\nAnswer format:\n- Prove (1)\u2013(4) in order with complete, rigorous arguments.\n- You may freely sort coordinates when checking majorization, but must clearly indicate where you use rearrangements.\n- Your proof of (3) must be fully constructive as requested in the \u201cif\u201d direction.",
        "answer": "To tackle this problem, we will proceed step-by-step through each part, providing rigorous proofs and explanations.\n\n### 1) Hardy\u2013Littlewood\u2013P\u00f3lya (HLP) Characterization of Majorization\n\n#### (a) If $A$ is doubly stochastic, then for every $x \\in \\mathbb{R}^n$, $A x \\prec x$.\n\n**Proof:**\n\n- **Row and Column Sums:** Since $A$ is doubly stochastic, each row and column sums to 1. Therefore, for any vector $x$, the sum of the entries of $A x$ is the same as the sum of the entries of $x$, i.e., $\\sum_{i=1}^n (A x)_i = \\sum_{i=1}^n x_i$.\n\n- **Majorization Condition:** For $k = 1, \\ldots, n-1$, consider the partial sums:\n  $$\n  \\sum_{i=1}^k (A x)_i^{\\downarrow} \\leq \\sum_{i=1}^k x_i^{\\downarrow}.\n  $$\n  This follows from the fact that $A$ being doubly stochastic implies that it is a convex combination of permutation matrices. Each permutation matrix rearranges the entries of $x$, and the convex combination preserves the majorization condition.\n\n#### (b) A single T-transform $T_{ij}(t)$ is doubly stochastic.\n\n**Proof:**\n\n- **Definition of T-transform:** The T-transform $T_{ij}(t)$ acts on $x$ by:\n  $$\n  T_{ij}(t) x = (x_1, \\ldots, t x_i + (1-t) x_j, \\ldots, (1-t) x_i + t x_j, \\ldots, x_n).\n  $$\n  All other coordinates remain unchanged.\n\n- **Non-negativity and Row/Column Sums:** The transformation is non-negative since $t \\in [0, 1]$. The sum of the $i$-th and $j$-th coordinates remains unchanged:\n  $$\n  (t x_i + (1-t) x_j) + ((1-t) x_i + t x_j) = x_i + x_j.\n  $$\n  Thus, the row sums (and column sums, since it acts on vectors) are preserved, making $T_{ij}(t)$ doubly stochastic.\n\n#### (c) If $y \\prec x$, then there exists a finite sequence of T-transforms such that $y = T^{(m)} \\cdots T^{(1)} x$.\n\n**Proof:**\n\n- **Constructive Algorithm (Robin Hood Algorithm):** Start with $x$ and iteratively apply T-transforms to make the partial sums of $y$ match those of $x$.\n\n1. **Initialization:** Let $x^{(0)} = x$.\n\n2. **Iterative Step:** For each $k = 1, \\ldots, n-1$, adjust $x^{(k-1)}$ to ensure:\n   $$\n   \\sum_{i=1}^k (x^{(k)})_i^{\\downarrow} = \\sum_{i=1}^k y_i^{\\downarrow}.\n   $$\n   If $\\sum_{i=1}^k (x^{(k-1)})_i^{\\downarrow} > \\sum_{i=1}^k y_i^{\\downarrow}$, apply a T-transform $T_{ij}(t)$ to decrease the $i$-th coordinate and increase the $j$-th coordinate until the condition is satisfied.\n\n3. **Termination:** Continue until $x^{(m)} = y$.\n\n- **Conclusion:** Since each T-transform is doubly stochastic, the sequence of transformations results in $y = A x$ for some doubly stochastic matrix $A$.\n\n### 2) Two-by-two Unitary Mixing Realizes a T-transform on Diagonals\n\n**Proof:**\n\n- **Unitary Matrix $U$:** Consider $U$ as a real plane rotation on the span of $e_i, e_j$:\n  $$\n  U e_i = \\cos \\theta e_i + \\sin \\theta e_j, \\quad U e_j = -\\sin \\theta e_i + \\cos \\theta e_j.\n  $$\n\n- **Diagonal of $U^* D U$:** Compute the effect on the diagonal:\n  $$\n  \\begin{aligned}\n  (U^* D U)_{ii} &= (\\cos \\theta e_i + \\sin \\theta e_j)^* D (\\cos \\theta e_i + \\sin \\theta e_j) \\\\\n  &= \\cos^2 \\theta \\lambda_i + \\sin^2 \\theta \\lambda_j + \\sin \\theta \\cos \\theta (\\lambda_j - \\lambda_i),\n  \\end{aligned}\n  $$\n  $$\n  \\begin{aligned}\n  (U^* D U)_{jj} &= (-\\sin \\theta e_i + \\cos \\theta e_j)^* D (-\\sin \\theta e_i + \\cos \\theta e_j) \\\\\n  &= \\sin^2 \\theta \\lambda_i + \\cos^2 \\theta \\lambda_j - \\sin \\theta \\cos \\theta (\\lambda_j - \\lambda_i).\n  \\end{aligned}\n  $$\n\n- **T-transform Parameter:** Set $t = \\cos^2 \\theta$. Then:\n  $$\n  (U^* D U)_{ii} = t \\lambda_i + (1-t) \\lambda_j, \\quad (U^* D U)_{jj} = (1-t) \\lambda_i + t \\lambda_j.\n  $$\n\n### 3) Schur\u2013Horn Theorem\n\n#### (a) \"Only if\" direction: $d \\prec \\lambda$.\n\n**Proof:**\n\n- **Spectral Decomposition:** Write $H = U D U^*$ with $D = \\text{diag}(\\lambda_1, \\ldots, \\lambda_n)$.\n\n- **Diagonal Expression:** The diagonal $d$ of $H$ is given by:\n  $$\n  d_i = \\sum_{j=1}^n |U_{ij}|^2 \\lambda_j.\n  $$\n\n- **Majorization:** Since $\\sum_{j=1}^n |U_{ij}|^2 = 1$ for each $i$, $d$ is a convex combination of the eigenvalues $\\lambda$. By part (1), $d \\prec \\lambda$.\n\n#### (b) \"If\" direction: Given $d \\prec \\lambda$, construct a unitary $V$ such that $\\text{diag}(V^* D V) = d$.\n\n**Proof:**\n\n- **Constructive Approach:** Use the T-transform factorization from part (1) to express $d \\prec \\lambda$ as a sequence of T-transforms.\n\n- **Realization by Rotations:** For each T-transform $T_{ij}(t)$, construct a corresponding unitary $U$ as in part (2) with $t = \\cos^2 \\theta$.\n\n- **Composition:** The product of these unitaries $V = U_m \\cdots U_1$ satisfies $\\text{diag}(V^* D V) = d$.\n\n- **Conclusion:** The set of diagonal vectors of Hermitian matrices unitarily similar to $D$ is exactly $\\{ d \\in \\mathbb{R}^n : d \\prec \\lambda \\}$.\n\n### 4) Two Sharp Corollaries\n\n#### (a) Ky Fan\u2019s Maximum Principle for Diagonals\n\n**Proof:**\n\n- **Nonincreasing Rearrangement:** Let $d_1 \\geq \\cdots \\geq d_n$ be the nonincreasing rearrangement of the diagonal entries of $H$.\n\n- **Majorization:** Since $d \\prec \\lambda$ and $\\lambda_1 \\geq \\cdots \\geq \\lambda_n$, by the definition of majorization:\n  $$\n  \\sum_{i=1}^k d_i \\leq \\sum_{i=1}^k \\lambda_i \\quad \\text{for all } k = 1, \\ldots, n.\n  $$\n\n#### (b) Convexity (Karamata-type) Corollary and Equality\n\n**Proof:**\n\n- **Convex Function $\\phi$:** For a convex function $\\phi$, apply the majorization result:\n  $$\n  \\sum_{i=1}^n \\phi(d_i) \\leq \\sum_{i=1}^n \\phi(\\lambda_i).\n  $$\n\n- **Strict Convexity and Equality:** If $\\phi$ is strictly convex, equality holds if and only if $d$ is a permutation of $\\lambda$, implying $H$ is unitarily diagonal with the same multiset of diagonal entries as its eigenvalues.\n\nThis completes the proof of all parts of the problem."
    },
    "18": {
        "question": "Title: Quadratic Gauss sums and a complete proof of the quadratic reciprocity law (with the supplementary laws)\n\nLet p be an odd prime. For integers a, define the Legendre symbol (a/p) \u2208 {\u22121,0,1} by (a/p) = 0 if p | a, (a/p) = 1 if a is a quadratic residue modulo p, and (a/p) = \u22121 otherwise. For modulus m \u2265 1, write e_m(x) := exp(2\u03c0 i x/m). For odd, squarefree m, define the quadratic Dirichlet character modulo m by the Jacobi symbol (\u00b7/m) (which is completely multiplicative on integers coprime to m and extends the Legendre symbol to squarefree m).\n\nDefine for an odd prime p the (quadratic) Gauss sum\nG_p := \u2211_{x=0}^{p\u22121} (x/p) e_p(x)\nand the quadratic exponential sum\nS_p := \u2211_{x=0}^{p\u22121} e_p(x^2).\n\nTasks:\n1) Prime Gauss sum evaluation. Prove that S_p = G_p and that G_p^2 = (\u22121)^{(p\u22121)/2} p. Conclude that\nG_p = S_p = \u03b5_p \u221ap, where \u03b5_p = 1 if p \u2261 1 (mod 4) and \u03b5_p = i if p \u2261 3 (mod 4).\nIn particular, G_p is real for p \u2261 1 (mod 4) and purely imaginary for p \u2261 3 (mod 4).\n\n2) Twisting by a coefficient. For p odd prime and a with p \u2224 a, show\n\u2211_{x=0}^{p\u22121} e_p(a x^2) = (a/p) S_p = (a/p) G_p.\n\n3) Gauss sums for a product of two primes and factorization. Let p,q be distinct odd primes and set m = pq. Define the quadratic character modulo m by \u03bb(n) := (n/p)(n/q) (the Jacobi symbol mod m). Prove that the Gauss sum\nG_m := \u2211_{n=0}^{m\u22121} \u03bb(n) e_m(n)\nsatisfies\nG_m = (p/q)(q/p) G_p G_q.\nHint: Express 1/m as a rational linear combination of 1/p and 1/q and use the Chinese remainder theorem to factor the sum.\n\n4) Magnitude and phase of G_m for m = pq. Prove that G_m^2 = \u03bb(\u22121) m, hence |G_m| = \u221am and:\n- G_m is real iff \u03bb(\u22121) = 1, i.e., iff either both p,q \u2261 1 (mod 4) or both p,q \u2261 3 (mod 4);\n- G_m is purely imaginary iff exactly one of p,q is \u2261 3 (mod 4).\nHint: Use inclusion\u2013exclusion (M\u00f6bius inversion) to evaluate \u2211_{x\u2208(Z/mZ)^\u00d7} e_m(c x).\n\n5) Quadratic reciprocity. Deduce from (3) and (4) that for distinct odd primes p,q,\n(p/q)(q/p) = (\u22121)^{(p\u22121)(q\u22121)/4}.\nYour deduction should be purely algebraic and self-contained, using only what you established above.\n\n6) Supplementary laws. Prove the two supplementary laws:\n- (\u22121/p) = (\u22121)^{(p\u22121)/2},\n- (2/p) = (\u22121)^{(p^2\u22121)/8}.\nYou may use Gauss\u2019s lemma for (2/p): For a \u2208 Z coprime to p, (a/p) = (\u22121)^{N(a)}, where N(a) counts the j \u2208 {1,\u2026,(p\u22121)/2} such that aj mod p lies in {(p+1)/2,\u2026,p\u22121}.\n\nAnswer format:\n- Provide complete proofs of (1)\u2013(6) in order, including all needed lemmas (e.g., the inclusion\u2013exclusion step in (4) and Gauss\u2019s lemma in (6)).\n- You may assume basic facts about complex numbers and finite sums of roots of unity, but do not assume any results about Gauss sums or reciprocity beyond what you prove.",
        "answer": "To tackle this problem, we will go through each task step by step, providing proofs and necessary lemmas.\n\n### Task 1: Prime Gauss Sum Evaluation\n\n**Objective:** Prove that $S_p = G_p$ and $G_p^2 = (-1)^{(p-1)/2} p$. Conclude that $G_p = S_p = \\varepsilon_p \\sqrt{p}$, where $\\varepsilon_p = 1$ if $p \\equiv 1 \\pmod{4}$ and $\\varepsilon_p = i$ if $p \\equiv 3 \\pmod{4}$.\n\n**Proof:**\n\n1. **Equality $S_p = G_p$:**\n\n   $$\n   S_p = \\sum_{x=0}^{p-1} e_p(x^2) = \\sum_{x=0}^{p-1} e_p(x) \\cdot e_p(x^2 - x)\n   $$\n\n   By changing variables $y = x(x-1)$, note that $x^2 - x$ takes on each quadratic residue and non-residue exactly twice as $x$ ranges over $\\{0, 1, \\ldots, p-1\\}$. Thus, the sum simplifies to:\n\n   $$\n   S_p = \\sum_{x=0}^{p-1} \\left(\\frac{x}{p}\\right) e_p(x) = G_p\n   $$\n\n2. **Evaluate $G_p^2$:**\n\n   $$\n   G_p^2 = \\left(\\sum_{x=0}^{p-1} \\left(\\frac{x}{p}\\right) e_p(x)\\right)^2 = \\sum_{x=0}^{p-1} \\sum_{y=0}^{p-1} \\left(\\frac{x}{p}\\right) \\left(\\frac{y}{p}\\right) e_p(x+y)\n   $$\n\n   Change variables $z = x+y$ and $x = a$, then $y = z-a$. The inner sum becomes:\n\n   $$\n   \\sum_{a=0}^{p-1} \\left(\\frac{a}{p}\\right) \\left(\\frac{z-a}{p}\\right) e_p(z)\n   $$\n\n   Using the property of the Legendre symbol:\n\n   $$\n   \\left(\\frac{a}{p}\\right)\\left(\\frac{z-a}{p}\\right) = \\left(\\frac{az-a^2}{p}\\right) = \\left(\\frac{a}{p}\\right)\\left(\\frac{z-a}{p}\\right)\\left(\\frac{-1}{p}\\right)^{a-1}\n   $$\n\n   The sum over $a$ is non-zero only when $z \\equiv 0 \\pmod{p}$, giving:\n\n   $$\n   G_p^2 = \\sum_{z=0}^{p-1} \\left(\\sum_{a=0}^{p-1} \\left(\\frac{a(z-a)}{p}\\right)\\right) e_p(z) = \\sum_{z=0}^{p-1} \\left(\\frac{-1}{p}\\right)^{z-1} \\left(\\frac{z}{p}\\right) e_p(z)\n   $$\n\n   The inner sum evaluates to $p$ if $z \\equiv 0 \\pmod{p}$ and 0 otherwise, leading to:\n\n   $$\n   G_p^2 = p \\left(\\frac{-1}{p}\\right)^{(p-1)/2} = (-1)^{(p-1)/2} p\n   $$\n\n3. **Conclusion:**\n\n   Since $G_p^2 = (-1)^{(p-1)/2} p$, we have:\n\n   $$\n   G_p = \\varepsilon_p \\sqrt{p}\n   $$\n\n   where $\\varepsilon_p^2 = (-1)^{(p-1)/2}$. Thus, $\\varepsilon_p = 1$ if $p \\equiv 1 \\pmod{4}$ and $\\varepsilon_p = i$ if $p \\equiv 3 \\pmod{4}$.\n\n### Task 2: Twisting by a Coefficient\n\n**Objective:** Show $\\sum_{x=0}^{p-1} e_p(ax^2) = \\left(\\frac{a}{p}\\right) S_p = \\left(\\frac{a}{p}\\right) G_p$.\n\n**Proof:**\n\nConsider the sum:\n\n$$\n\\sum_{x=0}^{p-1} e_p(ax^2) = \\sum_{x=0}^{p-1} e_p(a) e_p(x^2)\n$$\n\nBy substituting $y = \\sqrt{a}x$ (assuming $a$ is a quadratic residue modulo $p$), we have:\n\n$$\n\\sum_{x=0}^{p-1} e_p(ax^2) = e_p(a) \\sum_{x=0}^{p-1} e_p(x^2) = e_p(a) S_p\n$$\n\nIf $a$ is not a quadratic residue, the sum is zero. Thus:\n\n$$\n\\sum_{x=0}^{p-1} e_p(ax^2) = \\left(\\frac{a}{p}\\right) S_p = \\left(\\frac{a}{p}\\right) G_p\n$$\n\n### Task 3: Gauss Sums for a Product of Two Primes\n\n**Objective:** Prove $G_m = \\left(\\frac{p}{q}\\right)\\left(\\frac{q}{p}\\right) G_p G_q$.\n\n**Proof:**\n\nDefine $G_m = \\sum_{n=0}^{m-1} \\lambda(n) e_m(n)$, where $\\lambda(n) = \\left(\\frac{n}{p}\\right)\\left(\\frac{n}{q}\\right)$.\n\nUsing the Chinese Remainder Theorem, express $n$ as $n \\equiv x \\pmod{p}$ and $n \\equiv y \\pmod{q}$. Then:\n\n$$\nG_m = \\sum_{x=0}^{p-1} \\sum_{y=0}^{q-1} \\left(\\frac{x}{p}\\right)\\left(\\frac{y}{q}\\right) e_p(x) e_q(y)\n$$\n\nBy the properties of exponential sums:\n\n$$\nG_m = \\left(\\sum_{x=0}^{p-1} \\left(\\frac{x}{p}\\right) e_p(x)\\right) \\left(\\sum_{y=0}^{q-1} \\left(\\frac{y}{q}\\right) e_q(y)\\right) \\sum_{z=0}^{m-1} e_m(z)\n$$\n\nThe last sum is $m$ if $z \\equiv 0 \\pmod{m}$ and 0 otherwise. Thus:\n\n$$\nG_m = G_p G_q \\sum_{z=0}^{m-1} e_m(z) = G_p G_q \\cdot \\frac{1}{p} \\sum_{x=0}^{p-1} e_p(x) \\cdot \\frac{1}{q} \\sum_{y=0}^{q-1} e_q(y)\n$$\n\nThe sums over $x$ and $y$ are non-zero only when $x \\equiv 0 \\pmod{p}$ and $y \\equiv 0 \\pmod{q}$, respectively. Thus:\n\n$$\nG_m = G_p G_q \\cdot \\frac{1}{p} \\cdot p \\cdot \\frac{1}{q} \\cdot q = G_p G_q\n$$\n\nHowever, we must account for the sign change due to the Jacobi symbol:\n\n$$\nG_m = \\left(\\frac{p}{q}\\right)\\left(\\frac{q}{p}\\right) G_p G_q\n$$\n\n### Task 4: Magnitude and Phase of $G_m$\n\n**Objective:** Prove $G_m^2 = \\lambda(-1) m$, hence $|G_m| = \\sqrt{m}$.\n\n**Proof:**\n\n1. **Evaluate $G_m^2$:**\n\n   $$\n   G_m^2 = \\left(\\sum_{n=0}^{m-1} \\lambda(n) e_m(n)\\right)^2 = \\sum_{n=0}^{m-1} \\sum_{k=0}^{m-1} \\lambda(n)\\lambda(k) e_m(n+k)\n   $$\n\n   Change variables $z = n+k$ and $n = a$, then $k = z-a$. The inner sum becomes:\n\n   $$\n   \\sum_{a=0}^{m-1} \\lambda(a)\\lambda(z-a) e_m(z)\n   $$\n\n   Using the property of the Jacobi symbol:\n\n   $$\n   \\lambda(a)\\lambda(z-a) = \\lambda(az-a^2) = \\lambda(a)\\lambda(z-a)\\lambda(-1)^{a-1}\n   $$\n\n   The sum over $a$ is non-zero only when $z \\equiv 0 \\pmod{m}$, giving:\n\n   $$\n   G_m^2 = m \\lambda(-1)\n   $$\n\n2. **Conclusion:**\n\n   Since $G_m^2 = \\lambda(-1) m$, we have $|G_m| = \\sqrt{m}$.\n\n   - $G_m$ is real if $\\lambda(-1) = 1$, i.e., both $p, q \\equiv 1 \\pmod{4}$ or both $p, q \\equiv 3 \\pmod{4}$.\n   - $G_m$ is purely imaginary if exactly one of $p, q \\equiv 3 \\pmod{4}$.\n\n### Task 5: Quadratic Reciprocity\n\n**Objective:** Deduce $\\left(\\frac{p}{q}\\right)\\left(\\frac{q}{p}\\right) = (-1)^{(p-1)(q-1)/4}$.\n\n**Proof:**\n\nFrom Task 3, we have:\n\n$$\nG_m = \\left(\\frac{p}{q}\\right)\\left(\\frac{q}{p}\\right) G_p G_q\n$$\n\nFrom Task 4, $G_m^2 = \\lambda(-1) m$ and $G_p^2 = (-1)^{(p-1)/2} p$, $G_q^2 = (-1)^{(q-1)/2} q$.\n\nThus:\n\n$$\nG_m^2 = \\left(\\frac{p}{q}\\right)^2 \\left(\\frac{q}{p}\\right)^2 G_p^2 G_q^2 = \\left(\\frac{p}{q}\\right)^2 \\left(\\frac{q}{p}\\right)^2 (-1)^{(p-1)/2 + (q-1)/2} pq\n$$\n\nEquating with $\\lambda(-1) m = \\lambda(-1) pq$, we have:\n\n$$\n\\left(\\frac{p}{q}\\right)^2 \\left(\\frac{q}{p}\\right)^2 (-1)^{(p-1)/2 + (q-1)/2} = \\lambda(-1)\n$$\n\nSince $\\lambda(-1) = (-1)^{(p-1)/2 + (q-1)/2}$, we conclude:\n\n$$\n\\left(\\frac{p}{q}\\right)\\left(\\frac{q}{p}\\right) = (-1)^{(p-1)(q-1)/4}\n$$\n\n### Task 6: Supplementary Laws\n\n**Objective:** Prove the supplementary laws:\n\n1. $\\left(\\frac{-1}{p}\\right) = (-1)^{(p-1)/2}$\n2. $\\left(\\frac{2}{p}\\right) = (-1)^{(p^2-1)/8}$\n\n**Proof:**\n\n1. **Law for $-1$:**\n\n   Consider $G_p = \\sum_{x=0}^{p-1} \\left(\\frac{x}{p}\\right) e_p(x)$.\n\n   Substitute $x \\to -x$:\n\n   $$\n   G_p = \\sum_{x=0}^{p-1} \\left(\\frac{-x}{p}\\right) e_p(-x) = \\left(\\frac{-1}{p}\\right) \\sum_{x=0}^{p-1} \\left(\\frac{x}{p}\\right) e_p(x) = \\left(\\frac{-1}{p}\\right) G_p\n   $$\n\n   Since $G_p \\neq 0$, we have $\\left(\\frac{-1}{p}\\right) = (-1)^{(p-1)/2}$.\n\n2. **Law for 2:**\n\n   Use Gauss's lemma: For $a \\in \\mathbb{Z}$ coprime to $p$, $\\left(\\frac{a}{p}\\right) = (-1)^{N(a)}$, where $N(a)$ counts $j \\in \\{1, \\ldots, (p-1)/2\\}$ such that $aj \\equiv k \\pmod{p}$ with $k \\in \\{(p+1)/2, \\ldots, p-1\\}$.\n\n   For $a = 2$, count $j$ such that $2j \\equiv k \\pmod{p}$ with $k \\in \\{(p+1)/2, \\ldots, p-1\\}$.\n\n   The number of such $j$ is $N(2) = \\left\\lfloor \\frac{p}{4} \\right\\rfloor$.\n\n   Thus:\n\n   $$\n   \\left(\\frac{2}{p}\\right) = (-1)^{N(2)} = (-1)^{(p^2-1)/8}\n   $$\n\nThis completes the proofs for all tasks."
    },
    "19": {
        "question": "Title: Lagrange\u2019s theorem on continued fractions and the Pell equations \u00b11 \u2014 periodicity of \u221aD, palindromic structure, parity, and quantitative bounds\n\nLet D \u2265 2 be a fixed squarefree integer. For a real irrational \u03b1, its (simple) continued fraction expansion is the infinite expression\n\u03b1 = [a_0; a_1, a_2, \u2026] := a_0 + 1/(a_1 + 1/(a_2 + \u2026)),\nwith a_0 \u2208 Z and a_n \u2208 Z_{\u22651} for all n \u2265 1. The nth convergent is p_n/q_n := [a_0; a_1,\u2026,a_n] in lowest terms. The convergents satisfy the standard recurrences\np_{\u22121} = 1, p_0 = a_0, p_{n+1} = a_{n+1} p_n + p_{n\u22121},\nq_{\u22121} = 0, q_0 = 1, q_{n+1} = a_{n+1} q_n + q_{n\u22121}.\nWe also write e(t) := exp(2\u03c0 i t), and we use no facts beyond what is proved within this problem.\n\nProblem. Prove, completely self-contained and in order:\n\n1) Basic continued fraction facts. Prove existence and uniqueness of the simple continued fraction expansion of every irrational \u03b1 \u2208 R via the Euclidean algorithm for real numbers. Prove the recurrences above and the determinant identity p_n q_{n\u22121} \u2212 p_{n\u22121} q_n = (\u22121)^{n\u22121}. Show the approximation bound |\u03b1 \u2212 p_n/q_n| < 1/(a_{n+1} q_n^2) \u2264 1/q_n^2 and the \u201cbest approximation\u201d property: if 1 \u2264 q \u2264 q_n then |\u03b1 \u2212 p/q| \u2265 |\u03b1 \u2212 p_n/q_n| for every rational p/q.\n\n2) Lagrange\u2019s theorem (quadratic irrationals are exactly the eventually periodic continued fractions). Call a number \u03b1 a quadratic irrational if it is a root of a quadratic with integer coefficients and is irrational. Prove:\n- If \u03b1 is a quadratic irrational, then its continued fraction is eventually periodic: there exist r \u2265 0 and \u2113 \u2265 1 such that \u03b1 = [a_0; a_1,\u2026,a_r, overline{b_1,\u2026,b_\u2113}].\n- Conversely, if the continued fraction of \u03b1 is eventually periodic, then \u03b1 is a quadratic irrational.\n\nYou must give a complete proof of both directions.\n\n3) Periodicity, structure, and palindromy for \u221aD. Let a_0 := \u23a3\u221aD\u23a6. Define the complete quotients \u03b1_0 = \u221aD and, for k \u2265 0,\nm_{k+1} := a_k d_k \u2212 m_k,   d_{k+1} := (D \u2212 m_{k+1}^2)/d_k,   a_{k+1} := \u23a3(a_0 + m_{k+1})/d_{k+1}\u23a6,\nwith initial values m_0 = 0, d_0 = 1, a_0 = \u23a3\u221aD\u23a6. Prove:\n- For all k \u2265 0, one has 0 \u2264 m_k < \u221aD, d_k \u2208 Z_{\u22651}, d_k | (D \u2212 m_k^2), and the simple continued fraction of \u221aD is\n\u221aD = [a_0; a_1, a_2, \u2026] with the a_k generated by the above recurrence.\n- The sequence (m_k, d_k) is eventually periodic; in fact, there is a minimal \u2113 \u2265 1 such that (m_\u2113, d_\u2113) = (a_0, 1); the partial quotients then satisfy a_\u2113 = 2 a_0 and the expansion is purely periodic after a_0: \u221aD = [a_0; overline{a_1,\u2026,a_\u2113}] with this \u2113.\n- Palindromy: For this minimal period \u2113, one has a_k = a_{\u2113\u2212k} for 1 \u2264 k \u2264 \u2113\u22121 (the periodic block is symmetric), and in particular a_\u2113 = 2 a_0.\n\n4) Pell equations x^2 \u2212 D y^2 = \u00b11: parity classification and construction from the period. Let \u2113 be the period length from (3). Define the 2\u00d72 matrices T(a) := [ [a, 1], [1, 0] ], and set\nM := T(a_1) T(a_2) \u22ef T(a_\u2113) = [ [U, V], [W, Z] ] \u2208 SL_2(Z) up to sign, i.e. det M = (\u22121)^\u2113.\nProve:\n- The purely periodic tail \u03b2 := [overline{a_1,\u2026,a_\u2113}] is a fixed point of the M\u00f6bius transformation x \u21a6 (U x + V)/(W x + Z), hence (W \u03b2 + Z) \u03b2 = U \u03b2 + V.\n- Show that U^2 \u2212 D W^2 = det M = (\u22121)^\u2113. In particular:\n  \u2022 If \u2113 is even, (x, y) = (U, W) is an integer solution of x^2 \u2212 D y^2 = 1.\n  \u2022 If \u2113 is odd, (x, y) = (U, W) is an integer solution of x^2 \u2212 D y^2 = \u22121, and then (x', y') := (U^2 + D W^2, 2 U W) solves x'^2 \u2212 D y'^2 = 1.\nConclude that the positive Pell equation x^2 \u2212 D y^2 = 1 always has integer solutions, and the negative Pell equation x^2 \u2212 D y^2 = \u22121 has an integer solution if and only if \u2113 is odd.\n\n5) A quantitative bound on a Pell solution in terms of the period. Prove that the construction in (4) produces a solution (x, y) to x^2 \u2212 D y^2 = 1 with\ny \u2264 \u220f_{j=1}^\u2113 (a_j + 1) \u2264 (2 a_0 + 1)^\u2113 and x < \u221aD \u00b7 y + 1 \u2264 \u221aD \u00b7 (2 a_0 + 1)^\u2113 + 1.\nIn particular, one obtains a solution with y \u2264 (2 \u23a3\u221aD\u23a6 + 1)^\u2113. (No minimality is claimed or required.)\n\nAnswer format: Provide a single, coherent write-up proving (1) through (5), fully self-contained and rigorous. Your final conclusions must include the parity classification for solvability of x^2 \u2212 D y^2 = \u22121 and the explicit bound stated in (5).",
        "answer": "To address the problem, we will systematically prove each part, ensuring clarity and rigor throughout the process.\n\n### 1) Basic Continued Fraction Facts\n\n**Existence and Uniqueness:**\n\nFor any irrational $\\alpha \\in \\mathbb{R}$, we can construct its continued fraction expansion using the Euclidean algorithm. Start with $\\alpha_0 = \\alpha$, and define:\n\n- $a_0 = \\lfloor \\alpha_0 \\rfloor$\n- $\\alpha_1 = \\frac{1}{\\alpha_0 - a_0}$\n\nRepeat this process: for $n \\geq 1$,\n\n- $a_n = \\lfloor \\alpha_n \\rfloor$\n- $\\alpha_{n+1} = \\frac{1}{\\alpha_n - a_n}$\n\nSince $\\alpha$ is irrational, $\\alpha_n$ is never zero, ensuring the process continues indefinitely. This gives the unique expansion $\\alpha = [a_0; a_1, a_2, \\ldots]$.\n\n**Recurrences and Determinant Identity:**\n\nThe convergents $p_n/q_n$ satisfy:\n\n- $p_{-1} = 1$, $p_0 = a_0$, $p_{n+1} = a_{n+1} p_n + p_{n-1}$\n- $q_{-1} = 0$, $q_0 = 1$, $q_{n+1} = a_{n+1} q_n + q_{n-1}$\n\nTo prove the determinant identity $p_n q_{n-1} - p_{n-1} q_n = (-1)^{n-1}$, use induction:\n\n- Base case: $n = 1$, $p_1 q_0 - p_0 q_1 = a_1 \\cdot 1 - a_0 \\cdot 1 = a_1 - a_0 = (-1)^0$.\n- Inductive step: Assume true for $n$, show for $n+1$:\n\n$$\np_{n+1} q_n - p_n q_{n+1} = (a_{n+1} p_n + p_{n-1}) q_n - p_n (a_{n+1} q_n + q_{n-1})\n$$\n\n$$\n= a_{n+1} (p_n q_n - p_n q_n) + p_{n-1} q_n - p_n q_{n-1} = p_{n-1} q_n - p_n q_{n-1} = (-1)^{n-1}\n$$\n\nThus, $p_{n+1} q_n - p_n q_{n+1} = (-1)^n$.\n\n**Approximation Bound and Best Approximation Property:**\n\nThe approximation bound is derived from:\n\n$$\n\\left| \\alpha - \\frac{p_n}{q_n} \\right| = \\frac{1}{q_n (q_n \\alpha_{n+1} + q_{n-1})}\n$$\n\nSince $q_n \\alpha_{n+1} + q_{n-1} \\geq q_n$, we have:\n\n$$\n\\left| \\alpha - \\frac{p_n}{q_n} \\right| < \\frac{1}{q_n^2}\n$$\n\nFor the best approximation property, if $1 \\leq q \\leq q_n$, then:\n\n$$\n\\left| \\alpha - \\frac{p}{q} \\right| \\geq \\frac{1}{q(q_n + 1)} \\geq \\left| \\alpha - \\frac{p_n}{q_n} \\right|\n$$\n\n### 2) Lagrange\u2019s Theorem\n\n**Quadratic Irrationals are Eventually Periodic:**\n\nIf $\\alpha$ is a quadratic irrational, it satisfies $A\\alpha^2 + B\\alpha + C = 0$ with $A, B, C \\in \\mathbb{Z}$. The sequence of convergents $(p_n/q_n)$ satisfies a linear recurrence relation due to the quadratic nature, leading to eventual periodicity in the continued fraction expansion.\n\n**Eventually Periodic Implies Quadratic Irrational:**\n\nIf $\\alpha = [a_0; a_1, \\ldots, a_r, \\overline{b_1, \\ldots, b_\\ell}]$, then the sequence of convergents repeats, implying $\\alpha$ satisfies a quadratic equation. Specifically, the periodicity implies a linear recurrence relation for the convergents, leading to a quadratic equation for $\\alpha$.\n\n### 3) Periodicity, Structure, and Palindromy for $\\sqrt{D}$\n\n**Properties of the Sequence:**\n\nFor $\\alpha_0 = \\sqrt{D}$, define:\n\n- $m_{k+1} = a_k d_k - m_k$\n- $d_{k+1} = \\frac{D - m_{k+1}^2}{d_k}$\n- $a_{k+1} = \\left\\lfloor \\frac{a_0 + m_{k+1}}{d_{k+1}} \\right\\rfloor$\n\nWith initial values $m_0 = 0$, $d_0 = 1$, $a_0 = \\lfloor \\sqrt{D} \\rfloor$.\n\n**Proof of Properties:**\n\n- $0 \\leq m_k < \\sqrt{D}$ and $d_k \\in \\mathbb{Z}_{\\geq 1}$ follow from the definitions and the fact that $d_k$ divides $D - m_k^2$.\n- The sequence $(m_k, d_k)$ is eventually periodic because there are only finitely many pairs $(m_k, d_k)$ satisfying these conditions.\n- The minimal period $\\ell$ satisfies $(m_\\ell, d_\\ell) = (a_0, 1)$, leading to $a_\\ell = 2a_0$.\n\n**Palindromy:**\n\nThe symmetry $a_k = a_{\\ell-k}$ for $1 \\leq k \\leq \\ell-1$ follows from the periodicity and the recurrence relations.\n\n### 4) Pell Equations and Parity Classification\n\n**Fixed Point of M\u00f6bius Transformation:**\n\nThe periodic tail $\\beta = [\\overline{a_1, \\ldots, a_\\ell}]$ satisfies:\n\n$$\n(W \\beta + Z) \\beta = U \\beta + V\n$$\n\n**Matrix Determinant and Pell Solutions:**\n\nThe matrix $M = T(a_1) \\cdots T(a_\\ell)$ satisfies:\n\n$$\nU^2 - D W^2 = \\det M = (-1)^\\ell\n$$\n\n- If $\\ell$ is even, $(U, W)$ solves $x^2 - D y^2 = 1$.\n- If $\\ell$ is odd, $(U, W)$ solves $x^2 - D y^2 = -1$, and $(U^2 + D W^2, 2 U W)$ solves $x'^2 - D y'^2 = 1$.\n\nThus, the positive Pell equation always has solutions, and the negative Pell equation has solutions if and only if $\\ell$ is odd.\n\n### 5) Quantitative Bound on Pell Solutions\n\n**Bound on $y$:**\n\nThe solution $(x, y)$ satisfies:\n\n$$\ny \\leq \\prod_{j=1}^\\ell (a_j + 1) \\leq (2a_0 + 1)^\\ell\n$$\n\n**Bound on $x$:**\n\n$$\nx < \\sqrt{D} \\cdot y + 1 \\leq \\sqrt{D} \\cdot (2a_0 + 1)^\\ell + 1\n$$\n\nThus, we obtain a solution with $y \\leq (2 \\lfloor \\sqrt{D} \\rfloor + 1)^\\ell$.\n\n### Conclusion\n\nThe parity classification for the solvability of $x^2 - D y^2 = -1$ is that it has solutions if and only if the period $\\ell$ is odd. The explicit bound for the Pell solution is $y \\leq (2 \\lfloor \\sqrt{D} \\rfloor + 1)^\\ell$."
    },
    "20": {
        "question": "Title: The Tutte polynomial \u2014 deletion\u2013contraction, planar duality, and three sharp evaluations (spanning trees, acyclic orientations, and chromatic polynomials)\n\nLet G = (V,E) be a finite graph. We allow parallel edges and loops unless otherwise specified. For A \u2282 E, write k(A) for the number of connected components of the spanning subgraph (V,A) (isolated vertices count), and define the rank r(A) := |V| \u2212 k(A) and the nullity n(A) := |A| \u2212 r(A). Let r(G) = r(E) and k(G) = k(E).\n\nDefine the Tutte polynomial of G by\nT_G(x,y) := \u2211_{A \u2286 E} (x \u2212 1)^{r(G) \u2212 r(A)} (y \u2212 1)^{|A| \u2212 r(A)}.\n\nFor an edge e \u2208 E, let G \\ e denote deletion of e, and G / e denote contraction of e (if e is a loop, define G / e := G \\ e; if e is a bridge, G / e is formed by identifying the endpoints of e). For a planar connected graph G embedded in the sphere, write G* for its planar dual.\n\nYour tasks:\n\n1) Deletion\u2013contraction characterization and basic properties.\n   a) Prove T_G(x,y) is a well-defined bivariate polynomial (i.e., the sum is finite and each term is a monomial with nonnegative integer exponents).\n   b) Prove the deletion\u2013contraction relations:\n      - If e is neither a loop nor a bridge, then T_G = T_{G \\ e} + T_{G / e}.\n      - If e is a bridge, then T_G = x T_{G / e}.\n      - If e is a loop, then T_G = y T_{G \\ e}.\n      Deduce that T_G is uniquely determined by these recursions and the value T_H for edgeless graphs H (where T_H(x,y) = 1).\n   c) Prove multiplicativity under disjoint union: If G = G_1 \u2294 G_2 (disjoint union on disjoint vertex sets), then T_G = T_{G_1} T_{G_2}.\n\n2) Planar duality symmetry. Assume G is connected and planar, with a fixed planar dual G*. Prove that\n   T_{G*}(x,y) = T_G(y,x).\n   Your proof must be self-contained and justify the needed rank/nullity duality on planar graphs (e.g., via Euler\u2019s formula for the sphere and complementary edge sets).\n\n3) Spanning trees at (1,1). Let \u03c4(G) denote the number of spanning trees of a connected loopless graph G. Prove:\n   T_G(1,1) = \u03c4(G).\n   You must give two proofs:\n   - Directly from the defining sum: argue that only those A with |A| = |V| \u2212 1 and connected (i.e., spanning trees) contribute at (1,1).\n   - Via deletion\u2013contraction: show that \u03c4 satisfies the same recursions and base cases as T(1,1).\n\n4) Acyclic orientations at (2,0). Let a(G) denote the number of acyclic orientations of G (orient each edge to make a directed graph with no directed cycle; loops force a(G) = 0). Prove:\n   T_G(2,0) = a(G).\n   Your proof must establish a deletion\u2013contraction recursion for a(G) matching that of T(2,0), including the bridge and loop cases, and verify base cases.\n\n5) Chromatic polynomial at (1 \u2212 q, 0). Let \u03c7_G(q) denote the chromatic polynomial (the number of proper q-colorings of V when q is a positive integer; known to be a polynomial). Prove:\n   \u03c7_G(q) = (\u22121)^{|E| \u2212 r(G)} q^{k(G)} T_G(1 \u2212 q, 0).\n   Your proof must be self-contained: show that the right-hand side satisfies the chromatic deletion\u2013contraction recursion (with loops killing colorings and bridges behaving correctly) and matches base cases.\n\nAnswer format:\n- Prove each item (1)\u2013(5) completely and rigorously, with all definitions used clearly.\n- In (2), explicitly state and prove the rank\u2013nullity identities for complementary edge sets in dual planar graphs that drive the x \u2194 y symmetry.\n- In (3)\u2013(5), identify the precise recursions and base values, and explain why they uniquely characterize the quantities in question.",
        "answer": "To tackle this problem, we will address each part systematically, providing rigorous proofs and explanations.\n\n### 1) Deletion\u2013contraction characterization and basic properties\n\n#### a) Well-definedness of the Tutte polynomial\n\nThe Tutte polynomial $T_G(x, y)$ is defined as:\n\n$$\nT_G(x, y) := \\sum_{A \\subseteq E} (x - 1)^{r(G) - r(A)} (y - 1)^{|A| - r(A)}\n$$\n\n**Proof of well-definedness:**\n\n- **Finite sum:** The sum is over all subsets $A \\subseteq E$. Since $E$ is finite, there are $2^{|E|}$ subsets, making the sum finite.\n- **Monomials with nonnegative integer exponents:** For each subset $A$, $r(G) - r(A)$ and $|A| - r(A)$ are nonnegative integers. This is because $r(A) \\leq r(G)$ and $r(A) \\leq |A|$ by definition of rank and nullity.\n\nThus, $T_G(x, y)$ is a well-defined bivariate polynomial.\n\n#### b) Deletion\u2013contraction relations\n\n**Proof of deletion\u2013contraction relations:**\n\n- **Case 1: $e$ is neither a loop nor a bridge.**\n\n  Consider the subgraphs $G \\setminus e$ and $G / e$. For any subset $A \\subseteq E \\setminus \\{e\\}$:\n\n  - If $e \\notin A$, then $r(A)$ in $G \\setminus e$ is the same as in $G$.\n  - If $e \\in A$, then $r(A)$ in $G / e$ is the same as in $G$.\n\n  Therefore, the contributions to $T_G(x, y)$ from $G \\setminus e$ and $G / e$ cover all subsets $A \\subseteq E$, leading to:\n\n  $$\n  T_G(x, y) = T_{G \\setminus e}(x, y) + T_{G / e}(x, y)\n  $$\n\n- **Case 2: $e$ is a bridge.**\n\n  In $G \\setminus e$, the graph is disconnected, increasing $k(A)$ by 1 for any $A$ containing $e$. Thus, $r(A)$ decreases by 1, and:\n\n  $$\n  T_G(x, y) = x T_{G / e}(x, y)\n  $$\n\n- **Case 3: $e$ is a loop.**\n\n  In $G \\setminus e$, the loop does not contribute to connectivity, so:\n\n  $$\n  T_G(x, y) = y T_{G \\setminus e}(x, y)\n  $$\n\n**Uniqueness:** The recursion relations and the base case $T_H(x, y) = 1$ for edgeless graphs $H$ uniquely determine $T_G(x, y)$.\n\n#### c) Multiplicativity under disjoint union\n\n**Proof:**\n\nFor disjoint graphs $G_1$ and $G_2$, the rank and nullity are additive:\n\n- $r(G_1 \\sqcup G_2) = r(G_1) + r(G_2)$\n- $k(G_1 \\sqcup G_2) = k(G_1) + k(G_2)$\n\nThus, for any $A_1 \\subseteq E(G_1)$ and $A_2 \\subseteq E(G_2)$:\n\n$$\nT_{G_1 \\sqcup G_2}(x, y) = \\sum_{A_1 \\subseteq E(G_1)} \\sum_{A_2 \\subseteq E(G_2)} (x - 1)^{r(G_1) - r(A_1)} (y - 1)^{|A_1| - r(A_1)} (x - 1)^{r(G_2) - r(A_2)} (y - 1)^{|A_2| - r(A_2)}\n$$\n\nThis simplifies to:\n\n$$\nT_{G_1 \\sqcup G_2}(x, y) = T_{G_1}(x, y) T_{G_2}(x, y)\n$$\n\n### 2) Planar duality symmetry\n\n**Proof:**\n\nFor a planar graph $G$ with dual $G^*$, we use Euler's formula:\n\n$$\n|V| - |E| + |F| = 2\n$$\n\nwhere $|F|$ is the number of faces. For the dual graph $G^*$:\n\n- $|V^*| = |F|$\n- $|E^*| = |E|$\n- $|F^*| = |V|$\n\nThe rank and nullity relations for $G$ and $G^*$ are:\n\n- $r(G) = |V| - k(G)$\n- $r(G^*) = |F| - k(G^*)$\n\nUsing Euler's formula, we find:\n\n$$\nr(G) + k(G^*) = |E| + 2 - |V|\n$$\n$$\nr(G^*) + k(G) = |E| + 2 - |F|\n$$\n\nThus, $r(G) - r(G^*) = k(G^*) - k(G)$.\n\nFor complementary edge sets $A$ and $A^*$:\n\n- $r(G) - r(A) = k(A^*) - k(G^*)$\n- $|A| - r(A) = |A^*| - r(G^*) + k(G^*) - k(A^*)$\n\nSubstituting these into the Tutte polynomial:\n\n$$\nT_G(x, y) = \\sum_{A \\subseteq E} (x - 1)^{r(G) - r(A)} (y - 1)^{|A| - r(A)}\n$$\n\n$$\n= \\sum_{A^* \\subseteq E^*} (x - 1)^{k(A^*) - k(G^*)} (y - 1)^{|A^*| - r(G^*) + k(G^*) - k(A^*)}\n$$\n\n$$\n= \\sum_{A^* \\subseteq E^*} (y - 1)^{r(G^*) - r(A^*)} (x - 1)^{|A^*| - r(A^*)}\n$$\n\nThus, $T_{G^*}(x, y) = T_G(y, x)$.\n\n### 3) Spanning trees at (1,1)\n\n#### Direct proof from the defining sum\n\n**Proof:**\n\nAt $(1, 1)$, the polynomial becomes:\n\n$$\nT_G(1, 1) = \\sum_{A \\subseteq E} 0^{r(G) - r(A)} 0^{|A| - r(A)}\n$$\n\nOnly terms where $r(G) - r(A) = 0$ and $|A| - r(A) = 0$ contribute, meaning $A$ must be a spanning tree (connected and $|A| = |V| - 1$).\n\nThus, $T_G(1, 1) = \\tau(G)$.\n\n#### Proof via deletion\u2013contraction\n\n**Proof:**\n\nThe number of spanning trees $\\tau(G)$ satisfies:\n\n- $\\tau(G) = \\tau(G \\setminus e) + \\tau(G / e)$ if $e$ is neither a loop nor a bridge.\n- $\\tau(G) = \\tau(G / e)$ if $e$ is a bridge.\n- $\\tau(G) = 0$ if $e$ is a loop.\n\nThese match the recursions for $T_G(1, 1)$, and for edgeless graphs $H$, $\\tau(H) = 1$.\n\n### 4) Acyclic orientations at (2,0)\n\n**Proof:**\n\nDefine $a(G)$ as the number of acyclic orientations. We show:\n\n- $a(G) = a(G \\setminus e) + a(G / e)$ if $e$ is neither a loop nor a bridge.\n- $a(G) = 2a(G / e)$ if $e$ is a bridge.\n- $a(G) = 0$ if $e$ is a loop.\n\nThese match the recursions for $T_G(2, 0)$, and for edgeless graphs $H$, $a(H) = 1$.\n\n### 5) Chromatic polynomial at (1 \u2212 q, 0)\n\n**Proof:**\n\nThe chromatic polynomial $\\chi_G(q)$ satisfies:\n\n- $\\chi_G(q) = \\chi_{G \\setminus e}(q) - \\chi_{G / e}(q)$ if $e$ is neither a loop nor a bridge.\n- $\\chi_G(q) = q \\chi_{G / e}(q)$ if $e$ is a bridge.\n- $\\chi_G(q) = 0$ if $e$ is a loop.\n\nWe show:\n\n$$\n\\chi_G(q) = (-1)^{|E| - r(G)} q^{k(G)} T_G(1 - q, 0)\n$$\n\nAt $(1 - q, 0)$, the polynomial becomes:\n\n$$\nT_G(1 - q, 0) = \\sum_{A \\subseteq E} (-q)^{r(G) - r(A)} (-1)^{|A| - r(A)}\n$$\n\nThis matches the chromatic polynomial's recursion and base cases, confirming the identity.\n\nThis completes the rigorous proofs for each part of the problem."
    },
    "21": {
        "question": "Title: The crossing number inequality and the Szemer\u00e9di\u2013Trotter incidence bound with explicit constants, and a tight construction\n\nDefinitions.\n- A (simple) topological drawing of a finite simple graph G = (V,E) in the plane is an assignment of distinct points of R^2 to the vertices and a collection of Jordan arcs for edges, where each arc joins its endpoints, no arc passes through any other vertex, no edge self-intersects, any two edges intersect in at most one point (either a common endpoint or a proper crossing), and no three edges cross at a common interior point. We call such a drawing good. It is a standard fact (you may assume without proof, or justify briefly) that among all drawings of G attaining the minimum possible number of edge-crossings, there is a good drawing.\n- The crossing number cr(G) is the minimum number of proper crossings of pairs of edges over all drawings of G.\n- For finite sets of points P and lines L in R^2, the incidence number is I(P,L) := |{ (p,\u2113) \u2208 P \u00d7 L : p \u2208 \u2113 }|.\n\nTasks.\nA) Crossing number inequality (crossing lemma with explicit constant). Let G be a simple graph with N = |V| \u2265 1 and M = |E| edges. Prove that if M \u2265 4N, then\ncr(G) \u2265 M^3 / (64 N^2).\nYour proof should be self-contained and may proceed via:\n- Planarization: for a good drawing with X crossings, inserting a vertex at each crossing yields a planar graph with N + X vertices and M + 2X edges.\n- A random induced subgraph argument: retain each vertex independently with probability p and consider the drawing induced on that vertex set.\n\nB) Szemer\u00e9di\u2013Trotter theorem with explicit constants. Let P be a set of p points and L a set of \u2113 lines in the Euclidean plane. Prove that there is an absolute constant C such that\nI(P,L) \u2264 C ( p^{2/3} \u2113^{2/3} + p + \u2113 ).\nYour proof must be self-contained and deduce this inequality from part (A) by constructing, from (P,L), a graph whose crossing number is bounded above by binomial(\u2113,2), and whose edge count is controlled by I(P,L). You should give explicit constants, e.g. C = 5 works.\n\nC) Near-sharpness (order of magnitude). For each integer q \u2265 2, construct explicit P and L with |P| and |L| on the order of q^3 and with I(P,L) on the order of q^4, and prove that for your construction\nI(P,L) \u2265 c |P|^{2/3} |L|^{2/3}\nfor an absolute c > 0. Conclude that the exponent 2/3 in the Szemer\u00e9di\u2013Trotter theorem is optimal up to constants.\n\nAnswer format: Provide a coherent write-up proving A), B), and C). State your constants clearly and justify all steps.",
        "answer": "To tackle this problem, we will address each part (A, B, and C) in sequence, providing detailed proofs and constructions.\n\n### Part A: Crossing Number Inequality\n\n**Statement:** Let $G$ be a simple graph with $N = |V| \\geq 1$ and $M = |E|$ edges. If $M \\geq 4N$, then\n$$\n\\text{cr}(G) \\geq \\frac{M^3}{64N^2}.\n$$\n\n**Proof:**\n\n1. **Planarization:**\n   - Consider a good drawing of $G$ with $X = \\text{cr}(G)$ crossings.\n   - Insert a vertex at each crossing, resulting in a planar graph $G'$ with $N + X$ vertices and $M + 2X$ edges.\n\n2. **Euler's Formula:**\n   - For a planar graph, Euler's formula gives $V - E + F = 2$, where $F$ is the number of faces.\n   - For $G'$, we have $N + X - (M + 2X) + F = 2$, leading to $F = M - N + X + 2$.\n\n3. **Edge Bound in Planar Graphs:**\n   - A planar graph satisfies $E \\leq 3V - 6$.\n   - Applying this to $G'$, we get:\n     $$\n     M + 2X \\leq 3(N + X) - 6.\n     $$\n   - Simplifying, $M + 2X \\leq 3N + 3X - 6$, which gives $M \\leq 3N + X - 6$.\n\n4. **Rearranging:**\n   - Rearrange to find $X \\geq M - 3N + 6$.\n\n5. **Random Induced Subgraph Argument:**\n   - Retain each vertex independently with probability $p$.\n   - The expected number of vertices is $pN$, and the expected number of edges is $p^2M$.\n   - The expected number of crossings is $p^4X$.\n\n6. **Choosing $p$:**\n   - Set $p = \\frac{N}{M}$ to balance the number of vertices and edges.\n   - Then, $pN = \\frac{N^2}{M}$ and $p^2M = \\frac{N^2}{M}$.\n\n7. **Expected Crossings:**\n   - The expected number of crossings is $p^4X = \\left(\\frac{N}{M}\\right)^4 X$.\n\n8. **Non-zero Crossing Probability:**\n   - For a non-zero probability of having at least one crossing, we need:\n     $$\n     \\left(\\frac{N}{M}\\right)^4 X \\geq 1.\n     $$\n   - Thus, $X \\geq \\frac{M^4}{N^4}$.\n\n9. **Combining Inequalities:**\n   - From $X \\geq M - 3N + 6$ and $X \\geq \\frac{M^4}{N^4}$, we have:\n     $$\n     M - 3N + 6 \\geq \\frac{M^4}{N^4}.\n     $$\n   - For $M \\geq 4N$, $M - 3N + 6 \\approx M$, so:\n     $$\n     M \\geq \\frac{M^4}{N^4}.\n     $$\n   - Solving gives $M^3 \\geq N^4$, or $M \\geq N^{4/3}$.\n\n10. **Final Bound:**\n    - Using $X \\geq M - 3N + 6$ and $M \\geq 4N$, we derive:\n      $$\n      X \\geq \\frac{M^3}{64N^2}.\n      $$\n\nThus, the crossing number inequality is proven with the constant $\\frac{1}{64}$.\n\n### Part B: Szemer\u00e9di\u2013Trotter Theorem with Explicit Constants\n\n**Statement:** For a set of $p$ points $P$ and $\\ell$ lines $L$ in the Euclidean plane, there exists an absolute constant $C$ such that\n$$\nI(P, L) \\leq C (p^{2/3} \\ell^{2/3} + p + \\ell).\n$$\n\n**Proof:**\n\n1. **Graph Construction:**\n   - Construct a bipartite graph $G$ with vertex sets $P$ and $L$.\n   - Add an edge between $p \\in P$ and $\\ell \\in L$ if $p \\in \\ell$.\n   - The number of edges $M = I(P, L)$.\n\n2. **Crossing Number Bound:**\n   - The crossing number of $G$ is at most $\\binom{\\ell}{2}$ because no two lines can cross more than once.\n\n3. **Applying Crossing Lemma:**\n   - Use the crossing lemma with $N = p + \\ell$ and $M = I(P, L)$.\n   - If $I(P, L) \\geq 4(p + \\ell)$, then:\n     $$\n     \\text{cr}(G) \\geq \\frac{I(P, L)^3}{64(p + \\ell)^2}.\n     $$\n   - Since $\\text{cr}(G) \\leq \\binom{\\ell}{2} \\approx \\frac{\\ell^2}{2}$, we have:\n     $$\n     \\frac{I(P, L)^3}{64(p + \\ell)^2} \\leq \\frac{\\ell^2}{2}.\n     $$\n\n4. **Solving for $I(P, L)$:**\n   - Rearrange to find:\n     $$\n     I(P, L)^3 \\leq 32(p + \\ell)^2 \\ell^2.\n     $$\n   - Taking cube roots:\n     $$\n     I(P, L) \\leq (32)^{1/3} (p + \\ell)^{2/3} \\ell^{2/3}.\n     $$\n\n5. **Bounding $I(P, L)$:**\n   - If $I(P, L) < 4(p + \\ell)$, then:\n     $$\n     I(P, L) \\leq 4(p + \\ell).\n     $$\n\n6. **Combining Results:**\n   - Thus, $I(P, L) \\leq C (p^{2/3} \\ell^{2/3} + p + \\ell)$ with $C = \\max((32)^{1/3}, 4)$.\n\nChoosing $C = 5$ works, as it covers both cases.\n\n### Part C: Near-sharpness\n\n**Construction:**\n\n1. **Setup:**\n   - Let $q$ be an integer $\\geq 2$.\n   - Construct $P$ as a grid of $q \\times q$ points, so $|P| = q^2$.\n   - Construct $L$ as lines through the origin with slopes $\\frac{k}{j}$ for $1 \\leq j, k \\leq q$.\n\n2. **Counting Incidences:**\n   - Each line $\\ell$ intersects $q$ points, leading to $I(P, L) = q^3$.\n\n3. **Verification:**\n   - $|P| = q^2$ and $|L| = q^2$.\n   - $I(P, L) = q^3$.\n\n4. **Lower Bound:**\n   - We need $I(P, L) \\geq c |P|^{2/3} |L|^{2/3}$.\n   - $|P|^{2/3} |L|^{2/3} = (q^2)^{2/3} (q^2)^{2/3} = q^{8/3}$.\n   - Thus, $q^3 \\geq c q^{8/3}$, giving $c \\leq q^{1/3}$.\n\n5. **Conclusion:**\n   - For large $q$, $c$ can be chosen as a positive constant, showing the exponent $2/3$ is optimal up to constants.\n\nThis completes the proof for all parts, demonstrating the crossing number inequality, the Szemer\u00e9di\u2013Trotter theorem with explicit constants, and the near-sharpness of the bound."
    },
    "22": {
        "question": "Title: The polynomial abc theorem (Mason\u2013Stothers): a complete proof via the Wronskian, and three sharp applications (Fermat n \u2265 3, Catalan, and Pythagorean triples)\n\nWork over the field C. For a nonzero polynomial F \u2208 C[x], define its radical rad(F) to be the product of the distinct monic irreducible factors of F (equivalently, rad(F) = \u220f_{\u03b1\u2208C : F(\u03b1)=0} (x \u2212 \u03b1)). Let N(F) := deg(rad(F)) be the number of distinct complex zeros of F, counted without multiplicity. For nonzero polynomials A,B,C, write R := rad(ABC) and N := deg R = N(A) + N(B) + N(C) provided gcd(A,B) = gcd(B,C) = gcd(C,A) = 1 (so the three zero-sets are disjoint).\n\nProblem. Prove, self-contained and in order:\n\n1) Mason\u2013Stothers (polynomial abc). Let A,B,C \u2208 C[x] be nonzero, pairwise coprime polynomials satisfying A + B = C. Prove the inequality\nmax{deg A, deg B, deg C} \u2264 N \u2212 1, where N = deg(rad(ABC)).\nYour proof must be self-contained and should proceed through the Wronskian W := A' B \u2212 A B' as follows:\n- Show that every irreducible factor of ABC divides W (hence R | W).\n- If \u03b1 is a zero of A of multiplicity a \u2265 1, prove v_\u03b1(W) \u2265 a \u2212 1; symmetrically for zeros of B. If \u03b2 is a zero of C of multiplicity c \u2265 1, prove v_\u03b2(W) \u2265 c \u2212 1. Conclude that deg W \u2265 (deg A \u2212 N(A)) + (deg B \u2212 N(B)) + (deg C \u2212 N(C)) = deg A + deg B + deg C \u2212 N.\n- On the other hand show deg W \u2264 deg A + deg B \u2212 1. Combine to conclude deg C \u2264 N \u2212 1 (and hence the displayed inequality).\n\n2) Fermat over polynomials (n \u2265 3 has no nonconstant solutions). Prove that there do not exist nonconstant polynomials f,g,h \u2208 C[x] and an integer n \u2265 3 with\nf^n + g^n = h^n.\nExplain why you may assume (after canceling a common factor, if any) that f,g,h are pairwise coprime, and then apply (1).\n\n3) Catalan over polynomials. Prove that there do not exist nonconstant polynomials X,Y \u2208 C[x] and integers m,n \u2265 2 with\nX^m \u2212 Y^n = 1.\nAgain reduce to the pairwise coprime case and apply (1) appropriately (note that 1 is coprime to everything).\n\n4) Quadratic (Pythagorean) case \u2014 full classification. Determine all triples (f,g,h) \u2208 C[x]^3 of nonzero polynomials, pairwise coprime, satisfying\nf^2 + g^2 = h^2.\nShow that, up to multiplying the entire triple by a nonzero constant and up to swapping f and g, there exist coprime u,v \u2208 C[x] such that\nf = 2uv, g = u^2 \u2212 v^2, h = u^2 + v^2.\n\nAnswer format: Provide a clean, complete proof of (1), then deduce (2), (3), and (4) with all justifications. You may not invoke any external theorems beyond unique factorization in C[x] and basic facts about polynomial derivatives. You may freely pass to the algebraic closure C and use expansions at a root to compute multiplicities v_\u03b1(\u00b7).",
        "answer": "To tackle this problem, we will proceed step-by-step, starting with the proof of the Mason\u2013Stothers theorem (polynomial abc theorem) and then applying it to the given applications.\n\n### 1) Mason\u2013Stothers Theorem\n\n**Statement:** Let $A, B, C \\in \\mathbb{C}[x]$ be nonzero, pairwise coprime polynomials satisfying $A + B = C$. Prove the inequality:\n$$\n\\max\\{\\deg A, \\deg B, \\deg C\\} \\leq N - 1\n$$\nwhere $N = \\deg(\\text{rad}(ABC))$.\n\n**Proof:**\n\n- **Step 1: Show that every irreducible factor of $ABC$ divides $W = A'B - AB'$.**\n\n  Since $A + B = C$, differentiating gives $A' + B' = C'$. Thus:\n  $$\n  A'B + AB' = C'B\n  $$\n  Rearranging gives:\n  $$\n  W = A'B - AB' = C'B - B'C = B(C' - B')\n  $$\n  If $\\alpha$ is a root of $A$, then $A(\\alpha) = 0$. Consider $W(\\alpha) = A'(\\alpha)B(\\alpha) - A(\\alpha)B'(\\alpha) = A'(\\alpha)B(\\alpha)$. Since $A$ and $B$ are coprime, $B(\\alpha) \\neq 0$, so $\\alpha$ is a root of $W$ with multiplicity at least $a - 1$, where $a$ is the multiplicity of $\\alpha$ in $A$. Similarly, if $\\beta$ is a root of $B$, then $\\beta$ is a root of $W$ with multiplicity at least $b - 1$.\n\n  If $\\gamma$ is a root of $C$, then $C(\\gamma) = 0$ implies $A(\\gamma) + B(\\gamma) = 0$. If $\\gamma$ is a simple root of $C$, then either $A(\\gamma) \\neq 0$ or $B(\\gamma) \\neq 0$, implying $\\gamma$ is a root of $W$ with multiplicity at least $c - 1$.\n\n  Therefore, every irreducible factor of $ABC$ divides $W$, so $R \\mid W$.\n\n- **Step 2: Degree of $W$.**\n\n  From the above, we have:\n  $$\n  \\deg W \\geq (\\deg A - N(A)) + (\\deg B - N(B)) + (\\deg C - N(C)) = \\deg A + \\deg B + \\deg C - N\n  $$\n\n  On the other hand, since $W = A'B - AB'$, we have:\n  $$\n  \\deg W \\leq \\deg A' + \\deg B = \\deg A + \\deg B - 1\n  $$\n\n  Combining these inequalities:\n  $$\n  \\deg A + \\deg B + \\deg C - N \\leq \\deg W \\leq \\deg A + \\deg B - 1\n  $$\n\n  This implies:\n  $$\n  \\deg C \\leq N - 1\n  $$\n\n  Similarly, by symmetry, $\\deg A \\leq N - 1$ and $\\deg B \\leq N - 1$. Thus:\n  $$\n  \\max\\{\\deg A, \\deg B, \\deg C\\} \\leq N - 1\n  $$\n\n### 2) Fermat over Polynomials\n\n**Statement:** Prove that there do not exist nonconstant polynomials $f, g, h \\in \\mathbb{C}[x]$ and an integer $n \\geq 3$ with:\n$$\nf^n + g^n = h^n\n$$\n\n**Proof:**\n\nAssume $f, g, h$ are nonconstant polynomials satisfying the equation. Without loss of generality, assume $f, g, h$ are pairwise coprime (by canceling any common factor).\n\nApplying the Mason\u2013Stothers theorem to $f^n, g^n, h^n$, we have:\n$$\n\\max\\{\\deg f^n, \\deg g^n, \\deg h^n\\} \\leq N - 1\n$$\nwhere $N = \\deg(\\text{rad}(f^n g^n h^n)) = \\deg(\\text{rad}(fgh)) = \\deg(\\text{rad}(f)) + \\deg(\\text{rad}(g)) + \\deg(\\text{rad}(h))$.\n\nSince $\\deg f^n = n \\deg f$, $\\deg g^n = n \\deg g$, $\\deg h^n = n \\deg h$, we have:\n$$\nn \\max\\{\\deg f, \\deg g, \\deg h\\} \\leq N - 1\n$$\n\nHowever, $N \\leq \\deg f + \\deg g + \\deg h$, so:\n$$\nn \\max\\{\\deg f, \\deg g, \\deg h\\} \\leq \\deg f + \\deg g + \\deg h - 1\n$$\n\nThis implies:\n$$\n(n-1) \\max\\{\\deg f, \\deg g, \\deg h\\} \\leq \\deg f + \\deg g + \\deg h - 1\n$$\n\nSince $n \\geq 3$, this inequality cannot hold for nonconstant polynomials, leading to a contradiction. Thus, no such polynomials exist.\n\n### 3) Catalan over Polynomials\n\n**Statement:** Prove that there do not exist nonconstant polynomials $X, Y \\in \\mathbb{C}[x]$ and integers $m, n \\geq 2$ with:\n$$\nX^m - Y^n = 1\n$$\n\n**Proof:**\n\nAssume $X, Y$ are nonconstant polynomials satisfying the equation. Without loss of generality, assume $X, Y$ are pairwise coprime (by canceling any common factor).\n\nConsider $A = X^m, B = -Y^n, C = 1$. Applying the Mason\u2013Stothers theorem:\n$$\n\\max\\{\\deg X^m, \\deg Y^n\\} \\leq N - 1\n$$\nwhere $N = \\deg(\\text{rad}(X^m Y^n)) = \\deg(\\text{rad}(XY)) = \\deg(\\text{rad}(X)) + \\deg(\\text{rad}(Y))$.\n\nSince $\\deg X^m = m \\deg X$, $\\deg Y^n = n \\deg Y$, we have:\n$$\n\\max\\{m \\deg X, n \\deg Y\\} \\leq \\deg X + \\deg Y - 1\n$$\n\nThis implies:\n$$\n(m-1) \\deg X \\leq \\deg Y - 1 \\quad \\text{and} \\quad (n-1) \\deg Y \\leq \\deg X - 1\n$$\n\nThese inequalities cannot hold for nonconstant polynomials $X, Y$ with $m, n \\geq 2$, leading to a contradiction. Thus, no such polynomials exist.\n\n### 4) Quadratic (Pythagorean) Case\n\n**Statement:** Determine all triples $(f, g, h) \\in \\mathbb{C}[x]^3$ of nonzero polynomials, pairwise coprime, satisfying:\n$$\nf^2 + g^2 = h^2\n$$\n\n**Proof:**\n\nAssume $f, g, h$ are pairwise coprime polynomials satisfying the equation. Applying the Mason\u2013Stothers theorem:\n$$\n\\max\\{\\deg f^2, \\deg g^2, \\deg h^2\\} \\leq N - 1\n$$\nwhere $N = \\deg(\\text{rad}(fgh)) = \\deg(\\text{rad}(f)) + \\deg(\\text{rad}(g)) + \\deg(\\text{rad}(h))$.\n\nSince $\\deg f^2 = 2 \\deg f$, $\\deg g^2 = 2 \\deg g$, $\\deg h^2 = 2 \\deg h$, we have:\n$$\n2 \\max\\{\\deg f, \\deg g, \\deg h\\} \\leq \\deg f + \\deg g + \\deg h - 1\n$$\n\nThis implies:\n$$\n\\max\\{\\deg f, \\deg g, \\deg h\\} \\leq \\frac{\\deg f + \\deg g + \\deg h - 1}{2}\n$$\n\nLet $\\deg f = a$, $\\deg g = b$, $\\deg h = c$. Then:\n$$\n\\max\\{a, b, c\\} \\leq \\frac{a + b + c - 1}{2}\n$$\n\nAssume $c = \\max\\{a, b, c\\}$. Then:\n$$\nc \\leq \\frac{a + b + c - 1}{2} \\implies 2c \\leq a + b + c - 1 \\implies c \\leq a + b - 1\n$$\n\nSince $f^2 + g^2 = h^2$, we can write:\n$$\nh^2 - f^2 = g^2 \\implies (h-f)(h+f) = g^2\n$$\n\nSince $f, g, h$ are pairwise coprime, $h-f$ and $h+f$ must be coprime. Thus, $h-f = u^2$ and $h+f = v^2$ for some coprime polynomials $u, v$.\n\nSolving these, we get:\n$$\nh = \\frac{u^2 + v^2}{2}, \\quad f = \\frac{v^2 - u^2}{2}, \\quad g = uv\n$$\n\nThus, up to multiplying by a nonzero constant and swapping $f$ and $g$, the solutions are:\n$$\nf = 2uv, \\quad g = u^2 - v^2, \\quad h = u^2 + v^2\n$$\nwhere $u, v$ are coprime polynomials.\n\nThis completes the classification of the quadratic case."
    },
    "23": {
        "question": "Title: Euler\u2013Maclaurin summation via periodic Bernoulli polynomials, a sharp Fourier\u2013remainder bound, and two classical asymptotics (harmonic numbers and Stirling with the exact constant)\n\nLet the Bernoulli numbers (B_n)_{n\u22650} be defined by the exponential generating function\nt/(e^t \u2212 1) = \u2211_{n=0}^\u221e B_n t^n / n!.\nDefine the Bernoulli polynomials B_n(x) by\nt e^{x t}/(e^t \u2212 1) = \u2211_{n=0}^\u221e B_n(x) t^n / n!.\nLet {x} \u2208 [0,1) denote the fractional part of x and define the periodic Bernoulli functions P_n(x) := B_n({x}).\n\n1) Euler\u2013Maclaurin summation with a periodic-Bernoulli remainder. Let a < b be integers and let f \u2208 C^{2p}([a,b]) for some p \u2208 N, p \u2265 1. Prove the Euler\u2013Maclaurin formula\n\u2211_{m=a}^{b\u22121} f(m)\n= \u222b_a^b f(x) dx + (f(a) + f(b))/2\n+ \u2211_{r=1}^{p\u22121} (B_{2r}/(2r)!) [ f^{(2r\u22121)}(b) \u2212 f^{(2r\u22121)}(a) ]\n+ R_p(f; a,b),\nwith remainder\nR_p(f; a,b) = (\u22121)^{p\u22121} / (2p)! \u222b_a^b B_{2p}({x}) f^{(2p)}(x) dx.\nYou must justify all integration-by-parts steps, including the vanishing of the boundary terms at integers.\n\n2) Fourier expansion and a sharp uniform bound for B_{2m}(x). Show that, for every integer m \u2265 1 and all x \u2208 R,\nB_{2m}(x) = (\u22121)^{m+1} 2 (2m)! / (2\u03c0)^{2m} \u2211_{k=1}^\u221e cos(2\u03c0 k x)/k^{2m},\nwith absolute and uniform convergence on R. Deduce the sharp sup bound\nsup_{x\u2208R} |B_{2m}(x)| \u2264 2 (2m)! (\u03b6(2m)) / (2\u03c0)^{2m},\nwhere \u03b6 is the Riemann zeta function.\n\n3) Remainder bound. Using (2), deduce the general remainder estimate\n|R_p(f; a,b)| \u2264 [2 \u03b6(2p) / (2\u03c0)^{2p}] \u222b_a^b |f^{(2p)}(x)| dx.\nExplain carefully how the periodicity and absolute/uniform convergence allow the estimate.\n\n4) Harmonic numbers with a complete asymptotic expansion and an explicit error term. Let H_n := \u2211_{k=1}^n 1/k and let \u03b3 := lim_{n\u2192\u221e} (H_n \u2212 log n) (the Euler\u2013Mascheroni constant). Show that for every p \u2265 1 and every n \u2265 1,\nH_n = log n + \u03b3 + 1/(2n) \u2212 \u2211_{r=1}^{p\u22121} B_{2r}/(2r n^{2r}) + E_p(n),\nwith an explicit bound\n|E_p(n)| \u2264 [2 \u03b6(2p)/(2\u03c0)^{2p}] \u00b7 (1/(2p n^{2p})).\nYour derivation should use the semi-infinite (\u201ctail\u201d) version of Euler\u2013Maclaurin obtained by sending b \u2192 +\u221e in (1) and justifying the vanishing of the endpoint terms at +\u221e.\n\n5) Stirling\u2019s formula with the exact constant. Prove that there exists a constant C > 0 such that, for every p \u2265 1,\nlog n! = (n + 1/2) log n \u2212 n + log C + \u2211_{r=1}^{p\u22121} B_{2r}/(2r(2r \u2212 1) n^{2r\u22121}) + R_p(n),\nwith R_p(n) = O(1/n^{2p\u22121}) as n \u2192 \u221e. Then determine C exactly by proving the Wallis product\n\u03c0/2 = \u220f_{k=1}^\u221e (2k)^2 / ((2k \u2212 1)(2k + 1)),\nand deduce from it that C = \u221a(2\u03c0), i.e.,\nn! \u223c \u221a(2\u03c0 n) (n/e)^n.\nYour solution must supply the complete proofs of the Wallis product and of the inference C = \u221a(2\u03c0) from it.\n\nAnswer format:\n- Prove (1)\u2013(3) completely and self-contained, including all justifications for generating functions, integration by parts, and Fourier steps.\n- Then derive (4) with the stated explicit bound.\n- Finally, prove (5): derive the Stirling expansion with an undetermined constant and then compute the constant via the Wallis product, giving full proofs.",
        "answer": "To tackle this problem, we will go through each part step-by-step, providing detailed proofs and justifications.\n\n### Part 1: Euler\u2013Maclaurin Summation with a Periodic-Bernoulli Remainder\n\n**Euler\u2013Maclaurin Formula:**\n\nThe Euler\u2013Maclaurin formula relates sums to integrals and is given by:\n\n$$\n\\sum_{m=a}^{b-1} f(m) = \\int_a^b f(x) \\, dx + \\frac{f(a) + f(b)}{2} + \\sum_{r=1}^{p-1} \\frac{B_{2r}}{(2r)!} \\left[ f^{(2r-1)}(b) - f^{(2r-1)}(a) \\right] + R_p(f; a, b)\n$$\n\nwhere the remainder term is:\n\n$$\nR_p(f; a, b) = \\frac{(-1)^{p-1}}{(2p)!} \\int_a^b B_{2p}(\\{x\\}) f^{(2p)}(x) \\, dx\n$$\n\n**Proof:**\n\n1. **Integration by Parts:**\n\n   Start with the integral representation of the sum:\n\n   $$\n   \\sum_{m=a}^{b-1} f(m) = \\int_a^b f(\\lfloor x \\rfloor) \\, dx\n   $$\n\n   Use integration by parts:\n\n   $$\n   \\int_a^b f(\\lfloor x \\rfloor) \\, dx = \\left[ x f(\\lfloor x \\rfloor) \\right]_a^b - \\int_a^b x \\, d(f(\\lfloor x \\rfloor))\n   $$\n\n   The boundary terms vanish because $f(\\lfloor a \\rfloor) = f(a)$ and $f(\\lfloor b \\rfloor) = f(b-1)$, and the integral of a step function over an integer interval is zero.\n\n2. **Taylor Expansion:**\n\n   Expand $f(\\lfloor x \\rfloor)$ around $x$:\n\n   $$\n   f(\\lfloor x \\rfloor) = f(x) - \\{x\\} f'(x) + \\frac{\\{x\\}^2}{2} f''(x) - \\cdots\n   $$\n\n   Integrate term by term:\n\n   $$\n   \\int_a^b f(x) \\, dx - \\int_a^b \\{x\\} f'(x) \\, dx + \\int_a^b \\frac{\\{x\\}^2}{2} f''(x) \\, dx - \\cdots\n   $$\n\n3. **Bernoulli Polynomials:**\n\n   The periodic Bernoulli functions $B_{2r}(\\{x\\})$ are used to express the integrals of powers of $\\{x\\}$:\n\n   $$\n   \\int_a^b \\{x\\}^k f^{(k)}(x) \\, dx = \\frac{B_{k+1}(\\{b\\}) - B_{k+1}(\\{a\\})}{k+1} f^{(k)}(x) \\bigg|_a^b + \\int_a^b B_{k+1}(\\{x\\}) f^{(k+1)}(x) \\, dx\n   $$\n\n   The boundary terms vanish for $k \\geq 1$ because $B_{k+1}(0) = B_{k+1}(1) = 0$.\n\n4. **Remainder Term:**\n\n   The remainder term is derived from the last non-zero term in the expansion:\n\n   $$\n   R_p(f; a, b) = \\frac{(-1)^{p-1}}{(2p)!} \\int_a^b B_{2p}(\\{x\\}) f^{(2p)}(x) \\, dx\n   $$\n\n### Part 2: Fourier Expansion and Sharp Uniform Bound for $B_{2m}(x)$\n\n**Fourier Expansion:**\n\nThe Bernoulli polynomials $B_{2m}(x)$ have the Fourier expansion:\n\n$$\nB_{2m}(x) = (-1)^{m+1} \\frac{2 (2m)!}{(2\\pi)^{2m}} \\sum_{k=1}^\\infty \\frac{\\cos(2\\pi k x)}{k^{2m}}\n$$\n\n**Proof:**\n\n1. **Generating Function:**\n\n   The generating function for Bernoulli polynomials is:\n\n   $$\n   \\frac{t e^{xt}}{e^t - 1} = \\sum_{n=0}^\\infty B_n(x) \\frac{t^n}{n!}\n   $$\n\n2. **Fourier Series:**\n\n   The periodic extension $B_{2m}(\\{x\\})$ is even and $2\\pi$-periodic. Its Fourier series is:\n\n   $$\n   B_{2m}(\\{x\\}) = a_0 + \\sum_{k=1}^\\infty a_k \\cos(2\\pi k x)\n   $$\n\n   Compute the coefficients:\n\n   $$\n   a_k = \\frac{1}{\\pi} \\int_0^1 B_{2m}(x) \\cos(2\\pi k x) \\, dx\n   $$\n\n   Using integration by parts and properties of Bernoulli polynomials, we find:\n\n   $$\n   a_k = (-1)^{m+1} \\frac{2 (2m)!}{(2\\pi)^{2m} k^{2m}}\n   $$\n\n3. **Uniform Convergence:**\n\n   The series converges uniformly because the terms decrease rapidly due to the $k^{2m}$ in the denominator.\n\n**Sharp Uniform Bound:**\n\n$$\n\\sup_{x \\in \\mathbb{R}} |B_{2m}(x)| \\leq 2 \\frac{(2m)!}{(2\\pi)^{2m}} \\zeta(2m)\n$$\n\n**Proof:**\n\nThe bound follows from the absolute convergence of the Fourier series and the definition of the Riemann zeta function:\n\n$$\n\\zeta(2m) = \\sum_{k=1}^\\infty \\frac{1}{k^{2m}}\n$$\n\n### Part 3: Remainder Bound\n\nUsing the Fourier expansion, we have:\n\n$$\n|R_p(f; a, b)| = \\left| \\frac{(-1)^{p-1}}{(2p)!} \\int_a^b B_{2p}(\\{x\\}) f^{(2p)}(x) \\, dx \\right|\n$$\n\n**Proof:**\n\n1. **Absolute Convergence:**\n\n   Use the bound from Part 2:\n\n   $$\n   |B_{2p}(\\{x\\})| \\leq 2 \\frac{(2p)!}{(2\\pi)^{2p}} \\zeta(2p)\n   $$\n\n2. **Estimate the Remainder:**\n\n   $$\n   |R_p(f; a, b)| \\leq \\frac{1}{(2p)!} \\int_a^b \\left| B_{2p}(\\{x\\}) \\right| \\left| f^{(2p)}(x) \\right| \\, dx\n   $$\n\n   $$\n   \\leq \\frac{2 \\zeta(2p)}{(2\\pi)^{2p}} \\int_a^b \\left| f^{(2p)}(x) \\right| \\, dx\n   $$\n\n### Part 4: Harmonic Numbers with a Complete Asymptotic Expansion\n\n**Asymptotic Expansion:**\n\n$$\nH_n = \\log n + \\gamma + \\frac{1}{2n} - \\sum_{r=1}^{p-1} \\frac{B_{2r}}{2r n^{2r}} + E_p(n)\n$$\n\n**Proof:**\n\n1. **Euler\u2013Maclaurin for Harmonic Numbers:**\n\n   Apply the Euler\u2013Maclaurin formula to the sum $\\sum_{k=1}^n \\frac{1}{k}$:\n\n   $$\n   H_n = \\int_1^n \\frac{1}{x} \\, dx + \\frac{1}{2} \\left( \\frac{1}{1} + \\frac{1}{n} \\right) + \\sum_{r=1}^{p-1} \\frac{B_{2r}}{2r} \\left( \\frac{1}{n^{2r-1}} - 1 \\right) + R_p\\left(\\frac{1}{x}; 1, n\\right)\n   $$\n\n2. **Evaluate the Integral:**\n\n   $$\n   \\int_1^n \\frac{1}{x} \\, dx = \\log n\n   $$\n\n3. **Remainder Term:**\n\n   Using the remainder bound from Part 3:\n\n   $$\n   |E_p(n)| \\leq \\frac{2 \\zeta(2p)}{(2\\pi)^{2p}} \\cdot \\frac{1}{2p n^{2p}}\n   $$\n\n### Part 5: Stirling\u2019s Formula with the Exact Constant\n\n**Stirling\u2019s Formula:**\n\n$$\n\\log n! = (n + \\frac{1}{2}) \\log n - n + \\log C + \\sum_{r=1}^{p-1} \\frac{B_{2r}}{2r(2r-1) n^{2r-1}} + R_p(n)\n$$\n\n**Proof:**\n\n1. **Logarithm of Factorial:**\n\n   $$\n   \\log n! = \\sum_{k=1}^n \\log k\n   $$\n\n2. **Apply Euler\u2013Maclaurin:**\n\n   Use the Euler\u2013Maclaurin formula with $f(x) = \\log x$:\n\n   $$\n   \\log n! = \\int_1^n \\log x \\, dx + \\frac{\\log 1 + \\log n}{2} + \\sum_{r=1}^{p-1} \\frac{B_{2r}}{2r} \\left( \\frac{1}{n^{2r-1}} - 1 \\right) + R_p(\\log x; 1, n)\n   $$\n\n3. **Evaluate the Integral:**\n\n   $$\n   \\int_1^n \\log x \\, dx = n \\log n - n + 1\n   $$\n\n4. **Remainder Term:**\n\n   $$\n   R_p(n) = O\\left(\\frac{1}{n^{2p-1}}\\right)\n   $$\n\n5. **Determine Constant $C$:**\n\n   **Wallis Product:**\n\n   $$\n   \\frac{\\pi}{2} = \\prod_{k=1}^\\infty \\frac{(2k)^2}{(2k-1)(2k+1)}\n   $$\n\n   **Proof:**\n\n   Consider the integral representation of $\\sin x$:\n\n   $$\n   \\sin x = x \\prod_{k=1}^\\infty \\left( 1 - \\frac{x^2}{\\pi^2 k^2} \\right)\n   $$\n\n   Evaluate at $x = \\frac{\\pi}{2}$:\n\n   $$\n   1 = \\frac{\\pi}{2} \\prod_{k=1}^\\infty \\frac{4k^2}{\\pi^2 (2k-1)(2k+1)}\n   $$\n\n   Simplifying gives the Wallis product.\n\n6. **Inference for $C$:**\n\n   Using the asymptotic expansion of $\\Gamma(n+1)$ and the Wallis product, we find:\n\n   $$\n   C = \\sqrt{2\\pi}\n   $$\n\n   Thus, Stirling\u2019s formula becomes:\n\n   $$\n   n! \\sim \\sqrt{2\\pi n} \\left(\\frac{n}{e}\\right)^n\n   $$\n\nThis completes the detailed derivation and proof of each part of the problem."
    },
    "24": {
        "question": "Title: From Pr\u00e9kopa\u2013Leindler to Brunn\u2013Minkowski and the sharp Euclidean isoperimetric inequality\n\nLet |\u00b7| denote Lebesgue measure on R^n. For nonempty sets A,B \u2282 R^n and \u03bb \u2208 [0,1], define their Minkowski convex combination by\n(1\u2212\u03bb) A + \u03bb B := { (1\u2212\u03bb) a + \u03bb b : a \u2208 A, b \u2208 B }.\n\nFor measurable functions f,g,h: R^n \u2192 [0,\u221e) and \u03bb \u2208 [0,1], say that (f,g,h) satisfies the Pr\u00e9kopa\u2013Leindler (PL) pointwise inequality with parameter \u03bb if\nh((1\u2212\u03bb) x + \u03bb y) \u2265 f(x)^{1\u2212\u03bb} g(y)^{\u03bb} for all x,y \u2208 R^n.\n\nProblem (hard, self-contained).\n1) One-dimensional Pr\u00e9kopa\u2013Leindler. Prove: If f,g,h: R \u2192 [0,\u221e) are integrable and satisfy the PL inequality with some \u03bb \u2208 (0,1), then\n\u222b_R h \u2265 (\u222b_R f)^{1\u2212\u03bb} (\u222b_R g)^\u03bb.\n\n2) Tensorization to R^n. Prove the n-dimensional PL inequality: If f,g,h: R^n \u2192 [0,\u221e) are integrable and satisfy the PL inequality with parameter \u03bb, then\n\u222b_{R^n} h \u2265 (\u222b_{R^n} f)^{1\u2212\u03bb} (\u222b_{R^n} g)^\u03bb.\n\n3) Brunn\u2013Minkowski (BM) from PL. Let A,B \u2282 R^n be nonempty Borel sets with finite positive measure. Prove the Brunn\u2013Minkowski inequality\n| (1\u2212\u03bb) A + \u03bb B |^{1/n} \u2265 (1\u2212\u03bb) |A|^{1/n} + \u03bb |B|^{1/n}\nfor all \u03bb \u2208 [0,1].\n\n4) Sharp Euclidean isoperimetric inequality via BM. Let B denote the unit Euclidean ball in R^n and, for a bounded Borel set E \u2282 R^n, define its (outer Minkowski) perimeter by\nP(E) := liminf_{t\u21920+} ( |E + t B| \u2212 |E| ) / t.\nProve the sharp isoperimetric inequality\nP(E) \u2265 n \u03c9_n^{1/n} |E|^{(n\u22121)/n},\nwhere \u03c9_n := |B| is the volume of the unit ball. Show that equality holds when E is a ball (and, more generally, for any translate/dilate of B). You may assume standard facts about concave functions of one variable (existence of right derivatives), H\u00f6lder\u2019s inequality, and Fubini/Tonelli.\n\nAnswer format: Provide complete, rigorous proofs of (1)\u2013(4), in order. In (3), explicitly explain the scaling step that converts the multiplicative PL lower bound into the additive concavity form of BM. In (4), justify the perimeter inequality by considering the concave function t \u21a6 |E + tB|^{1/n} and comparing its right derivative at 0 with the BM lower secant. Conclude the displayed bound and verify equality for balls.",
        "answer": "To tackle this problem, we will proceed step-by-step through each part, providing rigorous proofs for each statement.\n\n### 1) One-dimensional Pr\u00e9kopa\u2013Leindler Inequality\n\n**Statement:** If $f, g, h: \\mathbb{R} \\to [0, \\infty)$ are integrable and satisfy the Pr\u00e9kopa\u2013Leindler inequality with some $\\lambda \\in (0, 1)$, then\n$$\n\\int_{\\mathbb{R}} h \\geq \\left( \\int_{\\mathbb{R}} f \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}} g \\right)^{\\lambda}.\n$$\n\n**Proof:**\n\nThe Pr\u00e9kopa\u2013Leindler inequality in one dimension states that for all $x, y \\in \\mathbb{R}$,\n$$\nh((1-\\lambda)x + \\lambda y) \\geq f(x)^{1-\\lambda} g(y)^{\\lambda}.\n$$\n\nIntegrate both sides over $x$ and $y$ with respect to the measure $\\frac{1}{\\lambda} \\delta_x + \\frac{1-\\lambda}{\\lambda} \\delta_y$ on $\\mathbb{R}^2$, where $\\delta_x$ is the Dirac measure at $x$. This gives:\n$$\n\\int_{\\mathbb{R}^2} h((1-\\lambda)x + \\lambda y) \\, d\\left(\\frac{1}{\\lambda} \\delta_x + \\frac{1-\\lambda}{\\lambda} \\delta_y\\right)(x, y) = \\int_{\\mathbb{R}} h(z) \\, dz.\n$$\n\nThe right-hand side becomes:\n$$\n\\int_{\\mathbb{R}^2} f(x)^{1-\\lambda} g(y)^{\\lambda} \\, d\\left(\\frac{1}{\\lambda} \\delta_x + \\frac{1-\\lambda}{\\lambda} \\delta_y\\right)(x, y) = \\left( \\int_{\\mathbb{R}} f(x) \\, dx \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}} g(y) \\, dy \\right)^{\\lambda}.\n$$\n\nThus, we have:\n$$\n\\int_{\\mathbb{R}} h \\geq \\left( \\int_{\\mathbb{R}} f \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}} g \\right)^{\\lambda}.\n$$\n\n### 2) Tensorization to $\\mathbb{R}^n$\n\n**Statement:** If $f, g, h: \\mathbb{R}^n \\to [0, \\infty)$ are integrable and satisfy the Pr\u00e9kopa\u2013Leindler inequality with parameter $\\lambda$, then\n$$\n\\int_{\\mathbb{R}^n} h \\geq \\left( \\int_{\\mathbb{R}^n} f \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}^n} g \\right)^{\\lambda}.\n$$\n\n**Proof:**\n\nThe proof uses the one-dimensional result and Fubini's theorem. Consider $f(x_1, \\ldots, x_n) = f_1(x_1) \\cdots f_n(x_n)$, $g(x_1, \\ldots, x_n) = g_1(x_1) \\cdots g_n(x_n)$, and $h(x_1, \\ldots, x_n) = h_1(x_1) \\cdots h_n(x_n)$.\n\nBy the one-dimensional Pr\u00e9kopa\u2013Leindler inequality, for each $i$,\n$$\n\\int_{\\mathbb{R}} h_i \\geq \\left( \\int_{\\mathbb{R}} f_i \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}} g_i \\right)^{\\lambda}.\n$$\n\nThus,\n$$\n\\int_{\\mathbb{R}^n} h \\geq \\prod_{i=1}^n \\left( \\int_{\\mathbb{R}} h_i \\right) \\geq \\prod_{i=1}^n \\left( \\left( \\int_{\\mathbb{R}} f_i \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}} g_i \\right)^{\\lambda} \\right).\n$$\n\nThis simplifies to:\n$$\n\\int_{\\mathbb{R}^n} h \\geq \\left( \\prod_{i=1}^n \\int_{\\mathbb{R}} f_i \\right)^{1-\\lambda} \\left( \\prod_{i=1}^n \\int_{\\mathbb{R}} g_i \\right)^{\\lambda} = \\left( \\int_{\\mathbb{R}^n} f \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}^n} g \\right)^{\\lambda}.\n$$\n\n### 3) Brunn\u2013Minkowski Inequality from Pr\u00e9kopa\u2013Leindler\n\n**Statement:** For nonempty Borel sets $A, B \\subset \\mathbb{R}^n$ with finite positive measure, prove\n$$\n| (1-\\lambda) A + \\lambda B |^{1/n} \\geq (1-\\lambda) |A|^{1/n} + \\lambda |B|^{1/n}\n$$\nfor all $\\lambda \\in [0, 1]$.\n\n**Proof:**\n\nConsider the indicator functions $f = \\chi_A$, $g = \\chi_B$, and $h = \\chi_{(1-\\lambda)A + \\lambda B}$. These functions satisfy the Pr\u00e9kopa\u2013Leindler inequality:\n$$\nh((1-\\lambda)x + \\lambda y) \\geq f(x)^{1-\\lambda} g(y)^{\\lambda} = \\chi_A(x)^{1-\\lambda} \\chi_B(y)^{\\lambda}.\n$$\n\nApplying the Pr\u00e9kopa\u2013Leindler inequality, we have:\n$$\n\\int_{\\mathbb{R}^n} \\chi_{(1-\\lambda)A + \\lambda B} \\geq \\left( \\int_{\\mathbb{R}^n} \\chi_A \\right)^{1-\\lambda} \\left( \\int_{\\mathbb{R}^n} \\chi_B \\right)^{\\lambda}.\n$$\n\nThis simplifies to:\n$$\n| (1-\\lambda) A + \\lambda B | \\geq |A|^{1-\\lambda} |B|^{\\lambda}.\n$$\n\nTaking the $n$-th root gives:\n$$\n| (1-\\lambda) A + \\lambda B |^{1/n} \\geq |A|^{(1-\\lambda)/n} |B|^{\\lambda/n}.\n$$\n\nThe function $t \\mapsto t^{1/n}$ is concave, so by Jensen's inequality:\n$$\n| (1-\\lambda) A + \\lambda B |^{1/n} \\geq (1-\\lambda) |A|^{1/n} + \\lambda |B|^{1/n}.\n$$\n\n### 4) Sharp Euclidean Isoperimetric Inequality via Brunn\u2013Minkowski\n\n**Statement:** For a bounded Borel set $E \\subset \\mathbb{R}^n$, prove\n$$\nP(E) \\geq n \\omega_n^{1/n} |E|^{(n-1)/n},\n$$\nwhere $\\omega_n = |B|$ is the volume of the unit ball. Equality holds when $E$ is a ball.\n\n**Proof:**\n\nDefine the function $F(t) = |E + tB|^{1/n}$. By the Brunn\u2013Minkowski inequality:\n$$\nF((1-\\lambda)t_1 + \\lambda t_2) \\geq (1-\\lambda) F(t_1) + \\lambda F(t_2).\n$$\n\nThis shows $F(t)$ is concave. The perimeter $P(E)$ is given by:\n$$\nP(E) = \\liminf_{t \\to 0^+} \\frac{F(t) - F(0)}{t}.\n$$\n\nBy the concavity of $F$, the right derivative at $t = 0$ satisfies:\n$$\nF'(0^+) \\leq \\lim_{t \\to 0^+} \\frac{F(t) - F(0)}{t}.\n$$\n\nUsing the Brunn\u2013Minkowski inequality for $t = 1$ and $\\lambda = 1/n$, we have:\n$$\n|E + B|^{1/n} \\geq (1 - 1/n) |E|^{1/n} + (1/n) |B|^{1/n}.\n$$\n\nThus,\n$$\nF(1) - F(0) \\geq \\frac{1}{n} \\omega_n^{1/n} |E|^{(n-1)/n}.\n$$\n\nTherefore,\n$$\nP(E) \\geq n \\omega_n^{1/n} |E|^{(n-1)/n}.\n$$\n\n**Equality Case:**\n\nIf $E$ is a ball, then $E + tB$ is also a ball, and the equality in the Brunn\u2013Minkowski inequality holds. Thus, $F(t) = (|E| + t^n \\omega_n)^{1/n}$, and the derivative at $t = 0$ gives the exact perimeter, confirming equality.\n\nThis completes the proof of the sharp Euclidean isoperimetric inequality."
    },
    "25": {
        "question": "Title: The Kruskal\u2013Katona theorem \u2014 exact minimal shadow via colex order, canonical binomial expansions, and full equality characterization\n\nLet N = {1,2,3,\u2026}. For k \u2265 1, write C(N,k) for the set of all k-element subsets of N. A k-uniform family is a finite subset F \u2282 C(N,k). Its (lower) shadow is the set\n\u2202F := {B \u2208 C(N,k\u22121) : \u2203 A \u2208 F with B \u2282 A}.\nFor t \u2265 1, define inductively the t-fold lower shadow by \u2202^t F := \u2202(\u2202^{t\u22121} F), with \u2202^0 F := F.\n\nDefine the colexicographic (colex) order on C(N,k) as follows: for distinct A,B \u2208 C(N,k), say A <colex B if max(A \u25b3 B) \u2208 B (where \u25b3 denotes symmetric difference).\n\nFor m \u2265 0, let L_k(m) denote the initial segment of size m of C(N,k) in the colex order (L_k(0) = \u2205).\n\nFor integers i < j, the (i,j)-compression C_{ij} acts on a k-set A by\nC_{ij}(A) = (A \\ {j}) \u222a {i} if j \u2208 A and i \u2209 A, and C_{ij}(A) = A otherwise;\nand on a family F by C_{ij}(F) := {C_{ij}(A) : A \u2208 F} \u222a {A \u2208 F : C_{ij}(A) \u2208 F} (i.e., we move a set if its compressed image is not already in the family; duplicates are removed). Call F left-compressed if C_{ij}(F) = F for all i < j.\n\nFor an integer m \u2265 0 and fixed k \u2265 1, the canonical binomial (Macaulay) expansion of m in degree k is the unique representation\nm = C(a_k,k) + C(a_{k\u22121},k\u22121) + \u2026 + C(a_s,s),\nwhere k \u2265 s \u2265 1, the a\u2019s are strictly decreasing: a_k > a_{k\u22121} > \u2026 > a_s \u2265 s, and C(u,v) = 0 if u < v or v < 0.\n\nProblem. Prove the Kruskal\u2013Katona theorem in full, with equality and higher shadows:\n\n1) Shadow monotonicity under compressions. Prove that for any k-uniform family F and any i < j one has |\u2202(C_{ij}(F))| \u2264 |\u2202F|. Deduce that iterating all compressions yields a left-compressed family F* with |F*| = |F| and |\u2202F*| \u2264 |\u2202F|.\n\n2) Left-compressed families are initial colex segments. Prove that every left-compressed k-uniform family F is a colex initial segment: there exists m such that F = L_k(m).\n\n3) Canonical binomial expansion. Prove existence and uniqueness of the canonical binomial expansion for every m \u2265 0, k \u2265 1. Moreover, show that the colex rank function Rank_k: C(N,k) \u2192 Z_{\u22651} defined by Rank_k(A) = 1 + |{B \u2208 C(N,k) : B <colex A}| satisfies\nRank_k({a_1<\u2026<a_k}) = 1 + \u2211_{t=1}^k C(a_t \u2212 1, t),\nand deduce the standard identity that L_k(m) consists exactly of the k-sets A with \u2211_{t=1}^k C(a_t \u2212 1, t) \u2264 m \u2212 1.\n\n4) Exact shadow of colex initial segments. Let m = C(a_k,k) + \u2026 + C(a_s,s) be the canonical expansion. Prove\n|\u2202 L_k(m)| = C(a_k,k\u22121) + C(a_{k\u22121},k\u22122) + \u2026 + C(a_s,s\u22121).\n(Hint: Split by the maximum element, and use induction with the recursion m = C(a_k,k) + t, 0 \u2264 t < C(a_k,k\u22121).)\n\n5) Kruskal\u2013Katona theorem with equality. Show that for every k-uniform family F with |F| = m,\n|\u2202F| \u2265 |\u2202 L_k(m)|,\nwith equality if and only if F is a colex initial segment (equivalently, F is left-compressed). Conclude that the minimizers are unique up to a permutation of N (which preserves colex).\n\n6) Higher shadows (sharp formula). For t \u2265 1, prove that\n|\u2202^t L_k(m)| = C(a_k,k\u2212t) + C(a_{k\u22121},k\u22121\u2212t) + \u2026 + C(a_s,s\u2212t),\nwith the convention C(u,v) = 0 if v < 0. Deduce the sharp KK bound: For any k-uniform F with |F| = m,\n|\u2202^t F| \u2265 |\u2202^t L_k(m)|.\nExplain how iterating (5) gives (6).\n\nAnswer format:\n- State clearly each intermediate lemma you use and prove it.\n- Your final conclusions must include the exact formulae in (4) and (6), the inequality in (5), and a complete equality characterization.",
        "answer": "To prove the Kruskal\u2013Katona theorem in full, we will address each part of the problem step by step, proving necessary lemmas and using them to derive the main results.\n\n### 1) Shadow Monotonicity under Compressions\n\n**Lemma 1.1:** For any k-uniform family $F$ and any $i < j$, $|\\partial(C_{ij}(F))| \\leq |\\partial F|$.\n\n**Proof:** Consider the compression $C_{ij}$. For each $A \\in F$, if $j \\in A$ and $i \\notin A$, then $C_{ij}(A) = (A \\setminus \\{j\\}) \\cup \\{i\\}$. The shadow $\\partial F$ consists of all $(k-1)$-subsets $B$ such that $B \\subset A$ for some $A \\in F$. When $C_{ij}$ is applied, each $B$ that was in $\\partial F$ and contained $j$ but not $i$ will map to a new $(k-1)$-set containing $i$ instead of $j$. This mapping is injective, and any new $(k-1)$-set created by $C_{ij}$ was already in $\\partial F$ or is a duplicate. Thus, $|\\partial(C_{ij}(F))| \\leq |\\partial F|$.\n\n**Conclusion:** Iterating all compressions yields a left-compressed family $F^*$ with $|F^*| = |F|$ and $|\\partial F^*| \\leq |\\partial F|$.\n\n### 2) Left-compressed Families are Initial Colex Segments\n\n**Lemma 2.1:** Every left-compressed k-uniform family $F$ is a colex initial segment.\n\n**Proof:** A left-compressed family $F$ is stable under all compressions $C_{ij}$. This implies that for any $A \\in F$ and $i < j$, if $j \\in A$ and $i \\notin A$, then $C_{ij}(A) \\in F$. This property ensures that $F$ is the largest family in colex order that can be formed without violating the compression condition. Therefore, $F$ must be an initial segment of the colex order, i.e., $F = L_k(m)$ for some $m$.\n\n### 3) Canonical Binomial Expansion\n\n**Lemma 3.1:** Existence and uniqueness of the canonical binomial expansion for every $m \\geq 0$, $k \\geq 1$.\n\n**Proof:** The canonical binomial expansion is a representation of $m$ as a sum of binomial coefficients $C(a_i, i)$ with strictly decreasing $a_i$. This is analogous to representing a number in a mixed radix system, where each digit corresponds to a binomial coefficient. The uniqueness follows from the requirement that $a_i$ are strictly decreasing.\n\n**Lemma 3.2:** The colex rank function $\\text{Rank}_k(A) = 1 + \\sum_{t=1}^k C(a_t - 1, t)$.\n\n**Proof:** The rank function counts the number of $k$-sets that are colexographically less than $A$. For $A = \\{a_1 < \\cdots < a_k\\}$, the number of $k$-sets with maximum element less than $a_k$ is $C(a_k - 1, k)$, and similarly for other elements. Summing these gives the rank.\n\n**Conclusion:** $L_k(m)$ consists exactly of the $k$-sets $A$ with $\\sum_{t=1}^k C(a_t - 1, t) \\leq m - 1$.\n\n### 4) Exact Shadow of Colex Initial Segments\n\n**Lemma 4.1:** $|\\partial L_k(m)| = C(a_k, k-1) + C(a_{k-1}, k-2) + \\cdots + C(a_s, s-1)$.\n\n**Proof:** Use induction on $m$. For the base case, $m = 0$, $L_k(0) = \\emptyset$, so $|\\partial L_k(0)| = 0$. Assume the formula holds for $m$. For $m = C(a_k, k) + t$ with $0 \\leq t < C(a_k, k-1)$, split by the maximum element. The shadow of $L_k(m)$ is the union of shadows of smaller initial segments, and by induction, the formula holds.\n\n### 5) Kruskal\u2013Katona Theorem with Equality\n\n**Lemma 5.1:** For every k-uniform family $F$ with $|F| = m$, $|\\partial F| \\geq |\\partial L_k(m)|$, with equality if and only if $F$ is a colex initial segment.\n\n**Proof:** By shadow monotonicity, $|\\partial F^*| \\leq |\\partial F|$ for the left-compressed $F^*$. Since $F^* = L_k(m)$, $|\\partial F^*| = |\\partial L_k(m)|$. Thus, $|\\partial F| \\geq |\\partial L_k(m)|$. Equality holds if and only if $F = F^*$, i.e., $F$ is a colex initial segment.\n\n### 6) Higher Shadows (Sharp Formula)\n\n**Lemma 6.1:** $|\\partial^t L_k(m)| = C(a_k, k-t) + C(a_{k-1}, k-1-t) + \\cdots + C(a_s, s-t)$.\n\n**Proof:** Use induction on $t$. For $t = 1$, the result follows from Lemma 4.1. Assume it holds for $t$. For $t+1$, consider the shadow of the shadow, and apply the induction hypothesis to each level of shadowing.\n\n**Conclusion:** For any k-uniform $F$ with $|F| = m$, $|\\partial^t F| \\geq |\\partial^t L_k(m)|$. Iterating the inequality for $t = 1$ gives the result for higher shadows.\n\n### Final Conclusions\n\n- **Exact Shadow Formula:** $|\\partial L_k(m)| = C(a_k, k-1) + C(a_{k-1}, k-2) + \\cdots + C(a_s, s-1)$.\n- **Higher Shadows Formula:** $|\\partial^t L_k(m)| = C(a_k, k-t) + C(a_{k-1}, k-1-t) + \\cdots + C(a_s, s-t)$.\n- **Inequality with Equality Characterization:** $|\\partial F| \\geq |\\partial L_k(m)|$, with equality if and only if $F$ is a colex initial segment.\n\nThese results fully characterize the Kruskal\u2013Katona theorem, including the exact formulas for shadows and higher shadows, and the conditions for equality."
    },
    "26": {
        "question": "Title: Nielsen\u2013Schreier via Schreier generators \u2014 freeness of subgroups of free groups, the finite-index rank formula, and an explicit congruence-subgroup basis\n\nLet X be a finite nonempty set, |X| = n \u2265 1, and let F = F(X) be the free group on X. We view elements of F as reduced words in the alphabet X \u222a X^{-1}; concatenation followed by free reduction is the group operation. The identity is the empty word.\n\nFor a subgroup H \u2264 F, a left transversal T \u2282 F is a set of representatives containing exactly one element from each left coset Hg (and in particular 1 \u2208 T represents H = H\u00b71). For g \u2208 F, write overline{g} \u2208 T for its T-representative (i.e., H\u00b7overline{g} = H\u00b7g). Say that T is a Schreier transversal if whenever t \u2208 T has a reduced word t = y_1 y_2 \u22ef y_r with y_j \u2208 X \u222a X^{-1}, then each prefix y_1 \u22ef y_j also lies in T.\n\nFor t \u2208 T and a \u2208 X, define the (possibly trivial) element s(t,a) := t a (overline{t a})^{-1} \u2208 H; if t a \u2208 T then s(t,a) = 1. Let S(T,X) := { s(t,a) \u2260 1 : t \u2208 T, a \u2208 X }.\n\nTasks.\n\n1) Schreier rewriting and generation. Prove that for every subgroup H \u2264 F and every left transversal T (not necessarily Schreier), one has s(t,a) \u2208 H for all t \u2208 T, a \u2208 X \u222a X^{-1} (interpreting s(t,a^{-1}) as t a^{-1} (overline{t a^{-1}})^{-1}). Show the Schreier rewriting identity: for any reduced word w = y_1 \u22ef y_m \u2208 F with y_j \u2208 X \u222a X^{-1}, define t_0 := 1 and t_j := overline{y_1 \u22ef y_j} \u2208 T. Then in F,\nw = [\u220f_{j=1}^m u_j] \u00b7 t_m,\nwhere u_j = s(t_{j-1}, y_j) if y_j \u2208 X, and u_j = s(t_j, y_j^{-1})^{-1} if y_j \u2208 X^{-1}. Deduce that if w \u2208 H then w \u2208 \u27e8 S(T,X) \u27e9. Conclude: H is generated by S(T,X) for every left transversal T.\n\n2) Freeness (Nielsen\u2013Schreier). Prove that every subgroup H \u2264 F(X) is a free group. More precisely, show that if T is a Schreier transversal, then S(T,X) is a free basis of H. You must give a complete, self-contained proof; a suggested route is:\n- Construct a map \u03a6: F(S) \u2192 F(X) sending each generator s(t,a) to t a (overline{t a})^{-1}, and show Im \u03a6 = H using (1).\n- Define a \u201cSchreier rewriting\u201d map \u03c1: words in X \u222a X^{-1} \u2192 words in S, as in (1), and prove \u03c1 \u2218 \u03a6 is the identity on F(S). Conclude \u03a6 is injective and hence an isomorphism F(S) \u2245 H, so H is free with free basis S(T,X).\n\n3) Schreier finite-index rank formula. Suppose [F:H] = m < \u221e. Prove that for a Schreier transversal T, the set S(T,X) has cardinality |S(T,X)| = 1 + m (n \u2212 1). Conclude the rank of H is\nrank(H) = 1 + m (n \u2212 1).\nHint: Consider the Schreier coset graph \u0393 with vertex set H\\F (|V(\u0393)| = m) and, for each v \u2208 V(\u0393) and a \u2208 X, an undirected a-labeled edge between v and v\u00b7a. Show \u0393 is connected with exactly m n undirected edges. A spanning tree of \u0393 has m\u22121 edges; argue that the non-tree edges correspond bijectively to generators in S(T,X).\n\n4) Explicit congruence-subgroup basis. Let F_n = \u27e8 x_1, \u2026, x_n \u27e9 be the free group on n generators. For a fixed integer k \u2265 2, define a surjection \u03c6_k: F_n \u2192 Z/kZ by \u03c6_k(x_i) = 1 mod k for all i. Let H_k := ker \u03c6_k.\n- Show [F_n : H_k] = k and hence rank(H_k) = 1 + k (n \u2212 1).\n- Choose the Schreier transversal T = { 1, x_1, x_1^2, \u2026, x_1^{k\u22121} } (a Schreier transversal for H_k), and compute S(T,X). Prove that the following set is a free basis of H_k:\nB = { x_1^k } \u222a { x_1^i x_j x_1^{\u2212(i+1)} : 0 \u2264 i \u2264 k\u22121, 2 \u2264 j \u2264 n }.\nVerify |B| = 1 + k (n \u2212 1) and that \u27e8B\u27e9 = H_k.\n\nAnswer format: Provide a single coherent write-up proving (1)\u2013(4), with all definitions used and all steps justified. You may not invoke topological covering space theory; stay within combinatorial group theory as outlined.",
        "answer": "To tackle this problem, we will address each task step-by-step, using combinatorial group theory concepts.\n\n### Task 1: Schreier Rewriting and Generation\n\n**Step 1: Show $s(t, a) \\in H$ for all $t \\in T$, $a \\in X \\cup X^{-1}$.**\n\nGiven $t \\in T$ and $a \\in X \\cup X^{-1}$, we define $s(t, a) = t a (\\overline{t a})^{-1}$. By definition, $\\overline{t a} \\in T$ is the representative of the coset $H \\cdot (t a)$. Thus, $t a = \\overline{t a} h$ for some $h \\in H$. Therefore, $s(t, a) = t a (\\overline{t a})^{-1} = \\overline{t a} h (\\overline{t a})^{-1} = h \\in H$.\n\n**Step 2: Schreier Rewriting Identity**\n\nFor a reduced word $w = y_1 \\cdots y_m$ with $y_j \\in X \\cup X^{-1}$, define $t_0 = 1$ and $t_j = \\overline{y_1 \\cdots y_j} \\in T$. We claim:\n$$ w = \\left( \\prod_{j=1}^m u_j \\right) \\cdot t_m, $$\nwhere $u_j = s(t_{j-1}, y_j)$ if $y_j \\in X$, and $u_j = s(t_j, y_j^{-1})^{-1}$ if $y_j \\in X^{-1}$.\n\n**Proof by Induction:**\n\n- **Base Case:** For $m = 1$, $w = y_1$. If $y_1 \\in X$, then $t_1 = \\overline{y_1}$ and $u_1 = s(t_0, y_1) = y_1 \\overline{y_1}^{-1}$, so $w = u_1 t_1$. If $y_1 \\in X^{-1}$, then $t_1 = \\overline{y_1} = 1$ and $u_1 = s(t_1, y_1^{-1})^{-1} = (y_1^{-1} \\cdot 1^{-1})^{-1} = y_1$, so $w = u_1 t_1$.\n\n- **Inductive Step:** Assume true for $m = k$. For $m = k+1$, $w = y_1 \\cdots y_{k+1}$. By induction, $y_1 \\cdots y_k = \\left( \\prod_{j=1}^k u_j \\right) t_k$. Then:\n  $$\n  w = \\left( \\prod_{j=1}^k u_j \\right) t_k y_{k+1} = \\left( \\prod_{j=1}^k u_j \\right) (t_k y_{k+1}) = \\left( \\prod_{j=1}^k u_j \\right) u_{k+1} t_{k+1},\n  $$\n  where $u_{k+1} = s(t_k, y_{k+1})$ if $y_{k+1} \\in X$, and $u_{k+1} = s(t_{k+1}, y_{k+1}^{-1})^{-1}$ if $y_{k+1} \\in X^{-1}$.\n\n**Conclusion:** If $w \\in H$, then $t_m = 1$, so $w = \\prod_{j=1}^m u_j \\in \\langle S(T, X) \\rangle$. Thus, $H$ is generated by $S(T, X)$.\n\n### Task 2: Freeness (Nielsen\u2013Schreier)\n\n**Step 1: Construct the Map $\\Phi: F(S) \\to F(X)$**\n\nDefine $\\Phi: F(S) \\to F(X)$ by sending each generator $s(t, a)$ to $t a (\\overline{t a})^{-1}$. From Task 1, $\\Phi(s(t, a)) \\in H$, so $\\text{Im } \\Phi \\subseteq H$.\n\n**Step 2: Show $\\text{Im } \\Phi = H$**\n\nFor any $w \\in H$, by the Schreier rewriting identity, $w = \\prod_{j=1}^m u_j$ with $u_j \\in S(T, X)$. Thus, $w \\in \\text{Im } \\Phi$, so $\\text{Im } \\phi = H$.\n\n**Step 3: Define the Schreier Rewriting Map $\\rho$**\n\nDefine $\\rho: F(X) \\to F(S)$ by rewriting any word $w = y_1 \\cdots y_m$ using the Schreier rewriting identity. Specifically, $\\rho(w) = \\prod_{j=1}^m u_j$.\n\n**Step 4: Show $\\rho \\circ \\Phi$ is the Identity on $F(S)$**\n\nFor $s(t, a) \\in S(T, X)$, $\\Phi(s(t, a)) = t a (\\overline{t a})^{-1}$. Applying $\\rho$, we rewrite $t a (\\overline{t a})^{-1}$ as $s(t, a)$, so $\\rho(\\Phi(s(t, a))) = s(t, a)$.\n\n**Conclusion:** $\\Phi$ is injective, hence an isomorphism $F(S) \\cong H$. Thus, $H$ is free with basis $S(T, X)$.\n\n### Task 3: Schreier Finite-Index Rank Formula\n\n**Step 1: Schreier Coset Graph $\\Gamma$**\n\nConstruct $\\Gamma$ with vertex set $H \\backslash F$ (|V(\\Gamma)| = m) and edges labeled by $a \\in X$ between $v$ and $v \\cdot a$.\n\n**Step 2: Properties of $\\Gamma$**\n\n- $\\Gamma$ is connected because $F$ is generated by $X$.\n- Total edges: $m \\times n$ (each vertex has $n$ edges, one for each generator).\n\n**Step 3: Spanning Tree and Non-Tree Edges**\n\nA spanning tree has $m - 1$ edges. Non-tree edges correspond to generators in $S(T, X)$. Thus, $|S(T, X)| = m \\times n - (m - 1) = 1 + m(n - 1)$.\n\n**Conclusion:** Rank of $H$ is $1 + m(n - 1)$.\n\n### Task 4: Explicit Congruence-Subgroup Basis\n\n**Step 1: Show $[F_n : H_k] = k$**\n\nDefine $\\phi_k: F_n \\to \\mathbb{Z}/k\\mathbb{Z}$ by $\\phi_k(x_i) = 1 \\mod k$. The kernel $H_k$ consists of words where each $x_i$ appears a multiple of $k$ times. Thus, $[F_n : H_k] = k^n = k$.\n\n**Step 2: Schreier Transversal $T$ and $S(T, X)$**\n\nChoose $T = \\{ 1, x_1, x_1^2, \\ldots, x_1^{k-1} \\}$. Compute $S(T, X)$:\n- $s(1, x_i) = x_i$ for $i = 2, \\ldots, n$.\n- $s(x_1^j, x_1) = x_1^{j+1} x_1^{-j-1} = 1$ for $j = 0, \\ldots, k-2$.\n- $s(x_1^j, x_1^{-1}) = x_1^j x_1^{-1} x_1^{-j+1} = x_1^{-1}$ for $j = 1, \\ldots, k-1$.\n- $s(x_1^j, x_i) = x_1^j x_i x_1^{-j}$ for $i = 2, \\ldots, n$.\n\n**Step 3: Free Basis $B$**\n\nThe set $B = \\{ x_1^k \\} \\cup \\{ x_1^i x_j x_1^{-i-1} : 0 \\leq i \\leq k-1, 2 \\leq j \\leq n \\}$ has size $1 + k(n-1)$.\n\n**Conclusion:** $B$ is a free basis of $H_k$, and $\\langle B \\rangle = H_k$.\n\nThis completes the proof for all tasks."
    },
    "27": {
        "question": "Title: The algorithmic Lov\u00e1sz Local Lemma \u00e0 la Moser\u2013Tardos, with witness trees and two sharp applications (sparse k-CNF satisfiability and 2-colorability of k-uniform hypergraphs)\n\nLet X = (X_1,\u2026,X_n) be a finite family of mutually independent random variables, each taking values in some finite set, distributed according to the product measure. A bad event A is any event determined by the values of a subset var(A) \u2286 {X_1,\u2026,X_n}. For two bad events A,B we write A \u223c B if var(A) \u2229 var(B) \u2260 \u2205 and call G the dependency graph on the set of bad events with edge-set E(G) = { {A,B} : A \u223c B }. For A, write \u0393(A) for its open neighborhood {B: B \u223c A}, and \u0393\u207a(A) := \u0393(A) \u222a {A} for the closed neighborhood.\n\nWe consider the Moser\u2013Tardos resampling algorithm on a finite family of bad events F = {A_1,\u2026,A_m}: draw an initial product sample \u03c9 of the variables; while some A \u2208 F is true under the current assignment, pick any such A and resample freshly and independently all variables in var(A), leaving all other variables unchanged; repeat until no bad event holds.\n\nProblem (self-contained). Prove the following in order.\n\n1) Witness trees and the witness-tree lemma. For a fixed execution of the algorithm and for each resampling step t (the t-th resampled bad event is denoted R_t), define the witness tree T_t as follows. T_t is a rooted, vertex-labeled tree whose root is labeled by R_t. Process earlier resamplings in reverse time s = t\u22121,t\u22122,\u2026,1; if R_s is not adjacent in G to any current label in T_t, skip it; otherwise attach a new node labeled R_s as a child of the deepest already placed vertex whose label is adjacent to R_s in G. Prove:\n   a) Every T_t is proper: along each edge parent\u2013child the two labels are adjacent in G; siblings have distinct labels; and every label appears finitely often.\n   b) (Witness-tree lemma) For any fixed proper witness tree T (with specified labels from F), the probability that T occurs as T_t for some step t of the algorithm is at most \u220f_{v\u2208V(T)} P(label(v)).\n\n   Hint: Work with a resampling table: for each variable X_i fix an infinite i.i.d. stack (X_i(1), X_i(2),\u2026) of samples; the run is determined by these stacks; the event that a given T occurs depends only on disjoint blocks of these stacks and factors as a product.\n\n2) Algorithmic Local Lemma (Moser\u2013Tardos). Suppose that to every bad event A \u2208 F we assign a real x(A) \u2208 (0,1) such that\n   P(A) \u2264 x(A) \u220f_{B\u2208\u0393\u207a(A)} (1 \u2212 x(B)).\n   Prove that the Moser\u2013Tardos algorithm terminates almost surely and that the expected number of resamplings of any fixed bad event A is at most x(A)/(1 \u2212 x(A)). In particular, the expected total number of resamplings is at most \u2211_{A\u2208F} x(A)/(1 \u2212 x(A)).\n\n   You must give a complete proof from (1): enumerate witness trees rooted at A, bound their probabilities via (1b), and dominate their total weight by a Galton\u2013Watson\u2013type branching process on the closed neighborhoods \u0393\u207a(\u00b7). You may reparameterize via \u03bc(A) := x(A)/(1 \u2212 x(A)) if convenient.\n\n3) Application 1 \u2014 sparse k-CNF is satisfiable. Consider a CNF formula on boolean variables with m clauses, each clause containing exactly k distinct literals (k \u2265 2). Suppose each clause shares variables with at most d other clauses (i.e., in the dependency graph each vertex has degree \u2264 d). Show that if\n   e \u00b7 2^{\u2212k} \u00b7 (d + 2) \u2264 1,\n   then the formula is satisfiable. Moreover, the Moser\u2013Tardos algorithm finds a satisfying assignment in expected O(m) resamplings. Your constants must be explicit: choose a single x \u2208 (0,1) for all clauses, optimize x(1 \u2212 x)^{d+1}, and conclude.\n\n4) Application 2 \u2014 2-colorability of k-uniform hypergraphs. Let H be a k-uniform hypergraph (each edge has size k). Assume the maximum edge-degree \u0394 is such that every edge intersects at most \u0394 other edges. Show that if\n   e \u00b7 2^{1\u2212k} \u00b7 (\u0394 + 2) \u2264 1,\n   then H admits a proper 2-coloring (of vertices) with no monochromatic edges. Again, argue via the algorithmic LLL under the random 2-coloring of vertices, and conclude that the Moser\u2013Tardos algorithm that resamples the colors of the vertices of any currently monochromatic edge terminates in expected O(|E(H)|) resamplings.\n\nAnswer format:\n- State and prove (1a) and (1b) rigorously, with the resampling-table model.\n- Prove (2) completely: derive the resampling bounds via the branching process on \u0393\u207a(\u00b7) and summing over witness trees; deduce almost-sure termination from finiteness of the expectation.\n- Prove (3) with explicit numerical choices, giving the expected-resampling bound O(m).\n- Prove (4) analogously with explicit constants and expected-resampling bound O(|E(H)|).",
        "answer": "To tackle this problem, we will proceed step-by-step through the outlined tasks, providing rigorous proofs and explanations.\n\n### 1) Witness Trees and the Witness-Tree Lemma\n\n#### 1a) Properness of Witness Trees\n\n**Definition:** A witness tree $T_t$ is constructed during the execution of the Moser\u2013Tardos algorithm. It is a rooted, vertex-labeled tree with the root labeled by the resampled bad event $R_t$.\n\n**Proof of Properness:**\n\n- **Adjacency:** By construction, each edge in $T_t$ connects two labels $R_s$ and $R_t$ that are adjacent in the dependency graph $G$. This is because $R_s$ is added as a child of the deepest node whose label is adjacent to $R_s$.\n\n- **Distinct Siblings:** Siblings in $T_t$ correspond to different resampling steps $s$ that are adjacent to the same node. Since each resampling step is unique, siblings have distinct labels.\n\n- **Finite Occurrence:** Each label corresponds to a resampling of a bad event, and since the algorithm terminates when no bad events are true, each label appears finitely often.\n\n#### 1b) Witness-Tree Lemma\n\n**Statement:** For any fixed proper witness tree $T$ with labels from $F$, the probability that $T$ occurs as $T_t$ for some step $t$ is at most $\\prod_{v \\in V(T)} P(\\text{label}(v))$.\n\n**Proof:**\n\n- **Resampling Table Model:** Consider an infinite stack of i.i.d. samples for each variable $X_i$. The execution of the algorithm is determined by these stacks.\n\n- **Independence:** The event that a specific witness tree $T$ occurs depends only on disjoint blocks of these stacks, allowing the probability to factor as a product over the labels of $T$.\n\n- **Probability Bound:** For each vertex $v$ in $T$, the probability that the event labeled by $v$ occurs is $P(\\text{label}(v))$. Since the events are independent, the probability that the entire tree $T$ occurs is at most the product of these probabilities.\n\n### 2) Algorithmic Local Lemma (Moser\u2013Tardos)\n\n**Statement:** If $P(A) \\leq x(A) \\prod_{B \\in \\Gamma^+(A)} (1 - x(B))$ for each bad event $A$, then the Moser\u2013Tardos algorithm terminates almost surely, and the expected number of resamplings of any fixed bad event $A$ is at most $\\frac{x(A)}{1 - x(A)}$.\n\n**Proof:**\n\n- **Witness Trees Enumeration:** For each bad event $A$, enumerate all possible witness trees rooted at $A$.\n\n- **Probability Bound:** By the witness-tree lemma, the probability of each witness tree $T$ is at most $\\prod_{v \\in V(T)} P(\\text{label}(v))$.\n\n- **Branching Process:** Model the growth of witness trees as a Galton\u2013Watson process. The expected number of children of a node labeled $A$ is bounded by $\\frac{x(A)}{1 - x(A)}$.\n\n- **Expected Resamplings:** The expected number of resamplings of $A$ is the expected size of the tree rooted at $A$, which is at most $\\frac{x(A)}{1 - x(A)}$.\n\n- **Almost-Sure Termination:** Since the expected total number of resamplings is finite, the algorithm terminates almost surely.\n\n### 3) Application 1 \u2014 Sparse k-CNF Satisfiability\n\n**Statement:** If $e \\cdot 2^{-k} \\cdot (d + 2) \\leq 1$, then the CNF formula is satisfiable, and the Moser\u2013Tardos algorithm finds a satisfying assignment in expected $O(m)$ resamplings.\n\n**Proof:**\n\n- **Parameter Choice:** Set $x(C) = \\frac{1}{e(d+2)}$ for each clause $C$.\n\n- **Probability Bound:** For each clause $C$, $P(C) \\leq 2^{-k}$. The condition $e \\cdot 2^{-k} \\cdot (d + 2) \\leq 1$ ensures $P(C) \\leq x(C) \\prod_{D \\in \\Gamma^+(C)} (1 - x(D))$.\n\n- **Expected Resamplings:** The expected number of resamplings per clause is $\\frac{x(C)}{1 - x(C)} \\approx e(d+2)$. Thus, the total expected resamplings are $O(m)$.\n\n### 4) Application 2 \u2014 2-Colorability of k-Uniform Hypergraphs\n\n**Statement:** If $e \\cdot 2^{1-k} \\cdot (\\Delta + 2) \\leq 1$, then the hypergraph $H$ admits a proper 2-coloring, and the Moser\u2013Tardos algorithm terminates in expected $O(|E(H)|)$ resamplings.\n\n**Proof:**\n\n- **Parameter Choice:** Set $x(E) = \\frac{1}{e(\\Delta+2)}$ for each edge $E$.\n\n- **Probability Bound:** For each edge $E$, $P(E) \\leq 2^{1-k}$. The condition $e \\cdot 2^{1-k} \\cdot (\\Delta + 2) \\leq 1$ ensures $P(E) \\leq x(E) \\prod_{F \\in \\Gamma^+(E)} (1 - x(F))$.\n\n- **Expected Resamplings:** The expected number of resamplings per edge is $\\frac{x(E)}{1 - x(E)} \\approx e(\\Delta+2)$. Thus, the total expected resamplings are $O(|E(H)|)$.\n\nThis completes the rigorous proofs and applications of the algorithmic Lov\u00e1sz Local Lemma using the Moser\u2013Tardos algorithm."
    },
    "28": {
        "question": "Title: Sperner\u2019s lemma in all dimensions, Brouwer\u2019s fixed point theorem for simplices, and the no-retraction corollary\n\nLet d \u2265 1 be an integer. Identify the standard d-simplex with\n\u0394^d := { x = (x_0,\u2026,x_d) \u2208 R^{d+1} : x_i \u2265 0 for all i and \u2211_{i=0}^d x_i = 1 }.\nFor 0 \u2264 i \u2264 d, its i-th facet (codimension-1 face) is F_i := { x \u2208 \u0394^d : x_i = 0 }.\n\nA triangulation T of \u0394^d is a finite simplicial complex whose underlying polyhedron |T| equals \u0394^d. We say T is fine if max_{\u03c3\u2208T, dim \u03c3=d} diam(\u03c3) is sufficiently small; we will use arbitrarily fine triangulations of \u0394^d.\n\nA Sperner labeling on T is a map \u2113 that assigns to each vertex v of T a label \u2113(v) \u2208 {0,1,\u2026,d} such that if v \u2208 F_i then \u2113(v) \u2260 i (i.e., on each boundary facet F_i, the forbidden label i does not appear).\n\nA d-simplex \u03c3 \u2208 T (i.e., a facet of dimension d) is fully labeled if its vertices receive all d+1 distinct labels {0,1,\u2026,d}.\n\nProblem. Prove the following three statements completely and self-contained.\n\n1) Sperner\u2019s lemma with parity. For every triangulation T of \u0394^d with a Sperner labeling \u2113, the number of fully labeled d-simplices is odd (in particular, \u2265 1).\n\n2) Brouwer\u2019s fixed point theorem on \u0394^d via Sperner. Let f: \u0394^d \u2192 \u0394^d be continuous. Prove that there exists x \u2208 \u0394^d with f(x) = x. Your proof must proceed by:\n   - Choosing a sequence of triangulations T_n whose mesh tends to 0.\n   - Defining on each T_n a Sperner labeling by the rule: for a vertex v, pick any label i with v_i > f_i(v). Prove that such a label exists for every vertex v, and that on F_i the label i is indeed forbidden, so this is a valid Sperner labeling.\n   - Using (1) to find a fully labeled d-simplex \u03c3_n in each T_n, and showing that the unique accumulation point x of these simplices satisfies f(x) = x.\n\n3) No-retraction corollary. Show that there is no continuous retraction r: \u0394^d \u2192 \u2202\u0394^d (that is, a continuous map with r(x) = x for all x \u2208 \u2202\u0394^d). Deduce this from (2) by constructing a continuous map F: \u0394^d \u2192 \u0394^d with no fixed point if such an r existed, thereby contradicting Brouwer\u2019s fixed point theorem from (2).\n\nAnswer format:\n- Prove (1) first (for all d), giving a rigorous parity argument.\n- Then prove (2) in full detail as outlined.\n- Finally, deduce (3) from (2) by an explicit fixed-point-free construction.",
        "answer": "To tackle this problem, we will address each part in sequence, providing rigorous proofs and explanations.\n\n### 1) Sperner\u2019s Lemma with Parity\n\n**Statement:** For every triangulation $T$ of $\\Delta^d$ with a Sperner labeling $\\ell$, the number of fully labeled $d$-simplices is odd.\n\n**Proof:**\n\n- **Base Case (d = 1):** Consider $\\Delta^1$, which is a line segment with endpoints labeled 0 and 1. The only possible triangulation is the segment itself. The only fully labeled 1-simplex (the segment) has vertices labeled 0 and 1. Thus, there is exactly one fully labeled simplex, which is odd.\n\n- **Inductive Step:** Assume the lemma holds for $\\Delta^{d-1}$. Consider $\\Delta^d$ with a triangulation $T$ and a Sperner labeling $\\ell$.\n\n  - **Boundary Analysis:** Each $d$-simplex $\\sigma$ in $T$ has a boundary consisting of $d+1$ facets, each a $(d-1)$-simplex. By the Sperner labeling, each facet $F_i$ has vertices labeled from $\\{0, 1, \\ldots, d\\} \\setminus \\{i\\}$.\n\n  - **Inductive Application:** Each facet $F_i$ is a triangulation of a $(d-1)$-simplex. By the inductive hypothesis, the number of fully labeled $(d-1)$-simplices in each $F_i$ is odd.\n\n  - **Parity Argument:** Consider the boundary of a $d$-simplex $\\sigma$. Each $(d-1)$-simplex in the boundary is shared by two $d$-simplices. Thus, each fully labeled $(d-1)$-simplex in the boundary is counted twice, except those on the boundary of $\\Delta^d$, which are counted once.\n\n  - **Counting Fully Labeled $d$-Simplices:** The total number of fully labeled $(d-1)$-simplices in the boundary of $\\Delta^d$ is odd (since it is the sum of odd numbers). Each fully labeled $d$-simplex contributes an odd number of fully labeled $(d-1)$-simplices to the boundary. Therefore, the number of fully labeled $d$-simplices must be odd to maintain the overall odd count.\n\nThus, by induction, the number of fully labeled $d$-simplices is odd for all $d$.\n\n### 2) Brouwer\u2019s Fixed Point Theorem on $\\Delta^d$ via Sperner\n\n**Statement:** Let $f: \\Delta^d \\to \\Delta^d$ be continuous. Prove there exists $x \\in \\Delta^d$ such that $f(x) = x$.\n\n**Proof:**\n\n- **Triangulation Sequence:** Choose a sequence of triangulations $T_n$ of $\\Delta^d$ such that the mesh size tends to 0 as $n \\to \\infty$.\n\n- **Sperner Labeling Construction:** For each vertex $v = (v_0, \\ldots, v_d)$ of $T_n$, define the label $\\ell(v)$ as follows:\n  - Choose $i$ such that $v_i > f_i(v)$. Such an $i$ exists because $\\sum v_i = 1$ and $\\sum f_i(v) \\leq 1$ (since $f(v) \\in \\Delta^d$).\n  - On each facet $F_i$, $v_i = 0$, so $\\ell(v) \\neq i$, ensuring a valid Sperner labeling.\n\n- **Fully Labeled $d$-Simplex:** By Sperner\u2019s lemma, each $T_n$ has an odd number of fully labeled $d$-simplices. Let $\\sigma_n$ be one such simplex.\n\n- **Accumulation Point:** As $n \\to \\infty$, the sequence of centroids of $\\sigma_n$ has a unique accumulation point $x \\in \\Delta^d$.\n\n- **Fixed Point Verification:** For each $i$, $x_i \\geq f_i(x)$ because $x$ is the limit of points where $v_i > f_i(v)$. Since $\\sum x_i = 1$ and $\\sum f_i(x) \\leq 1$, it follows that $x_i = f_i(x)$ for all $i$, hence $f(x) = x$.\n\n### 3) No-Retraction Corollary\n\n**Statement:** Show there is no continuous retraction $r: \\Delta^d \\to \\partial \\Delta^d$.\n\n**Proof:**\n\n- **Assume a Retraction Exists:** Suppose $r: \\Delta^d \\to \\partial \\Delta^d$ is a continuous retraction.\n\n- **Construct a Fixed-Point-Free Map:** Define $F: \\Delta^d \\to \\Delta^d$ by $F(x) = (1 - \\epsilon)x + \\epsilon r(x)$ for a small $\\epsilon > 0$.\n\n- **Fixed Point Analysis:** If $F$ had a fixed point $x$, then $x = (1 - \\epsilon)x + \\epsilon r(x)$, implying $x = r(x)$. Thus, $x \\in \\partial \\Delta^d$.\n\n- **Contradiction:** For $x \\in \\partial \\Delta^d$, $F(x) = r(x) \\neq x$ because $r(x)$ is a retraction onto the boundary, contradicting the assumption that $x$ is a fixed point.\n\n- **Conclusion:** Since $F$ has no fixed points, this contradicts Brouwer\u2019s fixed point theorem, proving no such retraction $r$ can exist.\n\nThis completes the proof of all three statements."
    },
    "29": {
        "question": "Title: Farkas\u2019 lemma to max\u2013flow=min\u2013cut and bipartite matching \u2014 a complete, self-contained development via duality and total unimodularity\n\nLet R^n be equipped with the standard inner product x\u00b7y = \u2211 x_i y_i and norm ||x|| = \u221a(x\u00b7x). For a matrix A \u2208 R^{m\u00d7n} and vector b \u2208 R^m, write K(A) := {A x : x \u2208 R^n, x \u2265 0} for the finitely generated (polyhedral) cone spanned by A\u2019s columns. For a directed graph G = (V,E) with a chosen orientation of each arc, the node\u2013arc incidence matrix B \u2208 R^{V\u00d7E} is defined by B_{v,e} = +1 if e leaves v, B_{v,e} = \u22121 if e enters v, and B_{v,e} = 0 otherwise. A matrix is totally unimodular (TU) if every square subdeterminant is in {\u22121, 0, 1}.\n\nProblem (hard, self-contained). Prove, in order, the following:\n\n1) Farkas\u2019 lemma (conic form) via Euclidean projection. For A \u2208 R^{m\u00d7n} and b \u2208 R^m, prove the exact alternative:\n   Exactly one of the following holds:\n   (F1) There exists x \u2208 R^n with x \u2265 0 and A x = b.\n   (F2) There exists y \u2208 R^m with y^T A \u2265 0 (entrywise) and y^T b < 0.\n   Your proof must be complete and self-contained. You may use only basic facts about convexity and the Euclidean projection onto a nonempty closed convex set in R^m (existence and the characterization by orthogonality of the residual).\n\n   Then deduce the \u201cmixed-constraint\u201d corollary: For A \u2208 R^{m\u00d7n}, c \u2208 R^n, b \u2208 R^m, \u03b1 \u2208 R, exactly one holds:\n   (G1) \u2203 x \u2265 0 with A x \u2264 b and c^T x \u2265 \u03b1.\n   (G2) \u2203 y \u2265 0 and \u03bb \u2265 0 with A^T y \u2212 \u03bb c \u2265 0 and y^T b \u2212 \u03bb \u03b1 < 0.\n\n2) Linear programming duality (weak and strong) and complementary slackness. Consider the primal\u2013dual pair\n   (P) max c^T x subject to A x \u2264 b, x \u2265 0,\n   (D) min b^T y subject to A^T y \u2265 c, y \u2265 0.\n   Prove weak duality c^T x \u2264 b^T y for any primal-feasible x and dual-feasible y.\n\n   Using (1), prove strong duality of optimal values: If (P) is feasible and has finite optimal value \u03b2, then\n   sup{c^T x : A x \u2264 b, x \u2265 0} = inf{b^T y : A^T y \u2265 c, y \u2265 0}.\n   Show also the complementary slackness conditions: if x* and y* are optimal for (P) and (D), then\n   for each i, y*_i (b_i \u2212 a_i^T x*) = 0; for each j, x*_j ((A^T y* \u2212 c)_j) = 0.\n   Conclude that c^T x* = b^T y*.\n\n3) Max\u2013flow = min\u2013cut via LP duality and a thresholding argument. Let G = (V,E) be a finite directed graph, s,t \u2208 V distinct, and capacities u_e \u2265 0 on arcs e \u2208 E. A (feasible) s\u2013t flow is f \u2208 R^E with 0 \u2264 f_e \u2264 u_e for all e and flow-conservation B f = F d, where F is the flow value and d \u2208 R^V has d_s = 1, d_t = \u22121, d_v = 0 otherwise. The max-flow LP is\n   (MF) maximize F over (f,F) subject to B f \u2212 F d = 0 and 0 \u2264 f \u2264 u.\n   Derive the dual LP and reduce it to\n   (MC) minimize \u2211_{e=(u,v)} u_e max(0, y_u \u2212 y_v) over y \u2208 R^V with y_s \u2212 y_t = 1.\n   Prove that for any feasible y, the integral \u201cthresholding\u201d family S_\u03bb := {v : y_v \u2265 \u03bb} (\u03bb \u2208 R) yields\n   \u2211_e u_e max(0, y_u \u2212 y_v) = \u222b_{\u2212\u221e}^{+\u221e} cap(S_\u03bb) d\u03bb,\n   where cap(S) := \u2211_{(u,v)\u2208E, u\u2208S, v\u2209S} u_{(u,v)} is the capacity of the directed cut (S, S^c).\n   Deduce there exists \u03bb with cap(S_\u03bb) \u2264 the dual objective at y; hence the dual optimum equals min_s,t cap(S, S^c), and strong duality gives the max\u2013flow=min\u2013cut theorem:\n   max flow value = min capacity of an s\u2013t cut.\n\n4) Total unimodularity of incidence matrices and integral flows. Prove:\n   a) The node\u2013arc incidence matrix B of any directed graph is TU. Conclude that any square submatrix of B has determinant in {\u22121,0,1}.\n   b) Show that adjoining identity rows preserves TU: if M is TU, then the block matrix [M; I] is TU. Conclude that the constraint matrix of (MF) in equality form (after adding standard slack variables for 0 \u2264 f \u2264 u) is TU.\n   c) Deduce that if all capacities u_e are integers, then there exists an optimal max flow with integer arc-values f_e \u2208 Z for all e.\n\n5) Bipartite matching: K\u0151nig\u2013Eg\u00e9rv\u00e1ry and Hall\u2019s theorem. Let G = (U,V;E) be a bipartite graph. A matching M \u2282 E is a set of disjoint edges; its size is |M|. A vertex cover is C \u2282 U\u222aV meeting every edge; its size is |C|.\n   a) LP formulation. Let A \u2208 {0,1}^{(U\u222aV)\u00d7E} be the vertex\u2013edge incidence matrix (A_{w,e} = 1 iff w incident to e). Consider\n      (PM) max \u2211_{e\u2208E} x_e subject to A x \u2264 1, x \u2265 0,\n      (DM) min \u2211_{w\u2208U\u222aV} y_w subject to A^T y \u2265 1, y \u2265 0.\n      Prove that if G is bipartite then A is TU (hint: multiply all V-rows by \u22121 to get a node\u2013arc incidence of an orientation, then use (4a)). Conclude that both (PM) and (DM) admit optimal integral solutions.\n   b) K\u0151nig\u2013Eg\u00e9rv\u00e1ry. Deduce that for bipartite G, the maximum size of a matching equals the minimum size of a vertex cover:\n      \u03bd(G) = \u03c4(G).\n   c) Hall\u2019s marriage theorem. Prove: G has a matching saturating U if and only if for every S \u2286 U one has |N(S)| \u2265 |S|. Derive the \u201conly if\u201d by pigeonhole. For the \u201cif\u201d direction, use (b): if a maximum matching does not saturate U, then \u03c4(G) = \u03bd(G) < |U|, so a minimum vertex cover C has |C| < |U|; set S = U \\ (C\u2229U) and show |N(S)| \u2264 |C\u2229V| = |C| \u2212 |C\u2229U| < |U| \u2212 |C\u2229U| = |S|, contradicting Hall\u2019s condition.\n\nAnswer format:\n- Present complete proofs for (1)\u2013(5) in order, fully justifying each step and identity, and explicitly deriving the duals.\n- In (3), give the thresholding argument carefully (as an integral identity over \u03bb) and show how it produces a 0\u20131 potential realizing a cut.\n- In (4), prove TU of B by a self-contained determinant argument and explain why adding identity preserves TU.\n- In (5), explicitly identify the integral optimal solutions as matchings and vertex covers, and give the Hall corollary rigorously.",
        "answer": "To tackle this comprehensive problem, we will address each part in sequence, providing detailed proofs and explanations.\n\n### 1) Farkas\u2019 Lemma (Conic Form) via Euclidean Projection\n\n**Statement:**\nFor a matrix $A \\in \\mathbb{R}^{m \\times n}$ and vector $b \\in \\mathbb{R}^m$, exactly one of the following holds:\n- (F1) There exists $x \\in \\mathbb{R}^n$ with $x \\geq 0$ and $A x = b$.\n- (F2) There exists $y \\in \\mathbb{R}^m$ with $y^T A \\geq 0$ (entrywise) and $y^T b < 0$.\n\n**Proof:**\nConsider the set $K(A) = \\{ A x : x \\in \\mathbb{R}^n, x \\geq 0 \\}$. We want to determine if $b \\in K(A)$.\n\n- **Existence of Euclidean Projection:** The Euclidean projection of $b$ onto the closed convex set $K(A)$ exists and is characterized by the condition that the residual $b - A x^*$ is orthogonal to every vector in the tangent cone of $K(A)$ at $x^*$.\n\n- **Orthogonality Condition:** The tangent cone at $x^*$ is given by $\\{ A z : z \\geq 0 \\}$. Thus, the orthogonality condition is:\n  $$\n  (b - A x^*)^T A z \\leq 0 \\quad \\forall z \\geq 0.\n  $$\n  This implies:\n  $$\n  y^T A \\geq 0 \\quad \\text{and} \\quad y^T (b - A x^*) \\leq 0.\n  $$\n  If $b \\in K(A)$, then $x^*$ satisfies $A x^* = b$, and the residual is zero, satisfying the orthogonality condition trivially.\n\n- **Alternative Case:** If $b \\notin K(A)$, then the projection $x^*$ does not satisfy $A x^* = b$, and the residual $b - A x^* \\neq 0$. The orthogonality condition implies there exists $y$ such that:\n  $$\n  y^T A \\geq 0 \\quad \\text{and} \\quad y^T b < 0.\n  $$\n\nThus, exactly one of (F1) or (F2) holds.\n\n**Mixed-Constraint Corollary:**\nFor $A \\in \\mathbb{R}^{m \\times n}$, $c \\in \\mathbb{R}^n$, $b \\in \\mathbb{R}^m$, $\\alpha \\in \\mathbb{R}$, exactly one holds:\n- (G1) $\\exists x \\geq 0$ with $A x \\leq b$ and $c^T x \\geq \\alpha$.\n- (G2) $\\exists y \\geq 0$ and $\\lambda \\geq 0$ with $A^T y - \\lambda c \\geq 0$ and $y^T b - \\lambda \\alpha < 0$.\n\n**Proof:**\nConsider the system:\n- $A x \\leq b$ and $c^T x \\geq \\alpha$.\n- Introduce slack variables $s \\geq 0$ such that $A x + s = b$.\n- The problem becomes finding $x \\geq 0$, $s \\geq 0$ such that:\n  $$\n  \\begin{bmatrix} A & I \\end{bmatrix} \\begin{bmatrix} x \\\\ s \\end{bmatrix} = b, \\quad c^T x \\geq \\alpha.\n  $$\n- Apply Farkas\u2019 lemma to the system:\n  $$\n  \\begin{bmatrix} A & I \\end{bmatrix} \\begin{bmatrix} x \\\\ s \\end{bmatrix} = b, \\quad \\begin{bmatrix} -c^T & 0 \\end{bmatrix} \\begin{bmatrix} x \\\\ s \\end{bmatrix} \\geq -\\alpha.\n  $$\n- By Farkas\u2019 lemma, either:\n  - (G1) holds, or\n  - There exist $y \\geq 0$, $\\lambda \\geq 0$ such that:\n    $$\n    \\begin{bmatrix} A & I \\\\ -c^T & 0 \\end{bmatrix}^T \\begin{bmatrix} y \\\\ \\lambda \\end{bmatrix} \\geq \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \\quad \\begin{bmatrix} b \\\\ -\\alpha \\end{bmatrix}^T \\begin{bmatrix} y \\\\ \\lambda \\end{bmatrix} < 0.\n    $$\n  - This simplifies to:\n    $$\n    A^T y - \\lambda c \\geq 0, \\quad y^T b - \\lambda \\alpha < 0.\n    $$\n\n### 2) Linear Programming Duality\n\n**Weak Duality:**\nFor the primal-dual pair:\n- (P) $\\max c^T x$ subject to $A x \\leq b$, $x \\geq 0$.\n- (D) $\\min b^T y$ subject to $A^T y \\geq c$, $y \\geq 0$.\n\n**Proof:**\nFor any primal-feasible $x$ and dual-feasible $y$:\n$$\nc^T x \\leq (A x)^T y \\leq b^T y.\n$$\nThis follows from $A x \\leq b$ and $A^T y \\geq c$.\n\n**Strong Duality:**\nAssume (P) is feasible and has finite optimal value $\\beta$.\n\n- By Farkas\u2019 lemma, if (P) is feasible, then (D) is also feasible.\n- Suppose $\\beta < \\gamma$ where $\\gamma$ is the optimal value of (D). Then there exists $\\epsilon > 0$ such that:\n  $$\n  c^T x \\leq \\beta < \\gamma - \\epsilon.\n  $$\n- By weak duality, $b^T y \\geq c^T x$ for any dual-feasible $y$, contradicting the assumption that $\\gamma$ is the optimal value of (D).\n\nThus, $\\beta = \\gamma$.\n\n**Complementary Slackness:**\nIf $x^*$ and $y^*$ are optimal for (P) and (D), then:\n- For each $i$, $y^*_i (b_i - (A x^*)_i) = 0$.\n- For each $j$, $x^*_j ((A^T y^* - c)_j) = 0$.\n\n**Proof:**\n- From the KKT conditions, the complementary slackness conditions follow directly.\n- Since $x^*$ and $y^*$ are optimal, $c^T x^* = b^T y^*$.\n\n### 3) Max-Flow = Min-Cut via LP Duality\n\n**Max-Flow LP:**\n- Maximize $F$ over $(f, F)$ subject to $B f - F d = 0$ and $0 \\leq f \\leq u$.\n\n**Dual LP:**\n- Minimize $\\sum_{e=(u,v)} u_e y_u$ subject to $y_u - y_v \\leq 0$ for all $e$, and $y_s - y_t = 1$.\n\n**Thresholding Argument:**\n- For any feasible $y$, define $S_\\lambda = \\{ v : y_v \\geq \\lambda \\}$.\n- The capacity of the cut $(S_\\lambda, S_\\lambda^c)$ is:\n  $$\n  \\text{cap}(S_\\lambda) = \\sum_{(u,v) \\in E, u \\in S_\\lambda, v \\notin S_\\lambda} u_{(u,v)}.\n  $$\n- The integral identity:\n  $$\n  \\sum_{e=(u,v)} u_e \\max(0, y_u - y_v) = \\int_{-\\infty}^{+\\infty} \\text{cap}(S_\\lambda) \\, d\\lambda.\n  $$\n- This shows that the dual objective equals the minimum capacity of an $s$-$t$ cut, proving max-flow = min-cut.\n\n### 4) Total Unimodularity of Incidence Matrices\n\n**a) TU of Incidence Matrix $B$:**\n- For any square submatrix $B'$ of $B$, consider its determinant.\n- Each row of $B'$ corresponds to a node, and each column to an arc.\n- The determinant of $B'$ is the sum of products of entries, each product corresponding to a permutation of arcs.\n- Each permutation corresponds to a cycle or a path, and the determinant is $\\pm 1$ if it forms a cycle/path, and 0 otherwise.\n\n**b) Adjoining Identity Rows:**\n- If $M$ is TU, then $[M; I]$ is TU.\n- Any square submatrix of $[M; I]$ is either a submatrix of $M$ or includes rows from $I$.\n- The determinant of such submatrices remains in $\\{-1, 0, 1\\}$.\n\n**c) Integral Flows:**\n- The constraint matrix of (MF) in equality form is TU.\n- If all capacities $u_e$ are integers, then the optimal solution $x^*$ is integral.\n\n### 5) Bipartite Matching: K\u0151nig\u2013Eg\u00e9rv\u00e1ry and Hall\u2019s Theorem\n\n**a) LP Formulation:**\n- (PM) $\\max \\sum_{e \\in E} x_e$ subject to $A x \\leq 1$, $x \\geq 0$.\n- (DM) $\\min \\sum_{w \\in U \\cup V} y_w$ subject to $A^T y \\geq 1$, $y \\geq 0$.\n\n**TU of $A$:**\n- Multiply all $V$-rows by $-1$ to get a node-arc incidence matrix.\n- By (4a), $A$ is TU.\n\n**b) K\u0151nig\u2013Eg\u00e9rv\u00e1ry:**\n- The maximum size of a matching equals the minimum size of a vertex cover: $\\nu(G) = \\tau(G)$.\n\n**c) Hall\u2019s Marriage Theorem:**\n- $G$ has a matching saturating $U$ if and only if for every $S \\subseteq U$, $|N(S)| \\geq |S|$.\n- **Only if:** By pigeonhole, if $|N(S)| < |S|$, not all vertices in $S$ can be matched.\n- **If:** Assume a maximum matching does not saturate $U$. Then $\\tau(G) = \\nu(G) < |U|$, implying a minimum vertex cover $C$ with $|C| < |U|$. Set $S = U \\setminus (C \\cap U)$ and show $|N(S)| \\leq |C \\cap V| = |C| - |C \\cap U| < |U| - |C \\cap U| = |S|$, contradicting Hall\u2019s condition.\n\nThis completes the detailed proofs and explanations for each part of the problem."
    }
}