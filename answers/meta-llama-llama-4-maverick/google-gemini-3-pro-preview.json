[
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $P(x)$ be the predicate \"$x$ is a prime number\" and $Q(x, y)$ be the predicate \"$y$ is the smallest prime greater than $x$.\" For all natural numbers $n$, consider the statement: \"For every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\" Formalize this statement using the given predicates $P(x)$ and $Q(x, y)$, and determine whether it is true or false. If true, provide a proof; if false, provide a counterexample.",
    "run_id": "1",
    "outer_attempt": 1,
    "topic_slug": "mathematical_logic_and_foundations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the problem, we will first formalize the statement using the provided predicates and then determine its truth value by analyzing the properties of natural numbers and prime numbers.\n\n### 1. Formalization of the Statement\n\nWe are given the following:\n*   **Domain**: The set of natural numbers, denoted as $\\mathbb{N}$. Standard definitions of $\\mathbb{N}$ are either $\\{0, 1, 2, \\dots\\}$ or $\\{1, 2, 3, \\dots\\}$.\n*   **Predicate** $P(x)$: \"$x$ is a prime number.\"\n*   **Predicate** $Q(x, y)$: \"$y$ is the smallest prime greater than $x$.\"\n*   **Statement**: \"For every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\"\n\nWe need to formalize the existence of a prime strictly between $n$ and $2n$. Note that stating \"there exists a prime $p$ such that $n < p < 2n$\" is logically equivalent to stating \"the smallest prime greater than $n$ is strictly less than $2n$.\"\n\n**Reasoning for equivalence:**\n1.  **Forward:** If there exists a prime $p$ such that $n < p < 2n$, let $q$ be the smallest prime greater than $n$. By definition, $n < q \\le p$. Since $p < 2n$, it follows that $n < q < 2n$. Thus, the smallest prime greater than $n$ is strictly less than $2n$.\n2.  **Reverse:** If $y$ is the smallest prime greater than $n$ (i.e., $Q(n, y)$ is true) and $y < 2n$, then $y$ is a prime satisfying $n < y < 2n$.\n\nTherefore, we can formalize the statement compactly using $Q(n, y)$ to represent the prime conditions:\n\n$$ \\forall n \\in \\mathbb{N}, \\exists y \\in \\mathbb{N}, (Q(n, y) \\land y < 2n) $$\n\nAlternatively, using only the basic predicate $P(x)$ inside the quantifier structure explicitly mentioned in the text:\n$$ \\forall n \\in \\mathbb{N}, \\exists p \\in \\mathbb{N}, (P(p) \\land n < p < 2n) $$\n\nGiven the instruction to use the provided predicates (specifically including $Q$), the first formalization is the most precise utilization of the definitions provided.\n\n### 2. Determination of Truth Value\n\nTo determine if the statement is true or false, we examine the statement for specific natural numbers. The statement claims the property holds for **every** natural number $n$.\n\n**Case Analysis:**\n*   **If $n = 1$:**\n    The inequality becomes $1 < p < 2(1)$, which simplifies to $1 < p < 2$.\n    There are no integers strictly between 1 and 2, and consequently, no prime numbers.\n    The smallest prime greater than 1 is 2. Testing the condition $y < 2n$:\n    $$2 < 2(1) \\implies 2 < 2$$\n    This inequality is false.\n\n*   **If $n = 2$:**\n    The inequality is $2 < p < 4$. The prime $p=3$ satisfies this. (True)\n\n*   **If $n = 3$:**\n    The inequality is $3 < p < 6$. The prime $p=5$ satisfies this. (True)\n\n*   **If $n = 0$ (if included in $\\mathbb{N}$):**\n    The inequality is $0 < p < 0$, which is impossible.\n\nSince the statement must hold for **all** natural numbers, a single counterexample is sufficient to disprove it. The case $n=1$ serves as this counterexample.\n\n**Note on Mathematical Context:**\nFor $n > 1$, the statement is true. This is a famous result in number theory known as **Bertrand's Postulate** (or the Bertrand-Chebyshev Theorem), which states that for any integer $n > 1$, there always exists at least one prime $p$ such that $n < p < 2n$. However, because the question specifies \"For every natural number $n$\" and standard definitions of $\\mathbb{N}$ include $1$, the statement is strictly false as written.\n\n### 3. Conclusion and Proof\n\n**Truth Value:** **False**\n\n**Counterexample:**\nLet $n = 1$. The statement asserts the existence of a prime $p$ such that $1 < p < 2$. Since there are no integers between 1 and 2, there is no such prime. Thus, the condition fails for $n=1$.\n\n**Final Formalized Answer:**\nThe formalized statement is:\n$$ \\forall n \\in \\mathbb{N}, \\exists y \\in \\mathbb{N}, (Q(n, y) \\land y < 2n) $$\nThe statement is **false** because for $n=1$, the smallest prime greater than 1 is 2, and $2$ is not strictly less than $2(1)$.",
        "raw_answer": "To solve the problem, we will first formalize the statement using the provided predicates and then determine its truth value by analyzing the properties of natural numbers and prime numbers.\n\n### 1. Formalization of the Statement\n\nWe are given the following:\n*   **Domain**: The set of natural numbers, denoted as $\\mathbb{N}$. Standard definitions of $\\mathbb{N}$ are either $\\{0, 1, 2, \\dots\\}$ or $\\{1, 2, 3, \\dots\\}$.\n*   **Predicate** $P(x)$: \"$x$ is a prime number.\"\n*   **Predicate** $Q(x, y)$: \"$y$ is the smallest prime greater than $x$.\"\n*   **Statement**: \"For every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\"\n\nWe need to formalize the existence of a prime strictly between $n$ and $2n$. Note that stating \"there exists a prime $p$ such that $n < p < 2n$\" is logically equivalent to stating \"the smallest prime greater than $n$ is strictly less than $2n$.\"\n\n**Reasoning for equivalence:**\n1.  **Forward:** If there exists a prime $p$ such that $n < p < 2n$, let $q$ be the smallest prime greater than $n$. By definition, $n < q \\le p$. Since $p < 2n$, it follows that $n < q < 2n$. Thus, the smallest prime greater than $n$ is strictly less than $2n$.\n2.  **Reverse:** If $y$ is the smallest prime greater than $n$ (i.e., $Q(n, y)$ is true) and $y < 2n$, then $y$ is a prime satisfying $n < y < 2n$.\n\nTherefore, we can formalize the statement compactly using $Q(n, y)$ to represent the prime conditions:\n\n$$ \\forall n \\in \\mathbb{N}, \\exists y \\in \\mathbb{N}, (Q(n, y) \\land y < 2n) $$\n\nAlternatively, using only the basic predicate $P(x)$ inside the quantifier structure explicitly mentioned in the text:\n$$ \\forall n \\in \\mathbb{N}, \\exists p \\in \\mathbb{N}, (P(p) \\land n < p < 2n) $$\n\nGiven the instruction to use the provided predicates (specifically including $Q$), the first formalization is the most precise utilization of the definitions provided.\n\n### 2. Determination of Truth Value\n\nTo determine if the statement is true or false, we examine the statement for specific natural numbers. The statement claims the property holds for **every** natural number $n$.\n\n**Case Analysis:**\n*   **If $n = 1$:**\n    The inequality becomes $1 < p < 2(1)$, which simplifies to $1 < p < 2$.\n    There are no integers strictly between 1 and 2, and consequently, no prime numbers.\n    The smallest prime greater than 1 is 2. Testing the condition $y < 2n$:\n    $$2 < 2(1) \\implies 2 < 2$$\n    This inequality is false.\n\n*   **If $n = 2$:**\n    The inequality is $2 < p < 4$. The prime $p=3$ satisfies this. (True)\n\n*   **If $n = 3$:**\n    The inequality is $3 < p < 6$. The prime $p=5$ satisfies this. (True)\n\n*   **If $n = 0$ (if included in $\\mathbb{N}$):**\n    The inequality is $0 < p < 0$, which is impossible.\n\nSince the statement must hold for **all** natural numbers, a single counterexample is sufficient to disprove it. The case $n=1$ serves as this counterexample.\n\n**Note on Mathematical Context:**\nFor $n > 1$, the statement is true. This is a famous result in number theory known as **Bertrand's Postulate** (or the Bertrand-Chebyshev Theorem), which states that for any integer $n > 1$, there always exists at least one prime $p$ such that $n < p < 2n$. However, because the question specifies \"For every natural number $n$\" and standard definitions of $\\mathbb{N}$ include $1$, the statement is strictly false as written.\n\n### 3. Conclusion and Proof\n\n**Truth Value:** **False**\n\n**Counterexample:**\nLet $n = 1$. The statement asserts the existence of a prime $p$ such that $1 < p < 2$. Since there are no integers between 1 and 2, there is no such prime. Thus, the condition fails for $n=1$.\n\n**Final Formalized Answer:**\nThe formalized statement is:\n$$ \\forall n \\in \\mathbb{N}, \\exists y \\in \\mathbb{N}, (Q(n, y) \\land y < 2n) $$\nThe statement is **false** because for $n=1$, the smallest prime greater than 1 is 2, and $2$ is not strictly less than $2(1)$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Combinatorics, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the domain\nThe domain specified is Combinatorics, which involves the study of counting, arranging, and optimizing objects in various ways. It encompasses topics such as permutations, combinations, graph theory, and more.\n\n## Step 3: Generate a problem\nTo create a challenging problem, let's consider a topic within Combinatorics that is both interesting and requires substantial reasoning. A potential topic is graph theory, specifically focusing on graph coloring or connectivity.\n\n## Step 4: Formulate the problem\nLet's formulate a problem: \"Prove that in any simple graph with $n$ vertices, if the graph is connected and has no cycles (i.e., it's a tree), then it has exactly $n-1$ edges.\"\n\n## Step 5: Verify the problem against the quality rubric\n- **Well-Posedness and Completeness**: The problem is self-contained, defines the necessary terms (simple graph, connected, no cycles, tree), and asks for a proof.\n- **Clarity**: The terms used are standard in graph theory, and the task is clear.\n- **Non-Triviality**: The problem requires understanding of graph theory and a proof involving induction or another suitable method, making it non-trivial.\n- **Solvability and Verification**: The statement is a known fact in graph theory and can be proven using established methods.\n\n## Step 6: Provide the solution\nTo solve this, we can use induction on $n$. For $n=1$, a tree has 0 edges, and $1-1=0$, so the statement holds. For $n>1$, assume the statement is true for all trees with fewer than $n$ vertices. A tree with $n$ vertices has at least one leaf (a vertex of degree 1); removing this leaf and its edge gives a tree with $n-1$ vertices. By the induction hypothesis, this smaller tree has $(n-1)-1 = n-2$ edges. Adding back the removed edge gives $n-2 + 1 = n-1$ edges, proving the statement for $n$.\n\n## Step 7: Format the output\nLet's format the problem and solution according to the required structure.\n\n\nLet $G$ be a simple graph with $n$ vertices. Prove that if $G$ is a tree (i.e., it is connected and has no cycles), then it has exactly $n-1$ edges.",
    "run_id": "2",
    "outer_attempt": 1,
    "topic_slug": "combinatorics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that a simple graph $G$ with $n$ vertices that is a tree (connected and acyclic) has exactly $n-1$ edges, we will use the principle of mathematical induction on the number of vertices $n$.\n\n### Proof\n\nLet $P(n)$ be the statement: \"Any tree with $n$ vertices has exactly $n-1$ edges.\"\n\n**1. Base Case ($n=1$)**\nConsider a graph $G$ with $n=1$ vertex. Since $G$ is a simple graph, it contains no self-loops. Since there is only one vertex, there can be no edges connecting distinct vertices. Therefore, the number of edges is 0.\nThe formula gives $n-1 = 1-1 = 0$.\nThus, $P(1)$ is true.\n\n**2. Inductive Hypothesis**\nAssume that $P(k)$ is true for some integer $k \\geq 1$. That is, assume any tree with $k$ vertices has exactly $k-1$ edges.\n\n**3. Inductive Step**\nWe must show that $P(k+1)$ is true. Let $T$ be an arbitrary tree with $n = k+1$ vertices. We need to show that $T$ has $(k+1)-1 = k$ edges.\n\nTo proceed, we utilize the following lemma:\n\n**Lemma:** Every tree with at least 2 vertices has at least two vertices of degree 1 (leaves).\n\n*Proof of Lemma:*\nConsider a simple path of maximal length in $T$. Let this path be $v_1, v_2, \\dots, v_m$. Since the graph is finite, such a path exists.\nConsider the endpoint $v_1$.\n- $v_1$ is connected to $v_2$.\n- If $v_1$ were connected to any other vertex $v_j$ in the path (where $j > 2$), the sequence $v_1, v_2, \\dots, v_j, v_1$ would form a cycle. This contradicts the assumption that $T$ is acyclic.\n- If $v_1$ were connected to any vertex $u$ not in the path, we could extend the path to $u, v_1, \\dots, v_m$, contradicting the assumption that the path is maximal.\nTherefore, $v_1$ has no neighbors other than $v_2$, so $\\deg(v_1) = 1$. The same argument applies to the other endpoint $v_m$. Thus, $T$ has at least two leaves.\n\n**Continuing the Inductive Step:**\nSince $n = k+1 \\geq 2$, by the Lemma, $T$ contains a leaf vertex $v$ with degree 1. Let $e$ be the unique edge incident to $v$, connecting $v$ to some vertex $u$.\n\nNow, consider the graph $T'$ obtained by removing the vertex $v$ and the edge $e$ from $T$.\n$$ V(T') = V(T) \\setminus \\{v\\} $$\n$$ E(T') = E(T) \\setminus \\{e\\} $$\n\nWe must verify that $T'$ is a tree:\n1.  **$T'$ has $k$ vertices:** Since $T$ had $k+1$ vertices, removing one leaves $k$.\n2.  **$T'$ is acyclic:** $T'$ is a subgraph of $T$. Since $T$ has no cycles, $T'$ cannot have cycles.\n3.  **$T'$ is connected:** Let $x$ and $y$ be any two distinct vertices in $T'$. Since $T$ is a tree, there is a unique path between $x$ and $y$ in $T$. Because $v$ is a leaf (degree 1), $v$ cannot be an intermediate vertex on the path between any two other vertices $x$ and $y$. Therefore, the path connecting $x$ and $y$ in $T$ consists entirely of edges and vertices present in $T'$. Thus, $x$ and $y$ are connected in $T'$.\n\nSince $T'$ is a connected acyclic graph with $k$ vertices, $T'$ is a tree. By the **Inductive Hypothesis**, $T'$ has exactly $k-1$ edges.\n\nThe number of edges in the original tree $T$ is the number of edges in $T'$ plus the removed edge $e$.\n$$ |E(T)| = |E(T')| + 1 = (k-1) + 1 = k $$\n\nThis matches the requirement $n-1 = (k+1)-1 = k$. Thus, $P(k+1)$ is true.\n\n**Conclusion**\nBy the principle of mathematical induction, for every integer $n \\geq 1$, a tree with $n$ vertices has exactly $n-1$ edges.",
        "raw_answer": "To prove that a simple graph $G$ with $n$ vertices that is a tree (connected and acyclic) has exactly $n-1$ edges, we will use the principle of mathematical induction on the number of vertices $n$.\n\n### Proof\n\nLet $P(n)$ be the statement: \"Any tree with $n$ vertices has exactly $n-1$ edges.\"\n\n**1. Base Case ($n=1$)**\nConsider a graph $G$ with $n=1$ vertex. Since $G$ is a simple graph, it contains no self-loops. Since there is only one vertex, there can be no edges connecting distinct vertices. Therefore, the number of edges is 0.\nThe formula gives $n-1 = 1-1 = 0$.\nThus, $P(1)$ is true.\n\n**2. Inductive Hypothesis**\nAssume that $P(k)$ is true for some integer $k \\geq 1$. That is, assume any tree with $k$ vertices has exactly $k-1$ edges.\n\n**3. Inductive Step**\nWe must show that $P(k+1)$ is true. Let $T$ be an arbitrary tree with $n = k+1$ vertices. We need to show that $T$ has $(k+1)-1 = k$ edges.\n\nTo proceed, we utilize the following lemma:\n\n**Lemma:** Every tree with at least 2 vertices has at least two vertices of degree 1 (leaves).\n\n*Proof of Lemma:*\nConsider a simple path of maximal length in $T$. Let this path be $v_1, v_2, \\dots, v_m$. Since the graph is finite, such a path exists.\nConsider the endpoint $v_1$.\n- $v_1$ is connected to $v_2$.\n- If $v_1$ were connected to any other vertex $v_j$ in the path (where $j > 2$), the sequence $v_1, v_2, \\dots, v_j, v_1$ would form a cycle. This contradicts the assumption that $T$ is acyclic.\n- If $v_1$ were connected to any vertex $u$ not in the path, we could extend the path to $u, v_1, \\dots, v_m$, contradicting the assumption that the path is maximal.\nTherefore, $v_1$ has no neighbors other than $v_2$, so $\\deg(v_1) = 1$. The same argument applies to the other endpoint $v_m$. Thus, $T$ has at least two leaves.\n\n**Continuing the Inductive Step:**\nSince $n = k+1 \\geq 2$, by the Lemma, $T$ contains a leaf vertex $v$ with degree 1. Let $e$ be the unique edge incident to $v$, connecting $v$ to some vertex $u$.\n\nNow, consider the graph $T'$ obtained by removing the vertex $v$ and the edge $e$ from $T$.\n$$ V(T') = V(T) \\setminus \\{v\\} $$\n$$ E(T') = E(T) \\setminus \\{e\\} $$\n\nWe must verify that $T'$ is a tree:\n1.  **$T'$ has $k$ vertices:** Since $T$ had $k+1$ vertices, removing one leaves $k$.\n2.  **$T'$ is acyclic:** $T'$ is a subgraph of $T$. Since $T$ has no cycles, $T'$ cannot have cycles.\n3.  **$T'$ is connected:** Let $x$ and $y$ be any two distinct vertices in $T'$. Since $T$ is a tree, there is a unique path between $x$ and $y$ in $T$. Because $v$ is a leaf (degree 1), $v$ cannot be an intermediate vertex on the path between any two other vertices $x$ and $y$. Therefore, the path connecting $x$ and $y$ in $T$ consists entirely of edges and vertices present in $T'$. Thus, $x$ and $y$ are connected in $T'$.\n\nSince $T'$ is a connected acyclic graph with $k$ vertices, $T'$ is a tree. By the **Inductive Hypothesis**, $T'$ has exactly $k-1$ edges.\n\nThe number of edges in the original tree $T$ is the number of edges in $T'$ plus the removed edge $e$.\n$$ |E(T)| = |E(T')| + 1 = (k-1) + 1 = k $$\n\nThis matches the requirement $n-1 = (k+1)-1 = k$. Thus, $P(k+1)$ is true.\n\n**Conclusion**\nBy the principle of mathematical induction, for every integer $n \\geq 1$, a tree with $n$ vertices has exactly $n-1$ edges.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the requirements for the problem.\nThe task is to generate a challenging but solvable mathematics problem in the domain of number theory, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within number theory.\nNumber theory encompasses various topics such as divisibility, prime numbers, congruences, and Diophantine equations. A challenging problem could involve proving a property related to prime numbers or solving a specific type of Diophantine equation.\n\n## Step 3: Formulate a problem that meets the criteria.\nLet's consider a problem involving the sum of divisors of a number and its relation to perfect numbers. A perfect number is a positive integer that is equal to the sum of its proper divisors, excluding the number itself.\n\n## Step 4: Specify the problem.\nConsider the following problem: \"Prove that if $n$ is an even perfect number, then $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.\"\n\n## Step 5: Provide the solution to the problem.\nTo solve this, we need to understand the definition of an even perfect number and its relation to Mersenne primes.\n\n## Step 6: Recall the definition and properties of even perfect numbers.\nAn even perfect number $n$ can be written as $n = 2^{k-1}(2^k - 1)$, where $2^k - 1$ is prime. This is known as the Euclid-Euler theorem.\n\n## Step 7: State the Euclid-Euler theorem.\nThe Euclid-Euler theorem states that every even perfect number is of the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime (i.e., $2^p - 1$ is prime).\n\n## Step 8: Provide the proof or reasoning for the given statement.\nThe proof involves two main parts: (1) showing that any number of the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is prime, is perfect, and (2) showing that every even perfect number is of this form.\n\n## Step 9: Outline the proof that $2^{p-1}(2^p - 1)$ is perfect when $2^p - 1$ is prime.\nLet $n = 2^{p-1}(2^p - 1)$. The sum of divisors of $n$, $\\sigma(n)$, is given by $\\sigma(n) = \\sigma(2^{p-1})\\sigma(2^p - 1)$. Since $2^p - 1$ is prime, $\\sigma(2^p - 1) = 2^p$. Also, $\\sigma(2^{p-1}) = 1 + 2 + 2^2 + \\cdots + 2^{p-1} = 2^p - 1$. Thus, $\\sigma(n) = (2^p - 1) \\cdot 2^p = 2 \\cdot 2^{p-1}(2^p - 1) = 2n$, proving $n$ is perfect.\n\n## Step 10: Outline the proof that every even perfect number is of the form $2^{p-1}(2^p - 1)$.\nLet $n$ be an even perfect number. Then $n = 2^k \\cdot m$, where $m$ is odd. Since $n$ is perfect, $\\sigma(n) = 2n$. Using the multiplicative property of $\\sigma$, we have $\\sigma(n) = \\sigma(2^k)\\sigma(m) = (2^{k+1} - 1)\\sigma(m)$. Thus, $(2^{k+1} - 1)\\sigma(m) = 2^{k+1}m$. This implies $2^{k+1} - 1$ divides $m$, so $m = (2^{k+1} - 1)d$ for some $d$. Substituting back gives $\\sigma(m) = 2^{k+1}d$. For $d = 1$, $m = 2^{k+1} - 1$ is prime, and $\\sigma(m) = m + 1 = 2^{k+1}$, which matches our requirement. For $d > 1$, it leads to a contradiction because $\\sigma(m) \\geq m + d > 2d$, unless $d = 1$ and $m$ is prime.\n\n## Step 11: Conclude the solution.\nThe given statement is a direct consequence of the Euclid-Euler theorem, which characterizes even perfect numbers.\n\nThe final answer is: \n\nProve that if $n$ is an even perfect number, then $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.",
    "run_id": "3",
    "outer_attempt": 1,
    "topic_slug": "number_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the rigorous proof of the statement.\n\n### **Theorem**\nIf $n$ is an even perfect number, then $n$ takes the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.\n\n---\n\n### **Proof**\n\n**1. Definitions and Setup**\nLet $n$ be an even perfect number.\nSince $n$ is even, we can write $n$ in the form:\n$$n = 2^k \\cdot m$$\nwhere $k \\geq 1$ is an integer and $m$ is an odd positive integer.\n\nSince $n$ is a perfect number, the sum of its positive divisors, denoted by $\\sigma(n)$, satisfies:\n$$\\sigma(n) = 2n$$\n\n**2. Multiplicative Property of $\\sigma$**\nThe function $\\sigma$ is multiplicative, meaning $\\sigma(ab) = \\sigma(a)\\sigma(b)$ if $\\gcd(a, b) = 1$.\nSince $m$ is odd, $\\gcd(2^k, m) = 1$. Therefore:\n$$\\sigma(n) = \\sigma(2^k \\cdot m) = \\sigma(2^k)\\sigma(m)$$\n\nWe calculate $\\sigma(2^k)$ as the sum of the geometric series $1 + 2 + \\dots + 2^k$:\n$$\\sigma(2^k) = \\frac{2^{k+1} - 1}{2 - 1} = 2^{k+1} - 1$$\n\nSubstituting this back into the perfect number equation $\\sigma(n) = 2n$:\n$$(2^{k+1} - 1)\\sigma(m) = 2(2^k \\cdot m)$$\n$$(2^{k+1} - 1)\\sigma(m) = 2^{k+1}m \\quad (*)$$\n\n**3. Divisibility Analysis**\nFrom equation $(*)$, we see that $2^{k+1} - 1$ divides the product $2^{k+1}m$.\nSince $2^{k+1} - 1$ is an odd number, $\\gcd(2^{k+1} - 1, 2^{k+1}) = 1$.\nBy Euclid's Lemma, $2^{k+1} - 1$ must divide $m$.\n\nThus, there exists an integer $q$ such that:\n$$m = (2^{k+1} - 1)q$$\n\n**4. Analyzing $\\sigma(m)$**\nSubstitute $m = (2^{k+1} - 1)q$ back into equation $(*)$:\n$$(2^{k+1} - 1)\\sigma(m) = 2^{k+1}(2^{k+1} - 1)q$$\nDividing both sides by the non-zero term $(2^{k+1} - 1)$, we obtain:\n$$\\sigma(m) = 2^{k+1}q$$\n\nWe also know that $m = (2^{k+1} - 1)q$. Let us consider the divisors of $m$.\nSince $m$ is a multiple of $q$, both $m$ and $q$ are distinct divisors of $m$. (Note: Since $n$ is even, $k \\geq 1$, which implies $2^{k+1} - 1 \\geq 3$, so $m > q$).\n\nThe sum of the divisors of $m$, $\\sigma(m)$, must include at least $m$ and $q$. Therefore:\n$$\\sigma(m) \\geq m + q$$\n\nSubstituting the expressions in terms of $q$:\n$$\\sigma(m) \\geq (2^{k+1} - 1)q + q$$\n$$\\sigma(m) \\geq 2^{k+1}q - q + q$$\n$$\\sigma(m) \\geq 2^{k+1}q$$\n\n**5. Forcing Primality**\nWe have established two facts:\n1. $\\sigma(m) = 2^{k+1}q$ (from the equation)\n2. $\\sigma(m) \\geq m + q = 2^{k+1}q$ (from the property of divisors)\n\nThe equality $\\sigma(m) = m + q$ holds if and only if $m$ and $q$ are the **only** positive divisors of $m$.\nThis implies two conditions:\n1. The divisor $q$ must be $1$ (since $1$ is always a divisor of any integer).\n2. The number $m$ must be prime (since its only divisors are $1$ and itself).\n\nThus, we determine:\n$$q = 1$$\n$$m = (2^{k+1} - 1)(1) = 2^{k+1} - 1$$\nAnd $m$ is a prime number.\n\n**6. Conclusion**\nWe have shown that $m = 2^{k+1} - 1$ is prime. For a number of the form $2^x - 1$ to be prime, the exponent $x$ must be prime. Let $p = k+1$, where $p$ is prime.\nThen:\n$$m = 2^p - 1$$\nis a Mersenne prime.\n\nSubstituting $k = p - 1$ and $m = 2^p - 1$ back into the expression for $n$:\n$$n = 2^{p-1}(2^p - 1)$$\n\n### **Final Answer**\nWe have proven that any even perfect number $n$ must be of the form $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.",
        "raw_answer": "Here is the rigorous proof of the statement.\n\n### **Theorem**\nIf $n$ is an even perfect number, then $n$ takes the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.\n\n---\n\n### **Proof**\n\n**1. Definitions and Setup**\nLet $n$ be an even perfect number.\nSince $n$ is even, we can write $n$ in the form:\n$$n = 2^k \\cdot m$$\nwhere $k \\geq 1$ is an integer and $m$ is an odd positive integer.\n\nSince $n$ is a perfect number, the sum of its positive divisors, denoted by $\\sigma(n)$, satisfies:\n$$\\sigma(n) = 2n$$\n\n**2. Multiplicative Property of $\\sigma$**\nThe function $\\sigma$ is multiplicative, meaning $\\sigma(ab) = \\sigma(a)\\sigma(b)$ if $\\gcd(a, b) = 1$.\nSince $m$ is odd, $\\gcd(2^k, m) = 1$. Therefore:\n$$\\sigma(n) = \\sigma(2^k \\cdot m) = \\sigma(2^k)\\sigma(m)$$\n\nWe calculate $\\sigma(2^k)$ as the sum of the geometric series $1 + 2 + \\dots + 2^k$:\n$$\\sigma(2^k) = \\frac{2^{k+1} - 1}{2 - 1} = 2^{k+1} - 1$$\n\nSubstituting this back into the perfect number equation $\\sigma(n) = 2n$:\n$$(2^{k+1} - 1)\\sigma(m) = 2(2^k \\cdot m)$$\n$$(2^{k+1} - 1)\\sigma(m) = 2^{k+1}m \\quad (*)$$\n\n**3. Divisibility Analysis**\nFrom equation $(*)$, we see that $2^{k+1} - 1$ divides the product $2^{k+1}m$.\nSince $2^{k+1} - 1$ is an odd number, $\\gcd(2^{k+1} - 1, 2^{k+1}) = 1$.\nBy Euclid's Lemma, $2^{k+1} - 1$ must divide $m$.\n\nThus, there exists an integer $q$ such that:\n$$m = (2^{k+1} - 1)q$$\n\n**4. Analyzing $\\sigma(m)$**\nSubstitute $m = (2^{k+1} - 1)q$ back into equation $(*)$:\n$$(2^{k+1} - 1)\\sigma(m) = 2^{k+1}(2^{k+1} - 1)q$$\nDividing both sides by the non-zero term $(2^{k+1} - 1)$, we obtain:\n$$\\sigma(m) = 2^{k+1}q$$\n\nWe also know that $m = (2^{k+1} - 1)q$. Let us consider the divisors of $m$.\nSince $m$ is a multiple of $q$, both $m$ and $q$ are distinct divisors of $m$. (Note: Since $n$ is even, $k \\geq 1$, which implies $2^{k+1} - 1 \\geq 3$, so $m > q$).\n\nThe sum of the divisors of $m$, $\\sigma(m)$, must include at least $m$ and $q$. Therefore:\n$$\\sigma(m) \\geq m + q$$\n\nSubstituting the expressions in terms of $q$:\n$$\\sigma(m) \\geq (2^{k+1} - 1)q + q$$\n$$\\sigma(m) \\geq 2^{k+1}q - q + q$$\n$$\\sigma(m) \\geq 2^{k+1}q$$\n\n**5. Forcing Primality**\nWe have established two facts:\n1. $\\sigma(m) = 2^{k+1}q$ (from the equation)\n2. $\\sigma(m) \\geq m + q = 2^{k+1}q$ (from the property of divisors)\n\nThe equality $\\sigma(m) = m + q$ holds if and only if $m$ and $q$ are the **only** positive divisors of $m$.\nThis implies two conditions:\n1. The divisor $q$ must be $1$ (since $1$ is always a divisor of any integer).\n2. The number $m$ must be prime (since its only divisors are $1$ and itself).\n\nThus, we determine:\n$$q = 1$$\n$$m = (2^{k+1} - 1)(1) = 2^{k+1} - 1$$\nAnd $m$ is a prime number.\n\n**6. Conclusion**\nWe have shown that $m = 2^{k+1} - 1$ is prime. For a number of the form $2^x - 1$ to be prime, the exponent $x$ must be prime. Let $p = k+1$, where $p$ is prime.\nThen:\n$$m = 2^p - 1$$\nis a Mersenne prime.\n\nSubstituting $k = p - 1$ and $m = 2^p - 1$ back into the expression for $n$:\n$$n = 2^{p-1}(2^p - 1)$$\n\n### **Final Answer**\nWe have proven that any even perfect number $n$ must be of the form $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of \"Order, lattices, ordered algebraic structures\" along with a complete and verifiable solution.\n\n## Step 2: Identify the key elements of the problem domain\nThe domain involves concepts related to order, lattices, and ordered algebraic structures. This includes partially ordered sets (posets), lattices, Boolean algebras, and other related structures.\n\n## Step 3: Formulate a problem that fits the domain\nTo create a problem, we need to consider what aspects of \"Order, lattices, ordered algebraic structures\" can be explored. A potential problem could involve proving a property about a specific type of lattice or ordered structure.\n\n## Step 4: Generate a specific problem\nLet's consider a problem involving a Boolean algebra, which is a type of lattice. A Boolean algebra is a distributive lattice with the additional property that every element has a complement.\n\n## Step 5: State the problem\n\"Let $B$ be a Boolean algebra. Prove that for any elements $a, b \\in B$, the following identity holds: $a \\vee (a \\wedge b) = a$.\"\n\n## Step 6: Provide a solution to the problem\nTo prove $a \\vee (a \\wedge b) = a$, we can use the properties of a Boolean algebra, specifically the absorption laws.\n\n## Step 7: Write out the solution in detail\nFirst, recall that a Boolean algebra is a distributive lattice with complementation. The absorption laws state that for any $a, b$ in the Boolean algebra, $a \\vee (a \\wedge b) = a$ and $a \\wedge (a \\vee b) = a$. We need to prove the first absorption law.\n\n## Step 8: Apply the properties of a lattice to prove the identity\nBy definition of a lattice, $a \\wedge b \\leq a$ because $a$ is an upper bound of $a$ and $a \\wedge b$, and $a \\wedge b$ is the greatest lower bound of $a$ and $b$. Thus, $a \\vee (a \\wedge b) = a$ because $a \\vee x = a$ whenever $x \\leq a$.\n\n## Step 9: Formalize the solution\nGiven $a, b \\in B$, since $a \\wedge b \\leq a$, we have $a \\vee (a \\wedge b) = a$ due to the property that $x \\leq y$ implies $y \\vee x = y$. Thus, $a \\vee (a \\wedge b) = a$.\n\n## Step 10: Present the problem and solution in the required format\n\nLet $B$ be a Boolean algebra. Prove that for any elements $a, b \\in B$, the following identity holds: $a \\vee (a \\wedge b) = a$.",
    "run_id": "4",
    "outer_attempt": 1,
    "topic_slug": "order_lattices_and_ordered_algebraic_structures",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To provide a rigorous answer to the question, we must first establish the definition of a Boolean algebra. The problem asks to prove the absorption law $a \\vee (a \\wedge b) = a$. While this is often taken as an axiom in the definition of a lattice, in the context of Boolean algebra, it is instructive and rigorous to derive it from the fundamental algebraic axioms (Huntington's or similar standard equational axioms).\n\n### Definition and Axioms\n\nLet $\\mathcal{B} = (B, \\vee, \\wedge, ', 0, 1)$ be a Boolean algebra. We assume the following standard axioms hold for all $x, y, z \\in B$:\n\n1.  **Commutativity:**\n    $x \\vee y = y \\vee x$\n    $x \\wedge y = y \\wedge x$\n2.  **Distributivity:**\n    $x \\vee (y \\wedge z) = (x \\vee y) \\wedge (x \\vee z)$\n    $x \\wedge (y \\vee z) = (x \\wedge y) \\vee (x \\wedge z)$\n3.  **Identity:**\n    $x \\vee 0 = x$\n    $x \\wedge 1 = x$\n4.  **Complementation:**\n    $x \\vee x' = 1$\n    $x \\wedge x' = 0$\n\n*(Note: Associativity is also an axiom of Boolean algebra, but the proof below relies only on the axioms listed above.)*\n\n### Goal\nProve that for any elements $a, b \\in B$, the identity $a \\vee (a \\wedge b) = a$ holds.\n\n---\n\n### Proof\n\nThe proof proceeds in two parts. First, we establish a lemma regarding the behavior of the element $1$. Second, we apply this lemma to prove the absorption identity.\n\n**Lemma 1:** For any element $x \\in B$, $x \\vee 1 = 1$.\n\n*Proof of Lemma 1:*\nWe use the Identity and Complementation axioms to rewrite $1$, and then apply Distributivity.\n$$\n\\begin{aligned}\nx \\vee 1 &= (x \\vee 1) \\wedge 1 & & (\\text{Identity: } y \\wedge 1 = y) \\\\\n&= (x \\vee 1) \\wedge (x \\vee x') & & (\\text{Complementation: } 1 = x \\vee x') \\\\\n&= x \\vee (1 \\wedge x') & & (\\text{Distributivity: } (x \\vee y) \\wedge (x \\vee z) = x \\vee (y \\wedge z)) \\\\\n&= x \\vee (x' \\wedge 1) & & (\\text{Commutativity}) \\\\\n&= x \\vee x' & & (\\text{Identity: } y \\wedge 1 = y) \\\\\n&= 1 & & (\\text{Complementation})\n\\end{aligned}\n$$\nThus, $x \\vee 1 = 1$.\n\n**Main Proof:**\nWe now prove $a \\vee (a \\wedge b) = a$.\n\n$$\n\\begin{aligned}\na \\vee (a \\wedge b) &= (a \\wedge 1) \\vee (a \\wedge b) & & (\\text{Identity: } a = a \\wedge 1) \\\\\n&= a \\wedge (1 \\vee b) & & (\\text{Distributivity: } (x \\wedge y) \\vee (x \\wedge z) = x \\wedge (y \\vee z)) \\\\\n&= a \\wedge (b \\vee 1) & & (\\text{Commutativity}) \\\\\n&= a \\wedge 1 & & (\\text{Lemma 1: } b \\vee 1 = 1) \\\\\n&= a & & (\\text{Identity})\n\\end{aligned}\n$$\n\n### Conclusion\nWe have derived the identity using only the standard algebraic axioms of a Boolean algebra.\nTherefore, for any elements $a, b \\in B$, the identity $a \\vee (a \\wedge b) = a$ holds.",
        "raw_answer": "To provide a rigorous answer to the question, we must first establish the definition of a Boolean algebra. The problem asks to prove the absorption law $a \\vee (a \\wedge b) = a$. While this is often taken as an axiom in the definition of a lattice, in the context of Boolean algebra, it is instructive and rigorous to derive it from the fundamental algebraic axioms (Huntington's or similar standard equational axioms).\n\n### Definition and Axioms\n\nLet $\\mathcal{B} = (B, \\vee, \\wedge, ', 0, 1)$ be a Boolean algebra. We assume the following standard axioms hold for all $x, y, z \\in B$:\n\n1.  **Commutativity:**\n    $x \\vee y = y \\vee x$\n    $x \\wedge y = y \\wedge x$\n2.  **Distributivity:**\n    $x \\vee (y \\wedge z) = (x \\vee y) \\wedge (x \\vee z)$\n    $x \\wedge (y \\vee z) = (x \\wedge y) \\vee (x \\wedge z)$\n3.  **Identity:**\n    $x \\vee 0 = x$\n    $x \\wedge 1 = x$\n4.  **Complementation:**\n    $x \\vee x' = 1$\n    $x \\wedge x' = 0$\n\n*(Note: Associativity is also an axiom of Boolean algebra, but the proof below relies only on the axioms listed above.)*\n\n### Goal\nProve that for any elements $a, b \\in B$, the identity $a \\vee (a \\wedge b) = a$ holds.\n\n---\n\n### Proof\n\nThe proof proceeds in two parts. First, we establish a lemma regarding the behavior of the element $1$. Second, we apply this lemma to prove the absorption identity.\n\n**Lemma 1:** For any element $x \\in B$, $x \\vee 1 = 1$.\n\n*Proof of Lemma 1:*\nWe use the Identity and Complementation axioms to rewrite $1$, and then apply Distributivity.\n$$\n\\begin{aligned}\nx \\vee 1 &= (x \\vee 1) \\wedge 1 & & (\\text{Identity: } y \\wedge 1 = y) \\\\\n&= (x \\vee 1) \\wedge (x \\vee x') & & (\\text{Complementation: } 1 = x \\vee x') \\\\\n&= x \\vee (1 \\wedge x') & & (\\text{Distributivity: } (x \\vee y) \\wedge (x \\vee z) = x \\vee (y \\wedge z)) \\\\\n&= x \\vee (x' \\wedge 1) & & (\\text{Commutativity}) \\\\\n&= x \\vee x' & & (\\text{Identity: } y \\wedge 1 = y) \\\\\n&= 1 & & (\\text{Complementation})\n\\end{aligned}\n$$\nThus, $x \\vee 1 = 1$.\n\n**Main Proof:**\nWe now prove $a \\vee (a \\wedge b) = a$.\n\n$$\n\\begin{aligned}\na \\vee (a \\wedge b) &= (a \\wedge 1) \\vee (a \\wedge b) & & (\\text{Identity: } a = a \\wedge 1) \\\\\n&= a \\wedge (1 \\vee b) & & (\\text{Distributivity: } (x \\wedge y) \\vee (x \\wedge z) = x \\wedge (y \\vee z)) \\\\\n&= a \\wedge (b \\vee 1) & & (\\text{Commutativity}) \\\\\n&= a \\wedge 1 & & (\\text{Lemma 1: } b \\vee 1 = 1) \\\\\n&= a & & (\\text{Identity})\n\\end{aligned}\n$$\n\n### Conclusion\nWe have derived the identity using only the standard algebraic axioms of a Boolean algebra.\nTherefore, for any elements $a, b \\in B$, the identity $a \\vee (a \\wedge b) = a$ holds.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of general algebraic systems, along with a complete and verifiable solution.\n\n## Step 2: Identify the domain\nThe domain is general algebraic systems, which includes topics like groups, rings, fields, and other algebraic structures.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving a specific algebraic structure. A challenging problem could involve proving a property about a certain type of algebraic system.\n\n## Step 4: Create a specific problem\nConsider the following problem: \"Let $G$ be a finite group and $H$ be a subgroup of $G$. Suppose that $|G| = 2|H|$. Prove that $H$ is a normal subgroup of $G$.\"\n\n## Step 5: Verify the problem meets the quality rubric\n- **Well-Posedness and Completeness**: The problem is fully specified with $G$ being a finite group and $H$ a subgroup of $G$, and the condition $|G| = 2|H|$ is given.\n- **Clarity**: The terms are standard in group theory, and the task is clear.\n- **Non-Triviality**: The problem requires understanding of group theory and the concept of normal subgroups, making it non-trivial.\n- **Solvability and Verification**: The problem is solvable using established methods in group theory.\n\n## Step 6: Provide the solution\nTo prove that $H$ is a normal subgroup of $G$, we need to show that for any $g \\in G$ and $h \\in H$, $g^{-1}hg \\in H$.\n\n## Step 7: Break down the solution\nFirst, note that since $|G| = 2|H|$, $H$ has index 2 in $G$. This implies there are exactly two cosets of $H$ in $G$: $H$ itself and $G \\setminus H$.\n\n## Step 8: Analyze cosets\nFor any $g \\in G$, if $g \\in H$, then $gH = H$ and $Hg = H$, so $gH = Hg$. If $g \\notin H$, then $gH = G \\setminus H$ because there are only two cosets and $gH$ cannot be $H$. Similarly, $Hg = G \\setminus H$, so again $gH = Hg$.\n\n## Step 9: Conclude normality\nSince $gH = Hg$ for all $g \\in G$, $H$ is normal in $G$.\n\n## Step 10: Write the problem and solution in the required format\n\nLet $G$ be a finite group and $H$ be a subgroup of $G$. Suppose that $|G| = 2|H|$. Prove that $H$ is a normal subgroup of $G$.",
    "run_id": "5",
    "outer_attempt": 1,
    "topic_slug": "general_algebraic_systems",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Theorem Statement**\nLet $G$ be a finite group and $H$ be a subgroup of $G$ such that $|G| = 2|H|$. Then $H$ is a normal subgroup of $G$.\n\n**Proof**\n\n**1. Definition of Index and Cosets**\nBy Lagrange's Theorem, the index of the subgroup $H$ in $G$, denoted $[G:H]$, is given by the ratio of their orders:\n$$[G:H] = \\frac{|G|}{|H|} = 2$$\nThe index $[G:H]$ represents the number of distinct left cosets of $H$ in $G$. Similarly, it represents the number of distinct right cosets of $H$ in $G$. Thus, there are exactly two left cosets and exactly two right cosets.\n\n**2. Partition by Cosets**\nThe left cosets of $H$ form a partition of the group $G$. Since $H$ itself is always a left coset (specifically, $1 \\cdot H = H$), let the set of left cosets be $\\{H, L_2\\}$.\nSince these sets partition $G$, their union is $G$ and their intersection is empty:\n$$H \\cup L_2 = G \\quad \\text{and} \\quad H \\cap L_2 = \\emptyset$$\nThis implies that the second left coset $L_2$ must be the set complement of $H$ in $G$:\n$$L_2 = G \\setminus H$$\nTherefore, for any element $g \\in G$, the left coset $gH$ is determined by whether $g$ belongs to $H$:\n$$gH = \\begin{cases} H & \\text{if } g \\in H \\\\ G \\setminus H & \\text{if } g \\notin H \\end{cases}$$\n\nSimilarly, the right cosets of $H$ partition $G$. Since $H$ is a right coset ($H \\cdot 1 = H$), the set of right cosets is $\\{H, R_2\\}$, where $R_2$ is the set complement of $H$ in $G$.\n$$R_2 = G \\setminus H$$\nTherefore, for any element $g \\in G$, the right coset $Hg$ is:\n$$Hg = \\begin{cases} H & \\text{if } g \\in H \\\\ G \\setminus H & \\text{if } g \\notin H \\end{cases}$$\n\n**3. Verification of Normality**\nA subgroup $H$ is normal in $G$ (denoted $H \\trianglelefteq G$) if and only if the left coset $gH$ is equal to the right coset $Hg$ for every element $g \\in G$.\n\nWe examine two cases for an arbitrary element $g \\in G$:\n\n*   **Case 1: $g \\in H$**\n    By the closure property of subgroups, $gH = H$ and $Hg = H$.\n    Thus, $gH = Hg$.\n\n*   **Case 2: $g \\notin H$**\n    Since $g \\notin H$, the left coset $gH$ cannot be $H$. Since there are only two left cosets ($H$ and $G \\setminus H$), $gH$ must be $G \\setminus H$.\n    Similarly, since $g \\notin H$, the right coset $Hg$ cannot be $H$. Since there are only two right cosets ($H$ and $G \\setminus H$), $Hg$ must be $G \\setminus H$.\n    Thus, $gH = G \\setminus H = Hg$.\n\n**Conclusion**\nSince $gH = Hg$ for all $g \\in G$, $H$ is a normal subgroup of $G$.",
        "raw_answer": "**Theorem Statement**\nLet $G$ be a finite group and $H$ be a subgroup of $G$ such that $|G| = 2|H|$. Then $H$ is a normal subgroup of $G$.\n\n**Proof**\n\n**1. Definition of Index and Cosets**\nBy Lagrange's Theorem, the index of the subgroup $H$ in $G$, denoted $[G:H]$, is given by the ratio of their orders:\n$$[G:H] = \\frac{|G|}{|H|} = 2$$\nThe index $[G:H]$ represents the number of distinct left cosets of $H$ in $G$. Similarly, it represents the number of distinct right cosets of $H$ in $G$. Thus, there are exactly two left cosets and exactly two right cosets.\n\n**2. Partition by Cosets**\nThe left cosets of $H$ form a partition of the group $G$. Since $H$ itself is always a left coset (specifically, $1 \\cdot H = H$), let the set of left cosets be $\\{H, L_2\\}$.\nSince these sets partition $G$, their union is $G$ and their intersection is empty:\n$$H \\cup L_2 = G \\quad \\text{and} \\quad H \\cap L_2 = \\emptyset$$\nThis implies that the second left coset $L_2$ must be the set complement of $H$ in $G$:\n$$L_2 = G \\setminus H$$\nTherefore, for any element $g \\in G$, the left coset $gH$ is determined by whether $g$ belongs to $H$:\n$$gH = \\begin{cases} H & \\text{if } g \\in H \\\\ G \\setminus H & \\text{if } g \\notin H \\end{cases}$$\n\nSimilarly, the right cosets of $H$ partition $G$. Since $H$ is a right coset ($H \\cdot 1 = H$), the set of right cosets is $\\{H, R_2\\}$, where $R_2$ is the set complement of $H$ in $G$.\n$$R_2 = G \\setminus H$$\nTherefore, for any element $g \\in G$, the right coset $Hg$ is:\n$$Hg = \\begin{cases} H & \\text{if } g \\in H \\\\ G \\setminus H & \\text{if } g \\notin H \\end{cases}$$\n\n**3. Verification of Normality**\nA subgroup $H$ is normal in $G$ (denoted $H \\trianglelefteq G$) if and only if the left coset $gH$ is equal to the right coset $Hg$ for every element $g \\in G$.\n\nWe examine two cases for an arbitrary element $g \\in G$:\n\n*   **Case 1: $g \\in H$**\n    By the closure property of subgroups, $gH = H$ and $Hg = H$.\n    Thus, $gH = Hg$.\n\n*   **Case 2: $g \\notin H$**\n    Since $g \\notin H$, the left coset $gH$ cannot be $H$. Since there are only two left cosets ($H$ and $G \\setminus H$), $gH$ must be $G \\setminus H$.\n    Similarly, since $g \\notin H$, the right coset $Hg$ cannot be $H$. Since there are only two right cosets ($H$ and $G \\setminus H$), $Hg$ must be $G \\setminus H$.\n    Thus, $gH = G \\setminus H = Hg$.\n\n**Conclusion**\nSince $gH = Hg$ for all $g \\in G$, $H$ is a normal subgroup of $G$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $F$ be a field and let $p(x) = x^3 + ax + b \\in F[x]$ be a cubic polynomial with distinct roots in some extension field of $F$. Suppose that the discriminant of $p(x)$ is a square in $F$. Prove that the Galois group of $p(x)$ over $F$ is isomorphic to $\\mathbb{Z}/3\\mathbb{Z}$ if and only if $p(x)$ is irreducible over $F$.",
    "run_id": "6",
    "outer_attempt": 1,
    "topic_slug": "field_theory_and_polynomials",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To provide a rigorous proof, we must interpret the properties of the polynomial and its Galois group within the context of Field Theory.\n\n### Preliminaries and Assumptions\n\nLet $F$ be a field and $p(x) = x^3 + ax + b \\in F[x]$.\nLet $K$ be a splitting field of $p(x)$ over $F$.\nLet the roots of $p(x)$ in $K$ be $\\alpha_1, \\alpha_2, \\alpha_3$. The problem states these roots are distinct, so $p(x)$ is separable and the discriminant $\\Delta \\neq 0$.\nThe Galois group of $p(x)$ over $F$ is $G = \\text{Gal}(K/F)$. Since $G$ permutes the three roots, $G$ is isomorphic to a subgroup of the symmetric group $S_3$.\n\n**Assumption regarding Characteristic:**\nWe assume that the characteristic of $F$ is not 2.\n*Reasoning:* The relationship between the discriminant being a square and the Galois group being a subgroup of the alternating group $A_3$ relies on the property that for distinct roots, the square root of the discriminant $\\delta = \\prod_{i<j}(\\alpha_i - \\alpha_j)$ satisfies $\\delta \\neq -\\delta$. In characteristic 2, this distinction vanishes, and the discriminant is always a square in $F$, rendering the condition in the problem statement trivial and the equivalence false (e.g., an irreducible cubic in characteristic 2 can have Galois group $S_3$).\n\n### Step 1: The Discriminant and the Alternating Group\n\nThe discriminant of $p(x)$ is given by $\\Delta = \\prod_{1 \\le i < j \\le 3} (\\alpha_i - \\alpha_j)^2$.\nLet $\\delta = \\prod_{1 \\le i < j \\le 3} (\\alpha_i - \\alpha_j)$. Then $\\delta^2 = \\Delta$.\nFor any $\\sigma \\in G$, the action of $\\sigma$ on $\\delta$ is given by:\n$$ \\sigma(\\delta) = \\text{sgn}(\\sigma) \\delta $$\nwhere $\\text{sgn}(\\sigma)$ is the sign of the permutation ($1$ for even permutations, $-1$ for odd permutations).\n\n**Hypothesis:** The discriminant $\\Delta$ is a square in $F$.\nThis implies $\\delta \\in F$.\nSince $\\delta \\in F$, it is fixed by all automorphisms in the Galois group:\n$$ \\forall \\sigma \\in G, \\quad \\sigma(\\delta) = \\delta $$\nCombining this with the sign property:\n$$ \\text{sgn}(\\sigma) \\delta = \\delta $$\nSince roots are distinct, $\\Delta \\neq 0$, so $\\delta \\neq 0$. In characteristic $\\neq 2$, $\\delta \\neq -\\delta$. Therefore:\n$$ \\text{sgn}(\\sigma) = 1 \\quad \\forall \\sigma \\in G $$\nThis implies that $G$ consists only of even permutations. Thus, $G$ is a subgroup of the alternating group $A_3$.\n\nThe subgroups of $S_3$ contained in $A_3$ are:\n1.  The trivial group $\\{e\\}$ (Order 1).\n2.  The alternating group $A_3 = \\{e, (123), (132)\\}$ (Order 3). Note that $A_3 \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n\nThus, given the discriminant condition, we have established that $G \\cong \\{e\\}$ or $G \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n\n### Step 2: Proof of Equivalence\n\nWe must prove: $G \\cong \\mathbb{Z}/3\\mathbb{Z} \\iff p(x)$ is irreducible over $F$.\n\n#### Part A: ($p(x)$ is irreducible $\\implies G \\cong \\mathbb{Z}/3\\mathbb{Z}$)\n\n1.  Assume $p(x)$ is irreducible over $F$.\n2.  Let $\\alpha_1$ be a root of $p(x)$. Since $p(x)$ is irreducible, the degree of the extension $F(\\alpha_1)/F$ is equal to the degree of the polynomial:\n    $$ [F(\\alpha_1) : F] = 3 $$\n3.  Since $K$ is the splitting field, $F \\subseteq F(\\alpha_1) \\subseteq K$. By the tower law, $[K:F] = [K:F(\\alpha_1)][F(\\alpha_1):F]$.\n4.  Therefore, $[F(\\alpha_1):F]$ divides $[K:F]$. Since $|G| = [K:F]$, we have $3 \\mid |G|$.\n5.  From Step 1, we know $G \\subseteq A_3$, so $|G|$ must divide $|A_3| = 3$.\n6.  The only positive integer that divides 3 and is divisible by 3 is 3.\n7.  Thus, $|G| = 3$. The only group of order 3 is the cyclic group $\\mathbb{Z}/3\\mathbb{Z}$.\n    $$ G \\cong \\mathbb{Z}/3\\mathbb{Z} $$\n\n#### Part B: ($G \\cong \\mathbb{Z}/3\\mathbb{Z} \\implies p(x)$ is irreducible)\n\n1.  Assume $G \\cong \\mathbb{Z}/3\\mathbb{Z}$. The elements of $G$ viewed as permutations of roots $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$ are $\\{e, (123), (132)\\}$.\n2.  The group $G$ acts transitively on the set of roots. (The orbit of any root $\\alpha_i$ is the entire set $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$).\n3.  **Transitivity implies irreducibility:**\n    If $p(x)$ were reducible over $F$, it would factor into polynomials of lower degree in $F[x]$.\n    Let $p(x) = f(x)g(x)$ with $\\deg(f) \\ge 1, \\deg(g) \\ge 1$.\n    The roots of $f(x)$ would form a subset of $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$ that is mapped to itself by all $\\sigma \\in G$ (since $\\sigma$ fixes coefficients in $F$, it maps roots of $f$ to roots of $f$).\n    This would imply the action of $G$ on the roots is not transitive (there would be an orbit of size $\\deg(f) < 3$).\n4.  Since the action is transitive, $p(x)$ cannot satisfy the condition of reducibility.\n    (Alternatively: The orbit of $\\alpha_1$ is the set of roots of its minimal polynomial. The size of the orbit is 3, so the minimal polynomial has degree 3. Since $p(x)$ is monic of degree 3 and shares a root with this minimal polynomial, $p(x)$ is the minimal polynomial, hence irreducible).\n5.  Therefore, $p(x)$ is irreducible over $F$.\n\n### Conclusion\n\nWe have shown that if the discriminant of the cubic polynomial $p(x)$ is a square in $F$ (and char $F \\neq 2$), then $G$ is a subgroup of $A_3$. Under this condition:\n- If $p(x)$ is irreducible, $|G|=3$, so $G \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n- If $G \\cong \\mathbb{Z}/3\\mathbb{Z}$, the transitive action on roots implies $p(x)$ is irreducible.\n\nThus, $\\text{Gal}(p(x)/F) \\cong \\mathbb{Z}/3\\mathbb{Z}$ if and only if $p(x)$ is irreducible over $F$.",
        "raw_answer": "To provide a rigorous proof, we must interpret the properties of the polynomial and its Galois group within the context of Field Theory.\n\n### Preliminaries and Assumptions\n\nLet $F$ be a field and $p(x) = x^3 + ax + b \\in F[x]$.\nLet $K$ be a splitting field of $p(x)$ over $F$.\nLet the roots of $p(x)$ in $K$ be $\\alpha_1, \\alpha_2, \\alpha_3$. The problem states these roots are distinct, so $p(x)$ is separable and the discriminant $\\Delta \\neq 0$.\nThe Galois group of $p(x)$ over $F$ is $G = \\text{Gal}(K/F)$. Since $G$ permutes the three roots, $G$ is isomorphic to a subgroup of the symmetric group $S_3$.\n\n**Assumption regarding Characteristic:**\nWe assume that the characteristic of $F$ is not 2.\n*Reasoning:* The relationship between the discriminant being a square and the Galois group being a subgroup of the alternating group $A_3$ relies on the property that for distinct roots, the square root of the discriminant $\\delta = \\prod_{i<j}(\\alpha_i - \\alpha_j)$ satisfies $\\delta \\neq -\\delta$. In characteristic 2, this distinction vanishes, and the discriminant is always a square in $F$, rendering the condition in the problem statement trivial and the equivalence false (e.g., an irreducible cubic in characteristic 2 can have Galois group $S_3$).\n\n### Step 1: The Discriminant and the Alternating Group\n\nThe discriminant of $p(x)$ is given by $\\Delta = \\prod_{1 \\le i < j \\le 3} (\\alpha_i - \\alpha_j)^2$.\nLet $\\delta = \\prod_{1 \\le i < j \\le 3} (\\alpha_i - \\alpha_j)$. Then $\\delta^2 = \\Delta$.\nFor any $\\sigma \\in G$, the action of $\\sigma$ on $\\delta$ is given by:\n$$ \\sigma(\\delta) = \\text{sgn}(\\sigma) \\delta $$\nwhere $\\text{sgn}(\\sigma)$ is the sign of the permutation ($1$ for even permutations, $-1$ for odd permutations).\n\n**Hypothesis:** The discriminant $\\Delta$ is a square in $F$.\nThis implies $\\delta \\in F$.\nSince $\\delta \\in F$, it is fixed by all automorphisms in the Galois group:\n$$ \\forall \\sigma \\in G, \\quad \\sigma(\\delta) = \\delta $$\nCombining this with the sign property:\n$$ \\text{sgn}(\\sigma) \\delta = \\delta $$\nSince roots are distinct, $\\Delta \\neq 0$, so $\\delta \\neq 0$. In characteristic $\\neq 2$, $\\delta \\neq -\\delta$. Therefore:\n$$ \\text{sgn}(\\sigma) = 1 \\quad \\forall \\sigma \\in G $$\nThis implies that $G$ consists only of even permutations. Thus, $G$ is a subgroup of the alternating group $A_3$.\n\nThe subgroups of $S_3$ contained in $A_3$ are:\n1.  The trivial group $\\{e\\}$ (Order 1).\n2.  The alternating group $A_3 = \\{e, (123), (132)\\}$ (Order 3). Note that $A_3 \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n\nThus, given the discriminant condition, we have established that $G \\cong \\{e\\}$ or $G \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n\n### Step 2: Proof of Equivalence\n\nWe must prove: $G \\cong \\mathbb{Z}/3\\mathbb{Z} \\iff p(x)$ is irreducible over $F$.\n\n#### Part A: ($p(x)$ is irreducible $\\implies G \\cong \\mathbb{Z}/3\\mathbb{Z}$)\n\n1.  Assume $p(x)$ is irreducible over $F$.\n2.  Let $\\alpha_1$ be a root of $p(x)$. Since $p(x)$ is irreducible, the degree of the extension $F(\\alpha_1)/F$ is equal to the degree of the polynomial:\n    $$ [F(\\alpha_1) : F] = 3 $$\n3.  Since $K$ is the splitting field, $F \\subseteq F(\\alpha_1) \\subseteq K$. By the tower law, $[K:F] = [K:F(\\alpha_1)][F(\\alpha_1):F]$.\n4.  Therefore, $[F(\\alpha_1):F]$ divides $[K:F]$. Since $|G| = [K:F]$, we have $3 \\mid |G|$.\n5.  From Step 1, we know $G \\subseteq A_3$, so $|G|$ must divide $|A_3| = 3$.\n6.  The only positive integer that divides 3 and is divisible by 3 is 3.\n7.  Thus, $|G| = 3$. The only group of order 3 is the cyclic group $\\mathbb{Z}/3\\mathbb{Z}$.\n    $$ G \\cong \\mathbb{Z}/3\\mathbb{Z} $$\n\n#### Part B: ($G \\cong \\mathbb{Z}/3\\mathbb{Z} \\implies p(x)$ is irreducible)\n\n1.  Assume $G \\cong \\mathbb{Z}/3\\mathbb{Z}$. The elements of $G$ viewed as permutations of roots $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$ are $\\{e, (123), (132)\\}$.\n2.  The group $G$ acts transitively on the set of roots. (The orbit of any root $\\alpha_i$ is the entire set $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$).\n3.  **Transitivity implies irreducibility:**\n    If $p(x)$ were reducible over $F$, it would factor into polynomials of lower degree in $F[x]$.\n    Let $p(x) = f(x)g(x)$ with $\\deg(f) \\ge 1, \\deg(g) \\ge 1$.\n    The roots of $f(x)$ would form a subset of $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$ that is mapped to itself by all $\\sigma \\in G$ (since $\\sigma$ fixes coefficients in $F$, it maps roots of $f$ to roots of $f$).\n    This would imply the action of $G$ on the roots is not transitive (there would be an orbit of size $\\deg(f) < 3$).\n4.  Since the action is transitive, $p(x)$ cannot satisfy the condition of reducibility.\n    (Alternatively: The orbit of $\\alpha_1$ is the set of roots of its minimal polynomial. The size of the orbit is 3, so the minimal polynomial has degree 3. Since $p(x)$ is monic of degree 3 and shares a root with this minimal polynomial, $p(x)$ is the minimal polynomial, hence irreducible).\n5.  Therefore, $p(x)$ is irreducible over $F$.\n\n### Conclusion\n\nWe have shown that if the discriminant of the cubic polynomial $p(x)$ is a square in $F$ (and char $F \\neq 2$), then $G$ is a subgroup of $A_3$. Under this condition:\n- If $p(x)$ is irreducible, $|G|=3$, so $G \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n- If $G \\cong \\mathbb{Z}/3\\mathbb{Z}$, the transitive action on roots implies $p(x)$ is irreducible.\n\nThus, $\\text{Gal}(p(x)/F) \\cong \\mathbb{Z}/3\\mathbb{Z}$ if and only if $p(x)$ is irreducible over $F$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of commutative algebra, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic in commutative algebra\nCommutative algebra involves the study of commutative rings and their ideals, modules, and algebras. A challenging problem could involve understanding the properties of ideals, quotient rings, or the behavior of polynomials over certain rings.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the properties of ideals in a polynomial ring. Specifically, we can examine the ideal generated by a set of polynomials and ask questions about its properties, such as whether it is prime or maximal.\n\n## Step 4: Construct the problem\nConsider the polynomial ring $\\mathbb{Q}[x, y]$ and the ideal $I = (x^2 + y^2, xy)$. We can ask: Is the ideal $I$ prime? To make it more challenging and ensure it's well-posed, we can ask to determine whether $I$ is radical, i.e., whether it is equal to its radical $\\sqrt{I}$.\n\n## Step 5: Write down the problem statement\nLet $I = (x^2 + y^2, xy)$ be an ideal in $\\mathbb{Q}[x, y]$. Determine whether $I = \\sqrt{I}$, where $\\sqrt{I} = \\{f \\in \\mathbb{Q}[x, y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N}\\}$.\n\n## Step 6: Provide the solution\nTo determine if $I = \\sqrt{I}$, we first need to understand what $\\sqrt{I}$ is. An element $f \\in \\mathbb{Q}[x, y]$ is in $\\sqrt{I}$ if $f^n \\in I$ for some $n$. We need to check if there are elements in $\\sqrt{I}$ that are not in $I$.\n\n## Step 7: Analyze the ideal $I$\nTo check if $I = \\sqrt{I}$, let's first examine the quotient ring $\\mathbb{Q}[x, y]/I$. The ideal $I$ contains $x^2 + y^2$ and $xy$, which implies that $x^2 + y^2$ and $xy$ are zero in $\\mathbb{Q}[x, y]/I$. We can simplify this by observing that $x^2y + y^3 = 0$ and $x^2y = 0$ in $\\mathbb{Q}[x, y]/I$, implying $y^3 = 0$ in $\\mathbb{Q}[x, y]/I$. Similarly, $x^3 = 0$.\n\n## Step 8: Check if $I$ is radical\nSince $x^3 = 0$ and $y^3 = 0$ in $\\mathbb{Q}[x, y]/I$, it follows that $x, y \\in \\sqrt{I}$ because $x^3, y^3 \\in I$. We need to verify if $x$ and $y$ are in $I$. If not, then $I \\neq \\sqrt{I}$.\n\n## Step 9: Verify if $x$ and $y$ are in $I$\nTo check if $x \\in I$, we need to see if there exist $f, g \\in \\mathbb{Q}[x, y]$ such that $x = f(x^2 + y^2) + g(xy)$. This simplifies to checking if $x$ can be expressed as a combination of $x^2 + y^2$ and $xy$, which is not possible because any element in $I$ is of degree at least 2.\n\n## Step 10: Conclude on $I = \\sqrt{I}$\nSince $x, y \\in \\sqrt{I}$ but $x, y \\notin I$, it follows that $I \\neq \\sqrt{I}$. Thus, $I$ is not radical.\n\nThe final answer is: \n\nLet $I = (x^2 + y^2, xy)$ be an ideal in $\\mathbb{Q}[x, y]$. Determine whether $I = \\sqrt{I}$, where $\\sqrt{I} = \\{f \\in \\mathbb{Q}[x, y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N}\\}$.",
    "run_id": "7",
    "outer_attempt": 1,
    "topic_slug": "commutative_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To determine whether the ideal $I = (x^2 + y^2, xy)$ in $\\mathbb{Q}[x, y]$ is equal to its radical $\\sqrt{I}$, we must verify if the condition $f \\in \\sqrt{I} \\implies f \\in I$ holds for all $f \\in \\mathbb{Q}[x, y]$.\n\n**Final Answer:**\nThe ideal $I$ is **not** equal to its radical $\\sqrt{I}$. That is, $I \\neq \\sqrt{I}$.\n\n**Proof:**\n\nTo prove that $I \\neq \\sqrt{I}$, it suffices to find a polynomial $f \\in \\mathbb{Q}[x, y]$ such that $f \\in \\sqrt{I}$ but $f \\notin I$.\n\n**Step 1: Analyze the degree of elements in $I$.**\nThe ideal $I$ is generated by two homogeneous polynomials of degree $2$: $g_1 = x^2 + y^2$ and $g_2 = xy$.\nAny element $h \\in I$ can be written as:\n$$h(x, y) = A(x, y)(x^2 + y^2) + B(x, y)(xy)$$\nfor some polynomials $A, B \\in \\mathbb{Q}[x, y]$.\n\nIf $h$ is not the zero polynomial, its degree is determined by the degrees of the generators. Since $\\mathbb{Q}[x, y]$ is an integral domain, $\\deg(P \\cdot Q) = \\deg(P) + \\deg(Q)$. Thus:\n$$\\deg(A \\cdot (x^2 + y^2)) = \\deg(A) + 2 \\geq 2 \\quad (\\text{if } A \\neq 0)$$\n$$\\deg(B \\cdot (xy)) = \\deg(B) + 2 \\geq 2 \\quad (\\text{if } B \\neq 0)$$\nConsequently, any non-zero polynomial in $I$ must have a total degree of at least $2$.\nThis implies that no polynomial of degree $1$ belongs to $I$. Specifically:\n$$x \\notin I \\quad \\text{and} \\quad y \\notin I$$\n\n**Step 2: Identify an element in $\\sqrt{I}$.**\nBy definition, $f \\in \\sqrt{I}$ if there exists an integer $n \\geq 1$ such that $f^n \\in I$. Let us test $f(x, y) = x$. We will check if $x^3 \\in I$.\n\nConsider the expression $x(x^2 + y^2)$:\n$$x(x^2 + y^2) = x^3 + xy^2$$\nWe can isolate $x^3$:\n$$x^3 = x(x^2 + y^2) - xy^2$$\nNotice that $xy^2 = y(xy)$. Since $x^2 + y^2 \\in I$ and $xy \\in I$, we have:\n$$x(x^2 + y^2) \\in I \\quad \\text{and} \\quad y(xy) \\in I$$\nSince $I$ is closed under subtraction, their difference is also in $I$:\n$$x^3 = x(x^2 + y^2) - y(xy) \\in I$$\n\n**Step 3: Conclusion.**\nWe have established the following:\n1.  $x^3 \\in I$, which implies $x \\in \\sqrt{I}$ by the definition of the radical.\n2.  $x \\notin I$, because $x$ has degree $1$ and all non-zero elements of $I$ have degree at least $2$.\n\nSince there exists an element $x$ in $\\sqrt{I}$ that is not in $I$, the ideal $I$ is not radical.\n\nTherefore, **$I \\neq \\sqrt{I}$**.",
        "raw_answer": "To determine whether the ideal $I = (x^2 + y^2, xy)$ in $\\mathbb{Q}[x, y]$ is equal to its radical $\\sqrt{I}$, we must verify if the condition $f \\in \\sqrt{I} \\implies f \\in I$ holds for all $f \\in \\mathbb{Q}[x, y]$.\n\n**Final Answer:**\nThe ideal $I$ is **not** equal to its radical $\\sqrt{I}$. That is, $I \\neq \\sqrt{I}$.\n\n**Proof:**\n\nTo prove that $I \\neq \\sqrt{I}$, it suffices to find a polynomial $f \\in \\mathbb{Q}[x, y]$ such that $f \\in \\sqrt{I}$ but $f \\notin I$.\n\n**Step 1: Analyze the degree of elements in $I$.**\nThe ideal $I$ is generated by two homogeneous polynomials of degree $2$: $g_1 = x^2 + y^2$ and $g_2 = xy$.\nAny element $h \\in I$ can be written as:\n$$h(x, y) = A(x, y)(x^2 + y^2) + B(x, y)(xy)$$\nfor some polynomials $A, B \\in \\mathbb{Q}[x, y]$.\n\nIf $h$ is not the zero polynomial, its degree is determined by the degrees of the generators. Since $\\mathbb{Q}[x, y]$ is an integral domain, $\\deg(P \\cdot Q) = \\deg(P) + \\deg(Q)$. Thus:\n$$\\deg(A \\cdot (x^2 + y^2)) = \\deg(A) + 2 \\geq 2 \\quad (\\text{if } A \\neq 0)$$\n$$\\deg(B \\cdot (xy)) = \\deg(B) + 2 \\geq 2 \\quad (\\text{if } B \\neq 0)$$\nConsequently, any non-zero polynomial in $I$ must have a total degree of at least $2$.\nThis implies that no polynomial of degree $1$ belongs to $I$. Specifically:\n$$x \\notin I \\quad \\text{and} \\quad y \\notin I$$\n\n**Step 2: Identify an element in $\\sqrt{I}$.**\nBy definition, $f \\in \\sqrt{I}$ if there exists an integer $n \\geq 1$ such that $f^n \\in I$. Let us test $f(x, y) = x$. We will check if $x^3 \\in I$.\n\nConsider the expression $x(x^2 + y^2)$:\n$$x(x^2 + y^2) = x^3 + xy^2$$\nWe can isolate $x^3$:\n$$x^3 = x(x^2 + y^2) - xy^2$$\nNotice that $xy^2 = y(xy)$. Since $x^2 + y^2 \\in I$ and $xy \\in I$, we have:\n$$x(x^2 + y^2) \\in I \\quad \\text{and} \\quad y(xy) \\in I$$\nSince $I$ is closed under subtraction, their difference is also in $I$:\n$$x^3 = x(x^2 + y^2) - y(xy) \\in I$$\n\n**Step 3: Conclusion.**\nWe have established the following:\n1.  $x^3 \\in I$, which implies $x \\in \\sqrt{I}$ by the definition of the radical.\n2.  $x \\notin I$, because $x$ has degree $1$ and all non-zero elements of $I$ have degree at least $2$.\n\nSince there exists an element $x$ in $\\sqrt{I}$ that is not in $I$, the ideal $I$ is not radical.\n\nTherefore, **$I \\neq \\sqrt{I}$**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of algebraic geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within algebraic geometry\nAlgebraic geometry is a broad field that involves the study of geometric objects, such as varieties and schemes, using tools from abstract algebra. A suitable topic could involve the study of curves, surfaces, or higher-dimensional varieties, and their properties.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the intersection of curves on a surface. A classic result in algebraic geometry is B\u00e9zout's theorem, which describes the intersection of two curves on a projective plane. We can formulate a problem related to this.\n\n## Step 4: State the problem\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.\n\n## Step 5: Provide the solution\nTo find the intersection points, we need to solve the system of equations given by $f(x,y,z) = 0$ and $g(x,y,z) = 0$. This means we have to solve $x^2 + y^2 - z^2 = 0$ and $xy - z^2 = 0$ simultaneously.\n\n## Step 6: Solve the system of equations\nFirst, from $xy - z^2 = 0$, we can express $z^2 = xy$. Substituting $z^2$ into the first equation gives $x^2 + y^2 - xy = 0$. This is a homogeneous equation in $x$ and $y$, which can be solved by considering it as a quadratic form.\n\n## Step 7: Analyze the quadratic form\nThe equation $x^2 - xy + y^2 = 0$ can be analyzed by finding its roots. This is equivalent to solving $x^2 - xy + y^2 = 0$ for $x$ in terms of $y$ (or vice versa), treating it as a quadratic equation.\n\n## Step 8: Solve for $x$ in terms of $y$\nUsing the quadratic formula, $x = \\frac{y \\pm \\sqrt{y^2 - 4y^2}}{2} = \\frac{y \\pm \\sqrt{-3y^2}}{2}$. For $y \\neq 0$, this simplifies to $x = \\frac{y(1 \\pm i\\sqrt{3})}{2}$. Thus, $x = y\\omega$ or $x = y\\omega^2$, where $\\omega$ is a primitive third root of unity.\n\n## Step 9: Determine the intersection points\nFor $x = y\\omega$ and $x = y\\omega^2$, substituting back into $xy = z^2$ gives $y^2\\omega = z^2$ and $y^2\\omega^2 = z^2$, respectively. This implies $z = \\pm y\\sqrt{\\omega}$ and $z = \\pm y\\sqrt{\\omega^2}$. However, we must consider the projective nature and the fact that we're working with homogeneous coordinates.\n\n## Step 10: Count the intersection points with multiplicity\nSince $\\omega$ and $\\omega^2$ are not real, and we're working over $\\mathbb{C}$, we need to consider the solutions in $\\mathbb{P}^2(\\mathbb{C})$. The solutions are given by the pairs $(x:y:z)$ satisfying both equations. We need to check if there are any solutions where $y = 0$, which would imply $x = 0$ and thus $z = 0$, but $(0,0,0)$ is not a valid point in $\\mathbb{P}^2$.\n\n## Step 11: Apply B\u00e9zout's theorem for a simpler solution\nB\u00e9zout's theorem states that two curves of degrees $d_1$ and $d_2$ intersect in $d_1d_2$ points, counted with multiplicity, if they have no common components. Here, $C_1$ and $C_2$ are both of degree 2, so they should intersect in $2 \\times 2 = 4$ points.\n\nThe final answer is: \n\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.",
    "run_id": "8",
    "outer_attempt": 1,
    "topic_slug": "algebraic_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the number of intersection points of the curves $C_1$ and $C_2$ in the complex projective plane $\\mathbb{P}^2$, counted with multiplicity, we will analyze the system of homogeneous equations defined by the polynomials $f$ and $g$.\n\n### 1. Problem Statement\nLet the two curves be defined by the homogeneous polynomials:\n$$f(x,y,z) = x^2 + y^2 - z^2 = 0$$\n$$g(x,y,z) = xy - z^2 = 0$$\nWe seek the number of solutions to this system in $\\mathbb{P}^2$, counted with intersection multiplicity. We assume the ground field is the field of complex numbers $\\mathbb{C}$, as is standard for intersection theory in algebraic geometry.\n\n### 2. Application of B\u00e9zout's Theorem\nB\u00e9zout's Theorem states that for two plane projective curves of degrees $d_1$ and $d_2$ defined over an algebraically closed field, if they do not share a common component, the number of intersection points counted with multiplicity is exactly $d_1 \\cdot d_2$.\n\n**Checking Degrees:**\n- $f(x,y,z)$ is a polynomial of degree $d_1 = 2$.\n- $g(x,y,z)$ is a polynomial of degree $d_2 = 2$.\n\n**Checking for Common Components:**\nBoth $f$ and $g$ define conics.\n- $g(x,y,z) = xy - z^2$ is an irreducible quadratic form (it corresponds to a non-degenerate conic, specifically identifiable as the Veronese embedding of $\\mathbb{P}^1$ or simply by noting it cannot be factored into linear terms).\n- $f(x,y,z) = x^2 + y^2 - z^2$ is also irreducible.\n- For them to share a common component, since they are both irreducible and of the same degree, they would have to be proportional. That is, $f = k \\cdot g$ for some constant $k$. Clearly, $x^2 + y^2 - z^2$ is not a scalar multiple of $xy - z^2$.\n\nThus, the curves have no common components. By B\u00e9zout's Theorem, the number of intersection points is:\n$$N = d_1 \\cdot d_2 = 2 \\cdot 2 = 4$$\n\n### 3. Explicit Verification of Intersection Points\nTo ensure rigor and verify that the multiplicities behave as expected (i.e., we don't have tangencies summing to 4, but rather 4 distinct points), we solve the system explicitly.\n\nThe system is:\n1. $x^2 + y^2 = z^2$\n2. $xy = z^2$\n\nSubstitute equation (2) into equation (1):\n$$x^2 + y^2 = xy$$\n$$x^2 - xy + y^2 = 0$$\n\nWe look for solutions $[x:y:z]$ in $\\mathbb{P}^2$. Note that $(0,0,0)$ is not a valid projective point.\nIf $y = 0$, the equation $x^2 - x(0) + 0 = 0$ implies $x = 0$. Then $z^2 = xy = 0 \\implies z=0$. Since $[0:0:0]$ is not valid, we must have $y \\neq 0$.\n\nSince $y \\neq 0$, we can dehomogenize by setting $y = 1$. The equation becomes:\n$$x^2 - x + 1 = 0$$\n\nThe roots of this quadratic equation are:\n$$x = \\frac{1 \\pm \\sqrt{1 - 4}}{2} = \\frac{1 \\pm i\\sqrt{3}}{2}$$\nLet $\\omega = e^{i\\pi/3} = \\frac{1 + i\\sqrt{3}}{2}$ and $\\bar{\\omega} = e^{-i\\pi/3} = \\frac{1 - i\\sqrt{3}}{2}$.\nSo, $x \\in \\{\\omega, \\bar{\\omega}\\}$.\n\nNow we solve for $z$ using $z^2 = xy$. Since $y=1$, $z^2 = x$.\n\n**Case 1: $x = \\omega$**\n$$z^2 = \\omega$$\nThis yields two distinct solutions for $z$: $z_1 = \\sqrt{\\omega}$ and $z_2 = -\\sqrt{\\omega}$.\nThis gives two intersection points:\n$$P_1 = [\\omega : 1 : \\sqrt{\\omega}]$$\n$$P_2 = [\\omega : 1 : -\\sqrt{\\omega}]$$\n\n**Case 2: $x = \\bar{\\omega}$**\n$$z^2 = \\bar{\\omega}$$\nThis yields two distinct solutions for $z$: $z_3 = \\sqrt{\\bar{\\omega}}$ and $z_4 = -\\sqrt{\\bar{\\omega}}$.\nThis gives two intersection points:\n$$P_3 = [\\bar{\\omega} : 1 : \\sqrt{\\bar{\\omega}}]$$\n$$P_4 = [\\bar{\\omega} : 1 : -\\sqrt{\\bar{\\omega}}]$$\n\n**Analysis of Multiplicity:**\nWe have found 4 distinct points ($P_1, P_2, P_3, P_4$).\nSince the sum of multiplicities must be 4 (by B\u00e9zout's Theorem), and there are 4 distinct solutions, each solution must have multiplicity exactly 1. This means the curves intersect transversally at all 4 points.\n\n### 4. Conclusion\nThe curves $C_1$ and $C_2$ intersect at exactly 4 distinct points. Summing their multiplicities:\n\n$$ \\sum_{P \\in C_1 \\cap C_2} m_P(C_1, C_2) = 4 $$\n\n**Answer:**\nThe number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity, is **4**.",
        "raw_answer": "To find the number of intersection points of the curves $C_1$ and $C_2$ in the complex projective plane $\\mathbb{P}^2$, counted with multiplicity, we will analyze the system of homogeneous equations defined by the polynomials $f$ and $g$.\n\n### 1. Problem Statement\nLet the two curves be defined by the homogeneous polynomials:\n$$f(x,y,z) = x^2 + y^2 - z^2 = 0$$\n$$g(x,y,z) = xy - z^2 = 0$$\nWe seek the number of solutions to this system in $\\mathbb{P}^2$, counted with intersection multiplicity. We assume the ground field is the field of complex numbers $\\mathbb{C}$, as is standard for intersection theory in algebraic geometry.\n\n### 2. Application of B\u00e9zout's Theorem\nB\u00e9zout's Theorem states that for two plane projective curves of degrees $d_1$ and $d_2$ defined over an algebraically closed field, if they do not share a common component, the number of intersection points counted with multiplicity is exactly $d_1 \\cdot d_2$.\n\n**Checking Degrees:**\n- $f(x,y,z)$ is a polynomial of degree $d_1 = 2$.\n- $g(x,y,z)$ is a polynomial of degree $d_2 = 2$.\n\n**Checking for Common Components:**\nBoth $f$ and $g$ define conics.\n- $g(x,y,z) = xy - z^2$ is an irreducible quadratic form (it corresponds to a non-degenerate conic, specifically identifiable as the Veronese embedding of $\\mathbb{P}^1$ or simply by noting it cannot be factored into linear terms).\n- $f(x,y,z) = x^2 + y^2 - z^2$ is also irreducible.\n- For them to share a common component, since they are both irreducible and of the same degree, they would have to be proportional. That is, $f = k \\cdot g$ for some constant $k$. Clearly, $x^2 + y^2 - z^2$ is not a scalar multiple of $xy - z^2$.\n\nThus, the curves have no common components. By B\u00e9zout's Theorem, the number of intersection points is:\n$$N = d_1 \\cdot d_2 = 2 \\cdot 2 = 4$$\n\n### 3. Explicit Verification of Intersection Points\nTo ensure rigor and verify that the multiplicities behave as expected (i.e., we don't have tangencies summing to 4, but rather 4 distinct points), we solve the system explicitly.\n\nThe system is:\n1. $x^2 + y^2 = z^2$\n2. $xy = z^2$\n\nSubstitute equation (2) into equation (1):\n$$x^2 + y^2 = xy$$\n$$x^2 - xy + y^2 = 0$$\n\nWe look for solutions $[x:y:z]$ in $\\mathbb{P}^2$. Note that $(0,0,0)$ is not a valid projective point.\nIf $y = 0$, the equation $x^2 - x(0) + 0 = 0$ implies $x = 0$. Then $z^2 = xy = 0 \\implies z=0$. Since $[0:0:0]$ is not valid, we must have $y \\neq 0$.\n\nSince $y \\neq 0$, we can dehomogenize by setting $y = 1$. The equation becomes:\n$$x^2 - x + 1 = 0$$\n\nThe roots of this quadratic equation are:\n$$x = \\frac{1 \\pm \\sqrt{1 - 4}}{2} = \\frac{1 \\pm i\\sqrt{3}}{2}$$\nLet $\\omega = e^{i\\pi/3} = \\frac{1 + i\\sqrt{3}}{2}$ and $\\bar{\\omega} = e^{-i\\pi/3} = \\frac{1 - i\\sqrt{3}}{2}$.\nSo, $x \\in \\{\\omega, \\bar{\\omega}\\}$.\n\nNow we solve for $z$ using $z^2 = xy$. Since $y=1$, $z^2 = x$.\n\n**Case 1: $x = \\omega$**\n$$z^2 = \\omega$$\nThis yields two distinct solutions for $z$: $z_1 = \\sqrt{\\omega}$ and $z_2 = -\\sqrt{\\omega}$.\nThis gives two intersection points:\n$$P_1 = [\\omega : 1 : \\sqrt{\\omega}]$$\n$$P_2 = [\\omega : 1 : -\\sqrt{\\omega}]$$\n\n**Case 2: $x = \\bar{\\omega}$**\n$$z^2 = \\bar{\\omega}$$\nThis yields two distinct solutions for $z$: $z_3 = \\sqrt{\\bar{\\omega}}$ and $z_4 = -\\sqrt{\\bar{\\omega}}$.\nThis gives two intersection points:\n$$P_3 = [\\bar{\\omega} : 1 : \\sqrt{\\bar{\\omega}}]$$\n$$P_4 = [\\bar{\\omega} : 1 : -\\sqrt{\\bar{\\omega}}]$$\n\n**Analysis of Multiplicity:**\nWe have found 4 distinct points ($P_1, P_2, P_3, P_4$).\nSince the sum of multiplicities must be 4 (by B\u00e9zout's Theorem), and there are 4 distinct solutions, each solution must have multiplicity exactly 1. This means the curves intersect transversally at all 4 points.\n\n### 4. Conclusion\nThe curves $C_1$ and $C_2$ intersect at exactly 4 distinct points. Summing their multiplicities:\n\n$$ \\sum_{P \\in C_1 \\cap C_2} m_P(C_1, C_2) = 4 $$\n\n**Answer:**\nThe number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity, is **4**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Linear and multilinear algebra; matrix theory, along with a complete and verifiable solution.\n\n## Step 2: Identify the key elements of a well-posed problem\nThe problem must be fully self-contained, clear, non-trivial, solvable, and verifiable. It should involve sophisticated techniques from linear and multilinear algebra or matrix theory.\n\n## Step 3: Generate a problem that fits the criteria\nLet's consider a problem that involves matrix theory and requires a good understanding of linear algebra concepts. A potential problem could involve proving a property of matrices or finding a specific matrix that satisfies certain conditions.\n\n## Step 4: Formulate the problem\nConsider the following problem: \"Let $A$ be a $3 \\times 3$ real matrix such that $A^3 = I$, where $I$ is the $3 \\times 3$ identity matrix. Prove that $A$ is diagonalizable over $\\mathbb{C}$.\"\n\n## Step 5: Verify that the problem is well-posed and solvable\nThe problem is well-posed because it specifies the domain of $A$ (real $3 \\times 3$ matrices), gives a clear condition ($A^3 = I$), and asks for a specific proof (that $A$ is diagonalizable over $\\mathbb{C}$). It is solvable using established methods in linear algebra.\n\n## Step 6: Provide a complete solution to the problem\nTo solve this, we note that $A$ satisfies the polynomial $x^3 - 1 = 0$. This polynomial factors as $(x-1)(x^2 + x + 1) = 0$. The roots are $1$, $e^{2\\pi i/3}$, and $e^{4\\pi i/3}$. Since $A$ satisfies this polynomial, its eigenvalues must be among these roots. Because the minimal polynomial of $A$ divides $x^3 - 1$ and has distinct roots (since $x^3 - 1$ has distinct roots), $A$ is diagonalizable over $\\mathbb{C}$.\n\n## Step 7: Write the problem and solution in the required format\n\nLet $A$ be a $3 \\times 3$ real matrix such that $A^3 = I$, where $I$ is the $3 \\times 3$ identity matrix. Prove that $A$ is diagonalizable over $\\mathbb{C}$.",
    "run_id": "9",
    "outer_attempt": 1,
    "topic_slug": "linear_and_multilinear_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Theorem Statement**\nLet $A$ be a $3 \\times 3$ real matrix such that $A^3 = I$, where $I$ is the $3 \\times 3$ identity matrix. Then $A$ is diagonalizable over $\\mathbb{C}$.\n\n**Proof**\n\n**1. Identification of an Annihilating Polynomial**\nWe are given that the matrix $A$ satisfies the equation:\n$$ A^3 - I = 0 $$\nConsider the polynomial $P(x) \\in \\mathbb{C}[x]$ defined by:\n$$ P(x) = x^3 - 1 $$\nSubstituting $A$ into this polynomial yields $P(A) = A^3 - I = 0$. Therefore, $P(x)$ is an annihilating polynomial for the matrix $A$.\n\n**2. Analysis of the Polynomial Roots**\nWe analyze the roots of $P(x)$ over the complex field $\\mathbb{C}$. The roots of $x^3 - 1 = 0$ are the third roots of unity. We can factor $P(x)$ as:\n$$ x^3 - 1 = (x - 1)(x - \\omega)(x - \\omega^2) $$\nwhere $\\omega = e^{i \\frac{2\\pi}{3}} = -\\frac{1}{2} + i\\frac{\\sqrt{3}}{2}$ is a primitive third root of unity.\n\nThe set of roots is $S = \\{1, \\omega, \\omega^2\\}$.\nWe verify that these roots are distinct:\n1.  $\\omega \\neq 1$ because $e^{i \\frac{2\\pi}{3}} \\neq 1$.\n2.  $\\omega^2 \\neq 1$ because $e^{i \\frac{4\\pi}{3}} \\neq 1$.\n3.  $\\omega \\neq \\omega^2$ implies $\\omega(1 - \\omega) \\neq 0$, which holds since $\\omega \\neq 0$ and $\\omega \\neq 1$.\nThus, $P(x)$ has simple (distinct) roots.\n\n**3. Relationship to the Minimal Polynomial**\nLet $\\mu_A(x)$ denote the minimal polynomial of $A$ over $\\mathbb{C}$. By the definition of the minimal polynomial, $\\mu_A(x)$ divides every annihilating polynomial of $A$. Therefore:\n$$ \\mu_A(x) \\mid (x^3 - 1) $$\nSince $P(x) = x^3 - 1$ factors into distinct linear terms $(x-1), (x-\\omega), (x-\\omega^2)$, any divisor $\\mu_A(x)$ must be a product of distinct linear factors from this set.\nSpecifically, $\\mu_A(x)$ takes the form:\n$$ \\mu_A(x) = (x - \\lambda_1) \\cdots (x - \\lambda_k) $$\nwhere $\\lambda_i \\in \\{1, \\omega, \\omega^2\\}$ are distinct distinct.\n\n**4. Criterion for Diagonalizability**\nA fundamental theorem in linear algebra states that a matrix $A \\in M_n(\\mathbb{F})$ is diagonalizable over the field $\\mathbb{F}$ if and only if its minimal polynomial splits into distinct linear factors over $\\mathbb{F}$.\n\nIn our case:\n1.  The field is $\\mathbb{F} = \\mathbb{C}$.\n2.  We established in Step 3 that $\\mu_A(x)$ is a product of distinct linear factors over $\\mathbb{C}$ (since it divides a polynomial with distinct linear factors).\n\n**Conclusion**\nSince the minimal polynomial $\\mu_A(x)$ has distinct roots, $A$ is diagonalizable over $\\mathbb{C}$.\n\nQ.E.D.",
        "raw_answer": "**Theorem Statement**\nLet $A$ be a $3 \\times 3$ real matrix such that $A^3 = I$, where $I$ is the $3 \\times 3$ identity matrix. Then $A$ is diagonalizable over $\\mathbb{C}$.\n\n**Proof**\n\n**1. Identification of an Annihilating Polynomial**\nWe are given that the matrix $A$ satisfies the equation:\n$$ A^3 - I = 0 $$\nConsider the polynomial $P(x) \\in \\mathbb{C}[x]$ defined by:\n$$ P(x) = x^3 - 1 $$\nSubstituting $A$ into this polynomial yields $P(A) = A^3 - I = 0$. Therefore, $P(x)$ is an annihilating polynomial for the matrix $A$.\n\n**2. Analysis of the Polynomial Roots**\nWe analyze the roots of $P(x)$ over the complex field $\\mathbb{C}$. The roots of $x^3 - 1 = 0$ are the third roots of unity. We can factor $P(x)$ as:\n$$ x^3 - 1 = (x - 1)(x - \\omega)(x - \\omega^2) $$\nwhere $\\omega = e^{i \\frac{2\\pi}{3}} = -\\frac{1}{2} + i\\frac{\\sqrt{3}}{2}$ is a primitive third root of unity.\n\nThe set of roots is $S = \\{1, \\omega, \\omega^2\\}$.\nWe verify that these roots are distinct:\n1.  $\\omega \\neq 1$ because $e^{i \\frac{2\\pi}{3}} \\neq 1$.\n2.  $\\omega^2 \\neq 1$ because $e^{i \\frac{4\\pi}{3}} \\neq 1$.\n3.  $\\omega \\neq \\omega^2$ implies $\\omega(1 - \\omega) \\neq 0$, which holds since $\\omega \\neq 0$ and $\\omega \\neq 1$.\nThus, $P(x)$ has simple (distinct) roots.\n\n**3. Relationship to the Minimal Polynomial**\nLet $\\mu_A(x)$ denote the minimal polynomial of $A$ over $\\mathbb{C}$. By the definition of the minimal polynomial, $\\mu_A(x)$ divides every annihilating polynomial of $A$. Therefore:\n$$ \\mu_A(x) \\mid (x^3 - 1) $$\nSince $P(x) = x^3 - 1$ factors into distinct linear terms $(x-1), (x-\\omega), (x-\\omega^2)$, any divisor $\\mu_A(x)$ must be a product of distinct linear factors from this set.\nSpecifically, $\\mu_A(x)$ takes the form:\n$$ \\mu_A(x) = (x - \\lambda_1) \\cdots (x - \\lambda_k) $$\nwhere $\\lambda_i \\in \\{1, \\omega, \\omega^2\\}$ are distinct distinct.\n\n**4. Criterion for Diagonalizability**\nA fundamental theorem in linear algebra states that a matrix $A \\in M_n(\\mathbb{F})$ is diagonalizable over the field $\\mathbb{F}$ if and only if its minimal polynomial splits into distinct linear factors over $\\mathbb{F}$.\n\nIn our case:\n1.  The field is $\\mathbb{F} = \\mathbb{C}$.\n2.  We established in Step 3 that $\\mu_A(x)$ is a product of distinct linear factors over $\\mathbb{C}$ (since it divides a polynomial with distinct linear factors).\n\n**Conclusion**\nSince the minimal polynomial $\\mu_A(x)$ has distinct roots, $A$ is diagonalizable over $\\mathbb{C}$.\n\nQ.E.D.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of associative rings and algebras, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within associative rings and algebras\nAssociative rings and algebras involve the study of algebraic structures with associative multiplication. A suitable topic could involve properties of ideals, quotient rings, or specific types of algebras like matrix algebras.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving the properties of a specific type of associative algebra. For instance, we could explore the characteristics of a matrix algebra over a ring.\n\n## Step 4: Generate a specific problem\nConsider the ring $R = \\mathbb{Z}/4\\mathbb{Z}$ and the matrix algebra $M_2(R)$ of $2 \\times 2$ matrices with entries in $R$. Let's examine the properties of ideals in $M_2(R)$.\n\n## Step 5: Formulate the problem statement\n\"Let $R = \\mathbb{Z}/4\\mathbb{Z}$ and consider the matrix algebra $M_2(R)$. Prove that $M_2(R)$ is not a simple ring, i.e., it has a non-trivial ideal.\"\n\n## Step 6: Provide the solution\nTo solve this, we need to show that there exists a non-trivial ideal in $M_2(R)$. An ideal $I$ in $M_2(R)$ is a subset that is closed under addition and under multiplication by any element of $M_2(R)$ from either side.\n\n## Step 7: Identify a non-trivial ideal\nConsider the set $I$ of matrices in $M_2(R)$ where all entries are even (i.e., $0$ or $2$ mod $4$). This set is non-empty and not equal to $M_2(R)$ because it does not contain matrices with odd entries.\n\n## Step 8: Verify that $I$ is an ideal\nFor $I$ to be an ideal, it must be closed under addition and under multiplication by elements of $M_2(R)$. For any two matrices $A, B \\in I$, $A + B$ has even entries because the sum of even numbers is even, so $A + B \\in I$. For any $A \\in I$ and $C \\in M_2(R)$, the product $CA$ and $AC$ will have entries that are products and sums of products involving elements of $R$. Since $A$ has even entries, $CA$ and $AC$ will also have even entries because multiplying any element of $R$ by an even element results in an even element.\n\n## Step 9: Check if $I$ is non-trivial\n$I$ is non-trivial if it is not the zero ideal and not the entire ring $M_2(R)$. The zero matrix is in $I$, and there are non-zero matrices in $I$ (e.g., $\\begin{pmatrix} 2 & 0 \\\\ 0 & 0 \\end{pmatrix}$), so $I$ is not the zero ideal. $I$ is not $M_2(R)$ because, for example, $\\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\notin I$.\n\n## Step 10: Conclude the solution\nSince $I$ is a non-trivial ideal, $M_2(R)$ is not a simple ring.\n\nThe final answer is: \n\nLet $R = \\mathbb{Z}/4\\mathbb{Z}$ and consider the matrix algebra $M_2(R)$. Prove that $M_2(R)$ is not a simple ring, i.e., it has a non-trivial ideal.",
    "run_id": "10",
    "outer_attempt": 1,
    "topic_slug": "associative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem Statement**\nLet $R = \\mathbb{Z}/4\\mathbb{Z}$ and consider the matrix algebra $M_2(R)$. Prove that $M_2(R)$ is not a simple ring, i.e., it has a non-trivial ideal.\n\n---\n\n### **Solution**\n\nTo prove that the matrix ring $M_2(R)$ is not simple, we must demonstrate the existence of a two-sided ideal $\\mathcal{J} \\subseteq M_2(R)$ such that $\\mathcal{J} \\neq \\{0\\}$ and $\\mathcal{J} \\neq M_2(R)$.\n\n#### **1. Analysis of the Base Ring $R$**\n\nThe base ring is $R = \\mathbb{Z}/4\\mathbb{Z} = \\{ \\bar{0}, \\bar{1}, \\bar{2}, \\bar{3} \\}$. The algebraic operations are addition and multiplication modulo 4.\n\nA ring is simple if its only two-sided ideals are the zero ideal and the ring itself. We first inspect the ideal structure of $R$. Consider the subset generated by the element $\\bar{2}$:\n$$ I = (\\bar{2}) = \\{ k \\cdot \\bar{2} \\mid k \\in \\mathbb{Z} \\} = \\{ \\bar{0}, \\bar{2} \\}. $$\n\n**Verification that $I$ is an ideal of $R$:**\n1.  **Additive Subgroup:**\n    *   $\\bar{0} \\in I$.\n    *   $\\bar{2} + \\bar{2} = \\bar{4} = \\bar{0} \\in I$.\n    *   The additive inverse of $\\bar{2}$ is $\\bar{2}$ (since $\\bar{2}+\\bar{2}=\\bar{0}$), which is in $I$.\n    *   Thus, $I$ is closed under addition and subtraction.\n2.  **Absorbs Multiplication:**\n    Let $r \\in R$ and $x \\in I$.\n    *   If $x = \\bar{0}$, then $rx = xr = \\bar{0} \\in I$.\n    *   If $x = \\bar{2}$, we check for all $r \\in R$:\n        *   $\\bar{0} \\cdot \\bar{2} = \\bar{0} \\in I$\n        *   $\\bar{1} \\cdot \\bar{2} = \\bar{2} \\in I$\n        *   $\\bar{2} \\cdot \\bar{2} = \\bar{4} = \\bar{0} \\in I$\n        *   $\\bar{3} \\cdot \\bar{2} = \\bar{6} = \\bar{2} \\in I$\n    *   Thus, $I$ is an ideal of $R$.\n\nSince $I$ contains $\\bar{2} \\neq \\bar{0}$ and does not contain the identity $\\bar{1}$, $I$ is a non-trivial ideal of $R$.\n\n#### **2. Construction of an Ideal in $M_2(R)$**\n\nIt is a standard result in ring theory that if $I$ is an ideal of a ring $R$, then the set of $n \\times n$ matrices with entries in $I$, denoted $M_n(I)$, is an ideal of $M_n(R)$. We will construct this set explicitly and prove it satisfies the conditions.\n\nLet $\\mathcal{J}$ be the set of $2 \\times 2$ matrices with entries in $I = \\{ \\bar{0}, \\bar{2} \\}$:\n$$ \\mathcal{J} = \\left\\{ \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\in M_2(R) \\;\\middle|\\; a, b, c, d \\in I \\right\\}. $$\n\n**Proof that $\\mathcal{J}$ is a two-sided ideal of $M_2(R)$:**\n\n1.  **Additive Subgroup:**\n    Let $A, B \\in \\mathcal{J}$. Then the entries $A_{ij}$ and $B_{ij}$ belong to $I$. Since $I$ is closed under addition, $(A+B)_{ij} = A_{ij} + B_{ij} \\in I$. Similarly for subtraction. Thus, $A \\pm B \\in \\mathcal{J}$.\n\n2.  **Left Ideal Property:**\n    Let $X \\in M_2(R)$ and $A \\in \\mathcal{J}$. Let $C = XA$. The entries of $C$ are given by:\n    $$ C_{ij} = \\sum_{k=1}^2 X_{ik} A_{kj} $$\n    Since $A \\in \\mathcal{J}$, every $A_{kj} \\in I$. Since $I$ is an ideal of $R$, the product $X_{ik} A_{kj} \\in I$ for any $X_{ik} \\in R$. Since $I$ is closed under addition, the sum $C_{ij}$ is in $I$.\n    Therefore, $XA \\in \\mathcal{J}$.\n\n3.  **Right Ideal Property:**\n    Let $X \\in M_2(R)$ and $A \\in \\mathcal{J}$. Let $D = AX$. The entries of $D$ are given by:\n    $$ D_{ij} = \\sum_{k=1}^2 A_{ik} X_{kj} $$\n    Since $A \\in \\mathcal{J}$, every $A_{ik} \\in I$. Since $I$ is an ideal of $R$, the product $A_{ik} X_{kj} \\in I$. Consequently, the sum $D_{ij}$ is in $I$.\n    Therefore, $AX \\in \\mathcal{J}$.\n\n#### **3. Verification of Non-Triviality**\n\nTo prove $M_2(R)$ is not simple, we must show $\\mathcal{J} \\neq \\{0\\}$ and $\\mathcal{J} \\neq M_2(R)$.\n\n1.  **$\\mathcal{J} \\neq \\{0\\}$:**\n    Consider the matrix $Z = \\begin{pmatrix} \\bar{2} & \\bar{0} \\\\ \\bar{0} & \\bar{0} \\end{pmatrix}$.\n    Since $\\bar{2}, \\bar{0} \\in I$, we have $Z \\in \\mathcal{J}$.\n    Since $\\bar{2} \\neq \\bar{0}$ in $\\mathbb{Z}/4\\mathbb{Z}$, $Z$ is not the zero matrix.\n    Thus, $\\mathcal{J}$ is not the zero ideal.\n\n2.  **$\\mathcal{J} \\neq M_2(R)$:**\n    Consider the identity matrix $Id = \\begin{pmatrix} \\bar{1} & \\bar{0} \\\\ \\bar{0} & \\bar{1} \\end{pmatrix}$.\n    The entry $\\bar{1} \\notin I$ because $I = \\{\\bar{0}, \\bar{2}\\}$.\n    Therefore, $Id \\notin \\mathcal{J}$.\n    Thus, $\\mathcal{J}$ is a proper subset of $M_2(R)$.\n\n### **Conclusion**\n\nWe have explicitly constructed a set $\\mathcal{J} \\subset M_2(R)$ consisting of matrices with even entries. We proved that $\\mathcal{J}$ is a two-sided ideal and that it is neither the zero ideal nor the entire ring.\n\nTherefore, $M_2(\\mathbb{Z}/4\\mathbb{Z})$ possesses a non-trivial ideal, which proves that it is **not a simple ring**.",
        "raw_answer": "**Problem Statement**\nLet $R = \\mathbb{Z}/4\\mathbb{Z}$ and consider the matrix algebra $M_2(R)$. Prove that $M_2(R)$ is not a simple ring, i.e., it has a non-trivial ideal.\n\n---\n\n### **Solution**\n\nTo prove that the matrix ring $M_2(R)$ is not simple, we must demonstrate the existence of a two-sided ideal $\\mathcal{J} \\subseteq M_2(R)$ such that $\\mathcal{J} \\neq \\{0\\}$ and $\\mathcal{J} \\neq M_2(R)$.\n\n#### **1. Analysis of the Base Ring $R$**\n\nThe base ring is $R = \\mathbb{Z}/4\\mathbb{Z} = \\{ \\bar{0}, \\bar{1}, \\bar{2}, \\bar{3} \\}$. The algebraic operations are addition and multiplication modulo 4.\n\nA ring is simple if its only two-sided ideals are the zero ideal and the ring itself. We first inspect the ideal structure of $R$. Consider the subset generated by the element $\\bar{2}$:\n$$ I = (\\bar{2}) = \\{ k \\cdot \\bar{2} \\mid k \\in \\mathbb{Z} \\} = \\{ \\bar{0}, \\bar{2} \\}. $$\n\n**Verification that $I$ is an ideal of $R$:**\n1.  **Additive Subgroup:**\n    *   $\\bar{0} \\in I$.\n    *   $\\bar{2} + \\bar{2} = \\bar{4} = \\bar{0} \\in I$.\n    *   The additive inverse of $\\bar{2}$ is $\\bar{2}$ (since $\\bar{2}+\\bar{2}=\\bar{0}$), which is in $I$.\n    *   Thus, $I$ is closed under addition and subtraction.\n2.  **Absorbs Multiplication:**\n    Let $r \\in R$ and $x \\in I$.\n    *   If $x = \\bar{0}$, then $rx = xr = \\bar{0} \\in I$.\n    *   If $x = \\bar{2}$, we check for all $r \\in R$:\n        *   $\\bar{0} \\cdot \\bar{2} = \\bar{0} \\in I$\n        *   $\\bar{1} \\cdot \\bar{2} = \\bar{2} \\in I$\n        *   $\\bar{2} \\cdot \\bar{2} = \\bar{4} = \\bar{0} \\in I$\n        *   $\\bar{3} \\cdot \\bar{2} = \\bar{6} = \\bar{2} \\in I$\n    *   Thus, $I$ is an ideal of $R$.\n\nSince $I$ contains $\\bar{2} \\neq \\bar{0}$ and does not contain the identity $\\bar{1}$, $I$ is a non-trivial ideal of $R$.\n\n#### **2. Construction of an Ideal in $M_2(R)$**\n\nIt is a standard result in ring theory that if $I$ is an ideal of a ring $R$, then the set of $n \\times n$ matrices with entries in $I$, denoted $M_n(I)$, is an ideal of $M_n(R)$. We will construct this set explicitly and prove it satisfies the conditions.\n\nLet $\\mathcal{J}$ be the set of $2 \\times 2$ matrices with entries in $I = \\{ \\bar{0}, \\bar{2} \\}$:\n$$ \\mathcal{J} = \\left\\{ \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\in M_2(R) \\;\\middle|\\; a, b, c, d \\in I \\right\\}. $$\n\n**Proof that $\\mathcal{J}$ is a two-sided ideal of $M_2(R)$:**\n\n1.  **Additive Subgroup:**\n    Let $A, B \\in \\mathcal{J}$. Then the entries $A_{ij}$ and $B_{ij}$ belong to $I$. Since $I$ is closed under addition, $(A+B)_{ij} = A_{ij} + B_{ij} \\in I$. Similarly for subtraction. Thus, $A \\pm B \\in \\mathcal{J}$.\n\n2.  **Left Ideal Property:**\n    Let $X \\in M_2(R)$ and $A \\in \\mathcal{J}$. Let $C = XA$. The entries of $C$ are given by:\n    $$ C_{ij} = \\sum_{k=1}^2 X_{ik} A_{kj} $$\n    Since $A \\in \\mathcal{J}$, every $A_{kj} \\in I$. Since $I$ is an ideal of $R$, the product $X_{ik} A_{kj} \\in I$ for any $X_{ik} \\in R$. Since $I$ is closed under addition, the sum $C_{ij}$ is in $I$.\n    Therefore, $XA \\in \\mathcal{J}$.\n\n3.  **Right Ideal Property:**\n    Let $X \\in M_2(R)$ and $A \\in \\mathcal{J}$. Let $D = AX$. The entries of $D$ are given by:\n    $$ D_{ij} = \\sum_{k=1}^2 A_{ik} X_{kj} $$\n    Since $A \\in \\mathcal{J}$, every $A_{ik} \\in I$. Since $I$ is an ideal of $R$, the product $A_{ik} X_{kj} \\in I$. Consequently, the sum $D_{ij}$ is in $I$.\n    Therefore, $AX \\in \\mathcal{J}$.\n\n#### **3. Verification of Non-Triviality**\n\nTo prove $M_2(R)$ is not simple, we must show $\\mathcal{J} \\neq \\{0\\}$ and $\\mathcal{J} \\neq M_2(R)$.\n\n1.  **$\\mathcal{J} \\neq \\{0\\}$:**\n    Consider the matrix $Z = \\begin{pmatrix} \\bar{2} & \\bar{0} \\\\ \\bar{0} & \\bar{0} \\end{pmatrix}$.\n    Since $\\bar{2}, \\bar{0} \\in I$, we have $Z \\in \\mathcal{J}$.\n    Since $\\bar{2} \\neq \\bar{0}$ in $\\mathbb{Z}/4\\mathbb{Z}$, $Z$ is not the zero matrix.\n    Thus, $\\mathcal{J}$ is not the zero ideal.\n\n2.  **$\\mathcal{J} \\neq M_2(R)$:**\n    Consider the identity matrix $Id = \\begin{pmatrix} \\bar{1} & \\bar{0} \\\\ \\bar{0} & \\bar{1} \\end{pmatrix}$.\n    The entry $\\bar{1} \\notin I$ because $I = \\{\\bar{0}, \\bar{2}\\}$.\n    Therefore, $Id \\notin \\mathcal{J}$.\n    Thus, $\\mathcal{J}$ is a proper subset of $M_2(R)$.\n\n### **Conclusion**\n\nWe have explicitly constructed a set $\\mathcal{J} \\subset M_2(R)$ consisting of matrices with even entries. We proved that $\\mathcal{J}$ is a two-sided ideal and that it is neither the zero ideal nor the entire ring.\n\nTherefore, $M_2(\\mathbb{Z}/4\\mathbb{Z})$ possesses a non-trivial ideal, which proves that it is **not a simple ring**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of nonassociative rings and algebras, along with a complete and verifiable solution. Nonassociative rings and algebras are mathematical structures where the multiplication operation is not necessarily associative.\n\n## Step 2: Identify a specific area within nonassociative rings and algebras\nA key area within nonassociative rings and algebras is the study of Lie algebras, which are crucial in various branches of mathematics and physics, particularly in the study of symmetries and conservation laws.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving Lie algebras. A Lie algebra is a vector space $\\mathfrak{g}$ over a field $\\mathbb{F}$, together with a binary operation $[\\cdot, \\cdot]: \\mathfrak{g} \\times \\mathfrak{g} \\to \\mathfrak{g}$, called the Lie bracket, that satisfies bilinearity, skew-symmetry, and the Jacobi identity.\n\n## Step 4: Specify the problem\nConsider the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$, which consists of $2 \\times 2$ real matrices with trace zero. The Lie bracket is defined as $[A, B] = AB - BA$. Let $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$. Show that $H, X, Y$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and determine the structure constants with respect to this basis.\n\n## Step 5: Provide the problem statement in the required format\n\nLet $\\mathfrak{sl}(2, \\mathbb{R})$ be the Lie algebra of $2 \\times 2$ real matrices with trace zero, with the Lie bracket $[A, B] = AB - BA$. Show that the matrices $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and compute the structure constants with respect to this basis.",
    "run_id": "11",
    "outer_attempt": 1,
    "topic_slug": "nonassociative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete solution to the problem concerning the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n### 1. Definition and Basis Verification\n\nFirst, we define the vector space $\\mathfrak{sl}(2, \\mathbb{R})$. It consists of all $2 \\times 2$ matrices with real entries such that the trace (the sum of diagonal elements) is zero.\n\nLet $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\in M_2(\\mathbb{R})$.\nThe condition $\\text{tr}(A) = 0$ implies $a + d = 0$, or $d = -a$.\nThus, a general element of $\\mathfrak{sl}(2, \\mathbb{R})$ takes the form:\n$$ A = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} $$\nwhere $a, b, c \\in \\mathbb{R}$. This indicates that the space has dimension 3.\n\nWe are given the matrices:\n$$ H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} $$\n\n**Checking Trace Condition:**\n*   $\\text{tr}(H) = 1 + (-1) = 0$\n*   $\\text{tr}(X) = 0 + 0 = 0$\n*   $\\text{tr}(Y) = 0 + 0 = 0$\nAll three matrices belong to $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Linear Independence:**\nConsider a linear combination equal to the zero matrix:\n$$ c_1 H + c_2 X + c_3 Y = \\mathbf{0} $$\nSubstituting the matrices:\n$$ c_1 \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + c_2 \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c_3 \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ \\begin{pmatrix} c_1 & c_2 \\\\ c_3 & -c_1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nComparing entries implies $c_1 = 0$, $c_2 = 0$, and $c_3 = 0$. Thus, the set $\\{H, X, Y\\}$ is linearly independent.\n\n**Spanning:**\nAny generic matrix $A = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} \\in \\mathfrak{sl}(2, \\mathbb{R})$ can be written as:\n$$ A = a \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + b \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = aH + bX + cY $$\nTherefore, $\\{H, X, Y\\}$ spans $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Conclusion:**\nSince the set is linearly independent and spans the space, $\\{H, X, Y\\}$ forms a basis for $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n---\n\n### 2. Computation of Lie Brackets\n\nThe Lie bracket is defined as $[A, B] = AB - BA$. We compute the brackets for the pairs of basis vectors. Note that $[A, A] = 0$ and $[B, A] = -[A, B]$, so we only need to compute $[H, X]$, $[H, Y]$, and $[X, Y]$.\n\n**1. Computing $[H, X]$:**\n$$ HX = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = X $$\n$$ XH = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix} = -X $$\n$$ [H, X] = HX - XH = X - (-X) = 2X $$\n\n**2. Computing $[H, Y]$:**\n$$ HY = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix} = -Y $$\n$$ YH = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = Y $$\n$$ [H, Y] = HY - YH = -Y - Y = -2Y $$\n\n**3. Computing $[X, Y]$:**\n$$ XY = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ YX = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\n$$ [X, Y] = XY - YX = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = H $$\n\n**Summary of Commutation Relations:**\n$$ [H, X] = 2X $$\n$$ [H, Y] = -2Y $$\n$$ [X, Y] = H $$\n\n---\n\n### 3. Structure Constants\n\nThe structure constants $C_{ij}^k$ with respect to a basis $\\{e_1, e_2, e_3\\}$ are the coefficients defined by the relation $[e_i, e_j] = \\sum_{k=1}^3 C_{ij}^k e_k$.\n\nWe identify the ordered basis as:\n$e_1 = H$, $e_2 = X$, $e_3 = Y$.\n\nFrom the commutation relations derived above:\n\n1.  $[e_1, e_2] = [H, X] = 2X = 0e_1 + 2e_2 + 0e_3$\n    *   $C_{12}^1 = 0$\n    *   $\\mathbf{C_{12}^2 = 2}$\n    *   $C_{12}^3 = 0$\n\n2.  $[e_1, e_3] = [H, Y] = -2Y = 0e_1 + 0e_2 - 2e_3$\n    *   $C_{13}^1 = 0$\n    *   $C_{13}^2 = 0$\n    *   $\\mathbf{C_{13}^3 = -2}$\n\n3.  $[e_2, e_3] = [X, Y] = H = 1e_1 + 0e_2 + 0e_3$\n    *   $\\mathbf{C_{23}^1 = 1}$\n    *   $C_{23}^2 = 0$\n    *   $C_{23}^3 = 0$\n\nDue to the skew-symmetry of the Lie bracket ($[e_j, e_i] = -[e_i, e_j]$), we also have:\n*   $C_{21}^2 = -2$\n*   $C_{31}^3 = 2$\n*   $C_{32}^1 = -1$\n\nAll other structure constants where $i=j$ are zero because $[e_i, e_i] = 0$.\n\n**Final Result:**\n\nThe matrices $H, X, Y$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$. The non-zero structure constants for the ordered basis $(H, X, Y)$ are:\n$$ C_{HX}^X = 2, \\quad C_{HY}^Y = -2, \\quad C_{XY}^H = 1 $$\nand their skew-symmetric counterparts:\n$$ C_{XH}^X = -2, \\quad C_{YH}^Y = 2, \\quad C_{YX}^H = -1 $$",
        "raw_answer": "Here is the complete solution to the problem concerning the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n### 1. Definition and Basis Verification\n\nFirst, we define the vector space $\\mathfrak{sl}(2, \\mathbb{R})$. It consists of all $2 \\times 2$ matrices with real entries such that the trace (the sum of diagonal elements) is zero.\n\nLet $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\in M_2(\\mathbb{R})$.\nThe condition $\\text{tr}(A) = 0$ implies $a + d = 0$, or $d = -a$.\nThus, a general element of $\\mathfrak{sl}(2, \\mathbb{R})$ takes the form:\n$$ A = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} $$\nwhere $a, b, c \\in \\mathbb{R}$. This indicates that the space has dimension 3.\n\nWe are given the matrices:\n$$ H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} $$\n\n**Checking Trace Condition:**\n*   $\\text{tr}(H) = 1 + (-1) = 0$\n*   $\\text{tr}(X) = 0 + 0 = 0$\n*   $\\text{tr}(Y) = 0 + 0 = 0$\nAll three matrices belong to $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Linear Independence:**\nConsider a linear combination equal to the zero matrix:\n$$ c_1 H + c_2 X + c_3 Y = \\mathbf{0} $$\nSubstituting the matrices:\n$$ c_1 \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + c_2 \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c_3 \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ \\begin{pmatrix} c_1 & c_2 \\\\ c_3 & -c_1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nComparing entries implies $c_1 = 0$, $c_2 = 0$, and $c_3 = 0$. Thus, the set $\\{H, X, Y\\}$ is linearly independent.\n\n**Spanning:**\nAny generic matrix $A = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} \\in \\mathfrak{sl}(2, \\mathbb{R})$ can be written as:\n$$ A = a \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + b \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = aH + bX + cY $$\nTherefore, $\\{H, X, Y\\}$ spans $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Conclusion:**\nSince the set is linearly independent and spans the space, $\\{H, X, Y\\}$ forms a basis for $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n---\n\n### 2. Computation of Lie Brackets\n\nThe Lie bracket is defined as $[A, B] = AB - BA$. We compute the brackets for the pairs of basis vectors. Note that $[A, A] = 0$ and $[B, A] = -[A, B]$, so we only need to compute $[H, X]$, $[H, Y]$, and $[X, Y]$.\n\n**1. Computing $[H, X]$:**\n$$ HX = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = X $$\n$$ XH = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix} = -X $$\n$$ [H, X] = HX - XH = X - (-X) = 2X $$\n\n**2. Computing $[H, Y]$:**\n$$ HY = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix} = -Y $$\n$$ YH = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = Y $$\n$$ [H, Y] = HY - YH = -Y - Y = -2Y $$\n\n**3. Computing $[X, Y]$:**\n$$ XY = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ YX = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\n$$ [X, Y] = XY - YX = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = H $$\n\n**Summary of Commutation Relations:**\n$$ [H, X] = 2X $$\n$$ [H, Y] = -2Y $$\n$$ [X, Y] = H $$\n\n---\n\n### 3. Structure Constants\n\nThe structure constants $C_{ij}^k$ with respect to a basis $\\{e_1, e_2, e_3\\}$ are the coefficients defined by the relation $[e_i, e_j] = \\sum_{k=1}^3 C_{ij}^k e_k$.\n\nWe identify the ordered basis as:\n$e_1 = H$, $e_2 = X$, $e_3 = Y$.\n\nFrom the commutation relations derived above:\n\n1.  $[e_1, e_2] = [H, X] = 2X = 0e_1 + 2e_2 + 0e_3$\n    *   $C_{12}^1 = 0$\n    *   $\\mathbf{C_{12}^2 = 2}$\n    *   $C_{12}^3 = 0$\n\n2.  $[e_1, e_3] = [H, Y] = -2Y = 0e_1 + 0e_2 - 2e_3$\n    *   $C_{13}^1 = 0$\n    *   $C_{13}^2 = 0$\n    *   $\\mathbf{C_{13}^3 = -2}$\n\n3.  $[e_2, e_3] = [X, Y] = H = 1e_1 + 0e_2 + 0e_3$\n    *   $\\mathbf{C_{23}^1 = 1}$\n    *   $C_{23}^2 = 0$\n    *   $C_{23}^3 = 0$\n\nDue to the skew-symmetry of the Lie bracket ($[e_j, e_i] = -[e_i, e_j]$), we also have:\n*   $C_{21}^2 = -2$\n*   $C_{31}^3 = 2$\n*   $C_{32}^1 = -1$\n\nAll other structure constants where $i=j$ are zero because $[e_i, e_i] = 0$.\n\n**Final Result:**\n\nThe matrices $H, X, Y$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$. The non-zero structure constants for the ordered basis $(H, X, Y)$ are:\n$$ C_{HX}^X = 2, \\quad C_{HY}^Y = -2, \\quad C_{XY}^H = 1 $$\nand their skew-symmetric counterparts:\n$$ C_{XH}^X = -2, \\quad C_{YH}^Y = 2, \\quad C_{YX}^H = -1 $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of category theory or homological algebra, along with a solution that is verifiable and follows the given guidelines.\n\n## Step 2: Identify the domain\nThe problem should be related to category theory or homological algebra.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we need to ensure it is well-posed, non-trivial, and solvable with the given constraints. Let's consider a problem that involves understanding and applying concepts from category theory.\n\n## Step 4: Generate the problem\nLet's formulate a problem that involves proving a property related to categories and functors.\n\n## Step 5: Write the problem\nProve that the functor $F: \\mathbf{Ab} \\to \\mathbf{Ab}$ defined by $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is exact.\n[/QUESTION]",
    "run_id": "12",
    "outer_attempt": 1,
    "topic_slug": "category_theory_and_homological_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the functor $F: \\mathbf{Ab} \\to \\mathbf{Ab}$ defined by $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is exact, we must show that it preserves short exact sequences.\n\n### 1. Definitions and Setup\n\nLet $\\mathbf{Ab}$ denote the category of abelian groups (equivalently, $\\mathbb{Z}$-modules).\nLet $0 \\to A \\xrightarrow{f} B \\xrightarrow{g} C \\to 0$ be a short exact sequence of abelian groups. This implies:\n1.  $f$ is injective ($\\ker(f) = \\{0\\}$).\n2.  $g$ is surjective ($\\text{im}(g) = C$).\n3.  $\\text{im}(f) = \\ker(g)$.\n\nWe apply the functor $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ to this sequence to obtain:\n$$0 \\to A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{f \\otimes 1} B \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{g \\otimes 1} C \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to 0$$\nTo prove $F$ is exact, we must verify that this induced sequence is also exact.\n\n### 2. Right Exactness\n\nIt is a standard result in homological algebra that the tensor product functor $- \\otimes_R M$ is right exact for any $R$-module $M$. Since $\\mathbb{Q}$ is a $\\mathbb{Z}$-module, the sequence:\n$$A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{f \\otimes 1} B \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{g \\otimes 1} C \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to 0$$\nis exact. This establishes that:\n1.  $g \\otimes 1$ is surjective.\n2.  $\\text{im}(f \\otimes 1) = \\ker(g \\otimes 1)$.\n\nThus, to complete the proof of exactness, we only need to show **Left Exactness**. Specifically, we must prove that $f \\otimes 1$ is injective.\n\n### 3. Left Exactness (Injectivity)\n\nWe need to show that if $f: A \\to B$ is injective, then $f \\otimes 1: A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to B \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is injective.\n\n**Lemma 1 (Structure of the Tensor Product):**\nFor any abelian group $G$, there is a natural isomorphism $\\eta: G \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{\\cong} S^{-1}G$, where $S = \\mathbb{Z} \\setminus \\{0\\}$ is the multiplicative set of non-zero integers, and $S^{-1}G$ is the localization of $G$ at $S$.\nThe isomorphism is given by $\\eta(g \\otimes \\frac{p}{q}) = \\frac{p \\cdot g}{q}$.\n\n**Proof of Lemma 1 (Sketch):**\nThe map $\\phi: G \\times \\mathbb{Q} \\to S^{-1}G$ defined by $(g, \\frac{p}{q}) \\mapsto \\frac{p \\cdot g}{q}$ is $\\mathbb{Z}$-bilinear. By the universal property of tensor products, this induces a homomorphism $\\eta: G \\otimes \\mathbb{Q} \\to S^{-1}G$.\nConversely, define $\\psi: S^{-1}G \\to G \\otimes \\mathbb{Q}$ by $\\frac{g}{q} \\mapsto g \\otimes \\frac{1}{q}$. One can check this is well-defined and inverse to $\\eta$.\n\n**Using the Lemma to prove Injectivity:**\nUsing the isomorphism $G \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\cong S^{-1}G$, checking the injectivity of $f \\otimes 1$ is equivalent to checking the injectivity of the induced map on localizations $S^{-1}f: S^{-1}A \\to S^{-1}B$, defined by $S^{-1}f(\\frac{a}{s}) = \\frac{f(a)}{s}$.\n\nLet $\\frac{a}{s} \\in S^{-1}A$ be an element in the kernel of $S^{-1}f$.\n$$S^{-1}f\\left(\\frac{a}{s}\\right) = \\frac{f(a)}{s} = 0 \\quad \\text{in } S^{-1}B$$\n\nBy the definition of equality in a localization, an element $\\frac{x}{y}$ is zero in $S^{-1}B$ if and only if there exists a $t \\in S$ such that $t \\cdot x = 0$ in $B$.\nApplying this here, there exists an integer $t \\in \\mathbb{Z} \\setminus \\{0\\}$ such that:\n$$t \\cdot f(a) = 0$$\n\nSince $f$ is a homomorphism, $t \\cdot f(a) = f(t \\cdot a)$. Thus:\n$$f(t \\cdot a) = 0$$\n\nSince $f$ is injective (by the hypothesis that the original sequence is exact), the kernel of $f$ is trivial. Therefore:\n$$t \\cdot a = 0$$\n\nNow we return to the element $\\frac{a}{s}$ in $S^{-1}A$. By the definition of localization, $\\frac{a}{s}$ is equal to $\\frac{t \\cdot a}{t \\cdot s}$. Substituting $t \\cdot a = 0$:\n$$\\frac{a}{s} = \\frac{0}{t \\cdot s} = 0 \\quad \\text{in } S^{-1}A$$\n\nSince the only element in the kernel of $S^{-1}f$ is $0$, the map is injective.\n\n### 4. Conclusion\n\nWe have shown:\n1.  The functor preserves surjectivity and exactness at the middle term (Right Exactness) due to general properties of the tensor product.\n2.  The functor preserves injectivity (Left Exactness) due to the properties of localization by non-zero integers (specifically, that $\\mathbb{Q}$ is torsion-free and thus flat over $\\mathbb{Z}$).\n\nSince $F$ preserves short exact sequences, $F$ is an **exact functor**.",
        "raw_answer": "To prove that the functor $F: \\mathbf{Ab} \\to \\mathbf{Ab}$ defined by $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is exact, we must show that it preserves short exact sequences.\n\n### 1. Definitions and Setup\n\nLet $\\mathbf{Ab}$ denote the category of abelian groups (equivalently, $\\mathbb{Z}$-modules).\nLet $0 \\to A \\xrightarrow{f} B \\xrightarrow{g} C \\to 0$ be a short exact sequence of abelian groups. This implies:\n1.  $f$ is injective ($\\ker(f) = \\{0\\}$).\n2.  $g$ is surjective ($\\text{im}(g) = C$).\n3.  $\\text{im}(f) = \\ker(g)$.\n\nWe apply the functor $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ to this sequence to obtain:\n$$0 \\to A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{f \\otimes 1} B \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{g \\otimes 1} C \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to 0$$\nTo prove $F$ is exact, we must verify that this induced sequence is also exact.\n\n### 2. Right Exactness\n\nIt is a standard result in homological algebra that the tensor product functor $- \\otimes_R M$ is right exact for any $R$-module $M$. Since $\\mathbb{Q}$ is a $\\mathbb{Z}$-module, the sequence:\n$$A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{f \\otimes 1} B \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{g \\otimes 1} C \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to 0$$\nis exact. This establishes that:\n1.  $g \\otimes 1$ is surjective.\n2.  $\\text{im}(f \\otimes 1) = \\ker(g \\otimes 1)$.\n\nThus, to complete the proof of exactness, we only need to show **Left Exactness**. Specifically, we must prove that $f \\otimes 1$ is injective.\n\n### 3. Left Exactness (Injectivity)\n\nWe need to show that if $f: A \\to B$ is injective, then $f \\otimes 1: A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to B \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is injective.\n\n**Lemma 1 (Structure of the Tensor Product):**\nFor any abelian group $G$, there is a natural isomorphism $\\eta: G \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{\\cong} S^{-1}G$, where $S = \\mathbb{Z} \\setminus \\{0\\}$ is the multiplicative set of non-zero integers, and $S^{-1}G$ is the localization of $G$ at $S$.\nThe isomorphism is given by $\\eta(g \\otimes \\frac{p}{q}) = \\frac{p \\cdot g}{q}$.\n\n**Proof of Lemma 1 (Sketch):**\nThe map $\\phi: G \\times \\mathbb{Q} \\to S^{-1}G$ defined by $(g, \\frac{p}{q}) \\mapsto \\frac{p \\cdot g}{q}$ is $\\mathbb{Z}$-bilinear. By the universal property of tensor products, this induces a homomorphism $\\eta: G \\otimes \\mathbb{Q} \\to S^{-1}G$.\nConversely, define $\\psi: S^{-1}G \\to G \\otimes \\mathbb{Q}$ by $\\frac{g}{q} \\mapsto g \\otimes \\frac{1}{q}$. One can check this is well-defined and inverse to $\\eta$.\n\n**Using the Lemma to prove Injectivity:**\nUsing the isomorphism $G \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\cong S^{-1}G$, checking the injectivity of $f \\otimes 1$ is equivalent to checking the injectivity of the induced map on localizations $S^{-1}f: S^{-1}A \\to S^{-1}B$, defined by $S^{-1}f(\\frac{a}{s}) = \\frac{f(a)}{s}$.\n\nLet $\\frac{a}{s} \\in S^{-1}A$ be an element in the kernel of $S^{-1}f$.\n$$S^{-1}f\\left(\\frac{a}{s}\\right) = \\frac{f(a)}{s} = 0 \\quad \\text{in } S^{-1}B$$\n\nBy the definition of equality in a localization, an element $\\frac{x}{y}$ is zero in $S^{-1}B$ if and only if there exists a $t \\in S$ such that $t \\cdot x = 0$ in $B$.\nApplying this here, there exists an integer $t \\in \\mathbb{Z} \\setminus \\{0\\}$ such that:\n$$t \\cdot f(a) = 0$$\n\nSince $f$ is a homomorphism, $t \\cdot f(a) = f(t \\cdot a)$. Thus:\n$$f(t \\cdot a) = 0$$\n\nSince $f$ is injective (by the hypothesis that the original sequence is exact), the kernel of $f$ is trivial. Therefore:\n$$t \\cdot a = 0$$\n\nNow we return to the element $\\frac{a}{s}$ in $S^{-1}A$. By the definition of localization, $\\frac{a}{s}$ is equal to $\\frac{t \\cdot a}{t \\cdot s}$. Substituting $t \\cdot a = 0$:\n$$\\frac{a}{s} = \\frac{0}{t \\cdot s} = 0 \\quad \\text{in } S^{-1}A$$\n\nSince the only element in the kernel of $S^{-1}f$ is $0$, the map is injective.\n\n### 4. Conclusion\n\nWe have shown:\n1.  The functor preserves surjectivity and exactness at the middle term (Right Exactness) due to general properties of the tensor product.\n2.  The functor preserves injectivity (Left Exactness) due to the properties of localization by non-zero integers (specifically, that $\\mathbb{Q}$ is torsion-free and thus flat over $\\mathbb{Z}$).\n\nSince $F$ preserves short exact sequences, $F$ is an **exact functor**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of K-theory, along with a solution that is verifiable and follows the given format.\n\n## Step 2: Identify the topic and relevant concepts\nThe topic is K-theory, which is a branch of algebraic topology that studies the properties of vector bundles and their relations to the underlying space. K-theory is crucial in various areas of mathematics and physics.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to understand what kind of questions are typically asked in K-theory. A common type of problem involves calculating the K-theory groups of a specific space or understanding the properties of K-theory groups under certain operations.\n\n## Step 4: Generate a specific problem\nLet's generate a problem related to the K-theory of a particular space. Consider the space $S^2$, the 2-sphere. A relevant problem could be to compute $K^0(S^2)$ and $K^1(S^2)$, which are related to the complex vector bundles on $S^2$.\n\n## Step 5: Formulate the problem in the required format\nWe need to provide a problem in the format: \"Compute $K^0(X)$ and $K^1(X)$ for $X = S^2$,\" where $S^2$ is the 2-sphere.\n\n## Step 6: Provide the solution\nTo solve this, we recall that $K^0(X)$ and $K^1(X)$ are related to the Grothendieck groups of complex vector bundles on $X$. For $S^2$, we know that $K^0(S^2)$ is related to the isomorphism classes of complex vector bundles on $S^2$, and $K^1(S^2)$ is related to the stable homotopy group $\\pi_1(S^2)$.\n\n## Step 7: Write down the problem and its solution\n### Problem\nCompute $K^0(S^2)$ and $K^1(S^2)$.",
    "run_id": "13",
    "outer_attempt": 1,
    "topic_slug": "k_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete, rigorous solution to the problem identified in the task.\n\n**Problem:** Compute the complex K-theory groups $K^0(S^2)$ and $K^1(S^2)$ for the 2-sphere $S^2$.\n\n### **Solution**\n\nWe aim to compute the unreduced complex K-theory groups $K^0(S^2)$ and $K^1(S^2)$. We assume $K^*(X)$ denotes the standard complex topological K-theory of a compact Hausdorff space $X$.\n\n**1. Preliminaries and Decomposition**\n\nFor a compact Hausdorff space $X$ with a chosen basepoint $x_0$, the unreduced K-theory group $K^0(X)$ splits as the direct sum of the reduced K-theory group $\\tilde{K}^0(X)$ and the K-theory of the point:\n$$ K^0(X) \\cong \\tilde{K}^0(X) \\oplus K^0(\\{x_0\\}). $$\nThe group $K^1(X)$ is defined as the reduced K-theory of the suspension of $X$ (up to a shift), specifically $K^1(X) \\cong \\tilde{K}^0(\\Sigma X)$. Note that for a point, $K^0(pt) \\cong \\mathbb{Z}$ and $K^1(pt) = 0$.\n\nFor the 2-sphere $S^2$, we have:\n1.  $K^0(S^2) \\cong \\tilde{K}^0(S^2) \\oplus \\mathbb{Z}$.\n2.  $K^1(S^2) \\cong \\tilde{K}^0(S^3)$.\n\nThe problem reduces to computing the reduced K-groups $\\tilde{K}^0(S^n)$ for $n=2$ and $n=3$.\n\n**2. Connection to Homotopy Groups of the Unitary Group**\n\nReduced K-theory groups of spheres are isomorphic to the homotopy groups of the classifying space of the unitary group (or the unitary group itself, depending on the index). Specifically, there is a standard isomorphism derived from the fact that vector bundles over $S^n$ are classified by the homotopy group of the transition maps on the equator $S^{n-1}$:\n$$ \\tilde{K}^0(S^n) \\cong \\pi_{n-1}(GL(\\infty, \\mathbb{C})) \\cong \\pi_{n-1}(U(\\infty)). $$\nHere $U(\\infty) = \\varinjlim U(n)$ is the stable unitary group.\n\n**3. Application of Bott Periodicity**\n\nBott Periodicity establishes the values of the homotopy groups $\\pi_k(U(\\infty))$. The periodicity theorem states that:\n$$ \\pi_k(U(\\infty)) \\cong \\pi_{k+2}(U(\\infty)) $$\nThe base cases are:\n*   $\\pi_0(U(\\infty)) = 0$ (since $U(n)$ is path-connected).\n*   $\\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\n\nUsing this periodicity, we can determine the groups for any $k \\geq 0$:\n*   For even $k$: $\\pi_k(U(\\infty)) \\cong \\pi_0(U(\\infty)) = 0$.\n*   For odd $k$: $\\pi_k(U(\\infty)) \\cong \\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\n\n**4. Computation of $K^0(S^2)$**\n\nUsing the relation $\\tilde{K}^0(S^n) \\cong \\pi_{n-1}(U(\\infty))$ for $n=2$:\n$$ \\tilde{K}^0(S^2) \\cong \\pi_1(U(\\infty)). $$\nFrom Bott Periodicity, $\\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\nThus, $\\tilde{K}^0(S^2) \\cong \\mathbb{Z}$.\n\nSubstituting this back into the decomposition formula:\n$$ K^0(S^2) \\cong \\tilde{K}^0(S^2) \\oplus \\mathbb{Z} \\cong \\mathbb{Z} \\oplus \\mathbb{Z}. $$\n\n*Note on Generators:* The group is generated by the class of the trivial line bundle, $[1]$, and the class of the tautological line bundle, $[H]$, via the identification $S^2 \\cong \\mathbb{C}P^1$. Alternatively, it is generated by $[1]$ and the reduced element $([H] - [1])$.\n\n**5. Computation of $K^1(S^2)$**\n\nWe use the definition $K^1(S^2) \\cong \\tilde{K}^0(S^3)$ (or equivalently $K^{-1}(S^2) \\cong [S^2, U(\\infty)]$).\nUsing the relation $\\tilde{K}^0(S^n) \\cong \\pi_{n-1}(U(\\infty))$ for $n=3$:\n$$ K^1(S^2) \\cong \\tilde{K}^0(S^3) \\cong \\pi_2(U(\\infty)). $$\nFrom Bott Periodicity, $\\pi_2(U(\\infty)) \\cong \\pi_0(U(\\infty)) = 0$.\nThus,\n$$ K^1(S^2) \\cong 0. $$\n\n**Conclusion**\n\nThe complex K-theory groups of the 2-sphere are:\n\n$$\nK^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}\n$$\n$$\nK^1(S^2) \\cong 0\n$$",
        "raw_answer": "Here is the complete, rigorous solution to the problem identified in the task.\n\n**Problem:** Compute the complex K-theory groups $K^0(S^2)$ and $K^1(S^2)$ for the 2-sphere $S^2$.\n\n### **Solution**\n\nWe aim to compute the unreduced complex K-theory groups $K^0(S^2)$ and $K^1(S^2)$. We assume $K^*(X)$ denotes the standard complex topological K-theory of a compact Hausdorff space $X$.\n\n**1. Preliminaries and Decomposition**\n\nFor a compact Hausdorff space $X$ with a chosen basepoint $x_0$, the unreduced K-theory group $K^0(X)$ splits as the direct sum of the reduced K-theory group $\\tilde{K}^0(X)$ and the K-theory of the point:\n$$ K^0(X) \\cong \\tilde{K}^0(X) \\oplus K^0(\\{x_0\\}). $$\nThe group $K^1(X)$ is defined as the reduced K-theory of the suspension of $X$ (up to a shift), specifically $K^1(X) \\cong \\tilde{K}^0(\\Sigma X)$. Note that for a point, $K^0(pt) \\cong \\mathbb{Z}$ and $K^1(pt) = 0$.\n\nFor the 2-sphere $S^2$, we have:\n1.  $K^0(S^2) \\cong \\tilde{K}^0(S^2) \\oplus \\mathbb{Z}$.\n2.  $K^1(S^2) \\cong \\tilde{K}^0(S^3)$.\n\nThe problem reduces to computing the reduced K-groups $\\tilde{K}^0(S^n)$ for $n=2$ and $n=3$.\n\n**2. Connection to Homotopy Groups of the Unitary Group**\n\nReduced K-theory groups of spheres are isomorphic to the homotopy groups of the classifying space of the unitary group (or the unitary group itself, depending on the index). Specifically, there is a standard isomorphism derived from the fact that vector bundles over $S^n$ are classified by the homotopy group of the transition maps on the equator $S^{n-1}$:\n$$ \\tilde{K}^0(S^n) \\cong \\pi_{n-1}(GL(\\infty, \\mathbb{C})) \\cong \\pi_{n-1}(U(\\infty)). $$\nHere $U(\\infty) = \\varinjlim U(n)$ is the stable unitary group.\n\n**3. Application of Bott Periodicity**\n\nBott Periodicity establishes the values of the homotopy groups $\\pi_k(U(\\infty))$. The periodicity theorem states that:\n$$ \\pi_k(U(\\infty)) \\cong \\pi_{k+2}(U(\\infty)) $$\nThe base cases are:\n*   $\\pi_0(U(\\infty)) = 0$ (since $U(n)$ is path-connected).\n*   $\\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\n\nUsing this periodicity, we can determine the groups for any $k \\geq 0$:\n*   For even $k$: $\\pi_k(U(\\infty)) \\cong \\pi_0(U(\\infty)) = 0$.\n*   For odd $k$: $\\pi_k(U(\\infty)) \\cong \\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\n\n**4. Computation of $K^0(S^2)$**\n\nUsing the relation $\\tilde{K}^0(S^n) \\cong \\pi_{n-1}(U(\\infty))$ for $n=2$:\n$$ \\tilde{K}^0(S^2) \\cong \\pi_1(U(\\infty)). $$\nFrom Bott Periodicity, $\\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\nThus, $\\tilde{K}^0(S^2) \\cong \\mathbb{Z}$.\n\nSubstituting this back into the decomposition formula:\n$$ K^0(S^2) \\cong \\tilde{K}^0(S^2) \\oplus \\mathbb{Z} \\cong \\mathbb{Z} \\oplus \\mathbb{Z}. $$\n\n*Note on Generators:* The group is generated by the class of the trivial line bundle, $[1]$, and the class of the tautological line bundle, $[H]$, via the identification $S^2 \\cong \\mathbb{C}P^1$. Alternatively, it is generated by $[1]$ and the reduced element $([H] - [1])$.\n\n**5. Computation of $K^1(S^2)$**\n\nWe use the definition $K^1(S^2) \\cong \\tilde{K}^0(S^3)$ (or equivalently $K^{-1}(S^2) \\cong [S^2, U(\\infty)]$).\nUsing the relation $\\tilde{K}^0(S^n) \\cong \\pi_{n-1}(U(\\infty))$ for $n=3$:\n$$ K^1(S^2) \\cong \\tilde{K}^0(S^3) \\cong \\pi_2(U(\\infty)). $$\nFrom Bott Periodicity, $\\pi_2(U(\\infty)) \\cong \\pi_0(U(\\infty)) = 0$.\nThus,\n$$ K^1(S^2) \\cong 0. $$\n\n**Conclusion**\n\nThe complex K-theory groups of the 2-sphere are:\n\n$$\nK^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}\n$$\n$$\nK^1(S^2) \\cong 0\n$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Group theory and generalizations\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Group theory and generalizations\nGroup theory is a branch of abstract algebra that studies the symmetric aspects of objects and the transformations that preserve those symmetries. A suitable topic could involve properties of groups, such as subgroup structures, homomorphisms, or specific types of groups like cyclic or symmetric groups.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider a topic like the classification of groups or the study of group homomorphisms. A potential problem could involve determining the number of homomorphisms between two given groups or analyzing the structure of a specific group.\n\n## Step 4: Generate a specific problem\nLet's consider the problem of finding the number of homomorphisms from the cyclic group of order 12, $\\mathbb{Z}_{12}$, to the symmetric group $S_3$. This involves understanding the structure of both groups and applying knowledge about homomorphisms.\n\n## Step 5: State the problem formally\nThe problem can be stated as: \"Let $\\mathbb{Z}_{12}$ be the cyclic group of order 12 and $S_3$ be the symmetric group on 3 elements. Determine the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\"\n\n## Step 6: Provide the solution\nTo solve this, we need to understand that a homomorphism $f: \\mathbb{Z}_{12} \\to S_3$ is determined by $f(1)$, where $1$ is a generator of $\\mathbb{Z}_{12}$. The element $f(1)$ must have an order that divides 12. $S_3$ has elements of orders 1, 2, and 3. We need to count how many elements in $S_3$ have orders that divide 12.\n\n## Step 7: Analyze the elements of $S_3$\n$S_3 = \\{e, (12), (13), (23), (123), (132)\\}$. The identity $e$ has order 1, the transpositions $(12), (13), (23)$ have order 2, and the 3-cycles $(123), (132)$ have order 3. The orders of elements in $S_3$ that divide 12 are 1, 2, and 3.\n\n## Step 8: Count the possible images of $1 \\in \\mathbb{Z}_{12}$\nThere is 1 element of order 1, 3 elements of order 2, and 2 elements of order 3. So, $f(1)$ can be any of these 6 elements because their orders divide 12.\n\n## Step 9: Conclude the number of homomorphisms\nSince $f(1)$ can be any of the 6 elements (1 of order 1, 3 of order 2, and 2 of order 3), there are 6 possible homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\n\n## Step 10: Format the problem and solution according to the required output format\n\nLet $\\mathbb{Z}_{12}$ be the cyclic group of order 12 and $S_3$ be the symmetric group on 3 elements. Determine the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.",
    "run_id": "14",
    "outer_attempt": 1,
    "topic_slug": "group_theory_and_generalizations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To determine the number of homomorphisms from the cyclic group $\\mathbb{Z}_{12}$ to the symmetric group $S_3$, we proceed with the following algebraic analysis.\n\n### 1. Structure of Homomorphisms from a Cyclic Group\n\nLet $\\phi: \\mathbb{Z}_{12} \\to S_3$ be a group homomorphism.\nThe group $\\mathbb{Z}_{12}$ is cyclic and generated by the element $1$ (using additive notation for $\\mathbb{Z}_{12}$). That is, $\\mathbb{Z}_{12} = \\langle 1 \\rangle$.\n\nA homomorphism from a cyclic group is completely determined by the image of its generator. Let $y = \\phi(1)$, where $y \\in S_3$.\nFor $\\phi$ to be a well-defined homomorphism, the algebraic constraints of the generator in the domain must be preserved in the image. Specifically, in $\\mathbb{Z}_{12}$, we have the relation:\n$$12 \\cdot 1 \\equiv 0 \\pmod{12}$$\nApplying $\\phi$ to both sides, we get:\n$$\\phi(12 \\cdot 1) = \\phi(0)$$\nUsing the property of homomorphisms ($\\phi(n \\cdot x) = \\phi(x)^n$ in multiplicative notation for the codomain, and $\\phi(0) = e$, where $e$ is the identity of $S_3$):\n$$y^{12} = e$$\nThus, a homomorphism exists for a specific choice of $y \\in S_3$ if and only if the order of $y$, denoted $|y|$, divides 12.\n\nThe problem reduces to finding the number of elements $y \\in S_3$ such that $|y|$ divides 12.\n\n### 2. Analysis of Elements in $S_3$\n\nThe symmetric group $S_3$ consists of all permutations of the set $\\{1, 2, 3\\}$. The order of the group is $|S_3| = 3! = 6$. We classify the elements by their cycle structure and determine their orders:\n\n1.  **Identity Element**:\n    -   $e = (1)(2)(3)$\n    -   Order: $|e| = 1$\n\n2.  **Transpositions (2-cycles)**:\n    -   Elements: $(1 \\ 2)$, $(1 \\ 3)$, $(2 \\ 3)$\n    -   Order: 2 (since $(a \\ b)^2 = e$)\n\n3.  **3-cycles**:\n    -   Elements: $(1 \\ 2 \\ 3)$, $(1 \\ 3 \\ 2)$\n    -   Order: 3 (since $(a \\ b \\ c)^3 = e$)\n\n### 3. Verification of Conditions\n\nWe now test the condition \"order divides 12\" for each class of elements:\n\n*   **Order 1**: $1$ divides $12$.\n    -   The identity element $e$ is a valid image.\n    -   Count: **1**\n\n*   **Order 2**: $2$ divides $12$.\n    -   All 3 transpositions satisfy $y^{12} = (y^2)^6 = e^6 = e$.\n    -   Count: **3**\n\n*   **Order 3**: $3$ divides $12$.\n    -   All 2 3-cycles satisfy $y^{12} = (y^3)^4 = e^4 = e$.\n    -   Count: **2**\n\nSince the orders of all elements in $S_3$ are divisors of 12, every element in $S_3$ can serve as the image $\\phi(1)$.\n\n### 4. Conclusion\n\nThe number of homomorphisms is the sum of the counts of valid images for the generator:\n$$ \\text{Total Homomorphisms} = 1 (\\text{from order 1}) + 3 (\\text{from order 2}) + 2 (\\text{from order 3}) = 6 $$\n\nThus, there are **6** homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.",
        "raw_answer": "To determine the number of homomorphisms from the cyclic group $\\mathbb{Z}_{12}$ to the symmetric group $S_3$, we proceed with the following algebraic analysis.\n\n### 1. Structure of Homomorphisms from a Cyclic Group\n\nLet $\\phi: \\mathbb{Z}_{12} \\to S_3$ be a group homomorphism.\nThe group $\\mathbb{Z}_{12}$ is cyclic and generated by the element $1$ (using additive notation for $\\mathbb{Z}_{12}$). That is, $\\mathbb{Z}_{12} = \\langle 1 \\rangle$.\n\nA homomorphism from a cyclic group is completely determined by the image of its generator. Let $y = \\phi(1)$, where $y \\in S_3$.\nFor $\\phi$ to be a well-defined homomorphism, the algebraic constraints of the generator in the domain must be preserved in the image. Specifically, in $\\mathbb{Z}_{12}$, we have the relation:\n$$12 \\cdot 1 \\equiv 0 \\pmod{12}$$\nApplying $\\phi$ to both sides, we get:\n$$\\phi(12 \\cdot 1) = \\phi(0)$$\nUsing the property of homomorphisms ($\\phi(n \\cdot x) = \\phi(x)^n$ in multiplicative notation for the codomain, and $\\phi(0) = e$, where $e$ is the identity of $S_3$):\n$$y^{12} = e$$\nThus, a homomorphism exists for a specific choice of $y \\in S_3$ if and only if the order of $y$, denoted $|y|$, divides 12.\n\nThe problem reduces to finding the number of elements $y \\in S_3$ such that $|y|$ divides 12.\n\n### 2. Analysis of Elements in $S_3$\n\nThe symmetric group $S_3$ consists of all permutations of the set $\\{1, 2, 3\\}$. The order of the group is $|S_3| = 3! = 6$. We classify the elements by their cycle structure and determine their orders:\n\n1.  **Identity Element**:\n    -   $e = (1)(2)(3)$\n    -   Order: $|e| = 1$\n\n2.  **Transpositions (2-cycles)**:\n    -   Elements: $(1 \\ 2)$, $(1 \\ 3)$, $(2 \\ 3)$\n    -   Order: 2 (since $(a \\ b)^2 = e$)\n\n3.  **3-cycles**:\n    -   Elements: $(1 \\ 2 \\ 3)$, $(1 \\ 3 \\ 2)$\n    -   Order: 3 (since $(a \\ b \\ c)^3 = e$)\n\n### 3. Verification of Conditions\n\nWe now test the condition \"order divides 12\" for each class of elements:\n\n*   **Order 1**: $1$ divides $12$.\n    -   The identity element $e$ is a valid image.\n    -   Count: **1**\n\n*   **Order 2**: $2$ divides $12$.\n    -   All 3 transpositions satisfy $y^{12} = (y^2)^6 = e^6 = e$.\n    -   Count: **3**\n\n*   **Order 3**: $3$ divides $12$.\n    -   All 2 3-cycles satisfy $y^{12} = (y^3)^4 = e^4 = e$.\n    -   Count: **2**\n\nSince the orders of all elements in $S_3$ are divisors of 12, every element in $S_3$ can serve as the image $\\phi(1)$.\n\n### 4. Conclusion\n\nThe number of homomorphisms is the sum of the counts of valid images for the generator:\n$$ \\text{Total Homomorphisms} = 1 (\\text{from order 1}) + 3 (\\text{from order 2}) + 2 (\\text{from order 3}) = 6 $$\n\nThus, there are **6** homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $G$ be a connected Lie group with Lie algebra $\\mathfrak{g}$. Suppose that $\\mathfrak{g}$ is simple and that $G$ has a discrete subgroup $\\Gamma$ such that $G/\\Gamma$ is compact. Prove that $\\Gamma$ is contained in the center of $G$ if and only if the adjoint representation of $G$ on $\\mathfrak{g}$ descends to a representation of $G/\\Gamma$.",
    "run_id": "15",
    "outer_attempt": 1,
    "topic_slug": "topological_groups_and_lie_groups",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The problem asks for a proof of a necessary and sufficient condition for the adjoint representation of a connected Lie group $G$ to descend to a quotient space $G/\\Gamma$.\n\n### Definitions and Preliminaries\n\nLet $G$ be a connected Lie group with simple Lie algebra $\\mathfrak{g}$. Let $\\Gamma$ be a discrete subgroup of $G$ such that $G/\\Gamma$ is compact.\nThe **adjoint representation** is the homomorphism $\\operatorname{Ad}: G \\to \\operatorname{Aut}(\\mathfrak{g})$ defined by $\\operatorname{Ad}(g) = (d\\Psi_g)_e$, where $\\Psi_g(x) = gxg^{-1}$ is the conjugation automorphism of $G$.\n\n**Concept of Descending:**\nA map $F: G \\to Y$ (where $Y$ is any set) **descends** to the quotient space $G/\\Gamma$ if and only if $F$ is constant on the left cosets of $\\Gamma$. That is, for all $g \\in G$ and $\\gamma \\in \\Gamma$:\n$$F(g\\gamma) = F(g)$$\nFurthermore, for the descended map to be a **representation** of $G/\\Gamma$, the quotient $G/\\Gamma$ must carry a group structure such that the projection $\\pi: G \\to G/\\Gamma$ is a homomorphism, and the descended map $\\overline{\\operatorname{Ad}}: G/\\Gamma \\to \\operatorname{Aut}(\\mathfrak{g})$ is a homomorphism satisfying $\\operatorname{Ad} = \\overline{\\operatorname{Ad}} \\circ \\pi$. The existence of a group structure on $G/\\Gamma$ requires $\\Gamma$ to be a normal subgroup of $G$.\n\n**Key Lemma: Kernel of the Adjoint Representation**\nFor a connected Lie group $G$, the kernel of the adjoint representation is exactly the center of the group, $Z(G)$.\n$$ \\ker(\\operatorname{Ad}) = Z(G) $$\n*Proof:*\n1.  Let $z \\in Z(G)$. Then $zgz^{-1} = g$ for all $g \\in G$. The conjugation map $\\Psi_z$ is the identity map on $G$. Its differential at the identity is $\\operatorname{Ad}(z) = I$. Thus $Z(G) \\subseteq \\ker(\\operatorname{Ad})$.\n2.  Conversely, let $g \\in \\ker(\\operatorname{Ad})$. Then $\\operatorname{Ad}(g) = I$. Consider the conjugation $\\Psi_g(x) = gxg^{-1}$. Its differential at the identity is $I$.\n    For any $X \\in \\mathfrak{g}$, using the exponential map:\n    $$ \\Psi_g(\\exp X) = g (\\exp X) g^{-1} = \\exp(\\operatorname{Ad}(g)X) = \\exp(IX) = \\exp(X) $$\n    Thus, $g$ commutes with all elements in the image of the exponential map. Since $G$ is connected, the image of $\\exp$ generates $G$. Therefore, $g$ commutes with all elements of $G$, so $g \\in Z(G)$.\n    Thus $\\ker(\\operatorname{Ad}) \\subseteq Z(G)$.\n\n---\n\n### Proof of the Equivalence\n\nWe must prove: $\\Gamma \\subseteq Z(G) \\iff \\operatorname{Ad}$ descends to a representation of $G/\\Gamma$.\n\n#### Direction $(\\Rightarrow)$\nAssume $\\Gamma \\subseteq Z(G)$.\n\n1.  **Group Structure:** Since $\\Gamma \\subseteq Z(G)$, every element $\\gamma \\in \\Gamma$ commutes with all $g \\in G$. Therefore, $\\gamma G = G \\gamma$, implying $\\Gamma$ is a normal subgroup of $G$. Consequently, the quotient space $G/\\Gamma$ inherits a Lie group structure.\n2.  **Factorization:** Since $\\Gamma \\subseteq Z(G)$ and $Z(G) = \\ker(\\operatorname{Ad})$, we have $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$.\n    For any $g \\in G$ and $\\gamma \\in \\Gamma$:\n    $$ \\operatorname{Ad}(g\\gamma) = \\operatorname{Ad}(g)\\operatorname{Ad}(\\gamma) = \\operatorname{Ad}(g)I = \\operatorname{Ad}(g) $$\n    This condition ensures that $\\operatorname{Ad}$ is constant on the cosets $g\\Gamma$.\n3.  **Conclusion:** The map $\\operatorname{Ad}$ factors through the projection $\\pi: G \\to G/\\Gamma$ to induce a well-defined map $\\overline{\\operatorname{Ad}}: G/\\Gamma \\to \\operatorname{Aut}(\\mathfrak{g})$. Since $\\operatorname{Ad}$ is a homomorphism and $G/\\Gamma$ is a group, $\\overline{\\operatorname{Ad}}$ is a homomorphism (a representation).\n    Thus, the adjoint representation descends to a representation of $G/\\Gamma$.\n\n#### Direction $(\\Leftarrow)$\nAssume the adjoint representation descends to a representation of $G/\\Gamma$.\n\n1.  **Kernel Condition:** By the definition of descending to the quotient space $G/\\Gamma$, we must have $\\operatorname{Ad}(g\\gamma) = \\operatorname{Ad}(g)$ for all $g \\in G$ and $\\gamma \\in \\Gamma$.\n    Evaluating this at $g=e$ (the identity of $G$):\n    $$ \\operatorname{Ad}(\\gamma) = \\operatorname{Ad}(e\\gamma) = \\operatorname{Ad}(e) = I $$\n    Therefore, $\\operatorname{Ad}(\\gamma) = I$ for all $\\gamma \\in \\Gamma$.\n    This implies $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$.\n2.  **Center Identification:** Using the Key Lemma established above for connected Lie groups, $\\ker(\\operatorname{Ad}) = Z(G)$.\n    Therefore:\n    $$ \\Gamma \\subseteq Z(G) $$\n\n### Role of Assumptions\nThe proof primarily relies on the connectedness of $G$ (to equate $\\ker(\\operatorname{Ad})$ with $Z(G)$). The assumptions that $\\mathfrak{g}$ is simple and $G/\\Gamma$ is compact ensure the problem is non-trivial and well-posed within the context of semisimple Lie theory:\n*   **Simplicity:** Since $\\mathfrak{g}$ is simple, its center is trivial ($Z(\\mathfrak{g})=0$), which implies that $Z(G)$ is a discrete subgroup of $G$. This is consistent with $\\Gamma$ being a discrete subgroup.\n*   **Compactness:** While not strictly required for the algebraic equivalence, the compactness of $G/\\Gamma$ (implying $\\Gamma$ is a uniform lattice) is a standard setting for such rigidity questions, ensuring well-behaved geometry.\n\n### Conclusion\nWe have shown that $\\operatorname{Ad}(g\\gamma) = \\operatorname{Ad}(g)$ is equivalent to $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$, and for a connected Lie group, $\\ker(\\operatorname{Ad}) = Z(G)$. Furthermore, for the descended map to form a group representation, $\\Gamma$ must be normal, which is automatically satisfied if $\\Gamma \\subseteq Z(G)$.\n\nTherefore, $\\Gamma$ is contained in the center of $G$ if and only if the adjoint representation of $G$ descends to a representation of $G/\\Gamma$.",
        "raw_answer": "The problem asks for a proof of a necessary and sufficient condition for the adjoint representation of a connected Lie group $G$ to descend to a quotient space $G/\\Gamma$.\n\n### Definitions and Preliminaries\n\nLet $G$ be a connected Lie group with simple Lie algebra $\\mathfrak{g}$. Let $\\Gamma$ be a discrete subgroup of $G$ such that $G/\\Gamma$ is compact.\nThe **adjoint representation** is the homomorphism $\\operatorname{Ad}: G \\to \\operatorname{Aut}(\\mathfrak{g})$ defined by $\\operatorname{Ad}(g) = (d\\Psi_g)_e$, where $\\Psi_g(x) = gxg^{-1}$ is the conjugation automorphism of $G$.\n\n**Concept of Descending:**\nA map $F: G \\to Y$ (where $Y$ is any set) **descends** to the quotient space $G/\\Gamma$ if and only if $F$ is constant on the left cosets of $\\Gamma$. That is, for all $g \\in G$ and $\\gamma \\in \\Gamma$:\n$$F(g\\gamma) = F(g)$$\nFurthermore, for the descended map to be a **representation** of $G/\\Gamma$, the quotient $G/\\Gamma$ must carry a group structure such that the projection $\\pi: G \\to G/\\Gamma$ is a homomorphism, and the descended map $\\overline{\\operatorname{Ad}}: G/\\Gamma \\to \\operatorname{Aut}(\\mathfrak{g})$ is a homomorphism satisfying $\\operatorname{Ad} = \\overline{\\operatorname{Ad}} \\circ \\pi$. The existence of a group structure on $G/\\Gamma$ requires $\\Gamma$ to be a normal subgroup of $G$.\n\n**Key Lemma: Kernel of the Adjoint Representation**\nFor a connected Lie group $G$, the kernel of the adjoint representation is exactly the center of the group, $Z(G)$.\n$$ \\ker(\\operatorname{Ad}) = Z(G) $$\n*Proof:*\n1.  Let $z \\in Z(G)$. Then $zgz^{-1} = g$ for all $g \\in G$. The conjugation map $\\Psi_z$ is the identity map on $G$. Its differential at the identity is $\\operatorname{Ad}(z) = I$. Thus $Z(G) \\subseteq \\ker(\\operatorname{Ad})$.\n2.  Conversely, let $g \\in \\ker(\\operatorname{Ad})$. Then $\\operatorname{Ad}(g) = I$. Consider the conjugation $\\Psi_g(x) = gxg^{-1}$. Its differential at the identity is $I$.\n    For any $X \\in \\mathfrak{g}$, using the exponential map:\n    $$ \\Psi_g(\\exp X) = g (\\exp X) g^{-1} = \\exp(\\operatorname{Ad}(g)X) = \\exp(IX) = \\exp(X) $$\n    Thus, $g$ commutes with all elements in the image of the exponential map. Since $G$ is connected, the image of $\\exp$ generates $G$. Therefore, $g$ commutes with all elements of $G$, so $g \\in Z(G)$.\n    Thus $\\ker(\\operatorname{Ad}) \\subseteq Z(G)$.\n\n---\n\n### Proof of the Equivalence\n\nWe must prove: $\\Gamma \\subseteq Z(G) \\iff \\operatorname{Ad}$ descends to a representation of $G/\\Gamma$.\n\n#### Direction $(\\Rightarrow)$\nAssume $\\Gamma \\subseteq Z(G)$.\n\n1.  **Group Structure:** Since $\\Gamma \\subseteq Z(G)$, every element $\\gamma \\in \\Gamma$ commutes with all $g \\in G$. Therefore, $\\gamma G = G \\gamma$, implying $\\Gamma$ is a normal subgroup of $G$. Consequently, the quotient space $G/\\Gamma$ inherits a Lie group structure.\n2.  **Factorization:** Since $\\Gamma \\subseteq Z(G)$ and $Z(G) = \\ker(\\operatorname{Ad})$, we have $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$.\n    For any $g \\in G$ and $\\gamma \\in \\Gamma$:\n    $$ \\operatorname{Ad}(g\\gamma) = \\operatorname{Ad}(g)\\operatorname{Ad}(\\gamma) = \\operatorname{Ad}(g)I = \\operatorname{Ad}(g) $$\n    This condition ensures that $\\operatorname{Ad}$ is constant on the cosets $g\\Gamma$.\n3.  **Conclusion:** The map $\\operatorname{Ad}$ factors through the projection $\\pi: G \\to G/\\Gamma$ to induce a well-defined map $\\overline{\\operatorname{Ad}}: G/\\Gamma \\to \\operatorname{Aut}(\\mathfrak{g})$. Since $\\operatorname{Ad}$ is a homomorphism and $G/\\Gamma$ is a group, $\\overline{\\operatorname{Ad}}$ is a homomorphism (a representation).\n    Thus, the adjoint representation descends to a representation of $G/\\Gamma$.\n\n#### Direction $(\\Leftarrow)$\nAssume the adjoint representation descends to a representation of $G/\\Gamma$.\n\n1.  **Kernel Condition:** By the definition of descending to the quotient space $G/\\Gamma$, we must have $\\operatorname{Ad}(g\\gamma) = \\operatorname{Ad}(g)$ for all $g \\in G$ and $\\gamma \\in \\Gamma$.\n    Evaluating this at $g=e$ (the identity of $G$):\n    $$ \\operatorname{Ad}(\\gamma) = \\operatorname{Ad}(e\\gamma) = \\operatorname{Ad}(e) = I $$\n    Therefore, $\\operatorname{Ad}(\\gamma) = I$ for all $\\gamma \\in \\Gamma$.\n    This implies $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$.\n2.  **Center Identification:** Using the Key Lemma established above for connected Lie groups, $\\ker(\\operatorname{Ad}) = Z(G)$.\n    Therefore:\n    $$ \\Gamma \\subseteq Z(G) $$\n\n### Role of Assumptions\nThe proof primarily relies on the connectedness of $G$ (to equate $\\ker(\\operatorname{Ad})$ with $Z(G)$). The assumptions that $\\mathfrak{g}$ is simple and $G/\\Gamma$ is compact ensure the problem is non-trivial and well-posed within the context of semisimple Lie theory:\n*   **Simplicity:** Since $\\mathfrak{g}$ is simple, its center is trivial ($Z(\\mathfrak{g})=0$), which implies that $Z(G)$ is a discrete subgroup of $G$. This is consistent with $\\Gamma$ being a discrete subgroup.\n*   **Compactness:** While not strictly required for the algebraic equivalence, the compactness of $G/\\Gamma$ (implying $\\Gamma$ is a uniform lattice) is a standard setting for such rigidity questions, ensuring well-behaved geometry.\n\n### Conclusion\nWe have shown that $\\operatorname{Ad}(g\\gamma) = \\operatorname{Ad}(g)$ is equivalent to $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$, and for a connected Lie group, $\\ker(\\operatorname{Ad}) = Z(G)$. Furthermore, for the descended map to form a group representation, $\\Gamma$ must be normal, which is automatically satisfied if $\\Gamma \\subseteq Z(G)$.\n\nTherefore, $\\Gamma$ is contained in the center of $G$ if and only if the adjoint representation of $G$ descends to a representation of $G/\\Gamma$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the requirements for the problem.\nThe task is to generate a challenging but solvable mathematics problem in the domain of real functions, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Determine the specific area within real functions to focus on.\nGiven the broad domain of real functions, we can consider various aspects such as differentiation, integration, functional equations, or properties of specific types of functions (e.g., continuous, differentiable, integrable).\n\n## Step 3: Choose a specific topic within real functions that can be used to create a challenging problem.\nLet's consider the topic of functional equations, which involves finding a function that satisfies a given equation involving the function and its inputs.\n\n## Step 4: Generate a challenging problem in the chosen topic.\nConsider the functional equation $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for $x, y \\in \\mathbb{R}$, where $f: \\mathbb{R} \\to \\mathbb{R}$. The task is to find all $f$ that satisfy this equation.\n\n## Step 5: Ensure the problem is well-posed and meets the quality rubric.\nThe given functional equation is well-defined, and the task is clear. We need to verify that it's non-trivial and solvable.\n\n## Step 6: Provide a solution to the generated problem.\nTo solve $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$, let's first check if there are any obvious solutions. For $y = 0$, we get $f(x) = \\frac{f(x) + f(0)}{1 - f(x)f(0)}$. This simplifies to $f(x)(1 - f(x)f(0)) = f(x) + f(0)$, or $f(x) - f(x)^2f(0) = f(x) + f(0)$, leading to $-f(x)^2f(0) = f(0)$. If $f(0) \\neq 0$, this gives $f(x)^2 = -1$ for all $x$, which is impossible for real-valued $f$. Thus, $f(0) = 0$.\n\n## Step 7: Continue solving the functional equation.\nSetting $y = x$, we have $f(2x) = \\frac{2f(x)}{1 - f(x)^2}$. This is a useful relation but let's first explore the derivative of $f$ if it exists. Assuming $f$ is differentiable, differentiating both sides with respect to $y$ and then setting $y = 0$ gives $f'(x) = \\frac{f'(0)(1 + f(x)^2)}{(1 - f(x)f(0))^2} = f'(0)(1 + f(x)^2)$ because $f(0) = 0$. So, $f'(x) = f'(0)(1 + f(x)^2)$.\n\n## Step 8: Solve the differential equation obtained from the functional equation.\nThe differential equation $f'(x) = f'(0)(1 + f(x)^2)$ can be solved by separation of variables: $\\frac{df}{1 + f^2} = f'(0)dx$. Integrating both sides gives $\\arctan(f(x)) = f'(0)x + C$, where $C$ is a constant. Since $f(0) = 0$, we have $C = 0$. Thus, $f(x) = \\tan(f'(0)x)$.\n\n## Step 9: Verify that the solution satisfies the original functional equation.\nSubstituting $f(x) = \\tan(f'(0)x)$ into the original equation: $\\tan(f'(0)(x+y)) = \\frac{\\tan(f'(0)x) + \\tan(f'(0)y)}{1 - \\tan(f'(0)x)\\tan(f'(0)y)}$, which is a known trigonometric identity, thus verifying that $f(x) = \\tan(f'(0)x)$ is a solution.\n\n## Step 10: Check if there are any constraints on $f'(0)$.\nFor $f(x) = \\tan(f'(0)x)$ to be defined for all $x \\in \\mathbb{R}$, $f'(0)$ must be $0$, otherwise, $f(x)$ will have discontinuities. If $f'(0) = 0$, then $f(x) = 0$ for all $x$, which is indeed a solution.\n\n## Step 11: Formulate the final problem and solution.\nLet's formulate the problem: \"Find all $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for all $x, y \\in \\mathbb{R}$.\"\n\n\nFind all $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for all $x, y \\in \\mathbb{R}$.",
    "run_id": "16",
    "outer_attempt": 1,
    "topic_slug": "real_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ satisfying the equation\n$$f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$$\nfor all $x, y \\in \\mathbb{R}$, we proceed with the following steps.\n\n### Step 1: Preliminary Analysis and Values\n\nFirst, we determine the value of $f(0)$. Letting $y = 0$ in the functional equation, we get:\n$$f(x) = \\frac{f(x) + f(0)}{1 - f(x)f(0)}$$\nAssuming the denominator is non-zero, we multiply through:\n$$f(x) [1 - f(x)f(0)] = f(x) + f(0)$$\n$$f(x) - f(x)^2 f(0) = f(x) + f(0)$$\n$$- f(x)^2 f(0) = f(0)$$\n$$f(0) [1 + f(x)^2] = 0$$\nSince $1 + f(x)^2 \\geq 1$ for any real $f(x)$, it is never zero. Therefore, we must have:\n$$f(0) = 0$$\n\nNext, we establish that $f(x)$ is an odd function. Letting $y = -x$, and using $f(0)=0$:\n$$f(0) = \\frac{f(x) + f(-x)}{1 - f(x)f(-x)} \\implies 0 = \\frac{f(x) + f(-x)}{1 - f(x)f(-x)}$$\nThis implies the numerator must be zero:\n$$f(x) + f(-x) = 0 \\implies f(-x) = -f(x)$$\n\n### Step 2: Domain Constraints and Range\n\nThe functional equation is valid only if the denominator $1 - f(x)f(y)$ is never zero. Thus, for all $x, y \\in \\mathbb{R}$:\n$$f(x)f(y) \\neq 1$$\nSetting $y = x$, we have $f(x)^2 \\neq 1$. This implies:\n$$f(x) \\neq 1 \\quad \\text{and} \\quad f(x) \\neq -1 \\quad \\text{for all } x \\in \\mathbb{R}.$$\n\n### Step 3: Transforming the Equation\n\nSince $f(x)$ never takes the values $\\pm 1$, the function $\\arctan(f(x))$ is well-defined. However, the standard arctangent maps to $(-\\pi/2, \\pi/2)$, while the general solution to $\\tan \\theta = z$ is $\\theta = \\arctan z + k\\pi$.\n\nLet us express $f(x)$ in terms of an auxiliary function $L(x)$:\n$$f(x) = \\tan(L(x))$$\nwhere $L(x)$ is a real-valued function. Substituting this into the original equation:\n$$\\tan(L(x+y)) = \\frac{\\tan(L(x)) + \\tan(L(y))}{1 - \\tan(L(x))\\tan(L(y))}$$\nBy the tangent addition formula, the right-hand side is $\\tan(L(x) + L(y))$. Thus:\n$$\\tan(L(x+y)) = \\tan(L(x) + L(y))$$\nThe general solution to $\\tan \\alpha = \\tan \\beta$ is $\\alpha = \\beta + k\\pi$ for some integer $k$. Therefore:\n$$L(x+y) = L(x) + L(y) + \\pi k(x, y)$$\nwhere $k(x, y)$ is an integer-valued function. This indicates that $L$ behaves like an additive function modulo $\\pi$. We can choose $L$ specifically to be an additive function $A: \\mathbb{R} \\to \\mathbb{R}$ satisfying the Cauchy functional equation:\n$$A(x+y) = A(x) + A(y)$$\nThen $f(x) = \\tan(A(x))$ satisfies the functional equation, provided the denominator condition is met.\n\n### Step 4: Validating the Constraint\n\nWe must ensure that the denominator in the original equation is never zero.\n$$1 - f(x)f(y) \\neq 0 \\iff 1 - \\tan(A(x))\\tan(A(y)) \\neq 0$$\nUsing the identity $\\cos(A+B) = \\cos A \\cos B - \\sin A \\sin B = \\cos A \\cos B (1 - \\tan A \\tan B)$, the condition is equivalent to:\n$$\\cos(A(x) + A(y)) \\neq 0$$\nThis holds if and only if:\n$$A(x) + A(y) \\neq \\frac{\\pi}{2} + n\\pi \\quad \\text{for all } n \\in \\mathbb{Z}$$\nSince $A$ is additive, $A(x+y) = A(x) + A(y)$. Let $z = x+y$. As $x$ and $y$ vary over $\\mathbb{R}$, $z$ varies over $\\mathbb{R}$. The condition simplifies to:\n$$\\text{Range}(A) \\cap \\left\\{ \\frac{\\pi}{2} + n\\pi \\mid n \\in \\mathbb{Z} \\right\\} = \\emptyset$$\n\n### Step 5: Classifying Solutions\n\n**Case 1: Continuous or Measurable Solutions**\nIf $f$ is continuous (or even Lebesgue measurable), then $A(x) = \\arctan(f(x))$ (lifted continuously) must be continuous. The only continuous solutions to the Cauchy functional equation $A(x+y) = A(x) + A(y)$ are of the form $A(x) = cx$ for some constant $c \\in \\mathbb{R}$.\nThe condition that the range of $A(x) = cx$ avoids the set $\\{\\pi/2 + n\\pi\\}$ implies that the range cannot be all of $\\mathbb{R}$. Since the range of $A(x) = cx$ is $\\mathbb{R}$ unless $c=0$ (in which case the range is $\\{0\\}$), we must have $c = 0$.\nIf $c = 0$, then $A(x) = 0$ for all $x$, which implies $f(x) = \\tan(0) = 0$.\n\n**Case 2: General Solutions**\nUsing the Axiom of Choice, there exist non-continuous additive functions (constructed using a Hamel basis of $\\mathbb{R}$ over $\\mathbb{Q}$).\nLet $A: \\mathbb{R} \\to \\mathbb{R}$ be an additive function. For $f(x) = \\tan(A(x))$ to be a solution, the image of $A$ must avoid the values $\\frac{\\pi}{2} + n\\pi$.\nOne class of such functions can be constructed by defining $A: \\mathbb{R} \\to \\mathbb{Q}$ (viewing $\\mathbb{R}$ as a vector space over $\\mathbb{Q}$ and mapping basis elements to rationals). Since $\\pi$ is irrational, the set $\\mathbb{Q}$ contains no elements of the form $\\frac{\\pi}{2} + n\\pi$ (which are irrational). Thus, any additive function with a rational range yields a valid non-trivial solution.\n\n### Conclusion\n\nThe solutions fall into two categories depending on regularity assumptions:\n\n1.  **Continuous Solution:** The only continuous function satisfying the equation is the zero function:\n    $$f(x) = 0$$\n\n2.  **General Solution:** The set of all solutions is given by:\n    $$f(x) = \\tan(A(x))$$\n    where $A: \\mathbb{R} \\to \\mathbb{R}$ is an additive function (i.e., $A(x+y) = A(x) + A(y)$) such that the range of $A$ contains no values of the form $\\frac{\\pi}{2} + n\\pi$ for any integer $n$.",
        "raw_answer": "To find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ satisfying the equation\n$$f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$$\nfor all $x, y \\in \\mathbb{R}$, we proceed with the following steps.\n\n### Step 1: Preliminary Analysis and Values\n\nFirst, we determine the value of $f(0)$. Letting $y = 0$ in the functional equation, we get:\n$$f(x) = \\frac{f(x) + f(0)}{1 - f(x)f(0)}$$\nAssuming the denominator is non-zero, we multiply through:\n$$f(x) [1 - f(x)f(0)] = f(x) + f(0)$$\n$$f(x) - f(x)^2 f(0) = f(x) + f(0)$$\n$$- f(x)^2 f(0) = f(0)$$\n$$f(0) [1 + f(x)^2] = 0$$\nSince $1 + f(x)^2 \\geq 1$ for any real $f(x)$, it is never zero. Therefore, we must have:\n$$f(0) = 0$$\n\nNext, we establish that $f(x)$ is an odd function. Letting $y = -x$, and using $f(0)=0$:\n$$f(0) = \\frac{f(x) + f(-x)}{1 - f(x)f(-x)} \\implies 0 = \\frac{f(x) + f(-x)}{1 - f(x)f(-x)}$$\nThis implies the numerator must be zero:\n$$f(x) + f(-x) = 0 \\implies f(-x) = -f(x)$$\n\n### Step 2: Domain Constraints and Range\n\nThe functional equation is valid only if the denominator $1 - f(x)f(y)$ is never zero. Thus, for all $x, y \\in \\mathbb{R}$:\n$$f(x)f(y) \\neq 1$$\nSetting $y = x$, we have $f(x)^2 \\neq 1$. This implies:\n$$f(x) \\neq 1 \\quad \\text{and} \\quad f(x) \\neq -1 \\quad \\text{for all } x \\in \\mathbb{R}.$$\n\n### Step 3: Transforming the Equation\n\nSince $f(x)$ never takes the values $\\pm 1$, the function $\\arctan(f(x))$ is well-defined. However, the standard arctangent maps to $(-\\pi/2, \\pi/2)$, while the general solution to $\\tan \\theta = z$ is $\\theta = \\arctan z + k\\pi$.\n\nLet us express $f(x)$ in terms of an auxiliary function $L(x)$:\n$$f(x) = \\tan(L(x))$$\nwhere $L(x)$ is a real-valued function. Substituting this into the original equation:\n$$\\tan(L(x+y)) = \\frac{\\tan(L(x)) + \\tan(L(y))}{1 - \\tan(L(x))\\tan(L(y))}$$\nBy the tangent addition formula, the right-hand side is $\\tan(L(x) + L(y))$. Thus:\n$$\\tan(L(x+y)) = \\tan(L(x) + L(y))$$\nThe general solution to $\\tan \\alpha = \\tan \\beta$ is $\\alpha = \\beta + k\\pi$ for some integer $k$. Therefore:\n$$L(x+y) = L(x) + L(y) + \\pi k(x, y)$$\nwhere $k(x, y)$ is an integer-valued function. This indicates that $L$ behaves like an additive function modulo $\\pi$. We can choose $L$ specifically to be an additive function $A: \\mathbb{R} \\to \\mathbb{R}$ satisfying the Cauchy functional equation:\n$$A(x+y) = A(x) + A(y)$$\nThen $f(x) = \\tan(A(x))$ satisfies the functional equation, provided the denominator condition is met.\n\n### Step 4: Validating the Constraint\n\nWe must ensure that the denominator in the original equation is never zero.\n$$1 - f(x)f(y) \\neq 0 \\iff 1 - \\tan(A(x))\\tan(A(y)) \\neq 0$$\nUsing the identity $\\cos(A+B) = \\cos A \\cos B - \\sin A \\sin B = \\cos A \\cos B (1 - \\tan A \\tan B)$, the condition is equivalent to:\n$$\\cos(A(x) + A(y)) \\neq 0$$\nThis holds if and only if:\n$$A(x) + A(y) \\neq \\frac{\\pi}{2} + n\\pi \\quad \\text{for all } n \\in \\mathbb{Z}$$\nSince $A$ is additive, $A(x+y) = A(x) + A(y)$. Let $z = x+y$. As $x$ and $y$ vary over $\\mathbb{R}$, $z$ varies over $\\mathbb{R}$. The condition simplifies to:\n$$\\text{Range}(A) \\cap \\left\\{ \\frac{\\pi}{2} + n\\pi \\mid n \\in \\mathbb{Z} \\right\\} = \\emptyset$$\n\n### Step 5: Classifying Solutions\n\n**Case 1: Continuous or Measurable Solutions**\nIf $f$ is continuous (or even Lebesgue measurable), then $A(x) = \\arctan(f(x))$ (lifted continuously) must be continuous. The only continuous solutions to the Cauchy functional equation $A(x+y) = A(x) + A(y)$ are of the form $A(x) = cx$ for some constant $c \\in \\mathbb{R}$.\nThe condition that the range of $A(x) = cx$ avoids the set $\\{\\pi/2 + n\\pi\\}$ implies that the range cannot be all of $\\mathbb{R}$. Since the range of $A(x) = cx$ is $\\mathbb{R}$ unless $c=0$ (in which case the range is $\\{0\\}$), we must have $c = 0$.\nIf $c = 0$, then $A(x) = 0$ for all $x$, which implies $f(x) = \\tan(0) = 0$.\n\n**Case 2: General Solutions**\nUsing the Axiom of Choice, there exist non-continuous additive functions (constructed using a Hamel basis of $\\mathbb{R}$ over $\\mathbb{Q}$).\nLet $A: \\mathbb{R} \\to \\mathbb{R}$ be an additive function. For $f(x) = \\tan(A(x))$ to be a solution, the image of $A$ must avoid the values $\\frac{\\pi}{2} + n\\pi$.\nOne class of such functions can be constructed by defining $A: \\mathbb{R} \\to \\mathbb{Q}$ (viewing $\\mathbb{R}$ as a vector space over $\\mathbb{Q}$ and mapping basis elements to rationals). Since $\\pi$ is irrational, the set $\\mathbb{Q}$ contains no elements of the form $\\frac{\\pi}{2} + n\\pi$ (which are irrational). Thus, any additive function with a rational range yields a valid non-trivial solution.\n\n### Conclusion\n\nThe solutions fall into two categories depending on regularity assumptions:\n\n1.  **Continuous Solution:** The only continuous function satisfying the equation is the zero function:\n    $$f(x) = 0$$\n\n2.  **General Solution:** The set of all solutions is given by:\n    $$f(x) = \\tan(A(x))$$\n    where $A: \\mathbb{R} \\to \\mathbb{R}$ is an additive function (i.e., $A(x+y) = A(x) + A(y)$) such that the range of $A$ contains no values of the form $\\frac{\\pi}{2} + n\\pi$ for any integer $n$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $f: [0,1] \\to \\mathbb{R}$ be a bounded measurable function. Prove that $\\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) dx = 0$.",
    "run_id": "17",
    "outer_attempt": 1,
    "topic_slug": "measure_and_integration",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Proof of the Riemann-Lebesgue Lemma for Bounded Measurable Functions on $[0,1]$**\n\nWe aim to prove that for a bounded measurable function $f: [0,1] \\to \\mathbb{R}$,\n$$ \\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) \\, dx = 0. $$\n\n### 1. Integrability of $f$\n\nFirst, we establish the integrability of $f$. We are given that $f$ is measurable and bounded on $[0,1]$. Let $M > 0$ be a bound such that $|f(x)| \\le M$ for all $x \\in [0,1]$.\nSince the interval $[0,1]$ has finite Lebesgue measure ($\\mu([0,1]) = 1$), the integral of the absolute value of $f$ is bounded:\n$$ \\int_{0}^{1} |f(x)| \\, dx \\le \\int_{0}^{1} M \\, dx = M < \\infty. $$\nThus, $f \\in L^1([0,1])$, the space of Lebesgue integrable functions on $[0,1]$.\n\n### 2. Strategy: Density Argument\n\nWe use a density argument. The set of **step functions** is dense in $L^1([0,1])$. This means that for any $f \\in L^1([0,1])$ and any $\\epsilon > 0$, there exists a step function $\\phi$ such that:\n$$ \\int_{0}^{1} |f(x) - \\phi(x)| \\, dx < \\frac{\\epsilon}{2}. $$\nA step function $\\phi$ on $[0,1]$ is a function that takes finitely many values on disjoint intervals. It can be written as a finite linear combination of characteristic functions of intervals:\n$$ \\phi(x) = \\sum_{j=1}^{k} c_j \\chi_{(a_j, b_j)}(x), $$\nwhere $c_j \\in \\mathbb{R}$, $(a_j, b_j) \\subseteq [0,1]$, and $\\chi_E$ denotes the characteristic function of the set $E$. Note that the inclusion or exclusion of endpoints does not affect the value of the integral.\n\n### 3. The Integral Split\n\nLet $\\epsilon > 0$ be arbitrary. We approximate $f$ by a step function $\\phi$ satisfying $\\|f - \\phi\\|_{L^1} < \\epsilon/2$.\nWe can split the target integral into two parts:\n$$ \\left| \\int_{0}^{1} f(x) \\sin(nx) \\, dx \\right| = \\left| \\int_{0}^{1} (f(x) - \\phi(x)) \\sin(nx) \\, dx + \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx \\right|. $$\nUsing the triangle inequality:\n$$ \\left| \\int_{0}^{1} f(x) \\sin(nx) \\, dx \\right| \\le \\underbrace{\\left| \\int_{0}^{1} (f(x) - \\phi(x)) \\sin(nx) \\, dx \\right|}_{I_1} + \\underbrace{\\left| \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx \\right|}_{I_2}. $$\n\n### 4. Bounding the First Term ($I_1$)\n\nWe estimate $I_1$ using the fact that $|\\sin(nx)| \\le 1$:\n$$ I_1 \\le \\int_{0}^{1} |f(x) - \\phi(x)| |\\sin(nx)| \\, dx \\le \\int_{0}^{1} |f(x) - \\phi(x)| \\, dx. $$\nBy our choice of $\\phi$, we have:\n$$ I_1 < \\frac{\\epsilon}{2}. $$\nThis bound holds for all $n$.\n\n### 5. Bounding the Second Term ($I_2$)\n\nWe compute the integral $I_2$ explicitly using the definition of $\\phi$:\n$$ \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx = \\int_{0}^{1} \\left( \\sum_{j=1}^{k} c_j \\chi_{(a_j, b_j)}(x) \\right) \\sin(nx) \\, dx = \\sum_{j=1}^{k} c_j \\int_{a_j}^{b_j} \\sin(nx) \\, dx. $$\nEvaluating the elementary integral $\\int \\sin(nx) dx = -\\frac{\\cos(nx)}{n}$:\n$$ \\int_{a_j}^{b_j} \\sin(nx) \\, dx = \\left[ -\\frac{\\cos(nx)}{n} \\right]_{a_j}^{b_j} = \\frac{\\cos(n a_j) - \\cos(n b_j)}{n}. $$\nSubstituting this back into the sum:\n$$ \\left| \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx \\right| = \\left| \\sum_{j=1}^{k} c_j \\frac{\\cos(n a_j) - \\cos(n b_j)}{n} \\right| \\le \\sum_{j=1}^{k} |c_j| \\frac{|\\cos(n a_j) - \\cos(n b_j)|}{n}. $$\nSince $|\\cos(\\theta)| \\le 1$, the term $|\\cos(n a_j) - \\cos(n b_j)| \\le 2$. Thus:\n$$ I_2 \\le \\frac{1}{n} \\sum_{j=1}^{k} 2|c_j|. $$\nThe sum $S = \\sum_{j=1}^{k} 2|c_j|$ is a constant independent of $n$ (it depends only on the fixed function $\\phi$).\nTherefore:\n$$ \\lim_{n \\to \\infty} \\frac{S}{n} = 0. $$\nThis implies there exists an integer $N$ such that for all $n > N$:\n$$ I_2 < \\frac{\\epsilon}{2}. $$\n\n### 6. Conclusion\n\nCombining the bounds for $I_1$ and $I_2$, for all $n > N$, we have:\n$$ \\left| \\int_{0}^{1} f(x) \\sin(nx) \\, dx \\right| \\le I_1 + I_2 < \\frac{\\epsilon}{2} + \\frac{\\epsilon}{2} = \\epsilon. $$\nSince $\\epsilon > 0$ was arbitrary, we conclude that:\n$$ \\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) \\, dx = 0. $$",
        "raw_answer": "**Proof of the Riemann-Lebesgue Lemma for Bounded Measurable Functions on $[0,1]$**\n\nWe aim to prove that for a bounded measurable function $f: [0,1] \\to \\mathbb{R}$,\n$$ \\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) \\, dx = 0. $$\n\n### 1. Integrability of $f$\n\nFirst, we establish the integrability of $f$. We are given that $f$ is measurable and bounded on $[0,1]$. Let $M > 0$ be a bound such that $|f(x)| \\le M$ for all $x \\in [0,1]$.\nSince the interval $[0,1]$ has finite Lebesgue measure ($\\mu([0,1]) = 1$), the integral of the absolute value of $f$ is bounded:\n$$ \\int_{0}^{1} |f(x)| \\, dx \\le \\int_{0}^{1} M \\, dx = M < \\infty. $$\nThus, $f \\in L^1([0,1])$, the space of Lebesgue integrable functions on $[0,1]$.\n\n### 2. Strategy: Density Argument\n\nWe use a density argument. The set of **step functions** is dense in $L^1([0,1])$. This means that for any $f \\in L^1([0,1])$ and any $\\epsilon > 0$, there exists a step function $\\phi$ such that:\n$$ \\int_{0}^{1} |f(x) - \\phi(x)| \\, dx < \\frac{\\epsilon}{2}. $$\nA step function $\\phi$ on $[0,1]$ is a function that takes finitely many values on disjoint intervals. It can be written as a finite linear combination of characteristic functions of intervals:\n$$ \\phi(x) = \\sum_{j=1}^{k} c_j \\chi_{(a_j, b_j)}(x), $$\nwhere $c_j \\in \\mathbb{R}$, $(a_j, b_j) \\subseteq [0,1]$, and $\\chi_E$ denotes the characteristic function of the set $E$. Note that the inclusion or exclusion of endpoints does not affect the value of the integral.\n\n### 3. The Integral Split\n\nLet $\\epsilon > 0$ be arbitrary. We approximate $f$ by a step function $\\phi$ satisfying $\\|f - \\phi\\|_{L^1} < \\epsilon/2$.\nWe can split the target integral into two parts:\n$$ \\left| \\int_{0}^{1} f(x) \\sin(nx) \\, dx \\right| = \\left| \\int_{0}^{1} (f(x) - \\phi(x)) \\sin(nx) \\, dx + \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx \\right|. $$\nUsing the triangle inequality:\n$$ \\left| \\int_{0}^{1} f(x) \\sin(nx) \\, dx \\right| \\le \\underbrace{\\left| \\int_{0}^{1} (f(x) - \\phi(x)) \\sin(nx) \\, dx \\right|}_{I_1} + \\underbrace{\\left| \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx \\right|}_{I_2}. $$\n\n### 4. Bounding the First Term ($I_1$)\n\nWe estimate $I_1$ using the fact that $|\\sin(nx)| \\le 1$:\n$$ I_1 \\le \\int_{0}^{1} |f(x) - \\phi(x)| |\\sin(nx)| \\, dx \\le \\int_{0}^{1} |f(x) - \\phi(x)| \\, dx. $$\nBy our choice of $\\phi$, we have:\n$$ I_1 < \\frac{\\epsilon}{2}. $$\nThis bound holds for all $n$.\n\n### 5. Bounding the Second Term ($I_2$)\n\nWe compute the integral $I_2$ explicitly using the definition of $\\phi$:\n$$ \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx = \\int_{0}^{1} \\left( \\sum_{j=1}^{k} c_j \\chi_{(a_j, b_j)}(x) \\right) \\sin(nx) \\, dx = \\sum_{j=1}^{k} c_j \\int_{a_j}^{b_j} \\sin(nx) \\, dx. $$\nEvaluating the elementary integral $\\int \\sin(nx) dx = -\\frac{\\cos(nx)}{n}$:\n$$ \\int_{a_j}^{b_j} \\sin(nx) \\, dx = \\left[ -\\frac{\\cos(nx)}{n} \\right]_{a_j}^{b_j} = \\frac{\\cos(n a_j) - \\cos(n b_j)}{n}. $$\nSubstituting this back into the sum:\n$$ \\left| \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx \\right| = \\left| \\sum_{j=1}^{k} c_j \\frac{\\cos(n a_j) - \\cos(n b_j)}{n} \\right| \\le \\sum_{j=1}^{k} |c_j| \\frac{|\\cos(n a_j) - \\cos(n b_j)|}{n}. $$\nSince $|\\cos(\\theta)| \\le 1$, the term $|\\cos(n a_j) - \\cos(n b_j)| \\le 2$. Thus:\n$$ I_2 \\le \\frac{1}{n} \\sum_{j=1}^{k} 2|c_j|. $$\nThe sum $S = \\sum_{j=1}^{k} 2|c_j|$ is a constant independent of $n$ (it depends only on the fixed function $\\phi$).\nTherefore:\n$$ \\lim_{n \\to \\infty} \\frac{S}{n} = 0. $$\nThis implies there exists an integer $N$ such that for all $n > N$:\n$$ I_2 < \\frac{\\epsilon}{2}. $$\n\n### 6. Conclusion\n\nCombining the bounds for $I_1$ and $I_2$, for all $n > N$, we have:\n$$ \\left| \\int_{0}^{1} f(x) \\sin(nx) \\, dx \\right| \\le I_1 + I_2 < \\frac{\\epsilon}{2} + \\frac{\\epsilon}{2} = \\epsilon. $$\nSince $\\epsilon > 0$ was arbitrary, we conclude that:\n$$ \\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) \\, dx = 0. $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of \"Functions of a complex variable\" along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the domain and requirements\nThe domain is \"Functions of a complex variable.\" This involves complex analysis, including topics like analytic functions, contour integration, and possibly properties of specific functions like the exponential or logarithmic function in the complex plane.\n\n## Step 3: Generate a problem\nTo create a challenging problem, we should consider a topic that requires a good understanding of complex analysis. One such topic is contour integration and the application of Cauchy's Integral Formula or the Residue Theorem.\n\n## Step 4: Formulate the problem\nLet's consider a problem that involves evaluating a contour integral using the Residue Theorem, which is a fundamental technique in complex analysis.\n\n## Step 5: Specify the problem\nThe problem could be: \"Evaluate the integral $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, where the contour $|z| = 2$ is traversed in the positive direction.\"\n\n## Step 6: Provide the solution\nTo solve $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, first identify the singularities of the integrand within the contour $|z| = 2$. The singularities occur at $z = \\pm i$, both of which are inside $|z| = 2$ since $|i| = |-i| = 1 < 2$.\n\n## Step 7: Apply the Residue Theorem\nThe Residue Theorem states that $\\oint_C f(z) dz = 2\\pi i \\sum \\text{Res}(f, z_j)$, where $z_j$ are the singularities enclosed by $C$. We need to calculate the residues at $z = i$ and $z = -i$.\n\n## Step 8: Calculate the residue at $z = i$\nThe residue of $\\frac{e^z}{z^2 + 1}$ at $z = i$ can be found using the formula for simple poles: $\\text{Res}(f, z_0) = \\lim_{z \\to z_0} (z - z_0)f(z)$. So, $\\text{Res}(f, i) = \\lim_{z \\to i} (z - i)\\frac{e^z}{(z - i)(z + i)} = \\lim_{z \\to i} \\frac{e^z}{z + i} = \\frac{e^i}{2i}$.\n\n## Step 9: Calculate the residue at $z = -i$\nSimilarly, $\\text{Res}(f, -i) = \\lim_{z \\to -i} (z + i)\\frac{e^z}{(z + i)(z - i)} = \\lim_{z \\to -i} \\frac{e^z}{z - i} = \\frac{e^{-i}}{-2i}$.\n\n## Step 10: Sum the residues and apply the Residue Theorem\n$\\sum \\text{Res} = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i} = \\sin(1)$, because $e^i - e^{-i} = 2i\\sin(1)$.\n\n## Step 11: Calculate the integral\n$\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz = 2\\pi i \\sin(1)$.\n\n## Step 12: Write the final answer in the required format\n\nEvaluate the integral $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, where the contour $|z| = 2$ is traversed in the positive direction.",
    "run_id": "18",
    "outer_attempt": 1,
    "topic_slug": "functions_of_a_complex_variable",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To evaluate the integral\n$$ I = \\oint_{|z|=2} \\frac{e^z}{z^2 + 1} \\, dz $$\nwhere the contour $C$ defined by $|z|=2$ is traversed in the positive (counter-clockwise) direction, we will use the **Cauchy Residue Theorem**.\n\n### 1. Identify Singularities\nLet $f(z) = \\frac{e^z}{z^2 + 1}$. The singularities of $f(z)$ occur where the denominator is zero:\n$$ z^2 + 1 = 0 \\implies z^2 = -1 \\implies z = \\pm i $$\nThe function $f(z)$ has simple poles at $z_1 = i$ and $z_2 = -i$ because the numerator $e^z$ is non-zero at these points ($e^{\\pm i} \\neq 0$) and the derivative of the denominator ($2z$) is non-zero at $z = \\pm i$.\n\n### 2. Check Singularities within the Contour\nThe contour is the circle centered at the origin with radius $R=2$. We check if the poles lie inside this contour:\n- For $z_1 = i$, $|z_1| = |i| = 1$. Since $1 < 2$, $z_1$ lies inside $C$.\n- For $z_2 = -i$, $|z_2| = |-i| = 1$. Since $1 < 2$, $z_2$ lies inside $C$.\n\nBoth poles are enclosed by the contour.\n\n### 3. Calculate Residues\nAccording to the Residue Theorem,\n$$ \\oint_C f(z) \\, dz = 2\\pi i \\left( \\text{Res}(f, i) + \\text{Res}(f, -i) \\right) $$\n\nWe calculate the residue at a simple pole $z_0$ using the formula:\n$$ \\text{Res}(f, z_0) = \\lim_{z \\to z_0} (z - z_0) f(z) = \\frac{g(z_0)}{h'(z_0)} $$\nwhere $f(z) = \\frac{g(z)}{h(z)}$, $g(z) = e^z$, and $h(z) = z^2 + 1$. Note that $h'(z) = 2z$.\n\n**Residue at $z = i$:**\n$$ \\text{Res}(f, i) = \\frac{e^i}{2(i)} = \\frac{e^i}{2i} $$\n\n**Residue at $z = -i$:**\n$$ \\text{Res}(f, -i) = \\frac{e^{-i}}{2(-i)} = -\\frac{e^{-i}}{2i} $$\n\n### 4. Sum the Residues and Evaluate the Integral\nNow sum the residues:\n$$ \\sum \\text{Res} = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i} $$\nRecall the definition of the sine function for complex arguments:\n$$ \\sin(z) = \\frac{e^{iz} - e^{-iz}}{2i} $$\nFor $z=1$, this becomes:\n$$ \\sin(1) = \\frac{e^{i} - e^{-i}}{2i} $$\nThus, the sum of the residues is $\\sin(1)$.\n\nFinally, multiply by $2\\pi i$:\n$$ I = 2\\pi i (\\sin(1)) = 2\\pi i \\sin(1) $$\n\n### Conclusion\nThe value of the integral is:\n$$ \\oint_{|z|=2} \\frac{e^z}{z^2 + 1} \\, dz = 2\\pi i \\sin(1) $$",
        "raw_answer": "To evaluate the integral\n$$ I = \\oint_{|z|=2} \\frac{e^z}{z^2 + 1} \\, dz $$\nwhere the contour $C$ defined by $|z|=2$ is traversed in the positive (counter-clockwise) direction, we will use the **Cauchy Residue Theorem**.\n\n### 1. Identify Singularities\nLet $f(z) = \\frac{e^z}{z^2 + 1}$. The singularities of $f(z)$ occur where the denominator is zero:\n$$ z^2 + 1 = 0 \\implies z^2 = -1 \\implies z = \\pm i $$\nThe function $f(z)$ has simple poles at $z_1 = i$ and $z_2 = -i$ because the numerator $e^z$ is non-zero at these points ($e^{\\pm i} \\neq 0$) and the derivative of the denominator ($2z$) is non-zero at $z = \\pm i$.\n\n### 2. Check Singularities within the Contour\nThe contour is the circle centered at the origin with radius $R=2$. We check if the poles lie inside this contour:\n- For $z_1 = i$, $|z_1| = |i| = 1$. Since $1 < 2$, $z_1$ lies inside $C$.\n- For $z_2 = -i$, $|z_2| = |-i| = 1$. Since $1 < 2$, $z_2$ lies inside $C$.\n\nBoth poles are enclosed by the contour.\n\n### 3. Calculate Residues\nAccording to the Residue Theorem,\n$$ \\oint_C f(z) \\, dz = 2\\pi i \\left( \\text{Res}(f, i) + \\text{Res}(f, -i) \\right) $$\n\nWe calculate the residue at a simple pole $z_0$ using the formula:\n$$ \\text{Res}(f, z_0) = \\lim_{z \\to z_0} (z - z_0) f(z) = \\frac{g(z_0)}{h'(z_0)} $$\nwhere $f(z) = \\frac{g(z)}{h(z)}$, $g(z) = e^z$, and $h(z) = z^2 + 1$. Note that $h'(z) = 2z$.\n\n**Residue at $z = i$:**\n$$ \\text{Res}(f, i) = \\frac{e^i}{2(i)} = \\frac{e^i}{2i} $$\n\n**Residue at $z = -i$:**\n$$ \\text{Res}(f, -i) = \\frac{e^{-i}}{2(-i)} = -\\frac{e^{-i}}{2i} $$\n\n### 4. Sum the Residues and Evaluate the Integral\nNow sum the residues:\n$$ \\sum \\text{Res} = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i} $$\nRecall the definition of the sine function for complex arguments:\n$$ \\sin(z) = \\frac{e^{iz} - e^{-iz}}{2i} $$\nFor $z=1$, this becomes:\n$$ \\sin(1) = \\frac{e^{i} - e^{-i}}{2i} $$\nThus, the sum of the residues is $\\sin(1)$.\n\nFinally, multiply by $2\\pi i$:\n$$ I = 2\\pi i (\\sin(1)) = 2\\pi i \\sin(1) $$\n\n### Conclusion\nThe value of the integral is:\n$$ \\oint_{|z|=2} \\frac{e^z}{z^2 + 1} \\, dz = 2\\pi i \\sin(1) $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Potential theory, along with a complete and verifiable solution. Potential theory is a branch of mathematics that deals with the study of potentials and their properties, particularly in relation to partial differential equations, especially Laplace's equation.\n\n## Step 2: Identify key concepts in Potential theory\nPotential theory involves the study of harmonic functions, potentials (such as Newtonian or logarithmic potentials), and their applications. Key concepts include the Laplace equation ($\\Delta u = 0$), Poisson's equation ($\\Delta u = f$), and boundary value problems (Dirichlet and Neumann problems).\n\n## Step 3: Formulate a problem\nTo create a challenging problem, we need to involve some of the advanced concepts or techniques from Potential theory. Let's consider a problem involving the Dirichlet problem for the Laplace equation on a specific domain.\n\n## Step 4: Specify the problem\nLet's consider the following problem: \"Let $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.\"\n\n## Step 5: Provide the solution\nTo solve this problem, we can use the Poisson integral formula, which gives the solution to the Dirichlet problem on the unit disk. The Poisson integral formula is given by $u(x) = \\frac{1}{2\\pi} \\int_{\\partial D} \\frac{1 - |x|^2}{|x - y|^2} f(y) ds(y)$, where $f(y)$ is the boundary data.\n\n## Step 6: Apply the Poisson integral formula\nFor $x = (r\\cos\\theta, r\\sin\\theta)$ and $y = (\\cos\\phi, \\sin\\phi)$, we have $|x - y|^2 = r^2 - 2r\\cos(\\theta - \\phi) + 1$ and $ds(y) = d\\phi$. The boundary data is $f(y) = \\log|y - (1,0)| = \\log\\sqrt{2 - 2\\cos\\phi}$. So, $u(x) = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} \\frac{1 - r^2}{r^2 - 2r\\cos(\\theta - \\phi) + 1} \\log\\sqrt{2 - 2\\cos\\phi} d\\phi$.\n\n## Step 7: Simplify the integral\nThe integral can be simplified by recognizing that $\\log\\sqrt{2 - 2\\cos\\phi} = \\log|1 - e^{i\\phi}| = \\log|1 - e^{i\\phi}| = \\Re(\\log(1 - e^{i\\phi}))$. However, directly evaluating this integral is complex and typically involves recognizing it as a special case that can be related to the properties of harmonic functions and the Poisson kernel.\n\n## Step 8: Evaluate the solution using properties of harmonic functions\nFor $x \\in D$, the solution can be found by directly applying properties of harmonic functions and recognizing that the given boundary condition corresponds to a specific harmonic function. The function $u(x) = \\log|x - (1,0)|$ is harmonic in $D$ except at $x = (1,0)$, which is outside $D$ since $|1,0| = 1$ is on $\\partial D$. Thus, we directly check if $u(x)$ satisfies the given boundary condition and is harmonic.\n\n## Step 9: Check if the given boundary data directly provides the solution\nSince $\\log|x - (1,0)|$ is harmonic in $D$ and equals $\\log|y - (1,0)|$ on $\\partial D$, it is the solution to the Dirichlet problem.\n\nThe final answer is: \n\nLet $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.",
    "run_id": "19",
    "outer_attempt": 1,
    "topic_slug": "potential_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the solution to the Dirichlet problem for the Laplace equation on the unit disk with the specified boundary condition, we will proceed through a rigorous mathematical derivation.\n\n### 1. Problem Statement\n\nLet $D = \\{x \\in \\mathbb{R}^2 : |x| < 1\\}$ be the open unit disk. We seek a function $u: D \\to \\mathbb{R}$ satisfying:\n1.  **Laplace's Equation:** $\\Delta u(x) = 0$ for all $x \\in D$.\n2.  **Boundary Condition:** $\\lim_{x \\to y, x \\in D} u(x) = \\log|y - (1,0)|$ for $y \\in \\partial D \\setminus \\{(1,0)\\}$.\n\nThe boundary data is given by $f(y) = \\log|y - (1,0)|$. We note that the point $(1,0)$ lies on the boundary $\\partial D$. The function $f(y)$ is singular at $(1,0)$ (approaching $-\\infty$), so we interpret the boundary condition in the sense of the Poisson integral for $L^1$ boundary data.\n\n### 2. Analysis of the Candidate Solution\n\nA powerful technique in potential theory is to inspect whether the function defining the boundary data is itself harmonic in the interior domain.\n\nConsider the function defined on $\\mathbb{R}^2 \\setminus \\{(1,0)\\}$:\n$$ v(x) = \\log|x - (1,0)| $$\n\n**Step 2.1: Verify Harmonicity**\nWe identify $\\mathbb{R}^2$ with the complex plane $\\mathbb{C}$. Let $x \\cong z = x_1 + i x_2$. Then $(1,0) \\cong 1$.\nThe function becomes $v(z) = \\log|z - 1|$.\nRecall that for any holomorphic function $g(z)$, its real part $\\Re(g(z))$ is harmonic.\nConsider the principal branch of the complex logarithm, $\\log(z - 1)$. This function is holomorphic on $\\mathbb{C} \\setminus (-\\infty, 1]$.\nHowever, we only need the function to be harmonic in the domain $D$ (the unit disk).\nThe singularity of $\\log(z - 1)$ is at $z = 1$. The branch cut can be taken along the ray $[1, \\infty)$ on the real axis, or any ray starting at 1 that does not intersect $D$.\nRegardless of the branch cut, the real part is well-defined:\n$$ \\Re(\\log(z - 1)) = \\log|z - 1| $$\nSince $\\log(z - 1)$ is holomorphic locally around any point in $D$ (as $1 \\notin D$), its real part $v(z) = \\log|z - 1|$ is harmonic in $D$.\n$$ \\Delta v = 0 \\quad \\text{for } x \\in D $$\n\n**Step 2.2: Verify Boundary Conditions**\nFor any $y \\in \\partial D \\setminus \\{(1,0)\\}$, the proposed solution $v(y)$ is exactly $\\log|y - (1,0)|$.\nThus, $v(x)$ satisfies the boundary condition pointwise everywhere except at the singularity $(1,0)$.\n\n### 3. Rigorous Derivation via Fourier Series\n\nTo ensure $v(x)$ is the unique solution in the appropriate class (Poisson integral of $L^1$ data), we derive it constructively using Fourier series.\n\nParametrize the boundary $\\partial D$ by $y(\\theta) = e^{i\\theta}$ for $\\theta \\in (0, 2\\pi)$.\nThe boundary data is:\n$$ f(\\theta) = \\log|e^{i\\theta} - 1| $$\nUsing the identity $|e^{i\\theta} - 1| = 2|\\sin(\\frac{\\theta}{2})|$, we have $f(\\theta) = \\log(2|\\sin(\\frac{\\theta}{2})|)$.\n\nWe utilize the known Fourier series expansion for this function. Recall the Taylor series for the principal logarithm for $|z| < 1$:\n$$ \\log(1 - z) = -\\sum_{n=1}^{\\infty} \\frac{z^n}{n} $$\nLet $z = r e^{i\\theta}$ with $r < 1$. Taking the real part:\n$$ \\Re(\\log(1 - r e^{i\\theta})) = -\\sum_{n=1}^{\\infty} \\frac{r^n \\cos(n\\theta)}{n} $$\nAccording to Abel's theorem, as $r \\to 1^-$, this series converges to the boundary function almost everywhere (specifically for $\\theta \\neq 0$):\n$$ \\Re(\\log(1 - e^{i\\theta})) = \\log|1 - e^{i\\theta}| = \\log|e^{i\\theta} - 1| $$\nThus, the Fourier series of our boundary data is:\n$$ f(\\theta) \\sim -\\sum_{n=1}^{\\infty} \\frac{\\cos(n\\theta)}{n} $$\nThe solution to the Dirichlet problem is the harmonic extension of this series into the interior $D$ (where $x \\cong r e^{i\\theta}$):\n$$ u(r, \\theta) = -\\sum_{n=1}^{\\infty} r^n \\frac{\\cos(n\\theta)}{n} $$\nRecognizing this sum as the real part of the Taylor series for $\\log(1-z)$ evaluated at $z = r e^{i\\theta}$:\n$$ u(r, \\theta) = \\Re\\left( \\log(1 - r e^{i\\theta}) \\right) = \\log|1 - r e^{i\\theta}| $$\nIn Cartesian coordinates, $|1 - r e^{i\\theta}| = |1 - x| = |x - (1,0)|$.\n\n### 4. Conclusion\n\nThe function $u(x) = \\log|x - (1,0)|$ is harmonic in $D$ and satisfies the prescribed boundary conditions. It is the unique solution given by the Poisson integral of the boundary data.\n\n**Final Answer:**\nThe solution to the Dirichlet problem is:\n$$ u(x) = \\log|x - (1,0)| $$",
        "raw_answer": "To find the solution to the Dirichlet problem for the Laplace equation on the unit disk with the specified boundary condition, we will proceed through a rigorous mathematical derivation.\n\n### 1. Problem Statement\n\nLet $D = \\{x \\in \\mathbb{R}^2 : |x| < 1\\}$ be the open unit disk. We seek a function $u: D \\to \\mathbb{R}$ satisfying:\n1.  **Laplace's Equation:** $\\Delta u(x) = 0$ for all $x \\in D$.\n2.  **Boundary Condition:** $\\lim_{x \\to y, x \\in D} u(x) = \\log|y - (1,0)|$ for $y \\in \\partial D \\setminus \\{(1,0)\\}$.\n\nThe boundary data is given by $f(y) = \\log|y - (1,0)|$. We note that the point $(1,0)$ lies on the boundary $\\partial D$. The function $f(y)$ is singular at $(1,0)$ (approaching $-\\infty$), so we interpret the boundary condition in the sense of the Poisson integral for $L^1$ boundary data.\n\n### 2. Analysis of the Candidate Solution\n\nA powerful technique in potential theory is to inspect whether the function defining the boundary data is itself harmonic in the interior domain.\n\nConsider the function defined on $\\mathbb{R}^2 \\setminus \\{(1,0)\\}$:\n$$ v(x) = \\log|x - (1,0)| $$\n\n**Step 2.1: Verify Harmonicity**\nWe identify $\\mathbb{R}^2$ with the complex plane $\\mathbb{C}$. Let $x \\cong z = x_1 + i x_2$. Then $(1,0) \\cong 1$.\nThe function becomes $v(z) = \\log|z - 1|$.\nRecall that for any holomorphic function $g(z)$, its real part $\\Re(g(z))$ is harmonic.\nConsider the principal branch of the complex logarithm, $\\log(z - 1)$. This function is holomorphic on $\\mathbb{C} \\setminus (-\\infty, 1]$.\nHowever, we only need the function to be harmonic in the domain $D$ (the unit disk).\nThe singularity of $\\log(z - 1)$ is at $z = 1$. The branch cut can be taken along the ray $[1, \\infty)$ on the real axis, or any ray starting at 1 that does not intersect $D$.\nRegardless of the branch cut, the real part is well-defined:\n$$ \\Re(\\log(z - 1)) = \\log|z - 1| $$\nSince $\\log(z - 1)$ is holomorphic locally around any point in $D$ (as $1 \\notin D$), its real part $v(z) = \\log|z - 1|$ is harmonic in $D$.\n$$ \\Delta v = 0 \\quad \\text{for } x \\in D $$\n\n**Step 2.2: Verify Boundary Conditions**\nFor any $y \\in \\partial D \\setminus \\{(1,0)\\}$, the proposed solution $v(y)$ is exactly $\\log|y - (1,0)|$.\nThus, $v(x)$ satisfies the boundary condition pointwise everywhere except at the singularity $(1,0)$.\n\n### 3. Rigorous Derivation via Fourier Series\n\nTo ensure $v(x)$ is the unique solution in the appropriate class (Poisson integral of $L^1$ data), we derive it constructively using Fourier series.\n\nParametrize the boundary $\\partial D$ by $y(\\theta) = e^{i\\theta}$ for $\\theta \\in (0, 2\\pi)$.\nThe boundary data is:\n$$ f(\\theta) = \\log|e^{i\\theta} - 1| $$\nUsing the identity $|e^{i\\theta} - 1| = 2|\\sin(\\frac{\\theta}{2})|$, we have $f(\\theta) = \\log(2|\\sin(\\frac{\\theta}{2})|)$.\n\nWe utilize the known Fourier series expansion for this function. Recall the Taylor series for the principal logarithm for $|z| < 1$:\n$$ \\log(1 - z) = -\\sum_{n=1}^{\\infty} \\frac{z^n}{n} $$\nLet $z = r e^{i\\theta}$ with $r < 1$. Taking the real part:\n$$ \\Re(\\log(1 - r e^{i\\theta})) = -\\sum_{n=1}^{\\infty} \\frac{r^n \\cos(n\\theta)}{n} $$\nAccording to Abel's theorem, as $r \\to 1^-$, this series converges to the boundary function almost everywhere (specifically for $\\theta \\neq 0$):\n$$ \\Re(\\log(1 - e^{i\\theta})) = \\log|1 - e^{i\\theta}| = \\log|e^{i\\theta} - 1| $$\nThus, the Fourier series of our boundary data is:\n$$ f(\\theta) \\sim -\\sum_{n=1}^{\\infty} \\frac{\\cos(n\\theta)}{n} $$\nThe solution to the Dirichlet problem is the harmonic extension of this series into the interior $D$ (where $x \\cong r e^{i\\theta}$):\n$$ u(r, \\theta) = -\\sum_{n=1}^{\\infty} r^n \\frac{\\cos(n\\theta)}{n} $$\nRecognizing this sum as the real part of the Taylor series for $\\log(1-z)$ evaluated at $z = r e^{i\\theta}$:\n$$ u(r, \\theta) = \\Re\\left( \\log(1 - r e^{i\\theta}) \\right) = \\log|1 - r e^{i\\theta}| $$\nIn Cartesian coordinates, $|1 - r e^{i\\theta}| = |1 - x| = |x - (1,0)|$.\n\n### 4. Conclusion\n\nThe function $u(x) = \\log|x - (1,0)|$ is harmonic in $D$ and satisfies the prescribed boundary conditions. It is the unique solution given by the Poisson integral of the boundary data.\n\n**Final Answer:**\nThe solution to the Dirichlet problem is:\n$$ u(x) = \\log|x - (1,0)| $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Several complex variables and analytic spaces\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify key concepts in the domain\nSeveral complex variables and analytic spaces involve the study of functions of multiple complex variables and the spaces on which these functions are defined. Key concepts include holomorphic functions, complex manifolds, analytic continuation, and various types of domains (e.g., domains of holomorphy, pseudoconvex domains).\n\n## Step 3: Formulate a problem\nTo create a problem, we need to focus on a specific aspect of several complex variables. Let's consider the concept of holomorphic functions on a domain in $\\mathbb{C}^n$. A potential problem could involve characterizing or analyzing the properties of such functions.\n\n## Step 4: Specify the problem\nLet's formulate a problem related to the extension of holomorphic functions. A well-known result in several complex variables is the Hartogs' extension theorem, which states that any holomorphic function defined on a domain in $\\mathbb{C}^n$ ($n > 1$) with a compact hole can be extended holomorphically to the whole domain. We can create a problem related to this concept.\n\n## Step 5: Create the problem statement\nConsider the domain $\\Omega = \\{z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1\\}$ and the subset $S = \\{z \\in \\Omega : |z_1| < \\frac{1}{2}\\}$. Let $f$ be a holomorphic function on $\\Omega \\setminus S$. Show that $f$ can be extended to a holomorphic function on $\\Omega$.\n\n## Step 6: Provide the solution\nTo solve this, we recognize that $\\Omega \\setminus S$ is not a compact hole in $\\Omega$, so we cannot directly apply Hartogs' theorem. However, we can analyze the problem by considering the properties of holomorphic functions in $\\mathbb{C}^2$ and the specific geometry of $\\Omega$ and $S$.\n\n## Step 7: Detail the solution\nFor $z = (z_1, z_2) \\in \\Omega \\setminus S$, $f(z)$ is holomorphic. We need to show that $f$ can be extended holomorphically to $\\Omega$. For any fixed $z_2$ with $|z_2| < 1$, $f(z_1, z_2)$ is holomorphic in $z_1$ for $\\frac{1}{2} \\leq |z_1| < 1$. By the principle of analytic continuation in one variable, if $f(z_1, z_2)$ is holomorphic for $|z_1| < 1$ except on a smaller disk, it can be extended. However, the direct application of Hartogs' theorem is not possible here due to the shape of $S$. Instead, we can use the fact that for each $z_2$, $f(\\cdot, z_2)$ can be extended to $|z_1| < 1$ because the singularity set is contained within $|z_1| \\leq \\frac{1}{2}$, and then apply Hartogs' theorem or a similar principle to conclude the extension is holomorphic in both variables.\n\n## Step 8: Write the problem and solution in the required format\n\nLet $\\Omega = \\{z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1\\}$ and $S = \\{z \\in \\Omega : |z_1| < \\frac{1}{2}\\}$. Suppose $f$ is a holomorphic function on $\\Omega \\setminus S$. Prove that $f$ can be extended to a holomorphic function on $\\Omega$.",
    "run_id": "20",
    "outer_attempt": 1,
    "topic_slug": "several_complex_variables_and_analytic_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The question presented in Step 8 is **ill-posed** because it asks for a proof of a mathematical assertion that is **false**. The problem violates the **Contradictory Premises** validity condition, as it assumes that a specific class of functions always admits a holomorphic extension when, in fact, it does not.\n\nBelow is the rigorous demonstration that the assertion is false, provided via a counterexample, followed by an analysis of the geometric obstruction.\n\n### 1. Analysis of the Domain and Statement\n\nLet us explicitly define the sets given in the problem statement:\n- The domain $\\Omega = \\{ z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1 \\}$ is the unit polydisc $\\Delta^2$.\n- The subset $S = \\{ z \\in \\Omega : |z_1| < \\frac{1}{2} \\}$.\n\nThe domain of definition for the function $f$ is $D = \\Omega \\setminus S$. We can determine the explicit structure of $D$:\n$$\nD = \\{ (z_1, z_2) \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1 \\} \\setminus \\{ (z_1, z_2) \\in \\mathbb{C}^2 : |z_1| < \\frac{1}{2}, |z_2| < 1 \\}\n$$\n$$\nD = \\{ (z_1, z_2) \\in \\mathbb{C}^2 : \\frac{1}{2} \\leq |z_1| < 1, \\, |z_2| < 1 \\}\n$$\nGeometrically, $D$ is the Cartesian product of an annulus $A = \\{ z_1 \\in \\mathbb{C} : \\frac{1}{2} \\leq |z_1| < 1 \\}$ and the unit disc $\\Delta = \\{ z_2 \\in \\mathbb{C} : |z_2| < 1 \\}$.\n\nThe question asks to prove that **any** holomorphic function $f$ on $D$ can be extended to a holomorphic function on $\\Omega$.\n\n### 2. Counterexample\n\nWe construct a function $f$ that is holomorphic on $D$ but cannot be extended holomorphically to $\\Omega$.\n\nConsider the function:\n$$\nf(z_1, z_2) = \\frac{1}{z_1}\n$$\n\n**Verification of Holomorphy on $D$:**\nFor any point $(z_1, z_2) \\in D$, we have the constraint $\\frac{1}{2} \\leq |z_1| < 1$.\nSince $|z_1| \\geq \\frac{1}{2}$, it follows that $z_1 \\neq 0$. The function $z \\mapsto \\frac{1}{z_1}$ is a rational function singular only at $z_1 = 0$. Since the singular locus $\\{z_1 = 0\\}$ is disjoint from $D$, $f$ is holomorphic on $D$.\n\n**Impossibility of Extension to $\\Omega$:**\nThe domain $\\Omega$ contains the set $\\{ (0, z_2) : |z_2| < 1 \\}$, which corresponds to $z_1 = 0$.\nSuppose there exists a holomorphic function $F: \\Omega \\to \\mathbb{C}$ such that $F|_D = f$.\nConsider the restriction of $F$ to the slice $z_2 = 0$. Let $g(z_1) = F(z_1, 0)$.\nSince $F$ is holomorphic on $\\Omega$, $g$ must be holomorphic on the unit disc $\\{ z_1 \\in \\mathbb{C} : |z_1| < 1 \\}$.\nHowever, for $\\frac{1}{2} \\leq |z_1| < 1$, we have $g(z_1) = f(z_1, 0) = \\frac{1}{z_1}$.\nBy the Identity Theorem for holomorphic functions, $g(z_1)$ must equal $\\frac{1}{z_1}$ everywhere on its domain of definition.\nBut $\\lim_{z_1 \\to 0} |g(z_1)| = \\lim_{z_1 \\to 0} \\frac{1}{|z_1|} = \\infty$.\nThis contradicts the requirement that $g$ is holomorphic (and thus continuous and finite) at $z_1 = 0$.\n\nTherefore, $f$ cannot be extended to a holomorphic function on $\\Omega$.\n\n### 3. Mathematical Context and Correction\n\nThe assertion fails because the domain $D = A \\times \\Delta$ is a **domain of holomorphy**. A fundamental result in Several Complex Variables states that a product domain $D_1 \\times D_2$ is a domain of holomorphy if and only if $D_1$ and $D_2$ are domains of holomorphy in their respective spaces.\n- The annulus $A = \\{ 1/2 \\leq |z_1| < 1 \\}$ is a domain of holomorphy in $\\mathbb{C}$.\n- The disc $\\Delta = \\{ |z_2| < 1 \\}$ is a domain of holomorphy in $\\mathbb{C}$.\nThus, $D$ is a domain of holomorphy, meaning there exists a holomorphic function on $D$ that cannot be extended to any larger domain.\n\n**To make the question answerable (Well-Posedness):**\nThe problem likely intended to describe a **Hartogs figure**, where extension is forced. A modification that would make the assertion true is:\nDefine $S = \\{ z \\in \\Omega : |z_1| < \\frac{1}{2} \\text{ and } |z_2| < \\frac{1}{2} \\}$.\nIn this case, $\\Omega \\setminus S$ is connected and \"surrounds\" the compact hole (or thick hole) in such a way that Hartogs' Extension Theorem applies, allowing every holomorphic function on $\\Omega \\setminus S$ to extend to $\\Omega$.\n\nHowever, as stated with $S$ defined solely by $|z_1| < 1/2$, the statement is false.",
        "raw_answer": "The question presented in Step 8 is **ill-posed** because it asks for a proof of a mathematical assertion that is **false**. The problem violates the **Contradictory Premises** validity condition, as it assumes that a specific class of functions always admits a holomorphic extension when, in fact, it does not.\n\nBelow is the rigorous demonstration that the assertion is false, provided via a counterexample, followed by an analysis of the geometric obstruction.\n\n### 1. Analysis of the Domain and Statement\n\nLet us explicitly define the sets given in the problem statement:\n- The domain $\\Omega = \\{ z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1 \\}$ is the unit polydisc $\\Delta^2$.\n- The subset $S = \\{ z \\in \\Omega : |z_1| < \\frac{1}{2} \\}$.\n\nThe domain of definition for the function $f$ is $D = \\Omega \\setminus S$. We can determine the explicit structure of $D$:\n$$\nD = \\{ (z_1, z_2) \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1 \\} \\setminus \\{ (z_1, z_2) \\in \\mathbb{C}^2 : |z_1| < \\frac{1}{2}, |z_2| < 1 \\}\n$$\n$$\nD = \\{ (z_1, z_2) \\in \\mathbb{C}^2 : \\frac{1}{2} \\leq |z_1| < 1, \\, |z_2| < 1 \\}\n$$\nGeometrically, $D$ is the Cartesian product of an annulus $A = \\{ z_1 \\in \\mathbb{C} : \\frac{1}{2} \\leq |z_1| < 1 \\}$ and the unit disc $\\Delta = \\{ z_2 \\in \\mathbb{C} : |z_2| < 1 \\}$.\n\nThe question asks to prove that **any** holomorphic function $f$ on $D$ can be extended to a holomorphic function on $\\Omega$.\n\n### 2. Counterexample\n\nWe construct a function $f$ that is holomorphic on $D$ but cannot be extended holomorphically to $\\Omega$.\n\nConsider the function:\n$$\nf(z_1, z_2) = \\frac{1}{z_1}\n$$\n\n**Verification of Holomorphy on $D$:**\nFor any point $(z_1, z_2) \\in D$, we have the constraint $\\frac{1}{2} \\leq |z_1| < 1$.\nSince $|z_1| \\geq \\frac{1}{2}$, it follows that $z_1 \\neq 0$. The function $z \\mapsto \\frac{1}{z_1}$ is a rational function singular only at $z_1 = 0$. Since the singular locus $\\{z_1 = 0\\}$ is disjoint from $D$, $f$ is holomorphic on $D$.\n\n**Impossibility of Extension to $\\Omega$:**\nThe domain $\\Omega$ contains the set $\\{ (0, z_2) : |z_2| < 1 \\}$, which corresponds to $z_1 = 0$.\nSuppose there exists a holomorphic function $F: \\Omega \\to \\mathbb{C}$ such that $F|_D = f$.\nConsider the restriction of $F$ to the slice $z_2 = 0$. Let $g(z_1) = F(z_1, 0)$.\nSince $F$ is holomorphic on $\\Omega$, $g$ must be holomorphic on the unit disc $\\{ z_1 \\in \\mathbb{C} : |z_1| < 1 \\}$.\nHowever, for $\\frac{1}{2} \\leq |z_1| < 1$, we have $g(z_1) = f(z_1, 0) = \\frac{1}{z_1}$.\nBy the Identity Theorem for holomorphic functions, $g(z_1)$ must equal $\\frac{1}{z_1}$ everywhere on its domain of definition.\nBut $\\lim_{z_1 \\to 0} |g(z_1)| = \\lim_{z_1 \\to 0} \\frac{1}{|z_1|} = \\infty$.\nThis contradicts the requirement that $g$ is holomorphic (and thus continuous and finite) at $z_1 = 0$.\n\nTherefore, $f$ cannot be extended to a holomorphic function on $\\Omega$.\n\n### 3. Mathematical Context and Correction\n\nThe assertion fails because the domain $D = A \\times \\Delta$ is a **domain of holomorphy**. A fundamental result in Several Complex Variables states that a product domain $D_1 \\times D_2$ is a domain of holomorphy if and only if $D_1$ and $D_2$ are domains of holomorphy in their respective spaces.\n- The annulus $A = \\{ 1/2 \\leq |z_1| < 1 \\}$ is a domain of holomorphy in $\\mathbb{C}$.\n- The disc $\\Delta = \\{ |z_2| < 1 \\}$ is a domain of holomorphy in $\\mathbb{C}$.\nThus, $D$ is a domain of holomorphy, meaning there exists a holomorphic function on $D$ that cannot be extended to any larger domain.\n\n**To make the question answerable (Well-Posedness):**\nThe problem likely intended to describe a **Hartogs figure**, where extension is forced. A modification that would make the assertion true is:\nDefine $S = \\{ z \\in \\Omega : |z_1| < \\frac{1}{2} \\text{ and } |z_2| < \\frac{1}{2} \\}$.\nIn this case, $\\Omega \\setminus S$ is connected and \"surrounds\" the compact hole (or thick hole) in such a way that Hartogs' Extension Theorem applies, allowing every holomorphic function on $\\Omega \\setminus S$ to extend to $\\Omega$.\n\nHowever, as stated with $S$ defined solely by $|z_1| < 1/2$, the statement is false.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of special functions, along with a clear and detailed solution, following specific guidelines.\n[/QUESTION]",
    "run_id": "21",
    "outer_attempt": 1,
    "topic_slug": "special_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Based on the task requirements, I have generated a challenging problem involving special functions (specifically the Gamma function and properties of improper integrals) and provided a complete, rigorous solution.\n\n---\n\n### **Problem Statement**\n\n**Problem:** For a real parameter $n > 1$, evaluate the definite integral:\n\n$$ I(n) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx $$\n\nProvide a closed-form expression for $I(n)$ in terms of standard mathematical constants and trigonometric functions. Justify all steps, including the convergence of the integral and the validity of any operations involving differentiation under the integral sign.\n\n---\n\n### **Solution**\n\nWe aim to evaluate the integral $I(n) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx$ for $n > 1$.\n\n#### **1. Convergence Analysis**\n\nFirst, we establish that the integral is well-defined.\nLet $f(x) = \\frac{\\ln x}{1+x^n}$.\n*   **Near $x \\to 0^+$:** The denominator $1+x^n \\approx 1$. Thus, $f(x) \\sim \\ln x$. Since $\\int_0^1 \\ln x \\, dx$ is absolutely convergent (calculating to $-1$), the integral converges at the lower bound.\n*   **Near $x \\to \\infty$:** For large $x$, $1+x^n \\sim x^n$. Thus, $f(x) \\sim \\frac{\\ln x}{x^n}$. Since $n > 1$, let $\\epsilon = \\frac{n-1}{2} > 0$. We have $\\frac{\\ln x}{x^n} = \\frac{\\ln x}{x^\\epsilon} \\cdot \\frac{1}{x^{n-\\epsilon}}$. Since $\\frac{\\ln x}{x^\\epsilon} \\to 0$, the tail is bounded by $C \\cdot \\frac{1}{x^{1+\\epsilon}}$, which converges by the $p$-test ($p = 1 + \\epsilon > 1$).\n\nThus, $I(n)$ converges for all $n > 1$.\n\n#### **2. Introduction of a Parameterized Integral**\n\nWe introduce a parameterized auxiliary integral (the Mellin transform of the function $\\frac{1}{1+x^n}$):\n$$ J(s) = \\int_0^{\\infty} \\frac{x^{s-1}}{1+x^n} \\, dx $$\nNotice that\n$$ \\frac{\\partial}{\\partial s} \\left( \\frac{x^{s-1}}{1+x^n} \\right) = \\frac{x^{s-1} \\ln x}{1+x^n} $$\nEvaluating this derivative at $s=1$ yields our target integrand:\n$$ J'(1) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx = I(n) $$\n\nTo rigorously justify differentiation under the integral sign, we verify the uniform convergence of the integral of the derivative. Let $s \\in [1-\\delta, 1+\\delta]$. We require the domain of integration for $s$ to satisfy $0 < s < n$ for $J(s)$ to converge. Since $n > 1$, we can choose $\\delta > 0$ such that $[1-\\delta, 1+\\delta] \\subset (0, n)$.\n*   On $(0, 1]$, $|x^{s-1}| \\le x^{-\\delta}$.\n*   On $[1, \\infty)$, $|x^{s-1}| \\le x^{\\delta}$.\nThe dominating function $g(x) = \\frac{|\\ln x| (x^{-\\delta} + x^{\\delta})}{1+x^n}$ is integrable on $(0, \\infty)$ given the choice of $\\delta$. By the Leibniz Integral Rule, $I(n) = J'(1)$.\n\n#### **3. Evaluation of $J(s)$ via Beta and Gamma Functions**\n\nWe evaluate $J(s)$ using a substitution to map it to the Beta function definition, $B(a, b) = \\int_0^\\infty \\frac{t^{a-1}}{(1+t)^{a+b}} \\, dt$.\n\nLet $u = x^n$. Then $x = u^{1/n}$ and $dx = \\frac{1}{n} u^{1/n - 1} \\, du$.\nSubstituting into $J(s)$:\n$$ J(s) = \\int_0^{\\infty} \\frac{(u^{1/n})^{s-1}}{1+u} \\cdot \\frac{1}{n} u^{1/n - 1} \\, du $$\n$$ J(s) = \\frac{1}{n} \\int_0^{\\infty} \\frac{u^{s/n - 1/n + 1/n - 1}}{1+u} \\, du $$\n$$ J(s) = \\frac{1}{n} \\int_0^{\\infty} \\frac{u^{s/n - 1}}{1+u} \\, du $$\n\nComparing this to the Beta function form $B(a, b)$ with $a = s/n$:\nSince the denominator is $(1+u)^1$, we must have $a+b=1$, implying $b = 1 - s/n$.\nThus:\n$$ J(s) = \\frac{1}{n} B\\left(\\frac{s}{n}, 1 - \\frac{s}{n}\\right) $$\n\nWe relate the Beta function to the Gamma function using the identity $B(x, y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$:\n$$ J(s) = \\frac{1}{n} \\frac{\\Gamma(s/n)\\Gamma(1 - s/n)}{\\Gamma(1)} $$\nSince $\\Gamma(1) = 1$, we invoke Euler's Reflection Formula, $\\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)}$, with $z = s/n$:\n$$ J(s) = \\frac{1}{n} \\cdot \\frac{\\pi}{\\sin(\\pi s/n)} $$\nThis closed form is valid for $0 < s < n$.\n\n#### **4. Computing the Derivative**\n\nWe now compute $I(n) = J'(1)$.\n$$ J(s) = \\frac{\\pi}{n} \\csc\\left(\\frac{\\pi s}{n}\\right) $$\nDifferentiating with respect to $s$:\n$$ J'(s) = \\frac{\\pi}{n} \\cdot \\frac{d}{ds} \\left( \\csc\\left(\\frac{\\pi s}{n}\\right) \\right) $$\nUsing the chain rule $\\frac{d}{dx} \\csc(u) = -\\csc(u)\\cot(u) \\frac{du}{dx}$:\n$$ J'(s) = \\frac{\\pi}{n} \\left( -\\csc\\left(\\frac{\\pi s}{n}\\right) \\cot\\left(\\frac{\\pi s}{n}\\right) \\cdot \\frac{\\pi}{n} \\right) $$\n$$ J'(s) = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\pi s/n)}{\\sin^2(\\pi s/n)} $$\n\nNow, evaluate at $s=1$:\n$$ I(n) = J'(1) = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\pi/n)}{\\sin^2(\\pi/n)} $$\n\n#### **Conclusion**\n\nThe value of the integral for $n > 1$ is:\n\n$$ \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\frac{\\pi}{n})}{\\sin^2(\\frac{\\pi}{n})} $$\n\n**Verification of Special Cases:**\n1.  **$n=2$**: $\\cos(\\pi/2) = 0$. The formula gives $0$.\n    *   Check: $\\int_0^\\infty \\frac{\\ln x}{1+x^2} dx$. Let $x=1/t$, $dx = -1/t^2 dt$.\n    *   $I = \\int_\\infty^0 \\frac{\\ln(1/t)}{1+1/t^2} (-1/t^2) dt = \\int_0^\\infty \\frac{-\\ln t}{t^2+1} dt = -I \\implies 2I=0 \\implies I=0$. Consistent.\n2.  **Sign check**: For large $n$, $\\frac{\\pi}{n}$ is small and positive. $\\cos(\\pi/n) \\approx 1$, $\\sin^2(\\pi/n) > 0$. The result is negative.\n    *   In the integral, for $x \\in (0,1)$, $\\ln x < 0$. For $x > 1$, $\\ln x > 0$.\n    *   For large $n$, $\\frac{1}{1+x^n} \\approx 1$ on $(0,1)$ and $\\approx 0$ on $(1, \\infty)$. The negative contribution from $(0,1)$ dominates. The negative sign is consistent.",
        "raw_answer": "Based on the task requirements, I have generated a challenging problem involving special functions (specifically the Gamma function and properties of improper integrals) and provided a complete, rigorous solution.\n\n---\n\n### **Problem Statement**\n\n**Problem:** For a real parameter $n > 1$, evaluate the definite integral:\n\n$$ I(n) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx $$\n\nProvide a closed-form expression for $I(n)$ in terms of standard mathematical constants and trigonometric functions. Justify all steps, including the convergence of the integral and the validity of any operations involving differentiation under the integral sign.\n\n---\n\n### **Solution**\n\nWe aim to evaluate the integral $I(n) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx$ for $n > 1$.\n\n#### **1. Convergence Analysis**\n\nFirst, we establish that the integral is well-defined.\nLet $f(x) = \\frac{\\ln x}{1+x^n}$.\n*   **Near $x \\to 0^+$:** The denominator $1+x^n \\approx 1$. Thus, $f(x) \\sim \\ln x$. Since $\\int_0^1 \\ln x \\, dx$ is absolutely convergent (calculating to $-1$), the integral converges at the lower bound.\n*   **Near $x \\to \\infty$:** For large $x$, $1+x^n \\sim x^n$. Thus, $f(x) \\sim \\frac{\\ln x}{x^n}$. Since $n > 1$, let $\\epsilon = \\frac{n-1}{2} > 0$. We have $\\frac{\\ln x}{x^n} = \\frac{\\ln x}{x^\\epsilon} \\cdot \\frac{1}{x^{n-\\epsilon}}$. Since $\\frac{\\ln x}{x^\\epsilon} \\to 0$, the tail is bounded by $C \\cdot \\frac{1}{x^{1+\\epsilon}}$, which converges by the $p$-test ($p = 1 + \\epsilon > 1$).\n\nThus, $I(n)$ converges for all $n > 1$.\n\n#### **2. Introduction of a Parameterized Integral**\n\nWe introduce a parameterized auxiliary integral (the Mellin transform of the function $\\frac{1}{1+x^n}$):\n$$ J(s) = \\int_0^{\\infty} \\frac{x^{s-1}}{1+x^n} \\, dx $$\nNotice that\n$$ \\frac{\\partial}{\\partial s} \\left( \\frac{x^{s-1}}{1+x^n} \\right) = \\frac{x^{s-1} \\ln x}{1+x^n} $$\nEvaluating this derivative at $s=1$ yields our target integrand:\n$$ J'(1) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx = I(n) $$\n\nTo rigorously justify differentiation under the integral sign, we verify the uniform convergence of the integral of the derivative. Let $s \\in [1-\\delta, 1+\\delta]$. We require the domain of integration for $s$ to satisfy $0 < s < n$ for $J(s)$ to converge. Since $n > 1$, we can choose $\\delta > 0$ such that $[1-\\delta, 1+\\delta] \\subset (0, n)$.\n*   On $(0, 1]$, $|x^{s-1}| \\le x^{-\\delta}$.\n*   On $[1, \\infty)$, $|x^{s-1}| \\le x^{\\delta}$.\nThe dominating function $g(x) = \\frac{|\\ln x| (x^{-\\delta} + x^{\\delta})}{1+x^n}$ is integrable on $(0, \\infty)$ given the choice of $\\delta$. By the Leibniz Integral Rule, $I(n) = J'(1)$.\n\n#### **3. Evaluation of $J(s)$ via Beta and Gamma Functions**\n\nWe evaluate $J(s)$ using a substitution to map it to the Beta function definition, $B(a, b) = \\int_0^\\infty \\frac{t^{a-1}}{(1+t)^{a+b}} \\, dt$.\n\nLet $u = x^n$. Then $x = u^{1/n}$ and $dx = \\frac{1}{n} u^{1/n - 1} \\, du$.\nSubstituting into $J(s)$:\n$$ J(s) = \\int_0^{\\infty} \\frac{(u^{1/n})^{s-1}}{1+u} \\cdot \\frac{1}{n} u^{1/n - 1} \\, du $$\n$$ J(s) = \\frac{1}{n} \\int_0^{\\infty} \\frac{u^{s/n - 1/n + 1/n - 1}}{1+u} \\, du $$\n$$ J(s) = \\frac{1}{n} \\int_0^{\\infty} \\frac{u^{s/n - 1}}{1+u} \\, du $$\n\nComparing this to the Beta function form $B(a, b)$ with $a = s/n$:\nSince the denominator is $(1+u)^1$, we must have $a+b=1$, implying $b = 1 - s/n$.\nThus:\n$$ J(s) = \\frac{1}{n} B\\left(\\frac{s}{n}, 1 - \\frac{s}{n}\\right) $$\n\nWe relate the Beta function to the Gamma function using the identity $B(x, y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$:\n$$ J(s) = \\frac{1}{n} \\frac{\\Gamma(s/n)\\Gamma(1 - s/n)}{\\Gamma(1)} $$\nSince $\\Gamma(1) = 1$, we invoke Euler's Reflection Formula, $\\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)}$, with $z = s/n$:\n$$ J(s) = \\frac{1}{n} \\cdot \\frac{\\pi}{\\sin(\\pi s/n)} $$\nThis closed form is valid for $0 < s < n$.\n\n#### **4. Computing the Derivative**\n\nWe now compute $I(n) = J'(1)$.\n$$ J(s) = \\frac{\\pi}{n} \\csc\\left(\\frac{\\pi s}{n}\\right) $$\nDifferentiating with respect to $s$:\n$$ J'(s) = \\frac{\\pi}{n} \\cdot \\frac{d}{ds} \\left( \\csc\\left(\\frac{\\pi s}{n}\\right) \\right) $$\nUsing the chain rule $\\frac{d}{dx} \\csc(u) = -\\csc(u)\\cot(u) \\frac{du}{dx}$:\n$$ J'(s) = \\frac{\\pi}{n} \\left( -\\csc\\left(\\frac{\\pi s}{n}\\right) \\cot\\left(\\frac{\\pi s}{n}\\right) \\cdot \\frac{\\pi}{n} \\right) $$\n$$ J'(s) = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\pi s/n)}{\\sin^2(\\pi s/n)} $$\n\nNow, evaluate at $s=1$:\n$$ I(n) = J'(1) = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\pi/n)}{\\sin^2(\\pi/n)} $$\n\n#### **Conclusion**\n\nThe value of the integral for $n > 1$ is:\n\n$$ \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\frac{\\pi}{n})}{\\sin^2(\\frac{\\pi}{n})} $$\n\n**Verification of Special Cases:**\n1.  **$n=2$**: $\\cos(\\pi/2) = 0$. The formula gives $0$.\n    *   Check: $\\int_0^\\infty \\frac{\\ln x}{1+x^2} dx$. Let $x=1/t$, $dx = -1/t^2 dt$.\n    *   $I = \\int_\\infty^0 \\frac{\\ln(1/t)}{1+1/t^2} (-1/t^2) dt = \\int_0^\\infty \\frac{-\\ln t}{t^2+1} dt = -I \\implies 2I=0 \\implies I=0$. Consistent.\n2.  **Sign check**: For large $n$, $\\frac{\\pi}{n}$ is small and positive. $\\cos(\\pi/n) \\approx 1$, $\\sin^2(\\pi/n) > 0$. The result is negative.\n    *   In the integral, for $x \\in (0,1)$, $\\ln x < 0$. For $x > 1$, $\\ln x > 0$.\n    *   For large $n$, $\\frac{1}{1+x^n} \\approx 1$ on $(0,1)$ and $\\approx 0$ on $(1, \\infty)$. The negative contribution from $(0,1)$ dominates. The negative sign is consistent.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of ordinary differential equations (ODEs), along with a complete and clear solution. The problem should be solvable, verifiable, and not require external resources or conjectures.\n\n## Step 2: Formulate the problem\nTo create a meaningful problem, we need to consider an ODE that is not trivial and involves some level of mathematical sophistication. Let's consider a second-order linear homogeneous differential equation with constant coefficients, which is a standard topic in ODEs.\n\n## Step 3: Propose a specific problem\nConsider the differential equation $y'' + 4y' + 4y = 0$. The task is to find the general solution to this equation.\n\n## Step 4: Verify the problem meets the criteria\n- **Non-trivial**: The equation is not straightforward to solve by inspection.\n- **Solvable**: The equation can be solved using standard methods for linear differential equations with constant coefficients.\n- **Verifiable**: The solution can be verified by substitution into the differential equation.",
    "run_id": "22",
    "outer_attempt": 1,
    "topic_slug": "ordinary_differential_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the general solution to the ordinary differential equation (ODE) given by:\n\n$$y'' + 4y' + 4y = 0$$\n\nwe proceed with the standard method for solving second-order linear homogeneous differential equations with constant coefficients.\n\n### 1. Classification and Method\n\nThe equation is of the form $ay'' + by' + cy = 0$ where $a=1$, $b=4$, and $c=4$. Since the coefficients are constants, we look for solutions of the form $y(x) = e^{rx}$, where $r$ is a constant to be determined.\n\nSubstituting $y = e^{rx}$, $y' = re^{rx}$, and $y'' = r^2 e^{rx}$ into the differential equation, we obtain:\n\n$$r^2 e^{rx} + 4r e^{rx} + 4 e^{rx} = 0$$\n\nFactoring out the non-zero term $e^{rx}$, we get the characteristic equation:\n\n$$r^2 + 4r + 4 = 0$$\n\n### 2. Solving the Characteristic Equation\n\nWe solve the quadratic equation for $r$:\n\n$$r^2 + 4r + 4 = (r + 2)^2 = 0$$\n\nThis yields a single repeated real root:\n$$r = -2$$\nwith multiplicity 2.\n\n### 3. Constructing the General Solution\n\nWhen the characteristic equation has a repeated real root $r$ of multiplicity 2, the two linearly independent solutions are given by:\n$$y_1(x) = e^{rx}$$\n$$y_2(x) = x e^{rx}$$\n\nSubstituting $r = -2$, our basis solutions are:\n$$y_1(x) = e^{-2x}$$\n$$y_2(x) = x e^{-2x}$$\n\nThe general solution is the linear combination of these independent solutions, using arbitrary constants $C_1$ and $C_2$:\n\n$$y(x) = C_1 e^{-2x} + C_2 x e^{-2x}$$\nor equivalently,\n$$y(x) = (C_1 + C_2 x) e^{-2x}$$\n\n### 4. Verification\n\nTo ensure the correctness of the solution, we verify that $y(x) = (C_1 + C_2 x) e^{-2x}$ satisfies the original ODE.\n\nLet us verify the term $y_2 = x e^{-2x}$, as $y_1$ is trivially a solution to the characteristic equation.\nCompute the derivatives of $y_2$:\nFirst derivative:\n$$y_2' = \\frac{d}{dx}(x e^{-2x}) = 1 \\cdot e^{-2x} + x(-2 e^{-2x}) = (1 - 2x)e^{-2x}$$\n\nSecond derivative:\n$$y_2'' = \\frac{d}{dx}((1 - 2x)e^{-2x}) = (-2)e^{-2x} + (1 - 2x)(-2e^{-2x})$$\n$$y_2'' = -2e^{-2x} - 2e^{-2x} + 4xe^{-2x} = (4x - 4)e^{-2x}$$\n\nSubstitute $y_2$, $y_2'$, and $y_2''$ into the LHS of the ODE:\n$$y'' + 4y' + 4y = [(4x - 4)e^{-2x}] + 4[(1 - 2x)e^{-2x}] + 4[x e^{-2x}]$$\n\nFactor out $e^{-2x}$:\n$$= e^{-2x} [ (4x - 4) + (4 - 8x) + 4x ]$$\n$$= e^{-2x} [ 4x - 8x + 4x - 4 + 4 ]$$\n$$= e^{-2x} [ 0 ] = 0$$\n\nThe solution satisfies the differential equation.\n\n### Final Conclusion\n\nThe general solution to the differential equation $y'' + 4y' + 4y = 0$ is:\n\n$$y(x) = C_1 e^{-2x} + C_2 x e^{-2x}$$\n\nwhere $C_1$ and $C_2$ are arbitrary constants.",
        "raw_answer": "To find the general solution to the ordinary differential equation (ODE) given by:\n\n$$y'' + 4y' + 4y = 0$$\n\nwe proceed with the standard method for solving second-order linear homogeneous differential equations with constant coefficients.\n\n### 1. Classification and Method\n\nThe equation is of the form $ay'' + by' + cy = 0$ where $a=1$, $b=4$, and $c=4$. Since the coefficients are constants, we look for solutions of the form $y(x) = e^{rx}$, where $r$ is a constant to be determined.\n\nSubstituting $y = e^{rx}$, $y' = re^{rx}$, and $y'' = r^2 e^{rx}$ into the differential equation, we obtain:\n\n$$r^2 e^{rx} + 4r e^{rx} + 4 e^{rx} = 0$$\n\nFactoring out the non-zero term $e^{rx}$, we get the characteristic equation:\n\n$$r^2 + 4r + 4 = 0$$\n\n### 2. Solving the Characteristic Equation\n\nWe solve the quadratic equation for $r$:\n\n$$r^2 + 4r + 4 = (r + 2)^2 = 0$$\n\nThis yields a single repeated real root:\n$$r = -2$$\nwith multiplicity 2.\n\n### 3. Constructing the General Solution\n\nWhen the characteristic equation has a repeated real root $r$ of multiplicity 2, the two linearly independent solutions are given by:\n$$y_1(x) = e^{rx}$$\n$$y_2(x) = x e^{rx}$$\n\nSubstituting $r = -2$, our basis solutions are:\n$$y_1(x) = e^{-2x}$$\n$$y_2(x) = x e^{-2x}$$\n\nThe general solution is the linear combination of these independent solutions, using arbitrary constants $C_1$ and $C_2$:\n\n$$y(x) = C_1 e^{-2x} + C_2 x e^{-2x}$$\nor equivalently,\n$$y(x) = (C_1 + C_2 x) e^{-2x}$$\n\n### 4. Verification\n\nTo ensure the correctness of the solution, we verify that $y(x) = (C_1 + C_2 x) e^{-2x}$ satisfies the original ODE.\n\nLet us verify the term $y_2 = x e^{-2x}$, as $y_1$ is trivially a solution to the characteristic equation.\nCompute the derivatives of $y_2$:\nFirst derivative:\n$$y_2' = \\frac{d}{dx}(x e^{-2x}) = 1 \\cdot e^{-2x} + x(-2 e^{-2x}) = (1 - 2x)e^{-2x}$$\n\nSecond derivative:\n$$y_2'' = \\frac{d}{dx}((1 - 2x)e^{-2x}) = (-2)e^{-2x} + (1 - 2x)(-2e^{-2x})$$\n$$y_2'' = -2e^{-2x} - 2e^{-2x} + 4xe^{-2x} = (4x - 4)e^{-2x}$$\n\nSubstitute $y_2$, $y_2'$, and $y_2''$ into the LHS of the ODE:\n$$y'' + 4y' + 4y = [(4x - 4)e^{-2x}] + 4[(1 - 2x)e^{-2x}] + 4[x e^{-2x}]$$\n\nFactor out $e^{-2x}$:\n$$= e^{-2x} [ (4x - 4) + (4 - 8x) + 4x ]$$\n$$= e^{-2x} [ 4x - 8x + 4x - 4 + 4 ]$$\n$$= e^{-2x} [ 0 ] = 0$$\n\nThe solution satisfies the differential equation.\n\n### Final Conclusion\n\nThe general solution to the differential equation $y'' + 4y' + 4y = 0$ is:\n\n$$y(x) = C_1 e^{-2x} + C_2 x e^{-2x}$$\n\nwhere $C_1$ and $C_2$ are arbitrary constants.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Consider the one-dimensional heat equation given by $\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}$, where $\\alpha > 0$ is a constant, $x \\in [0, L]$, and $t \\geq 0$. The boundary conditions are $u(0, t) = u(L, t) = 0$ for all $t \\geq 0$, and the initial condition is $u(x, 0) = \\sin(\\frac{\\pi x}{L}) + 2\\sin(\\frac{3\\pi x}{L})$. Find the solution $u(x, t)$ for $x \\in [0, L]$ and $t \\geq 0$.",
    "run_id": "23",
    "outer_attempt": 1,
    "topic_slug": "partial_differential_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the solution $u(x, t)$ for the one-dimensional heat equation subject to the given boundary and initial conditions, we will use the method of separation of variables.\n\n### 1. Separation of Variables\n\nWe assume the solution can be written as a product of a function of space $X(x)$ and a function of time $T(t)$:\n$$ u(x, t) = X(x)T(t) $$\n\nSubstituting this into the heat equation $\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}$:\n$$ X(x)T'(t) = \\alpha X''(x)T(t) $$\n\nDividing both sides by $\\alpha X(x)T(t)$ (assuming the solution is non-trivial):\n$$ \\frac{T'(t)}{\\alpha T(t)} = \\frac{X''(x)}{X(x)} $$\n\nSince the left side depends only on $t$ and the right side depends only on $x$, both sides must equal a constant. Let us denote this separation constant by $-\\lambda$. Thus, we obtain two ordinary differential equations:\n1.  **Spatial Equation:** $X''(x) + \\lambda X(x) = 0$\n2.  **Temporal Equation:** $T'(t) + \\alpha \\lambda T(t) = 0$\n\n### 2. Solving the Spatial Problem (Eigenvalue Problem)\n\nWe solve the spatial equation $X''(x) + \\lambda X(x) = 0$ subject to the boundary conditions derived from the problem statement:\n-   $u(0, t) = X(0)T(t) = 0 \\implies X(0) = 0$\n-   $u(L, t) = X(L)T(t) = 0 \\implies X(L) = 0$\n\nWe consider three cases for the constant $\\lambda$:\n\n**Case 1: $\\lambda < 0$**\nLet $\\lambda = -k^2$ where $k > 0$. The general solution is $X(x) = c_1 e^{kx} + c_2 e^{-kx}$.\nUsing the boundary conditions:\n-   $X(0) = c_1 + c_2 = 0 \\implies c_2 = -c_1$\n-   $X(L) = c_1(e^{kL} - e^{-kL}) = 2c_1 \\sinh(kL) = 0$\nSince $\\sinh(kL) \\neq 0$ for $k, L > 0$, we must have $c_1 = 0$, which implies $c_2 = 0$. This yields the trivial solution.\n\n**Case 2: $\\lambda = 0$**\nThe general solution is $X(x) = c_1 x + c_2$.\n-   $X(0) = c_2 = 0$\n-   $X(L) = c_1 L = 0 \\implies c_1 = 0$\nThis also yields the trivial solution.\n\n**Case 3: $\\lambda > 0$**\nLet $\\lambda = k^2$ where $k > 0$. The general solution is $X(x) = c_1 \\cos(kx) + c_2 \\sin(kx)$.\n-   $X(0) = c_1 \\cdot 1 + c_2 \\cdot 0 = 0 \\implies c_1 = 0$.\n-   $X(L) = c_2 \\sin(kL) = 0$.\nFor a non-trivial solution ($c_2 \\neq 0$), we require $\\sin(kL) = 0$. This implies:\n$$ kL = n\\pi, \\quad n = 1, 2, 3, \\dots $$\n$$ k_n = \\frac{n\\pi}{L} $$\nTherefore, the eigenvalues are $\\lambda_n = k_n^2 = \\left(\\frac{n\\pi}{L}\\right)^2$, and the corresponding eigenfunctions are:\n$$ X_n(x) = \\sin\\left(\\frac{n\\pi x}{L}\\right) $$\n\n### 3. Solving the Temporal Problem\n\nSubstitute $\\lambda_n$ into the temporal equation $T'(t) + \\alpha \\lambda_n T(t) = 0$:\n$$ T'_n(t) + \\alpha \\left(\\frac{n\\pi}{L}\\right)^2 T_n(t) = 0 $$\nThe solution to this first-order linear ODE is:\n$$ T_n(t) = B_n e^{-\\alpha \\left(\\frac{n\\pi}{L}\\right)^2 t} $$\nwhere $B_n$ is an arbitrary constant.\n\n### 4. General Solution and Initial Condition\n\nBy the principle of superposition, the general solution is a linear combination of the fundamental solutions $u_n(x, t) = X_n(x)T_n(t)$:\n$$ u(x, t) = \\sum_{n=1}^{\\infty} B_n \\sin\\left(\\frac{n\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{n\\pi}{L}\\right)^2 t} $$\n\nWe determine the coefficients $B_n$ using the initial condition at $t = 0$:\n$$ u(x, 0) = \\sum_{n=1}^{\\infty} B_n \\sin\\left(\\frac{n\\pi x}{L}\\right) = \\sin\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\left(\\frac{3\\pi x}{L}\\right) $$\n\nThe right-hand side is already expressed as a Fourier sine series. By the orthogonality of the sine functions $\\left\\{ \\sin\\left(\\frac{n\\pi x}{L}\\right) \\right\\}_{n=1}^{\\infty}$ on the interval $[0, L]$, we can equate the coefficients of corresponding terms directly:\n\n1.  For $n = 1$, the term is $\\sin\\left(\\frac{\\pi x}{L}\\right)$. Matching coefficients gives $B_1 = 1$.\n2.  For $n = 3$, the term is $\\sin\\left(\\frac{3\\pi x}{L}\\right)$. Matching coefficients gives $B_3 = 2$.\n3.  For all other $n$ ($n \\neq 1, 3$), the coefficients are $B_n = 0$.\n\n### 5. Final Solution\n\nSubstituting the non-zero coefficients $B_1$ and $B_3$ back into the general series solution:\n\n$$ u(x, t) = 1 \\cdot \\sin\\left(\\frac{\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{\\pi}{L}\\right)^2 t} + 2 \\cdot \\sin\\left(\\frac{3\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{3\\pi}{L}\\right)^2 t} $$\n\nThus, the final solution is:\n\n$$ u(x, t) = e^{-\\frac{\\alpha \\pi^2 t}{L^2}} \\sin\\left(\\frac{\\pi x}{L}\\right) + 2e^{-\\frac{9\\alpha \\pi^2 t}{L^2}} \\sin\\left(\\frac{3\\pi x}{L}\\right) $$",
        "raw_answer": "To find the solution $u(x, t)$ for the one-dimensional heat equation subject to the given boundary and initial conditions, we will use the method of separation of variables.\n\n### 1. Separation of Variables\n\nWe assume the solution can be written as a product of a function of space $X(x)$ and a function of time $T(t)$:\n$$ u(x, t) = X(x)T(t) $$\n\nSubstituting this into the heat equation $\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}$:\n$$ X(x)T'(t) = \\alpha X''(x)T(t) $$\n\nDividing both sides by $\\alpha X(x)T(t)$ (assuming the solution is non-trivial):\n$$ \\frac{T'(t)}{\\alpha T(t)} = \\frac{X''(x)}{X(x)} $$\n\nSince the left side depends only on $t$ and the right side depends only on $x$, both sides must equal a constant. Let us denote this separation constant by $-\\lambda$. Thus, we obtain two ordinary differential equations:\n1.  **Spatial Equation:** $X''(x) + \\lambda X(x) = 0$\n2.  **Temporal Equation:** $T'(t) + \\alpha \\lambda T(t) = 0$\n\n### 2. Solving the Spatial Problem (Eigenvalue Problem)\n\nWe solve the spatial equation $X''(x) + \\lambda X(x) = 0$ subject to the boundary conditions derived from the problem statement:\n-   $u(0, t) = X(0)T(t) = 0 \\implies X(0) = 0$\n-   $u(L, t) = X(L)T(t) = 0 \\implies X(L) = 0$\n\nWe consider three cases for the constant $\\lambda$:\n\n**Case 1: $\\lambda < 0$**\nLet $\\lambda = -k^2$ where $k > 0$. The general solution is $X(x) = c_1 e^{kx} + c_2 e^{-kx}$.\nUsing the boundary conditions:\n-   $X(0) = c_1 + c_2 = 0 \\implies c_2 = -c_1$\n-   $X(L) = c_1(e^{kL} - e^{-kL}) = 2c_1 \\sinh(kL) = 0$\nSince $\\sinh(kL) \\neq 0$ for $k, L > 0$, we must have $c_1 = 0$, which implies $c_2 = 0$. This yields the trivial solution.\n\n**Case 2: $\\lambda = 0$**\nThe general solution is $X(x) = c_1 x + c_2$.\n-   $X(0) = c_2 = 0$\n-   $X(L) = c_1 L = 0 \\implies c_1 = 0$\nThis also yields the trivial solution.\n\n**Case 3: $\\lambda > 0$**\nLet $\\lambda = k^2$ where $k > 0$. The general solution is $X(x) = c_1 \\cos(kx) + c_2 \\sin(kx)$.\n-   $X(0) = c_1 \\cdot 1 + c_2 \\cdot 0 = 0 \\implies c_1 = 0$.\n-   $X(L) = c_2 \\sin(kL) = 0$.\nFor a non-trivial solution ($c_2 \\neq 0$), we require $\\sin(kL) = 0$. This implies:\n$$ kL = n\\pi, \\quad n = 1, 2, 3, \\dots $$\n$$ k_n = \\frac{n\\pi}{L} $$\nTherefore, the eigenvalues are $\\lambda_n = k_n^2 = \\left(\\frac{n\\pi}{L}\\right)^2$, and the corresponding eigenfunctions are:\n$$ X_n(x) = \\sin\\left(\\frac{n\\pi x}{L}\\right) $$\n\n### 3. Solving the Temporal Problem\n\nSubstitute $\\lambda_n$ into the temporal equation $T'(t) + \\alpha \\lambda_n T(t) = 0$:\n$$ T'_n(t) + \\alpha \\left(\\frac{n\\pi}{L}\\right)^2 T_n(t) = 0 $$\nThe solution to this first-order linear ODE is:\n$$ T_n(t) = B_n e^{-\\alpha \\left(\\frac{n\\pi}{L}\\right)^2 t} $$\nwhere $B_n$ is an arbitrary constant.\n\n### 4. General Solution and Initial Condition\n\nBy the principle of superposition, the general solution is a linear combination of the fundamental solutions $u_n(x, t) = X_n(x)T_n(t)$:\n$$ u(x, t) = \\sum_{n=1}^{\\infty} B_n \\sin\\left(\\frac{n\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{n\\pi}{L}\\right)^2 t} $$\n\nWe determine the coefficients $B_n$ using the initial condition at $t = 0$:\n$$ u(x, 0) = \\sum_{n=1}^{\\infty} B_n \\sin\\left(\\frac{n\\pi x}{L}\\right) = \\sin\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\left(\\frac{3\\pi x}{L}\\right) $$\n\nThe right-hand side is already expressed as a Fourier sine series. By the orthogonality of the sine functions $\\left\\{ \\sin\\left(\\frac{n\\pi x}{L}\\right) \\right\\}_{n=1}^{\\infty}$ on the interval $[0, L]$, we can equate the coefficients of corresponding terms directly:\n\n1.  For $n = 1$, the term is $\\sin\\left(\\frac{\\pi x}{L}\\right)$. Matching coefficients gives $B_1 = 1$.\n2.  For $n = 3$, the term is $\\sin\\left(\\frac{3\\pi x}{L}\\right)$. Matching coefficients gives $B_3 = 2$.\n3.  For all other $n$ ($n \\neq 1, 3$), the coefficients are $B_n = 0$.\n\n### 5. Final Solution\n\nSubstituting the non-zero coefficients $B_1$ and $B_3$ back into the general series solution:\n\n$$ u(x, t) = 1 \\cdot \\sin\\left(\\frac{\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{\\pi}{L}\\right)^2 t} + 2 \\cdot \\sin\\left(\\frac{3\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{3\\pi}{L}\\right)^2 t} $$\n\nThus, the final solution is:\n\n$$ u(x, t) = e^{-\\frac{\\alpha \\pi^2 t}{L^2}} \\sin\\left(\\frac{\\pi x}{L}\\right) + 2e^{-\\frac{9\\alpha \\pi^2 t}{L^2}} \\sin\\left(\\frac{3\\pi x}{L}\\right) $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of dynamical systems and ergodic theory, along with a complete and verifiable solution.\n\n## Step 2: Identify key concepts in dynamical systems and ergodic theory\nDynamical systems involve the study of the behavior of systems that change over time according to certain rules. Ergodic theory is a branch of mathematics that studies the behavior of dynamical systems over time, focusing on their statistical properties. Key concepts include ergodicity, measure-preserving transformations, and the ergodic theorem.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to incorporate concepts from dynamical systems and ergodic theory. A potential problem could involve analyzing the behavior of a specific dynamical system, such as determining if it is ergodic or calculating its invariant measures.\n\n## Step 4: Specify the problem\nLet's consider a simple yet challenging example: the rotation map on the unit circle. The unit circle can be represented as $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$, and a rotation map $T: \\mathbb{T} \\to \\mathbb{T}$ is defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$.\n\n## Step 5: Formulate the question\nWe can ask whether the rotation map $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$ when $\\alpha$ is irrational.\n\n## Step 6: Write the problem statement\n\"Let $T: \\mathbb{T} \\to \\mathbb{T}$ be defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$ is irrational. Prove that $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$.\"\n\n## Step 7: Provide the solution\nTo prove that $T$ is ergodic, we need to show that if $A \\subset \\mathbb{T}$ is $T$-invariant (i.e., $T(A) = A$) and measurable, then either $m(A) = 0$ or $m(A) = 1$, where $m$ denotes the Lebesgue measure.\n\n## Step 8: Detail the solution\nFirst, recall that $T$ is measure-preserving because $m(T^{-1}(A)) = m(A)$ for any measurable $A \\subset \\mathbb{T}$. For $T$ to be ergodic, we must show that $T$-invariant sets have measure 0 or 1.\n\n## Step 9: Use Fourier analysis to prove ergodicity\nConsider a $T$-invariant set $A$. The characteristic function $\\chi_A$ of $A$ is $T$-invariant, meaning $\\chi_A(T(x)) = \\chi_A(x)$. We can expand $\\chi_A$ in a Fourier series: $\\chi_A(x) = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi inx}$, where $c_n = \\int_{\\mathbb{T}} \\chi_A(x)e^{-2\\pi inx} dx$.\n\n## Step 10: Apply $T$-invariance to the Fourier series\nSince $\\chi_A(T(x)) = \\chi_A(x + \\alpha) = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi in(x + \\alpha)} = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi in\\alpha}e^{2\\pi inx}$, and this equals $\\chi_A(x)$, we have $c_n = c_n e^{2\\pi in\\alpha}$ for all $n$. For $\\alpha$ irrational, $e^{2\\pi in\\alpha} \\neq 1$ unless $n = 0$. Thus, $c_n = 0$ for $n \\neq 0$.\n\n## Step 11: Conclude ergodicity from the Fourier analysis\nThis implies $\\chi_A(x) = c_0 = \\int_{\\mathbb{T}} \\chi_A(x) dx = m(A)$, meaning $\\chi_A$ is constant. Hence, $A$ is either $\\mathbb{T}$ (if $m(A) = 1$) or $\\emptyset$ (if $m(A) = 0$), proving $T$ is ergodic.\n\n## Step 12: Format the question and answer according to the required structure\n\nLet $T: \\mathbb{T} \\to \\mathbb{T}$ be defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$ is irrational. Prove that $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$.",
    "run_id": "24",
    "outer_attempt": 1,
    "topic_slug": "dynamical_systems_and_ergodic_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the rigorous solution to the problem involving the ergodicity of irrational rotations on the unit circle.\n\n### **Problem Statement**\nLet $T: \\mathbb{T} \\to \\mathbb{T}$ be defined by $T(x) = x + \\alpha \\pmod 1$, where $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$ is the unit circle and $\\alpha \\in \\mathbb{R}$ is irrational. Prove that $T$ is ergodic with respect to the Lebesgue measure $\\mu$ on $\\mathbb{T}$.\n\n---\n\n### **Solution**\n\nTo prove that the transformation $T$ is ergodic, we must show that the only measurable sets invariant under $T$ are trivial (having measure 0 or 1).\n\n**Definition of Ergodicity:**\nA measure-preserving transformation $T$ on a probability space $(X, \\mathcal{B}, \\mu)$ is **ergodic** if for every measurable set $A \\in \\mathcal{B}$ such that $T^{-1}(A) = A$ (up to a set of measure zero), we have either $\\mu(A) = 0$ or $\\mu(A) = 1$.\n\nAn equivalent and often more analytically tractable characterization involves invariant functions:\n**Theorem:** $T$ is ergodic if and only if every function $f \\in L^2(X, \\mu)$ satisfying $f \\circ T = f$ almost everywhere is constant almost everywhere.\n\nWe will use this characterization to prove the statement.\n\n#### **Step 1: Verification that $T$ is Measure-Preserving**\nThe Lebesgue measure $\\mu$ on the circle $\\mathbb{T}$ is invariant under translation. For any measurable set $A \\subseteq \\mathbb{T}$,\n$$ \\mu(T^{-1}(A)) = \\mu(\\{x \\mid x + \\alpha \\in A\\}) = \\mu(A - \\alpha). $$\nSince Lebesgue measure is translation-invariant, $\\mu(A - \\alpha) = \\mu(A)$. Thus, $T$ is a measure-preserving transformation.\n\n#### **Step 2: Analysis of Invariant Functions using Fourier Series**\nLet $f \\in L^2(\\mathbb{T}, \\mu)$ be a $T$-invariant function. That is:\n$$ f(T(x)) = f(x) \\quad \\text{for } \\mu\\text{-almost every } x \\in \\mathbb{T}. $$\n\nSince $\\{e_n(x) = e^{2\\pi i n x} \\mid n \\in \\mathbb{Z}\\}$ forms an orthonormal basis for the Hilbert space $L^2(\\mathbb{T})$, we can expand $f$ into its Fourier series:\n$$ f(x) = \\sum_{n \\in \\mathbb{Z}} c_n e^{2\\pi i n x}, \\quad \\text{where } c_n = \\int_{\\mathbb{T}} f(x) e^{-2\\pi i n x} \\, d\\mu(x). $$\nHere, the series converges to $f$ in the $L^2$ norm.\n\nWe compute the Fourier series of the composition $f \\circ T$:\n$$ (f \\circ T)(x) = f(x + \\alpha) = \\sum_{n \\in \\mathbb{Z}} c_n e^{2\\pi i n (x + \\alpha)} = \\sum_{n \\in \\mathbb{Z}} \\left( c_n e^{2\\pi i n \\alpha} \\right) e^{2\\pi i n x}. $$\n\n#### **Step 3: Comparing Fourier Coefficients**\nSince $f \\circ T = f$ almost everywhere, their Fourier coefficients must be identical. By the uniqueness of Fourier coefficients in $L^2(\\mathbb{T})$, we equate the coefficients for each $n \\in \\mathbb{Z}$:\n$$ c_n = c_n e^{2\\pi i n \\alpha}. $$\nRearranging this equation gives:\n$$ c_n (1 - e^{2\\pi i n \\alpha}) = 0. $$\n\n#### **Step 4: Using the Irrationality of $\\alpha$**\nWe analyze the condition $c_n (1 - e^{2\\pi i n \\alpha}) = 0$ for different values of $n$:\n\n1.  **Case $n = 0$**:\n    The term $1 - e^{2\\pi i (0) \\alpha} = 1 - 1 = 0$. The equation becomes $c_0 \\cdot 0 = 0$, which places no constraint on $c_0$.\n\n2.  **Case $n \\neq 0$**:\n    We must determine if the factor $(1 - e^{2\\pi i n \\alpha})$ can be zero.\n    $$ 1 - e^{2\\pi i n \\alpha} = 0 \\iff e^{2\\pi i n \\alpha} = 1 \\iff n\\alpha = k \\text{ for some } k \\in \\mathbb{Z}. $$\n    This implies $\\alpha = \\frac{k}{n}$.\n    However, the problem states that $\\alpha$ is **irrational**. Therefore, $\\alpha$ cannot be expressed as a ratio of integers $k/n$ for any $n \\neq 0$.\n    Consequently, $e^{2\\pi i n \\alpha} \\neq 1$, which implies $(1 - e^{2\\pi i n \\alpha}) \\neq 0$.\n    \n    To satisfy the equation $c_n (1 - e^{2\\pi i n \\alpha}) = 0$, we must have:\n    $$ c_n = 0 \\quad \\text{for all } n \\neq 0. $$\n\n#### **Step 5: Conclusion**\nWe have determined that for any $T$-invariant function $f$, all Fourier coefficients $c_n$ are zero except possibly $c_0$. Thus, the Fourier series reduces to:\n$$ f(x) = c_0. $$\nSince the Fourier series converges to $f$ in $L^2$, $f$ is equal to the constant $c_0$ almost everywhere.\n\n#### **Final Argument for Sets**\nTo complete the proof based on the definition of ergodicity involving sets:\nLet $A \\subseteq \\mathbb{T}$ be a measurable set such that $T^{-1}(A) = A$ (modulo measure zero). Consider its indicator function $\\chi_A(x)$.\n1.  Since $A$ is invariant, $\\chi_A(T(x)) = \\chi_A(x)$ almost everywhere.\n2.  $\\chi_A \\in L^2(\\mathbb{T})$ because $\\mathbb{T}$ has finite measure.\n3.  By the result above, $\\chi_A$ must be constant almost everywhere.\n4.  Since $\\chi_A$ only takes values in $\\{0, 1\\}$, the only possible constants are 0 or 1.\n    - If $\\chi_A = 0$ a.e., then $\\mu(A) = 0$.\n    - If $\\chi_A = 1$ a.e., then $\\mu(A) = 1$.\n\nThus, $T$ is ergodic with respect to the Lebesgue measure.\n\n**Q.E.D.**",
        "raw_answer": "Here is the rigorous solution to the problem involving the ergodicity of irrational rotations on the unit circle.\n\n### **Problem Statement**\nLet $T: \\mathbb{T} \\to \\mathbb{T}$ be defined by $T(x) = x + \\alpha \\pmod 1$, where $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$ is the unit circle and $\\alpha \\in \\mathbb{R}$ is irrational. Prove that $T$ is ergodic with respect to the Lebesgue measure $\\mu$ on $\\mathbb{T}$.\n\n---\n\n### **Solution**\n\nTo prove that the transformation $T$ is ergodic, we must show that the only measurable sets invariant under $T$ are trivial (having measure 0 or 1).\n\n**Definition of Ergodicity:**\nA measure-preserving transformation $T$ on a probability space $(X, \\mathcal{B}, \\mu)$ is **ergodic** if for every measurable set $A \\in \\mathcal{B}$ such that $T^{-1}(A) = A$ (up to a set of measure zero), we have either $\\mu(A) = 0$ or $\\mu(A) = 1$.\n\nAn equivalent and often more analytically tractable characterization involves invariant functions:\n**Theorem:** $T$ is ergodic if and only if every function $f \\in L^2(X, \\mu)$ satisfying $f \\circ T = f$ almost everywhere is constant almost everywhere.\n\nWe will use this characterization to prove the statement.\n\n#### **Step 1: Verification that $T$ is Measure-Preserving**\nThe Lebesgue measure $\\mu$ on the circle $\\mathbb{T}$ is invariant under translation. For any measurable set $A \\subseteq \\mathbb{T}$,\n$$ \\mu(T^{-1}(A)) = \\mu(\\{x \\mid x + \\alpha \\in A\\}) = \\mu(A - \\alpha). $$\nSince Lebesgue measure is translation-invariant, $\\mu(A - \\alpha) = \\mu(A)$. Thus, $T$ is a measure-preserving transformation.\n\n#### **Step 2: Analysis of Invariant Functions using Fourier Series**\nLet $f \\in L^2(\\mathbb{T}, \\mu)$ be a $T$-invariant function. That is:\n$$ f(T(x)) = f(x) \\quad \\text{for } \\mu\\text{-almost every } x \\in \\mathbb{T}. $$\n\nSince $\\{e_n(x) = e^{2\\pi i n x} \\mid n \\in \\mathbb{Z}\\}$ forms an orthonormal basis for the Hilbert space $L^2(\\mathbb{T})$, we can expand $f$ into its Fourier series:\n$$ f(x) = \\sum_{n \\in \\mathbb{Z}} c_n e^{2\\pi i n x}, \\quad \\text{where } c_n = \\int_{\\mathbb{T}} f(x) e^{-2\\pi i n x} \\, d\\mu(x). $$\nHere, the series converges to $f$ in the $L^2$ norm.\n\nWe compute the Fourier series of the composition $f \\circ T$:\n$$ (f \\circ T)(x) = f(x + \\alpha) = \\sum_{n \\in \\mathbb{Z}} c_n e^{2\\pi i n (x + \\alpha)} = \\sum_{n \\in \\mathbb{Z}} \\left( c_n e^{2\\pi i n \\alpha} \\right) e^{2\\pi i n x}. $$\n\n#### **Step 3: Comparing Fourier Coefficients**\nSince $f \\circ T = f$ almost everywhere, their Fourier coefficients must be identical. By the uniqueness of Fourier coefficients in $L^2(\\mathbb{T})$, we equate the coefficients for each $n \\in \\mathbb{Z}$:\n$$ c_n = c_n e^{2\\pi i n \\alpha}. $$\nRearranging this equation gives:\n$$ c_n (1 - e^{2\\pi i n \\alpha}) = 0. $$\n\n#### **Step 4: Using the Irrationality of $\\alpha$**\nWe analyze the condition $c_n (1 - e^{2\\pi i n \\alpha}) = 0$ for different values of $n$:\n\n1.  **Case $n = 0$**:\n    The term $1 - e^{2\\pi i (0) \\alpha} = 1 - 1 = 0$. The equation becomes $c_0 \\cdot 0 = 0$, which places no constraint on $c_0$.\n\n2.  **Case $n \\neq 0$**:\n    We must determine if the factor $(1 - e^{2\\pi i n \\alpha})$ can be zero.\n    $$ 1 - e^{2\\pi i n \\alpha} = 0 \\iff e^{2\\pi i n \\alpha} = 1 \\iff n\\alpha = k \\text{ for some } k \\in \\mathbb{Z}. $$\n    This implies $\\alpha = \\frac{k}{n}$.\n    However, the problem states that $\\alpha$ is **irrational**. Therefore, $\\alpha$ cannot be expressed as a ratio of integers $k/n$ for any $n \\neq 0$.\n    Consequently, $e^{2\\pi i n \\alpha} \\neq 1$, which implies $(1 - e^{2\\pi i n \\alpha}) \\neq 0$.\n    \n    To satisfy the equation $c_n (1 - e^{2\\pi i n \\alpha}) = 0$, we must have:\n    $$ c_n = 0 \\quad \\text{for all } n \\neq 0. $$\n\n#### **Step 5: Conclusion**\nWe have determined that for any $T$-invariant function $f$, all Fourier coefficients $c_n$ are zero except possibly $c_0$. Thus, the Fourier series reduces to:\n$$ f(x) = c_0. $$\nSince the Fourier series converges to $f$ in $L^2$, $f$ is equal to the constant $c_0$ almost everywhere.\n\n#### **Final Argument for Sets**\nTo complete the proof based on the definition of ergodicity involving sets:\nLet $A \\subseteq \\mathbb{T}$ be a measurable set such that $T^{-1}(A) = A$ (modulo measure zero). Consider its indicator function $\\chi_A(x)$.\n1.  Since $A$ is invariant, $\\chi_A(T(x)) = \\chi_A(x)$ almost everywhere.\n2.  $\\chi_A \\in L^2(\\mathbb{T})$ because $\\mathbb{T}$ has finite measure.\n3.  By the result above, $\\chi_A$ must be constant almost everywhere.\n4.  Since $\\chi_A$ only takes values in $\\{0, 1\\}$, the only possible constants are 0 or 1.\n    - If $\\chi_A = 0$ a.e., then $\\mu(A) = 0$.\n    - If $\\chi_A = 1$ a.e., then $\\mu(A) = 1$.\n\nThus, $T$ is ergodic with respect to the Lebesgue measure.\n\n**Q.E.D.**",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of difference and functional equations, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the key elements of a good problem in the domain\nA good problem in the domain of difference and functional equations should involve a functional equation or a difference equation that requires substantive mathematical reasoning to solve. It should be fully specified, with clear notation and constraints.\n\n## Step 3: Generate a problem\nLet's generate a problem: \"Find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation $f(x + y) = f(x) + f(y) + xy$ for all $x, y \\in \\mathbb{R}$, and $f(1) = 1$.\"\n\n## Step 4: Verify that the generated problem meets the quality rubric\n- **Well-Posedness and Completeness**: The problem is fully self-contained, with the domain and codomain of $f$ specified, and the functional equation given.\n- **Clarity**: The notation is standard, and the task is clear.\n- **Non-Triviality**: The problem requires solving a functional equation, which is non-trivial.\n- **Solvability and Verification**: The problem is solvable using established methods for functional equations.\n\n## Step 5: Solve the generated problem\nTo solve $f(x + y) = f(x) + f(y) + xy$, let's first try substituting specific values for $x$ and $y$ to derive additional information.\n\n## Step 6: Substitute $x = y = 0$ into the equation\n$f(0 + 0) = f(0) + f(0) + 0 \\cdot 0$ simplifies to $f(0) = 2f(0)$, which implies $f(0) = 0$.\n\n## Step 7: Substitute $y = 1$ into the original equation\n$f(x + 1) = f(x) + f(1) + x = f(x) + x + 1$, since $f(1) = 1$. This gives a recursive formula to find $f(x)$ for integer values of $x$.\n\n## Step 8: Use the recursive formula to find $f(n)$ for any integer $n$\nStarting from $f(0) = 0$ and $f(1) = 1$, we can derive $f(2)$, $f(3)$, etc., to look for a pattern. $f(2) = f(1) + f(1) + 1 = 3$, $f(3) = f(2) + f(1) + 2 = 6$. It appears that $f(n) = \\frac{n(n+1)}{2}$ for positive integers $n$.\n\n## Step 9: Check if $f(x) = \\frac{x(x+1)}{2}$ satisfies the original functional equation\nSubstitute $f(x) = \\frac{x(x+1)}{2}$ into $f(x + y) = f(x) + f(y) + xy$:\n- LHS: $f(x + y) = \\frac{(x+y)(x+y+1)}{2} = \\frac{x^2 + 2xy + y^2 + x + y}{2}$\n- RHS: $f(x) + f(y) + xy = \\frac{x(x+1)}{2} + \\frac{y(y+1)}{2} + xy = \\frac{x^2 + x + y^2 + y + 2xy}{2}$\nBoth sides are equal, so $f(x) = \\frac{x(x+1)}{2}$ is a solution.\n\n## Step 10: Verify that the solution satisfies the initial condition\n$f(1) = \\frac{1(1+1)}{2} = 1$, which matches the given condition.\n\nThe final answer is: \n\nFind all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation $f(x + y) = f(x) + f(y) + xy$ for all $x, y \\in \\mathbb{R}$, and $f(1) = 1$.",
    "run_id": "25",
    "outer_attempt": 1,
    "topic_slug": "difference_and_functional_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation\n$$ f(x + y) = f(x) + f(y) + xy $$\nfor all $x, y \\in \\mathbb{R}$, subject to the condition $f(1) = 1$, we proceed with the following steps.\n\n### Step 1: Reduce the Non-Homogeneous Equation\nThe term $xy$ in the functional equation makes it non-homogeneous. We seek to eliminate this term by finding a particular solution.\n\nConsider a polynomial solution of the form $p(x) = ax^2$. Substituting this into the equation:\n$$ a(x+y)^2 = ax^2 + ay^2 + xy $$\n$$ a(x^2 + 2xy + y^2) = ax^2 + ay^2 + xy $$\n$$ ax^2 + 2axy + ay^2 = ax^2 + ay^2 + xy $$\nComparing the terms, we must have $2axy = xy$, which implies $2a = 1$, or $a = \\frac{1}{2}$.\n\nThus, $p(x) = \\frac{1}{2}x^2$ satisfies the non-homogeneous part of the recurrence. We can now express the general function $f(x)$ as the sum of this particular solution and a homogeneous part. Let:\n$$ f(x) = \\frac{1}{2}x^2 + g(x) $$\nwhere $g: \\mathbb{R} \\to \\mathbb{R}$ is a new function to be determined.\n\n### Step 2: Determine the Equation for $g(x)$\nSubstitute $f(x) = \\frac{1}{2}x^2 + g(x)$ into the original functional equation:\n$$ \\frac{1}{2}(x+y)^2 + g(x+y) = \\left(\\frac{1}{2}x^2 + g(x)\\right) + \\left(\\frac{1}{2}y^2 + g(y)\\right) + xy $$\nExpand the left side:\n$$ \\frac{1}{2}(x^2 + 2xy + y^2) + g(x+y) = \\frac{1}{2}x^2 + g(x) + \\frac{1}{2}y^2 + g(y) + xy $$\n$$ \\frac{1}{2}x^2 + xy + \\frac{1}{2}y^2 + g(x+y) = \\frac{1}{2}x^2 + \\frac{1}{2}y^2 + xy + g(x) + g(y) $$\nSubtracting $\\frac{1}{2}x^2 + \\frac{1}{2}y^2 + xy$ from both sides yields:\n$$ g(x+y) = g(x) + g(y) $$\nThis is the **Cauchy Functional Equation**.\n\n### Step 3: Apply the Initial Condition\nWe are given $f(1) = 1$. Using the definition of $g(x)$:\n$$ f(1) = \\frac{1}{2}(1)^2 + g(1) = 1 $$\n$$ \\frac{1}{2} + g(1) = 1 \\implies g(1) = \\frac{1}{2} $$\n\n### Step 4: Solve the Cauchy Functional Equation\nThe function $g: \\mathbb{R} \\to \\mathbb{R}$ must satisfy:\n1. $g(x+y) = g(x) + g(y)$ for all $x, y \\in \\mathbb{R}$\n2. $g(1) = \\frac{1}{2}$\n\nFrom the additivity property $g(x+y) = g(x) + g(y)$, we can prove by induction that $g(nx) = n g(x)$ for all integers $n$. Furthermore, for any rational number $q = \\frac{m}{n}$ (where $m, n \\in \\mathbb{Z}, n \\neq 0$), we have $g(q) = q g(1)$.\n\nProof for rationals:\nSince $g(1) = \\frac{1}{2}$, for any integer $n$:\n$$ g(n) = g(n \\cdot 1) = n g(1) = \\frac{n}{2} $$\nFor any rational $x = \\frac{m}{n}$:\n$$ g\\left(n \\cdot \\frac{m}{n}\\right) = n g\\left(\\frac{m}{n}\\right) $$\n$$ g(m) = n g\\left(\\frac{m}{n}\\right) $$\n$$ \\frac{m}{2} = n g\\left(\\frac{m}{n}\\right) \\implies g\\left(\\frac{m}{n}\\right) = \\frac{1}{n} \\cdot \\frac{m}{2} = \\frac{1}{2} \\cdot \\frac{m}{n} $$\nThus, for all $x \\in \\mathbb{Q}$, $g(x) = \\frac{1}{2}x$.\n\nHowever, for $x \\notin \\mathbb{Q}$, $g(x)$ is not uniquely determined by the value at $1$ without additional assumptions (such as continuity, monotonicity, or boundedness). The general solution to the Cauchy Functional Equation is any additive function $A: \\mathbb{R} \\to \\mathbb{R}$.\n\nLet $A(x)$ be any additive function (i.e., $A(x+y)=A(x)+A(y)$). The condition $g(1) = 1/2$ restricts $A$ such that $A(1) = 1/2$.\nWe can write this as $g(x) = A(x)$, where $A(1) = 1/2$. Alternatively, we can define $H(x) = A(x) - \\frac{1}{2}x$. Then $H$ is an additive function with $H(1) = A(1) - \\frac{1}{2} = 0$. Since $H(1)=0$ and $H$ is additive, $H(q) = 0$ for all $q \\in \\mathbb{Q}$.\nThus, the most general form for $g(x)$ is:\n$$ g(x) = \\frac{1}{2}x + H(x) $$\nwhere $H: \\mathbb{R} \\to \\mathbb{R}$ is an additive function such that $H(x) = 0$ for all $x \\in \\mathbb{Q}$.\n\n### Step 5: Construct the Final Solution\nSubstituting $g(x)$ back into the expression for $f(x)$:\n$$ f(x) = \\frac{1}{2}x^2 + g(x) $$\n$$ f(x) = \\frac{1}{2}x^2 + \\frac{1}{2}x + H(x) $$\n$$ f(x) = \\frac{x(x+1)}{2} + H(x) $$\n\n**Verification:**\nLHS: $f(x+y) = \\frac{(x+y)^2 + (x+y)}{2} + H(x+y)$\nRHS: $f(x) + f(y) + xy = \\left(\\frac{x^2+x}{2} + H(x)\\right) + \\left(\\frac{y^2+y}{2} + H(y)\\right) + xy$\n\nExpanding terms:\nLHS: $\\frac{x^2 + 2xy + y^2 + x + y}{2} + H(x) + H(y)$ (since H is additive)\nRHS: $\\frac{x^2 + x + y^2 + y + 2xy}{2} + H(x) + H(y)$\nThe sides are identical.\nCondition $f(1) = \\frac{1(2)}{2} + H(1) = 1 + 0 = 1$. The condition holds.\n\n### Conclusion\n\nThe set of all solutions depends on whether any regularity conditions (like continuity) are assumed. Since the problem statement does not impose such conditions, we provide the general solution.\n\nThe complete set of functions $f: \\mathbb{R} \\to \\mathbb{R}$ satisfying the conditions is given by:\n$$ f(x) = \\frac{x(x+1)}{2} + H(x) $$\nwhere $H: \\mathbb{R} \\to \\mathbb{R}$ is any additive function (satisfying $H(x+y) = H(x) + H(y)$) that vanishes on all rational numbers (i.e., $H(q) = 0$ for all $q \\in \\mathbb{Q}$).\n\n*Note: If $f$ is assumed to be continuous, then $H(x)$ must be identically zero, and the unique solution is $f(x) = \\frac{x(x+1)}{2}$.*",
        "raw_answer": "To find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation\n$$ f(x + y) = f(x) + f(y) + xy $$\nfor all $x, y \\in \\mathbb{R}$, subject to the condition $f(1) = 1$, we proceed with the following steps.\n\n### Step 1: Reduce the Non-Homogeneous Equation\nThe term $xy$ in the functional equation makes it non-homogeneous. We seek to eliminate this term by finding a particular solution.\n\nConsider a polynomial solution of the form $p(x) = ax^2$. Substituting this into the equation:\n$$ a(x+y)^2 = ax^2 + ay^2 + xy $$\n$$ a(x^2 + 2xy + y^2) = ax^2 + ay^2 + xy $$\n$$ ax^2 + 2axy + ay^2 = ax^2 + ay^2 + xy $$\nComparing the terms, we must have $2axy = xy$, which implies $2a = 1$, or $a = \\frac{1}{2}$.\n\nThus, $p(x) = \\frac{1}{2}x^2$ satisfies the non-homogeneous part of the recurrence. We can now express the general function $f(x)$ as the sum of this particular solution and a homogeneous part. Let:\n$$ f(x) = \\frac{1}{2}x^2 + g(x) $$\nwhere $g: \\mathbb{R} \\to \\mathbb{R}$ is a new function to be determined.\n\n### Step 2: Determine the Equation for $g(x)$\nSubstitute $f(x) = \\frac{1}{2}x^2 + g(x)$ into the original functional equation:\n$$ \\frac{1}{2}(x+y)^2 + g(x+y) = \\left(\\frac{1}{2}x^2 + g(x)\\right) + \\left(\\frac{1}{2}y^2 + g(y)\\right) + xy $$\nExpand the left side:\n$$ \\frac{1}{2}(x^2 + 2xy + y^2) + g(x+y) = \\frac{1}{2}x^2 + g(x) + \\frac{1}{2}y^2 + g(y) + xy $$\n$$ \\frac{1}{2}x^2 + xy + \\frac{1}{2}y^2 + g(x+y) = \\frac{1}{2}x^2 + \\frac{1}{2}y^2 + xy + g(x) + g(y) $$\nSubtracting $\\frac{1}{2}x^2 + \\frac{1}{2}y^2 + xy$ from both sides yields:\n$$ g(x+y) = g(x) + g(y) $$\nThis is the **Cauchy Functional Equation**.\n\n### Step 3: Apply the Initial Condition\nWe are given $f(1) = 1$. Using the definition of $g(x)$:\n$$ f(1) = \\frac{1}{2}(1)^2 + g(1) = 1 $$\n$$ \\frac{1}{2} + g(1) = 1 \\implies g(1) = \\frac{1}{2} $$\n\n### Step 4: Solve the Cauchy Functional Equation\nThe function $g: \\mathbb{R} \\to \\mathbb{R}$ must satisfy:\n1. $g(x+y) = g(x) + g(y)$ for all $x, y \\in \\mathbb{R}$\n2. $g(1) = \\frac{1}{2}$\n\nFrom the additivity property $g(x+y) = g(x) + g(y)$, we can prove by induction that $g(nx) = n g(x)$ for all integers $n$. Furthermore, for any rational number $q = \\frac{m}{n}$ (where $m, n \\in \\mathbb{Z}, n \\neq 0$), we have $g(q) = q g(1)$.\n\nProof for rationals:\nSince $g(1) = \\frac{1}{2}$, for any integer $n$:\n$$ g(n) = g(n \\cdot 1) = n g(1) = \\frac{n}{2} $$\nFor any rational $x = \\frac{m}{n}$:\n$$ g\\left(n \\cdot \\frac{m}{n}\\right) = n g\\left(\\frac{m}{n}\\right) $$\n$$ g(m) = n g\\left(\\frac{m}{n}\\right) $$\n$$ \\frac{m}{2} = n g\\left(\\frac{m}{n}\\right) \\implies g\\left(\\frac{m}{n}\\right) = \\frac{1}{n} \\cdot \\frac{m}{2} = \\frac{1}{2} \\cdot \\frac{m}{n} $$\nThus, for all $x \\in \\mathbb{Q}$, $g(x) = \\frac{1}{2}x$.\n\nHowever, for $x \\notin \\mathbb{Q}$, $g(x)$ is not uniquely determined by the value at $1$ without additional assumptions (such as continuity, monotonicity, or boundedness). The general solution to the Cauchy Functional Equation is any additive function $A: \\mathbb{R} \\to \\mathbb{R}$.\n\nLet $A(x)$ be any additive function (i.e., $A(x+y)=A(x)+A(y)$). The condition $g(1) = 1/2$ restricts $A$ such that $A(1) = 1/2$.\nWe can write this as $g(x) = A(x)$, where $A(1) = 1/2$. Alternatively, we can define $H(x) = A(x) - \\frac{1}{2}x$. Then $H$ is an additive function with $H(1) = A(1) - \\frac{1}{2} = 0$. Since $H(1)=0$ and $H$ is additive, $H(q) = 0$ for all $q \\in \\mathbb{Q}$.\nThus, the most general form for $g(x)$ is:\n$$ g(x) = \\frac{1}{2}x + H(x) $$\nwhere $H: \\mathbb{R} \\to \\mathbb{R}$ is an additive function such that $H(x) = 0$ for all $x \\in \\mathbb{Q}$.\n\n### Step 5: Construct the Final Solution\nSubstituting $g(x)$ back into the expression for $f(x)$:\n$$ f(x) = \\frac{1}{2}x^2 + g(x) $$\n$$ f(x) = \\frac{1}{2}x^2 + \\frac{1}{2}x + H(x) $$\n$$ f(x) = \\frac{x(x+1)}{2} + H(x) $$\n\n**Verification:**\nLHS: $f(x+y) = \\frac{(x+y)^2 + (x+y)}{2} + H(x+y)$\nRHS: $f(x) + f(y) + xy = \\left(\\frac{x^2+x}{2} + H(x)\\right) + \\left(\\frac{y^2+y}{2} + H(y)\\right) + xy$\n\nExpanding terms:\nLHS: $\\frac{x^2 + 2xy + y^2 + x + y}{2} + H(x) + H(y)$ (since H is additive)\nRHS: $\\frac{x^2 + x + y^2 + y + 2xy}{2} + H(x) + H(y)$\nThe sides are identical.\nCondition $f(1) = \\frac{1(2)}{2} + H(1) = 1 + 0 = 1$. The condition holds.\n\n### Conclusion\n\nThe set of all solutions depends on whether any regularity conditions (like continuity) are assumed. Since the problem statement does not impose such conditions, we provide the general solution.\n\nThe complete set of functions $f: \\mathbb{R} \\to \\mathbb{R}$ satisfying the conditions is given by:\n$$ f(x) = \\frac{x(x+1)}{2} + H(x) $$\nwhere $H: \\mathbb{R} \\to \\mathbb{R}$ is any additive function (satisfying $H(x+y) = H(x) + H(y)$) that vanishes on all rational numbers (i.e., $H(q) = 0$ for all $q \\in \\mathbb{Q}$).\n\n*Note: If $f$ is assumed to be continuous, then $H(x)$ must be identically zero, and the unique solution is $f(x) = \\frac{x(x+1)}{2}$.*",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$.",
    "run_id": "26",
    "outer_attempt": 1,
    "topic_slug": "sequences_series_and_summability",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$, we will proceed by decomposing the general term into partial fractions, expressing the series in terms of partial sums, and utilizing the known series expansion for $\\ln(2)$.\n\n### 1. Partial Fraction Decomposition\n\nFirst, we analyze the term $a_n = \\frac{(-1)^{n+1}}{n(n+1)}$. We can decompose the rational part $\\frac{1}{n(n+1)}$ as follows:\n$$ \\frac{1}{n(n+1)} = \\frac{1}{n} - \\frac{1}{n+1} $$\nThus, the general term of the series becomes:\n$$ a_n = (-1)^{n+1} \\left( \\frac{1}{n} - \\frac{1}{n+1} \\right) = \\frac{(-1)^{n+1}}{n} - \\frac{(-1)^{n+1}}{n+1} $$\nNoting that $-(-1)^{n+1} = (-1)^{n+2}$, we can rewrite this as:\n$$ a_n = \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{n+2}}{n+1} $$\n\n### 2. Analysis of Partial Sums\n\nLet $S_N$ be the partial sum of the first $N$ terms. By the linearity of finite summation, we can split $S_N$ into two separate sums:\n$$ S_N = \\sum_{n=1}^{N} \\left( \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{n+2}}{n+1} \\right) = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{n=1}^{N} \\frac{(-1)^{n+2}}{n+1} $$\n\nWe will shift the index of the second sum to align the denominators with the first sum. Let $k = n + 1$. When $n=1$, $k=2$, and when $n=N$, $k=N+1$.\n$$ \\sum_{n=1}^{N} \\frac{(-1)^{n+2}}{n+1} = \\sum_{k=2}^{N+1} \\frac{(-1)^{k+1}}{k} $$\n\nNow, substitute this back into the expression for $S_N$:\n$$ S_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{k=2}^{N+1} \\frac{(-1)^{k+1}}{k} $$\n\nWe can isolate the first term of the first sum ($n=1$) and the last term of the second sum ($k=N+1$) to align the ranges of summation from $2$ to $N$:\n1. The first sum is: $1 + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n}$\n2. The second sum is: $\\sum_{k=2}^{N} \\frac{(-1)^{k+1}}{k} + \\frac{(-1)^{N+2}}{N+1}$\n\nCombining these (and noting that the summation index variable is a dummy variable, so we can set $k=n$):\n$$ S_N = 1 + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{N+2}}{N+1} $$\n$$ S_N = 1 + 2\\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{N}}{N+1} $$\n*(Note: $(-1)^{N+2} = (-1)^N$)*\n\n### 3. Evaluating the Limit\n\nWe now take the limit as $N \\to \\infty$.\n$$ S = \\lim_{N \\to \\infty} S_N = 1 + 2 \\lim_{N \\to \\infty} \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\lim_{N \\to \\infty} \\frac{(-1)^{N}}{N+1} $$\n\nThe last term clearly approaches 0:\n$$ \\lim_{N \\to \\infty} \\frac{(-1)^{N}}{N+1} = 0 $$\n\nTo evaluate the infinite sum, recall the Mercator series for $\\ln(1+x)$ evaluated at $x=1$:\n$$ \\ln(2) = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n} = 1 - \\frac{1}{2} + \\frac{1}{3} - \\frac{1}{4} + \\dots $$\nWe can isolate the first term ($n=1$) from this series:\n$$ \\ln(2) = 1 + \\sum_{n=2}^{\\infty} \\frac{(-1)^{n+1}}{n} $$\nTherefore:\n$$ \\sum_{n=2}^{\\infty} \\frac{(-1)^{n+1}}{n} = \\ln(2) - 1 $$\n\nSubstituting this result back into our expression for the total sum $S$:\n$$ S = 1 + 2(\\ln(2) - 1) + 0 $$\n$$ S = 1 + 2\\ln(2) - 2 $$\n$$ S = 2\\ln(2) - 1 $$\n\n### Conclusion\n\nThe value of the infinite series is:\n$$ \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)} = 2\\ln(2) - 1 $$",
        "raw_answer": "To evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$, we will proceed by decomposing the general term into partial fractions, expressing the series in terms of partial sums, and utilizing the known series expansion for $\\ln(2)$.\n\n### 1. Partial Fraction Decomposition\n\nFirst, we analyze the term $a_n = \\frac{(-1)^{n+1}}{n(n+1)}$. We can decompose the rational part $\\frac{1}{n(n+1)}$ as follows:\n$$ \\frac{1}{n(n+1)} = \\frac{1}{n} - \\frac{1}{n+1} $$\nThus, the general term of the series becomes:\n$$ a_n = (-1)^{n+1} \\left( \\frac{1}{n} - \\frac{1}{n+1} \\right) = \\frac{(-1)^{n+1}}{n} - \\frac{(-1)^{n+1}}{n+1} $$\nNoting that $-(-1)^{n+1} = (-1)^{n+2}$, we can rewrite this as:\n$$ a_n = \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{n+2}}{n+1} $$\n\n### 2. Analysis of Partial Sums\n\nLet $S_N$ be the partial sum of the first $N$ terms. By the linearity of finite summation, we can split $S_N$ into two separate sums:\n$$ S_N = \\sum_{n=1}^{N} \\left( \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{n+2}}{n+1} \\right) = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{n=1}^{N} \\frac{(-1)^{n+2}}{n+1} $$\n\nWe will shift the index of the second sum to align the denominators with the first sum. Let $k = n + 1$. When $n=1$, $k=2$, and when $n=N$, $k=N+1$.\n$$ \\sum_{n=1}^{N} \\frac{(-1)^{n+2}}{n+1} = \\sum_{k=2}^{N+1} \\frac{(-1)^{k+1}}{k} $$\n\nNow, substitute this back into the expression for $S_N$:\n$$ S_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{k=2}^{N+1} \\frac{(-1)^{k+1}}{k} $$\n\nWe can isolate the first term of the first sum ($n=1$) and the last term of the second sum ($k=N+1$) to align the ranges of summation from $2$ to $N$:\n1. The first sum is: $1 + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n}$\n2. The second sum is: $\\sum_{k=2}^{N} \\frac{(-1)^{k+1}}{k} + \\frac{(-1)^{N+2}}{N+1}$\n\nCombining these (and noting that the summation index variable is a dummy variable, so we can set $k=n$):\n$$ S_N = 1 + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{N+2}}{N+1} $$\n$$ S_N = 1 + 2\\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{N}}{N+1} $$\n*(Note: $(-1)^{N+2} = (-1)^N$)*\n\n### 3. Evaluating the Limit\n\nWe now take the limit as $N \\to \\infty$.\n$$ S = \\lim_{N \\to \\infty} S_N = 1 + 2 \\lim_{N \\to \\infty} \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\lim_{N \\to \\infty} \\frac{(-1)^{N}}{N+1} $$\n\nThe last term clearly approaches 0:\n$$ \\lim_{N \\to \\infty} \\frac{(-1)^{N}}{N+1} = 0 $$\n\nTo evaluate the infinite sum, recall the Mercator series for $\\ln(1+x)$ evaluated at $x=1$:\n$$ \\ln(2) = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n} = 1 - \\frac{1}{2} + \\frac{1}{3} - \\frac{1}{4} + \\dots $$\nWe can isolate the first term ($n=1$) from this series:\n$$ \\ln(2) = 1 + \\sum_{n=2}^{\\infty} \\frac{(-1)^{n+1}}{n} $$\nTherefore:\n$$ \\sum_{n=2}^{\\infty} \\frac{(-1)^{n+1}}{n} = \\ln(2) - 1 $$\n\nSubstituting this result back into our expression for the total sum $S$:\n$$ S = 1 + 2(\\ln(2) - 1) + 0 $$\n$$ S = 1 + 2\\ln(2) - 2 $$\n$$ S = 2\\ln(2) - 1 $$\n\n### Conclusion\n\nThe value of the infinite series is:\n$$ \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)} = 2\\ln(2) - 1 $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the topic\nThe task is to generate a challenging mathematics problem along with a complete and verifiable solution in the domain of \"Approximations and expansions.\" The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within \"Approximations and expansions\"\nA suitable topic could involve Taylor series expansions, asymptotic approximations, or other related areas where mathematical functions are approximated.\n\n## Step 3: Formulate a challenging problem\nLet's consider a problem involving the approximation of a function using its Taylor series expansion. A classic example is approximating $e^x$ or $\\sin(x)$ around $x = 0$. However, to make it more challenging, we could involve a less straightforward function or require the derivation of an approximation under certain conditions.\n\n## Step 4: Create a specific problem\nConsider the function $f(x) = \\frac{1}{\\sqrt{1 + x}}$. We can ask to find the Taylor series expansion of $f(x)$ around $x = 0$ up to the third term and then use this expansion to approximate $f(0.1)$.\n\n## Step 5: Formulate the problem statement\nLet's refine the problem: \"Find the Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to and including the term involving $x^3$. Then, use this expansion to approximate $f(0.1)$ and compare it with the exact value.\"\n\n## Step 6: Write the problem in the required format\n\nFind the Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to and including the term involving $x^3$. Then, use this expansion to approximate $f(0.1)$ and compare it with the exact value.",
    "run_id": "27",
    "outer_attempt": 1,
    "topic_slug": "approximations_and_expansions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the problem presented in Step 6, we will proceed in three parts:\n1.  Derive the Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to the third-order term.\n2.  Use this expansion to approximate $f(0.1)$.\n3.  Compare the approximation with the exact value.\n\n### Part 1: Taylor Series Expansion\n\nThe Taylor series expansion of a function $f(x)$ centered at $x = a$ is given by:\n$$f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!} (x-a)^n$$\nFor this problem, $a = 0$ (a Maclaurin series), and we are required to find terms up to $n=3$. The polynomial approximation $P_3(x)$ is:\n$$P_3(x) = f(0) + f'(0)x + \\frac{f''(0)}{2!}x^2 + \\frac{f'''(0)}{3!}x^3$$\n\n**Step 1.1: Calculate Derivatives**\nLet $f(x) = (1+x)^{-1/2}$. We compute the first three derivatives with respect to $x$:\n\n1.  **Zeroth Derivative (Function value):**\n    $$f(x) = (1+x)^{-1/2}$$\n\n2.  **First Derivative:**\n    $$f'(x) = -\\frac{1}{2}(1+x)^{-3/2}$$\n\n3.  **Second Derivative:**\n    $$f''(x) = \\left(-\\frac{1}{2}\\right)\\left(-\\frac{3}{2}\\right)(1+x)^{-5/2} = \\frac{3}{4}(1+x)^{-5/2}$$\n\n4.  **Third Derivative:**\n    $$f'''(x) = \\left(\\frac{3}{4}\\right)\\left(-\\frac{5}{2}\\right)(1+x)^{-7/2} = -\\frac{15}{8}(1+x)^{-7/2}$$\n\n**Step 1.2: Evaluate at $x = 0$**\n\n1.  $f(0) = (1+0)^{-1/2} = 1$\n2.  $f'(0) = -\\frac{1}{2}(1)^{-3/2} = -\\frac{1}{2}$\n3.  $f''(0) = \\frac{3}{4}(1)^{-5/2} = \\frac{3}{4}$\n4.  $f'''(0) = -\\frac{15}{8}(1)^{-7/2} = -\\frac{15}{8}$\n\n**Step 1.3: Construct the Polynomial**\nSubstitute these values into the Taylor formula:\n\n$$P_3(x) = 1 + \\left(-\\frac{1}{2}\\right)x + \\frac{3/4}{2!}x^2 + \\frac{-15/8}{3!}x^3$$\n\nSimplify the coefficients:\n-   Coefficient of $x$: $-\\frac{1}{2}$\n-   Coefficient of $x^2$: $\\frac{3/4}{2} = \\frac{3}{8}$\n-   Coefficient of $x^3$: $\\frac{-15/8}{6} = -\\frac{15}{48} = -\\frac{5}{16}$\n\nThus, the Taylor series expansion up to the term involving $x^3$ is:\n$$f(x) \\approx 1 - \\frac{1}{2}x + \\frac{3}{8}x^2 - \\frac{5}{16}x^3$$\n\n### Part 2: Approximation of $f(0.1)$\n\nWe approximate $f(0.1)$ by evaluating $P_3(0.1)$.\nLet $x = 0.1$.\n\n$$P_3(0.1) = 1 - \\frac{1}{2}(0.1) + \\frac{3}{8}(0.1)^2 - \\frac{5}{16}(0.1)^3$$\n\nConvert fractions to decimals for calculation:\n-   $1/2 = 0.5$\n-   $3/8 = 0.375$\n-   $5/16 = 0.3125$\n\nSubstitute these values:\n$$P_3(0.1) = 1 - 0.5(0.1) + 0.375(0.01) - 0.3125(0.001)$$\n\nCalculate each term:\n1.  $0.5 \\times 0.1 = 0.05$\n2.  $0.375 \\times 0.01 = 0.00375$\n3.  $0.3125 \\times 0.001 = 0.0003125$\n\nCombine terms:\n$$P_3(0.1) = 1 - 0.05 + 0.00375 - 0.0003125$$\n$$P_3(0.1) = 0.95 + 0.00375 - 0.0003125$$\n$$P_3(0.1) = 0.95375 - 0.0003125$$\n$$P_3(0.1) = 0.9534375$$\n\n**Approximate value:** $0.9534375$\n\n### Part 3: Comparison with Exact Value\n\nThe exact value is $f(0.1) = \\frac{1}{\\sqrt{1 + 0.1}} = \\frac{1}{\\sqrt{1.1}}$.\n\nUsing a calculator for high precision:\n$$\\sqrt{1.1} \\approx 1.04880884817$$\n$$f(0.1) = \\frac{1}{1.04880884817} \\approx 0.95346258925$$\n\n**Comparison:**\n-   **Approximation ($P_3(0.1)$):** $0.9534375$\n-   **Exact Value ($f(0.1)$):** $\\approx 0.9534626$\n\n**Absolute Error:**\n$$|f(0.1) - P_3(0.1)| \\approx |0.95346258925 - 0.9534375|$$\n$$\\approx 0.000025089$$\n\nThe approximation is accurate to 4 decimal places.\n\n### Final Conclusion\n\nThe Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to $x^3$ is:\n$$1 - \\frac{1}{2}x + \\frac{3}{8}x^2 - \\frac{5}{16}x^3$$\n\nUsing this expansion, the approximate value of $f(0.1)$ is **0.9534375**, which differs from the exact value by approximately $2.5 \\times 10^{-5}$.",
        "raw_answer": "To solve the problem presented in Step 6, we will proceed in three parts:\n1.  Derive the Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to the third-order term.\n2.  Use this expansion to approximate $f(0.1)$.\n3.  Compare the approximation with the exact value.\n\n### Part 1: Taylor Series Expansion\n\nThe Taylor series expansion of a function $f(x)$ centered at $x = a$ is given by:\n$$f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!} (x-a)^n$$\nFor this problem, $a = 0$ (a Maclaurin series), and we are required to find terms up to $n=3$. The polynomial approximation $P_3(x)$ is:\n$$P_3(x) = f(0) + f'(0)x + \\frac{f''(0)}{2!}x^2 + \\frac{f'''(0)}{3!}x^3$$\n\n**Step 1.1: Calculate Derivatives**\nLet $f(x) = (1+x)^{-1/2}$. We compute the first three derivatives with respect to $x$:\n\n1.  **Zeroth Derivative (Function value):**\n    $$f(x) = (1+x)^{-1/2}$$\n\n2.  **First Derivative:**\n    $$f'(x) = -\\frac{1}{2}(1+x)^{-3/2}$$\n\n3.  **Second Derivative:**\n    $$f''(x) = \\left(-\\frac{1}{2}\\right)\\left(-\\frac{3}{2}\\right)(1+x)^{-5/2} = \\frac{3}{4}(1+x)^{-5/2}$$\n\n4.  **Third Derivative:**\n    $$f'''(x) = \\left(\\frac{3}{4}\\right)\\left(-\\frac{5}{2}\\right)(1+x)^{-7/2} = -\\frac{15}{8}(1+x)^{-7/2}$$\n\n**Step 1.2: Evaluate at $x = 0$**\n\n1.  $f(0) = (1+0)^{-1/2} = 1$\n2.  $f'(0) = -\\frac{1}{2}(1)^{-3/2} = -\\frac{1}{2}$\n3.  $f''(0) = \\frac{3}{4}(1)^{-5/2} = \\frac{3}{4}$\n4.  $f'''(0) = -\\frac{15}{8}(1)^{-7/2} = -\\frac{15}{8}$\n\n**Step 1.3: Construct the Polynomial**\nSubstitute these values into the Taylor formula:\n\n$$P_3(x) = 1 + \\left(-\\frac{1}{2}\\right)x + \\frac{3/4}{2!}x^2 + \\frac{-15/8}{3!}x^3$$\n\nSimplify the coefficients:\n-   Coefficient of $x$: $-\\frac{1}{2}$\n-   Coefficient of $x^2$: $\\frac{3/4}{2} = \\frac{3}{8}$\n-   Coefficient of $x^3$: $\\frac{-15/8}{6} = -\\frac{15}{48} = -\\frac{5}{16}$\n\nThus, the Taylor series expansion up to the term involving $x^3$ is:\n$$f(x) \\approx 1 - \\frac{1}{2}x + \\frac{3}{8}x^2 - \\frac{5}{16}x^3$$\n\n### Part 2: Approximation of $f(0.1)$\n\nWe approximate $f(0.1)$ by evaluating $P_3(0.1)$.\nLet $x = 0.1$.\n\n$$P_3(0.1) = 1 - \\frac{1}{2}(0.1) + \\frac{3}{8}(0.1)^2 - \\frac{5}{16}(0.1)^3$$\n\nConvert fractions to decimals for calculation:\n-   $1/2 = 0.5$\n-   $3/8 = 0.375$\n-   $5/16 = 0.3125$\n\nSubstitute these values:\n$$P_3(0.1) = 1 - 0.5(0.1) + 0.375(0.01) - 0.3125(0.001)$$\n\nCalculate each term:\n1.  $0.5 \\times 0.1 = 0.05$\n2.  $0.375 \\times 0.01 = 0.00375$\n3.  $0.3125 \\times 0.001 = 0.0003125$\n\nCombine terms:\n$$P_3(0.1) = 1 - 0.05 + 0.00375 - 0.0003125$$\n$$P_3(0.1) = 0.95 + 0.00375 - 0.0003125$$\n$$P_3(0.1) = 0.95375 - 0.0003125$$\n$$P_3(0.1) = 0.9534375$$\n\n**Approximate value:** $0.9534375$\n\n### Part 3: Comparison with Exact Value\n\nThe exact value is $f(0.1) = \\frac{1}{\\sqrt{1 + 0.1}} = \\frac{1}{\\sqrt{1.1}}$.\n\nUsing a calculator for high precision:\n$$\\sqrt{1.1} \\approx 1.04880884817$$\n$$f(0.1) = \\frac{1}{1.04880884817} \\approx 0.95346258925$$\n\n**Comparison:**\n-   **Approximation ($P_3(0.1)$):** $0.9534375$\n-   **Exact Value ($f(0.1)$):** $\\approx 0.9534626$\n\n**Absolute Error:**\n$$|f(0.1) - P_3(0.1)| \\approx |0.95346258925 - 0.9534375|$$\n$$\\approx 0.000025089$$\n\nThe approximation is accurate to 4 decimal places.\n\n### Final Conclusion\n\nThe Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to $x^3$ is:\n$$1 - \\frac{1}{2}x + \\frac{3}{8}x^2 - \\frac{5}{16}x^3$$\n\nUsing this expansion, the approximate value of $f(0.1)$ is **0.9534375**, which differs from the exact value by approximately $2.5 \\times 10^{-5}$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ and suppose that its Fourier transform $\\hat{f}$ is supported in the ball $B(0,1) = \\{ \\xi \\in \\mathbb{R}^n : |\\xi| \\leq 1 \\}$. Prove that $f$ is smooth, i.e., $f \\in C^\\infty(\\mathbb{R}^n)$, and that for any multi-index $\\alpha$, there exists a constant $C_\\alpha > 0$ such that $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$ for all $x \\in \\mathbb{R}^n$.",
    "run_id": "28",
    "outer_attempt": 1,
    "topic_slug": "harmonic_analysis_on_euclidean_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The problem asks us to prove two properties for a function $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ whose Fourier transform $\\hat{f}$ is supported in the unit ball $B(0,1)$. The two properties are:\n1.  $f$ is smooth, i.e., $f \\in C^\\infty(\\mathbb{R}^n)$.\n2.  $f$ and its derivatives satisfy the decay estimate $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$.\n\nWhile the first assertion (smoothness) is true and can be proven rigorously, the second assertion (decay rate) is **false** as stated. There exist functions satisfying the given hypotheses that do not decay as fast as $(1+|x|)^{-n-1}$.\n\nBelow, we provide the proof of smoothness and then demonstrate via counterexample why the decay estimate does not hold in general.\n\n### Part 1: Proof of Smoothness\n\nWe are given that $f \\in L^1(\\mathbb{R}^n)$. By the Riemann-Lebesgue lemma, the Fourier transform $\\hat{f}$ is continuous and bounded. We are also given that $\\text{supp}(\\hat{f}) \\subseteq B(0,1)$.\nSince $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$, we can recover $f$ from $\\hat{f}$ via the inverse Fourier transform (which holds pointwise or almost everywhere; since $\\hat{f} \\in L^1$, it holds pointwise and $f$ is continuous):\n$$ f(x) = \\int_{\\mathbb{R}^n} \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nUsing the support condition, the integral is restricted to the unit ball:\n$$ f(x) = \\int_{B(0,1)} \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nTo prove that $f \\in C^\\infty(\\mathbb{R}^n)$, consider the partial derivative with respect to $x$ corresponding to a multi-index $\\alpha$. Formally differentiating under the integral sign gives the integrand:\n$$ g_\\alpha(x, \\xi) = (2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} $$\nWe must verify that this differentiation is valid.\n1.  For any fixed $x$, the function $\\xi \\mapsto g_\\alpha(x, \\xi)$ is continuous on $B(0,1)$ (since $\\hat{f}$ is continuous) and zero outside. Thus, it is integrable.\n2.  We can bound the integrand uniformly in $x$:\n    $$ |(2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi}| \\leq (2\\pi)^ {|\\alpha|} |\\xi|^{|\\alpha|} |\\hat{f}(\\xi)| $$\n    Since $|\\xi| \\leq 1$ on the support of $\\hat{f}$, and $\\hat{f}$ is bounded (let $\\|\\hat{f}\\|_\\infty = M$), we have:\n    $$ |(2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi}| \\leq (2\\pi)^{|\\alpha|} M \\chi_{B(0,1)}(\\xi) $$\n    The dominating function $G(\\xi) = (2\\pi)^{|\\alpha|} M \\chi_{B(0,1)}(\\xi)$ is in $L^1(\\mathbb{R}^n)$ because the volume of the ball is finite.\n\nBy the standard theorem on differentiation under the integral sign (a consequence of the Dominated Convergence Theorem), $f$ is infinitely differentiable, and\n$$ \\partial^\\alpha f(x) = \\int_{B(0,1)} (2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nThus, $f \\in C^\\infty(\\mathbb{R}^n)$. Furthermore, by the bound on the integrand, $\\partial^\\alpha f$ is bounded on $\\mathbb{R}^n$.\n\n---\n\n### Part 2: Analysis of the Decay Estimate\n\nThe problem asserts that $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$. This implies that $f(x)$ must decay at least as fast as $|x|^{-n-1}$ as $|x| \\to \\infty$. We will show this is false by constructing a counterexample.\n\nConsider the family of radial functions defined by their Fourier transforms. Let $\\delta > 0$ and define $\\hat{f}_\\delta$ on $\\mathbb{R}^n$ by:\n$$ \\hat{f}_\\delta(\\xi) = \\begin{cases} (1 - |\\xi|^2)^\\delta & \\text{if } |\\xi| \\leq 1 \\\\ 0 & \\text{if } |\\xi| > 1 \\end{cases} $$\nThis function is supported in $B(0,1)$. Since $\\delta > 0$, $\\hat{f}_\\delta$ is continuous everywhere (vanishing at the boundary $|\\xi|=1$).\n\nThe inverse Fourier transform $f_\\delta(x)$ is related to the Bessel function of the first kind. Specifically, for $x \\in \\mathbb{R}^n$:\n$$ f_\\delta(x) = \\frac{\\Gamma(\\delta+1)}{\\pi^\\delta} |x|^{-(n/2 + \\delta)} J_{n/2 + \\delta}(2\\pi |x|) $$\nUsing the asymptotic expansion of the Bessel function for large argument $r$, $J_\\nu(r) \\approx \\sqrt{\\frac{2}{\\pi r}} \\cos(r - \\dots)$, the decay of $f_\\delta(x)$ as $|x| \\to \\infty$ is:\n$$ |f_\\delta(x)| \\sim C |x|^{-(n/2 + \\delta)} |x|^{-1/2} = C |x|^{-\\frac{n+1}{2} - \\delta} $$\nLet $\\gamma = \\frac{n+1}{2} + \\delta$. So $|f_\\delta(x)| \\sim |x|^{-\\gamma}$.\n\n**Condition 1: Integrability ($f \\in L^1$)**\nFor $f_\\delta$ to be in $L^1(\\mathbb{R}^n)$, we require the integral of $|x|^{-\\gamma}$ to converge at infinity (it is bounded near 0). Using polar coordinates, we need:\n$$ \\int_1^\\infty r^{-\\gamma} r^{n-1} \\, dr < \\infty \\iff -\\gamma + n - 1 < -1 \\iff \\gamma > n $$\nSubstituting $\\gamma$:\n$$ \\frac{n+1}{2} + \\delta > n \\iff \\delta > \\frac{n-1}{2} $$\n\n**Condition 2: The Claimed Decay**\nThe problem claims decay of order $|x|^{-n-1}$. This requires:\n$$ \\gamma \\ge n+1 \\iff \\frac{n+1}{2} + \\delta \\ge n+1 \\iff \\delta \\ge \\frac{n+1}{2} $$\n\n**The Contradiction**\nWe observe a gap between the condition for $L^1$ membership and the condition for the claimed decay. If we choose $\\delta$ such that:\n$$ \\frac{n-1}{2} < \\delta < \\frac{n+1}{2} $$\nthen $f_\\delta \\in L^1(\\mathbb{R}^n)$ (and $L^2$, as $\\hat{f}_\\delta \\in L^2$ trivially), and $\\text{supp}(\\hat{f}_\\delta) \\subset B(0,1)$, but $f_\\delta(x)$ decays like $|x|^{-\\frac{n+1}{2}-\\delta}$, which is **slower** than $|x|^{-n-1}$.\n\n**Specific Counterexample in 1D ($n=1$):**\nWe need $0 < \\delta < 1$. Let $\\delta = 0.5$.\nThen $\\hat{f}_{0.5}(\\xi) = (1-\\xi^2)^{0.5} \\chi_{[-1,1]}(\\xi)$.\nThe function $f_{0.5}(x)$ behaves asymptotically as $|x|^{-(1+1)/2 - 0.5} = |x|^{-1.5}$.\nSince $1.5 > 1$, $f_{0.5} \\in L^1(\\mathbb{R})$.\nHowever, the claimed decay is $(1+|x|)^{-2}$.\nSince $|x|^{-1.5}$ decays slower than $|x|^{-2}$, the inequality $|\\partial^\\alpha f(x)| \\leq C (1+|x|)^{-2}$ fails for $\\alpha=0$ and large $x$.\n\n### Conclusion\nThe function $f$ is guaranteed to be smooth ($C^\\infty$), but the decay estimate $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$ is **not necessarily true** under the stated assumptions. The estimate holds only if stronger regularity assumptions are imposed on $\\hat{f}$ at the boundary of the unit ball (e.g., if $\\hat{f} \\in C_c^\\infty(B(0,1))$).",
        "raw_answer": "The problem asks us to prove two properties for a function $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ whose Fourier transform $\\hat{f}$ is supported in the unit ball $B(0,1)$. The two properties are:\n1.  $f$ is smooth, i.e., $f \\in C^\\infty(\\mathbb{R}^n)$.\n2.  $f$ and its derivatives satisfy the decay estimate $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$.\n\nWhile the first assertion (smoothness) is true and can be proven rigorously, the second assertion (decay rate) is **false** as stated. There exist functions satisfying the given hypotheses that do not decay as fast as $(1+|x|)^{-n-1}$.\n\nBelow, we provide the proof of smoothness and then demonstrate via counterexample why the decay estimate does not hold in general.\n\n### Part 1: Proof of Smoothness\n\nWe are given that $f \\in L^1(\\mathbb{R}^n)$. By the Riemann-Lebesgue lemma, the Fourier transform $\\hat{f}$ is continuous and bounded. We are also given that $\\text{supp}(\\hat{f}) \\subseteq B(0,1)$.\nSince $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$, we can recover $f$ from $\\hat{f}$ via the inverse Fourier transform (which holds pointwise or almost everywhere; since $\\hat{f} \\in L^1$, it holds pointwise and $f$ is continuous):\n$$ f(x) = \\int_{\\mathbb{R}^n} \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nUsing the support condition, the integral is restricted to the unit ball:\n$$ f(x) = \\int_{B(0,1)} \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nTo prove that $f \\in C^\\infty(\\mathbb{R}^n)$, consider the partial derivative with respect to $x$ corresponding to a multi-index $\\alpha$. Formally differentiating under the integral sign gives the integrand:\n$$ g_\\alpha(x, \\xi) = (2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} $$\nWe must verify that this differentiation is valid.\n1.  For any fixed $x$, the function $\\xi \\mapsto g_\\alpha(x, \\xi)$ is continuous on $B(0,1)$ (since $\\hat{f}$ is continuous) and zero outside. Thus, it is integrable.\n2.  We can bound the integrand uniformly in $x$:\n    $$ |(2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi}| \\leq (2\\pi)^ {|\\alpha|} |\\xi|^{|\\alpha|} |\\hat{f}(\\xi)| $$\n    Since $|\\xi| \\leq 1$ on the support of $\\hat{f}$, and $\\hat{f}$ is bounded (let $\\|\\hat{f}\\|_\\infty = M$), we have:\n    $$ |(2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi}| \\leq (2\\pi)^{|\\alpha|} M \\chi_{B(0,1)}(\\xi) $$\n    The dominating function $G(\\xi) = (2\\pi)^{|\\alpha|} M \\chi_{B(0,1)}(\\xi)$ is in $L^1(\\mathbb{R}^n)$ because the volume of the ball is finite.\n\nBy the standard theorem on differentiation under the integral sign (a consequence of the Dominated Convergence Theorem), $f$ is infinitely differentiable, and\n$$ \\partial^\\alpha f(x) = \\int_{B(0,1)} (2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nThus, $f \\in C^\\infty(\\mathbb{R}^n)$. Furthermore, by the bound on the integrand, $\\partial^\\alpha f$ is bounded on $\\mathbb{R}^n$.\n\n---\n\n### Part 2: Analysis of the Decay Estimate\n\nThe problem asserts that $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$. This implies that $f(x)$ must decay at least as fast as $|x|^{-n-1}$ as $|x| \\to \\infty$. We will show this is false by constructing a counterexample.\n\nConsider the family of radial functions defined by their Fourier transforms. Let $\\delta > 0$ and define $\\hat{f}_\\delta$ on $\\mathbb{R}^n$ by:\n$$ \\hat{f}_\\delta(\\xi) = \\begin{cases} (1 - |\\xi|^2)^\\delta & \\text{if } |\\xi| \\leq 1 \\\\ 0 & \\text{if } |\\xi| > 1 \\end{cases} $$\nThis function is supported in $B(0,1)$. Since $\\delta > 0$, $\\hat{f}_\\delta$ is continuous everywhere (vanishing at the boundary $|\\xi|=1$).\n\nThe inverse Fourier transform $f_\\delta(x)$ is related to the Bessel function of the first kind. Specifically, for $x \\in \\mathbb{R}^n$:\n$$ f_\\delta(x) = \\frac{\\Gamma(\\delta+1)}{\\pi^\\delta} |x|^{-(n/2 + \\delta)} J_{n/2 + \\delta}(2\\pi |x|) $$\nUsing the asymptotic expansion of the Bessel function for large argument $r$, $J_\\nu(r) \\approx \\sqrt{\\frac{2}{\\pi r}} \\cos(r - \\dots)$, the decay of $f_\\delta(x)$ as $|x| \\to \\infty$ is:\n$$ |f_\\delta(x)| \\sim C |x|^{-(n/2 + \\delta)} |x|^{-1/2} = C |x|^{-\\frac{n+1}{2} - \\delta} $$\nLet $\\gamma = \\frac{n+1}{2} + \\delta$. So $|f_\\delta(x)| \\sim |x|^{-\\gamma}$.\n\n**Condition 1: Integrability ($f \\in L^1$)**\nFor $f_\\delta$ to be in $L^1(\\mathbb{R}^n)$, we require the integral of $|x|^{-\\gamma}$ to converge at infinity (it is bounded near 0). Using polar coordinates, we need:\n$$ \\int_1^\\infty r^{-\\gamma} r^{n-1} \\, dr < \\infty \\iff -\\gamma + n - 1 < -1 \\iff \\gamma > n $$\nSubstituting $\\gamma$:\n$$ \\frac{n+1}{2} + \\delta > n \\iff \\delta > \\frac{n-1}{2} $$\n\n**Condition 2: The Claimed Decay**\nThe problem claims decay of order $|x|^{-n-1}$. This requires:\n$$ \\gamma \\ge n+1 \\iff \\frac{n+1}{2} + \\delta \\ge n+1 \\iff \\delta \\ge \\frac{n+1}{2} $$\n\n**The Contradiction**\nWe observe a gap between the condition for $L^1$ membership and the condition for the claimed decay. If we choose $\\delta$ such that:\n$$ \\frac{n-1}{2} < \\delta < \\frac{n+1}{2} $$\nthen $f_\\delta \\in L^1(\\mathbb{R}^n)$ (and $L^2$, as $\\hat{f}_\\delta \\in L^2$ trivially), and $\\text{supp}(\\hat{f}_\\delta) \\subset B(0,1)$, but $f_\\delta(x)$ decays like $|x|^{-\\frac{n+1}{2}-\\delta}$, which is **slower** than $|x|^{-n-1}$.\n\n**Specific Counterexample in 1D ($n=1$):**\nWe need $0 < \\delta < 1$. Let $\\delta = 0.5$.\nThen $\\hat{f}_{0.5}(\\xi) = (1-\\xi^2)^{0.5} \\chi_{[-1,1]}(\\xi)$.\nThe function $f_{0.5}(x)$ behaves asymptotically as $|x|^{-(1+1)/2 - 0.5} = |x|^{-1.5}$.\nSince $1.5 > 1$, $f_{0.5} \\in L^1(\\mathbb{R})$.\nHowever, the claimed decay is $(1+|x|)^{-2}$.\nSince $|x|^{-1.5}$ decays slower than $|x|^{-2}$, the inequality $|\\partial^\\alpha f(x)| \\leq C (1+|x|)^{-2}$ fails for $\\alpha=0$ and large $x$.\n\n### Conclusion\nThe function $f$ is guaranteed to be smooth ($C^\\infty$), but the decay estimate $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$ is **not necessarily true** under the stated assumptions. The estimate holds only if stronger regularity assumptions are imposed on $\\hat{f}$ at the boundary of the unit ball (e.g., if $\\hat{f} \\in C_c^\\infty(B(0,1))$).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task requires generating a challenging mathematics problem in the domain of abstract harmonic analysis. The problem should be well-posed, solvable, and verifiable.\n[/QUESTION]",
    "run_id": "29",
    "outer_attempt": 1,
    "topic_slug": "abstract_harmonic_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Based on the instruction to act as a testee generating a challenging problem in abstract harmonic analysis, here is the generated problem followed by a complete, rigorous solution.\n\n---\n\n### **Generated Problem**\n\n**Topic:** Harmonic Analysis on Local Fields ($p$-adic Analysis)\n\n**Problem Statement:**\nLet $p$ be a prime number and let $\\mathbb{Q}_p$ denote the field of $p$-adic numbers. Let $\\mu$ be the additive Haar measure on $\\mathbb{Q}_p$, normalized such that $\\mu(\\mathbb{Z}_p) = 1$, where $\\mathbb{Z}_p$ is the ring of $p$-adic integers. Let $\\psi$ be the standard additive character of $\\mathbb{Q}_p$ defined by $\\psi(x) = e^{2\\pi i \\{x\\}_p}$, where $\\{x\\}_p$ denotes the fractional part of $x$.\n\nConsider the function $f: \\mathbb{Q}_p \\to \\mathbb{R}$ defined by:\n$$ f(x) = \\begin{cases} 1 & \\text{if } |x|_p \\le 1, \\\\ |x|_p^{-2} & \\text{if } |x|_p > 1. \\end{cases} $$\n\n1.  Prove that $f \\in L^1(\\mathbb{Q}_p) \\cap L^2(\\mathbb{Q}_p)$.\n2.  Compute the Fourier transform $\\widehat{f}(\\xi)$, defined by\n    $$ \\widehat{f}(\\xi) = \\int_{\\mathbb{Q}_p} f(x) \\psi(x\\xi) \\, d\\mu(x). $$\n    Express $\\widehat{f}(\\xi)$ explicitly as a function of $|\\xi|_p$.\n3.  Verify the Plancherel theorem for this function by explicitly computing $\\|f\\|_{L^2}^2$ and $\\|\\widehat{f}\\|_{L^2}^2$.\n\n---\n\n### **Solution**\n\n#### **Part 1: Integrability of $f$**\n\nThe group $\\mathbb{Q}_p$ can be decomposed into disjoint spherical shells $S_k = \\{ x \\in \\mathbb{Q}_p : |x|_p = p^k \\}$ for $k \\in \\mathbb{Z}$.\nThe measure of a shell $S_k$ is given by:\n$$ \\mu(S_k) = \\mu(p^{-k}\\mathbb{Z}_p) - \\mu(p^{-k+1}\\mathbb{Z}_p) = p^k - p^{k-1} = p^k(1 - p^{-1}). $$\n\n**Checking $L^1$ norm:**\n$$ \\|f\\|_1 = \\int_{\\mathbb{Q}_p} |f(x)| \\, d\\mu(x) = \\int_{|x|_p \\le 1} 1 \\, d\\mu(x) + \\sum_{k=1}^{\\infty} \\int_{S_k} |x|_p^{-2} \\, d\\mu(x). $$\nThe first term is $\\mu(\\mathbb{Z}_p) = 1$.\nFor the sum, on $S_k$, $|x|_p = p^k$, so $f(x) = p^{-2k}$.\n$$ \\sum_{k=1}^{\\infty} p^{-2k} \\mu(S_k) = \\sum_{k=1}^{\\infty} p^{-2k} \\cdot p^k (1 - p^{-1}) = (1 - p^{-1}) \\sum_{k=1}^{\\infty} p^{-k}. $$\nThis is a geometric series with ratio $1/p < 1$.\n$$ \\sum_{k=1}^{\\infty} p^{-k} = \\frac{1/p}{1 - 1/p} = \\frac{1}{p-1}. $$\nThus,\n$$ \\|f\\|_1 = 1 + (1 - p^{-1}) \\frac{1}{p-1} = 1 + \\frac{p-1}{p} \\frac{1}{p-1} = 1 + \\frac{1}{p} < \\infty. $$\nSo $f \\in L^1(\\mathbb{Q}_p)$.\n\n**Checking $L^2$ norm:**\n$$ \\|f\\|_2^2 = \\int_{\\mathbb{Q}_p} |f(x)|^2 \\, d\\mu(x) = \\int_{|x|_p \\le 1} 1^2 \\, d\\mu(x) + \\sum_{k=1}^{\\infty} \\int_{S_k} (p^{-2k})^2 \\, d\\mu(x). $$\n$$ \\|f\\|_2^2 = 1 + \\sum_{k=1}^{\\infty} p^{-4k} p^k (1 - p^{-1}) = 1 + (1 - p^{-1}) \\sum_{k=1}^{\\infty} p^{-3k}. $$\nThe geometric series sum is $\\frac{p^{-3}}{1 - p^{-3}} = \\frac{1}{p^3 - 1}$.\n$$ \\|f\\|_2^2 = 1 + \\frac{p-1}{p} \\frac{1}{(p-1)(p^2+p+1)} = 1 + \\frac{1}{p(p^2+p+1)} < \\infty. $$\nSo $f \\in L^2(\\mathbb{Q}_p)$.\n\n---\n\n#### **Part 2: Computing the Fourier Transform**\n\nSince $f$ is a radial function (depends only on $|x|_p$), $\\widehat{f}$ will also be radial. Let $|\\xi|_p = p^m$ for some integer $m$.\n$$ \\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{\\infty} \\int_{S_k} f(x) \\psi(x\\xi) \\, d\\mu(x). $$\nSubstituting the values of $f(x)$:\n$$ \\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{0} \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x) + \\sum_{k=1}^{\\infty} p^{-2k} \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x). $$\nLet $I_k(\\xi) = \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x)$.\nWe define the ball $B_k = \\{ x : |x|_p \\le p^k \\}$. Then $S_k = B_k \\setminus B_{k-1}$.\nThe integral of the character over a ball is a standard result:\n$$ \\int_{B_k} \\psi(x\\xi) \\, d\\mu(x) = \\begin{cases} \\mu(B_k) = p^k & \\text{if } |\\xi|_p \\le p^{-k}, \\\\ 0 & \\text{if } |\\xi|_p > p^{-k}. \\end{cases} $$\nGiven $|\\xi|_p = p^m$, the condition $|\\xi|_p \\le p^{-k}$ is equivalent to $p^m \\le p^{-k} \\iff m \\le -k \\iff k \\le -m$.\n\nThus,\n$$ I_k(\\xi) = \\int_{B_k} \\psi(x\\xi) \\, d\\mu - \\int_{B_{k-1}} \\psi(x\\xi) \\, d\\mu. $$\nWe analyze $I_k(\\xi)$ based on the relation between $k$ and $-m$:\n1.  If $k \\le -m - 1$ (so $k-1 < k \\le -m$), both integrals are non-zero.\n    $I_k(\\xi) = p^k - p^{k-1}$. (Note: In this range, the character oscillates slowly enough to be effectively 1).\n2.  If $k = -m$:\n    The integral over $B_k$ is $p^k$ (since $k \\le -m$ holds).\n    The integral over $B_{k-1}$ is $p^{k-1}$ (since $k-1 \\le -m$ holds).\n    Wait, the condition is strict for the cutoff. Let's re-evaluate carefully.\n    \n    Let $J_k = \\mathbb{1}_{k \\le -m} p^k$. Then $I_k = J_k - J_{k-1}$.\n    \n    -   **Case $k < -m$**: $k \\le -m$ and $k-1 \\le -m$.\n        $I_k = p^k - p^{k-1}$.\n    -   **Case $k = -m$**: $k \\le -m$ is true. $k-1 \\le -m$ is true.\n        $I_k = p^{-m} - p^{-m-1}$.\n    -   **Case $k = -m+1$**: $k \\le -m$ is false ($J_k=0$). $k-1 = -m \\le -m$ is true ($J_{k-1}=p^{-m}$).\n        $I_k = 0 - p^{-m} = -p^{-m}$.\n    -   **Case $k > -m+1$**: Both are 0. $I_k = 0$.\n\nSo the only non-zero terms in the sum for $\\widehat{f}(\\xi)$ are for $k \\le -m+1$.\nWe split the calculation into cases for $m$ (the magnitude of $\\xi$).\n\n**Case A: $|\\xi|_p \\le 1$ (i.e., $m \\le 0$).**\nThe critical index is $-m+1 \\ge 1$.\nThe sum has two parts: $k \\le 0$ where $f(x)=1$, and $k \\ge 1$ where $f(x)=p^{-2k}$.\nSince $m \\le 0$, the \"cutoff\" $k = -m+1$ occurs in the $k \\ge 1$ region.\n\n1.  Sum for $k \\le 0$:\n    $$ \\sum_{k=-\\infty}^{0} 1 \\cdot (p^k - p^{k-1}) = \\lim_{N\\to-\\infty} (p^0 - p^{N-1}) = 1. $$\n    (This is simply $\\int_{|x|_p \\le 1} \\psi(x\\xi) d\\mu$, which is 1 since $|\\xi|_p \\le 1$).\n\n2.  Sum for $1 \\le k \\le -m$:\n    Here $I_k = p^k - p^{k-1}$.\n    $$ \\sum_{k=1}^{-m} p^{-2k} (p^k - p^{k-1}) = (1 - p^{-1}) \\sum_{k=1}^{-m} p^{-k} = (1 - p^{-1}) \\frac{p^{-1}(1 - p^{m})}{1 - p^{-1}} = p^{-1} - p^{m-1}. $$\n    If $-m < 1$ (i.e., $m=0$), this sum is empty (equals 0).\n\n3.  Term for $k = -m+1$:\n    $I_k = -p^{-m}$. $f(p^k) = p^{-2(-m+1)} = p^{2m-2}$.\n    $$ \\text{Term} = p^{2m-2} (-p^{-m}) = -p^{m-2}. $$\n\n**Subcase A1: $m=0$ ($|\\xi|_p=1$).**\nSum 1 (for $k \\le 0$) = 1.\nSum 2 (empty) = 0.\nTerm $k=1$: $I_1 = -1$ (since $m=0, -m+1=1$). $f(p)=p^{-2}$.\nContribution: $-p^{-2}$.\n$$ \\widehat{f}(\\xi) = 1 - p^{-2}. $$\n\n**Subcase A2: $m < 0$ ($|\\xi|_p < 1$).**\nTotal = (Sum 1) + (Sum 2) + (Term $k=-m+1$).\n$$ \\widehat{f}(\\xi) = 1 + (p^{-1} - p^{m-1}) - p^{m-2} = 1 + p^{-1} - p^{m-2}(p+1). $$\n\n**Case B: $|\\xi|_p > 1$ (i.e., $m \\ge 1$).**\nHere $-m+1 \\le 0$. The cutoff happens within the region where $f(x)=1$.\nThe terms for $k \\ge 1$ are all zero because $I_k=0$ there.\nWe only sum for $k \\le -m+1 \\le 0$.\nIn this range $f(p^k) = 1$.\nThe integral is over the ball $B_{-m+1}$.\n$$ \\widehat{f}(\\xi) = \\int_{|x|_p \\le p^{-m+1}} 1 \\cdot \\psi(x\\xi) \\, d\\mu(x). $$\nWe use the ball integral formula with radius $R = p^{-m+1}$.\nCondition for non-zero: $|\\xi|_p \\le 1/R = p^{m-1}$.\nBut we know $|\\xi|_p = p^m$.\nSince $p^m > p^{m-1}$, the condition is **false**.\nThus, $\\int_{B_{-m+1}} \\psi(x\\xi) \\, d\\mu(x) = 0$.\nWait, let's re-verify the cutoff summation logic.\n$\\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{-m+1} f(p^k) I_k$.\nSince $k \\le -m+1 \\le 0$, $f(p^k) = 1$ everywhere in the sum.\nSo $\\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{-m+1} (J_k - J_{k-1}) = J_{-m+1} - \\lim_{N\\to-\\infty} J_N$.\n$J_{-m+1} = p^{-m+1} \\mathbb{1}_{-m+1 \\le -m}$.\nIs $-m+1 \\le -m$? $1 \\le 0$? False.\nSo $J_{-m+1} = 0$.\nHence $\\widehat{f}(\\xi) = 0$ for all $m \\ge 1$.\n\n**Summary of $\\widehat{f}(\\xi)$:**\n$$ \\widehat{f}(\\xi) = \\begin{cases} 1 + p^{-1} - p^{-2}(p+1)|\\xi|_p & \\text{if } |\\xi|_p < 1, \\\\ 1 - p^{-2} & \\text{if } |\\xi|_p = 1, \\\\ 0 & \\text{if } |\\xi|_p > 1. \\end{cases} $$\nLet's check continuity at $|\\xi|_p \\to 1^-$ (i.e., $m \\to 0^-$? No, $p$-adic norm is discrete).\nAt $m=0$, formula 1 gives $1 + p^{-1} - p^{-2}(p+1) = 1 + p^{-1} - p^{-1} - p^{-2} = 1 - p^{-2}$. Matches.\nSo we can combine them:\n$$ \\widehat{f}(\\xi) = \\left( 1 + \\frac{1}{p} - \\frac{p+1}{p^2} |\\xi|_p \\right) \\mathbf{1}_{|\\xi|_p \\le 1}. $$\n\n---\n\n#### **Part 3: Verification of Plancherel Theorem**\n\nWe previously computed $\\|f\\|_2^2 = 1 + \\frac{1}{p(p^2+p+1)}$.\n\nNow we compute $\\|\\widehat{f}\\|_2^2$:\n$$ \\|\\widehat{f}\\|_2^2 = \\int_{\\mathbb{Q}_p} |\\widehat{f}(\\xi)|^2 \\, d\\mu(\\xi). $$\nSince $\\widehat{f}$ is supported on $|\\xi|_p \\le 1$ ($m \\le 0$):\n$$ \\|\\widehat{f}\\|_2^2 = \\sum_{m=-\\infty}^{0} \\int_{S_m} \\left( 1 + p^{-1} - p^{-2}(p+1)p^m \\right)^2 \\, d\\mu(\\xi). $$\nLet $A = 1 + p^{-1}$. Let $B = p^{-2}(p+1)$.\nTerm in square: $(A - B p^m)^2 = A^2 - 2AB p^m + B^2 p^{2m}$.\nMeasure of $S_m$ ($m \\le 0$): $p^m(1 - p^{-1})$.\n\n$$ \\|\\widehat{f}\\|_2^2 = \\sum_{m=-\\infty}^{0} (A^2 - 2AB p^m + B^2 p^{2m}) p^m (1 - p^{-1}). $$\nLet $C = 1 - p^{-1}$. Sum over $j = -m$ where $j \\in [0, \\infty)$. $p^m = p^{-j}$.\nTerms:\n1.  $A^2 \\sum p^m \\cdot p^m C$? No, integrand is constant on shell. Integral is Value$^2 \\times$ Volume.\n    $\\sum_{m=-\\infty}^0 (A - B p^m)^2 p^m C$.\n    Let $x = p^m$. Summing geometric series $\\sum_{k=0}^\\infty x^{k}$ with $x=1/p$.\n    Series 1: $\\sum_{m \\le 0} A^2 p^m = A^2 \\frac{1}{1-1/p} = A^2 \\frac{p}{p-1} = A^2 / C$.\n    Series 2: $\\sum_{m \\le 0} (-2AB) p^{2m} = -2AB \\frac{1}{1-1/p^2}$.\n    Series 3: $\\sum_{m \\le 0} B^2 p^{3m} = B^2 \\frac{1}{1-1/p^3}$.\n\nTotal $\\|\\widehat{f}\\|_2^2 = C \\left[ \\frac{A^2}{1-p^{-1}} - \\frac{2AB}{1-p^{-2}} + \\frac{B^2}{1-p^{-3}} \\right]$.\nNote $C = 1 - p^{-1}$.\nTerm 1: $C \\frac{A^2}{C} = A^2 = (1 + p^{-1})^2 = 1 + 2p^{-1} + p^{-2}$.\nTerm 2: $C \\frac{2AB}{C(1+p^{-1})} = \\frac{2AB}{1+p^{-1}} = \\frac{2A(p^{-2}(p+1))}{A} = 2 p^{-2}(p+1) = 2p^{-1} + 2p^{-2}$.\n    (Since $A = 1+1/p = (p+1)/p$, $2AB/(1+1/p) = 2B ((p+1)/p) / ((p+1)/p) = 2B$).\n    Wait, $1-p^{-2} = (1-p^{-1})(1+p^{-1})$. So denominator cancels $C$.\n    Left with $2AB/(1+p^{-1})$. Recall $A = 1+p^{-1}$. So it is just $2B$.\n    $2B = 2(p^{-2}(p+1)) = 2p^{-2} + 2p^{-1}$.\nTerm 3: $C \\frac{B^2}{1-p^{-3}} = (1-p^{-1}) \\frac{B^2}{(1-p^{-1})(1+p^{-1}+p^{-2})} = \\frac{B^2}{1+p^{-1}+p^{-2}}$.\n    $B = p^{-2}(p+1)$. $B^2 = p^{-4}(p+1)^2$.\n    Term 3 = $\\frac{p^{-4}(p+1)^2}{1+p^{-1}+p^{-2}} \\cdot \\frac{p^2}{p^2} = \\frac{p^{-4}(p+1)^2 p^2}{p^2+p+1} = \\frac{p^{-2}(p+1)^2}{p^2+p+1}$.\n\nSum = (Term 1) - (Term 2) + (Term 3).\n$(1 + 2p^{-1} + p^{-2}) - (2p^{-1} + 2p^{-2}) + \\text{Term 3}$\n$= 1 - p^{-2} + \\frac{p^{-2}(p+1)^2}{p^2+p+1}$\n$= 1 + p^{-2} \\left( -1 + \\frac{p^2+2p+1}{p^2+p+1} \\right)$\n$= 1 + p^{-2} \\left( \\frac{-(p^2+p+1) + p^2+2p+1}{p^2+p+1} \\right)$\n$= 1 + p^{-2} \\left( \\frac{p}{p^2+p+1} \\right)$\n$= 1 + \\frac{p^{-1}}{p^2+p+1} = 1 + \\frac{1}{p(p^2+p+1)}$.\n\nThis matches the result for $\\|f\\|_2^2$ exactly.\n\n**Conclusion:**\nThe Plancherel theorem is verified: $\\|f\\|_2^2 = \\|\\widehat{f}\\|_2^2$.",
        "raw_answer": "Based on the instruction to act as a testee generating a challenging problem in abstract harmonic analysis, here is the generated problem followed by a complete, rigorous solution.\n\n---\n\n### **Generated Problem**\n\n**Topic:** Harmonic Analysis on Local Fields ($p$-adic Analysis)\n\n**Problem Statement:**\nLet $p$ be a prime number and let $\\mathbb{Q}_p$ denote the field of $p$-adic numbers. Let $\\mu$ be the additive Haar measure on $\\mathbb{Q}_p$, normalized such that $\\mu(\\mathbb{Z}_p) = 1$, where $\\mathbb{Z}_p$ is the ring of $p$-adic integers. Let $\\psi$ be the standard additive character of $\\mathbb{Q}_p$ defined by $\\psi(x) = e^{2\\pi i \\{x\\}_p}$, where $\\{x\\}_p$ denotes the fractional part of $x$.\n\nConsider the function $f: \\mathbb{Q}_p \\to \\mathbb{R}$ defined by:\n$$ f(x) = \\begin{cases} 1 & \\text{if } |x|_p \\le 1, \\\\ |x|_p^{-2} & \\text{if } |x|_p > 1. \\end{cases} $$\n\n1.  Prove that $f \\in L^1(\\mathbb{Q}_p) \\cap L^2(\\mathbb{Q}_p)$.\n2.  Compute the Fourier transform $\\widehat{f}(\\xi)$, defined by\n    $$ \\widehat{f}(\\xi) = \\int_{\\mathbb{Q}_p} f(x) \\psi(x\\xi) \\, d\\mu(x). $$\n    Express $\\widehat{f}(\\xi)$ explicitly as a function of $|\\xi|_p$.\n3.  Verify the Plancherel theorem for this function by explicitly computing $\\|f\\|_{L^2}^2$ and $\\|\\widehat{f}\\|_{L^2}^2$.\n\n---\n\n### **Solution**\n\n#### **Part 1: Integrability of $f$**\n\nThe group $\\mathbb{Q}_p$ can be decomposed into disjoint spherical shells $S_k = \\{ x \\in \\mathbb{Q}_p : |x|_p = p^k \\}$ for $k \\in \\mathbb{Z}$.\nThe measure of a shell $S_k$ is given by:\n$$ \\mu(S_k) = \\mu(p^{-k}\\mathbb{Z}_p) - \\mu(p^{-k+1}\\mathbb{Z}_p) = p^k - p^{k-1} = p^k(1 - p^{-1}). $$\n\n**Checking $L^1$ norm:**\n$$ \\|f\\|_1 = \\int_{\\mathbb{Q}_p} |f(x)| \\, d\\mu(x) = \\int_{|x|_p \\le 1} 1 \\, d\\mu(x) + \\sum_{k=1}^{\\infty} \\int_{S_k} |x|_p^{-2} \\, d\\mu(x). $$\nThe first term is $\\mu(\\mathbb{Z}_p) = 1$.\nFor the sum, on $S_k$, $|x|_p = p^k$, so $f(x) = p^{-2k}$.\n$$ \\sum_{k=1}^{\\infty} p^{-2k} \\mu(S_k) = \\sum_{k=1}^{\\infty} p^{-2k} \\cdot p^k (1 - p^{-1}) = (1 - p^{-1}) \\sum_{k=1}^{\\infty} p^{-k}. $$\nThis is a geometric series with ratio $1/p < 1$.\n$$ \\sum_{k=1}^{\\infty} p^{-k} = \\frac{1/p}{1 - 1/p} = \\frac{1}{p-1}. $$\nThus,\n$$ \\|f\\|_1 = 1 + (1 - p^{-1}) \\frac{1}{p-1} = 1 + \\frac{p-1}{p} \\frac{1}{p-1} = 1 + \\frac{1}{p} < \\infty. $$\nSo $f \\in L^1(\\mathbb{Q}_p)$.\n\n**Checking $L^2$ norm:**\n$$ \\|f\\|_2^2 = \\int_{\\mathbb{Q}_p} |f(x)|^2 \\, d\\mu(x) = \\int_{|x|_p \\le 1} 1^2 \\, d\\mu(x) + \\sum_{k=1}^{\\infty} \\int_{S_k} (p^{-2k})^2 \\, d\\mu(x). $$\n$$ \\|f\\|_2^2 = 1 + \\sum_{k=1}^{\\infty} p^{-4k} p^k (1 - p^{-1}) = 1 + (1 - p^{-1}) \\sum_{k=1}^{\\infty} p^{-3k}. $$\nThe geometric series sum is $\\frac{p^{-3}}{1 - p^{-3}} = \\frac{1}{p^3 - 1}$.\n$$ \\|f\\|_2^2 = 1 + \\frac{p-1}{p} \\frac{1}{(p-1)(p^2+p+1)} = 1 + \\frac{1}{p(p^2+p+1)} < \\infty. $$\nSo $f \\in L^2(\\mathbb{Q}_p)$.\n\n---\n\n#### **Part 2: Computing the Fourier Transform**\n\nSince $f$ is a radial function (depends only on $|x|_p$), $\\widehat{f}$ will also be radial. Let $|\\xi|_p = p^m$ for some integer $m$.\n$$ \\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{\\infty} \\int_{S_k} f(x) \\psi(x\\xi) \\, d\\mu(x). $$\nSubstituting the values of $f(x)$:\n$$ \\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{0} \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x) + \\sum_{k=1}^{\\infty} p^{-2k} \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x). $$\nLet $I_k(\\xi) = \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x)$.\nWe define the ball $B_k = \\{ x : |x|_p \\le p^k \\}$. Then $S_k = B_k \\setminus B_{k-1}$.\nThe integral of the character over a ball is a standard result:\n$$ \\int_{B_k} \\psi(x\\xi) \\, d\\mu(x) = \\begin{cases} \\mu(B_k) = p^k & \\text{if } |\\xi|_p \\le p^{-k}, \\\\ 0 & \\text{if } |\\xi|_p > p^{-k}. \\end{cases} $$\nGiven $|\\xi|_p = p^m$, the condition $|\\xi|_p \\le p^{-k}$ is equivalent to $p^m \\le p^{-k} \\iff m \\le -k \\iff k \\le -m$.\n\nThus,\n$$ I_k(\\xi) = \\int_{B_k} \\psi(x\\xi) \\, d\\mu - \\int_{B_{k-1}} \\psi(x\\xi) \\, d\\mu. $$\nWe analyze $I_k(\\xi)$ based on the relation between $k$ and $-m$:\n1.  If $k \\le -m - 1$ (so $k-1 < k \\le -m$), both integrals are non-zero.\n    $I_k(\\xi) = p^k - p^{k-1}$. (Note: In this range, the character oscillates slowly enough to be effectively 1).\n2.  If $k = -m$:\n    The integral over $B_k$ is $p^k$ (since $k \\le -m$ holds).\n    The integral over $B_{k-1}$ is $p^{k-1}$ (since $k-1 \\le -m$ holds).\n    Wait, the condition is strict for the cutoff. Let's re-evaluate carefully.\n    \n    Let $J_k = \\mathbb{1}_{k \\le -m} p^k$. Then $I_k = J_k - J_{k-1}$.\n    \n    -   **Case $k < -m$**: $k \\le -m$ and $k-1 \\le -m$.\n        $I_k = p^k - p^{k-1}$.\n    -   **Case $k = -m$**: $k \\le -m$ is true. $k-1 \\le -m$ is true.\n        $I_k = p^{-m} - p^{-m-1}$.\n    -   **Case $k = -m+1$**: $k \\le -m$ is false ($J_k=0$). $k-1 = -m \\le -m$ is true ($J_{k-1}=p^{-m}$).\n        $I_k = 0 - p^{-m} = -p^{-m}$.\n    -   **Case $k > -m+1$**: Both are 0. $I_k = 0$.\n\nSo the only non-zero terms in the sum for $\\widehat{f}(\\xi)$ are for $k \\le -m+1$.\nWe split the calculation into cases for $m$ (the magnitude of $\\xi$).\n\n**Case A: $|\\xi|_p \\le 1$ (i.e., $m \\le 0$).**\nThe critical index is $-m+1 \\ge 1$.\nThe sum has two parts: $k \\le 0$ where $f(x)=1$, and $k \\ge 1$ where $f(x)=p^{-2k}$.\nSince $m \\le 0$, the \"cutoff\" $k = -m+1$ occurs in the $k \\ge 1$ region.\n\n1.  Sum for $k \\le 0$:\n    $$ \\sum_{k=-\\infty}^{0} 1 \\cdot (p^k - p^{k-1}) = \\lim_{N\\to-\\infty} (p^0 - p^{N-1}) = 1. $$\n    (This is simply $\\int_{|x|_p \\le 1} \\psi(x\\xi) d\\mu$, which is 1 since $|\\xi|_p \\le 1$).\n\n2.  Sum for $1 \\le k \\le -m$:\n    Here $I_k = p^k - p^{k-1}$.\n    $$ \\sum_{k=1}^{-m} p^{-2k} (p^k - p^{k-1}) = (1 - p^{-1}) \\sum_{k=1}^{-m} p^{-k} = (1 - p^{-1}) \\frac{p^{-1}(1 - p^{m})}{1 - p^{-1}} = p^{-1} - p^{m-1}. $$\n    If $-m < 1$ (i.e., $m=0$), this sum is empty (equals 0).\n\n3.  Term for $k = -m+1$:\n    $I_k = -p^{-m}$. $f(p^k) = p^{-2(-m+1)} = p^{2m-2}$.\n    $$ \\text{Term} = p^{2m-2} (-p^{-m}) = -p^{m-2}. $$\n\n**Subcase A1: $m=0$ ($|\\xi|_p=1$).**\nSum 1 (for $k \\le 0$) = 1.\nSum 2 (empty) = 0.\nTerm $k=1$: $I_1 = -1$ (since $m=0, -m+1=1$). $f(p)=p^{-2}$.\nContribution: $-p^{-2}$.\n$$ \\widehat{f}(\\xi) = 1 - p^{-2}. $$\n\n**Subcase A2: $m < 0$ ($|\\xi|_p < 1$).**\nTotal = (Sum 1) + (Sum 2) + (Term $k=-m+1$).\n$$ \\widehat{f}(\\xi) = 1 + (p^{-1} - p^{m-1}) - p^{m-2} = 1 + p^{-1} - p^{m-2}(p+1). $$\n\n**Case B: $|\\xi|_p > 1$ (i.e., $m \\ge 1$).**\nHere $-m+1 \\le 0$. The cutoff happens within the region where $f(x)=1$.\nThe terms for $k \\ge 1$ are all zero because $I_k=0$ there.\nWe only sum for $k \\le -m+1 \\le 0$.\nIn this range $f(p^k) = 1$.\nThe integral is over the ball $B_{-m+1}$.\n$$ \\widehat{f}(\\xi) = \\int_{|x|_p \\le p^{-m+1}} 1 \\cdot \\psi(x\\xi) \\, d\\mu(x). $$\nWe use the ball integral formula with radius $R = p^{-m+1}$.\nCondition for non-zero: $|\\xi|_p \\le 1/R = p^{m-1}$.\nBut we know $|\\xi|_p = p^m$.\nSince $p^m > p^{m-1}$, the condition is **false**.\nThus, $\\int_{B_{-m+1}} \\psi(x\\xi) \\, d\\mu(x) = 0$.\nWait, let's re-verify the cutoff summation logic.\n$\\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{-m+1} f(p^k) I_k$.\nSince $k \\le -m+1 \\le 0$, $f(p^k) = 1$ everywhere in the sum.\nSo $\\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{-m+1} (J_k - J_{k-1}) = J_{-m+1} - \\lim_{N\\to-\\infty} J_N$.\n$J_{-m+1} = p^{-m+1} \\mathbb{1}_{-m+1 \\le -m}$.\nIs $-m+1 \\le -m$? $1 \\le 0$? False.\nSo $J_{-m+1} = 0$.\nHence $\\widehat{f}(\\xi) = 0$ for all $m \\ge 1$.\n\n**Summary of $\\widehat{f}(\\xi)$:**\n$$ \\widehat{f}(\\xi) = \\begin{cases} 1 + p^{-1} - p^{-2}(p+1)|\\xi|_p & \\text{if } |\\xi|_p < 1, \\\\ 1 - p^{-2} & \\text{if } |\\xi|_p = 1, \\\\ 0 & \\text{if } |\\xi|_p > 1. \\end{cases} $$\nLet's check continuity at $|\\xi|_p \\to 1^-$ (i.e., $m \\to 0^-$? No, $p$-adic norm is discrete).\nAt $m=0$, formula 1 gives $1 + p^{-1} - p^{-2}(p+1) = 1 + p^{-1} - p^{-1} - p^{-2} = 1 - p^{-2}$. Matches.\nSo we can combine them:\n$$ \\widehat{f}(\\xi) = \\left( 1 + \\frac{1}{p} - \\frac{p+1}{p^2} |\\xi|_p \\right) \\mathbf{1}_{|\\xi|_p \\le 1}. $$\n\n---\n\n#### **Part 3: Verification of Plancherel Theorem**\n\nWe previously computed $\\|f\\|_2^2 = 1 + \\frac{1}{p(p^2+p+1)}$.\n\nNow we compute $\\|\\widehat{f}\\|_2^2$:\n$$ \\|\\widehat{f}\\|_2^2 = \\int_{\\mathbb{Q}_p} |\\widehat{f}(\\xi)|^2 \\, d\\mu(\\xi). $$\nSince $\\widehat{f}$ is supported on $|\\xi|_p \\le 1$ ($m \\le 0$):\n$$ \\|\\widehat{f}\\|_2^2 = \\sum_{m=-\\infty}^{0} \\int_{S_m} \\left( 1 + p^{-1} - p^{-2}(p+1)p^m \\right)^2 \\, d\\mu(\\xi). $$\nLet $A = 1 + p^{-1}$. Let $B = p^{-2}(p+1)$.\nTerm in square: $(A - B p^m)^2 = A^2 - 2AB p^m + B^2 p^{2m}$.\nMeasure of $S_m$ ($m \\le 0$): $p^m(1 - p^{-1})$.\n\n$$ \\|\\widehat{f}\\|_2^2 = \\sum_{m=-\\infty}^{0} (A^2 - 2AB p^m + B^2 p^{2m}) p^m (1 - p^{-1}). $$\nLet $C = 1 - p^{-1}$. Sum over $j = -m$ where $j \\in [0, \\infty)$. $p^m = p^{-j}$.\nTerms:\n1.  $A^2 \\sum p^m \\cdot p^m C$? No, integrand is constant on shell. Integral is Value$^2 \\times$ Volume.\n    $\\sum_{m=-\\infty}^0 (A - B p^m)^2 p^m C$.\n    Let $x = p^m$. Summing geometric series $\\sum_{k=0}^\\infty x^{k}$ with $x=1/p$.\n    Series 1: $\\sum_{m \\le 0} A^2 p^m = A^2 \\frac{1}{1-1/p} = A^2 \\frac{p}{p-1} = A^2 / C$.\n    Series 2: $\\sum_{m \\le 0} (-2AB) p^{2m} = -2AB \\frac{1}{1-1/p^2}$.\n    Series 3: $\\sum_{m \\le 0} B^2 p^{3m} = B^2 \\frac{1}{1-1/p^3}$.\n\nTotal $\\|\\widehat{f}\\|_2^2 = C \\left[ \\frac{A^2}{1-p^{-1}} - \\frac{2AB}{1-p^{-2}} + \\frac{B^2}{1-p^{-3}} \\right]$.\nNote $C = 1 - p^{-1}$.\nTerm 1: $C \\frac{A^2}{C} = A^2 = (1 + p^{-1})^2 = 1 + 2p^{-1} + p^{-2}$.\nTerm 2: $C \\frac{2AB}{C(1+p^{-1})} = \\frac{2AB}{1+p^{-1}} = \\frac{2A(p^{-2}(p+1))}{A} = 2 p^{-2}(p+1) = 2p^{-1} + 2p^{-2}$.\n    (Since $A = 1+1/p = (p+1)/p$, $2AB/(1+1/p) = 2B ((p+1)/p) / ((p+1)/p) = 2B$).\n    Wait, $1-p^{-2} = (1-p^{-1})(1+p^{-1})$. So denominator cancels $C$.\n    Left with $2AB/(1+p^{-1})$. Recall $A = 1+p^{-1}$. So it is just $2B$.\n    $2B = 2(p^{-2}(p+1)) = 2p^{-2} + 2p^{-1}$.\nTerm 3: $C \\frac{B^2}{1-p^{-3}} = (1-p^{-1}) \\frac{B^2}{(1-p^{-1})(1+p^{-1}+p^{-2})} = \\frac{B^2}{1+p^{-1}+p^{-2}}$.\n    $B = p^{-2}(p+1)$. $B^2 = p^{-4}(p+1)^2$.\n    Term 3 = $\\frac{p^{-4}(p+1)^2}{1+p^{-1}+p^{-2}} \\cdot \\frac{p^2}{p^2} = \\frac{p^{-4}(p+1)^2 p^2}{p^2+p+1} = \\frac{p^{-2}(p+1)^2}{p^2+p+1}$.\n\nSum = (Term 1) - (Term 2) + (Term 3).\n$(1 + 2p^{-1} + p^{-2}) - (2p^{-1} + 2p^{-2}) + \\text{Term 3}$\n$= 1 - p^{-2} + \\frac{p^{-2}(p+1)^2}{p^2+p+1}$\n$= 1 + p^{-2} \\left( -1 + \\frac{p^2+2p+1}{p^2+p+1} \\right)$\n$= 1 + p^{-2} \\left( \\frac{-(p^2+p+1) + p^2+2p+1}{p^2+p+1} \\right)$\n$= 1 + p^{-2} \\left( \\frac{p}{p^2+p+1} \\right)$\n$= 1 + \\frac{p^{-1}}{p^2+p+1} = 1 + \\frac{1}{p(p^2+p+1)}$.\n\nThis matches the result for $\\|f\\|_2^2$ exactly.\n\n**Conclusion:**\nThe Plancherel theorem is verified: $\\|f\\|_2^2 = \\|\\widehat{f}\\|_2^2$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging mathematics problem in the domain of \"Integral transforms, operational calculus\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Choose a specific topic within the domain\nLet's focus on the Laplace transform, a key concept within integral transforms and operational calculus. The Laplace transform is defined as $\\mathcal{L}\\{f(t)\\} = \\int_{0}^{\\infty} e^{-st}f(t)dt = F(s)$, where $f(t)$ is a function defined for $t \\geq 0$.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider applying the Laplace transform to solve a differential equation, as this involves understanding both the transform and its inverse. A suitable problem could involve solving an initial value problem (IVP) using the Laplace transform.\n\n## Step 4: Specify the problem\nLet's consider the following IVP: $y'' + 4y = \\sin(2t)$, with initial conditions $y(0) = 0$ and $y'(0) = 0$. The task is to solve for $y(t)$ using the Laplace transform.\n\n## Step 5: Write the problem statement\n\nUse the Laplace transform to solve the initial value problem $y'' + 4y = \\sin(2t)$, where $y(0) = 0$ and $y'(0) = 0$.\n\n## Step 6: Provide the solution\nTo solve the given IVP using the Laplace transform, we first apply the Laplace transform to both sides of the differential equation.\n\n## Step 7: Apply the Laplace transform to the differential equation\n$\\mathcal{L}\\{y'' + 4y\\} = \\mathcal{L}\\{\\sin(2t)\\}$. Using linearity, we get $\\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\}$.\n\n## Step 8: Evaluate the Laplace transforms\n$\\mathcal{L}\\{y''\\} = s^2Y(s) - sy(0) - y'(0)$ and $\\mathcal{L}\\{y\\} = Y(s)$, where $Y(s) = \\mathcal{L}\\{y(t)\\}$. Given $y(0) = 0$ and $y'(0) = 0$, $\\mathcal{L}\\{y''\\} = s^2Y(s)$. $\\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4}$.\n\n## Step 9: Substitute the known values and simplify\n$s^2Y(s) + 4Y(s) = \\frac{2}{s^2 + 4}$. Thus, $Y(s)(s^2 + 4) = \\frac{2}{s^2 + 4}$, which simplifies to $Y(s) = \\frac{2}{(s^2 + 4)^2}$.\n\n## Step 10: Find the inverse Laplace transform of $Y(s)$\nTo find $y(t)$, we need $\\mathcal{L}^{-1}\\{Y(s)\\} = \\mathcal{L}^{-1}\\left\\{\\frac{2}{(s^2 + 4)^2}\\right\\}$. Recall that $\\mathcal{L}\\{\\sin(at)\\} = \\frac{a}{s^2 + a^2}$, and use the property that $\\mathcal{L}^{-1}\\{F(s)\\} = f(t)$ implies $\\mathcal{L}^{-1}\\left\\{\\frac{d}{ds}F(s)\\right\\} = -tf(t)$, or more directly, utilize the convolution or known transforms.\n\n## Step 11: Evaluate the inverse Laplace transform\nUsing the formula for $\\mathcal{L}^{-1}\\left\\{\\frac{2a^3}{(s^2 + a^2)^2}\\right\\} = \\sin(at) - at\\cos(at)$ with $a = 2$, we adjust for our case: $\\mathcal{L}^{-1}\\left\\{\\frac{2}{(s^2 + 4)^2}\\right\\} = \\frac{1}{4}\\mathcal{L}^{-1}\\left\\{\\frac{2 \\cdot 2^3}{(s^2 + 2^2)^2}\\right\\} = \\frac{1}{4}(\\sin(2t) - 2t\\cos(2t))$.\n\n## Step 12: Write the complete solution",
    "run_id": "30",
    "outer_attempt": 1,
    "topic_slug": "integral_transforms_and_operational_calculus",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the initial value problem (IVP) given by\n$$y'' + 4y = \\sin(2t)$$\nwith initial conditions $y(0) = 0$ and $y'(0) = 0$, we will use the Laplace transform method.\n\n### Step 1: Apply the Laplace Transform\n\nLet $Y(s) = \\mathcal{L}\\{y(t)\\}$ be the Laplace transform of the unknown function $y(t)$. Applying the Laplace transform to both sides of the differential equation, we utilize the linearity property:\n$$ \\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\} $$\n\nRecall the derivative property for the Laplace transform:\n$$ \\mathcal{L}\\{y''\\} = s^2 Y(s) - s y(0) - y'(0) $$\n\nSubstitute the given initial conditions $y(0) = 0$ and $y'(0) = 0$:\n$$ \\mathcal{L}\\{y''\\} = s^2 Y(s) - s(0) - 0 = s^2 Y(s) $$\n\nNext, recall the standard transform for sine:\n$$ \\mathcal{L}\\{\\sin(at)\\} = \\frac{a}{s^2 + a^2} $$\nFor $\\sin(2t)$, where $a=2$:\n$$ \\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4} $$\n\nSubstituting these back into the transformed equation yields:\n$$ s^2 Y(s) + 4 Y(s) = \\frac{2}{s^2 + 4} $$\n\n### Step 2: Solve for $Y(s)$\n\nFactor out $Y(s)$ on the left side:\n$$ (s^2 + 4) Y(s) = \\frac{2}{s^2 + 4} $$\n\nDivide by $(s^2 + 4)$ to isolate $Y(s)$:\n$$ Y(s) = \\frac{2}{(s^2 + 4)^2} $$\n\n### Step 3: Compute the Inverse Laplace Transform\n\nWe now need to find $y(t) = \\mathcal{L}^{-1}\\{Y(s)\\}$. We are looking for the inverse transform of:\n$$ Y(s) = \\frac{2}{(s^2 + 4)^2} $$\n\nWe can derive this inverse using the property of the derivative of a transform, specifically regarding the term $t \\cos(at)$.\nRecall that if $F(s) = \\mathcal{L}\\{f(t)\\}$, then $F'(s) = \\mathcal{L}\\{-t f(t)\\}$.\n\nLet us consider the transform of $\\cos(2t)$:\n$$ \\mathcal{L}\\{\\cos(2t)\\} = \\frac{s}{s^2 + 4} $$\nDifferentiating with respect to $s$:\n$$ \\frac{d}{ds} \\left( \\frac{s}{s^2 + 4} \\right) = \\frac{1 \\cdot (s^2 + 4) - s \\cdot (2s)}{(s^2 + 4)^2} = \\frac{4 - s^2}{(s^2 + 4)^2} $$\nUsing the property $\\mathcal{L}\\{t f(t)\\} = -F'(s)$, we have:\n$$ \\mathcal{L}\\{t \\cos(2t)\\} = - \\frac{4 - s^2}{(s^2 + 4)^2} = \\frac{s^2 - 4}{(s^2 + 4)^2} $$\n\nThis does not immediately match our target $Y(s)$. However, we can also look at the transform of $\\sin(2t)$:\n$$ \\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4} = \\frac{2(s^2 + 4)}{(s^2 + 4)^2} = \\frac{2s^2 + 8}{(s^2 + 4)^2} $$\n\nWe seek a linear combination of these known transforms that equals $\\frac{2}{(s^2 + 4)^2}$. Let us check the expression $\\sin(2t) - 2t \\cos(2t)$.\n$$ \\mathcal{L}\\{\\sin(2t) - 2t \\cos(2t)\\} = \\mathcal{L}\\{\\sin(2t)\\} - 2\\mathcal{L}\\{t \\cos(2t)\\} $$\n$$ = \\frac{2s^2 + 8}{(s^2 + 4)^2} - 2 \\left( \\frac{s^2 - 4}{(s^2 + 4)^2} \\right) $$\n$$ = \\frac{2s^2 + 8 - 2s^2 + 8}{(s^2 + 4)^2} $$\n$$ = \\frac{16}{(s^2 + 4)^2} $$\n\nWe have obtained a numerator of 16. Our target numerator is 2. Therefore, we must divide by 8:\n$$ \\mathcal{L}^{-1} \\left\\{ \\frac{2}{(s^2 + 4)^2} \\right\\} = \\frac{1}{8} \\mathcal{L}^{-1} \\left\\{ \\frac{16}{(s^2 + 4)^2} \\right\\} $$\n$$ y(t) = \\frac{1}{8} \\left( \\sin(2t) - 2t \\cos(2t) \\right) $$\n\n### Step 4: Final Solution and Verification\n\nSimplifying the expression:\n$$ y(t) = \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) $$\n\n**Verification:**\nLet us verify this solution satisfies the original IVP.\n1.  **Initial Conditions:**\n    *   $y(0) = \\frac{1}{8}(0) - 0 = 0$. (Check)\n    *   $y'(t) = \\frac{1}{8}(2\\cos(2t)) - \\frac{1}{4}(\\cos(2t) - 2t\\sin(2t)) = \\frac{1}{4}\\cos(2t) - \\frac{1}{4}\\cos(2t) + \\frac{1}{2}t\\sin(2t) = \\frac{1}{2}t\\sin(2t)$.\n    *   $y'(0) = 0$. (Check)\n\n2.  **Differential Equation:**\n    *   Calculate $y''(t)$:\n        $y''(t) = \\frac{d}{dt} \\left( \\frac{1}{2}t\\sin(2t) \\right) = \\frac{1}{2}(\\sin(2t) + 2t\\cos(2t)) = \\frac{1}{2}\\sin(2t) + t\\cos(2t)$.\n    *   Substitute into $y'' + 4y$:\n        $$ \\left( \\frac{1}{2}\\sin(2t) + t\\cos(2t) \\right) + 4 \\left( \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) \\right) $$\n        $$ = \\frac{1}{2}\\sin(2t) + t\\cos(2t) + \\frac{1}{2}\\sin(2t) - t\\cos(2t) $$\n        $$ = \\sin(2t) $$\n    The solution satisfies the differential equation.\n\n**Conclusion:**\nThe solution to the initial value problem is:\n$$ y(t) = \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) $$",
        "raw_answer": "To solve the initial value problem (IVP) given by\n$$y'' + 4y = \\sin(2t)$$\nwith initial conditions $y(0) = 0$ and $y'(0) = 0$, we will use the Laplace transform method.\n\n### Step 1: Apply the Laplace Transform\n\nLet $Y(s) = \\mathcal{L}\\{y(t)\\}$ be the Laplace transform of the unknown function $y(t)$. Applying the Laplace transform to both sides of the differential equation, we utilize the linearity property:\n$$ \\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\} $$\n\nRecall the derivative property for the Laplace transform:\n$$ \\mathcal{L}\\{y''\\} = s^2 Y(s) - s y(0) - y'(0) $$\n\nSubstitute the given initial conditions $y(0) = 0$ and $y'(0) = 0$:\n$$ \\mathcal{L}\\{y''\\} = s^2 Y(s) - s(0) - 0 = s^2 Y(s) $$\n\nNext, recall the standard transform for sine:\n$$ \\mathcal{L}\\{\\sin(at)\\} = \\frac{a}{s^2 + a^2} $$\nFor $\\sin(2t)$, where $a=2$:\n$$ \\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4} $$\n\nSubstituting these back into the transformed equation yields:\n$$ s^2 Y(s) + 4 Y(s) = \\frac{2}{s^2 + 4} $$\n\n### Step 2: Solve for $Y(s)$\n\nFactor out $Y(s)$ on the left side:\n$$ (s^2 + 4) Y(s) = \\frac{2}{s^2 + 4} $$\n\nDivide by $(s^2 + 4)$ to isolate $Y(s)$:\n$$ Y(s) = \\frac{2}{(s^2 + 4)^2} $$\n\n### Step 3: Compute the Inverse Laplace Transform\n\nWe now need to find $y(t) = \\mathcal{L}^{-1}\\{Y(s)\\}$. We are looking for the inverse transform of:\n$$ Y(s) = \\frac{2}{(s^2 + 4)^2} $$\n\nWe can derive this inverse using the property of the derivative of a transform, specifically regarding the term $t \\cos(at)$.\nRecall that if $F(s) = \\mathcal{L}\\{f(t)\\}$, then $F'(s) = \\mathcal{L}\\{-t f(t)\\}$.\n\nLet us consider the transform of $\\cos(2t)$:\n$$ \\mathcal{L}\\{\\cos(2t)\\} = \\frac{s}{s^2 + 4} $$\nDifferentiating with respect to $s$:\n$$ \\frac{d}{ds} \\left( \\frac{s}{s^2 + 4} \\right) = \\frac{1 \\cdot (s^2 + 4) - s \\cdot (2s)}{(s^2 + 4)^2} = \\frac{4 - s^2}{(s^2 + 4)^2} $$\nUsing the property $\\mathcal{L}\\{t f(t)\\} = -F'(s)$, we have:\n$$ \\mathcal{L}\\{t \\cos(2t)\\} = - \\frac{4 - s^2}{(s^2 + 4)^2} = \\frac{s^2 - 4}{(s^2 + 4)^2} $$\n\nThis does not immediately match our target $Y(s)$. However, we can also look at the transform of $\\sin(2t)$:\n$$ \\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4} = \\frac{2(s^2 + 4)}{(s^2 + 4)^2} = \\frac{2s^2 + 8}{(s^2 + 4)^2} $$\n\nWe seek a linear combination of these known transforms that equals $\\frac{2}{(s^2 + 4)^2}$. Let us check the expression $\\sin(2t) - 2t \\cos(2t)$.\n$$ \\mathcal{L}\\{\\sin(2t) - 2t \\cos(2t)\\} = \\mathcal{L}\\{\\sin(2t)\\} - 2\\mathcal{L}\\{t \\cos(2t)\\} $$\n$$ = \\frac{2s^2 + 8}{(s^2 + 4)^2} - 2 \\left( \\frac{s^2 - 4}{(s^2 + 4)^2} \\right) $$\n$$ = \\frac{2s^2 + 8 - 2s^2 + 8}{(s^2 + 4)^2} $$\n$$ = \\frac{16}{(s^2 + 4)^2} $$\n\nWe have obtained a numerator of 16. Our target numerator is 2. Therefore, we must divide by 8:\n$$ \\mathcal{L}^{-1} \\left\\{ \\frac{2}{(s^2 + 4)^2} \\right\\} = \\frac{1}{8} \\mathcal{L}^{-1} \\left\\{ \\frac{16}{(s^2 + 4)^2} \\right\\} $$\n$$ y(t) = \\frac{1}{8} \\left( \\sin(2t) - 2t \\cos(2t) \\right) $$\n\n### Step 4: Final Solution and Verification\n\nSimplifying the expression:\n$$ y(t) = \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) $$\n\n**Verification:**\nLet us verify this solution satisfies the original IVP.\n1.  **Initial Conditions:**\n    *   $y(0) = \\frac{1}{8}(0) - 0 = 0$. (Check)\n    *   $y'(t) = \\frac{1}{8}(2\\cos(2t)) - \\frac{1}{4}(\\cos(2t) - 2t\\sin(2t)) = \\frac{1}{4}\\cos(2t) - \\frac{1}{4}\\cos(2t) + \\frac{1}{2}t\\sin(2t) = \\frac{1}{2}t\\sin(2t)$.\n    *   $y'(0) = 0$. (Check)\n\n2.  **Differential Equation:**\n    *   Calculate $y''(t)$:\n        $y''(t) = \\frac{d}{dt} \\left( \\frac{1}{2}t\\sin(2t) \\right) = \\frac{1}{2}(\\sin(2t) + 2t\\cos(2t)) = \\frac{1}{2}\\sin(2t) + t\\cos(2t)$.\n    *   Substitute into $y'' + 4y$:\n        $$ \\left( \\frac{1}{2}\\sin(2t) + t\\cos(2t) \\right) + 4 \\left( \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) \\right) $$\n        $$ = \\frac{1}{2}\\sin(2t) + t\\cos(2t) + \\frac{1}{2}\\sin(2t) - t\\cos(2t) $$\n        $$ = \\sin(2t) $$\n    The solution satisfies the differential equation.\n\n**Conclusion:**\nThe solution to the initial value problem is:\n$$ y(t) = \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of integral equations, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the specific domain within integral equations\nIntegral equations involve equations where the unknown function appears under an integral sign. A common type is the Fredholm integral equation of the second kind, given by $f(x) = g(x) + \\lambda \\int_{a}^{b} K(x, t)f(t)dt$, where $f(x)$ is the unknown function, $g(x)$ and $K(x, t)$ are known functions, and $\\lambda$ is a parameter.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider a specific case of the Fredholm integral equation of the second kind with a given kernel $K(x, t)$ and a function $g(x)$, and ask to solve for $f(x)$.\n\n## Step 4: Specify the problem\nLet's consider the integral equation $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$. This is a Fredholm integral equation of the second kind. We need to find $f(x)$.\n\n## Step 5: Provide the solution\nTo solve $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$, let's first simplify the integral.\n$f(x) = x + x\\int_{0}^{1} tf(t)dt + x\\int_{0}^{1} f(t)dt + \\int_{0}^{1} tf(t)dt$.\nLet $A = \\int_{0}^{1} f(t)dt$ and $B = \\int_{0}^{1} tf(t)dt$. Then, $f(x) = x + xB + xA + B = x(1 + A + B) + B$.\n\n## Step 6: Calculate A and B using the definitions\nSubstitute $f(x)$ from Step 5 into the definitions of $A$ and $B$.\n$A = \\int_{0}^{1} [t(1 + A + B) + B]dt = \\left[\\frac{t^2}{2}(1 + A + B) + Bt\\right]_{0}^{1} = \\frac{1}{2}(1 + A + B) + B$.\n$B = \\int_{0}^{1} t[t(1 + A + B) + B]dt = \\left[\\frac{t^3}{3}(1 + A + B) + \\frac{Bt^2}{2}\\right]_{0}^{1} = \\frac{1}{3}(1 + A + B) + \\frac{B}{2}$.\n\n## Step 7: Solve for A and B\nFrom Step 6, we have:\n1. $A = \\frac{1}{2}(1 + A + B) + B$\n2. $B = \\frac{1}{3}(1 + A + B) + \\frac{B}{2}$.\n\nSimplifying these equations:\n1. $A = \\frac{1}{2} + \\frac{A}{2} + \\frac{B}{2} + B$ implies $\\frac{A}{2} = \\frac{1}{2} + \\frac{3B}{2}$, so $A = 1 + 3B$.\n2. $B = \\frac{1}{3} + \\frac{A}{3} + \\frac{B}{3} + \\frac{B}{2}$ implies $B - \\frac{B}{2} - \\frac{B}{3} = \\frac{1}{3} + \\frac{A}{3}$, so $\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3}$.\n\n## Step 8: Continue solving for A and B\nFrom equation 2 in Step 7: $\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3}$, we get $B = 2 + 2A$.\nSubstitute $A = 1 + 3B$ from Step 7 into $B = 2 + 2A$:\n$B = 2 + 2(1 + 3B)$, so $B = 2 + 2 + 6B$, which simplifies to $B = 4 + 6B$, hence $-5B = 4$, and $B = -\\frac{4}{5}$.\n\n## Step 9: Find A using B\nSubstitute $B = -\\frac{4}{5}$ into $A = 1 + 3B$:\n$A = 1 + 3(-\\frac{4}{5}) = 1 - \\frac{12}{5} = -\\frac{7}{5}$.\n\n## Step 10: Substitute A and B back into f(x)\n$f(x) = x(1 + A + B) + B = x(1 - \\frac{7}{5} - \\frac{4}{5}) - \\frac{4}{5}$.\n$f(x) = x(1 - \\frac{11}{5}) - \\frac{4}{5} = x(-\\frac{6}{5}) - \\frac{4}{5}$.\n$f(x) = -\\frac{6}{5}x - \\frac{4}{5}$.\n\nThe final answer is: \n\nSolve the integral equation $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$ for $f(x)$.",
    "run_id": "31",
    "outer_attempt": 1,
    "topic_slug": "integral_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the integral equation for $f(x)$, we will identify it as a Fredholm integral equation of the second kind with a separable (degenerate) kernel. The equation is given by:\n\n$$ f(x) = x + \\int_{0}^{1} (xt + x + t)f(t) \\, dt $$\n\n### Step 1: Separate the Kernel\n\nFirst, we expand the kernel $K(x,t) = xt + x + t$ and rewrite the integral to separate the terms involving $x$ from the terms involving only $t$.\n\n$$ f(x) = x + \\int_{0}^{1} x(t + 1)f(t) \\, dt + \\int_{0}^{1} tf(t) \\, dt $$\n\nBecause the integration is with respect to $t$, we can factor out terms depending on $x$:\n\n$$ f(x) = x + x \\int_{0}^{1} (t + 1)f(t) \\, dt + \\int_{0}^{1} tf(t) \\, dt $$\n\nWe can further split the first integral:\n\n$$ f(x) = x + x \\left( \\int_{0}^{1} tf(t) \\, dt + \\int_{0}^{1} f(t) \\, dt \\right) + \\int_{0}^{1} tf(t) \\, dt $$\n\n### Step 2: Define Constants\n\nThe integrals in the expression above are definite integrals with limits $0$ to $1$, so they evaluate to constant values. Let us define two constants, $A$ and $B$:\n\n1.  $$ A = \\int_{0}^{1} f(t) \\, dt $$\n2.  $$ B = \\int_{0}^{1} tf(t) \\, dt $$\n\nSubstituting these constants back into the equation for $f(x)$:\n\n$$ f(x) = x + x(B + A) + B $$\n\nGrouping the terms with $x$:\n\n$$ f(x) = x(1 + A + B) + B $$\n\nThis tells us that the solution $f(x)$ is a linear function of the form $f(x) = Kx + B$, where $K = 1 + A + B$.\n\n### Step 3: Set Up a System of Equations\n\nNow we substitute the specific form $f(t) = (1 + A + B)t + B$ into the definitions of $A$ and $B$ to create a system of linear equations.\n\n**For A:**\n$$ A = \\int_{0}^{1} f(t) \\, dt = \\int_{0}^{1} \\left[ (1 + A + B)t + B \\right] \\, dt $$\n$$ A = (1 + A + B) \\int_{0}^{1} t \\, dt + B \\int_{0}^{1} 1 \\, dt $$\n$$ A = (1 + A + B) \\left[ \\frac{t^2}{2} \\right]_{0}^{1} + B \\left[ t \\right]_{0}^{1} $$\n$$ A = \\frac{1}{2}(1 + A + B) + B $$\n\nMultiply by 2 to clear the fraction:\n$$ 2A = 1 + A + B + 2B $$\n$$ 2A = 1 + A + 3B $$\n$$ A - 3B = 1 \\quad \\dots \\text{(Equation 1)} $$\n\n**For B:**\n$$ B = \\int_{0}^{1} tf(t) \\, dt = \\int_{0}^{1} t \\left[ (1 + A + B)t + B \\right] \\, dt $$\n$$ B = \\int_{0}^{1} \\left[ (1 + A + B)t^2 + Bt \\right] \\, dt $$\n$$ B = (1 + A + B) \\left[ \\frac{t^3}{3} \\right]_{0}^{1} + B \\left[ \\frac{t^2}{2} \\right]_{0}^{1} $$\n$$ B = \\frac{1}{3}(1 + A + B) + \\frac{1}{2}B $$\n\nMultiply by 6 to clear the fractions:\n$$ 6B = 2(1 + A + B) + 3B $$\n$$ 6B = 2 + 2A + 2B + 3B $$\n$$ 6B = 2 + 2A + 5B $$\n$$ B - 2A = 2 \\quad \\dots \\text{(Equation 2)} $$\n\n### Step 4: Solve the System\n\nWe have the linear system:\n1.  $A - 3B = 1$\n2.  $-2A + B = 2$\n\nFrom (1), we have $A = 1 + 3B$. Substitute this into (2):\n$$ -2(1 + 3B) + B = 2 $$\n$$ -2 - 6B + B = 2 $$\n$$ -5B = 4 $$\n$$ B = -\\frac{4}{5} $$\n\nNow find $A$:\n$$ A = 1 + 3\\left(-\\frac{4}{5}\\right) $$\n$$ A = 1 - \\frac{12}{5} $$\n$$ A = -\\frac{7}{5} $$\n\n### Step 5: Construct the Final Function\n\nRecall the form of $f(x)$:\n$$ f(x) = x(1 + A + B) + B $$\n\nSubstitute the values of $A$ and $B$:\n$$ 1 + A + B = 1 + \\left(-\\frac{7}{5}\\right) + \\left(-\\frac{4}{5}\\right) $$\n$$ 1 + A + B = 1 - \\frac{11}{5} = -\\frac{6}{5} $$\n\nThus:\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$\n\n### Verification\n\nWe verify the solution by substituting $f(x) = -\\frac{6}{5}x - \\frac{4}{5}$ into the original integral equation.\n\n**RHS:**\n$$ x + \\int_{0}^{1} (xt + x + t)\\left(-\\frac{6}{5}t - \\frac{4}{5}\\right) \\, dt $$\n$$ = x - \\frac{1}{5} \\int_{0}^{1} (x(t+1) + t)(6t + 4) \\, dt $$\n$$ = x - \\frac{1}{5} \\left[ \\int_{0}^{1} x(t+1)(6t+4) \\, dt + \\int_{0}^{1} t(6t+4) \\, dt \\right] $$\n\nCalculate the first integral part:\n$$ \\int_{0}^{1} (6t^2 + 10t + 4) \\, dt = \\left[ 2t^3 + 5t^2 + 4t \\right]_{0}^{1} = 2 + 5 + 4 = 11 $$\n\nCalculate the second integral part:\n$$ \\int_{0}^{1} (6t^2 + 4t) \\, dt = \\left[ 2t^3 + 2t^2 \\right]_{0}^{1} = 2 + 2 = 4 $$\n\nSubstitute back into the RHS expression:\n$$ \\text{RHS} = x - \\frac{1}{5} [ x(11) + 4 ] = x - \\frac{11}{5}x - \\frac{4}{5} = -\\frac{6}{5}x - \\frac{4}{5} $$\n\n**LHS:**\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$\n\nSince LHS = RHS, the solution is correct.\n\n### Final Answer\n\nThe solution to the integral equation is:\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$",
        "raw_answer": "To solve the integral equation for $f(x)$, we will identify it as a Fredholm integral equation of the second kind with a separable (degenerate) kernel. The equation is given by:\n\n$$ f(x) = x + \\int_{0}^{1} (xt + x + t)f(t) \\, dt $$\n\n### Step 1: Separate the Kernel\n\nFirst, we expand the kernel $K(x,t) = xt + x + t$ and rewrite the integral to separate the terms involving $x$ from the terms involving only $t$.\n\n$$ f(x) = x + \\int_{0}^{1} x(t + 1)f(t) \\, dt + \\int_{0}^{1} tf(t) \\, dt $$\n\nBecause the integration is with respect to $t$, we can factor out terms depending on $x$:\n\n$$ f(x) = x + x \\int_{0}^{1} (t + 1)f(t) \\, dt + \\int_{0}^{1} tf(t) \\, dt $$\n\nWe can further split the first integral:\n\n$$ f(x) = x + x \\left( \\int_{0}^{1} tf(t) \\, dt + \\int_{0}^{1} f(t) \\, dt \\right) + \\int_{0}^{1} tf(t) \\, dt $$\n\n### Step 2: Define Constants\n\nThe integrals in the expression above are definite integrals with limits $0$ to $1$, so they evaluate to constant values. Let us define two constants, $A$ and $B$:\n\n1.  $$ A = \\int_{0}^{1} f(t) \\, dt $$\n2.  $$ B = \\int_{0}^{1} tf(t) \\, dt $$\n\nSubstituting these constants back into the equation for $f(x)$:\n\n$$ f(x) = x + x(B + A) + B $$\n\nGrouping the terms with $x$:\n\n$$ f(x) = x(1 + A + B) + B $$\n\nThis tells us that the solution $f(x)$ is a linear function of the form $f(x) = Kx + B$, where $K = 1 + A + B$.\n\n### Step 3: Set Up a System of Equations\n\nNow we substitute the specific form $f(t) = (1 + A + B)t + B$ into the definitions of $A$ and $B$ to create a system of linear equations.\n\n**For A:**\n$$ A = \\int_{0}^{1} f(t) \\, dt = \\int_{0}^{1} \\left[ (1 + A + B)t + B \\right] \\, dt $$\n$$ A = (1 + A + B) \\int_{0}^{1} t \\, dt + B \\int_{0}^{1} 1 \\, dt $$\n$$ A = (1 + A + B) \\left[ \\frac{t^2}{2} \\right]_{0}^{1} + B \\left[ t \\right]_{0}^{1} $$\n$$ A = \\frac{1}{2}(1 + A + B) + B $$\n\nMultiply by 2 to clear the fraction:\n$$ 2A = 1 + A + B + 2B $$\n$$ 2A = 1 + A + 3B $$\n$$ A - 3B = 1 \\quad \\dots \\text{(Equation 1)} $$\n\n**For B:**\n$$ B = \\int_{0}^{1} tf(t) \\, dt = \\int_{0}^{1} t \\left[ (1 + A + B)t + B \\right] \\, dt $$\n$$ B = \\int_{0}^{1} \\left[ (1 + A + B)t^2 + Bt \\right] \\, dt $$\n$$ B = (1 + A + B) \\left[ \\frac{t^3}{3} \\right]_{0}^{1} + B \\left[ \\frac{t^2}{2} \\right]_{0}^{1} $$\n$$ B = \\frac{1}{3}(1 + A + B) + \\frac{1}{2}B $$\n\nMultiply by 6 to clear the fractions:\n$$ 6B = 2(1 + A + B) + 3B $$\n$$ 6B = 2 + 2A + 2B + 3B $$\n$$ 6B = 2 + 2A + 5B $$\n$$ B - 2A = 2 \\quad \\dots \\text{(Equation 2)} $$\n\n### Step 4: Solve the System\n\nWe have the linear system:\n1.  $A - 3B = 1$\n2.  $-2A + B = 2$\n\nFrom (1), we have $A = 1 + 3B$. Substitute this into (2):\n$$ -2(1 + 3B) + B = 2 $$\n$$ -2 - 6B + B = 2 $$\n$$ -5B = 4 $$\n$$ B = -\\frac{4}{5} $$\n\nNow find $A$:\n$$ A = 1 + 3\\left(-\\frac{4}{5}\\right) $$\n$$ A = 1 - \\frac{12}{5} $$\n$$ A = -\\frac{7}{5} $$\n\n### Step 5: Construct the Final Function\n\nRecall the form of $f(x)$:\n$$ f(x) = x(1 + A + B) + B $$\n\nSubstitute the values of $A$ and $B$:\n$$ 1 + A + B = 1 + \\left(-\\frac{7}{5}\\right) + \\left(-\\frac{4}{5}\\right) $$\n$$ 1 + A + B = 1 - \\frac{11}{5} = -\\frac{6}{5} $$\n\nThus:\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$\n\n### Verification\n\nWe verify the solution by substituting $f(x) = -\\frac{6}{5}x - \\frac{4}{5}$ into the original integral equation.\n\n**RHS:**\n$$ x + \\int_{0}^{1} (xt + x + t)\\left(-\\frac{6}{5}t - \\frac{4}{5}\\right) \\, dt $$\n$$ = x - \\frac{1}{5} \\int_{0}^{1} (x(t+1) + t)(6t + 4) \\, dt $$\n$$ = x - \\frac{1}{5} \\left[ \\int_{0}^{1} x(t+1)(6t+4) \\, dt + \\int_{0}^{1} t(6t+4) \\, dt \\right] $$\n\nCalculate the first integral part:\n$$ \\int_{0}^{1} (6t^2 + 10t + 4) \\, dt = \\left[ 2t^3 + 5t^2 + 4t \\right]_{0}^{1} = 2 + 5 + 4 = 11 $$\n\nCalculate the second integral part:\n$$ \\int_{0}^{1} (6t^2 + 4t) \\, dt = \\left[ 2t^3 + 2t^2 \\right]_{0}^{1} = 2 + 2 = 4 $$\n\nSubstitute back into the RHS expression:\n$$ \\text{RHS} = x - \\frac{1}{5} [ x(11) + 4 ] = x - \\frac{11}{5}x - \\frac{4}{5} = -\\frac{6}{5}x - \\frac{4}{5} $$\n\n**LHS:**\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$\n\nSince LHS = RHS, the solution is correct.\n\n### Final Answer\n\nThe solution to the integral equation is:\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $H$ be a Hilbert space and $T: H \\to H$ be a bounded linear operator. Suppose that $T$ is self-adjoint and satisfies the condition $\\|T\\| \\leq 1$. Prove that the operator $I - T^2$ is positive, where $I$ denotes the identity operator on $H$.",
    "run_id": "32",
    "outer_attempt": 1,
    "topic_slug": "functional_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the operator $I - T^2$ is positive, we must demonstrate two properties:\n1.  The operator $I - T^2$ is self-adjoint.\n2.  For every vector $x$ in the Hilbert space $H$, the inner product $\\langle (I - T^2)x, x \\rangle$ is non-negative (i.e., $\\ge 0$).\n\n### 1. Self-Adjointness of $I - T^2$\n\nLet $A^*$ denote the adjoint of a bounded linear operator $A$. By the properties of the adjoint operation:\n- $(A + B)^* = A^* + B^*$\n- $(AB)^* = B^* A^*$\n- $I^* = I$ (where $I$ is the identity operator)\n\nWe are given that $T$ is self-adjoint, meaning $T^* = T$. \n\nNow, we compute the adjoint of $I - T^2$:\n$$\n(I - T^2)^* = I^* - (T^2)^* = I - (T \\cdot T)^*\n$$\nUsing the product rule for adjoints:\n$$\n(T \\cdot T)^* = T^* \\cdot T^*\n$$\nSubstituting $T^* = T$:\n$$\nT^* \\cdot T^* = T \\cdot T = T^2\n$$\nThus:\n$$\n(I - T^2)^* = I - T^2\n$$\nSince $(I - T^2)^* = I - T^2$, the operator is self-adjoint.\n\n### 2. Positivity Condition\n\nWe must show that $\\langle (I - T^2)x, x \\rangle \\ge 0$ for all $x \\in H$.\n\nLet $x \\in H$ be an arbitrary vector. By the linearity of the inner product, we can expand the expression:\n$$\n\\langle (I - T^2)x, x \\rangle = \\langle Ix - T^2x, x \\rangle = \\langle x, x \\rangle - \\langle T^2x, x \\rangle\n$$\nUsing the property that $\\langle x, x \\rangle = \\|x\\|^2$, we have:\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\langle T^2x, x \\rangle\n$$\nNext, we analyze the term $\\langle T^2x, x \\rangle$. Since $T^2x = T(Tx)$, we write:\n$$\n\\langle T^2x, x \\rangle = \\langle T(Tx), x \\rangle\n$$\nBy the definition of the adjoint operator, $\\langle Ty, z \\rangle = \\langle y, T^*z \\rangle$ for any $y, z \\in H$. Letting $y = Tx$ and $z = x$, we get:\n$$\n\\langle T(Tx), x \\rangle = \\langle Tx, T^*x \\rangle\n$$\nSince $T$ is self-adjoint ($T^* = T$), this becomes:\n$$\n\\langle Tx, Tx \\rangle = \\|Tx\\|^2\n$$\nSubstituting this result back into our expansion:\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2\n$$\n\n### 3. Applying the Norm Bound\n\nWe are given the condition $\\|T\\| \\le 1$. By the definition of the operator norm, for any vector $x \\in H$:\n$$\n\\|Tx\\| \\le \\|T\\| \\|x\\|\n$$\nSince $\\|T\\| \\le 1$, it follows that:\n$$\n\\|Tx\\| \\le 1 \\cdot \\|x\\| = \\|x\\|\n$$\nBecause norms are non-negative, we can square both sides of the inequality $\\|Tx\\| \\le \\|x\\|$ to obtain:\n$$\n\\|Tx\\|^2 \\le \\|x\\|^2\n$$\nRearranging this inequality yields:\n$$\n\\|x\\|^2 - \\|Tx\\|^2 \\ge 0\n$$\n\n### Conclusion\n\nCombining the results from the steps above, for any $x \\in H$:\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2 \\ge 0\n$$\nSince $I - T^2$ is a self-adjoint operator satisfying $\\langle (I - T^2)x, x \\rangle \\ge 0$ for all $x \\in H$, **the operator $I - T^2$ is positive**.",
        "raw_answer": "To prove that the operator $I - T^2$ is positive, we must demonstrate two properties:\n1.  The operator $I - T^2$ is self-adjoint.\n2.  For every vector $x$ in the Hilbert space $H$, the inner product $\\langle (I - T^2)x, x \\rangle$ is non-negative (i.e., $\\ge 0$).\n\n### 1. Self-Adjointness of $I - T^2$\n\nLet $A^*$ denote the adjoint of a bounded linear operator $A$. By the properties of the adjoint operation:\n- $(A + B)^* = A^* + B^*$\n- $(AB)^* = B^* A^*$\n- $I^* = I$ (where $I$ is the identity operator)\n\nWe are given that $T$ is self-adjoint, meaning $T^* = T$. \n\nNow, we compute the adjoint of $I - T^2$:\n$$\n(I - T^2)^* = I^* - (T^2)^* = I - (T \\cdot T)^*\n$$\nUsing the product rule for adjoints:\n$$\n(T \\cdot T)^* = T^* \\cdot T^*\n$$\nSubstituting $T^* = T$:\n$$\nT^* \\cdot T^* = T \\cdot T = T^2\n$$\nThus:\n$$\n(I - T^2)^* = I - T^2\n$$\nSince $(I - T^2)^* = I - T^2$, the operator is self-adjoint.\n\n### 2. Positivity Condition\n\nWe must show that $\\langle (I - T^2)x, x \\rangle \\ge 0$ for all $x \\in H$.\n\nLet $x \\in H$ be an arbitrary vector. By the linearity of the inner product, we can expand the expression:\n$$\n\\langle (I - T^2)x, x \\rangle = \\langle Ix - T^2x, x \\rangle = \\langle x, x \\rangle - \\langle T^2x, x \\rangle\n$$\nUsing the property that $\\langle x, x \\rangle = \\|x\\|^2$, we have:\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\langle T^2x, x \\rangle\n$$\nNext, we analyze the term $\\langle T^2x, x \\rangle$. Since $T^2x = T(Tx)$, we write:\n$$\n\\langle T^2x, x \\rangle = \\langle T(Tx), x \\rangle\n$$\nBy the definition of the adjoint operator, $\\langle Ty, z \\rangle = \\langle y, T^*z \\rangle$ for any $y, z \\in H$. Letting $y = Tx$ and $z = x$, we get:\n$$\n\\langle T(Tx), x \\rangle = \\langle Tx, T^*x \\rangle\n$$\nSince $T$ is self-adjoint ($T^* = T$), this becomes:\n$$\n\\langle Tx, Tx \\rangle = \\|Tx\\|^2\n$$\nSubstituting this result back into our expansion:\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2\n$$\n\n### 3. Applying the Norm Bound\n\nWe are given the condition $\\|T\\| \\le 1$. By the definition of the operator norm, for any vector $x \\in H$:\n$$\n\\|Tx\\| \\le \\|T\\| \\|x\\|\n$$\nSince $\\|T\\| \\le 1$, it follows that:\n$$\n\\|Tx\\| \\le 1 \\cdot \\|x\\| = \\|x\\|\n$$\nBecause norms are non-negative, we can square both sides of the inequality $\\|Tx\\| \\le \\|x\\|$ to obtain:\n$$\n\\|Tx\\|^2 \\le \\|x\\|^2\n$$\nRearranging this inequality yields:\n$$\n\\|x\\|^2 - \\|Tx\\|^2 \\ge 0\n$$\n\n### Conclusion\n\nCombining the results from the steps above, for any $x \\in H$:\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2 \\ge 0\n$$\nSince $I - T^2$ is a self-adjoint operator satisfying $\\langle (I - T^2)x, x \\rangle \\ge 0$ for all $x \\in H$, **the operator $I - T^2$ is positive**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $T: L^2[0,1] \\to L^2[0,1]$ be defined by $Tf(x) = \\int_{0}^{x} f(t) dt$. Prove that $T$ is compact and find its spectrum.",
    "run_id": "33",
    "outer_attempt": 1,
    "topic_slug": "operator_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the problem regarding the Volterra operator $T: L^2[0,1] \\to L^2[0,1]$ defined by \n$$ (Tf)(x) = \\int_{0}^{x} f(t) \\, dt, $$\nwe proceed in two parts: first proving that $T$ is a compact operator, and then determining its spectrum $\\sigma(T)$. We treat $L^2[0,1]$ as a complex Hilbert space.\n\n---\n\n### Part 1: Proof of Compactness\n\nWe prove that $T$ is compact by showing it is a Hilbert-Schmidt operator.\n\n**Step 1: Express $T$ as an Integral Operator**\nThe operator $T$ can be written in the form of a Fredholm integral operator:\n$$ (Tf)(x) = \\int_{0}^{1} K(x,t) f(t) \\, dt, $$\nwhere the kernel $K(x,t)$ is defined by the characteristic function of the region $0 \\le t \\le x \\le 1$:\n$$ K(x,t) = \\begin{cases} \n1 & \\text{if } 0 \\le t \\le x, \\\\\n0 & \\text{if } x < t \\le 1.\n\\end{cases} $$\n\n**Step 2: Verify the Hilbert-Schmidt Condition**\nA linear integral operator on $L^2[0,1]$ is a Hilbert-Schmidt operator if its kernel $K$ belongs to $L^2([0,1] \\times [0,1])$. We compute the $L^2$ norm of the kernel:\n$$ \\|K\\|_{L^2}^2 = \\int_{0}^{1} \\int_{0}^{1} |K(x,t)|^2 \\, dt \\, dx. $$\nSubstituting the definition of $K(x,t)$:\n$$ \\|K\\|_{L^2}^2 = \\int_{0}^{1} \\left( \\int_{0}^{x} 1^2 \\, dt \\right) dx = \\int_{0}^{1} [t]_{0}^{x} \\, dx = \\int_{0}^{1} x \\, dx. $$\nEvaluating the final integral:\n$$ \\int_{0}^{1} x \\, dx = \\left[ \\frac{1}{2}x^2 \\right]_{0}^{1} = \\frac{1}{2}. $$\nSince $\\|K\\|_{L^2}^2 = \\frac{1}{2} < \\infty$, the kernel $K$ is square-integrable.\n\n**Conclusion for Part 1**\nEvery Hilbert-Schmidt operator on a separable Hilbert space is a compact operator. Therefore, $T$ is compact.\n\n---\n\n### Part 2: Determination of the Spectrum\n\nLet $\\sigma(T)$ denote the spectrum of $T$. Since $T$ is a compact operator on an infinite-dimensional Banach space, the Riesz-Schauder theorem applies. This theorem states:\n1. $0 \\in \\sigma(T)$.\n2. The non-zero elements of the spectrum, $\\sigma(T) \\setminus \\{0\\}$, consist entirely of eigenvalues (the point spectrum $\\sigma_p(T)$).\n\nThus, to find $\\sigma(T)$, we must determine if $0$ is an eigenvalue and find all non-zero eigenvalues.\n\n**Step 1: Check if $\\lambda = 0$ is an eigenvalue**\nWe check for non-trivial solutions to $Tf = 0$:\n$$ \\int_{0}^{x} f(t) \\, dt = 0 \\quad \\text{for almost every } x \\in [0,1]. $$\nSince $f \\in L^2[0,1] \\subset L^1[0,1]$, the integral $F(x) = \\int_0^x f(t) dt$ is absolutely continuous. Differentiating both sides with respect to $x$ (using the Lebesgue differentiation theorem) gives:\n$$ f(x) = 0 \\quad \\text{almost everywhere}. $$\nThus, the kernel of $T$ is trivial ($\\text{Ker}(T) = \\{0\\}$), so $\\lambda = 0$ is **not** an eigenvalue.\nHowever, as noted above, $0 \\in \\sigma(T)$ because $T$ is a compact operator on an infinite-dimensional space (implying $T$ cannot be boundedly invertible).\n\n**Step 2: Check for eigenvalues $\\lambda \\neq 0$**\nSuppose there exists $\\lambda \\in \\mathbb{C} \\setminus \\{0\\}$ and a non-zero function $f \\in L^2[0,1]$ such that $Tf = \\lambda f$.\n$$ \\int_{0}^{x} f(t) \\, dt = \\lambda f(x). \\quad (*)$$\n\n*Regularity Argument:*\nSince $f \\in L^2[0,1]$, the left-hand side of $(*)$ is an absolutely continuous function of $x$. Therefore, $\\lambda f(x)$ is continuous. Since $\\lambda \\neq 0$, $f(x)$ must be continuous.\nSince $f$ is continuous, the integrand in the left-hand side is continuous, making the integral continuously differentiable ($C^1$). Therefore, $f$ must be a $C^1$ function.\n\n*Differential Equation:*\nWe can now differentiate $(*)$ with respect to $x$:\n$$ \\frac{d}{dx} \\int_{0}^{x} f(t) \\, dt = \\frac{d}{dx} (\\lambda f(x)) $$\n$$ f(x) = \\lambda f'(x). $$\nThis can be rewritten as a first-order linear ordinary differential equation:\n$$ f'(x) - \\frac{1}{\\lambda} f(x) = 0. $$\nThe general solution is:\n$$ f(x) = C e^{x/\\lambda}, $$\nwhere $C$ is an arbitrary constant.\n\n*Boundary Condition:*\nWe must ensure the solution satisfies the original integral equation $(*)$ at a specific point, typically $x=0$, to determine $C$.\nEvaluating $(*)$ at $x=0$:\n$$ \\text{LHS} = \\int_{0}^{0} f(t) \\, dt = 0, $$\n$$ \\text{RHS} = \\lambda f(0). $$\nSince $\\lambda \\neq 0$, we must have $f(0) = 0$.\n\nSubstituting the general solution into this boundary condition:\n$$ f(0) = C e^{0/\\lambda} = C \\cdot 1 = C. $$\nThus, $C = 0$.\n\nThis implies $f(x) = 0$ for all $x \\in [0,1]$. Since an eigenvector must be non-zero, there are no eigenvalues $\\lambda \\neq 0$.\n\n**Conclusion for Part 2**\nThe point spectrum of $T$ is empty ($\\sigma_p(T) = \\emptyset$). Since $T$ is compact and the space is infinite-dimensional, the spectrum contains $0$ but no other values.\n\n### Final Answer\n\n1. The operator $T$ is **compact** because it is a Hilbert-Schmidt operator with kernel norm $\\|K\\|_{L^2} = 1/\\sqrt{2}$.\n2. The spectrum of $T$ is **$\\sigma(T) = \\{0\\}$**.",
        "raw_answer": "To solve the problem regarding the Volterra operator $T: L^2[0,1] \\to L^2[0,1]$ defined by \n$$ (Tf)(x) = \\int_{0}^{x} f(t) \\, dt, $$\nwe proceed in two parts: first proving that $T$ is a compact operator, and then determining its spectrum $\\sigma(T)$. We treat $L^2[0,1]$ as a complex Hilbert space.\n\n---\n\n### Part 1: Proof of Compactness\n\nWe prove that $T$ is compact by showing it is a Hilbert-Schmidt operator.\n\n**Step 1: Express $T$ as an Integral Operator**\nThe operator $T$ can be written in the form of a Fredholm integral operator:\n$$ (Tf)(x) = \\int_{0}^{1} K(x,t) f(t) \\, dt, $$\nwhere the kernel $K(x,t)$ is defined by the characteristic function of the region $0 \\le t \\le x \\le 1$:\n$$ K(x,t) = \\begin{cases} \n1 & \\text{if } 0 \\le t \\le x, \\\\\n0 & \\text{if } x < t \\le 1.\n\\end{cases} $$\n\n**Step 2: Verify the Hilbert-Schmidt Condition**\nA linear integral operator on $L^2[0,1]$ is a Hilbert-Schmidt operator if its kernel $K$ belongs to $L^2([0,1] \\times [0,1])$. We compute the $L^2$ norm of the kernel:\n$$ \\|K\\|_{L^2}^2 = \\int_{0}^{1} \\int_{0}^{1} |K(x,t)|^2 \\, dt \\, dx. $$\nSubstituting the definition of $K(x,t)$:\n$$ \\|K\\|_{L^2}^2 = \\int_{0}^{1} \\left( \\int_{0}^{x} 1^2 \\, dt \\right) dx = \\int_{0}^{1} [t]_{0}^{x} \\, dx = \\int_{0}^{1} x \\, dx. $$\nEvaluating the final integral:\n$$ \\int_{0}^{1} x \\, dx = \\left[ \\frac{1}{2}x^2 \\right]_{0}^{1} = \\frac{1}{2}. $$\nSince $\\|K\\|_{L^2}^2 = \\frac{1}{2} < \\infty$, the kernel $K$ is square-integrable.\n\n**Conclusion for Part 1**\nEvery Hilbert-Schmidt operator on a separable Hilbert space is a compact operator. Therefore, $T$ is compact.\n\n---\n\n### Part 2: Determination of the Spectrum\n\nLet $\\sigma(T)$ denote the spectrum of $T$. Since $T$ is a compact operator on an infinite-dimensional Banach space, the Riesz-Schauder theorem applies. This theorem states:\n1. $0 \\in \\sigma(T)$.\n2. The non-zero elements of the spectrum, $\\sigma(T) \\setminus \\{0\\}$, consist entirely of eigenvalues (the point spectrum $\\sigma_p(T)$).\n\nThus, to find $\\sigma(T)$, we must determine if $0$ is an eigenvalue and find all non-zero eigenvalues.\n\n**Step 1: Check if $\\lambda = 0$ is an eigenvalue**\nWe check for non-trivial solutions to $Tf = 0$:\n$$ \\int_{0}^{x} f(t) \\, dt = 0 \\quad \\text{for almost every } x \\in [0,1]. $$\nSince $f \\in L^2[0,1] \\subset L^1[0,1]$, the integral $F(x) = \\int_0^x f(t) dt$ is absolutely continuous. Differentiating both sides with respect to $x$ (using the Lebesgue differentiation theorem) gives:\n$$ f(x) = 0 \\quad \\text{almost everywhere}. $$\nThus, the kernel of $T$ is trivial ($\\text{Ker}(T) = \\{0\\}$), so $\\lambda = 0$ is **not** an eigenvalue.\nHowever, as noted above, $0 \\in \\sigma(T)$ because $T$ is a compact operator on an infinite-dimensional space (implying $T$ cannot be boundedly invertible).\n\n**Step 2: Check for eigenvalues $\\lambda \\neq 0$**\nSuppose there exists $\\lambda \\in \\mathbb{C} \\setminus \\{0\\}$ and a non-zero function $f \\in L^2[0,1]$ such that $Tf = \\lambda f$.\n$$ \\int_{0}^{x} f(t) \\, dt = \\lambda f(x). \\quad (*)$$\n\n*Regularity Argument:*\nSince $f \\in L^2[0,1]$, the left-hand side of $(*)$ is an absolutely continuous function of $x$. Therefore, $\\lambda f(x)$ is continuous. Since $\\lambda \\neq 0$, $f(x)$ must be continuous.\nSince $f$ is continuous, the integrand in the left-hand side is continuous, making the integral continuously differentiable ($C^1$). Therefore, $f$ must be a $C^1$ function.\n\n*Differential Equation:*\nWe can now differentiate $(*)$ with respect to $x$:\n$$ \\frac{d}{dx} \\int_{0}^{x} f(t) \\, dt = \\frac{d}{dx} (\\lambda f(x)) $$\n$$ f(x) = \\lambda f'(x). $$\nThis can be rewritten as a first-order linear ordinary differential equation:\n$$ f'(x) - \\frac{1}{\\lambda} f(x) = 0. $$\nThe general solution is:\n$$ f(x) = C e^{x/\\lambda}, $$\nwhere $C$ is an arbitrary constant.\n\n*Boundary Condition:*\nWe must ensure the solution satisfies the original integral equation $(*)$ at a specific point, typically $x=0$, to determine $C$.\nEvaluating $(*)$ at $x=0$:\n$$ \\text{LHS} = \\int_{0}^{0} f(t) \\, dt = 0, $$\n$$ \\text{RHS} = \\lambda f(0). $$\nSince $\\lambda \\neq 0$, we must have $f(0) = 0$.\n\nSubstituting the general solution into this boundary condition:\n$$ f(0) = C e^{0/\\lambda} = C \\cdot 1 = C. $$\nThus, $C = 0$.\n\nThis implies $f(x) = 0$ for all $x \\in [0,1]$. Since an eigenvector must be non-zero, there are no eigenvalues $\\lambda \\neq 0$.\n\n**Conclusion for Part 2**\nThe point spectrum of $T$ is empty ($\\sigma_p(T) = \\emptyset$). Since $T$ is compact and the space is infinite-dimensional, the spectrum contains $0$ but no other values.\n\n### Final Answer\n\n1. The operator $T$ is **compact** because it is a Hilbert-Schmidt operator with kernel norm $\\|K\\|_{L^2} = 1/\\sqrt{2}$.\n2. The spectrum of $T$ is **$\\sigma(T) = \\{0\\}$**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of calculus of variations and optimal control, along with a complete solution. The problem should be solvable, verifiable, and adhere to the specified format.",
    "run_id": "34",
    "outer_attempt": 1,
    "topic_slug": "calculus_of_variations_and_optimization",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is a challenging mathematical problem in the domain of **Calculus of Variations**, followed by a complete and rigorous solution.\n\n***\n\n### **Problem Statement**\n\nFind the function $y(x)$ continuously differentiable on the interval $[0, 1]$ that minimizes the functional:\n$$ J[y] = \\int_{0}^{1} \\left( (y'(x))^2 + y(x)^2 \\right) \\, dx $$\nsubject to the boundary conditions:\n$$ y(0) = 0, \\quad y(1) = 0 $$\nand the isoperimetric constraint:\n$$ \\int_{0}^{1} y(x) \\, dx = 1 $$\nProvide the explicit analytical expression for the optimal curve $y(x)$ and calculate the minimum value of the functional $J[y]$.\n\n***\n\n### **Solution**\n\nTo solve this constrained optimization problem, we employ the method of Lagrange multipliers in the calculus of variations.\n\n#### **1. Formulation of the Auxiliary Functional**\n\nWe introduce a Lagrange multiplier constant $\\lambda$ associated with the integral constraint. We define the auxiliary functional $L[y]$:\n$$ L[y] = \\int_{0}^{1} \\left( (y')^2 + y^2 \\right) \\, dx + \\lambda \\left( \\int_{0}^{1} y \\, dx - 1 \\right) $$\nThis can be rewritten as maximizing/minimizing the integral of the auxiliary Lagrangian $\\mathcal{F}$:\n$$ L[y] = \\int_{0}^{1} \\mathcal{F}(x, y, y') \\, dx - \\lambda $$\nwhere $\\mathcal{F}(x, y, y') = (y')^2 + y^2 + \\lambda y$.\n\n#### **2. The Euler-Lagrange Equation**\n\nA necessary condition for $y(x)$ to be an extremal is that it satisfies the Euler-Lagrange equation:\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y} - \\frac{d}{dx} \\left( \\frac{\\partial \\mathcal{F}}{\\partial y'} \\right) = 0 $$\nCalculating the partial derivatives:\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y} = 2y + \\lambda $$\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y'} = 2y' $$\nSubstitute these into the equation:\n$$ (2y + \\lambda) - \\frac{d}{dx}(2y') = 0 $$\n$$ 2y + \\lambda - 2y'' = 0 $$\nDividing by 2, we obtain the non-homogeneous linear differential equation:\n$$ y'' - y = \\frac{\\lambda}{2} $$\n\n#### **3. Solving the Differential Equation**\n\nThe general solution to the differential equation $y'' - y = \\frac{\\lambda}{2}$ consists of the homogeneous solution $y_h$ and a particular solution $y_p$.\n\n**Homogeneous solution** ($y'' - y = 0$):\n$$ y_h(x) = c_1 \\cosh(x) + c_2 \\sinh(x) $$\n\n**Particular solution**:\nSince the right-hand side is a constant, we posit a constant particular solution $y_p = A$.\n$$ 0 - A = \\frac{\\lambda}{2} \\implies A = -\\frac{\\lambda}{2} $$\n\nThus, the general solution is:\n$$ y(x) = c_1 \\cosh(x) + c_2 \\sinh(x) - \\frac{\\lambda}{2} $$\n\n#### **4. Applying Boundary Conditions**\n\nWe apply the boundary conditions $y(0)=0$ and $y(1)=0$ to determine constants $c_1$ and $c_2$ in terms of $\\lambda$.\n\n**At $x=0$:**\n$$ y(0) = c_1 \\cosh(0) + c_2 \\sinh(0) - \\frac{\\lambda}{2} = 0 $$\n$$ c_1 (1) + 0 - \\frac{\\lambda}{2} = 0 \\implies c_1 = \\frac{\\lambda}{2} $$\n\n**At $x=1$:**\n$$ y(1) = c_1 \\cosh(1) + c_2 \\sinh(1) - \\frac{\\lambda}{2} = 0 $$\nSubstitute $c_1 = \\frac{\\lambda}{2}$:\n$$ \\frac{\\lambda}{2} \\cosh(1) + c_2 \\sinh(1) - \\frac{\\lambda}{2} = 0 $$\n$$ c_2 \\sinh(1) = \\frac{\\lambda}{2} (1 - \\cosh(1)) $$\n$$ c_2 = \\frac{\\lambda}{2} \\frac{1 - \\cosh(1)}{\\sinh(1)} $$\n\nUsing the half-angle hyperbolic identities $\\cosh(x) - 1 = 2\\sinh^2(x/2)$ and $\\sinh(x) = 2\\sinh(x/2)\\cosh(x/2)$:\n$$ \\frac{1 - \\cosh(1)}{\\sinh(1)} = \\frac{-2\\sinh^2(1/2)}{2\\sinh(1/2)\\cosh(1/2)} = -\\tanh(1/2) $$\nSo,\n$$ c_2 = -\\frac{\\lambda}{2} \\tanh(1/2) $$\n\nSubstituting $c_1$ and $c_2$ back into the expression for $y(x)$:\n$$ y(x) = \\frac{\\lambda}{2} \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] $$\n\n#### **5. Determining the Lagrange Multiplier**\n\nWe use the isoperimetric constraint $\\int_{0}^{1} y(x) \\, dx = 1$ to solve for $\\lambda$.\n$$ \\int_{0}^{1} \\frac{\\lambda}{2} \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] dx = 1 $$\nFactor out $\\frac{\\lambda}{2}$:\n$$ \\frac{\\lambda}{2} \\left( \\left[ \\sinh(x) \\right]_0^1 - \\tanh(1/2) \\left[ \\cosh(x) \\right]_0^1 - \\left[ x \\right]_0^1 \\right) = 1 $$\nEvaluate the terms:\n1.  $\\left[ \\sinh(x) \\right]_0^1 = \\sinh(1)$\n2.  $\\left[ \\cosh(x) \\right]_0^1 = \\cosh(1) - 1$\n3.  $\\left[ x \\right]_0^1 = 1$\n\nThe equation becomes:\n$$ \\frac{\\lambda}{2} \\left( \\sinh(1) - \\frac{\\cosh(1)-1}{\\sinh(1)}(\\cosh(1)-1) - 1 \\right) = 1 $$\nSimplify the term inside the parenthesis:\n$$ \\sinh(1) - 1 - \\frac{(\\cosh(1)-1)^2}{\\sinh(1)} $$\nFind a common denominator ($\\sinh(1)$):\n$$ \\frac{\\sinh^2(1) - \\sinh(1) - (\\cosh^2(1) - 2\\cosh(1) + 1)}{\\sinh(1)} $$\nRecall the identity $\\cosh^2(x) - \\sinh^2(x) = 1$, so $\\sinh^2(x) - \\cosh^2(x) = -1$:\n$$ \\frac{-1 - \\sinh(1) + 2\\cosh(1) - 1}{\\sinh(1)} = \\frac{2\\cosh(1) - \\sinh(1) - 2}{\\sinh(1)} $$\n\nThus, the constraint equation is:\n$$ \\frac{\\lambda}{2} \\left( \\frac{2\\cosh(1) - \\sinh(1) - 2}{\\sinh(1)} \\right) = 1 $$\n$$ \\lambda = \\frac{2\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} $$\n\n#### **6. Final Expression for $y(x)$**\n\nSubstitute $\\lambda$ back into the expression for $y(x)$:\n$$ y(x) = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} \\left[ \\cosh(x) - \\frac{\\cosh(1)-1}{\\sinh(1)}\\sinh(x) - 1 \\right] $$\nThis simplifies slightly by grouping the hyperbolic terms. Let $K = \\frac{\\lambda}{2}$.\n$$ y(x) = K \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] $$\nwhere $K = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2}$.\n\n#### **7. Calculation of the Minimum Functional Value**\n\nWe calculate $J[y]$. Note that the Euler-Lagrange equation implies $y'' = y + \\frac{\\lambda}{2}$.\nIntegration by parts on the first term of $J$:\n$$ \\int_0^1 (y')^2 dx = [y y']_0^1 - \\int_0^1 y y'' dx $$\nSince $y(0)=y(1)=0$, the boundary term $[y y']_0^1$ vanishes.\n$$ \\int_0^1 (y')^2 dx = - \\int_0^1 y (y + \\frac{\\lambda}{2}) dx = - \\int_0^1 (y^2 + \\frac{\\lambda}{2} y) dx $$\nSubstitute this back into $J[y]$:\n$$ J[y] = \\int_0^1 \\left( -y^2 - \\frac{\\lambda}{2} y + y^2 \\right) dx = -\\frac{\\lambda}{2} \\int_0^1 y \\, dx $$\nUsing the constraint $\\int_0^1 y \\, dx = 1$:\n$$ J[y] = -\\frac{\\lambda}{2} $$\nSubstituting the value of $\\lambda$:\n$$ J_{min} = -K = -\\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} $$\nUsing numerical values ($\\sinh(1) \\approx 1.1752$, $\\cosh(1) \\approx 1.5431$):\n$$ 2(1.5431) - 1.1752 - 2 = 3.0862 - 3.1752 = -0.089 $$\n$$ J_{min} \\approx -\\frac{1.1752}{-0.089} \\approx 13.2 $$\n(Exact values should be preserved).\n\n**Check for Minimality:**\nThe integrand $\\mathcal{F} = y'^2 + y^2 + \\lambda y$ is convex with respect to $y$ and $y'$ (Hessian with respect to $y, y'$ is positive definite diagonal matrix $\\text{diag}(2, 2)$). Therefore, the extremal found is a global minimum.\n\n### **Final Answer**\n\nThe optimal curve is:\n$$ y(x) = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} \\left( \\cosh(x) - \\tanh\\left(\\frac{1}{2}\\right)\\sinh(x) - 1 \\right) $$\nThe minimum value of the functional is:\n$$ J_{min} = \\frac{\\sinh(1)}{2 + \\sinh(1) - 2\\cosh(1)} $$",
        "raw_answer": "Here is a challenging mathematical problem in the domain of **Calculus of Variations**, followed by a complete and rigorous solution.\n\n***\n\n### **Problem Statement**\n\nFind the function $y(x)$ continuously differentiable on the interval $[0, 1]$ that minimizes the functional:\n$$ J[y] = \\int_{0}^{1} \\left( (y'(x))^2 + y(x)^2 \\right) \\, dx $$\nsubject to the boundary conditions:\n$$ y(0) = 0, \\quad y(1) = 0 $$\nand the isoperimetric constraint:\n$$ \\int_{0}^{1} y(x) \\, dx = 1 $$\nProvide the explicit analytical expression for the optimal curve $y(x)$ and calculate the minimum value of the functional $J[y]$.\n\n***\n\n### **Solution**\n\nTo solve this constrained optimization problem, we employ the method of Lagrange multipliers in the calculus of variations.\n\n#### **1. Formulation of the Auxiliary Functional**\n\nWe introduce a Lagrange multiplier constant $\\lambda$ associated with the integral constraint. We define the auxiliary functional $L[y]$:\n$$ L[y] = \\int_{0}^{1} \\left( (y')^2 + y^2 \\right) \\, dx + \\lambda \\left( \\int_{0}^{1} y \\, dx - 1 \\right) $$\nThis can be rewritten as maximizing/minimizing the integral of the auxiliary Lagrangian $\\mathcal{F}$:\n$$ L[y] = \\int_{0}^{1} \\mathcal{F}(x, y, y') \\, dx - \\lambda $$\nwhere $\\mathcal{F}(x, y, y') = (y')^2 + y^2 + \\lambda y$.\n\n#### **2. The Euler-Lagrange Equation**\n\nA necessary condition for $y(x)$ to be an extremal is that it satisfies the Euler-Lagrange equation:\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y} - \\frac{d}{dx} \\left( \\frac{\\partial \\mathcal{F}}{\\partial y'} \\right) = 0 $$\nCalculating the partial derivatives:\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y} = 2y + \\lambda $$\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y'} = 2y' $$\nSubstitute these into the equation:\n$$ (2y + \\lambda) - \\frac{d}{dx}(2y') = 0 $$\n$$ 2y + \\lambda - 2y'' = 0 $$\nDividing by 2, we obtain the non-homogeneous linear differential equation:\n$$ y'' - y = \\frac{\\lambda}{2} $$\n\n#### **3. Solving the Differential Equation**\n\nThe general solution to the differential equation $y'' - y = \\frac{\\lambda}{2}$ consists of the homogeneous solution $y_h$ and a particular solution $y_p$.\n\n**Homogeneous solution** ($y'' - y = 0$):\n$$ y_h(x) = c_1 \\cosh(x) + c_2 \\sinh(x) $$\n\n**Particular solution**:\nSince the right-hand side is a constant, we posit a constant particular solution $y_p = A$.\n$$ 0 - A = \\frac{\\lambda}{2} \\implies A = -\\frac{\\lambda}{2} $$\n\nThus, the general solution is:\n$$ y(x) = c_1 \\cosh(x) + c_2 \\sinh(x) - \\frac{\\lambda}{2} $$\n\n#### **4. Applying Boundary Conditions**\n\nWe apply the boundary conditions $y(0)=0$ and $y(1)=0$ to determine constants $c_1$ and $c_2$ in terms of $\\lambda$.\n\n**At $x=0$:**\n$$ y(0) = c_1 \\cosh(0) + c_2 \\sinh(0) - \\frac{\\lambda}{2} = 0 $$\n$$ c_1 (1) + 0 - \\frac{\\lambda}{2} = 0 \\implies c_1 = \\frac{\\lambda}{2} $$\n\n**At $x=1$:**\n$$ y(1) = c_1 \\cosh(1) + c_2 \\sinh(1) - \\frac{\\lambda}{2} = 0 $$\nSubstitute $c_1 = \\frac{\\lambda}{2}$:\n$$ \\frac{\\lambda}{2} \\cosh(1) + c_2 \\sinh(1) - \\frac{\\lambda}{2} = 0 $$\n$$ c_2 \\sinh(1) = \\frac{\\lambda}{2} (1 - \\cosh(1)) $$\n$$ c_2 = \\frac{\\lambda}{2} \\frac{1 - \\cosh(1)}{\\sinh(1)} $$\n\nUsing the half-angle hyperbolic identities $\\cosh(x) - 1 = 2\\sinh^2(x/2)$ and $\\sinh(x) = 2\\sinh(x/2)\\cosh(x/2)$:\n$$ \\frac{1 - \\cosh(1)}{\\sinh(1)} = \\frac{-2\\sinh^2(1/2)}{2\\sinh(1/2)\\cosh(1/2)} = -\\tanh(1/2) $$\nSo,\n$$ c_2 = -\\frac{\\lambda}{2} \\tanh(1/2) $$\n\nSubstituting $c_1$ and $c_2$ back into the expression for $y(x)$:\n$$ y(x) = \\frac{\\lambda}{2} \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] $$\n\n#### **5. Determining the Lagrange Multiplier**\n\nWe use the isoperimetric constraint $\\int_{0}^{1} y(x) \\, dx = 1$ to solve for $\\lambda$.\n$$ \\int_{0}^{1} \\frac{\\lambda}{2} \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] dx = 1 $$\nFactor out $\\frac{\\lambda}{2}$:\n$$ \\frac{\\lambda}{2} \\left( \\left[ \\sinh(x) \\right]_0^1 - \\tanh(1/2) \\left[ \\cosh(x) \\right]_0^1 - \\left[ x \\right]_0^1 \\right) = 1 $$\nEvaluate the terms:\n1.  $\\left[ \\sinh(x) \\right]_0^1 = \\sinh(1)$\n2.  $\\left[ \\cosh(x) \\right]_0^1 = \\cosh(1) - 1$\n3.  $\\left[ x \\right]_0^1 = 1$\n\nThe equation becomes:\n$$ \\frac{\\lambda}{2} \\left( \\sinh(1) - \\frac{\\cosh(1)-1}{\\sinh(1)}(\\cosh(1)-1) - 1 \\right) = 1 $$\nSimplify the term inside the parenthesis:\n$$ \\sinh(1) - 1 - \\frac{(\\cosh(1)-1)^2}{\\sinh(1)} $$\nFind a common denominator ($\\sinh(1)$):\n$$ \\frac{\\sinh^2(1) - \\sinh(1) - (\\cosh^2(1) - 2\\cosh(1) + 1)}{\\sinh(1)} $$\nRecall the identity $\\cosh^2(x) - \\sinh^2(x) = 1$, so $\\sinh^2(x) - \\cosh^2(x) = -1$:\n$$ \\frac{-1 - \\sinh(1) + 2\\cosh(1) - 1}{\\sinh(1)} = \\frac{2\\cosh(1) - \\sinh(1) - 2}{\\sinh(1)} $$\n\nThus, the constraint equation is:\n$$ \\frac{\\lambda}{2} \\left( \\frac{2\\cosh(1) - \\sinh(1) - 2}{\\sinh(1)} \\right) = 1 $$\n$$ \\lambda = \\frac{2\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} $$\n\n#### **6. Final Expression for $y(x)$**\n\nSubstitute $\\lambda$ back into the expression for $y(x)$:\n$$ y(x) = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} \\left[ \\cosh(x) - \\frac{\\cosh(1)-1}{\\sinh(1)}\\sinh(x) - 1 \\right] $$\nThis simplifies slightly by grouping the hyperbolic terms. Let $K = \\frac{\\lambda}{2}$.\n$$ y(x) = K \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] $$\nwhere $K = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2}$.\n\n#### **7. Calculation of the Minimum Functional Value**\n\nWe calculate $J[y]$. Note that the Euler-Lagrange equation implies $y'' = y + \\frac{\\lambda}{2}$.\nIntegration by parts on the first term of $J$:\n$$ \\int_0^1 (y')^2 dx = [y y']_0^1 - \\int_0^1 y y'' dx $$\nSince $y(0)=y(1)=0$, the boundary term $[y y']_0^1$ vanishes.\n$$ \\int_0^1 (y')^2 dx = - \\int_0^1 y (y + \\frac{\\lambda}{2}) dx = - \\int_0^1 (y^2 + \\frac{\\lambda}{2} y) dx $$\nSubstitute this back into $J[y]$:\n$$ J[y] = \\int_0^1 \\left( -y^2 - \\frac{\\lambda}{2} y + y^2 \\right) dx = -\\frac{\\lambda}{2} \\int_0^1 y \\, dx $$\nUsing the constraint $\\int_0^1 y \\, dx = 1$:\n$$ J[y] = -\\frac{\\lambda}{2} $$\nSubstituting the value of $\\lambda$:\n$$ J_{min} = -K = -\\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} $$\nUsing numerical values ($\\sinh(1) \\approx 1.1752$, $\\cosh(1) \\approx 1.5431$):\n$$ 2(1.5431) - 1.1752 - 2 = 3.0862 - 3.1752 = -0.089 $$\n$$ J_{min} \\approx -\\frac{1.1752}{-0.089} \\approx 13.2 $$\n(Exact values should be preserved).\n\n**Check for Minimality:**\nThe integrand $\\mathcal{F} = y'^2 + y^2 + \\lambda y$ is convex with respect to $y$ and $y'$ (Hessian with respect to $y, y'$ is positive definite diagonal matrix $\\text{diag}(2, 2)$). Therefore, the extremal found is a global minimum.\n\n### **Final Answer**\n\nThe optimal curve is:\n$$ y(x) = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} \\left( \\cosh(x) - \\tanh\\left(\\frac{1}{2}\\right)\\sinh(x) - 1 \\right) $$\nThe minimum value of the functional is:\n$$ J_{min} = \\frac{\\sinh(1)}{2 + \\sinh(1) - 2\\cosh(1)} $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Geometry, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Choose a geometry topic\nTo create a challenging problem, we need to select a topic within geometry that is rich enough to allow for a non-trivial question. Let's consider problems related to geometric shapes, such as triangles, circles, or more complex figures.\n\n## Step 3: Formulate a problem\nLet's formulate a problem involving a triangle and a circle, as these are fundamental geometric objects. A potential problem could involve the properties of inscribed angles, the relationship between a triangle and its circumcircle, or the application of geometric theorems like Ptolemy's theorem.\n\n## Step 4: Create a specific problem\nConsider the following problem: \"Let $ABC$ be a triangle with $AB = 5$, $AC = 6$, and $BC = 7$. The circumcircle of triangle $ABC$ has center $O$. Let $D$ be the point on $BC$ such that $AD$ is the angle bisector of $\\angle BAC$. Find the length of $AD$.\"\n\n## Step 5: Verify the problem meets the criteria\n- **Well-Posedness and Completeness**: The triangle $ABC$ is well-defined by its side lengths (5, 6, 7), and $D$ is defined as the point on $BC$ where $AD$ bisects $\\angle BAC$. The circumcircle and its center $O$ are also well-defined.\n- **Clarity**: The problem statement is clear and unambiguous.\n- **Non-Triviality**: The problem requires applying geometric principles, such as the Angle Bisector Theorem and possibly properties of the circumcircle.\n- **Solvability and Verification**: The problem is solvable using established geometric methods.\n\n## Step 6: Solve the problem\nTo solve this, we can use the Angle Bisector Theorem to find $BD$ and $DC$, and then apply the Stewart's Theorem to find $AD$.\n\n### Step 6.1: Apply the Angle Bisector Theorem\nThe Angle Bisector Theorem states that $\\frac{BD}{DC} = \\frac{AB}{AC}$. So, $\\frac{BD}{DC} = \\frac{5}{6}$.\n\n### Step 6.2: Calculate $BD$ and $DC$\nGiven $BC = 7$, we have $BD + DC = 7$. From the Angle Bisector Theorem, we can write $BD = \\frac{5}{11} \\times 7$ and $DC = \\frac{6}{11} \\times 7$. Thus, $BD = \\frac{35}{11}$ and $DC = \\frac{42}{11}$.\n\n### Step 6.3: Apply Stewart's Theorem to find $AD$\nStewart's Theorem states that $b^2n + c^2m = a(d^2 + m*n)$, where $a = BC = 7$, $b = AC = 6$, $c = AB = 5$, $d = AD$, $m = BD = \\frac{35}{11}$, and $n = DC = \\frac{42}{11}$. Substituting these values gives us an equation to solve for $d = AD$.\n\n## Step 7: Perform Stewart's Theorem calculation\nLet's substitute the given values into Stewart's Theorem:\n$6^2(\\frac{35}{11}) + 5^2(\\frac{42}{11}) = 7(AD^2 + \\frac{35}{11}*\\frac{42}{11})$.\nSimplifying yields:\n$36(\\frac{35}{11}) + 25(\\frac{42}{11}) = 7(AD^2 + \\frac{1470}{121})$.\nThis simplifies to:\n$\\frac{1260}{11} + \\frac{1050}{11} = 7AD^2 + \\frac{7*1470}{121}$.\nFurther simplification gives:\n$\\frac{2310}{11} = 7AD^2 + \\frac{10290}{121}$.\nConverting to a common denominator:\n$\\frac{2310*11}{121} = 7AD^2 + \\frac{10290}{121}$,\n$\\frac{25410}{121} = 7AD^2 + \\frac{10290}{121}$.\nSimplifying:\n$7AD^2 = \\frac{25410 - 10290}{121}$,\n$7AD^2 = \\frac{15120}{121}$,\n$AD^2 = \\frac{15120}{7*121}$,\n$AD^2 = \\frac{2160}{121}$,\n$AD = \\sqrt{\\frac{2160}{121}}$.\n\n## Step 8: Simplify $AD$\n$AD = \\sqrt{\\frac{2160}{121}} = \\sqrt{\\frac{16*135}{121}} = \\sqrt{\\frac{16*9*15}{121}} = \\frac{4*3}{11}\\sqrt{15} = \\frac{12\\sqrt{15}}{11}$.\n\nThe final answer is: \n\nLet $ABC$ be a triangle with $AB = 5$, $AC = 6$, and $BC = 7$. The circumcircle of triangle $ABC$ has center $O$. Let $D$ be the point on $BC$ such that $AD$ is the angle bisector of $\\angle BAC$. Find the length of $AD$.",
    "run_id": "35",
    "outer_attempt": 1,
    "topic_slug": "geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the length of the segment $AD$, we will utilize the properties of the angle bisector in a triangle. Specifically, we will use the Angle Bisector Theorem to determine the segments of the opposite side, and then apply the standard formula for the length of an angle bisector (which can be derived from Stewart's Theorem or circumcircle properties).\n\n### 1. Setup and Given Information\n\nWe are given a triangle $ABC$ with the following side lengths:\n*   $c = AB = 5$\n*   $b = AC = 6$\n*   $a = BC = 7$\n\nPoint $D$ lies on the segment $BC$ such that $AD$ bisects $\\angle BAC$. We need to find the length of $AD$.\n\n*(Note: The problem mentions the circumcenter $O$. While relevant for derivations involving the circumcircle, it is not strictly required for the calculation of the internal bisector length given the side lengths.)*\n\n### 2. Determine the Lengths of Segments $BD$ and $DC$\n\nAccording to the **Angle Bisector Theorem**, the angle bisector of an angle of a triangle divides the opposite side into two segments that are proportional to the other two sides of the triangle.\n\nMathematically, this is expressed as:\n$$ \\frac{BD}{DC} = \\frac{AB}{AC} $$\n\nSubstituting the given values:\n$$ \\frac{BD}{DC} = \\frac{5}{6} $$\n\nSince $D$ lies on $BC$, we have $BD + DC = BC = 7$.\nLet $BD = 5k$ and $DC = 6k$ for some constant $k$.\n$$ 5k + 6k = 7 $$\n$$ 11k = 7 \\implies k = \\frac{7}{11} $$\n\nNow we can find the exact lengths of $BD$ and $DC$:\n$$ BD = 5 \\left( \\frac{7}{11} \\right) = \\frac{35}{11} $$\n$$ DC = 6 \\left( \\frac{7}{11} \\right) = \\frac{42}{11} $$\n\n### 3. Calculate the Length of $AD$\n\nThe length of the internal angle bisector $AD$ can be found using the formula:\n$$ AD^2 = AB \\cdot AC - BD \\cdot DC $$\n\n*Derivation Context: This formula is a direct consequence of Stewart's Theorem applied to the cevian $AD$, or can be derived using the power of a point with respect to the circumcircle.*\n\nSubstitute the known values into the formula:\n$$ AD^2 = (5)(6) - \\left( \\frac{35}{11} \\right) \\left( \\frac{42}{11} \\right) $$\n\nCalculate the product of the segments:\n$$ \\left( \\frac{35}{11} \\right) \\left( \\frac{42}{11} \\right) = \\frac{35 \\times 42}{121} = \\frac{1470}{121} $$\n\nSubstitute this back into the equation for $AD^2$:\n$$ AD^2 = 30 - \\frac{1470}{121} $$\n\nTo subtract, find a common denominator:\n$$ 30 = \\frac{30 \\times 121}{121} = \\frac{3630}{121} $$\n\nNow perform the subtraction:\n$$ AD^2 = \\frac{3630 - 1470}{121} = \\frac{2160}{121} $$\n\n### 4. Simplify the Result\n\nNow, take the square root of both sides to find $AD$:\n$$ AD = \\sqrt{\\frac{2160}{121}} = \\frac{\\sqrt{2160}}{11} $$\n\nWe simplify the radical $\\sqrt{2160}$. First, factor out perfect squares:\n$$ 2160 = 10 \\times 216 = 10 \\times 6^3 = 2 \\cdot 5 \\cdot 2^3 \\cdot 3^3 = 2^4 \\cdot 3^3 \\cdot 5 $$\n$$ 2160 = 16 \\cdot 9 \\cdot 15 = 144 \\cdot 15 $$\n\nThus:\n$$ \\sqrt{2160} = \\sqrt{144 \\cdot 15} = 12\\sqrt{15} $$\n\nSubstituting this back into the expression for $AD$:\n$$ AD = \\frac{12\\sqrt{15}}{11} $$\n\n### Conclusion\n\nThe length of the angle bisector $AD$ is:\n\n$$ \\frac{12\\sqrt{15}}{11} $$",
        "raw_answer": "To find the length of the segment $AD$, we will utilize the properties of the angle bisector in a triangle. Specifically, we will use the Angle Bisector Theorem to determine the segments of the opposite side, and then apply the standard formula for the length of an angle bisector (which can be derived from Stewart's Theorem or circumcircle properties).\n\n### 1. Setup and Given Information\n\nWe are given a triangle $ABC$ with the following side lengths:\n*   $c = AB = 5$\n*   $b = AC = 6$\n*   $a = BC = 7$\n\nPoint $D$ lies on the segment $BC$ such that $AD$ bisects $\\angle BAC$. We need to find the length of $AD$.\n\n*(Note: The problem mentions the circumcenter $O$. While relevant for derivations involving the circumcircle, it is not strictly required for the calculation of the internal bisector length given the side lengths.)*\n\n### 2. Determine the Lengths of Segments $BD$ and $DC$\n\nAccording to the **Angle Bisector Theorem**, the angle bisector of an angle of a triangle divides the opposite side into two segments that are proportional to the other two sides of the triangle.\n\nMathematically, this is expressed as:\n$$ \\frac{BD}{DC} = \\frac{AB}{AC} $$\n\nSubstituting the given values:\n$$ \\frac{BD}{DC} = \\frac{5}{6} $$\n\nSince $D$ lies on $BC$, we have $BD + DC = BC = 7$.\nLet $BD = 5k$ and $DC = 6k$ for some constant $k$.\n$$ 5k + 6k = 7 $$\n$$ 11k = 7 \\implies k = \\frac{7}{11} $$\n\nNow we can find the exact lengths of $BD$ and $DC$:\n$$ BD = 5 \\left( \\frac{7}{11} \\right) = \\frac{35}{11} $$\n$$ DC = 6 \\left( \\frac{7}{11} \\right) = \\frac{42}{11} $$\n\n### 3. Calculate the Length of $AD$\n\nThe length of the internal angle bisector $AD$ can be found using the formula:\n$$ AD^2 = AB \\cdot AC - BD \\cdot DC $$\n\n*Derivation Context: This formula is a direct consequence of Stewart's Theorem applied to the cevian $AD$, or can be derived using the power of a point with respect to the circumcircle.*\n\nSubstitute the known values into the formula:\n$$ AD^2 = (5)(6) - \\left( \\frac{35}{11} \\right) \\left( \\frac{42}{11} \\right) $$\n\nCalculate the product of the segments:\n$$ \\left( \\frac{35}{11} \\right) \\left( \\frac{42}{11} \\right) = \\frac{35 \\times 42}{121} = \\frac{1470}{121} $$\n\nSubstitute this back into the equation for $AD^2$:\n$$ AD^2 = 30 - \\frac{1470}{121} $$\n\nTo subtract, find a common denominator:\n$$ 30 = \\frac{30 \\times 121}{121} = \\frac{3630}{121} $$\n\nNow perform the subtraction:\n$$ AD^2 = \\frac{3630 - 1470}{121} = \\frac{2160}{121} $$\n\n### 4. Simplify the Result\n\nNow, take the square root of both sides to find $AD$:\n$$ AD = \\sqrt{\\frac{2160}{121}} = \\frac{\\sqrt{2160}}{11} $$\n\nWe simplify the radical $\\sqrt{2160}$. First, factor out perfect squares:\n$$ 2160 = 10 \\times 216 = 10 \\times 6^3 = 2 \\cdot 5 \\cdot 2^3 \\cdot 3^3 = 2^4 \\cdot 3^3 \\cdot 5 $$\n$$ 2160 = 16 \\cdot 9 \\cdot 15 = 144 \\cdot 15 $$\n\nThus:\n$$ \\sqrt{2160} = \\sqrt{144 \\cdot 15} = 12\\sqrt{15} $$\n\nSubstituting this back into the expression for $AD$:\n$$ AD = \\frac{12\\sqrt{15}}{11} $$\n\n### Conclusion\n\nThe length of the angle bisector $AD$ is:\n\n$$ \\frac{12\\sqrt{15}}{11} $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Convex and discrete geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Convex and discrete geometry\nConvex and discrete geometry encompasses a broad range of topics including the geometry of convex sets, polytopes, and discrete geometric structures. A suitable topic could involve properties of convex polytopes, such as their faces, volumes, or the relationships between their vertices and facets.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem related to the properties of a specific convex polytope. A well-known result in convex geometry is the characterization of regular polytopes. However, a more challenging and less straightforward problem could involve understanding the relationship between the number of vertices, edges, and faces of a polytope.\n\n## Step 4: Generate a problem statement\nConsider a 3-dimensional convex polytope $P$ that is simple (every vertex is incident to exactly 3 edges) and has $V$ vertices, $E$ edges, and $F$ faces. The problem is to prove that for such a polytope, Euler's formula ($V - E + F = 2$) holds, and then use this to derive a relationship between $V$ and $F$.\n\n## Step 5: Write down the problem in the required format\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces. Prove that $V - E + F = 2$ and derive a formula relating $V$ and $F$ using the fact that $P$ is simple.",
    "run_id": "36",
    "outer_attempt": 1,
    "topic_slug": "convex_and_discrete_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete, rigorous solution to the problem presented.\n\n### Problem Statement\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces.\n1. Prove that $V - E + F = 2$.\n2. Derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n---\n\n### Part 1: Proof of Euler's Formula for 3-Polytopes\n\n**Theorem:** For any convex 3-dimensional polytope, the number of vertices ($V$), edges ($E$), and faces ($F$) satisfy $V - E + F = 2$.\n\n**Proof:**\n\n**1. Reduction to Planar Graphs**\nThe boundary of a convex 3-polytope $P$ is homeomorphic to the 2-sphere $S^2$. We can project this boundary onto the Euclidean plane $\\mathbb{R}^2$ to form a planar graph $G$. A standard method is using a Schlegel diagram: we choose a face of the polytope to act as the \"window\" and project the remaining structure through this face onto the plane.\n- The vertices and edges of $P$ correspond one-to-one with the vertices and edges of $G$. Thus, $V_G = V$ and $E_G = E$.\n- The faces of $P$ correspond to the bounded regions of the plane graph $G$, plus the one unbounded region (the exterior) which corresponds to the face we projected through. Thus, $F_G = F$.\n- Since $P$ is a convex polytope, its 1-skeleton is connected; thus $G$ is a connected planar graph.\n\nThe problem reduces to proving Euler's formula for a connected planar graph $G$: $V_G - E_G + F_G = 2$.\n\n**2. Inductive Proof for Planar Graphs**\nWe proceed by induction on the number of faces, $F_G$.\n\n**Base Case:** $F_G = 1$.\nIf the graph has only one face (the unbounded region), it cannot contain any cycles (a cycle would enclose a bounded face). Since $G$ is connected and has no cycles, it is a tree.\nFor a tree with $V_G$ vertices and $E_G$ edges, we know that $E_G = V_G - 1$.\nSubstituting into Euler's expression:\n$$V_G - E_G + F_G = V_G - (V_G - 1) + 1 = 1 + 1 = 2$$\nThe formula holds for the base case.\n\n**Inductive Step:**\nAssume that for any connected planar graph with $k$ faces, $V - E + k = 2$.\nConsider a connected planar graph $G$ with $k+1$ faces ($k \\geq 1$).\nSince $k+1 \\geq 2$, the graph is not a tree and must contain at least one cycle. Furthermore, there must exist an edge $e$ that lies on the boundary between two distinct faces (an internal edge).\nRemove this edge $e$.\n- The number of edges becomes $E' = E - 1$.\n- The number of vertices remains $V' = V$.\n- Removing the boundary between two faces merges them into one. Thus, the number of faces becomes $F' = (k+1) - 1 = k$.\n- Removing an edge from a cycle does not disconnect the graph, so the resulting graph $G'$ is still connected.\n\nBy the inductive hypothesis, Euler's formula holds for $G'$:\n$$V' - E' + F' = 2$$\nSubstitute the relations back in terms of $G$:\n$$V - (E - 1) + (F - 1) = 2$$\n$$V - E + 1 + F - 1 = 2$$\n$$V - E + F = 2$$\n\n**Conclusion:**\nBy the principle of mathematical induction, $V - E + F = 2$ holds for all connected planar graphs, and consequently for all convex 3-polytopes.\n\n---\n\n### Part 2: Derivation of the Relation for Simple Polytopes\n\n**Definition:** A 3-dimensional polytope is **simple** if every vertex is incident to exactly 3 edges.\n\n**1. Establish the Vertex-Edge Relation**\nLet $\\deg(v)$ denote the degree of a vertex $v$ (the number of edges incident to it).\nSince $P$ is simple, for every vertex $v_i$, $\\deg(v_i) = 3$.\nWe sum the degrees of all vertices:\n$$\\sum_{i=1}^{V} \\deg(v_i) = 3V$$\n\nBy the Handshaking Lemma (graph theory), the sum of the degrees of the vertices in a graph is equal to twice the number of edges, because each edge connects two vertices and is counted exactly twice in the sum.\n$$2E = \\sum_{i=1}^{V} \\deg(v_i)$$\n\nEquating the two expressions:\n$$2E = 3V \\implies E = \\frac{3}{2}V$$\n\n**2. Substitute into Euler's Formula**\nWe start with Euler's formula proven in Part 1:\n$$V - E + F = 2$$\n\nSubstitute $E = \\frac{3}{2}V$ into the equation:\n$$V - \\frac{3}{2}V + F = 2$$\n\nSimplify the terms with $V$:\n$$-\\frac{1}{2}V + F = 2$$\n\n**3. Final Formula**\nTo express the relationship cleanly, we can solve for $V$ in terms of $F$:\n$$\\frac{1}{2}V = F - 2$$\n$$V = 2F - 4$$\n\nAlternatively, we can write it as $2F - V = 4$.\n\n### Final Answer\n\n1.  **Proof**: The relation $V - E + F = 2$ is proven by mapping the polytope to a connected planar graph and using induction on the number of faces.\n2.  **Relation**: For a simple 3-dimensional convex polytope, the relationship between the number of vertices and faces is:\n    $$V = 2F - 4$$",
        "raw_answer": "Here is the complete, rigorous solution to the problem presented.\n\n### Problem Statement\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces.\n1. Prove that $V - E + F = 2$.\n2. Derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n---\n\n### Part 1: Proof of Euler's Formula for 3-Polytopes\n\n**Theorem:** For any convex 3-dimensional polytope, the number of vertices ($V$), edges ($E$), and faces ($F$) satisfy $V - E + F = 2$.\n\n**Proof:**\n\n**1. Reduction to Planar Graphs**\nThe boundary of a convex 3-polytope $P$ is homeomorphic to the 2-sphere $S^2$. We can project this boundary onto the Euclidean plane $\\mathbb{R}^2$ to form a planar graph $G$. A standard method is using a Schlegel diagram: we choose a face of the polytope to act as the \"window\" and project the remaining structure through this face onto the plane.\n- The vertices and edges of $P$ correspond one-to-one with the vertices and edges of $G$. Thus, $V_G = V$ and $E_G = E$.\n- The faces of $P$ correspond to the bounded regions of the plane graph $G$, plus the one unbounded region (the exterior) which corresponds to the face we projected through. Thus, $F_G = F$.\n- Since $P$ is a convex polytope, its 1-skeleton is connected; thus $G$ is a connected planar graph.\n\nThe problem reduces to proving Euler's formula for a connected planar graph $G$: $V_G - E_G + F_G = 2$.\n\n**2. Inductive Proof for Planar Graphs**\nWe proceed by induction on the number of faces, $F_G$.\n\n**Base Case:** $F_G = 1$.\nIf the graph has only one face (the unbounded region), it cannot contain any cycles (a cycle would enclose a bounded face). Since $G$ is connected and has no cycles, it is a tree.\nFor a tree with $V_G$ vertices and $E_G$ edges, we know that $E_G = V_G - 1$.\nSubstituting into Euler's expression:\n$$V_G - E_G + F_G = V_G - (V_G - 1) + 1 = 1 + 1 = 2$$\nThe formula holds for the base case.\n\n**Inductive Step:**\nAssume that for any connected planar graph with $k$ faces, $V - E + k = 2$.\nConsider a connected planar graph $G$ with $k+1$ faces ($k \\geq 1$).\nSince $k+1 \\geq 2$, the graph is not a tree and must contain at least one cycle. Furthermore, there must exist an edge $e$ that lies on the boundary between two distinct faces (an internal edge).\nRemove this edge $e$.\n- The number of edges becomes $E' = E - 1$.\n- The number of vertices remains $V' = V$.\n- Removing the boundary between two faces merges them into one. Thus, the number of faces becomes $F' = (k+1) - 1 = k$.\n- Removing an edge from a cycle does not disconnect the graph, so the resulting graph $G'$ is still connected.\n\nBy the inductive hypothesis, Euler's formula holds for $G'$:\n$$V' - E' + F' = 2$$\nSubstitute the relations back in terms of $G$:\n$$V - (E - 1) + (F - 1) = 2$$\n$$V - E + 1 + F - 1 = 2$$\n$$V - E + F = 2$$\n\n**Conclusion:**\nBy the principle of mathematical induction, $V - E + F = 2$ holds for all connected planar graphs, and consequently for all convex 3-polytopes.\n\n---\n\n### Part 2: Derivation of the Relation for Simple Polytopes\n\n**Definition:** A 3-dimensional polytope is **simple** if every vertex is incident to exactly 3 edges.\n\n**1. Establish the Vertex-Edge Relation**\nLet $\\deg(v)$ denote the degree of a vertex $v$ (the number of edges incident to it).\nSince $P$ is simple, for every vertex $v_i$, $\\deg(v_i) = 3$.\nWe sum the degrees of all vertices:\n$$\\sum_{i=1}^{V} \\deg(v_i) = 3V$$\n\nBy the Handshaking Lemma (graph theory), the sum of the degrees of the vertices in a graph is equal to twice the number of edges, because each edge connects two vertices and is counted exactly twice in the sum.\n$$2E = \\sum_{i=1}^{V} \\deg(v_i)$$\n\nEquating the two expressions:\n$$2E = 3V \\implies E = \\frac{3}{2}V$$\n\n**2. Substitute into Euler's Formula**\nWe start with Euler's formula proven in Part 1:\n$$V - E + F = 2$$\n\nSubstitute $E = \\frac{3}{2}V$ into the equation:\n$$V - \\frac{3}{2}V + F = 2$$\n\nSimplify the terms with $V$:\n$$-\\frac{1}{2}V + F = 2$$\n\n**3. Final Formula**\nTo express the relationship cleanly, we can solve for $V$ in terms of $F$:\n$$\\frac{1}{2}V = F - 2$$\n$$V = 2F - 4$$\n\nAlternatively, we can write it as $2F - V = 4$.\n\n### Final Answer\n\n1.  **Proof**: The relation $V - E + F = 2$ is proven by mapping the polytope to a connected planar graph and using induction on the number of faces.\n2.  **Relation**: For a simple 3-dimensional convex polytope, the relationship between the number of vertices and faces is:\n    $$V = 2F - 4$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of differential geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within differential geometry\nDifferential geometry is a broad field that includes the study of curves and surfaces, Riemannian geometry, and more. A suitable topic could involve the properties of curves or surfaces, such as curvature, geodesics, or the application of differential geometry to other areas like physics.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the curvature of a surface. A classic result in differential geometry is the Theorema Egregium of Gauss, which states that the Gaussian curvature of a surface is invariant under isometric deformations. A challenging problem could involve calculating or utilizing this curvature.\n\n## Step 4: Construct the problem statement\nTo create a problem, let's consider a specific surface and ask a question about its geometric properties. For example, we could examine the surface given by $z = x^2 + y^2$ and ask to compute its Gaussian curvature at a given point.\n\n## Step 5: Write the problem statement\nLet's define the problem: \"Let $S$ be the surface given by $z = x^2 + y^2$. Compute the Gaussian curvature $K$ of $S$ at the point $(1,1,2)$.\"\n\n## Step 6: Provide the solution\nTo solve this, we first need to parameterize the surface. The surface $S$ can be parameterized by $\\vec{r}(x,y) = (x, y, x^2 + y^2)$. The Gaussian curvature $K$ can be found using the formula $K = \\frac{LN - M^2}{EG - F^2}$, where $E, F, G$ are coefficients of the first fundamental form, and $L, M, N$ are coefficients of the second fundamental form.\n\n## Step 7: Calculate the first and second fundamental forms\nFirst, compute $\\vec{r}_x = (1, 0, 2x)$ and $\\vec{r}_y = (0, 1, 2y)$. Then, $E = \\vec{r}_x \\cdot \\vec{r}_x = 1 + 4x^2$, $F = \\vec{r}_x \\cdot \\vec{r}_y = 4xy$, and $G = \\vec{r}_y \\cdot \\vec{r}_y = 1 + 4y^2$. The normal vector $\\vec{n} = \\frac{\\vec{r}_x \\times \\vec{r}_y}{\\|\\vec{r}_x \\times \\vec{r}_y\\|}$, and $\\vec{r}_x \\times \\vec{r}_y = (-2x, -2y, 1)$, so $\\|\\vec{r}_x \\times \\vec{r}_y\\| = \\sqrt{4x^2 + 4y^2 + 1}$. Thus, $\\vec{n} = \\frac{1}{\\sqrt{4x^2 + 4y^2 + 1}}(-2x, -2y, 1)$.\n\n## Step 8: Continue with the calculation of $L, M, N$\n$L = \\vec{r}_{xx} \\cdot \\vec{n}$, $M = \\vec{r}_{xy} \\cdot \\vec{n}$, and $N = \\vec{r}_{yy} \\cdot \\vec{n}$. We have $\\vec{r}_{xx} = (0, 0, 2)$, $\\vec{r}_{xy} = (0, 0, 0)$, and $\\vec{r}_{yy} = (0, 0, 2)$. So, $L = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}}$, $M = 0$, and $N = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}}$.\n\n## Step 9: Evaluate $K$ at $(1,1,2)$\nAt $(1,1,2)$, $x = 1$, $y = 1$, so $E = 5$, $F = 4$, $G = 5$, $L = \\frac{2}{3}$, $M = 0$, and $N = \\frac{2}{3}$. Thus, $EG - F^2 = 25 - 16 = 9$ and $LN - M^2 = \\frac{4}{9}$.\n\n## Step 10: Calculate $K$\n$K = \\frac{LN - M^2}{EG - F^2} = \\frac{\\frac{4}{9}}{9} = \\frac{4}{81}$.\n\nThe final answer is: \n\nLet $S$ be the surface given by $z = x^2 + y^2$. Compute the Gaussian curvature $K$ of $S$ at the point $(1,1,2)$.",
    "run_id": "37",
    "outer_attempt": 1,
    "topic_slug": "differential_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the Gaussian curvature $K$ of the surface $S$ defined by $z = x^2 + y^2$ at the point $(1,1,2)$, we will utilize the method of fundamental forms.\n\n### 1. Parameterization of the Surface\n\nThe surface $S$ is the graph of the function $f(x,y) = x^2 + y^2$. We can parameterize $S$ using the coordinates $x$ and $y$ as follows:\n$$ \\mathbf{r}(x,y) = (x, y, x^2 + y^2) $$\n\n### 2. First Fundamental Form\n\nWe compute the first partial derivatives of the position vector $\\mathbf{r}$ with respect to $x$ and $y$:\n$$ \\mathbf{r}_x = \\frac{\\partial \\mathbf{r}}{\\partial x} = (1, 0, 2x) $$\n$$ \\mathbf{r}_y = \\frac{\\partial \\mathbf{r}}{\\partial y} = (0, 1, 2y) $$\n\nThe coefficients of the first fundamental form, $E, F,$ and $G$, are given by the dot products of these tangent vectors:\n$$ E = \\mathbf{r}_x \\cdot \\mathbf{r}_x = 1^2 + 0^2 + (2x)^2 = 1 + 4x^2 $$\n$$ F = \\mathbf{r}_x \\cdot \\mathbf{r}_y = 1(0) + 0(1) + (2x)(2y) = 4xy $$\n$$ G = \\mathbf{r}_y \\cdot \\mathbf{r}_y = 0^2 + 1^2 + (2y)^2 = 1 + 4y^2 $$\n\n### 3. Unit Normal Vector\n\nTo find the second fundamental form, we first need the unit normal vector $\\mathbf{n}$. We compute the cross product of the tangent vectors:\n$$ \\mathbf{r}_x \\times \\mathbf{r}_y = \\begin{vmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ 1 & 0 & 2x \\\\ 0 & 1 & 2y \\end{vmatrix} = (-2x)\\mathbf{i} - (2y)\\mathbf{j} + (1)\\mathbf{k} = (-2x, -2y, 1) $$\n\nThe magnitude of this vector is:\n$$ \\| \\mathbf{r}_x \\times \\mathbf{r}_y \\| = \\sqrt{(-2x)^2 + (-2y)^2 + 1^2} = \\sqrt{4x^2 + 4y^2 + 1} $$\n\nThus, the unit normal vector is:\n$$ \\mathbf{n} = \\frac{\\mathbf{r}_x \\times \\mathbf{r}_y}{\\| \\mathbf{r}_x \\times \\mathbf{r}_y \\|} = \\frac{1}{\\sqrt{4x^2 + 4y^2 + 1}}(-2x, -2y, 1) $$\n\n### 4. Second Fundamental Form\n\nWe compute the second partial derivatives of $\\mathbf{r}$:\n$$ \\mathbf{r}_{xx} = (0, 0, 2) $$\n$$ \\mathbf{r}_{xy} = (0, 0, 0) $$\n$$ \\mathbf{r}_{yy} = (0, 0, 2) $$\n\nThe coefficients of the second fundamental form, $L, M,$ and $N$, are the projections of these second derivatives onto the unit normal $\\mathbf{n}$:\n$$ L = \\mathbf{r}_{xx} \\cdot \\mathbf{n} = \\frac{(0,0,2) \\cdot (-2x, -2y, 1)}{\\sqrt{4x^2 + 4y^2 + 1}} = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}} $$\n$$ M = \\mathbf{r}_{xy} \\cdot \\mathbf{n} = \\frac{(0,0,0) \\cdot (-2x, -2y, 1)}{\\sqrt{4x^2 + 4y^2 + 1}} = 0 $$\n$$ N = \\mathbf{r}_{yy} \\cdot \\mathbf{n} = \\frac{(0,0,2) \\cdot (-2x, -2y, 1)}{\\sqrt{4x^2 + 4y^2 + 1}} = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}} $$\n\n### 5. Calculation of Gaussian Curvature\n\nThe Gaussian curvature $K$ is given by the ratio of the determinants of the second and first fundamental forms:\n$$ K = \\frac{LN - M^2}{EG - F^2} $$\n\nFirst, let us evaluate the components at the point of interest. The point is given as $(1,1,2)$, which implies $x=1$ and $y=1$.\n\n**Evaluation of First Fundamental Form coefficients at $(1,1)$:**\n$$ E = 1 + 4(1)^2 = 5 $$\n$$ F = 4(1)(1) = 4 $$\n$$ G = 1 + 4(1)^2 = 5 $$\nDenominator determinant:\n$$ EG - F^2 = (5)(5) - (4)^2 = 25 - 16 = 9 $$\n\n**Evaluation of Second Fundamental Form coefficients at $(1,1)$:**\nThe normalization factor is $\\sqrt{4(1)^2 + 4(1)^2 + 1} = \\sqrt{9} = 3$.\n$$ L = \\frac{2}{3} $$\n$$ M = 0 $$\n$$ N = \\frac{2}{3} $$\nNumerator determinant:\n$$ LN - M^2 = \\left(\\frac{2}{3}\\right)\\left(\\frac{2}{3}\\right) - 0^2 = \\frac{4}{9} $$\n\n**Final Calculation:**\n$$ K = \\frac{4/9}{9} = \\frac{4}{81} $$\n\n### Conclusion\nThe Gaussian curvature of the surface $S$ at the point $(1,1,2)$ is $\\frac{4}{81}$.",
        "raw_answer": "To find the Gaussian curvature $K$ of the surface $S$ defined by $z = x^2 + y^2$ at the point $(1,1,2)$, we will utilize the method of fundamental forms.\n\n### 1. Parameterization of the Surface\n\nThe surface $S$ is the graph of the function $f(x,y) = x^2 + y^2$. We can parameterize $S$ using the coordinates $x$ and $y$ as follows:\n$$ \\mathbf{r}(x,y) = (x, y, x^2 + y^2) $$\n\n### 2. First Fundamental Form\n\nWe compute the first partial derivatives of the position vector $\\mathbf{r}$ with respect to $x$ and $y$:\n$$ \\mathbf{r}_x = \\frac{\\partial \\mathbf{r}}{\\partial x} = (1, 0, 2x) $$\n$$ \\mathbf{r}_y = \\frac{\\partial \\mathbf{r}}{\\partial y} = (0, 1, 2y) $$\n\nThe coefficients of the first fundamental form, $E, F,$ and $G$, are given by the dot products of these tangent vectors:\n$$ E = \\mathbf{r}_x \\cdot \\mathbf{r}_x = 1^2 + 0^2 + (2x)^2 = 1 + 4x^2 $$\n$$ F = \\mathbf{r}_x \\cdot \\mathbf{r}_y = 1(0) + 0(1) + (2x)(2y) = 4xy $$\n$$ G = \\mathbf{r}_y \\cdot \\mathbf{r}_y = 0^2 + 1^2 + (2y)^2 = 1 + 4y^2 $$\n\n### 3. Unit Normal Vector\n\nTo find the second fundamental form, we first need the unit normal vector $\\mathbf{n}$. We compute the cross product of the tangent vectors:\n$$ \\mathbf{r}_x \\times \\mathbf{r}_y = \\begin{vmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ 1 & 0 & 2x \\\\ 0 & 1 & 2y \\end{vmatrix} = (-2x)\\mathbf{i} - (2y)\\mathbf{j} + (1)\\mathbf{k} = (-2x, -2y, 1) $$\n\nThe magnitude of this vector is:\n$$ \\| \\mathbf{r}_x \\times \\mathbf{r}_y \\| = \\sqrt{(-2x)^2 + (-2y)^2 + 1^2} = \\sqrt{4x^2 + 4y^2 + 1} $$\n\nThus, the unit normal vector is:\n$$ \\mathbf{n} = \\frac{\\mathbf{r}_x \\times \\mathbf{r}_y}{\\| \\mathbf{r}_x \\times \\mathbf{r}_y \\|} = \\frac{1}{\\sqrt{4x^2 + 4y^2 + 1}}(-2x, -2y, 1) $$\n\n### 4. Second Fundamental Form\n\nWe compute the second partial derivatives of $\\mathbf{r}$:\n$$ \\mathbf{r}_{xx} = (0, 0, 2) $$\n$$ \\mathbf{r}_{xy} = (0, 0, 0) $$\n$$ \\mathbf{r}_{yy} = (0, 0, 2) $$\n\nThe coefficients of the second fundamental form, $L, M,$ and $N$, are the projections of these second derivatives onto the unit normal $\\mathbf{n}$:\n$$ L = \\mathbf{r}_{xx} \\cdot \\mathbf{n} = \\frac{(0,0,2) \\cdot (-2x, -2y, 1)}{\\sqrt{4x^2 + 4y^2 + 1}} = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}} $$\n$$ M = \\mathbf{r}_{xy} \\cdot \\mathbf{n} = \\frac{(0,0,0) \\cdot (-2x, -2y, 1)}{\\sqrt{4x^2 + 4y^2 + 1}} = 0 $$\n$$ N = \\mathbf{r}_{yy} \\cdot \\mathbf{n} = \\frac{(0,0,2) \\cdot (-2x, -2y, 1)}{\\sqrt{4x^2 + 4y^2 + 1}} = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}} $$\n\n### 5. Calculation of Gaussian Curvature\n\nThe Gaussian curvature $K$ is given by the ratio of the determinants of the second and first fundamental forms:\n$$ K = \\frac{LN - M^2}{EG - F^2} $$\n\nFirst, let us evaluate the components at the point of interest. The point is given as $(1,1,2)$, which implies $x=1$ and $y=1$.\n\n**Evaluation of First Fundamental Form coefficients at $(1,1)$:**\n$$ E = 1 + 4(1)^2 = 5 $$\n$$ F = 4(1)(1) = 4 $$\n$$ G = 1 + 4(1)^2 = 5 $$\nDenominator determinant:\n$$ EG - F^2 = (5)(5) - (4)^2 = 25 - 16 = 9 $$\n\n**Evaluation of Second Fundamental Form coefficients at $(1,1)$:**\nThe normalization factor is $\\sqrt{4(1)^2 + 4(1)^2 + 1} = \\sqrt{9} = 3$.\n$$ L = \\frac{2}{3} $$\n$$ M = 0 $$\n$$ N = \\frac{2}{3} $$\nNumerator determinant:\n$$ LN - M^2 = \\left(\\frac{2}{3}\\right)\\left(\\frac{2}{3}\\right) - 0^2 = \\frac{4}{9} $$\n\n**Final Calculation:**\n$$ K = \\frac{4/9}{9} = \\frac{4}{81} $$\n\n### Conclusion\nThe Gaussian curvature of the surface $S$ at the point $(1,1,2)$ is $\\frac{4}{81}$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of general topology, along with a complete solution, following specific guidelines.\n[/QUESTION]",
    "run_id": "38",
    "outer_attempt": 1,
    "topic_slug": "general_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is a challenging problem in general topology concerning metrization theorems for compact spaces, followed by a complete and rigorous solution.\n\n***\n\n# Problem: Metrizability of Compact Hausdorff Spaces via the Diagonal\n\n**Problem Statement:**\nLet $X$ be a compact Hausdorff topological space. Let $\\Delta = \\{(x, x) \\in X \\times X \\mid x \\in X\\}$ denote the diagonal subset of the product space $X \\times X$.\n\nProve that $X$ is metrizable if and only if $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n\n(Note: A set is a $G_\\delta$ set if it can be written as a countable intersection of open sets.)\n\n***\n\n# Solution\n\nWe must prove the equivalence of two statements for a compact Hausdorff space $X$:\n1. $X$ is metrizable.\n2. The diagonal $\\Delta$ is a $G_\\delta$ set in $X \\times X$ (with the product topology).\n\n## Part 1: Forward Implication ($\\implies$)\n\n**Hypothesis:** Assume $X$ is metrizable.\n**Goal:** Show that $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n\n1.  Since $X$ is metrizable, let $d: X \\times X \\to [0, \\infty)$ be a metric that induces the topology of $X$.\n2.  The metric function $d$ is continuous on $X \\times X$ (with respect to the product topology induced by the metric on $X$).\n3.  The diagonal $\\Delta$ is precisely the zero set of the metric:\n    $$ \\Delta = \\{(x, y) \\in X \\times X \\mid d(x, y) = 0 \\} = d^{-1}(\\{0\\}). $$\n4.  Consider the sets $U_n$ defined by:\n    $$ U_n = \\{(x, y) \\in X \\times X \\mid d(x, y) < \\frac{1}{n} \\} = d^{-1}\\left(\\left[0, \\frac{1}{n}\\right)\\right). $$\n5.  Since $d$ is continuous and $[0, 1/n)$ is open in $[0, \\infty)$, each set $U_n$ is open in $X \\times X$.\n6.  The intersection of these sets is:\n    $$ \\bigcap_{n=1}^{\\infty} U_n = \\{(x, y) \\in X \\times X \\mid d(x, y) < \\frac{1}{n} \\text{ for all } n \\in \\mathbb{Z}^+\\} = \\{(x, y) \\mid d(x, y) = 0\\} = \\Delta. $$\n7.  Therefore, $\\Delta$ is the intersection of a countable collection of open sets. By definition, $\\Delta$ is a $G_\\delta$ set.\n\nThis direction holds for any metrizable space (compactness is not required here).\n\n## Part 2: Reverse Implication ($\\impliedby$)\n\n**Hypothesis:** Assume $X$ is compact Hausdorff and $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n**Goal:** Show that $X$ is metrizable.\n\n**Strategy:** A standard metrization theorem states that a compact Hausdorff space is metrizable if and only if it is second-countable. Since we are given that $X$ is compact Hausdorff, it suffices to prove that $X$ is second-countable (i.e., has a countable basis).\n\n### Step 2.1: Properties of the Diagonal and Covers\n\n1.  Since $\\Delta$ is a $G_\\delta$ set, there exist open sets $W_1, W_2, \\dots$ in $X \\times X$ such that $\\Delta = \\bigcap_{n=1}^\\infty W_n$.\n2.  Since $X$ is Hausdorff, $\\Delta$ is closed in $X \\times X$.\n3.  Since $X$ is compact Hausdorff, the product space $X \\times X$ is also compact Hausdorff.\n4.  Compact Hausdorff spaces are normal ($T_4$). In a normal space, for any closed $G_\\delta$ set $F$, there exists a sequence of open sets $G_n$ such that $F = \\bigcap G_n$ and $\\overline{G_{n+1}} \\subseteq G_n$ for all $n$.\n    *Justification:* We have $\\Delta = \\bigcap W_n$. Since $X \\times X$ is normal, we can use Urysohn's Lemma or simple normality properties to construct the sequence $G_n$ inductively. Let $G_1 = W_1$. Since $\\Delta \\subseteq G_1$ is closed and $G_1$ is open, normality implies there exists an open $V$ such that $\\Delta \\subseteq V \\subseteq \\overline{V} \\subseteq G_1$. Intersect with $W_2$ to maintain the limit, i.e., set $G_2 = V \\cap W_2$. Proceeding inductively, we construct a sequence $G_n$ such that $\\Delta = \\bigcap_{n=1}^\\infty G_n$ and $\\overline{G_{n+1}} \\subseteq G_n$.\n\n### Step 2.2: Constructing Countable Covers of $X$\n\nFor each $n \\in \\mathbb{Z}^+$, we construct a finite open cover $\\mathcal{U}_n$ of $X$ with a specific \"smallness\" property relative to $G_n$.\n\n1.  Fix $n$. For each $x \\in X$, we have $(x, x) \\in \\Delta \\subseteq G_n$.\n2.  Since $G_n$ is open in the product topology, there exists an open neighborhood $V_x$ of $x$ in $X$ such that $V_x \\times V_x \\subseteq G_n$.\n3.  The collection $\\{V_x \\mid x \\in X\\}$ covers $X$. Since $X$ is compact, there exists a finite subcover. Let us denote this finite cover by $\\mathcal{U}_n$.\n4.  Property of $\\mathcal{U}_n$: For every $U \\in \\mathcal{U}_n$, $U \\times U \\subseteq G_n$.\n\nLet $\\mathcal{B} = \\bigcup_{n=1}^\\infty \\mathcal{U}_n$. Since each $\\mathcal{U}_n$ is finite, $\\mathcal{B}$ is a countable collection of open sets.\n\n### Step 2.3: Proving $\\mathcal{B}$ forms a Basis\n\nWe claim that for every $x \\in X$ and every open neighborhood $O$ of $x$, there exists a set $U \\in \\mathcal{B}$ such that $x \\in U \\subseteq O$. If this holds, $\\mathcal{B}$ is a basis for $X$.\n\nLet's define the star of $x$ with respect to a cover $\\mathcal{C}$ as $St(x, \\mathcal{C}) = \\bigcup \\{ U \\in \\mathcal{C} \\mid x \\in U \\}$.\n\n**Claim:** The collection $\\{ St(x, \\mathcal{U}_n) \\}_{n \\ge 1}$ forms a neighborhood basis for $x$. That is, for any open $O$ containing $x$, there exists $N$ such that $St(x, \\mathcal{U}_N) \\subseteq O$.\n\n**Proof of Claim (by contradiction):**\n1.  Suppose there exists an open neighborhood $O$ of $x$ such that for all $n$, $St(x, \\mathcal{U}_n) \\not\\subseteq O$.\n2.  Then for each $n$, there exists a point $y_n \\in St(x, \\mathcal{U}_n) \\setminus O$.\n3.  The sequence $(y_n)$ lies in the set $X \\setminus O$, which is closed in the compact space $X$. Therefore, $X \\setminus O$ is compact.\n4.  The sequence $(y_n)$ must have a cluster point $z \\in X \\setminus O$.\n5.  Since $x \\in O$ and $z \\in X \\setminus O$, we have $x \\neq z$. Thus $(x, z) \\notin \\Delta$.\n6.  Consider the relation established by the covers. Since $y_n \\in St(x, \\mathcal{U}_n)$, there exists some $U \\in \\mathcal{U}_n$ such that $x \\in U$ and $y_n \\in U$.\n7.  By the construction of $\\mathcal{U}_n$, $U \\times U \\subseteq G_n$. Therefore, $(x, y_n) \\in G_n$.\n8.  Now, fix an integer $k$. For all $n \\geq k$, we have $(x, y_n) \\in G_n \\subseteq G_k$.\n9.  Since $z$ is a cluster point of $(y_n)$, the point $(x, z)$ is a cluster point of the sequence $((x, y_n))$ in $X \\times X$.\n10. Since all terms $(x, y_n)$ for $n \\ge k$ lie in $G_k$, the cluster point $(x, z)$ must lie in the closure $\\overline{G_k}$.\n11. Recall our construction in Step 2.1: $\\overline{G_{k+1}} \\subseteq G_k$.\n12. Since $(x, z) \\in \\overline{G_{k+1}}$ (applying the logic from step 10 to $k+1$), we have $(x, z) \\in G_k$.\n13. This holds for *all* $k$. Therefore, $(x, z) \\in \\bigcap_{k=1}^\\infty G_k = \\Delta$.\n14. This implies $x = z$.\n15. This contradicts the fact that $x \\in O$ and $z \\in X \\setminus O$.\n\nTherefore, the assumption was false. There exists some $N$ such that $St(x, \\mathcal{U}_N) \\subseteq O$.\n\n**Conclusion of Step 2.3:**\nSince $St(x, \\mathcal{U}_N)$ is a union of finitely many sets from $\\mathcal{U}_N$ (all of which contain $x$), any single $U \\in \\mathcal{U}_N$ containing $x$ satisfies $x \\in U \\subseteq St(x, \\mathcal{U}_N) \\subseteq O$. Since $U \\in \\mathcal{U}_N \\subset \\mathcal{B}$, we have found a basis element inside $O$ containing $x$. Thus, $\\mathcal{B}$ is a countable basis for the topology of $X$.\n\n### Step 2.4: Final Conclusion\n\n1.  $X$ is a compact Hausdorff space.\n2.  We have shown that if $\\Delta$ is a $G_\\delta$ set, then $X$ admits a countable basis (is second-countable).\n3.  By the Urysohn Metrization Theorem (or the specific version for compact spaces: A compact Hausdorff space is metrizable iff it is second-countable), $X$ is metrizable.\n\nThus, both directions are proven.\n\n**Q.E.D.**",
        "raw_answer": "Here is a challenging problem in general topology concerning metrization theorems for compact spaces, followed by a complete and rigorous solution.\n\n***\n\n# Problem: Metrizability of Compact Hausdorff Spaces via the Diagonal\n\n**Problem Statement:**\nLet $X$ be a compact Hausdorff topological space. Let $\\Delta = \\{(x, x) \\in X \\times X \\mid x \\in X\\}$ denote the diagonal subset of the product space $X \\times X$.\n\nProve that $X$ is metrizable if and only if $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n\n(Note: A set is a $G_\\delta$ set if it can be written as a countable intersection of open sets.)\n\n***\n\n# Solution\n\nWe must prove the equivalence of two statements for a compact Hausdorff space $X$:\n1. $X$ is metrizable.\n2. The diagonal $\\Delta$ is a $G_\\delta$ set in $X \\times X$ (with the product topology).\n\n## Part 1: Forward Implication ($\\implies$)\n\n**Hypothesis:** Assume $X$ is metrizable.\n**Goal:** Show that $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n\n1.  Since $X$ is metrizable, let $d: X \\times X \\to [0, \\infty)$ be a metric that induces the topology of $X$.\n2.  The metric function $d$ is continuous on $X \\times X$ (with respect to the product topology induced by the metric on $X$).\n3.  The diagonal $\\Delta$ is precisely the zero set of the metric:\n    $$ \\Delta = \\{(x, y) \\in X \\times X \\mid d(x, y) = 0 \\} = d^{-1}(\\{0\\}). $$\n4.  Consider the sets $U_n$ defined by:\n    $$ U_n = \\{(x, y) \\in X \\times X \\mid d(x, y) < \\frac{1}{n} \\} = d^{-1}\\left(\\left[0, \\frac{1}{n}\\right)\\right). $$\n5.  Since $d$ is continuous and $[0, 1/n)$ is open in $[0, \\infty)$, each set $U_n$ is open in $X \\times X$.\n6.  The intersection of these sets is:\n    $$ \\bigcap_{n=1}^{\\infty} U_n = \\{(x, y) \\in X \\times X \\mid d(x, y) < \\frac{1}{n} \\text{ for all } n \\in \\mathbb{Z}^+\\} = \\{(x, y) \\mid d(x, y) = 0\\} = \\Delta. $$\n7.  Therefore, $\\Delta$ is the intersection of a countable collection of open sets. By definition, $\\Delta$ is a $G_\\delta$ set.\n\nThis direction holds for any metrizable space (compactness is not required here).\n\n## Part 2: Reverse Implication ($\\impliedby$)\n\n**Hypothesis:** Assume $X$ is compact Hausdorff and $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n**Goal:** Show that $X$ is metrizable.\n\n**Strategy:** A standard metrization theorem states that a compact Hausdorff space is metrizable if and only if it is second-countable. Since we are given that $X$ is compact Hausdorff, it suffices to prove that $X$ is second-countable (i.e., has a countable basis).\n\n### Step 2.1: Properties of the Diagonal and Covers\n\n1.  Since $\\Delta$ is a $G_\\delta$ set, there exist open sets $W_1, W_2, \\dots$ in $X \\times X$ such that $\\Delta = \\bigcap_{n=1}^\\infty W_n$.\n2.  Since $X$ is Hausdorff, $\\Delta$ is closed in $X \\times X$.\n3.  Since $X$ is compact Hausdorff, the product space $X \\times X$ is also compact Hausdorff.\n4.  Compact Hausdorff spaces are normal ($T_4$). In a normal space, for any closed $G_\\delta$ set $F$, there exists a sequence of open sets $G_n$ such that $F = \\bigcap G_n$ and $\\overline{G_{n+1}} \\subseteq G_n$ for all $n$.\n    *Justification:* We have $\\Delta = \\bigcap W_n$. Since $X \\times X$ is normal, we can use Urysohn's Lemma or simple normality properties to construct the sequence $G_n$ inductively. Let $G_1 = W_1$. Since $\\Delta \\subseteq G_1$ is closed and $G_1$ is open, normality implies there exists an open $V$ such that $\\Delta \\subseteq V \\subseteq \\overline{V} \\subseteq G_1$. Intersect with $W_2$ to maintain the limit, i.e., set $G_2 = V \\cap W_2$. Proceeding inductively, we construct a sequence $G_n$ such that $\\Delta = \\bigcap_{n=1}^\\infty G_n$ and $\\overline{G_{n+1}} \\subseteq G_n$.\n\n### Step 2.2: Constructing Countable Covers of $X$\n\nFor each $n \\in \\mathbb{Z}^+$, we construct a finite open cover $\\mathcal{U}_n$ of $X$ with a specific \"smallness\" property relative to $G_n$.\n\n1.  Fix $n$. For each $x \\in X$, we have $(x, x) \\in \\Delta \\subseteq G_n$.\n2.  Since $G_n$ is open in the product topology, there exists an open neighborhood $V_x$ of $x$ in $X$ such that $V_x \\times V_x \\subseteq G_n$.\n3.  The collection $\\{V_x \\mid x \\in X\\}$ covers $X$. Since $X$ is compact, there exists a finite subcover. Let us denote this finite cover by $\\mathcal{U}_n$.\n4.  Property of $\\mathcal{U}_n$: For every $U \\in \\mathcal{U}_n$, $U \\times U \\subseteq G_n$.\n\nLet $\\mathcal{B} = \\bigcup_{n=1}^\\infty \\mathcal{U}_n$. Since each $\\mathcal{U}_n$ is finite, $\\mathcal{B}$ is a countable collection of open sets.\n\n### Step 2.3: Proving $\\mathcal{B}$ forms a Basis\n\nWe claim that for every $x \\in X$ and every open neighborhood $O$ of $x$, there exists a set $U \\in \\mathcal{B}$ such that $x \\in U \\subseteq O$. If this holds, $\\mathcal{B}$ is a basis for $X$.\n\nLet's define the star of $x$ with respect to a cover $\\mathcal{C}$ as $St(x, \\mathcal{C}) = \\bigcup \\{ U \\in \\mathcal{C} \\mid x \\in U \\}$.\n\n**Claim:** The collection $\\{ St(x, \\mathcal{U}_n) \\}_{n \\ge 1}$ forms a neighborhood basis for $x$. That is, for any open $O$ containing $x$, there exists $N$ such that $St(x, \\mathcal{U}_N) \\subseteq O$.\n\n**Proof of Claim (by contradiction):**\n1.  Suppose there exists an open neighborhood $O$ of $x$ such that for all $n$, $St(x, \\mathcal{U}_n) \\not\\subseteq O$.\n2.  Then for each $n$, there exists a point $y_n \\in St(x, \\mathcal{U}_n) \\setminus O$.\n3.  The sequence $(y_n)$ lies in the set $X \\setminus O$, which is closed in the compact space $X$. Therefore, $X \\setminus O$ is compact.\n4.  The sequence $(y_n)$ must have a cluster point $z \\in X \\setminus O$.\n5.  Since $x \\in O$ and $z \\in X \\setminus O$, we have $x \\neq z$. Thus $(x, z) \\notin \\Delta$.\n6.  Consider the relation established by the covers. Since $y_n \\in St(x, \\mathcal{U}_n)$, there exists some $U \\in \\mathcal{U}_n$ such that $x \\in U$ and $y_n \\in U$.\n7.  By the construction of $\\mathcal{U}_n$, $U \\times U \\subseteq G_n$. Therefore, $(x, y_n) \\in G_n$.\n8.  Now, fix an integer $k$. For all $n \\geq k$, we have $(x, y_n) \\in G_n \\subseteq G_k$.\n9.  Since $z$ is a cluster point of $(y_n)$, the point $(x, z)$ is a cluster point of the sequence $((x, y_n))$ in $X \\times X$.\n10. Since all terms $(x, y_n)$ for $n \\ge k$ lie in $G_k$, the cluster point $(x, z)$ must lie in the closure $\\overline{G_k}$.\n11. Recall our construction in Step 2.1: $\\overline{G_{k+1}} \\subseteq G_k$.\n12. Since $(x, z) \\in \\overline{G_{k+1}}$ (applying the logic from step 10 to $k+1$), we have $(x, z) \\in G_k$.\n13. This holds for *all* $k$. Therefore, $(x, z) \\in \\bigcap_{k=1}^\\infty G_k = \\Delta$.\n14. This implies $x = z$.\n15. This contradicts the fact that $x \\in O$ and $z \\in X \\setminus O$.\n\nTherefore, the assumption was false. There exists some $N$ such that $St(x, \\mathcal{U}_N) \\subseteq O$.\n\n**Conclusion of Step 2.3:**\nSince $St(x, \\mathcal{U}_N)$ is a union of finitely many sets from $\\mathcal{U}_N$ (all of which contain $x$), any single $U \\in \\mathcal{U}_N$ containing $x$ satisfies $x \\in U \\subseteq St(x, \\mathcal{U}_N) \\subseteq O$. Since $U \\in \\mathcal{U}_N \\subset \\mathcal{B}$, we have found a basis element inside $O$ containing $x$. Thus, $\\mathcal{B}$ is a countable basis for the topology of $X$.\n\n### Step 2.4: Final Conclusion\n\n1.  $X$ is a compact Hausdorff space.\n2.  We have shown that if $\\Delta$ is a $G_\\delta$ set, then $X$ admits a countable basis (is second-countable).\n3.  By the Urysohn Metrization Theorem (or the specific version for compact spaces: A compact Hausdorff space is metrizable iff it is second-countable), $X$ is metrizable.\n\nThus, both directions are proven.\n\n**Q.E.D.**",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $X = S^1 \\vee S^1$ be the wedge sum of two circles, where the wedge point is $x_0$. Compute $\\pi_1(X, x_0)$.",
    "run_id": "39",
    "outer_attempt": 1,
    "topic_slug": "algebraic_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To compute the fundamental group of the wedge sum of two circles $X = S^1 \\vee S^1$, we will apply the **Seifert-van Kampen Theorem**.\n\n### 1. Geometric Setup and Decomposition\n\nLet the two circles comprising $X$ be denoted by $C_a$ and $C_b$. They are joined at the single wedge point $x_0$.\n$$ X = C_a \\cup C_b, \\quad C_a \\cap C_b = \\{x_0\\} $$\n\nTo apply the Seifert-van Kampen theorem, we must choose two open, path-connected subsets $U$ and $V$ such that $X = U \\cup V$ and their intersection $U \\cap V$ is also path-connected and contains the basepoint $x_0$.\n\nWe define appropriate open neighborhoods as follows:\n1.  Let $U$ be the union of the circle $C_a$ and a small open arc of $C_b$ containing $x_0$.\n2.  Let $V$ be the union of the circle $C_b$ and a small open arc of $C_a$ containing $x_0$.\n\n### 2. Homotopy Types of the Subsets\n\nWe analyze the homotopy type and fundamental group of each subset:\n\n*   **Subset $U$:** The small arc of $C_b$ included in $U$ can be continuously retracted to the point $x_0$. Thus, $U$ deformation retracts onto the circle $C_a$.\n    $$ U \\simeq S^1 \\implies \\pi_1(U, x_0) \\cong \\pi_1(S^1, x_0) \\cong \\mathbb{Z} $$\n    Let this group be generated by the loop $a$ traversing $C_a$. So, $\\pi_1(U, x_0) = \\langle a \\rangle$.\n\n*   **Subset $V$:** Similarly, the small arc of $C_a$ included in $V$ retracts to $x_0$. Thus, $V$ deformation retracts onto the circle $C_b$.\n    $$ V \\simeq S^1 \\implies \\pi_1(V, x_0) \\cong \\pi_1(S^1, x_0) \\cong \\mathbb{Z} $$\n    Let this group be generated by the loop $b$ traversing $C_b$. So, $\\pi_1(V, x_0) = \\langle b \\rangle$.\n\n*   **Intersection $U \\cap V$:** The intersection consists of the small open arc from $C_a$ and the small open arc from $C_b$, crossing at $x_0$. This space is topologically a cross (homeomorphic to the union of two open intervals intersecting at a single point). This space is contractible (it deformation retracts to the single point $x_0$).\n    $$ U \\cap V \\simeq \\{x_0\\} \\implies \\pi_1(U \\cap V, x_0) \\cong \\{1\\} $$\n    The fundamental group of the intersection is the trivial group.\n\n### 3. Applying the Seifert-van Kampen Theorem\n\nThe Seifert-van Kampen theorem states that $\\pi_1(X, x_0)$ is the free product of $\\pi_1(U, x_0)$ and $\\pi_1(V, x_0)$ amalgamated over $\\pi_1(U \\cap V, x_0)$.\n\n$$ \\pi_1(X, x_0) \\cong \\pi_1(U, x_0) *_{\\pi_1(U \\cap V, x_0)} \\pi_1(V, x_0) $$\n\nLet $i_U: U \\cap V \\hookrightarrow U$ and $i_V: U \\cap V \\hookrightarrow V$ be the inclusion maps. The induced homomorphisms on the fundamental groups are maps from the trivial group $\\{1\\}$ to $\\mathbb{Z}$. The amalgamation is trivial because the group being amalgamated is trivial.\n\nTherefore, the fundamental group is simply the free product of the groups:\n$$ \\pi_1(X, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} $$\n\n### 4. Conclusion\n\nThe group $\\mathbb{Z} * \\mathbb{Z}$ is the **free group on two generators**. If we denote the generator corresponding to the loop around the first circle as $a$ and the generator corresponding to the loop around the second circle as $b$, the fundamental group consists of all reduced words formed by letters $a, b, a^{-1}, b^{-1}$.\n\n**Final Answer:**\nThe fundamental group of the wedge sum of two circles is the free group on two generators, denoted as $F_2$ or $\\mathbb{Z} * \\mathbb{Z}$.\n$$ \\pi_1(S^1 \\vee S^1, x_0) \\cong \\langle a, b \\rangle \\cong \\mathbb{Z} * \\mathbb{Z} $$",
        "raw_answer": "To compute the fundamental group of the wedge sum of two circles $X = S^1 \\vee S^1$, we will apply the **Seifert-van Kampen Theorem**.\n\n### 1. Geometric Setup and Decomposition\n\nLet the two circles comprising $X$ be denoted by $C_a$ and $C_b$. They are joined at the single wedge point $x_0$.\n$$ X = C_a \\cup C_b, \\quad C_a \\cap C_b = \\{x_0\\} $$\n\nTo apply the Seifert-van Kampen theorem, we must choose two open, path-connected subsets $U$ and $V$ such that $X = U \\cup V$ and their intersection $U \\cap V$ is also path-connected and contains the basepoint $x_0$.\n\nWe define appropriate open neighborhoods as follows:\n1.  Let $U$ be the union of the circle $C_a$ and a small open arc of $C_b$ containing $x_0$.\n2.  Let $V$ be the union of the circle $C_b$ and a small open arc of $C_a$ containing $x_0$.\n\n### 2. Homotopy Types of the Subsets\n\nWe analyze the homotopy type and fundamental group of each subset:\n\n*   **Subset $U$:** The small arc of $C_b$ included in $U$ can be continuously retracted to the point $x_0$. Thus, $U$ deformation retracts onto the circle $C_a$.\n    $$ U \\simeq S^1 \\implies \\pi_1(U, x_0) \\cong \\pi_1(S^1, x_0) \\cong \\mathbb{Z} $$\n    Let this group be generated by the loop $a$ traversing $C_a$. So, $\\pi_1(U, x_0) = \\langle a \\rangle$.\n\n*   **Subset $V$:** Similarly, the small arc of $C_a$ included in $V$ retracts to $x_0$. Thus, $V$ deformation retracts onto the circle $C_b$.\n    $$ V \\simeq S^1 \\implies \\pi_1(V, x_0) \\cong \\pi_1(S^1, x_0) \\cong \\mathbb{Z} $$\n    Let this group be generated by the loop $b$ traversing $C_b$. So, $\\pi_1(V, x_0) = \\langle b \\rangle$.\n\n*   **Intersection $U \\cap V$:** The intersection consists of the small open arc from $C_a$ and the small open arc from $C_b$, crossing at $x_0$. This space is topologically a cross (homeomorphic to the union of two open intervals intersecting at a single point). This space is contractible (it deformation retracts to the single point $x_0$).\n    $$ U \\cap V \\simeq \\{x_0\\} \\implies \\pi_1(U \\cap V, x_0) \\cong \\{1\\} $$\n    The fundamental group of the intersection is the trivial group.\n\n### 3. Applying the Seifert-van Kampen Theorem\n\nThe Seifert-van Kampen theorem states that $\\pi_1(X, x_0)$ is the free product of $\\pi_1(U, x_0)$ and $\\pi_1(V, x_0)$ amalgamated over $\\pi_1(U \\cap V, x_0)$.\n\n$$ \\pi_1(X, x_0) \\cong \\pi_1(U, x_0) *_{\\pi_1(U \\cap V, x_0)} \\pi_1(V, x_0) $$\n\nLet $i_U: U \\cap V \\hookrightarrow U$ and $i_V: U \\cap V \\hookrightarrow V$ be the inclusion maps. The induced homomorphisms on the fundamental groups are maps from the trivial group $\\{1\\}$ to $\\mathbb{Z}$. The amalgamation is trivial because the group being amalgamated is trivial.\n\nTherefore, the fundamental group is simply the free product of the groups:\n$$ \\pi_1(X, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} $$\n\n### 4. Conclusion\n\nThe group $\\mathbb{Z} * \\mathbb{Z}$ is the **free group on two generators**. If we denote the generator corresponding to the loop around the first circle as $a$ and the generator corresponding to the loop around the second circle as $b$, the fundamental group consists of all reduced words formed by letters $a, b, a^{-1}, b^{-1}$.\n\n**Final Answer:**\nThe fundamental group of the wedge sum of two circles is the free group on two generators, denoted as $F_2$ or $\\mathbb{Z} * \\mathbb{Z}$.\n$$ \\pi_1(S^1 \\vee S^1, x_0) \\cong \\langle a, b \\rangle \\cong \\mathbb{Z} * \\mathbb{Z} $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Manifolds and cell complexes\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within the domain\nA suitable topic within \"Manifolds and cell complexes\" could involve the properties or constructions related to manifolds or cell complexes, such as their topology, geometry, or algebraic invariants.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the Euler characteristic of a manifold, which is a fundamental concept in algebraic topology that relates to both manifolds and cell complexes. The Euler characteristic is a topological invariant that can be computed using a cell decomposition of a manifold.\n\n## Step 4: Construct the problem statement\nConsider a 2-dimensional manifold $M$ that is homeomorphic to a sphere with $g$ handles (i.e., a surface of genus $g$). The task is to prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.\n\n## Step 5: Provide the problem statement in the required format\n\nLet $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles. Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.",
    "run_id": "40",
    "outer_attempt": 1,
    "topic_slug": "manifolds_and_cell_complexes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the comprehensive solution to the problem.\n\n### Problem Statement\nLet $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles (an orientable surface of genus $g$). Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.\n\n---\n\n### Solution\n\nTo prove this result, we will construct a specific cell decomposition (CW-complex structure) for the surface $M$ and calculate the Euler characteristic using the definition $\\chi(M) = V - E + F$, where $V, E,$ and $F$ correspond to the number of 0-cells (vertices), 1-cells (edges), and 2-cells (faces), respectively.\n\nWe treat the cases $g=0$ and $g \\geq 1$ separately to ensure rigor, although the formula holds for both.\n\n#### Case 1: The Sphere ($g=0$)\nA sphere with 0 handles is simply the 2-sphere, $S^2$.\nWe can compute its Euler characteristic using a standard triangulation, such as the boundary of a tetrahedron.\n1.  **Vertices ($V$)**: 4\n2.  **Edges ($E$)**: 6\n3.  **Faces ($F$)**: 4\n\nCalculating $\\chi(S^2)$:\n$$ \\chi(S^2) = V - E + F = 4 - 6 + 4 = 2 $$\nUsing the formula $2 - 2g$ with $g=0$:\n$$ 2 - 2(0) = 2 $$\nThe formula holds for $g=0$.\n\n#### Case 2: Surface of Genus $g \\geq 1$\nFor $g \\geq 1$, the surface $M$ can be constructed as a quotient space of a regular polygon. This is the **standard polygonal presentation** of an orientable surface.\n\n**1. The Polygonal Model**\nA surface of genus $g$ is homeomorphic to the quotient of a regular $4g$-sided polygon $P$ in the Euclidean plane. The edges of the polygon are identified in pairs according to the standard word $W$:\n$$ W = a_1 b_1 a_1^{-1} b_1^{-1} a_2 b_2 a_2^{-1} b_2^{-1} \\dots a_g b_g a_g^{-1} b_g^{-1} $$\nHere, each letter represents an edge of the polygon. The exponent $-1$ indicates that the edge is traversed in the direction opposite to the boundary orientation.\n\n**2. Cell Decomposition**\nWe define a CW-complex structure on $M$ induced by this identification:\n*   **Faces ($F$):** The interior of the polygon $P$ forms a single 2-cell. Thus, $F = 1$.\n*   **Edges ($E$):** The boundary of the polygon consists of $4g$ edges. The identification word pairs every edge $x$ with a corresponding edge $x^{-1}$. Since every edge is identified with exactly one other edge, the number of distinct 1-cells in the quotient is:\n    $$ E = \\frac{4g}{2} = 2g $$\n\n**3. Vertices ($V$):**\nWe must determine how the vertices of the polygon are identified. Let the vertices of the $4g$-gon be $v_0, v_1, \\dots, v_{4g-1}$ in counterclockwise order.\nConsider the $i$-th handle represented by the sequence of edges $a_i, b_i, a_i^{-1}, b_i^{-1}$. Let the vertices involved in this sequence locally be $p_0, p_1, p_2, p_3, p_4$ such that:\n*   $a_i$ connects $p_0 \\to p_1$\n*   $b_i$ connects $p_1 \\to p_2$\n*   $a_i^{-1}$ connects $p_2 \\to p_3$\n*   $b_i^{-1}$ connects $p_3 \\to p_4$\n\nThe identification of edges dictates the identification of their endpoints:\n1.  **Identify $a_i$ with $a_i^{-1}$:**\n    The edge $a_i$ (directed $p_0 \\to p_1$) is identified with $a_i^{-1}$ (which corresponds to the geometric edge $p_2 \\to p_3$ traversed backwards, i.e., $p_3 \\to p_2$).\n    Therefore, the start of $a_i$ is identified with the start of the traversal of $a_i^{-1}$, and the end with the end.\n    $$ p_0 \\sim p_3 \\quad \\text{and} \\quad p_1 \\sim p_2 $$\n\n2.  **Identify $b_i$ with $b_i^{-1}$:**\n    The edge $b_i$ (directed $p_1 \\to p_2$) is identified with $b_i^{-1}$ (geometric edge $p_3 \\to p_4$ traversed backwards, i.e., $p_4 \\to p_3$).\n    $$ p_1 \\sim p_4 \\quad \\text{and} \\quad p_2 \\sim p_3 $$\n\n**Analyzing the Equivalence Class:**\nCombining these identifications for the $i$-th group:\n*   From $a_i$: $p_1 \\sim p_2$ and $p_0 \\sim p_3$.\n*   From $b_i$: $p_2 \\sim p_3$ and $p_1 \\sim p_4$.\n*   Chaining these: $p_0 \\sim p_3 \\sim p_2 \\sim p_1 \\sim p_4$.\n\nThus, all vertices associated with the $i$-th handle ($p_0$ through $p_4$) are identified to a single point. Since $p_4$ is the starting vertex ($p_0$) of the $(i+1)$-th handle group (or wraps around to the start of the polygon if $i=g$), the equivalence relation propagates through all $g$ groups.\n\nConsequently, all $4g$ vertices of the polygon are identified to a single vertex in the quotient manifold.\n$$ V = 1 $$\n\n**4. Calculation**\nWe now compute the Euler characteristic $\\chi(M)$:\n$$ \\chi(M) = V - E + F $$\nSubstituting the values derived above ($V=1, E=2g, F=1$):\n$$ \\chi(M) = 1 - 2g + 1 $$\n$$ \\chi(M) = 2 - 2g $$\n\n### Alternative Approach: Connected Sums\nWe can also verify this result using the properties of the connected sum operation $\\#$.\nA surface of genus $g$ is the connected sum of $g$ tori: $M_g = T^2 \\# T^2 \\# \\dots \\# T^2$.\nThe Euler characteristic of a connected sum is given by:\n$$ \\chi(A \\# B) = \\chi(A) + \\chi(B) - 2 $$\nWe proceed by induction:\n1.  **Base Case ($g=1$):** For a torus $T^2$, we have the identification $aba^{-1}b^{-1}$. Here $V=1, E=2, F=1$, so $\\chi(T^2) = 1 - 2 + 1 = 0$.\n    Formula: $2 - 2(1) = 0$. (Verified)\n2.  **Inductive Step:** Assume $\\chi(M_{k}) = 2 - 2k$.\n    $$ M_{k+1} = M_k \\# T^2 $$\n    $$ \\chi(M_{k+1}) = \\chi(M_k) + \\chi(T^2) - 2 $$\n    $$ \\chi(M_{k+1}) = (2 - 2k) + 0 - 2 $$\n    $$ \\chi(M_{k+1}) = 2 - 2k - 2 = 2 - 2(k+1) $$\n\nThis confirms the result for all $g \\geq 1$.\n\n### Conclusion\nWe have shown through explicit cell decomposition and the connected sum formula that for a 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles, the Euler characteristic is:\n$$ \\chi(M) = 2 - 2g $$",
        "raw_answer": "Here is the comprehensive solution to the problem.\n\n### Problem Statement\nLet $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles (an orientable surface of genus $g$). Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.\n\n---\n\n### Solution\n\nTo prove this result, we will construct a specific cell decomposition (CW-complex structure) for the surface $M$ and calculate the Euler characteristic using the definition $\\chi(M) = V - E + F$, where $V, E,$ and $F$ correspond to the number of 0-cells (vertices), 1-cells (edges), and 2-cells (faces), respectively.\n\nWe treat the cases $g=0$ and $g \\geq 1$ separately to ensure rigor, although the formula holds for both.\n\n#### Case 1: The Sphere ($g=0$)\nA sphere with 0 handles is simply the 2-sphere, $S^2$.\nWe can compute its Euler characteristic using a standard triangulation, such as the boundary of a tetrahedron.\n1.  **Vertices ($V$)**: 4\n2.  **Edges ($E$)**: 6\n3.  **Faces ($F$)**: 4\n\nCalculating $\\chi(S^2)$:\n$$ \\chi(S^2) = V - E + F = 4 - 6 + 4 = 2 $$\nUsing the formula $2 - 2g$ with $g=0$:\n$$ 2 - 2(0) = 2 $$\nThe formula holds for $g=0$.\n\n#### Case 2: Surface of Genus $g \\geq 1$\nFor $g \\geq 1$, the surface $M$ can be constructed as a quotient space of a regular polygon. This is the **standard polygonal presentation** of an orientable surface.\n\n**1. The Polygonal Model**\nA surface of genus $g$ is homeomorphic to the quotient of a regular $4g$-sided polygon $P$ in the Euclidean plane. The edges of the polygon are identified in pairs according to the standard word $W$:\n$$ W = a_1 b_1 a_1^{-1} b_1^{-1} a_2 b_2 a_2^{-1} b_2^{-1} \\dots a_g b_g a_g^{-1} b_g^{-1} $$\nHere, each letter represents an edge of the polygon. The exponent $-1$ indicates that the edge is traversed in the direction opposite to the boundary orientation.\n\n**2. Cell Decomposition**\nWe define a CW-complex structure on $M$ induced by this identification:\n*   **Faces ($F$):** The interior of the polygon $P$ forms a single 2-cell. Thus, $F = 1$.\n*   **Edges ($E$):** The boundary of the polygon consists of $4g$ edges. The identification word pairs every edge $x$ with a corresponding edge $x^{-1}$. Since every edge is identified with exactly one other edge, the number of distinct 1-cells in the quotient is:\n    $$ E = \\frac{4g}{2} = 2g $$\n\n**3. Vertices ($V$):**\nWe must determine how the vertices of the polygon are identified. Let the vertices of the $4g$-gon be $v_0, v_1, \\dots, v_{4g-1}$ in counterclockwise order.\nConsider the $i$-th handle represented by the sequence of edges $a_i, b_i, a_i^{-1}, b_i^{-1}$. Let the vertices involved in this sequence locally be $p_0, p_1, p_2, p_3, p_4$ such that:\n*   $a_i$ connects $p_0 \\to p_1$\n*   $b_i$ connects $p_1 \\to p_2$\n*   $a_i^{-1}$ connects $p_2 \\to p_3$\n*   $b_i^{-1}$ connects $p_3 \\to p_4$\n\nThe identification of edges dictates the identification of their endpoints:\n1.  **Identify $a_i$ with $a_i^{-1}$:**\n    The edge $a_i$ (directed $p_0 \\to p_1$) is identified with $a_i^{-1}$ (which corresponds to the geometric edge $p_2 \\to p_3$ traversed backwards, i.e., $p_3 \\to p_2$).\n    Therefore, the start of $a_i$ is identified with the start of the traversal of $a_i^{-1}$, and the end with the end.\n    $$ p_0 \\sim p_3 \\quad \\text{and} \\quad p_1 \\sim p_2 $$\n\n2.  **Identify $b_i$ with $b_i^{-1}$:**\n    The edge $b_i$ (directed $p_1 \\to p_2$) is identified with $b_i^{-1}$ (geometric edge $p_3 \\to p_4$ traversed backwards, i.e., $p_4 \\to p_3$).\n    $$ p_1 \\sim p_4 \\quad \\text{and} \\quad p_2 \\sim p_3 $$\n\n**Analyzing the Equivalence Class:**\nCombining these identifications for the $i$-th group:\n*   From $a_i$: $p_1 \\sim p_2$ and $p_0 \\sim p_3$.\n*   From $b_i$: $p_2 \\sim p_3$ and $p_1 \\sim p_4$.\n*   Chaining these: $p_0 \\sim p_3 \\sim p_2 \\sim p_1 \\sim p_4$.\n\nThus, all vertices associated with the $i$-th handle ($p_0$ through $p_4$) are identified to a single point. Since $p_4$ is the starting vertex ($p_0$) of the $(i+1)$-th handle group (or wraps around to the start of the polygon if $i=g$), the equivalence relation propagates through all $g$ groups.\n\nConsequently, all $4g$ vertices of the polygon are identified to a single vertex in the quotient manifold.\n$$ V = 1 $$\n\n**4. Calculation**\nWe now compute the Euler characteristic $\\chi(M)$:\n$$ \\chi(M) = V - E + F $$\nSubstituting the values derived above ($V=1, E=2g, F=1$):\n$$ \\chi(M) = 1 - 2g + 1 $$\n$$ \\chi(M) = 2 - 2g $$\n\n### Alternative Approach: Connected Sums\nWe can also verify this result using the properties of the connected sum operation $\\#$.\nA surface of genus $g$ is the connected sum of $g$ tori: $M_g = T^2 \\# T^2 \\# \\dots \\# T^2$.\nThe Euler characteristic of a connected sum is given by:\n$$ \\chi(A \\# B) = \\chi(A) + \\chi(B) - 2 $$\nWe proceed by induction:\n1.  **Base Case ($g=1$):** For a torus $T^2$, we have the identification $aba^{-1}b^{-1}$. Here $V=1, E=2, F=1$, so $\\chi(T^2) = 1 - 2 + 1 = 0$.\n    Formula: $2 - 2(1) = 0$. (Verified)\n2.  **Inductive Step:** Assume $\\chi(M_{k}) = 2 - 2k$.\n    $$ M_{k+1} = M_k \\# T^2 $$\n    $$ \\chi(M_{k+1}) = \\chi(M_k) + \\chi(T^2) - 2 $$\n    $$ \\chi(M_{k+1}) = (2 - 2k) + 0 - 2 $$\n    $$ \\chi(M_{k+1}) = 2 - 2k - 2 = 2 - 2(k+1) $$\n\nThis confirms the result for all $g \\geq 1$.\n\n### Conclusion\nWe have shown through explicit cell decomposition and the connected sum formula that for a 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles, the Euler characteristic is:\n$$ \\chi(M) = 2 - 2g $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Global analysis, analysis on manifolds\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify key concepts in the domain\nGlobal analysis and analysis on manifolds involve the study of geometric and topological properties of manifolds using analytical techniques. Key concepts include differential forms, integration on manifolds, Stokes' theorem, and the study of differential equations on manifolds.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to identify a specific concept or technique within global analysis or analysis on manifolds that can be used to formulate a challenging yet solvable question. One such concept is the application of Stokes' theorem, which relates the integral of a differential form over a manifold to the integral of its exterior derivative over the boundary of the manifold.\n\n## Step 4: Construct the problem\nLet's consider a specific manifold and a differential form. A common example is the unit sphere $S^2$ in $\\mathbb{R}^3$. We can formulate a problem involving the integration of a differential form over $S^2$ and applying Stokes' theorem.\n\n## Step 5: Specify the problem\nLet $\\omega = y \\, dx \\wedge dz$ be a 2-form on $\\mathbb{R}^3$. Consider the unit sphere $S^2 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 = 1 \\}$ oriented with the outward unit normal. Evaluate $\\int_{S^2} \\omega$.\n\n## Step 6: Provide the solution\nTo solve this, we can directly integrate $\\omega$ over $S^2$ or apply Stokes' theorem. Stokes' theorem states that $\\int_M d\\omega = \\int_{\\partial M} \\omega$, where $M$ is a manifold with boundary $\\partial M$. Here, we can consider $M = B^3 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 \\leq 1 \\}$, so $\\partial M = S^2$.\n\n## Step 7: Calculate $d\\omega$\n$d\\omega = d(y \\, dx \\wedge dz) = dy \\wedge dx \\wedge dz = -dx \\wedge dy \\wedge dz$ because $d(y) = dy$, $d(dx) = 0$, and $d(dz) = 0$. So, $d\\omega = -dx \\wedge dy \\wedge dz$.\n\n## Step 8: Apply Stokes' theorem\n$\\int_{S^2} \\omega = \\int_{B^3} d\\omega = \\int_{B^3} -dx \\wedge dy \\wedge dz = -\\int_{B^3} dV$, where $dV = dx \\wedge dy \\wedge dz$ is the volume form on $\\mathbb{R}^3$. Thus, $\\int_{S^2} \\omega = -\\text{Vol}(B^3)$.\n\n## Step 9: Calculate the volume of $B^3$\nThe volume of the unit ball $B^3$ is given by $\\frac{4}{3}\\pi(1)^3 = \\frac{4}{3}\\pi$.\n\n## Step 10: Conclude the solution\n$\\int_{S^2} \\omega = -\\frac{4}{3}\\pi$.\n\nThe final answer is: \n\nLet $\\omega = y \\, dx \\wedge dz$ be a 2-form on $\\mathbb{R}^3$. Consider the unit sphere $S^2 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 = 1 \\}$ oriented with the outward unit normal. Evaluate $\\int_{S^2} \\omega$.",
    "run_id": "41",
    "outer_attempt": 1,
    "topic_slug": "global_analysis_on_manifolds",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete solution to the problem presented.\n\n**Problem Statement**\nLet $\\omega = y \\, dx \\wedge dz$ be a 2-form on $\\mathbb{R}^3$. Consider the unit sphere $S^2 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 = 1 \\}$ oriented with the outward unit normal. Evaluate the integral:\n$$ I = \\int_{S^2} \\omega $$\n\n### Solution\n\nWe will evaluate this integral using Stokes' Theorem, which relates the integral of a differential form over the boundary of a manifold to the integral of its exterior derivative over the manifold itself.\n\n**1. Setup and Stokes' Theorem**\nLet $B^3$ be the closed unit ball in $\\mathbb{R}^3$, defined by $B^3 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 \\leq 1 \\}$.\nThe boundary of $B^3$ is the unit sphere $S^2$, i.e., $\\partial B^3 = S^2$.\n\nThe standard orientation of $\\mathbb{R}^3$ is given by the volume form $dV = dx \\wedge dy \\wedge dz$. The induced orientation on the boundary $\\partial B^3$ is the outward unit normal, which matches the orientation specified for $S^2$ in the problem.\n\nStokes' Theorem states:\n$$ \\int_{\\partial M} \\omega = \\int_{M} d\\omega $$\nSubstituting our manifold and form:\n$$ \\int_{S^2} \\omega = \\int_{B^3} d\\omega $$\n\n**2. Calculating the Exterior Derivative**\nWe calculate the exterior derivative $d\\omega$ of the 2-form $\\omega = y \\, dx \\wedge dz$.\n$$ d\\omega = d(y \\, dx \\wedge dz) $$\nUsing the properties of the exterior derivative (linearity and the product rule $d(f \\eta) = df \\wedge \\eta + f \\, d\\eta$):\n$$ d\\omega = dy \\wedge (dx \\wedge dz) + y \\, d(dx \\wedge dz) $$\nSince $d(dx) = 0$ and $d(dz) = 0$, the second term vanishes. Thus:\n$$ d\\omega = dy \\wedge dx \\wedge dz $$\nTo align this with the standard volume form $dx \\wedge dy \\wedge dz$, we use the anticommutativity property of the wedge product ($du \\wedge dv = -dv \\wedge du$). Swapping $dy$ and $dx$:\n$$ dy \\wedge dx = -dx \\wedge dy $$\nTherefore:\n$$ d\\omega = -dx \\wedge dy \\wedge dz $$\n\n**3. Evaluating the Integral**\nSubstitute $d\\omega$ back into the integral over the ball $B^3$:\n$$ I = \\int_{B^3} (-dx \\wedge dy \\wedge dz) = -\\int_{B^3} dx \\wedge dy \\wedge dz $$\nThe integral $\\int_{B^3} dx \\wedge dy \\wedge dz$ represents the volume of the unit ball $B^3$.\n\nThe volume $V$ of a ball of radius $r$ is given by $V = \\frac{4}{3}\\pi r^3$.\nFor the unit ball ($r=1$):\n$$ \\text{Vol}(B^3) = \\frac{4}{3}\\pi (1)^3 = \\frac{4}{3}\\pi $$\n\nSubstituting this volume into our expression for $I$:\n$$ I = - \\left( \\frac{4}{3}\\pi \\right) $$\n\n**4. Alternative Verification (Direct Parameterization)**\nTo ensure rigor, we verify the result using spherical coordinates parametrization.\nLet $x = \\sin\\phi \\cos\\theta$, $y = \\sin\\phi \\sin\\theta$, $z = \\cos\\phi$, where $\\phi \\in [0, \\pi]$ and $\\theta \\in [0, 2\\pi]$.\nWe compute the pullback of $\\omega = y \\, dx \\wedge dz$.\n$$ y = \\sin\\phi \\sin\\theta $$\n$$ dx = \\cos\\phi \\cos\\theta \\, d\\phi - \\sin\\phi \\sin\\theta \\, d\\theta $$\n$$ dz = -\\sin\\phi \\, d\\phi $$\n$$ dx \\wedge dz = (\\cos\\phi \\cos\\theta \\, d\\phi - \\sin\\phi \\sin\\theta \\, d\\theta) \\wedge (-\\sin\\phi \\, d\\phi) $$\nSince $d\\phi \\wedge d\\phi = 0$, only the term with $d\\theta \\wedge d\\phi$ remains:\n$$ dx \\wedge dz = (-\\sin\\phi \\sin\\theta \\, d\\theta) \\wedge (-\\sin\\phi \\, d\\phi) = \\sin^2\\phi \\sin\\theta \\, d\\theta \\wedge d\\phi $$\nUsing $d\\theta \\wedge d\\phi = -d\\phi \\wedge d\\theta$:\n$$ dx \\wedge dz = -\\sin^2\\phi \\sin\\theta \\, d\\phi \\wedge d\\theta $$\nNow substitute into $\\omega$:\n$$ \\omega = (\\sin\\phi \\sin\\theta)(-\\sin^2\\phi \\sin\\theta \\, d\\phi \\wedge d\\theta) = -\\sin^3\\phi \\sin^2\\theta \\, d\\phi \\wedge d\\theta $$\nIntegrating over the domain:\n$$ \\int_{S^2} \\omega = \\int_{0}^{2\\pi} \\int_{0}^{\\pi} -\\sin^3\\phi \\sin^2\\theta \\, d\\phi \\, d\\theta $$\n$$ = - \\left( \\int_{0}^{\\pi} \\sin^3\\phi \\, d\\phi \\right) \\left( \\int_{0}^{2\\pi} \\sin^2\\theta \\, d\\theta \\right) $$\nUsing standard integral results $\\int_{0}^{\\pi} \\sin^3\\phi \\, d\\phi = \\frac{4}{3}$ and $\\int_{0}^{2\\pi} \\sin^2\\theta \\, d\\theta = \\pi$:\n$$ \\int_{S^2} \\omega = - \\left( \\frac{4}{3} \\right) (\\pi) = -\\frac{4}{3}\\pi $$\nThe direct calculation confirms the result derived via Stokes' Theorem.\n\n### Final Conclusion\nThe value of the integral is:\n$$ \\int_{S^2} \\omega = -\\frac{4}{3}\\pi $$",
        "raw_answer": "Here is the complete solution to the problem presented.\n\n**Problem Statement**\nLet $\\omega = y \\, dx \\wedge dz$ be a 2-form on $\\mathbb{R}^3$. Consider the unit sphere $S^2 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 = 1 \\}$ oriented with the outward unit normal. Evaluate the integral:\n$$ I = \\int_{S^2} \\omega $$\n\n### Solution\n\nWe will evaluate this integral using Stokes' Theorem, which relates the integral of a differential form over the boundary of a manifold to the integral of its exterior derivative over the manifold itself.\n\n**1. Setup and Stokes' Theorem**\nLet $B^3$ be the closed unit ball in $\\mathbb{R}^3$, defined by $B^3 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 \\leq 1 \\}$.\nThe boundary of $B^3$ is the unit sphere $S^2$, i.e., $\\partial B^3 = S^2$.\n\nThe standard orientation of $\\mathbb{R}^3$ is given by the volume form $dV = dx \\wedge dy \\wedge dz$. The induced orientation on the boundary $\\partial B^3$ is the outward unit normal, which matches the orientation specified for $S^2$ in the problem.\n\nStokes' Theorem states:\n$$ \\int_{\\partial M} \\omega = \\int_{M} d\\omega $$\nSubstituting our manifold and form:\n$$ \\int_{S^2} \\omega = \\int_{B^3} d\\omega $$\n\n**2. Calculating the Exterior Derivative**\nWe calculate the exterior derivative $d\\omega$ of the 2-form $\\omega = y \\, dx \\wedge dz$.\n$$ d\\omega = d(y \\, dx \\wedge dz) $$\nUsing the properties of the exterior derivative (linearity and the product rule $d(f \\eta) = df \\wedge \\eta + f \\, d\\eta$):\n$$ d\\omega = dy \\wedge (dx \\wedge dz) + y \\, d(dx \\wedge dz) $$\nSince $d(dx) = 0$ and $d(dz) = 0$, the second term vanishes. Thus:\n$$ d\\omega = dy \\wedge dx \\wedge dz $$\nTo align this with the standard volume form $dx \\wedge dy \\wedge dz$, we use the anticommutativity property of the wedge product ($du \\wedge dv = -dv \\wedge du$). Swapping $dy$ and $dx$:\n$$ dy \\wedge dx = -dx \\wedge dy $$\nTherefore:\n$$ d\\omega = -dx \\wedge dy \\wedge dz $$\n\n**3. Evaluating the Integral**\nSubstitute $d\\omega$ back into the integral over the ball $B^3$:\n$$ I = \\int_{B^3} (-dx \\wedge dy \\wedge dz) = -\\int_{B^3} dx \\wedge dy \\wedge dz $$\nThe integral $\\int_{B^3} dx \\wedge dy \\wedge dz$ represents the volume of the unit ball $B^3$.\n\nThe volume $V$ of a ball of radius $r$ is given by $V = \\frac{4}{3}\\pi r^3$.\nFor the unit ball ($r=1$):\n$$ \\text{Vol}(B^3) = \\frac{4}{3}\\pi (1)^3 = \\frac{4}{3}\\pi $$\n\nSubstituting this volume into our expression for $I$:\n$$ I = - \\left( \\frac{4}{3}\\pi \\right) $$\n\n**4. Alternative Verification (Direct Parameterization)**\nTo ensure rigor, we verify the result using spherical coordinates parametrization.\nLet $x = \\sin\\phi \\cos\\theta$, $y = \\sin\\phi \\sin\\theta$, $z = \\cos\\phi$, where $\\phi \\in [0, \\pi]$ and $\\theta \\in [0, 2\\pi]$.\nWe compute the pullback of $\\omega = y \\, dx \\wedge dz$.\n$$ y = \\sin\\phi \\sin\\theta $$\n$$ dx = \\cos\\phi \\cos\\theta \\, d\\phi - \\sin\\phi \\sin\\theta \\, d\\theta $$\n$$ dz = -\\sin\\phi \\, d\\phi $$\n$$ dx \\wedge dz = (\\cos\\phi \\cos\\theta \\, d\\phi - \\sin\\phi \\sin\\theta \\, d\\theta) \\wedge (-\\sin\\phi \\, d\\phi) $$\nSince $d\\phi \\wedge d\\phi = 0$, only the term with $d\\theta \\wedge d\\phi$ remains:\n$$ dx \\wedge dz = (-\\sin\\phi \\sin\\theta \\, d\\theta) \\wedge (-\\sin\\phi \\, d\\phi) = \\sin^2\\phi \\sin\\theta \\, d\\theta \\wedge d\\phi $$\nUsing $d\\theta \\wedge d\\phi = -d\\phi \\wedge d\\theta$:\n$$ dx \\wedge dz = -\\sin^2\\phi \\sin\\theta \\, d\\phi \\wedge d\\theta $$\nNow substitute into $\\omega$:\n$$ \\omega = (\\sin\\phi \\sin\\theta)(-\\sin^2\\phi \\sin\\theta \\, d\\phi \\wedge d\\theta) = -\\sin^3\\phi \\sin^2\\theta \\, d\\phi \\wedge d\\theta $$\nIntegrating over the domain:\n$$ \\int_{S^2} \\omega = \\int_{0}^{2\\pi} \\int_{0}^{\\pi} -\\sin^3\\phi \\sin^2\\theta \\, d\\phi \\, d\\theta $$\n$$ = - \\left( \\int_{0}^{\\pi} \\sin^3\\phi \\, d\\phi \\right) \\left( \\int_{0}^{2\\pi} \\sin^2\\theta \\, d\\theta \\right) $$\nUsing standard integral results $\\int_{0}^{\\pi} \\sin^3\\phi \\, d\\phi = \\frac{4}{3}$ and $\\int_{0}^{2\\pi} \\sin^2\\theta \\, d\\theta = \\pi$:\n$$ \\int_{S^2} \\omega = - \\left( \\frac{4}{3} \\right) (\\pi) = -\\frac{4}{3}\\pi $$\nThe direct calculation confirms the result derived via Stokes' Theorem.\n\n### Final Conclusion\nThe value of the integral is:\n$$ \\int_{S^2} \\omega = -\\frac{4}{3}\\pi $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $X$ and $Y$ be independent random variables with $X \\sim \\text{Exp}(\\lambda)$ and $Y \\sim \\text{Exp}(\\mu)$, where $\\lambda > 0$ and $\\mu > 0$ are the rate parameters. Define $Z = \\min(X, Y)$. Derive the probability density function (pdf) of $Z$ and compute $\\mathbb{E}[Z]$.",
    "run_id": "42",
    "outer_attempt": 1,
    "topic_slug": "probability_theory_and_stochastic_processes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We define the random variables $X$ and $Y$ with the following properties:\n*   $X \\sim \\text{Exp}(\\lambda)$ with pdf $f_X(x) = \\lambda e^{-\\lambda x}$ for $x \\ge 0$.\n*   $Y \\sim \\text{Exp}(\\mu)$ with pdf $f_Y(y) = \\mu e^{-\\mu y}$ for $y \\ge 0$.\n*   $X$ and $Y$ are independent.\n*   $\\lambda > 0$ and $\\mu > 0$.\n\nWe seek the probability density function (pdf) of $Z = \\min(X, Y)$ and its expected value $\\mathbb{E}[Z]$.\n\n### 1. Derivation of the PDF of $Z$\n\nFirst, we determine the cumulative distribution function (CDF) of $Z$, denoted as $F_Z(z) = P(Z \\le z)$. It is mathematically more convenient to work with the complementary CDF (also known as the survival function), $P(Z > z)$.\n\nBy the definition of the minimum, $Z > z$ if and only if both $X > z$ and $Y > z$. Therefore:\n$$ P(Z > z) = P(\\min(X, Y) > z) = P(X > z \\text{ and } Y > z) $$\n\nSince $X$ and $Y$ are independent random variables, the probability of the intersection of events is the product of their individual probabilities:\n$$ P(X > z \\text{ and } Y > z) = P(X > z) \\cdot P(Y > z) $$\n\nWe calculate the survival functions for $X$ and $Y$. For $z \\ge 0$:\n$$ P(X > z) = \\int_{z}^{\\infty} \\lambda e^{-\\lambda x} \\, dx = \\left[ -e^{-\\lambda x} \\right]_{z}^{\\infty} = e^{-\\lambda z} $$\n$$ P(Y > z) = \\int_{z}^{\\infty} \\mu e^{-\\mu y} \\, dy = \\left[ -e^{-\\mu y} \\right]_{z}^{\\infty} = e^{-\\mu z} $$\nFor $z < 0$, the probabilities are $1$ since exponential random variables are non-negative.\n\nSubstituting these back into the expression for $P(Z > z)$ for $z \\ge 0$:\n$$ P(Z > z) = e^{-\\lambda z} \\cdot e^{-\\mu z} = e^{-(\\lambda + \\mu) z} $$\n\nNow, we find the CDF $F_Z(z)$:\n$$ F_Z(z) = 1 - P(Z > z) = \\begin{cases} 1 - e^{-(\\lambda + \\mu) z} & \\text{for } z \\ge 0 \\\\ 0 & \\text{for } z < 0 \\end{cases} $$\n\nThe probability density function $f_Z(z)$ is the derivative of the CDF with respect to $z$.\nFor $z \\ge 0$:\n$$ f_Z(z) = \\frac{d}{dz} \\left( 1 - e^{-(\\lambda + \\mu) z} \\right) = (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} $$\nFor $z < 0$, $f_Z(z) = 0$.\n\nThus, the pdf of $Z$ is:\n$$ f_Z(z) = \\begin{cases} (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} & z \\ge 0 \\\\ 0 & z < 0 \\end{cases} $$\n\nThis indicates that $Z$ follows an exponential distribution with rate parameter $\\lambda + \\mu$.\n$$ Z \\sim \\text{Exp}(\\lambda + \\mu) $$\n\n### 2. Computation of $\\mathbb{E}[Z]$\n\nSince we have identified that $Z \\sim \\text{Exp}(\\lambda + \\mu)$, we can utilize the standard property of the exponential distribution. For a random variable $T \\sim \\text{Exp}(r)$, the expected value is $\\mathbb{E}[T] = \\frac{1}{r}$.\n\nHere, the rate parameter is $r = \\lambda + \\mu$. Therefore:\n$$ \\mathbb{E}[Z] = \\frac{1}{\\lambda + \\mu} $$\n\n**Alternative derivation via integration:**\nWe compute the expectation directly using the definition $\\mathbb{E}[Z] = \\int_{-\\infty}^{\\infty} z f_Z(z) \\, dz$.\n$$ \\mathbb{E}[Z] = \\int_{0}^{\\infty} z (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} \\, dz $$\nLet $k = \\lambda + \\mu$. Then $\\mathbb{E}[Z] = k \\int_{0}^{\\infty} z e^{-k z} \\, dz$.\nUsing integration by parts, let $u = z$ and $dv = e^{-kz} dz$. Then $du = dz$ and $v = -\\frac{1}{k}e^{-kz}$.\n$$ \\int_{0}^{\\infty} z e^{-k z} \\, dz = \\left[ -\\frac{z}{k} e^{-kz} \\right]_{0}^{\\infty} - \\int_{0}^{\\infty} \\left(-\\frac{1}{k} e^{-kz}\\right) \\, dz $$\nThe boundary term $\\left[ -\\frac{z}{k} e^{-kz} \\right]_{0}^{\\infty}$ evaluates to $0$ (since $\\lim_{z \\to \\infty} z e^{-kz} = 0$ for $k > 0$).\nThe remaining integral is:\n$$ \\frac{1}{k} \\int_{0}^{\\infty} e^{-kz} \\, dz = \\frac{1}{k} \\left[ -\\frac{1}{k} e^{-kz} \\right]_{0}^{\\infty} = \\frac{1}{k} \\left( 0 - \\left(-\\frac{1}{k}\\right) \\right) = \\frac{1}{k^2} $$\nSubstituting the integral back into the expression for expectation:\n$$ \\mathbb{E}[Z] = k \\cdot \\frac{1}{k^2} = \\frac{1}{k} = \\frac{1}{\\lambda + \\mu} $$\n\n### Final Answer\n\nThe probability density function of $Z$ is:\n$$ f_Z(z) = \\begin{cases} (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} & z \\ge 0 \\\\ 0 & z < 0 \\end{cases} $$\n\nThe expected value of $Z$ is:\n$$ \\mathbb{E}[Z] = \\frac{1}{\\lambda + \\mu} $$",
        "raw_answer": "We define the random variables $X$ and $Y$ with the following properties:\n*   $X \\sim \\text{Exp}(\\lambda)$ with pdf $f_X(x) = \\lambda e^{-\\lambda x}$ for $x \\ge 0$.\n*   $Y \\sim \\text{Exp}(\\mu)$ with pdf $f_Y(y) = \\mu e^{-\\mu y}$ for $y \\ge 0$.\n*   $X$ and $Y$ are independent.\n*   $\\lambda > 0$ and $\\mu > 0$.\n\nWe seek the probability density function (pdf) of $Z = \\min(X, Y)$ and its expected value $\\mathbb{E}[Z]$.\n\n### 1. Derivation of the PDF of $Z$\n\nFirst, we determine the cumulative distribution function (CDF) of $Z$, denoted as $F_Z(z) = P(Z \\le z)$. It is mathematically more convenient to work with the complementary CDF (also known as the survival function), $P(Z > z)$.\n\nBy the definition of the minimum, $Z > z$ if and only if both $X > z$ and $Y > z$. Therefore:\n$$ P(Z > z) = P(\\min(X, Y) > z) = P(X > z \\text{ and } Y > z) $$\n\nSince $X$ and $Y$ are independent random variables, the probability of the intersection of events is the product of their individual probabilities:\n$$ P(X > z \\text{ and } Y > z) = P(X > z) \\cdot P(Y > z) $$\n\nWe calculate the survival functions for $X$ and $Y$. For $z \\ge 0$:\n$$ P(X > z) = \\int_{z}^{\\infty} \\lambda e^{-\\lambda x} \\, dx = \\left[ -e^{-\\lambda x} \\right]_{z}^{\\infty} = e^{-\\lambda z} $$\n$$ P(Y > z) = \\int_{z}^{\\infty} \\mu e^{-\\mu y} \\, dy = \\left[ -e^{-\\mu y} \\right]_{z}^{\\infty} = e^{-\\mu z} $$\nFor $z < 0$, the probabilities are $1$ since exponential random variables are non-negative.\n\nSubstituting these back into the expression for $P(Z > z)$ for $z \\ge 0$:\n$$ P(Z > z) = e^{-\\lambda z} \\cdot e^{-\\mu z} = e^{-(\\lambda + \\mu) z} $$\n\nNow, we find the CDF $F_Z(z)$:\n$$ F_Z(z) = 1 - P(Z > z) = \\begin{cases} 1 - e^{-(\\lambda + \\mu) z} & \\text{for } z \\ge 0 \\\\ 0 & \\text{for } z < 0 \\end{cases} $$\n\nThe probability density function $f_Z(z)$ is the derivative of the CDF with respect to $z$.\nFor $z \\ge 0$:\n$$ f_Z(z) = \\frac{d}{dz} \\left( 1 - e^{-(\\lambda + \\mu) z} \\right) = (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} $$\nFor $z < 0$, $f_Z(z) = 0$.\n\nThus, the pdf of $Z$ is:\n$$ f_Z(z) = \\begin{cases} (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} & z \\ge 0 \\\\ 0 & z < 0 \\end{cases} $$\n\nThis indicates that $Z$ follows an exponential distribution with rate parameter $\\lambda + \\mu$.\n$$ Z \\sim \\text{Exp}(\\lambda + \\mu) $$\n\n### 2. Computation of $\\mathbb{E}[Z]$\n\nSince we have identified that $Z \\sim \\text{Exp}(\\lambda + \\mu)$, we can utilize the standard property of the exponential distribution. For a random variable $T \\sim \\text{Exp}(r)$, the expected value is $\\mathbb{E}[T] = \\frac{1}{r}$.\n\nHere, the rate parameter is $r = \\lambda + \\mu$. Therefore:\n$$ \\mathbb{E}[Z] = \\frac{1}{\\lambda + \\mu} $$\n\n**Alternative derivation via integration:**\nWe compute the expectation directly using the definition $\\mathbb{E}[Z] = \\int_{-\\infty}^{\\infty} z f_Z(z) \\, dz$.\n$$ \\mathbb{E}[Z] = \\int_{0}^{\\infty} z (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} \\, dz $$\nLet $k = \\lambda + \\mu$. Then $\\mathbb{E}[Z] = k \\int_{0}^{\\infty} z e^{-k z} \\, dz$.\nUsing integration by parts, let $u = z$ and $dv = e^{-kz} dz$. Then $du = dz$ and $v = -\\frac{1}{k}e^{-kz}$.\n$$ \\int_{0}^{\\infty} z e^{-k z} \\, dz = \\left[ -\\frac{z}{k} e^{-kz} \\right]_{0}^{\\infty} - \\int_{0}^{\\infty} \\left(-\\frac{1}{k} e^{-kz}\\right) \\, dz $$\nThe boundary term $\\left[ -\\frac{z}{k} e^{-kz} \\right]_{0}^{\\infty}$ evaluates to $0$ (since $\\lim_{z \\to \\infty} z e^{-kz} = 0$ for $k > 0$).\nThe remaining integral is:\n$$ \\frac{1}{k} \\int_{0}^{\\infty} e^{-kz} \\, dz = \\frac{1}{k} \\left[ -\\frac{1}{k} e^{-kz} \\right]_{0}^{\\infty} = \\frac{1}{k} \\left( 0 - \\left(-\\frac{1}{k}\\right) \\right) = \\frac{1}{k^2} $$\nSubstituting the integral back into the expression for expectation:\n$$ \\mathbb{E}[Z] = k \\cdot \\frac{1}{k^2} = \\frac{1}{k} = \\frac{1}{\\lambda + \\mu} $$\n\n### Final Answer\n\nThe probability density function of $Z$ is:\n$$ f_Z(z) = \\begin{cases} (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} & z \\ge 0 \\\\ 0 & z < 0 \\end{cases} $$\n\nThe expected value of $Z$ is:\n$$ \\mathbb{E}[Z] = \\frac{1}{\\lambda + \\mu} $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $X$ and $Y$ be independent random variables with $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ and $Y \\sim \\mathcal{N}(0, 1)$, where $\\mu \\in \\mathbb{R}$ and $\\sigma > 0$ are unknown parameters. Suppose we have a sample of $n$ independent observations from $X$ and $m$ independent observations from $Y$, denoted as $x_1, x_2, \\ldots, x_n$ and $y_1, y_2, \\ldots, y_m$, respectively. Derive the likelihood ratio test statistic for testing $H_0: \\mu = 0, \\sigma = 1$ against $H_1: \\mu \\neq 0 \\text{ or } \\sigma \\neq 1$.",
    "run_id": "43",
    "outer_attempt": 1,
    "topic_slug": "statistics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To derive the likelihood ratio test (LRT) statistic for the given problem, we proceed through the following steps: constructing the joint likelihood function, maximizing it under the null and alternative hypotheses, and computing the ratio.\n\n### 1. The Likelihood Function\n\nLet $\\mathbf{x} = (x_1, \\ldots, x_n)$ and $\\mathbf{y} = (y_1, \\ldots, y_m)$ denote the observed samples.\nThe random variables are $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ and $Y \\sim \\mathcal{N}(0, 1)$.\nThe parameters of interest are $\\theta = (\\mu, \\sigma^2)$, with parameter space $\\Omega = \\mathbb{R} \\times (0, \\infty)$.\nSince the samples are independent, the joint likelihood function $L(\\mu, \\sigma^2; \\mathbf{x}, \\mathbf{y})$ is the product of the individual probability density functions:\n\n$$\nL(\\mu, \\sigma^2) = \\left( \\prod_{i=1}^n f_X(x_i; \\mu, \\sigma^2) \\right) \\times \\left( \\prod_{j=1}^m f_Y(y_j) \\right)\n$$\n\nSubstituting the normal density functions:\n$$f_X(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n$$f_Y(y) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{y^2}{2}\\right)$$\n\nThe likelihood function becomes:\n$$\nL(\\mu, \\sigma^2) = \\left[ (2\\pi\\sigma^2)^{-n/2} \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n (x_i - \\mu)^2\\right) \\right] \\times \\left[ (2\\pi)^{-m/2} \\exp\\left(-\\frac{1}{2}\\sum_{j=1}^m y_j^2\\right) \\right]\n$$\n\nLet $C(\\mathbf{y}) = (2\\pi)^{-m/2} \\exp\\left(-\\frac{1}{2}\\sum_{j=1}^m y_j^2\\right)$. Note that $C(\\mathbf{y})$ does not depend on the unknown parameters $\\mu$ and $\\sigma^2$. It will act as a constant multiplier.\n\n### 2. Maximizing the Likelihood Under the Null Hypothesis ($H_0$)\n\nUnder $H_0: \\mu = 0, \\sigma = 1$, the parameters are fixed. The restricted parameter space is $\\Omega_0 = \\{(0, 1)\\}$.\nThe likelihood is simply the function evaluated at these values:\n\n$$\nL_0 = \\sup_{(\\mu, \\sigma^2) \\in \\Omega_0} L(\\mu, \\sigma^2) = L(0, 1)\n$$\n$$\nL_0 = (2\\pi)^{-n/2} \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right) \\cdot C(\\mathbf{y})\n$$\n\n### 3. Maximizing the Likelihood Under the Alternative Hypothesis ($H_1$)\n\nUnder the general case (representing the union of $H_0$ and $H_1$), the parameters $(\\mu, \\sigma^2)$ can vary over $\\Omega = \\mathbb{R} \\times (0, \\infty)$. To maximize $L(\\mu, \\sigma^2)$, we only need to maximize the factor corresponding to $\\mathbf{x}$, as $C(\\mathbf{y})$ is constant. This is the standard maximum likelihood estimation (MLE) for a normal distribution.\n\nThe MLEs for $\\mu$ and $\\sigma^2$ are:\n$$\n\\hat{\\mu} = \\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i\n$$\n$$\n\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2\n$$\n\nEvaluating the likelihood at these estimates:\n$$\nL_1 = \\sup_{(\\mu, \\sigma^2) \\in \\Omega} L(\\mu, \\sigma^2) = L(\\hat{\\mu}, \\hat{\\sigma}^2)\n$$\n\nSubstitute $\\hat{\\mu}$ and $\\hat{\\sigma}^2$ into the $X$-component of the likelihood:\n1. The term $\\sum_{i=1}^n (x_i - \\hat{\\mu})^2 = \\sum_{i=1}^n (x_i - \\bar{x})^2 = n\\hat{\\sigma}^2$.\n2. The exponential term becomes $\\exp\\left(-\\frac{n\\hat{\\sigma}^2}{2\\hat{\\sigma}^2}\\right) = e^{-n/2}$.\n\nThus:\n$$\nL_1 = (2\\pi\\hat{\\sigma}^2)^{-n/2} e^{-n/2} \\cdot C(\\mathbf{y})\n$$\n\n### 4. Constructing the Likelihood Ratio Statistic\n\nThe likelihood ratio statistic $\\lambda$ is defined as:\n$$\n\\lambda = \\frac{L_0}{L_1}\n$$\n\nSubstitute the expressions for $L_0$ and $L_1$. Notice that $C(\\mathbf{y})$ and $(2\\pi)^{-n/2}$ appear in both the numerator and denominator and cancel out. Note also that the sample $\\mathbf{y}$ provides no information regarding $\\mu$ or $\\sigma$, so it does not influence the test statistic.\n\n$$\n\\lambda = \\frac{(2\\pi)^{-n/2} \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right)}{(2\\pi)^{-n/2} (\\hat{\\sigma}^2)^{-n/2} e^{-n/2}}\n$$\n\nSimplify the expression:\n$$\n\\lambda = \\frac{\\exp\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right)}{(\\hat{\\sigma}^2)^{-n/2} e^{-n/2}}\n$$\n$$\n\\lambda = (\\hat{\\sigma}^2)^{n/2} e^{n/2} \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right)\n$$\n\nWe can rewrite the sum of squares using the identity $\\sum_{i=1}^n x_i^2 = n\\hat{\\sigma}^2 + n\\bar{x}^2$:\n$$\n\\exp\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right) = \\exp\\left(-\\frac{1}{2}(n\\hat{\\sigma}^2 + n\\bar{x}^2)\\right)\n$$\n\nSubstitute this back into the expression for $\\lambda$:\n$$\n\\lambda = (\\hat{\\sigma}^2)^{n/2} \\exp\\left(\\frac{n}{2}\\right) \\exp\\left(-\\frac{n\\hat{\\sigma}^2}{2} - \\frac{n\\bar{x}^2}{2}\\right)\n$$\n$$\n\\lambda = (\\hat{\\sigma}^2)^{n/2} \\exp\\left( \\frac{n}{2} (1 - \\hat{\\sigma}^2 - \\bar{x}^2) \\right)\n$$\n\n### 5. Final Result\n\nThe likelihood ratio test statistic $\\lambda$ is:\n\n$$\n\\lambda(\\mathbf{x}) = \\left( \\hat{\\sigma}^2 \\right)^{n/2} \\exp\\left( \\frac{n}{2} (1 - \\hat{\\sigma}^2 - \\bar{x}^2) \\right)\n$$\n\nwhere $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$ and $\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2$.\n\nIt is common to express the test statistic as $-2 \\ln \\lambda$, which asymptotically follows a Chi-squared distribution under $H_0$. Taking the natural logarithm and multiplying by $-2$:\n\n$$\n-2 \\ln \\lambda = -2 \\left[ \\frac{n}{2} \\ln(\\hat{\\sigma}^2) + \\frac{n}{2}(1 - \\hat{\\sigma}^2 - \\bar{x}^2) \\right]\n$$\n\n$$\n-2 \\ln \\lambda = n \\left[ \\hat{\\sigma}^2 + \\bar{x}^2 - 1 - \\ln(\\hat{\\sigma}^2) \\right]\n$$\n\nThe test rejects $H_0$ for small values of $\\lambda$ (or large values of $-2 \\ln \\lambda$).\n\n**Answer:**\nThe likelihood ratio test statistic is:\n$$ \\lambda = \\left( \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2 \\right)^{n/2} \\exp\\left( \\frac{n}{2} \\left( 1 - \\frac{1}{n}\\sum_{i=1}^n x_i^2 \\right) \\right) $$\nEquivalently, in terms of the MLE variance $\\hat{\\sigma}^2$:\n$$ \\lambda = (\\hat{\\sigma}^2)^{n/2} e^{\\frac{n}{2}(1 - \\hat{\\sigma}^2 - \\bar{x}^2)} $$",
        "raw_answer": "To derive the likelihood ratio test (LRT) statistic for the given problem, we proceed through the following steps: constructing the joint likelihood function, maximizing it under the null and alternative hypotheses, and computing the ratio.\n\n### 1. The Likelihood Function\n\nLet $\\mathbf{x} = (x_1, \\ldots, x_n)$ and $\\mathbf{y} = (y_1, \\ldots, y_m)$ denote the observed samples.\nThe random variables are $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ and $Y \\sim \\mathcal{N}(0, 1)$.\nThe parameters of interest are $\\theta = (\\mu, \\sigma^2)$, with parameter space $\\Omega = \\mathbb{R} \\times (0, \\infty)$.\nSince the samples are independent, the joint likelihood function $L(\\mu, \\sigma^2; \\mathbf{x}, \\mathbf{y})$ is the product of the individual probability density functions:\n\n$$\nL(\\mu, \\sigma^2) = \\left( \\prod_{i=1}^n f_X(x_i; \\mu, \\sigma^2) \\right) \\times \\left( \\prod_{j=1}^m f_Y(y_j) \\right)\n$$\n\nSubstituting the normal density functions:\n$$f_X(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n$$f_Y(y) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{y^2}{2}\\right)$$\n\nThe likelihood function becomes:\n$$\nL(\\mu, \\sigma^2) = \\left[ (2\\pi\\sigma^2)^{-n/2} \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n (x_i - \\mu)^2\\right) \\right] \\times \\left[ (2\\pi)^{-m/2} \\exp\\left(-\\frac{1}{2}\\sum_{j=1}^m y_j^2\\right) \\right]\n$$\n\nLet $C(\\mathbf{y}) = (2\\pi)^{-m/2} \\exp\\left(-\\frac{1}{2}\\sum_{j=1}^m y_j^2\\right)$. Note that $C(\\mathbf{y})$ does not depend on the unknown parameters $\\mu$ and $\\sigma^2$. It will act as a constant multiplier.\n\n### 2. Maximizing the Likelihood Under the Null Hypothesis ($H_0$)\n\nUnder $H_0: \\mu = 0, \\sigma = 1$, the parameters are fixed. The restricted parameter space is $\\Omega_0 = \\{(0, 1)\\}$.\nThe likelihood is simply the function evaluated at these values:\n\n$$\nL_0 = \\sup_{(\\mu, \\sigma^2) \\in \\Omega_0} L(\\mu, \\sigma^2) = L(0, 1)\n$$\n$$\nL_0 = (2\\pi)^{-n/2} \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right) \\cdot C(\\mathbf{y})\n$$\n\n### 3. Maximizing the Likelihood Under the Alternative Hypothesis ($H_1$)\n\nUnder the general case (representing the union of $H_0$ and $H_1$), the parameters $(\\mu, \\sigma^2)$ can vary over $\\Omega = \\mathbb{R} \\times (0, \\infty)$. To maximize $L(\\mu, \\sigma^2)$, we only need to maximize the factor corresponding to $\\mathbf{x}$, as $C(\\mathbf{y})$ is constant. This is the standard maximum likelihood estimation (MLE) for a normal distribution.\n\nThe MLEs for $\\mu$ and $\\sigma^2$ are:\n$$\n\\hat{\\mu} = \\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i\n$$\n$$\n\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2\n$$\n\nEvaluating the likelihood at these estimates:\n$$\nL_1 = \\sup_{(\\mu, \\sigma^2) \\in \\Omega} L(\\mu, \\sigma^2) = L(\\hat{\\mu}, \\hat{\\sigma}^2)\n$$\n\nSubstitute $\\hat{\\mu}$ and $\\hat{\\sigma}^2$ into the $X$-component of the likelihood:\n1. The term $\\sum_{i=1}^n (x_i - \\hat{\\mu})^2 = \\sum_{i=1}^n (x_i - \\bar{x})^2 = n\\hat{\\sigma}^2$.\n2. The exponential term becomes $\\exp\\left(-\\frac{n\\hat{\\sigma}^2}{2\\hat{\\sigma}^2}\\right) = e^{-n/2}$.\n\nThus:\n$$\nL_1 = (2\\pi\\hat{\\sigma}^2)^{-n/2} e^{-n/2} \\cdot C(\\mathbf{y})\n$$\n\n### 4. Constructing the Likelihood Ratio Statistic\n\nThe likelihood ratio statistic $\\lambda$ is defined as:\n$$\n\\lambda = \\frac{L_0}{L_1}\n$$\n\nSubstitute the expressions for $L_0$ and $L_1$. Notice that $C(\\mathbf{y})$ and $(2\\pi)^{-n/2}$ appear in both the numerator and denominator and cancel out. Note also that the sample $\\mathbf{y}$ provides no information regarding $\\mu$ or $\\sigma$, so it does not influence the test statistic.\n\n$$\n\\lambda = \\frac{(2\\pi)^{-n/2} \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right)}{(2\\pi)^{-n/2} (\\hat{\\sigma}^2)^{-n/2} e^{-n/2}}\n$$\n\nSimplify the expression:\n$$\n\\lambda = \\frac{\\exp\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right)}{(\\hat{\\sigma}^2)^{-n/2} e^{-n/2}}\n$$\n$$\n\\lambda = (\\hat{\\sigma}^2)^{n/2} e^{n/2} \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right)\n$$\n\nWe can rewrite the sum of squares using the identity $\\sum_{i=1}^n x_i^2 = n\\hat{\\sigma}^2 + n\\bar{x}^2$:\n$$\n\\exp\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right) = \\exp\\left(-\\frac{1}{2}(n\\hat{\\sigma}^2 + n\\bar{x}^2)\\right)\n$$\n\nSubstitute this back into the expression for $\\lambda$:\n$$\n\\lambda = (\\hat{\\sigma}^2)^{n/2} \\exp\\left(\\frac{n}{2}\\right) \\exp\\left(-\\frac{n\\hat{\\sigma}^2}{2} - \\frac{n\\bar{x}^2}{2}\\right)\n$$\n$$\n\\lambda = (\\hat{\\sigma}^2)^{n/2} \\exp\\left( \\frac{n}{2} (1 - \\hat{\\sigma}^2 - \\bar{x}^2) \\right)\n$$\n\n### 5. Final Result\n\nThe likelihood ratio test statistic $\\lambda$ is:\n\n$$\n\\lambda(\\mathbf{x}) = \\left( \\hat{\\sigma}^2 \\right)^{n/2} \\exp\\left( \\frac{n}{2} (1 - \\hat{\\sigma}^2 - \\bar{x}^2) \\right)\n$$\n\nwhere $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$ and $\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2$.\n\nIt is common to express the test statistic as $-2 \\ln \\lambda$, which asymptotically follows a Chi-squared distribution under $H_0$. Taking the natural logarithm and multiplying by $-2$:\n\n$$\n-2 \\ln \\lambda = -2 \\left[ \\frac{n}{2} \\ln(\\hat{\\sigma}^2) + \\frac{n}{2}(1 - \\hat{\\sigma}^2 - \\bar{x}^2) \\right]\n$$\n\n$$\n-2 \\ln \\lambda = n \\left[ \\hat{\\sigma}^2 + \\bar{x}^2 - 1 - \\ln(\\hat{\\sigma}^2) \\right]\n$$\n\nThe test rejects $H_0$ for small values of $\\lambda$ (or large values of $-2 \\ln \\lambda$).\n\n**Answer:**\nThe likelihood ratio test statistic is:\n$$ \\lambda = \\left( \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2 \\right)^{n/2} \\exp\\left( \\frac{n}{2} \\left( 1 - \\frac{1}{n}\\sum_{i=1}^n x_i^2 \\right) \\right) $$\nEquivalently, in terms of the MLE variance $\\hat{\\sigma}^2$:\n$$ \\lambda = (\\hat{\\sigma}^2)^{n/2} e^{\\frac{n}{2}(1 - \\hat{\\sigma}^2 - \\bar{x}^2)} $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Consider the function $f(x) = e^x - 2x - 1$. We want to approximate the root of $f(x)$ in the interval $[0,1]$ using the Newton-Raphson method. Starting with $x_0 = 1$, perform two iterations of the Newton-Raphson method to find $x_2$. Provide the exact value of $x_2$.",
    "run_id": "44",
    "outer_attempt": 1,
    "topic_slug": "numerical_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the problem, we will perform two iterations of the Newton-Raphson method for the function $f(x) = e^x - 2x - 1$ starting with $x_0 = 1$.\n\n### 1. The Newton-Raphson Method\n\nThe Newton-Raphson iteration formula is given by:\n$$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$$\n\nFirst, we determine the derivative of $f(x)$ with respect to $x$:\n$$f(x) = e^x - 2x - 1$$\n$$f'(x) = \\frac{d}{dx}(e^x - 2x - 1) = e^x - 2$$\n\n### 2. Iteration 1: Finding $x_1$\n\nWe are given the initial guess $x_0 = 1$. We calculate $f(x_0)$ and $f'(x_0)$:\n$$f(1) = e^1 - 2(1) - 1 = e - 3$$\n$$f'(1) = e^1 - 2 = e - 2$$\n\nNow, we compute $x_1$:\n$$x_1 = 1 - \\frac{e - 3}{e - 2}$$\n\nTo simplify this expression, we find a common denominator:\n$$x_1 = \\frac{e - 2}{e - 2} - \\frac{e - 3}{e - 2}$$\n$$x_1 = \\frac{(e - 2) - (e - 3)}{e - 2}$$\n$$x_1 = \\frac{e - 2 - e + 3}{e - 2}$$\n$$x_1 = \\frac{1}{e - 2}$$\n\n### 3. Iteration 2: Finding $x_2$\n\nNow we use $x_1 = \\frac{1}{e - 2}$ to find $x_2$. The formula is:\n$$x_2 = x_1 - \\frac{f(x_1)}{f'(x_1)}$$\n\nSubstituting the function and derivative expressions:\n$$x_2 = x_1 - \\frac{e^{x_1} - 2x_1 - 1}{e^{x_1} - 2}$$\n\nTo simplify, we combine the terms into a single fraction:\n$$x_2 = \\frac{x_1(e^{x_1} - 2) - (e^{x_1} - 2x_1 - 1)}{e^{x_1} - 2}$$\n$$x_2 = \\frac{x_1 e^{x_1} - 2x_1 - e^{x_1} + 2x_1 + 1}{e^{x_1} - 2}$$\n\nNotice that the $-2x_1$ and $+2x_1$ terms cancel out:\n$$x_2 = \\frac{x_1 e^{x_1} - e^{x_1} + 1}{e^{x_1} - 2}$$\n$$x_2 = \\frac{e^{x_1}(x_1 - 1) + 1}{e^{x_1} - 2}$$\n\nNow, we substitute the exact value of $x_1 = \\frac{1}{e - 2}$.\nFirst, let's simplify the term $(x_1 - 1)$:\n$$x_1 - 1 = \\frac{1}{e - 2} - 1 = \\frac{1 - (e - 2)}{e - 2} = \\frac{1 - e + 2}{e - 2} = \\frac{3 - e}{e - 2}$$\n\nNow substitute this back into the expression for $x_2$:\n$$x_2 = \\frac{e^{\\frac{1}{e - 2}} \\left( \\frac{3 - e}{e - 2} \\right) + 1}{e^{\\frac{1}{e - 2}} - 2}$$\n\nTo express this as a single fraction, we multiply the numerator and the denominator by $(e - 2)$:\n$$x_2 = \\frac{(3 - e)e^{\\frac{1}{e - 2}} + (e - 2)}{(e - 2)(e^{\\frac{1}{e - 2}} - 2)}$$\n\n### Final Answer\n\nThe exact value of $x_2$ is:\n$$x_2 = \\frac{(3 - e)e^{\\frac{1}{e - 2}} + e - 2}{(e - 2)(e^{\\frac{1}{e - 2}} - 2)}$$",
        "raw_answer": "To solve the problem, we will perform two iterations of the Newton-Raphson method for the function $f(x) = e^x - 2x - 1$ starting with $x_0 = 1$.\n\n### 1. The Newton-Raphson Method\n\nThe Newton-Raphson iteration formula is given by:\n$$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$$\n\nFirst, we determine the derivative of $f(x)$ with respect to $x$:\n$$f(x) = e^x - 2x - 1$$\n$$f'(x) = \\frac{d}{dx}(e^x - 2x - 1) = e^x - 2$$\n\n### 2. Iteration 1: Finding $x_1$\n\nWe are given the initial guess $x_0 = 1$. We calculate $f(x_0)$ and $f'(x_0)$:\n$$f(1) = e^1 - 2(1) - 1 = e - 3$$\n$$f'(1) = e^1 - 2 = e - 2$$\n\nNow, we compute $x_1$:\n$$x_1 = 1 - \\frac{e - 3}{e - 2}$$\n\nTo simplify this expression, we find a common denominator:\n$$x_1 = \\frac{e - 2}{e - 2} - \\frac{e - 3}{e - 2}$$\n$$x_1 = \\frac{(e - 2) - (e - 3)}{e - 2}$$\n$$x_1 = \\frac{e - 2 - e + 3}{e - 2}$$\n$$x_1 = \\frac{1}{e - 2}$$\n\n### 3. Iteration 2: Finding $x_2$\n\nNow we use $x_1 = \\frac{1}{e - 2}$ to find $x_2$. The formula is:\n$$x_2 = x_1 - \\frac{f(x_1)}{f'(x_1)}$$\n\nSubstituting the function and derivative expressions:\n$$x_2 = x_1 - \\frac{e^{x_1} - 2x_1 - 1}{e^{x_1} - 2}$$\n\nTo simplify, we combine the terms into a single fraction:\n$$x_2 = \\frac{x_1(e^{x_1} - 2) - (e^{x_1} - 2x_1 - 1)}{e^{x_1} - 2}$$\n$$x_2 = \\frac{x_1 e^{x_1} - 2x_1 - e^{x_1} + 2x_1 + 1}{e^{x_1} - 2}$$\n\nNotice that the $-2x_1$ and $+2x_1$ terms cancel out:\n$$x_2 = \\frac{x_1 e^{x_1} - e^{x_1} + 1}{e^{x_1} - 2}$$\n$$x_2 = \\frac{e^{x_1}(x_1 - 1) + 1}{e^{x_1} - 2}$$\n\nNow, we substitute the exact value of $x_1 = \\frac{1}{e - 2}$.\nFirst, let's simplify the term $(x_1 - 1)$:\n$$x_1 - 1 = \\frac{1}{e - 2} - 1 = \\frac{1 - (e - 2)}{e - 2} = \\frac{1 - e + 2}{e - 2} = \\frac{3 - e}{e - 2}$$\n\nNow substitute this back into the expression for $x_2$:\n$$x_2 = \\frac{e^{\\frac{1}{e - 2}} \\left( \\frac{3 - e}{e - 2} \\right) + 1}{e^{\\frac{1}{e - 2}} - 2}$$\n\nTo express this as a single fraction, we multiply the numerator and the denominator by $(e - 2)$:\n$$x_2 = \\frac{(3 - e)e^{\\frac{1}{e - 2}} + (e - 2)}{(e - 2)(e^{\\frac{1}{e - 2}} - 2)}$$\n\n### Final Answer\n\nThe exact value of $x_2$ is:\n$$x_2 = \\frac{(3 - e)e^{\\frac{1}{e - 2}} + e - 2}{(e - 2)(e^{\\frac{1}{e - 2}} - 2)}$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $G$ be a simple graph with $n$ vertices. Prove that if $G$ is a tree (i.e., it is connected and has no cycles), then it has exactly $n-1$ edges.",
    "run_id": "2",
    "outer_attempt": 2,
    "topic_slug": "combinatorics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Theorem:** Let $G$ be a simple graph with $n$ vertices. If $G$ is a tree (connected and acyclic), then $G$ has exactly $n-1$ edges.\n\n**Proof:**\n\nWe will prove this statement using mathematical induction on $n$, the number of vertices in the graph.\n\nLet $P(n)$ be the proposition that every tree with $n$ vertices has exactly $n-1$ edges.\n\n### 1. Base Case ($n=1$)\nConsider a graph $G$ with $n=1$ vertex. Since simple graphs do not allow self-loops, there can be no edges connecting this vertex to itself.\nThus, the number of edges is $0$.\nUsing the formula: $n-1 = 1-1 = 0$.\nThe base case holds.\n\n### 2. Inductive Hypothesis\nAssume that for some integer $k \\ge 1$, the proposition $P(k)$ is true. That is, any tree with $k$ vertices has exactly $k-1$ edges.\n\n### 3. Inductive Step\nWe must show that $P(k+1)$ is true. Let $T$ be a tree with $n = k+1$ vertices. Since $k \\ge 1$, $n \\ge 2$.\n\nTo proceed, we utilize the following lemma:\n\n**Lemma:** Every tree with at least 2 vertices contains at least two vertices of degree 1 (leaves).\n\n*Proof of Lemma:*\nConsider a simple path of maximum length in $T$: $v_0, v_1, \\dots, v_m$. Since the graph is finite, such a path exists.\nConsider the endpoint $v_0$. Since $T$ is connected and $n \\ge 2$, $v_0$ has at least one neighbor ($v_1$).\nSuppose $v_0$ has another neighbor, $u$.\n- If $u$ is not on the path, we could extend the path to $u, v_0, v_1, \\dots$, contradicting the assumption that the path is of maximum length.\n- If $u$ is on the path (i.e., $u = v_i$ for some $i > 1$), then the edges $(v_0, v_1), (v_1, v_2), \\dots, (v_{i-1}, v_i)$ combined with $(v_i, v_0)$ form a cycle. This contradicts the assumption that $T$ is a tree (acyclic).\nTherefore, $v_0$ has exactly one neighbor, making it a leaf (degree 1). The same logic applies to $v_m$. Thus, $T$ has at least two leaves.\n\n**Continuing the Inductive Step:**\nBy the lemma, the tree $T$ (which has $k+1 \\ge 2$ vertices) contains a leaf. Let $v$ be a leaf vertex and let $e$ be the single edge connecting $v$ to the rest of the graph.\n\nWe construct a new graph $T'$ by removing the vertex $v$ and the edge $e$ from $T$.\nLet $V'$ be the vertex set of $T'$ and $E'$ be the edge set of $T'$.\n$$ |V'| = (k+1) - 1 = k $$\n$$ |E'| = |E(T)| - 1 $$\n\nWe must verify that $T'$ is a tree to apply the inductive hypothesis.\n1.  **Acyclic:** Since $T$ has no cycles, removing a vertex and an edge cannot create a cycle. Thus, $T'$ contains no cycles.\n2.  **Connected:** Let $x$ and $y$ be any two distinct vertices in $T'$. Since $T$ is a tree, there is a unique path between $x$ and $y$ in $T$. Since $v$ is a leaf (degree 1), $v$ cannot be an intermediate vertex in the path between any two other nodes $x, y \\in V \\setminus \\{v\\}$. Therefore, the path between $x$ and $y$ remains intact in $T'$. Thus, $T'$ is connected.\n\nSince $T'$ is connected and acyclic, $T'$ is a tree with $k$ vertices.\nBy the inductive hypothesis, $T'$ has exactly $k-1$ edges. So, $|E'| = k-1$.\n\nSince $|E(T)| = |E'| + 1$ (accounting for the removed edge $e$), we have:\n$$ |E(T)| = (k-1) + 1 = k $$\n\nNote that for $n = k+1$, the formula predicts $(k+1) - 1 = k$ edges. The result matches.\n\n### Conclusion\nBy the Principle of Mathematical Induction, $P(n)$ is true for all integers $n \\ge 1$.\nTherefore, every tree with $n$ vertices has exactly $n-1$ edges.",
        "raw_answer": "**Theorem:** Let $G$ be a simple graph with $n$ vertices. If $G$ is a tree (connected and acyclic), then $G$ has exactly $n-1$ edges.\n\n**Proof:**\n\nWe will prove this statement using mathematical induction on $n$, the number of vertices in the graph.\n\nLet $P(n)$ be the proposition that every tree with $n$ vertices has exactly $n-1$ edges.\n\n### 1. Base Case ($n=1$)\nConsider a graph $G$ with $n=1$ vertex. Since simple graphs do not allow self-loops, there can be no edges connecting this vertex to itself.\nThus, the number of edges is $0$.\nUsing the formula: $n-1 = 1-1 = 0$.\nThe base case holds.\n\n### 2. Inductive Hypothesis\nAssume that for some integer $k \\ge 1$, the proposition $P(k)$ is true. That is, any tree with $k$ vertices has exactly $k-1$ edges.\n\n### 3. Inductive Step\nWe must show that $P(k+1)$ is true. Let $T$ be a tree with $n = k+1$ vertices. Since $k \\ge 1$, $n \\ge 2$.\n\nTo proceed, we utilize the following lemma:\n\n**Lemma:** Every tree with at least 2 vertices contains at least two vertices of degree 1 (leaves).\n\n*Proof of Lemma:*\nConsider a simple path of maximum length in $T$: $v_0, v_1, \\dots, v_m$. Since the graph is finite, such a path exists.\nConsider the endpoint $v_0$. Since $T$ is connected and $n \\ge 2$, $v_0$ has at least one neighbor ($v_1$).\nSuppose $v_0$ has another neighbor, $u$.\n- If $u$ is not on the path, we could extend the path to $u, v_0, v_1, \\dots$, contradicting the assumption that the path is of maximum length.\n- If $u$ is on the path (i.e., $u = v_i$ for some $i > 1$), then the edges $(v_0, v_1), (v_1, v_2), \\dots, (v_{i-1}, v_i)$ combined with $(v_i, v_0)$ form a cycle. This contradicts the assumption that $T$ is a tree (acyclic).\nTherefore, $v_0$ has exactly one neighbor, making it a leaf (degree 1). The same logic applies to $v_m$. Thus, $T$ has at least two leaves.\n\n**Continuing the Inductive Step:**\nBy the lemma, the tree $T$ (which has $k+1 \\ge 2$ vertices) contains a leaf. Let $v$ be a leaf vertex and let $e$ be the single edge connecting $v$ to the rest of the graph.\n\nWe construct a new graph $T'$ by removing the vertex $v$ and the edge $e$ from $T$.\nLet $V'$ be the vertex set of $T'$ and $E'$ be the edge set of $T'$.\n$$ |V'| = (k+1) - 1 = k $$\n$$ |E'| = |E(T)| - 1 $$\n\nWe must verify that $T'$ is a tree to apply the inductive hypothesis.\n1.  **Acyclic:** Since $T$ has no cycles, removing a vertex and an edge cannot create a cycle. Thus, $T'$ contains no cycles.\n2.  **Connected:** Let $x$ and $y$ be any two distinct vertices in $T'$. Since $T$ is a tree, there is a unique path between $x$ and $y$ in $T$. Since $v$ is a leaf (degree 1), $v$ cannot be an intermediate vertex in the path between any two other nodes $x, y \\in V \\setminus \\{v\\}$. Therefore, the path between $x$ and $y$ remains intact in $T'$. Thus, $T'$ is connected.\n\nSince $T'$ is connected and acyclic, $T'$ is a tree with $k$ vertices.\nBy the inductive hypothesis, $T'$ has exactly $k-1$ edges. So, $|E'| = k-1$.\n\nSince $|E(T)| = |E'| + 1$ (accounting for the removed edge $e$), we have:\n$$ |E(T)| = (k-1) + 1 = k $$\n\nNote that for $n = k+1$, the formula predicts $(k+1) - 1 = k$ edges. The result matches.\n\n### Conclusion\nBy the Principle of Mathematical Induction, $P(n)$ is true for all integers $n \\ge 1$.\nTherefore, every tree with $n$ vertices has exactly $n-1$ edges.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of algebraic geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within algebraic geometry\nAlgebraic geometry is a broad field that involves the study of geometric objects, such as varieties and schemes, using tools from abstract algebra. A suitable topic could involve the study of curves, surfaces, or higher-dimensional varieties, and their properties.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the intersection of curves on a surface. A classic result in algebraic geometry is B\u00e9zout's theorem, which describes the intersection of two curves on a projective plane. We can formulate a problem related to this.\n\n## Step 4: State the problem\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.\n\n## Step 5: Provide the solution\nTo find the intersection points, we need to solve the system of equations given by $f(x,y,z) = 0$ and $g(x,y,z) = 0$. This means we have to solve $x^2 + y^2 - z^2 = 0$ and $xy - z^2 = 0$ simultaneously.\n\n## Step 6: Solve the system of equations using B\u00e9zout's theorem\nB\u00e9zout's theorem states that two curves of degrees $d_1$ and $d_2$ intersect in $d_1d_2$ points, counted with multiplicity, if they have no common components. Here, $C_1$ and $C_2$ are both of degree 2, so they should intersect in $2 \\times 2 = 4$ points.\n\n## Step 7: Verify if $C_1$ and $C_2$ have any common components\nTo check if $C_1$ and $C_2$ have common components, we need to see if $f$ and $g$ have a common factor. This involves checking if there's a non-constant polynomial that divides both $f$ and $g$.\n\n## Step 8: Check for common factors\nWe examine if there's a linear combination of $f$ and $g$ that simplifies to a constant or a factorable expression. However, given the nature of $f$ and $g$, and without loss of generality, we can directly apply B\u00e9zout's theorem if we confirm they don't share a component.\n\n## Step 9: Apply B\u00e9zout's theorem\nSince both $f$ and $g$ are of degree 2 and there's no immediate indication they share a factor (which would be a linear factor given their degree), we can conclude they intersect in 4 points counted with multiplicity.\n\n## Step 10: Conclude the number of intersection points\nBy B\u00e9zout's theorem, $C_1$ and $C_2$ intersect in 4 points.\n\nThe final answer is: \n\n\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.",
    "run_id": "8",
    "outer_attempt": 2,
    "topic_slug": "algebraic_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To determine the number of intersection points of the two curves $C_1$ and $C_2$ in $\\mathbb{P}^2$ counted with multiplicity, we employ B\u00e9zout's Theorem. We assume the standard setting of algebraic geometry, working over the complex numbers $\\mathbb{C}$ (or an algebraically closed field of characteristic 0), as intersection multiplicities are naturally defined in this context.\n\n### 1. Problem Setup and Definitions\n\nThe curves $C_1$ and $C_2$ are defined by the following homogeneous polynomials in $\\mathbb{C}[x,y,z]$:\n$$f(x,y,z) = x^2 + y^2 - z^2$$\n$$g(x,y,z) = xy - z^2$$\n\nWe aim to find the size of the intersection set $V(f) \\cap V(g)$ in the projective plane $\\mathbb{P}^2$, counted with multiplicity.\n\n### 2. Application of B\u00e9zout's Theorem\n\n**B\u00e9zout's Theorem** states that if two plane curves defined by homogeneous polynomials of degrees $d_1$ and $d_2$ do not share a common component, then they intersect in exactly $d_1 \\cdot d_2$ points, counted with multiplicity.\n\n**Step 2a: Determine Degrees**\nThe polynomial $f$ is a quadratic form, so $\\deg(f) = 2$.\nThe polynomial $g$ is a quadratic form, so $\\deg(g) = 2$.\n\n**Step 2b: Check for Common Components**\nTo apply B\u00e9zout's Theorem, we must verify that $C_1$ and $C_2$ share no common component (i.e., $f$ and $g$ have no common non-constant factor).\n\nConsider the linear combination $h = f - g$:\n$$h(x,y,z) = (x^2 + y^2 - z^2) - (xy - z^2) = x^2 - xy + y^2$$\n\nIf $f$ and $g$ share a common factor $k(x,y,z)$, then $k$ must also divide their difference $h$.\nWe factor $h$ over $\\mathbb{C}$. The equation $x^2 - xy + y^2 = 0$ can be viewed as a quadratic in $x$. Solving for $x$ in terms of $y$:\n$$x = \\frac{y \\pm \\sqrt{y^2 - 4y^2}}{2} = \\frac{1 \\pm i\\sqrt{3}}{2}y$$\nLet $\\omega = e^{i\\pi/3} = \\frac{1 + i\\sqrt{3}}{2}$. Then the roots are $\\omega y$ and $\\bar{\\omega} y$.\nThus, $h$ factors into two linear forms:\n$$h(x,y,z) = (x - \\omega y)(x - \\bar{\\omega} y)$$\n\nThe potential common factors are $L_1 = x - \\omega y$ and $L_2 = x - \\bar{\\omega} y$. We verify if either divides $g(x,y,z) = xy - z^2$.\n\n1.  **Test $L_1$**: If $L_1$ divides $g$, then $g$ must vanish whenever $x = \\omega y$.\n    Substitute $x = \\omega y$ into $g$:\n    $$g(\\omega y, y, z) = (\\omega y)(y) - z^2 = \\omega y^2 - z^2$$\n    This is not the zero polynomial (it depends on $z$). Thus, $L_1$ does not divide $g$.\n\n2.  **Test $L_2$**: Similarly, substitute $x = \\bar{\\omega} y$ into $g$:\n    $$g(\\bar{\\omega} y, y, z) = \\bar{\\omega} y^2 - z^2 \\neq 0$$\n    Thus, $L_2$ does not divide $g$.\n\nSince neither linear factor of $f-g$ divides $g$, the polynomials $f$ and $g$ are coprime. Therefore, the curves have no common components.\n\n**Step 2c: Calculate Total Intersection Count**\nBy B\u00e9zout's Theorem, the total number of intersection points counted with multiplicity is:\n$$N = \\deg(f) \\cdot \\deg(g) = 2 \\cdot 2 = 4$$\n\n---\n\n### 3. Explicit Verification (Completeness Check)\n\nTo ensure the solution is robust and there are no edge cases (such as points at infinity or singular points affecting the count), we explicitly find the solutions.\n\n**System of Equations:**\n1. $x^2 + y^2 = z^2$\n2. $xy = z^2$\n\n**Case 1: Points at Infinity ($z=0$)**\nIf $z=0$, the system becomes:\n1. $x^2 + y^2 = 0$\n2. $xy = 0$\nFrom (2), either $x=0$ or $y=0$.\n- If $x=0$, then (1) implies $y^2=0 \\Rightarrow y=0$. Point: $[0:0:0]$, which is not in $\\mathbb{P}^2$.\n- If $y=0$, then (1) implies $x^2=0 \\Rightarrow x=0$. Same result.\nThus, there are **no intersection points at infinity**.\n\n**Case 2: Affine Points ($z=1$)**\nThe system becomes:\n1. $x^2 + y^2 = 1$\n2. $xy = 1$\n\nSubtract (2) from (1):\n$$x^2 - xy + y^2 = 0$$\nSince $xy=1$, $y \\neq 0$. Divide by $y^2$:\n$$\\left(\\frac{x}{y}\\right)^2 - \\left(\\frac{x}{y}\\right) + 1 = 0$$\nLet $u = x/y$. The roots are $u = \\frac{1 \\pm i\\sqrt{3}}{2} = e^{\\pm i\\pi/3}$.\nLet these roots be $\\omega$ and $\\bar{\\omega}$.\n\nSubcase 2a: $x = \\omega y$.\nSubstitute into $xy=1$: $\\omega y^2 = 1 \\implies y^2 = \\omega^{-1} = \\bar{\\omega}$.\n$$y = \\pm \\sqrt{\\bar{\\omega}}$$\nThis yields two distinct values for $y$, and consequently two distinct points $(x,y)$.\n\nSubcase 2b: $x = \\bar{\\omega} y$.\nSubstitute into $xy=1$: $\\bar{\\omega} y^2 = 1 \\implies y^2 = \\bar{\\omega}^{-1} = \\omega$.\n$$y = \\pm \\sqrt{\\omega}$$\nThis yields two distinct values for $y$, and consequently two distinct points.\n\n**Conclusion of Verification:**\nWe have found 4 distinct geometric points:\n1. $[\\omega\\sqrt{\\bar{\\omega}} : \\sqrt{\\bar{\\omega}} : 1]$\n2. $[-\\omega\\sqrt{\\bar{\\omega}} : -\\sqrt{\\bar{\\omega}} : 1]$\n3. $[\\bar{\\omega}\\sqrt{\\omega} : \\sqrt{\\omega} : 1]$\n4. $[-\\bar{\\omega}\\sqrt{\\omega} : -\\sqrt{\\omega} : 1]$\n\nSince there are 4 distinct points and the sum of multiplicities must be 4, each point has multiplicity 1 (the intersections are transversal).\n\n### 4. Final Answer\n\nThe curves $C_1$ and $C_2$ have no common component and are both of degree 2. By B\u00e9zout's Theorem, the number of intersection points counted with multiplicity is $2 \\times 2 = 4$.\n\nThe number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity, is 4.",
        "raw_answer": "To determine the number of intersection points of the two curves $C_1$ and $C_2$ in $\\mathbb{P}^2$ counted with multiplicity, we employ B\u00e9zout's Theorem. We assume the standard setting of algebraic geometry, working over the complex numbers $\\mathbb{C}$ (or an algebraically closed field of characteristic 0), as intersection multiplicities are naturally defined in this context.\n\n### 1. Problem Setup and Definitions\n\nThe curves $C_1$ and $C_2$ are defined by the following homogeneous polynomials in $\\mathbb{C}[x,y,z]$:\n$$f(x,y,z) = x^2 + y^2 - z^2$$\n$$g(x,y,z) = xy - z^2$$\n\nWe aim to find the size of the intersection set $V(f) \\cap V(g)$ in the projective plane $\\mathbb{P}^2$, counted with multiplicity.\n\n### 2. Application of B\u00e9zout's Theorem\n\n**B\u00e9zout's Theorem** states that if two plane curves defined by homogeneous polynomials of degrees $d_1$ and $d_2$ do not share a common component, then they intersect in exactly $d_1 \\cdot d_2$ points, counted with multiplicity.\n\n**Step 2a: Determine Degrees**\nThe polynomial $f$ is a quadratic form, so $\\deg(f) = 2$.\nThe polynomial $g$ is a quadratic form, so $\\deg(g) = 2$.\n\n**Step 2b: Check for Common Components**\nTo apply B\u00e9zout's Theorem, we must verify that $C_1$ and $C_2$ share no common component (i.e., $f$ and $g$ have no common non-constant factor).\n\nConsider the linear combination $h = f - g$:\n$$h(x,y,z) = (x^2 + y^2 - z^2) - (xy - z^2) = x^2 - xy + y^2$$\n\nIf $f$ and $g$ share a common factor $k(x,y,z)$, then $k$ must also divide their difference $h$.\nWe factor $h$ over $\\mathbb{C}$. The equation $x^2 - xy + y^2 = 0$ can be viewed as a quadratic in $x$. Solving for $x$ in terms of $y$:\n$$x = \\frac{y \\pm \\sqrt{y^2 - 4y^2}}{2} = \\frac{1 \\pm i\\sqrt{3}}{2}y$$\nLet $\\omega = e^{i\\pi/3} = \\frac{1 + i\\sqrt{3}}{2}$. Then the roots are $\\omega y$ and $\\bar{\\omega} y$.\nThus, $h$ factors into two linear forms:\n$$h(x,y,z) = (x - \\omega y)(x - \\bar{\\omega} y)$$\n\nThe potential common factors are $L_1 = x - \\omega y$ and $L_2 = x - \\bar{\\omega} y$. We verify if either divides $g(x,y,z) = xy - z^2$.\n\n1.  **Test $L_1$**: If $L_1$ divides $g$, then $g$ must vanish whenever $x = \\omega y$.\n    Substitute $x = \\omega y$ into $g$:\n    $$g(\\omega y, y, z) = (\\omega y)(y) - z^2 = \\omega y^2 - z^2$$\n    This is not the zero polynomial (it depends on $z$). Thus, $L_1$ does not divide $g$.\n\n2.  **Test $L_2$**: Similarly, substitute $x = \\bar{\\omega} y$ into $g$:\n    $$g(\\bar{\\omega} y, y, z) = \\bar{\\omega} y^2 - z^2 \\neq 0$$\n    Thus, $L_2$ does not divide $g$.\n\nSince neither linear factor of $f-g$ divides $g$, the polynomials $f$ and $g$ are coprime. Therefore, the curves have no common components.\n\n**Step 2c: Calculate Total Intersection Count**\nBy B\u00e9zout's Theorem, the total number of intersection points counted with multiplicity is:\n$$N = \\deg(f) \\cdot \\deg(g) = 2 \\cdot 2 = 4$$\n\n---\n\n### 3. Explicit Verification (Completeness Check)\n\nTo ensure the solution is robust and there are no edge cases (such as points at infinity or singular points affecting the count), we explicitly find the solutions.\n\n**System of Equations:**\n1. $x^2 + y^2 = z^2$\n2. $xy = z^2$\n\n**Case 1: Points at Infinity ($z=0$)**\nIf $z=0$, the system becomes:\n1. $x^2 + y^2 = 0$\n2. $xy = 0$\nFrom (2), either $x=0$ or $y=0$.\n- If $x=0$, then (1) implies $y^2=0 \\Rightarrow y=0$. Point: $[0:0:0]$, which is not in $\\mathbb{P}^2$.\n- If $y=0$, then (1) implies $x^2=0 \\Rightarrow x=0$. Same result.\nThus, there are **no intersection points at infinity**.\n\n**Case 2: Affine Points ($z=1$)**\nThe system becomes:\n1. $x^2 + y^2 = 1$\n2. $xy = 1$\n\nSubtract (2) from (1):\n$$x^2 - xy + y^2 = 0$$\nSince $xy=1$, $y \\neq 0$. Divide by $y^2$:\n$$\\left(\\frac{x}{y}\\right)^2 - \\left(\\frac{x}{y}\\right) + 1 = 0$$\nLet $u = x/y$. The roots are $u = \\frac{1 \\pm i\\sqrt{3}}{2} = e^{\\pm i\\pi/3}$.\nLet these roots be $\\omega$ and $\\bar{\\omega}$.\n\nSubcase 2a: $x = \\omega y$.\nSubstitute into $xy=1$: $\\omega y^2 = 1 \\implies y^2 = \\omega^{-1} = \\bar{\\omega}$.\n$$y = \\pm \\sqrt{\\bar{\\omega}}$$\nThis yields two distinct values for $y$, and consequently two distinct points $(x,y)$.\n\nSubcase 2b: $x = \\bar{\\omega} y$.\nSubstitute into $xy=1$: $\\bar{\\omega} y^2 = 1 \\implies y^2 = \\bar{\\omega}^{-1} = \\omega$.\n$$y = \\pm \\sqrt{\\omega}$$\nThis yields two distinct values for $y$, and consequently two distinct points.\n\n**Conclusion of Verification:**\nWe have found 4 distinct geometric points:\n1. $[\\omega\\sqrt{\\bar{\\omega}} : \\sqrt{\\bar{\\omega}} : 1]$\n2. $[-\\omega\\sqrt{\\bar{\\omega}} : -\\sqrt{\\bar{\\omega}} : 1]$\n3. $[\\bar{\\omega}\\sqrt{\\omega} : \\sqrt{\\omega} : 1]$\n4. $[-\\bar{\\omega}\\sqrt{\\omega} : -\\sqrt{\\omega} : 1]$\n\nSince there are 4 distinct points and the sum of multiplicities must be 4, each point has multiplicity 1 (the intersections are transversal).\n\n### 4. Final Answer\n\nThe curves $C_1$ and $C_2$ have no common component and are both of degree 2. By B\u00e9zout's Theorem, the number of intersection points counted with multiplicity is $2 \\times 2 = 4$.\n\nThe number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity, is 4.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $x > 0$ and consider the function $f(x) = \\frac{\\Gamma(x+1)}{x^x \\sqrt{x}}$, where $\\Gamma(x)$ denotes the Gamma function. Prove that $f(x)$ is strictly decreasing for $x > 0$.",
    "run_id": "21",
    "outer_attempt": 2,
    "topic_slug": "special_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the function $f(x) = \\frac{\\Gamma(x+1)}{x^x \\sqrt{x}}$ is strictly decreasing for $x > 0$, we will analyze the first derivative of its natural logarithm.\n\n### 1. Logarithmic Transformation\n\nLet $g(x) = \\ln f(x)$. Since the natural logarithm is a strictly increasing function, $f(x)$ is strictly decreasing if and only if $g(x)$ is strictly decreasing.\n\nFirst, simplify the expression for $f(x)$:\n$$f(x) = \\frac{\\Gamma(x+1)}{x^x \\cdot x^{1/2}} = \\frac{\\Gamma(x+1)}{x^{x + 1/2}}$$\nUsing the property $\\Gamma(x+1) = x\\Gamma(x)$, we can also write this as:\n$$f(x) = \\frac{x\\Gamma(x)}{x^{x + 1/2}} = \\frac{\\Gamma(x)}{x^{x - 1/2}}$$\nHowever, using the form involving $\\Gamma(x+1)$ directly is convenient. Taking the natural logarithm:\n$$g(x) = \\ln \\Gamma(x+1) - \\left(x + \\frac{1}{2}\\right)\\ln x$$\n\n### 2. Differentiation\n\nWe compute the derivative $g'(x)$ with respect to $x$. Recall that $\\frac{d}{dx} \\ln \\Gamma(z) = \\psi(z)$, where $\\psi(z)$ is the digamma function.\n$$g'(x) = \\frac{d}{dx} \\left( \\ln \\Gamma(x+1) \\right) - \\frac{d}{dx} \\left( \\left(x + \\frac{1}{2}\\right)\\ln x \\right)$$\n$$g'(x) = \\psi(x+1) - \\left[ 1 \\cdot \\ln x + \\left(x + \\frac{1}{2}\\right) \\cdot \\frac{1}{x} \\right]$$\n$$g'(x) = \\psi(x+1) - \\ln x - 1 - \\frac{1}{2x}$$\n\nUsing the recurrence relation $\\psi(x+1) = \\psi(x) + \\frac{1}{x}$, we substitute for $\\psi(x+1)$:\n$$g'(x) = \\left( \\psi(x) + \\frac{1}{x} \\right) - \\ln x - 1 - \\frac{1}{2x}$$\n$$g'(x) = \\psi(x) - \\ln x - 1 + \\frac{1}{2x}$$\n\nTo prove that $f(x)$ is strictly decreasing, we must show that $g'(x) < 0$ for all $x > 0$. In fact, we will prove the stronger inequality $g'(x) < -1$.\n\n### 3. Bound on the Digamma Function\n\nWe utilize the integral representation of the digamma function derived from Binet's second formula for $\\ln \\Gamma(x)$. For $x > 0$:\n$$\\psi(x) = \\ln x - \\frac{1}{2x} - \\int_0^\\infty \\left( \\frac{1}{e^t - 1} - \\frac{1}{t} + \\frac{1}{2} \\right) e^{-xt} \\, dt$$\nLet $\\phi(t) = \\frac{1}{e^t - 1} - \\frac{1}{t} + \\frac{1}{2}$. We investigate the sign of $\\phi(t)$ for $t > 0$.\nRewriting $\\phi(t)$:\n$$\\phi(t) = \\frac{2t - 2(e^t - 1) + t(e^t - 1)}{2t(e^t - 1)} = \\frac{2t - 2e^t + 2 + te^t - t}{2t(e^t - 1)} = \\frac{t + 2 + (t-2)e^t}{2t(e^t - 1)}$$\nSince $2t(e^t - 1) > 0$ for $t > 0$, the sign depends on the numerator $N(t) = t + 2 + (t-2)e^t$.\nWe compute the derivatives of $N(t)$:\n1. $N'(t) = 1 + [1 \\cdot e^t + (t-2)e^t] = 1 + (t-1)e^t$\n2. $N''(t) = [1 \\cdot e^t + (t-1)e^t] = te^t$\n\nFor $t > 0$, $N''(t) > 0$, so $N'(t)$ is strictly increasing.\nSince $N'(0) = 1 + (0-1)(1) = 0$, we have $N'(t) > 0$ for all $t > 0$.\nConsequently, $N(t)$ is strictly increasing.\nSince $N(0) = 0 + 2 + (-2)(1) = 0$, we have $N(t) > 0$ for all $t > 0$.\n\nThus, $\\phi(t) > 0$ for all $t > 0$. Since the integrand is strictly positive, the integral term is strictly positive:\n$$\\int_0^\\infty \\phi(t) e^{-xt} \\, dt > 0$$\nSubstituting this back into the expression for $\\psi(x)$:\n$$\\psi(x) < \\ln x - \\frac{1}{2x}$$\n\n### 4. Establishing the Sign of the Derivative\n\nNow we substitute the inequality for $\\psi(x)$ into our expression for $g'(x)$:\n$$g'(x) = \\psi(x) - \\ln x + \\frac{1}{2x} - 1$$\n$$g'(x) < \\left( \\ln x - \\frac{1}{2x} \\right) - \\ln x + \\frac{1}{2x} - 1$$\n$$g'(x) < -1$$\n\nSince $g'(x) < -1$ for all $x > 0$, it follows that $g'(x) < 0$.\n\n### Conclusion\n\nWe have shown that the derivative of $\\ln f(x)$ is strictly negative for all $x > 0$. Since a function with a strictly negative derivative is strictly decreasing, $g(x)$ is strictly decreasing. Therefore, $f(x) = e^{g(x)}$ is strictly decreasing for $x > 0$.\n\n**Final Result:** The function $f(x)$ is strictly decreasing for $x > 0$.",
        "raw_answer": "To prove that the function $f(x) = \\frac{\\Gamma(x+1)}{x^x \\sqrt{x}}$ is strictly decreasing for $x > 0$, we will analyze the first derivative of its natural logarithm.\n\n### 1. Logarithmic Transformation\n\nLet $g(x) = \\ln f(x)$. Since the natural logarithm is a strictly increasing function, $f(x)$ is strictly decreasing if and only if $g(x)$ is strictly decreasing.\n\nFirst, simplify the expression for $f(x)$:\n$$f(x) = \\frac{\\Gamma(x+1)}{x^x \\cdot x^{1/2}} = \\frac{\\Gamma(x+1)}{x^{x + 1/2}}$$\nUsing the property $\\Gamma(x+1) = x\\Gamma(x)$, we can also write this as:\n$$f(x) = \\frac{x\\Gamma(x)}{x^{x + 1/2}} = \\frac{\\Gamma(x)}{x^{x - 1/2}}$$\nHowever, using the form involving $\\Gamma(x+1)$ directly is convenient. Taking the natural logarithm:\n$$g(x) = \\ln \\Gamma(x+1) - \\left(x + \\frac{1}{2}\\right)\\ln x$$\n\n### 2. Differentiation\n\nWe compute the derivative $g'(x)$ with respect to $x$. Recall that $\\frac{d}{dx} \\ln \\Gamma(z) = \\psi(z)$, where $\\psi(z)$ is the digamma function.\n$$g'(x) = \\frac{d}{dx} \\left( \\ln \\Gamma(x+1) \\right) - \\frac{d}{dx} \\left( \\left(x + \\frac{1}{2}\\right)\\ln x \\right)$$\n$$g'(x) = \\psi(x+1) - \\left[ 1 \\cdot \\ln x + \\left(x + \\frac{1}{2}\\right) \\cdot \\frac{1}{x} \\right]$$\n$$g'(x) = \\psi(x+1) - \\ln x - 1 - \\frac{1}{2x}$$\n\nUsing the recurrence relation $\\psi(x+1) = \\psi(x) + \\frac{1}{x}$, we substitute for $\\psi(x+1)$:\n$$g'(x) = \\left( \\psi(x) + \\frac{1}{x} \\right) - \\ln x - 1 - \\frac{1}{2x}$$\n$$g'(x) = \\psi(x) - \\ln x - 1 + \\frac{1}{2x}$$\n\nTo prove that $f(x)$ is strictly decreasing, we must show that $g'(x) < 0$ for all $x > 0$. In fact, we will prove the stronger inequality $g'(x) < -1$.\n\n### 3. Bound on the Digamma Function\n\nWe utilize the integral representation of the digamma function derived from Binet's second formula for $\\ln \\Gamma(x)$. For $x > 0$:\n$$\\psi(x) = \\ln x - \\frac{1}{2x} - \\int_0^\\infty \\left( \\frac{1}{e^t - 1} - \\frac{1}{t} + \\frac{1}{2} \\right) e^{-xt} \\, dt$$\nLet $\\phi(t) = \\frac{1}{e^t - 1} - \\frac{1}{t} + \\frac{1}{2}$. We investigate the sign of $\\phi(t)$ for $t > 0$.\nRewriting $\\phi(t)$:\n$$\\phi(t) = \\frac{2t - 2(e^t - 1) + t(e^t - 1)}{2t(e^t - 1)} = \\frac{2t - 2e^t + 2 + te^t - t}{2t(e^t - 1)} = \\frac{t + 2 + (t-2)e^t}{2t(e^t - 1)}$$\nSince $2t(e^t - 1) > 0$ for $t > 0$, the sign depends on the numerator $N(t) = t + 2 + (t-2)e^t$.\nWe compute the derivatives of $N(t)$:\n1. $N'(t) = 1 + [1 \\cdot e^t + (t-2)e^t] = 1 + (t-1)e^t$\n2. $N''(t) = [1 \\cdot e^t + (t-1)e^t] = te^t$\n\nFor $t > 0$, $N''(t) > 0$, so $N'(t)$ is strictly increasing.\nSince $N'(0) = 1 + (0-1)(1) = 0$, we have $N'(t) > 0$ for all $t > 0$.\nConsequently, $N(t)$ is strictly increasing.\nSince $N(0) = 0 + 2 + (-2)(1) = 0$, we have $N(t) > 0$ for all $t > 0$.\n\nThus, $\\phi(t) > 0$ for all $t > 0$. Since the integrand is strictly positive, the integral term is strictly positive:\n$$\\int_0^\\infty \\phi(t) e^{-xt} \\, dt > 0$$\nSubstituting this back into the expression for $\\psi(x)$:\n$$\\psi(x) < \\ln x - \\frac{1}{2x}$$\n\n### 4. Establishing the Sign of the Derivative\n\nNow we substitute the inequality for $\\psi(x)$ into our expression for $g'(x)$:\n$$g'(x) = \\psi(x) - \\ln x + \\frac{1}{2x} - 1$$\n$$g'(x) < \\left( \\ln x - \\frac{1}{2x} \\right) - \\ln x + \\frac{1}{2x} - 1$$\n$$g'(x) < -1$$\n\nSince $g'(x) < -1$ for all $x > 0$, it follows that $g'(x) < 0$.\n\n### Conclusion\n\nWe have shown that the derivative of $\\ln f(x)$ is strictly negative for all $x > 0$. Since a function with a strictly negative derivative is strictly decreasing, $g(x)$ is strictly decreasing. Therefore, $f(x) = e^{g(x)}$ is strictly decreasing for $x > 0$.\n\n**Final Result:** The function $f(x)$ is strictly decreasing for $x > 0$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the given topic\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Sequences, series, summability\" along with a complete and verifiable solution. The problem should be simpler than the given previous attempt and must adhere to the quality rubric provided.\n\n## Step 2: Review the quality rubric for question generation\nThe question must be well-posed, clear, non-trivial, solvable, and verifiable. It should not have missing constraints, contradictory premises, multiple incompatible interpretations, undefined objects, or external dependencies.\n\n## Step 3: Analyze the previous attempt\nThe previous attempt was to evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$. This problem involves series and summability, indicating the topic is appropriate. However, the new problem should be simpler.\n\n## Step 4: Generate a new problem that is simpler and well-posed\nTo create a simpler problem, consider a basic series that is well-known and easy to compute. A good candidate could be evaluating a finite series or a simple infinite series that converges to a known value.\n\n## Step 5: Propose a specific problem\nLet's consider the series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$. This is a geometric series with the first term $a = \\frac{1}{2}$ and common ratio $r = \\frac{1}{2}$. The sum of an infinite geometric series is given by $\\frac{a}{1 - r}$ when $|r| < 1$, which applies here.\n\n## Step 6: Formulate the problem statement\nThe problem statement could be: \"Evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$.\"\n\n## Step 7: Provide a complete solution\nTo solve $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$, recognize it as a geometric series. The sum $S$ of the first $n$ terms of a geometric series can be calculated using $S_n = a\\frac{1-r^n}{1-r}$, where $a$ is the first term and $r$ is the common ratio. For an infinite geometric series where $|r| < 1$, the sum is $S = \\frac{a}{1-r}$.\n\n## Step 8: Calculate the sum\nHere, $a = \\frac{1}{2}$ and $r = \\frac{1}{2}$. So, $S = \\frac{\\frac{1}{2}}{1 - \\frac{1}{2}} = \\frac{\\frac{1}{2}}{\\frac{1}{2}} = 1$.\n\n## Step 9: Write the problem and solution in the required format\n\nEvaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$.",
    "run_id": "26",
    "outer_attempt": 2,
    "topic_slug": "sequences_series_and_summability",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$, we will identify the type of series, verify its convergence, and calculate its sum using the limit of partial sums.\n\n### 1. Identification of the Series\nThe given series is:\n$$ \\sum_{n=1}^{\\infty} \\frac{1}{2^n} = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\dots $$\nThis is a geometric series where each term is obtained by multiplying the previous term by a constant factor.\nLet the series be represented as $\\sum_{n=1}^{\\infty} a_n$.\nThe first term is $a = a_1 = \\frac{1}{2}$.\nThe common ratio $r$ is determined by the ratio of consecutive terms:\n$$ r = \\frac{a_{n+1}}{a_n} = \\frac{1/2^{n+1}}{1/2^n} = \\frac{2^n}{2^{n+1}} = \\frac{1}{2} $$\n\n### 2. Condition for Convergence\nA geometric series $\\sum_{n=0}^{\\infty} ar^n$ (or $\\sum_{n=1}^{\\infty} ar^{n-1}$) converges if and only if the absolute value of the common ratio $|r| < 1$.\nIn this case:\n$$ |r| = \\left| \\frac{1}{2} \\right| = \\frac{1}{2} $$\nSince $\\frac{1}{2} < 1$, the series converges to a finite value.\n\n### 3. Calculation of the Sum\nWe can determine the sum by looking at the partial sum $S_N$ of the first $N$ terms:\n$$ S_N = \\sum_{n=1}^{N} \\frac{1}{2^n} = \\frac{1}{2} + \\frac{1}{4} + \\dots + \\frac{1}{2^N} $$\nMultiplying the partial sum by the common ratio $r = \\frac{1}{2}$:\n$$ \\frac{1}{2} S_N = \\frac{1}{4} + \\frac{1}{8} + \\dots + \\frac{1}{2^{N+1}} $$\nSubtracting the equation for $\\frac{1}{2} S_N$ from the equation for $S_N$:\n$$ S_N - \\frac{1}{2} S_N = \\left( \\frac{1}{2} + \\frac{1}{4} + \\dots + \\frac{1}{2^N} \\right) - \\left( \\frac{1}{4} + \\frac{1}{8} + \\dots + \\frac{1}{2^{N+1}} \\right) $$\nMost intermediate terms cancel out (telescoping sum effect):\n$$ \\frac{1}{2} S_N = \\frac{1}{2} - \\frac{1}{2^{N+1}} $$\nMultiplying both sides by 2:\n$$ S_N = 1 - \\frac{1}{2^N} $$\nThe value of the infinite series $S$ is the limit of the partial sums as $N$ approaches infinity:\n$$ S = \\lim_{N \\to \\infty} S_N = \\lim_{N \\to \\infty} \\left( 1 - \\frac{1}{2^N} \\right) $$\nSince $\\lim_{N \\to \\infty} \\frac{1}{2^N} = 0$:\n$$ S = 1 - 0 = 1 $$\n\n### Alternative Method: Standard Formula\nFor a convergent infinite geometric series with first term $a$ and common ratio $r$, the sum is given by the formula:\n$$ S = \\frac{a}{1 - r} $$\nSubstituting $a = \\frac{1}{2}$ and $r = \\frac{1}{2}$:\n$$ S = \\frac{1/2}{1 - 1/2} = \\frac{1/2}{1/2} = 1 $$\n\n### Conclusion\nThe value of the infinite series is:\n$$ \\sum_{n=1}^{\\infty} \\frac{1}{2^n} = 1 $$",
        "raw_answer": "To evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$, we will identify the type of series, verify its convergence, and calculate its sum using the limit of partial sums.\n\n### 1. Identification of the Series\nThe given series is:\n$$ \\sum_{n=1}^{\\infty} \\frac{1}{2^n} = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\dots $$\nThis is a geometric series where each term is obtained by multiplying the previous term by a constant factor.\nLet the series be represented as $\\sum_{n=1}^{\\infty} a_n$.\nThe first term is $a = a_1 = \\frac{1}{2}$.\nThe common ratio $r$ is determined by the ratio of consecutive terms:\n$$ r = \\frac{a_{n+1}}{a_n} = \\frac{1/2^{n+1}}{1/2^n} = \\frac{2^n}{2^{n+1}} = \\frac{1}{2} $$\n\n### 2. Condition for Convergence\nA geometric series $\\sum_{n=0}^{\\infty} ar^n$ (or $\\sum_{n=1}^{\\infty} ar^{n-1}$) converges if and only if the absolute value of the common ratio $|r| < 1$.\nIn this case:\n$$ |r| = \\left| \\frac{1}{2} \\right| = \\frac{1}{2} $$\nSince $\\frac{1}{2} < 1$, the series converges to a finite value.\n\n### 3. Calculation of the Sum\nWe can determine the sum by looking at the partial sum $S_N$ of the first $N$ terms:\n$$ S_N = \\sum_{n=1}^{N} \\frac{1}{2^n} = \\frac{1}{2} + \\frac{1}{4} + \\dots + \\frac{1}{2^N} $$\nMultiplying the partial sum by the common ratio $r = \\frac{1}{2}$:\n$$ \\frac{1}{2} S_N = \\frac{1}{4} + \\frac{1}{8} + \\dots + \\frac{1}{2^{N+1}} $$\nSubtracting the equation for $\\frac{1}{2} S_N$ from the equation for $S_N$:\n$$ S_N - \\frac{1}{2} S_N = \\left( \\frac{1}{2} + \\frac{1}{4} + \\dots + \\frac{1}{2^N} \\right) - \\left( \\frac{1}{4} + \\frac{1}{8} + \\dots + \\frac{1}{2^{N+1}} \\right) $$\nMost intermediate terms cancel out (telescoping sum effect):\n$$ \\frac{1}{2} S_N = \\frac{1}{2} - \\frac{1}{2^{N+1}} $$\nMultiplying both sides by 2:\n$$ S_N = 1 - \\frac{1}{2^N} $$\nThe value of the infinite series $S$ is the limit of the partial sums as $N$ approaches infinity:\n$$ S = \\lim_{N \\to \\infty} S_N = \\lim_{N \\to \\infty} \\left( 1 - \\frac{1}{2^N} \\right) $$\nSince $\\lim_{N \\to \\infty} \\frac{1}{2^N} = 0$:\n$$ S = 1 - 0 = 1 $$\n\n### Alternative Method: Standard Formula\nFor a convergent infinite geometric series with first term $a$ and common ratio $r$, the sum is given by the formula:\n$$ S = \\frac{a}{1 - r} $$\nSubstituting $a = \\frac{1}{2}$ and $r = \\frac{1}{2}$:\n$$ S = \\frac{1/2}{1 - 1/2} = \\frac{1/2}{1/2} = 1 $$\n\n### Conclusion\nThe value of the infinite series is:\n$$ \\sum_{n=1}^{\\infty} \\frac{1}{2^n} = 1 $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the given topic\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Harmonic analysis on Euclidean spaces\" along with a complete and verifiable solution. The problem should be simpler than the given previous attempts but still challenging.\n\n## Step 2: Review the previous attempts and identify the complexity\nThe previous attempt was to prove that a function $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ with its Fourier transform $\\hat{f}$ supported in $B(0,1)$ is smooth and satisfies a certain decay condition. This involves understanding the properties of the Fourier transform, its relation to smoothness, and decay properties of functions.\n\n## Step 3: Simplify the problem while maintaining relevance to the topic\nTo simplify, we can consider a specific case or a related property. For instance, examining the properties of the Fourier transform on $L^2(\\mathbb{R}^n)$ or exploring the smoothness and decay properties for a specific class of functions.\n\n## Step 4: Formulate a new problem\nLet's consider a problem that involves understanding the Fourier transform and its properties. A potential problem could be: \"Let $f(x) = e^{-\\pi|x|^2}$ for $x \\in \\mathbb{R}^n$. Show that $f$ is an eigenfunction of the Fourier transform, i.e., $\\hat{f}(\\xi) = c f(\\xi)$ for some constant $c$, and determine $c$.\"\n\n## Step 5: Verify that the new problem is well-posed and solvable\nThe function $f(x) = e^{-\\pi|x|^2}$ is well-defined and belongs to $L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$. The Fourier transform of $f$ is given by $\\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} e^{-\\pi|x|^2} e^{-2\\pi i x \\cdot \\xi} dx$. This is a standard Gaussian integral, which can be evaluated.\n\n## Step 6: Solve the problem\nTo solve, we compute $\\hat{f}(\\xi)$. For $n=1$, $\\hat{f}(\\xi) = \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} e^{-2\\pi i x \\xi} dx = e^{-\\pi \\xi^2}$, using the known Fourier transform of a Gaussian. For $\\mathbb{R}^n$, the result generalizes to $\\hat{f}(\\xi) = e^{-\\pi |\\xi|^2}$ because the integral separates into $n$ one-dimensional integrals.\n\n## Step 7: Determine the constant $c$\nSince $\\hat{f}(\\xi) = e^{-\\pi |\\xi|^2} = f(\\xi)$, we have $c = 1$.\n\n## Step 8: Present the problem and solution in the required format\n\nLet $f(x) = e^{-\\pi|x|^2}$ for $x \\in \\mathbb{R}^n$. Show that $f$ is an eigenfunction of the Fourier transform, i.e., $\\hat{f}(\\xi) = c f(\\xi)$ for some constant $c$, and determine $c$.",
    "run_id": "28",
    "outer_attempt": 2,
    "topic_slug": "harmonic_analysis_on_euclidean_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete solution to the problem.\n\n### **1. Definitions and Setup**\n\nTo solve the problem, we first establish the standard definition of the Fourier transform used in harmonic analysis on Euclidean spaces. For a function $f \\in L^1(\\mathbb{R}^n)$, the Fourier transform $\\hat{f}$ is defined by:\n$$ \\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} f(x) e^{-2\\pi i x \\cdot \\xi} \\, dx $$\nwhere $x \\cdot \\xi = \\sum_{j=1}^n x_j \\xi_j$ is the standard inner product in $\\mathbb{R}^n$.\n\nWe are given the Gaussian function:\n$$ f(x) = e^{-\\pi|x|^2} $$\nwhere $|x|^2 = \\sum_{j=1}^n x_j^2$. Note that $f$ belongs to the Schwartz space $\\mathcal{S}(\\mathbb{R}^n)$ (and thus $L^1(\\mathbb{R}^n)$), so the integral is well-defined.\n\n---\n\n### **2. Reduction to One Dimension**\n\nUsing the property of the exponential function, we can factor $f(x)$ and the kernel $e^{-2\\pi i x \\cdot \\xi}$ into products of one-dimensional terms:\n$$ f(x) = e^{-\\pi \\sum_{j=1}^n x_j^2} = \\prod_{j=1}^n e^{-\\pi x_j^2} $$\n$$ e^{-2\\pi i x \\cdot \\xi} = e^{-2\\pi i \\sum_{j=1}^n x_j \\xi_j} = \\prod_{j=1}^n e^{-2\\pi i x_j \\xi_j} $$\n\nSubstituting these into the definition of the Fourier transform:\n$$ \\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} \\left( \\prod_{j=1}^n e^{-\\pi x_j^2} \\right) \\left( \\prod_{j=1}^n e^{-2\\pi i x_j \\xi_j} \\right) \\, dx $$\n\nBy Fubini's Theorem, since the integrand is separable and absolutely integrable, we can write the integral over $\\mathbb{R}^n$ as a product of $n$ integrals over $\\mathbb{R}$:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi x_j^2} e^{-2\\pi i x_j \\xi_j} \\, dx_j \\right) $$\n\nLet us define the one-dimensional integral $I(k)$ for a scalar variable $k \\in \\mathbb{R}$:\n$$ I(k) = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2 - 2\\pi i t k} \\, dt $$\nThen the $n$-dimensional Fourier transform is:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n I(\\xi_j) $$\n\n---\n\n### **3. Evaluation of the One-Dimensional Integral**\n\nWe calculate $I(k) = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2 - 2\\pi i t k} \\, dt$.\n\n**Step 3.1: Completing the Square**\nWe manipulate the exponent to form a perfect square:\n$$ -\\pi t^2 - 2\\pi i t k = -\\pi (t^2 + 2i t k) $$\nAdd and subtract $(ik)^2 = -k^2$ inside the parenthesis:\n$$ -\\pi (t^2 + 2i t k - k^2 + k^2) = -\\pi ( (t+ik)^2 + k^2 ) = -\\pi(t+ik)^2 - \\pi k^2 $$\nThus, the integral becomes:\n$$ I(k) = \\int_{-\\infty}^{\\infty} e^{-\\pi(t+ik)^2 - \\pi k^2} \\, dt = e^{-\\pi k^2} \\int_{-\\infty}^{\\infty} e^{-\\pi(t+ik)^2} \\, dt $$\n\n**Step 3.2: Contour Integration**\nLet $J = \\int_{-\\infty}^{\\infty} e^{-\\pi(t+ik)^2} \\, dt$.\nConsider the complex function $g(z) = e^{-\\pi z^2}$. We integrate $g(z)$ over a rectangular contour $C$ in the complex plane with vertices at $-R, R, R+ik, -R+ik$ (assuming $k>0$ without loss of generality; the result holds for all real $k$).\n\nBy Cauchy's Integral Theorem, since $g(z)$ is analytic on the entire complex plane:\n$$ \\oint_C e^{-\\pi z^2} \\, dz = 0 $$\n$$ \\int_{-R}^{R} e^{-\\pi x^2} \\, dx + \\int_{0}^{k} e^{-\\pi (R+iy)^2} i \\, dy + \\int_{R}^{-R} e^{-\\pi (x+ik)^2} \\, dx + \\int_{k}^{0} e^{-\\pi (-R+iy)^2} i \\, dy = 0 $$\n\nAs $R \\to \\infty$, the integrals along the vertical sides vanish. For example, on the right side $z = R+iy$:\n$$ |e^{-\\pi(R+iy)^2}| = |e^{-\\pi(R^2 - y^2 + 2iRy)}| = e^{-\\pi R^2} e^{\\pi y^2} $$\nSince $y$ is bounded between $0$ and $k$, $e^{\\pi y^2}$ is bounded, and the term decays rapidly to $0$ as $R \\to \\infty$.\n\nThus, taking the limit $R \\to \\infty$, we obtain:\n$$ \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} \\, dx - \\int_{-\\infty}^{\\infty} e^{-\\pi (x+ik)^2} \\, dx = 0 $$\n$$ \\implies \\int_{-\\infty}^{\\infty} e^{-\\pi (t+ik)^2} \\, dt = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2} \\, dt $$\n\n**Step 3.3: Calculating the Gaussian Integral**\nLet $G = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2} \\, dt$.\nWe compute $G^2$ using polar coordinates:\n$$ G^2 = \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} \\, dx \\right) \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi y^2} \\, dy \\right) = \\int_{\\mathbb{R}^2} e^{-\\pi(x^2+y^2)} \\, dx \\, dy $$\n$$ G^2 = \\int_{0}^{2\\pi} d\\theta \\int_{0}^{\\infty} e^{-\\pi r^2} r \\, dr $$\nLet $u = \\pi r^2$, then $du = 2\\pi r dr$, so $r dr = \\frac{1}{2\\pi} du$.\n$$ G^2 = 2\\pi \\int_{0}^{\\infty} e^{-u} \\frac{1}{2\\pi} \\, du = \\int_{0}^{\\infty} e^{-u} \\, du = 1 $$\nSince $e^{-\\pi t^2}$ is positive, $G = 1$.\n\n**Step 3.4: Final Expression for $I(k)$**\nCombining the results:\n$$ I(k) = e^{-\\pi k^2} \\cdot G = e^{-\\pi k^2} $$\n\n---\n\n### **4. Conclusion**\n\nSubstituting $I(\\xi_j) = e^{-\\pi \\xi_j^2}$ back into the $n$-dimensional product:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n e^{-\\pi \\xi_j^2} = e^{-\\pi \\sum_{j=1}^n \\xi_j^2} = e^{-\\pi |\\xi|^2} $$\n\nWe observe that:\n$$ \\hat{f}(\\xi) = f(\\xi) $$\n\nThis equation is of the form $\\hat{f}(\\xi) = c f(\\xi)$ with $c=1$.\n\n**Answer:**\nThe function $f(x) = e^{-\\pi|x|^2}$ is an eigenfunction of the Fourier transform with eigenvalue **$c = 1$**.",
        "raw_answer": "Here is the complete solution to the problem.\n\n### **1. Definitions and Setup**\n\nTo solve the problem, we first establish the standard definition of the Fourier transform used in harmonic analysis on Euclidean spaces. For a function $f \\in L^1(\\mathbb{R}^n)$, the Fourier transform $\\hat{f}$ is defined by:\n$$ \\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} f(x) e^{-2\\pi i x \\cdot \\xi} \\, dx $$\nwhere $x \\cdot \\xi = \\sum_{j=1}^n x_j \\xi_j$ is the standard inner product in $\\mathbb{R}^n$.\n\nWe are given the Gaussian function:\n$$ f(x) = e^{-\\pi|x|^2} $$\nwhere $|x|^2 = \\sum_{j=1}^n x_j^2$. Note that $f$ belongs to the Schwartz space $\\mathcal{S}(\\mathbb{R}^n)$ (and thus $L^1(\\mathbb{R}^n)$), so the integral is well-defined.\n\n---\n\n### **2. Reduction to One Dimension**\n\nUsing the property of the exponential function, we can factor $f(x)$ and the kernel $e^{-2\\pi i x \\cdot \\xi}$ into products of one-dimensional terms:\n$$ f(x) = e^{-\\pi \\sum_{j=1}^n x_j^2} = \\prod_{j=1}^n e^{-\\pi x_j^2} $$\n$$ e^{-2\\pi i x \\cdot \\xi} = e^{-2\\pi i \\sum_{j=1}^n x_j \\xi_j} = \\prod_{j=1}^n e^{-2\\pi i x_j \\xi_j} $$\n\nSubstituting these into the definition of the Fourier transform:\n$$ \\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} \\left( \\prod_{j=1}^n e^{-\\pi x_j^2} \\right) \\left( \\prod_{j=1}^n e^{-2\\pi i x_j \\xi_j} \\right) \\, dx $$\n\nBy Fubini's Theorem, since the integrand is separable and absolutely integrable, we can write the integral over $\\mathbb{R}^n$ as a product of $n$ integrals over $\\mathbb{R}$:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi x_j^2} e^{-2\\pi i x_j \\xi_j} \\, dx_j \\right) $$\n\nLet us define the one-dimensional integral $I(k)$ for a scalar variable $k \\in \\mathbb{R}$:\n$$ I(k) = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2 - 2\\pi i t k} \\, dt $$\nThen the $n$-dimensional Fourier transform is:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n I(\\xi_j) $$\n\n---\n\n### **3. Evaluation of the One-Dimensional Integral**\n\nWe calculate $I(k) = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2 - 2\\pi i t k} \\, dt$.\n\n**Step 3.1: Completing the Square**\nWe manipulate the exponent to form a perfect square:\n$$ -\\pi t^2 - 2\\pi i t k = -\\pi (t^2 + 2i t k) $$\nAdd and subtract $(ik)^2 = -k^2$ inside the parenthesis:\n$$ -\\pi (t^2 + 2i t k - k^2 + k^2) = -\\pi ( (t+ik)^2 + k^2 ) = -\\pi(t+ik)^2 - \\pi k^2 $$\nThus, the integral becomes:\n$$ I(k) = \\int_{-\\infty}^{\\infty} e^{-\\pi(t+ik)^2 - \\pi k^2} \\, dt = e^{-\\pi k^2} \\int_{-\\infty}^{\\infty} e^{-\\pi(t+ik)^2} \\, dt $$\n\n**Step 3.2: Contour Integration**\nLet $J = \\int_{-\\infty}^{\\infty} e^{-\\pi(t+ik)^2} \\, dt$.\nConsider the complex function $g(z) = e^{-\\pi z^2}$. We integrate $g(z)$ over a rectangular contour $C$ in the complex plane with vertices at $-R, R, R+ik, -R+ik$ (assuming $k>0$ without loss of generality; the result holds for all real $k$).\n\nBy Cauchy's Integral Theorem, since $g(z)$ is analytic on the entire complex plane:\n$$ \\oint_C e^{-\\pi z^2} \\, dz = 0 $$\n$$ \\int_{-R}^{R} e^{-\\pi x^2} \\, dx + \\int_{0}^{k} e^{-\\pi (R+iy)^2} i \\, dy + \\int_{R}^{-R} e^{-\\pi (x+ik)^2} \\, dx + \\int_{k}^{0} e^{-\\pi (-R+iy)^2} i \\, dy = 0 $$\n\nAs $R \\to \\infty$, the integrals along the vertical sides vanish. For example, on the right side $z = R+iy$:\n$$ |e^{-\\pi(R+iy)^2}| = |e^{-\\pi(R^2 - y^2 + 2iRy)}| = e^{-\\pi R^2} e^{\\pi y^2} $$\nSince $y$ is bounded between $0$ and $k$, $e^{\\pi y^2}$ is bounded, and the term decays rapidly to $0$ as $R \\to \\infty$.\n\nThus, taking the limit $R \\to \\infty$, we obtain:\n$$ \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} \\, dx - \\int_{-\\infty}^{\\infty} e^{-\\pi (x+ik)^2} \\, dx = 0 $$\n$$ \\implies \\int_{-\\infty}^{\\infty} e^{-\\pi (t+ik)^2} \\, dt = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2} \\, dt $$\n\n**Step 3.3: Calculating the Gaussian Integral**\nLet $G = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2} \\, dt$.\nWe compute $G^2$ using polar coordinates:\n$$ G^2 = \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} \\, dx \\right) \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi y^2} \\, dy \\right) = \\int_{\\mathbb{R}^2} e^{-\\pi(x^2+y^2)} \\, dx \\, dy $$\n$$ G^2 = \\int_{0}^{2\\pi} d\\theta \\int_{0}^{\\infty} e^{-\\pi r^2} r \\, dr $$\nLet $u = \\pi r^2$, then $du = 2\\pi r dr$, so $r dr = \\frac{1}{2\\pi} du$.\n$$ G^2 = 2\\pi \\int_{0}^{\\infty} e^{-u} \\frac{1}{2\\pi} \\, du = \\int_{0}^{\\infty} e^{-u} \\, du = 1 $$\nSince $e^{-\\pi t^2}$ is positive, $G = 1$.\n\n**Step 3.4: Final Expression for $I(k)$**\nCombining the results:\n$$ I(k) = e^{-\\pi k^2} \\cdot G = e^{-\\pi k^2} $$\n\n---\n\n### **4. Conclusion**\n\nSubstituting $I(\\xi_j) = e^{-\\pi \\xi_j^2}$ back into the $n$-dimensional product:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n e^{-\\pi \\xi_j^2} = e^{-\\pi \\sum_{j=1}^n \\xi_j^2} = e^{-\\pi |\\xi|^2} $$\n\nWe observe that:\n$$ \\hat{f}(\\xi) = f(\\xi) $$\n\nThis equation is of the form $\\hat{f}(\\xi) = c f(\\xi)$ with $c=1$.\n\n**Answer:**\nThe function $f(x) = e^{-\\pi|x|^2}$ is an eigenfunction of the Fourier transform with eigenvalue **$c = 1$**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $G$ be a locally compact abelian group with Haar measure $\\mu$. Suppose $f \\in L^1(G, \\mu) \\cap L^2(G, \\mu)$ and that the Fourier transform of $f$, denoted $\\hat{f}$, is also in $L^1(G, \\mu)$. Prove that $f$ is equal almost everywhere to a continuous function on $G$.",
    "run_id": "29",
    "outer_attempt": 2,
    "topic_slug": "abstract_harmonic_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Analysis of the Problem Statement**\n\nThe question asks for a proof regarding a function $f$ on a locally compact abelian group $G$. However, the problem statement contains a fundamental mathematical inconsistency regarding the domain of the Fourier transform. Therefore, the question is **ill-posed** and cannot be answered rigorously as stated.\n\n**Specific Violation: Undefined Objects and Domain Mismatch**\n\n1.  **Definitions and Domains:**\n    *   Let $G$ be a locally compact abelian group with Haar measure $\\mu$.\n    *   The function $f$ is given to be in $L^1(G, \\mu) \\cap L^2(G, \\mu)$, meaning $f$ is a function defined on the group $G$.\n    *   The Fourier transform of $f$, denoted $\\hat{f}$, is a function defined on the **dual group** $\\widehat{G}$. That is, $\\hat{f}: \\widehat{G} \\to \\mathbb{C}$, defined (for $f \\in L^1$) by $\\hat{f}(\\gamma) = \\int_G f(x) \\overline{\\gamma(x)} \\, d\\mu(x)$ for $\\gamma \\in \\widehat{G}$.\n\n2.  **The Error:**\n    *   The problem states: \"the Fourier transform of $f$... is also in $L^1(G, \\mu)$.\"\n    *   The space $L^1(G, \\mu)$ consists of equivalence classes of integrable functions defined on the group $G$.\n    *   Since $\\hat{f}$ is defined on the dual group $\\widehat{G}$, it cannot belong to $L^1(G, \\mu)$ unless $G$ and $\\widehat{G}$ are the same space.\n    *   For a general locally compact abelian group, $G$ and $\\widehat{G}$ are distinct. For example, if $G$ is the circle group $\\mathbb{T}$, then $\\widehat{G}$ is the group of integers $\\mathbb{Z}$. A function defined on $\\mathbb{Z}$ (a sequence) cannot belong to $L^1(\\mathbb{T})$ (functions on the circle).\n\n**Conclusion**\n\nThe premise $\\hat{f} \\in L^1(G, \\mu)$ treats a function defined on the dual group $\\widehat{G}$ as a function on the primal group $G$. Without a specific canonical identification between $G$ and $\\widehat{G}$ (which does not exist for general LCA groups), this condition is mathematically undefined.\n\n**Suggestion for Clarification**\n\nTo make the question well-posed and answerable, the condition on the Fourier transform should be defined on the appropriate measure space. The likely intended hypothesis is:\n$$ \\hat{f} \\in L^1(\\widehat{G}, \\widehat{\\mu}) $$\nwhere $\\widehat{\\mu}$ is the Haar measure on the dual group $\\widehat{G}$. Under this corrected hypothesis, the problem becomes a standard application of the Fourier Inversion Theorem, which states that if $f \\in L^1(G)$ and $\\hat{f} \\in L^1(\\widehat{G})$, then $f$ agrees almost everywhere with a continuous function (specifically, the inverse Fourier transform of $\\hat{f}$).",
        "raw_answer": "**Analysis of the Problem Statement**\n\nThe question asks for a proof regarding a function $f$ on a locally compact abelian group $G$. However, the problem statement contains a fundamental mathematical inconsistency regarding the domain of the Fourier transform. Therefore, the question is **ill-posed** and cannot be answered rigorously as stated.\n\n**Specific Violation: Undefined Objects and Domain Mismatch**\n\n1.  **Definitions and Domains:**\n    *   Let $G$ be a locally compact abelian group with Haar measure $\\mu$.\n    *   The function $f$ is given to be in $L^1(G, \\mu) \\cap L^2(G, \\mu)$, meaning $f$ is a function defined on the group $G$.\n    *   The Fourier transform of $f$, denoted $\\hat{f}$, is a function defined on the **dual group** $\\widehat{G}$. That is, $\\hat{f}: \\widehat{G} \\to \\mathbb{C}$, defined (for $f \\in L^1$) by $\\hat{f}(\\gamma) = \\int_G f(x) \\overline{\\gamma(x)} \\, d\\mu(x)$ for $\\gamma \\in \\widehat{G}$.\n\n2.  **The Error:**\n    *   The problem states: \"the Fourier transform of $f$... is also in $L^1(G, \\mu)$.\"\n    *   The space $L^1(G, \\mu)$ consists of equivalence classes of integrable functions defined on the group $G$.\n    *   Since $\\hat{f}$ is defined on the dual group $\\widehat{G}$, it cannot belong to $L^1(G, \\mu)$ unless $G$ and $\\widehat{G}$ are the same space.\n    *   For a general locally compact abelian group, $G$ and $\\widehat{G}$ are distinct. For example, if $G$ is the circle group $\\mathbb{T}$, then $\\widehat{G}$ is the group of integers $\\mathbb{Z}$. A function defined on $\\mathbb{Z}$ (a sequence) cannot belong to $L^1(\\mathbb{T})$ (functions on the circle).\n\n**Conclusion**\n\nThe premise $\\hat{f} \\in L^1(G, \\mu)$ treats a function defined on the dual group $\\widehat{G}$ as a function on the primal group $G$. Without a specific canonical identification between $G$ and $\\widehat{G}$ (which does not exist for general LCA groups), this condition is mathematically undefined.\n\n**Suggestion for Clarification**\n\nTo make the question well-posed and answerable, the condition on the Fourier transform should be defined on the appropriate measure space. The likely intended hypothesis is:\n$$ \\hat{f} \\in L^1(\\widehat{G}, \\widehat{\\mu}) $$\nwhere $\\widehat{\\mu}$ is the Haar measure on the dual group $\\widehat{G}$. Under this corrected hypothesis, the problem becomes a standard application of the Fourier Inversion Theorem, which states that if $f \\in L^1(G)$ and $\\hat{f} \\in L^1(\\widehat{G})$, then $f$ agrees almost everywhere with a continuous function (specifically, the inverse Fourier transform of $\\hat{f}$).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Operator Theory, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Review the given topic and previous attempts\nThe topic is Operator Theory, and a previous attempt was made with the question: \"Let $T: L^2[0,1] \\to L^2[0,1]$ be defined by $Tf(x) = \\int_{0}^{x} f(t) dt$. Prove that $T$ is compact and find its spectrum.\" This question was adjudicated incorrect, and we need to generate a materially different, well-posed, and simpler question.\n\n## Step 3: Identify key concepts in Operator Theory\nOperator Theory involves the study of linear operators between vector spaces, particularly focusing on their properties such as boundedness, compactness, and spectral properties. A simpler question should still involve these concepts but in a more straightforward manner.\n\n## Step 4: Generate a new problem\nTo create a simpler problem, consider a basic operator and ask a fundamental question about its properties. For example, consider the operator $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ defined by a matrix. We can ask to determine if $T$ is bounded and find its spectrum.\n\n## Step 5: Formulate the problem\nLet's define $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ by $T(x, y) = (x + y, y)$. This can be represented by the matrix $\\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$. The task is to show that $T$ is bounded and to find its spectrum.\n\n## Step 6: Write the problem statement\n\"Let $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ be defined by $T(x, y) = (x + y, y)$. Show that $T$ is a bounded operator and find its spectrum.\"\n\n## Step 7: Provide the solution\nTo show $T$ is bounded, we need to show there exists a constant $M$ such that $\\|T(x, y)\\| \\leq M\\|(x, y)\\|$ for all $(x, y) \\in \\mathbb{C}^2$. Using the standard Euclidean norm, $\\|(x, y)\\| = \\sqrt{|x|^2 + |y|^2}$, we have $\\|T(x, y)\\| = \\|(x + y, y)\\| = \\sqrt{|x + y|^2 + |y|^2}$. By the triangle inequality, $|x + y| \\leq |x| + |y|$, so $|x + y|^2 \\leq (|x| + |y|)^2 \\leq 2(|x|^2 + |y|^2)$, hence $\\|T(x, y)\\| = \\sqrt{|x + y|^2 + |y|^2} \\leq \\sqrt{2(|x|^2 + |y|^2) + |y|^2} = \\sqrt{2|x|^2 + 3|y|^2} \\leq \\sqrt{3(|x|^2 + |y|^2)} = \\sqrt{3}\\|(x, y)\\|$. Thus, $T$ is bounded with $M = \\sqrt{3}$.\n\nTo find the spectrum, we need to find $\\lambda$ such that $T - \\lambda I$ is not invertible. The matrix representation of $T - \\lambda I$ is $\\begin{pmatrix} 1 - \\lambda & 1 \\\\ 0 & 1 - \\lambda \\end{pmatrix}$. This matrix is not invertible if its determinant is zero, i.e., $(1 - \\lambda)^2 = 0$. Thus, $\\lambda = 1$ is the only eigenvalue, and since $T$ is a bounded operator on a finite-dimensional space, its spectrum consists of its eigenvalues. Hence, the spectrum of $T$ is $\\{1\\}$.\n\n## Step 8: Format the output\n\nLet $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ be defined by $T(x, y) = (x + y, y)$. Show that $T$ is a bounded operator and find its spectrum.",
    "run_id": "33",
    "outer_attempt": 2,
    "topic_slug": "operator_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete solution to the problem.\n\n### Problem Statement\nLet $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ be defined by $T(x, y) = (x + y, y)$. Show that $T$ is a bounded operator and find its spectrum.\n\n---\n\n### Solution\n\n#### Part 1: Boundedness of $T$\n\n**Definition**: Let $V$ be a normed vector space. A linear operator $T: V \\to V$ is **bounded** if there exists a real constant $M \\geq 0$ such that for all vectors $\\mathbf{v} \\in V$:\n$$ \\|T\\mathbf{v}\\| \\leq M \\|\\mathbf{v}\\| $$\n\nWe equip $\\mathbb{C}^2$ with the standard Euclidean norm. For a vector $\\mathbf{v} = (x, y) \\in \\mathbb{C}^2$, the norm is defined as:\n$$ \\|\\mathbf{v}\\| = \\sqrt{|x|^2 + |y|^2} $$\n\nWe examine the norm of the image $T(x, y) = (x+y, y)$:\n$$ \\|T(x, y)\\|^2 = |x + y|^2 + |y|^2 $$\n\nUsing the triangle inequality ($|a+b| \\leq |a| + |b|$) and the elementary inequality $(a+b)^2 \\leq 2(a^2 + b^2)$ for real $a,b \\geq 0$, we have:\n$$ |x + y|^2 \\leq (|x| + |y|)^2 \\leq 2(|x|^2 + |y|^2) $$\n\nSubstituting this back into the expression for $\\|T(x, y)\\|^2$:\n$$ \\begin{aligned} \\|T(x, y)\\|^2 &= |x + y|^2 + |y|^2 \\\\ &\\leq 2(|x|^2 + |y|^2) + |y|^2 \\\\ &= 2|x|^2 + 3|y|^2 \\end{aligned} $$\n\nSince $2|x|^2 + 3|y|^2 \\leq 3|x|^2 + 3|y|^2 = 3(|x|^2 + |y|^2)$, we obtain:\n$$ \\|T(x, y)\\|^2 \\leq 3 \\|\\mathbf{v}\\|^2 $$\n\nTaking the square root of both sides gives:\n$$ \\|T(x, y)\\| \\leq \\sqrt{3} \\|\\mathbf{v}\\| $$\n\nThis inequality holds for all $(x,y) \\in \\mathbb{C}^2$. Thus, $T$ is a bounded operator.\n\n*(Note: While it is a standard theorem that every linear operator on a finite-dimensional normed space is bounded, the explicit derivation above confirms the property directly from the definition.)*\n\n#### Part 2: Spectrum of $T$\n\n**Definition**: The spectrum of a bounded linear operator $T$ on a vector space $V$, denoted $\\sigma(T)$, is the set of scalars $\\lambda \\in \\mathbb{C}$ such that the operator $T - \\lambda I$ is not invertible.\n\nSince $\\mathbb{C}^2$ is finite-dimensional, the operator $T - \\lambda I$ is not invertible if and only if its determinant is zero. Therefore, the spectrum consists exactly of the eigenvalues of $T$.\n\nWe find the matrix representation of $T$ with respect to the standard basis $e_1 = (1, 0)$ and $e_2 = (0, 1)$:\n1. $T(e_1) = T(1, 0) = (1+0, 0) = (1, 0) = 1e_1 + 0e_2$\n2. $T(e_2) = T(0, 1) = (0+1, 1) = (1, 1) = 1e_1 + 1e_2$\n\nThe matrix $A$ representing $T$ is:\n$$ A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix} $$\n\nTo find the eigenvalues, we solve the characteristic equation $\\det(A - \\lambda I) = 0$:\n$$ \\det \\begin{pmatrix} 1 - \\lambda & 1 \\\\ 0 & 1 - \\lambda \\end{pmatrix} = 0 $$\n\nCalculating the determinant:\n$$ (1 - \\lambda)(1 - \\lambda) - (1)(0) = 0 $$\n$$ (1 - \\lambda)^2 = 0 $$\n\nThe only solution to this equation is $\\lambda = 1$.\n\n### Conclusion\n\n1.  We have shown that $\\|T\\mathbf{v}\\| \\leq \\sqrt{3}\\|\\mathbf{v}\\|$ for all $\\mathbf{v}$, proving that **$T$ is a bounded operator**.\n2.  The spectrum of $T$ is the set containing the single eigenvalue:\n    $$ \\sigma(T) = \\{1\\} $$",
        "raw_answer": "Here is the complete solution to the problem.\n\n### Problem Statement\nLet $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ be defined by $T(x, y) = (x + y, y)$. Show that $T$ is a bounded operator and find its spectrum.\n\n---\n\n### Solution\n\n#### Part 1: Boundedness of $T$\n\n**Definition**: Let $V$ be a normed vector space. A linear operator $T: V \\to V$ is **bounded** if there exists a real constant $M \\geq 0$ such that for all vectors $\\mathbf{v} \\in V$:\n$$ \\|T\\mathbf{v}\\| \\leq M \\|\\mathbf{v}\\| $$\n\nWe equip $\\mathbb{C}^2$ with the standard Euclidean norm. For a vector $\\mathbf{v} = (x, y) \\in \\mathbb{C}^2$, the norm is defined as:\n$$ \\|\\mathbf{v}\\| = \\sqrt{|x|^2 + |y|^2} $$\n\nWe examine the norm of the image $T(x, y) = (x+y, y)$:\n$$ \\|T(x, y)\\|^2 = |x + y|^2 + |y|^2 $$\n\nUsing the triangle inequality ($|a+b| \\leq |a| + |b|$) and the elementary inequality $(a+b)^2 \\leq 2(a^2 + b^2)$ for real $a,b \\geq 0$, we have:\n$$ |x + y|^2 \\leq (|x| + |y|)^2 \\leq 2(|x|^2 + |y|^2) $$\n\nSubstituting this back into the expression for $\\|T(x, y)\\|^2$:\n$$ \\begin{aligned} \\|T(x, y)\\|^2 &= |x + y|^2 + |y|^2 \\\\ &\\leq 2(|x|^2 + |y|^2) + |y|^2 \\\\ &= 2|x|^2 + 3|y|^2 \\end{aligned} $$\n\nSince $2|x|^2 + 3|y|^2 \\leq 3|x|^2 + 3|y|^2 = 3(|x|^2 + |y|^2)$, we obtain:\n$$ \\|T(x, y)\\|^2 \\leq 3 \\|\\mathbf{v}\\|^2 $$\n\nTaking the square root of both sides gives:\n$$ \\|T(x, y)\\| \\leq \\sqrt{3} \\|\\mathbf{v}\\| $$\n\nThis inequality holds for all $(x,y) \\in \\mathbb{C}^2$. Thus, $T$ is a bounded operator.\n\n*(Note: While it is a standard theorem that every linear operator on a finite-dimensional normed space is bounded, the explicit derivation above confirms the property directly from the definition.)*\n\n#### Part 2: Spectrum of $T$\n\n**Definition**: The spectrum of a bounded linear operator $T$ on a vector space $V$, denoted $\\sigma(T)$, is the set of scalars $\\lambda \\in \\mathbb{C}$ such that the operator $T - \\lambda I$ is not invertible.\n\nSince $\\mathbb{C}^2$ is finite-dimensional, the operator $T - \\lambda I$ is not invertible if and only if its determinant is zero. Therefore, the spectrum consists exactly of the eigenvalues of $T$.\n\nWe find the matrix representation of $T$ with respect to the standard basis $e_1 = (1, 0)$ and $e_2 = (0, 1)$:\n1. $T(e_1) = T(1, 0) = (1+0, 0) = (1, 0) = 1e_1 + 0e_2$\n2. $T(e_2) = T(0, 1) = (0+1, 1) = (1, 1) = 1e_1 + 1e_2$\n\nThe matrix $A$ representing $T$ is:\n$$ A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix} $$\n\nTo find the eigenvalues, we solve the characteristic equation $\\det(A - \\lambda I) = 0$:\n$$ \\det \\begin{pmatrix} 1 - \\lambda & 1 \\\\ 0 & 1 - \\lambda \\end{pmatrix} = 0 $$\n\nCalculating the determinant:\n$$ (1 - \\lambda)(1 - \\lambda) - (1)(0) = 0 $$\n$$ (1 - \\lambda)^2 = 0 $$\n\nThe only solution to this equation is $\\lambda = 1$.\n\n### Conclusion\n\n1.  We have shown that $\\|T\\mathbf{v}\\| \\leq \\sqrt{3}\\|\\mathbf{v}\\|$ for all $\\mathbf{v}$, proving that **$T$ is a bounded operator**.\n2.  The spectrum of $T$ is the set containing the single eigenvalue:\n    $$ \\sigma(T) = \\{1\\} $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task requires generating a challenging but solvable mathematics problem in the domain of calculus of variations and optimal control, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable problem in the domain\nA classic problem in calculus of variations is finding the curve that minimizes the distance between two points. However, to make it more challenging and relevant to optimal control, we can consider a problem that involves optimizing a functional subject to certain constraints.\n\n## Step 3: Formulate the problem\nLet's consider the problem of finding the function $y(x)$ that minimizes the functional $J[y] = \\int_{0}^{1} (y'^2 + y) \\,dx$, subject to the boundary conditions $y(0) = 0$ and $y(1) = 1$. This problem is relevant to the calculus of variations and involves optimizing a functional.\n\n## Step 4: Write down the problem statement\nThe problem can be stated as: \"Minimize $J[y] = \\int_{0}^{1} (y'^2 + y) \\,dx$ subject to $y(0) = 0$ and $y(1) = 1$, where $y(x)$ is a continuously differentiable function on $[0,1]$.\"\n\n## Step 5: Provide the solution to the problem\nTo solve this, we use the Euler-Lagrange equation, which states that for a functional $J[y] = \\int_{a}^{b} F(x, y, y') \\,dx$, the extremal $y(x)$ satisfies $\\frac{\\partial F}{\\partial y} - \\frac{d}{dx}(\\frac{\\partial F}{\\partial y'}) = 0$. Here, $F = y'^2 + y$, so $\\frac{\\partial F}{\\partial y} = 1$ and $\\frac{\\partial F}{\\partial y'} = 2y'$.\n\n## Step 6: Apply the Euler-Lagrange equation\nSubstituting into the Euler-Lagrange equation gives $1 - \\frac{d}{dx}(2y') = 0$, which simplifies to $1 - 2y'' = 0$. Thus, $y'' = \\frac{1}{2}$.\n\n## Step 7: Solve the differential equation\nIntegrating $y'' = \\frac{1}{2}$ twice gives $y(x) = \\frac{x^2}{4} + Ax + B$, where $A$ and $B$ are constants.\n\n## Step 8: Apply the boundary conditions\nUsing $y(0) = 0$ gives $B = 0$, and $y(1) = 1$ gives $1 = \\frac{1}{4} + A$, so $A = \\frac{3}{4}$.\n\n## Step 9: Write the solution\nThus, $y(x) = \\frac{x^2}{4} + \\frac{3x}{4}$.\n\n## Step 10: Verify the solution\nTo verify, we check that $y(x)$ satisfies the boundary conditions and the Euler-Lagrange equation. $y(0) = 0$ and $y(1) = \\frac{1}{4} + \\frac{3}{4} = 1$, so the boundary conditions are satisfied. The function $y(x)$ is also continuously differentiable.\n\nThe final answer is:\n\n\n\nMinimize $J[y] = \\int_{0}^{1} (y'^2 + y) \\,dx$ subject to $y(0) = 0$ and $y(1) = 1$, where $y(x)$ is a continuously differentiable function on $[0,1]$.",
    "run_id": "34",
    "outer_attempt": 2,
    "topic_slug": "calculus_of_variations_and_optimization",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the problem of minimizing the functional\n$$J[y] = \\int_{0}^{1} ((y')^2 + y) \\,dx$$\nsubject to the boundary conditions $y(0) = 0$ and $y(1) = 1$, we employ the calculus of variations.\n\n### 1. Setup and Euler-Lagrange Equation\n\nLet the integrand be denoted by $F(x, y, y')$. In this problem:\n$$F(x, y, y') = (y')^2 + y$$\n\nA necessary condition for a function $y(x)$ to be an extremum (minimum or maximum) of the functional $J[y]$ is that it satisfies the Euler-Lagrange equation:\n$$\\frac{\\partial F}{\\partial y} - \\frac{d}{dx}\\left(\\frac{\\partial F}{\\partial y'}\\right) = 0$$\n\nFirst, we compute the partial derivatives of $F$:\n1.  **Partial derivative with respect to $y$:**\n    $$\\frac{\\partial F}{\\partial y} = \\frac{\\partial}{\\partial y}((y')^2 + y) = 1$$\n\n2.  **Partial derivative with respect to $y'$:**\n    $$\\frac{\\partial F}{\\partial y'} = \\frac{\\partial}{\\partial y'}((y')^2 + y) = 2y'$$\n\nNow, substitute these into the Euler-Lagrange equation:\n$$1 - \\frac{d}{dx}(2y') = 0$$\n\nCompute the total derivative with respect to $x$:\n$$1 - 2y'' = 0$$\n\n### 2. Solving the Differential Equation\n\nWe now have a second-order ordinary differential equation (ODE):\n$$2y'' = 1 \\implies y'' = \\frac{1}{2}$$\n\nWe solve this by integrating with respect to $x$ twice.\n\n**First Integration:**\n$$y'(x) = \\int \\frac{1}{2} \\,dx = \\frac{1}{2}x + C_1$$\nwhere $C_1$ is an integration constant.\n\n**Second Integration:**\n$$y(x) = \\int \\left(\\frac{1}{2}x + C_1\\right) \\,dx = \\frac{1}{2}\\left(\\frac{x^2}{2}\\right) + C_1x + C_2$$\n$$y(x) = \\frac{1}{4}x^2 + C_1x + C_2$$\nwhere $C_2$ is the second integration constant.\n\n### 3. Applying Boundary Conditions\n\nWe determine the constants $C_1$ and $C_2$ using the given boundary conditions $y(0) = 0$ and $y(1) = 1$.\n\n**Condition 1: $y(0) = 0$**\nSubstituting $x=0$ into the general solution:\n$$y(0) = \\frac{1}{4}(0)^2 + C_1(0) + C_2 = 0$$\n$$\\implies C_2 = 0$$\n\nSo, the function simplifies to:\n$$y(x) = \\frac{1}{4}x^2 + C_1x$$\n\n**Condition 2: $y(1) = 1$**\nSubstituting $x=1$ into the simplified equation:\n$$y(1) = \\frac{1}{4}(1)^2 + C_1(1) = 1$$\n$$\\frac{1}{4} + C_1 = 1$$\n$$C_1 = 1 - \\frac{1}{4} = \\frac{3}{4}$$\n\n### 4. Final Solution and Verification\n\nSubstituting the constants back into the general solution, we obtain:\n$$y(x) = \\frac{1}{4}x^2 + \\frac{3}{4}x$$\n\n**Verification of Minimization (Legendre Condition):**\nTo ensure this stationary function is a minimum, we check the second variation. The Legendre condition states that for a minimum, we must have $\\frac{\\partial^2 F}{\\partial y'^2} \\geq 0$.\n$$\\frac{\\partial^2 F}{\\partial y'^2} = \\frac{\\partial}{\\partial y'}(2y') = 2$$\nSince $2 > 0$ for all $x$, the sufficient condition for a minimum is satisfied. Since the functional is strictly convex in $y'$, this extremum is the global minimum.\n\n### Conclusion\n\nThe function that minimizes the functional subject to the given boundary conditions is:\n\n$$y(x) = \\frac{1}{4}x^2 + \\frac{3}{4}x$$",
        "raw_answer": "To solve the problem of minimizing the functional\n$$J[y] = \\int_{0}^{1} ((y')^2 + y) \\,dx$$\nsubject to the boundary conditions $y(0) = 0$ and $y(1) = 1$, we employ the calculus of variations.\n\n### 1. Setup and Euler-Lagrange Equation\n\nLet the integrand be denoted by $F(x, y, y')$. In this problem:\n$$F(x, y, y') = (y')^2 + y$$\n\nA necessary condition for a function $y(x)$ to be an extremum (minimum or maximum) of the functional $J[y]$ is that it satisfies the Euler-Lagrange equation:\n$$\\frac{\\partial F}{\\partial y} - \\frac{d}{dx}\\left(\\frac{\\partial F}{\\partial y'}\\right) = 0$$\n\nFirst, we compute the partial derivatives of $F$:\n1.  **Partial derivative with respect to $y$:**\n    $$\\frac{\\partial F}{\\partial y} = \\frac{\\partial}{\\partial y}((y')^2 + y) = 1$$\n\n2.  **Partial derivative with respect to $y'$:**\n    $$\\frac{\\partial F}{\\partial y'} = \\frac{\\partial}{\\partial y'}((y')^2 + y) = 2y'$$\n\nNow, substitute these into the Euler-Lagrange equation:\n$$1 - \\frac{d}{dx}(2y') = 0$$\n\nCompute the total derivative with respect to $x$:\n$$1 - 2y'' = 0$$\n\n### 2. Solving the Differential Equation\n\nWe now have a second-order ordinary differential equation (ODE):\n$$2y'' = 1 \\implies y'' = \\frac{1}{2}$$\n\nWe solve this by integrating with respect to $x$ twice.\n\n**First Integration:**\n$$y'(x) = \\int \\frac{1}{2} \\,dx = \\frac{1}{2}x + C_1$$\nwhere $C_1$ is an integration constant.\n\n**Second Integration:**\n$$y(x) = \\int \\left(\\frac{1}{2}x + C_1\\right) \\,dx = \\frac{1}{2}\\left(\\frac{x^2}{2}\\right) + C_1x + C_2$$\n$$y(x) = \\frac{1}{4}x^2 + C_1x + C_2$$\nwhere $C_2$ is the second integration constant.\n\n### 3. Applying Boundary Conditions\n\nWe determine the constants $C_1$ and $C_2$ using the given boundary conditions $y(0) = 0$ and $y(1) = 1$.\n\n**Condition 1: $y(0) = 0$**\nSubstituting $x=0$ into the general solution:\n$$y(0) = \\frac{1}{4}(0)^2 + C_1(0) + C_2 = 0$$\n$$\\implies C_2 = 0$$\n\nSo, the function simplifies to:\n$$y(x) = \\frac{1}{4}x^2 + C_1x$$\n\n**Condition 2: $y(1) = 1$**\nSubstituting $x=1$ into the simplified equation:\n$$y(1) = \\frac{1}{4}(1)^2 + C_1(1) = 1$$\n$$\\frac{1}{4} + C_1 = 1$$\n$$C_1 = 1 - \\frac{1}{4} = \\frac{3}{4}$$\n\n### 4. Final Solution and Verification\n\nSubstituting the constants back into the general solution, we obtain:\n$$y(x) = \\frac{1}{4}x^2 + \\frac{3}{4}x$$\n\n**Verification of Minimization (Legendre Condition):**\nTo ensure this stationary function is a minimum, we check the second variation. The Legendre condition states that for a minimum, we must have $\\frac{\\partial^2 F}{\\partial y'^2} \\geq 0$.\n$$\\frac{\\partial^2 F}{\\partial y'^2} = \\frac{\\partial}{\\partial y'}(2y') = 2$$\nSince $2 > 0$ for all $x$, the sufficient condition for a minimum is satisfied. Since the functional is strictly convex in $y'$, this extremum is the global minimum.\n\n### Conclusion\n\nThe function that minimizes the functional subject to the given boundary conditions is:\n\n$$y(x) = \\frac{1}{4}x^2 + \\frac{3}{4}x$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Convex and discrete geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Convex and discrete geometry\nConvex and discrete geometry encompasses a broad range of topics including the geometry of convex sets, polytopes, and discrete geometric structures. A suitable topic could involve properties of convex polytopes, such as their faces, volumes, or the relationships between their vertices and facets.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem related to the properties of a specific convex polytope. A well-known result in convex geometry is the characterization of regular polytopes. However, a more challenging and less straightforward problem could involve understanding the relationship between the number of vertices, edges, and faces of a polytope.\n\n## Step 4: Generate a problem statement\nConsider a 3-dimensional convex polytope $P$ that is simple (every vertex is incident to exactly 3 edges) and has $V$ vertices, $E$ edges, and $F$ faces. The problem is to prove that for such a polytope, Euler's formula ($V - E + F = 2$) holds, and then use this to derive a relationship between $V$ and $F$.\n\n## Step 5: Write down the problem in the required format\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces. Prove that $V - E + F = 2$ and derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces. Prove that $V - E + F = 2$ and derive a formula relating $V$ and $F$ using the fact that $P$ is simple.",
    "run_id": "36",
    "outer_attempt": 2,
    "topic_slug": "convex_and_discrete_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete solution to the problem involving the simple 3-dimensional convex polytope.\n\n### **Problem Statement**\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces.\n1.  Prove Euler's Formula: $V - E + F = 2$.\n2.  Derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n---\n\n### **Part 1: Proof of Euler's Formula ($V - E + F = 2$)**\n\nWe prove this result by mapping the polytope to a planar graph and using induction.\n\n**1. Transformation to a Planar Graph**\nThe boundary of a 3-dimensional convex polytope is homeomorphic to a 2-sphere. We can project this boundary onto the Euclidean plane $\\mathbb{R}^2$ using a **Schlegel diagram** or stereographic projection. This process maps the vertices and edges of the polytope to a connected planar graph $G$ such that:\n*   The vertices of $G$ correspond one-to-one with the vertices of $P$.\n*   The edges of $G$ correspond one-to-one with the edges of $P$ and do not intersect except at vertices.\n*   The regions (faces) bounded by the edges of $G$, including the outer unbounded region, correspond one-to-one with the faces of $P$.\n\nThus, the problem reduces to proving Euler's formula for a connected planar graph.\n\n**2. Inductive Proof on the Number of Edges**\nLet $G$ be a connected planar graph with $V$ vertices, $E$ edges, and $F$ faces. We construct the graph starting from a single vertex and adding edges, tracking the value $\\chi = V - E + F$.\n\n*   **Base Case:** Start with a graph consisting of a single vertex.\n    *   $V = 1$\n    *   $E = 0$\n    *   $F = 1$ (the single unbounded region)\n    *   $\\chi = 1 - 0 + 1 = 2$.\n    The formula holds.\n\n*   **Inductive Step:** Suppose the formula $V - E + F = 2$ holds for a connected planar graph $G$. We add a new edge to $G$ to create a new graph $G'$. There are two ways to add an edge while maintaining planarity and connectivity:\n\n    *   **Case A: Add an edge connecting an existing vertex to a new vertex.**\n        *   The number of vertices increases by 1 ($V' = V + 1$).\n        *   The number of edges increases by 1 ($E' = E + 1$).\n        *   No new cycle is created, so the number of faces remains the same ($F' = F$).\n        *   New characteristic:\n            $$V' - E' + F' = (V + 1) - (E + 1) + F = V - E + F = 2$$\n        The formula is preserved.\n\n    *   **Case B: Add an edge connecting two existing vertices.**\n        *   The number of vertices remains the same ($V' = V$).\n        *   The number of edges increases by 1 ($E' = E + 1$).\n        *   This new edge splits an existing face into two distinct faces, increasing the number of faces by 1 ($F' = F + 1$).\n        *   New characteristic:\n            $$V' - E' + F' = V - (E + 1) + (F + 1) = V - E + F = 2$$\n        The formula is preserved.\n\nSince any connected planar graph can be constructed from a single vertex by a sequence of these operations, Euler's formula $V - E + F = 2$ holds for all such graphs, and consequently for all 3-dimensional convex polytopes.\n\n---\n\n### **Part 2: Derivation of the Relationship between $V$ and $F$**\n\nWe are given that the polytope $P$ is **simple**. In the context of 3-dimensional polytopes, a simple polytope is one where every vertex is incident to exactly 3 edges.\n\n**1. Using the Handshaking Lemma**\nLet $\\deg(v)$ denote the degree of vertex $v$ (the number of edges incident to $v$).\nAccording to the Handshaking Lemma (sum of degrees formula), the sum of degrees in a graph is equal to twice the number of edges:\n$$ \\sum_{i=1}^{V} \\deg(v_i) = 2E $$\n\nSince $P$ is simple, $\\deg(v) = 3$ for all vertices $v$. Therefore:\n$$ \\sum_{i=1}^{V} 3 = 3V $$\nEquating the two expressions for the sum of degrees:\n$$ 3V = 2E \\implies E = \\frac{3}{2}V $$\n\n**2. Substituting into Euler's Formula**\nWe substitute the expression for $E$ into Euler's equation $V - E + F = 2$:\n\n$$ V - \\left( \\frac{3}{2}V \\right) + F = 2 $$\n\nSimplify the equation:\n$$ -\\frac{1}{2}V + F = 2 $$\n\nMultiply by 2 to clear the fraction:\n$$ -V + 2F = 4 $$\n\nRearranging to solve for $V$:\n$$ V = 2F - 4 $$\n\n### **Conclusion**\n\n1.  Euler's formula states that **$V - E + F = 2$**.\n2.  For a simple 3-dimensional convex polytope, the number of vertices is determined by the number of faces according to the formula:\n    **$$V = 2F - 4$$**",
        "raw_answer": "Here is the complete solution to the problem involving the simple 3-dimensional convex polytope.\n\n### **Problem Statement**\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces.\n1.  Prove Euler's Formula: $V - E + F = 2$.\n2.  Derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n---\n\n### **Part 1: Proof of Euler's Formula ($V - E + F = 2$)**\n\nWe prove this result by mapping the polytope to a planar graph and using induction.\n\n**1. Transformation to a Planar Graph**\nThe boundary of a 3-dimensional convex polytope is homeomorphic to a 2-sphere. We can project this boundary onto the Euclidean plane $\\mathbb{R}^2$ using a **Schlegel diagram** or stereographic projection. This process maps the vertices and edges of the polytope to a connected planar graph $G$ such that:\n*   The vertices of $G$ correspond one-to-one with the vertices of $P$.\n*   The edges of $G$ correspond one-to-one with the edges of $P$ and do not intersect except at vertices.\n*   The regions (faces) bounded by the edges of $G$, including the outer unbounded region, correspond one-to-one with the faces of $P$.\n\nThus, the problem reduces to proving Euler's formula for a connected planar graph.\n\n**2. Inductive Proof on the Number of Edges**\nLet $G$ be a connected planar graph with $V$ vertices, $E$ edges, and $F$ faces. We construct the graph starting from a single vertex and adding edges, tracking the value $\\chi = V - E + F$.\n\n*   **Base Case:** Start with a graph consisting of a single vertex.\n    *   $V = 1$\n    *   $E = 0$\n    *   $F = 1$ (the single unbounded region)\n    *   $\\chi = 1 - 0 + 1 = 2$.\n    The formula holds.\n\n*   **Inductive Step:** Suppose the formula $V - E + F = 2$ holds for a connected planar graph $G$. We add a new edge to $G$ to create a new graph $G'$. There are two ways to add an edge while maintaining planarity and connectivity:\n\n    *   **Case A: Add an edge connecting an existing vertex to a new vertex.**\n        *   The number of vertices increases by 1 ($V' = V + 1$).\n        *   The number of edges increases by 1 ($E' = E + 1$).\n        *   No new cycle is created, so the number of faces remains the same ($F' = F$).\n        *   New characteristic:\n            $$V' - E' + F' = (V + 1) - (E + 1) + F = V - E + F = 2$$\n        The formula is preserved.\n\n    *   **Case B: Add an edge connecting two existing vertices.**\n        *   The number of vertices remains the same ($V' = V$).\n        *   The number of edges increases by 1 ($E' = E + 1$).\n        *   This new edge splits an existing face into two distinct faces, increasing the number of faces by 1 ($F' = F + 1$).\n        *   New characteristic:\n            $$V' - E' + F' = V - (E + 1) + (F + 1) = V - E + F = 2$$\n        The formula is preserved.\n\nSince any connected planar graph can be constructed from a single vertex by a sequence of these operations, Euler's formula $V - E + F = 2$ holds for all such graphs, and consequently for all 3-dimensional convex polytopes.\n\n---\n\n### **Part 2: Derivation of the Relationship between $V$ and $F$**\n\nWe are given that the polytope $P$ is **simple**. In the context of 3-dimensional polytopes, a simple polytope is one where every vertex is incident to exactly 3 edges.\n\n**1. Using the Handshaking Lemma**\nLet $\\deg(v)$ denote the degree of vertex $v$ (the number of edges incident to $v$).\nAccording to the Handshaking Lemma (sum of degrees formula), the sum of degrees in a graph is equal to twice the number of edges:\n$$ \\sum_{i=1}^{V} \\deg(v_i) = 2E $$\n\nSince $P$ is simple, $\\deg(v) = 3$ for all vertices $v$. Therefore:\n$$ \\sum_{i=1}^{V} 3 = 3V $$\nEquating the two expressions for the sum of degrees:\n$$ 3V = 2E \\implies E = \\frac{3}{2}V $$\n\n**2. Substituting into Euler's Formula**\nWe substitute the expression for $E$ into Euler's equation $V - E + F = 2$:\n\n$$ V - \\left( \\frac{3}{2}V \\right) + F = 2 $$\n\nSimplify the equation:\n$$ -\\frac{1}{2}V + F = 2 $$\n\nMultiply by 2 to clear the fraction:\n$$ -V + 2F = 4 $$\n\nRearranging to solve for $V$:\n$$ V = 2F - 4 $$\n\n### **Conclusion**\n\n1.  Euler's formula states that **$V - E + F = 2$**.\n2.  For a simple 3-dimensional convex polytope, the number of vertices is determined by the number of faces according to the formula:\n    **$$V = 2F - 4$$**",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of general topology, along with a complete solution, following specific guidelines.\n\n## Step 2: Review the guidelines for a well-posed question\nThe question must be self-contained, clear, non-trivial, and solvable with established mathematical methods. It should not require external dependencies or be culturally dependent.\n\n## Step 3: Identify a topic within general topology\nGeneral topology involves the study of topological spaces, continuous functions, and topological properties. A suitable topic could involve properties of specific topological spaces or the behavior of continuous functions.\n\n## Step 4: Generate a problem\nLet's consider a problem involving the concept of compactness and continuous functions. A well-known result in general topology is that the continuous image of a compact space is compact.\n\n## Step 5: Formulate the problem\n\"Let $X = [0,1] \\cup [2,3]$ be a subspace of $\\mathbb{R}$ with the standard topology. Define a function $f: X \\to \\mathbb{R}$ by $f(x) = x^2$. Prove that $f(X)$ is compact.\"\n\n## Step 6: Verify that the problem is well-posed\n- The domain $X$ is explicitly defined.\n- The function $f$ is clearly defined.\n- The task is to prove a specific property ($f(X)$ being compact) which is a well-defined mathematical concept.\n- The problem does not require external dependencies.\n\n## Step 7: Provide a solution to the problem\nTo prove that $f(X)$ is compact, we need to show that it is closed and bounded since $f(X) \\subset \\mathbb{R}$ and $\\mathbb{R}$ is a metric space.\n\n## Step 8: Calculate $f(X)$\nGiven $X = [0,1] \\cup [2,3]$, $f(X) = f([0,1]) \\cup f([2,3]) = [0,1] \\cup [4,9]$.\n\n## Step 9: Show that $f(X)$ is compact\n$f(X) = [0,1] \\cup [4,9]$ is a union of two closed and bounded intervals, hence it is closed and bounded. Therefore, $f(X)$ is compact because it is a closed and bounded subset of $\\mathbb{R}$.\n\n## Step 10: Write the problem and solution in the required format\n\nLet $X = [0,1] \\cup [2,3]$ be a subspace of $\\mathbb{R}$ with the standard topology. Define a function $f: X \\to \\mathbb{R}$ by $f(x) = x^2$. Prove that $f(X)$ is compact.",
    "run_id": "38",
    "outer_attempt": 2,
    "topic_slug": "general_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the image set $f(X)$ is compact, we will proceed by establishing the topological properties of the domain $X$ and the function $f$, and then applying a fundamental theorem of general topology. Alternatively, we can verify the result by explicitly computing the set $f(X)$.\n\n### Method 1: Topological Proof\n\n**Step 1: Establish that the domain $X$ is compact.**\nThe set $X$ is given by the union of two intervals:\n$$ X = [0,1] \\cup [2,3] $$\nWe consider $X$ as a subspace of $\\mathbb{R}$ with the standard topology. By the **Heine-Borel Theorem**, a subset of Euclidean space $\\mathbb{R}^n$ is compact if and only if it is both closed and bounded.\n\n1.  **Boundedness**: $X$ is contained in the interval $[0,3]$, so $X$ is bounded.\n2.  **Closedness**: The intervals $[0,1]$ and $[2,3]$ are closed sets in $\\mathbb{R}$ (they contain their limit points). The union of a finite number of closed sets is closed. Therefore, $X$ is closed.\n\nSince $X$ is a closed and bounded subset of $\\mathbb{R}$, $X$ is compact.\n\n**Step 2: Establish that the function $f$ is continuous.**\nThe function is defined as $f: X \\to \\mathbb{R}$ with $f(x) = x^2$.\nConsider the function $g: \\mathbb{R} \\to \\mathbb{R}$ defined by $g(x) = x^2$. It is a well-known result from calculus that polynomial functions are continuous on $\\mathbb{R}$.\nThe function $f$ is the restriction of $g$ to the subspace $X$ (i.e., $f = g|_X$). By the definition of the subspace topology, the restriction of a continuous function to a subspace is continuous.\nTherefore, $f$ is continuous on $X$.\n\n**Step 3: Apply the theorem regarding continuous images of compact sets.**\nWe invoke the following standard theorem from general topology:\n> **Theorem:** Let $X$ and $Y$ be topological spaces. If $f: X \\to Y$ is a continuous function and $X$ is compact, then the image $f(X)$ is compact in $Y$.\n\nSince we have established that $X$ is compact (Step 1) and $f$ is continuous (Step 2), it follows directly that $f(X)$ is compact.\n\n---\n\n### Method 2: Verification by Explicit Calculation\n\nWe can also determine $f(X)$ explicitly and check its compactness using the Heine-Borel theorem.\n\n**Step 1: Compute the image of the sub-intervals.**\nSince $f(x) = x^2$ is a strictly increasing function for $x \\geq 0$, it maps closed intervals $[a, b]$ (where $a \\ge 0$) to $[a^2, b^2]$.\n1.  For the interval $[0,1]$:\n    $$ f([0,1]) = [0^2, 1^2] = [0,1] $$\n2.  For the interval $[2,3]$:\n    $$ f([2,3]) = [2^2, 3^2] = [4,9] $$\n\n**Step 2: Form the union.**\n$$ f(X) = f([0,1]) \\cup f([2,3]) = [0,1] \\cup [4,9] $$\n\n**Step 3: Check Compactness.**\nThe set $S = [0,1] \\cup [4,9]$ is:\n1.  **Bounded**: $S \\subset [0,9]$.\n2.  **Closed**: $S$ is the union of two closed intervals, hence it is closed.\n\nTherefore, $f(X)$ is compact.\n\n### Conclusion\nBy establishing that $X$ is compact and $f$ is continuous, we have proven that the image $f(X)$ is compact. Explicit calculation confirms that $f(X) = [0,1] \\cup [4,9]$, which is a compact subset of $\\mathbb{R}$.",
        "raw_answer": "To prove that the image set $f(X)$ is compact, we will proceed by establishing the topological properties of the domain $X$ and the function $f$, and then applying a fundamental theorem of general topology. Alternatively, we can verify the result by explicitly computing the set $f(X)$.\n\n### Method 1: Topological Proof\n\n**Step 1: Establish that the domain $X$ is compact.**\nThe set $X$ is given by the union of two intervals:\n$$ X = [0,1] \\cup [2,3] $$\nWe consider $X$ as a subspace of $\\mathbb{R}$ with the standard topology. By the **Heine-Borel Theorem**, a subset of Euclidean space $\\mathbb{R}^n$ is compact if and only if it is both closed and bounded.\n\n1.  **Boundedness**: $X$ is contained in the interval $[0,3]$, so $X$ is bounded.\n2.  **Closedness**: The intervals $[0,1]$ and $[2,3]$ are closed sets in $\\mathbb{R}$ (they contain their limit points). The union of a finite number of closed sets is closed. Therefore, $X$ is closed.\n\nSince $X$ is a closed and bounded subset of $\\mathbb{R}$, $X$ is compact.\n\n**Step 2: Establish that the function $f$ is continuous.**\nThe function is defined as $f: X \\to \\mathbb{R}$ with $f(x) = x^2$.\nConsider the function $g: \\mathbb{R} \\to \\mathbb{R}$ defined by $g(x) = x^2$. It is a well-known result from calculus that polynomial functions are continuous on $\\mathbb{R}$.\nThe function $f$ is the restriction of $g$ to the subspace $X$ (i.e., $f = g|_X$). By the definition of the subspace topology, the restriction of a continuous function to a subspace is continuous.\nTherefore, $f$ is continuous on $X$.\n\n**Step 3: Apply the theorem regarding continuous images of compact sets.**\nWe invoke the following standard theorem from general topology:\n> **Theorem:** Let $X$ and $Y$ be topological spaces. If $f: X \\to Y$ is a continuous function and $X$ is compact, then the image $f(X)$ is compact in $Y$.\n\nSince we have established that $X$ is compact (Step 1) and $f$ is continuous (Step 2), it follows directly that $f(X)$ is compact.\n\n---\n\n### Method 2: Verification by Explicit Calculation\n\nWe can also determine $f(X)$ explicitly and check its compactness using the Heine-Borel theorem.\n\n**Step 1: Compute the image of the sub-intervals.**\nSince $f(x) = x^2$ is a strictly increasing function for $x \\geq 0$, it maps closed intervals $[a, b]$ (where $a \\ge 0$) to $[a^2, b^2]$.\n1.  For the interval $[0,1]$:\n    $$ f([0,1]) = [0^2, 1^2] = [0,1] $$\n2.  For the interval $[2,3]$:\n    $$ f([2,3]) = [2^2, 3^2] = [4,9] $$\n\n**Step 2: Form the union.**\n$$ f(X) = f([0,1]) \\cup f([2,3]) = [0,1] \\cup [4,9] $$\n\n**Step 3: Check Compactness.**\nThe set $S = [0,1] \\cup [4,9]$ is:\n1.  **Bounded**: $S \\subset [0,9]$.\n2.  **Closed**: $S$ is the union of two closed intervals, hence it is closed.\n\nTherefore, $f(X)$ is compact.\n\n### Conclusion\nBy establishing that $X$ is compact and $f$ is continuous, we have proven that the image $f(X)$ is compact. Explicit calculation confirms that $f(X) = [0,1] \\cup [4,9]$, which is a compact subset of $\\mathbb{R}$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Manifolds and cell complexes\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within the domain\nA suitable topic within \"Manifolds and cell complexes\" could involve the properties or constructions related to manifolds or cell complexes, such as their topology, geometry, or algebraic invariants.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the Euler characteristic of a manifold, which is a fundamental concept in algebraic topology that relates to both manifolds and cell complexes. The Euler characteristic is a topological invariant that can be computed using a cell decomposition of a manifold.\n\n## Step 4: Construct the problem statement\nConsider a 2-dimensional manifold $M$ that is homeomorphic to a sphere with $g$ handles (i.e., a surface of genus $g$). The task is to prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.\n\n## Step 5: Provide the problem statement in the required format\n\n\nLet $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles. Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.",
    "run_id": "40",
    "outer_attempt": 2,
    "topic_slug": "manifolds_and_cell_complexes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To provide a rigorous answer to the problem, we will model the manifold $M$ using the standard tools of algebraic topology, specifically the theory of **CW complexes** (cell complexes). We will calculate the Euler characteristic using the definition $\\chi(M) = \\sum (-1)^k c_k$, where $c_k$ is the number of cells of dimension $k$.\n\n### 1. Mathematical Formulation\n\n**Definition:** The Euler characteristic $\\chi(M)$ of a finite cell complex $M$ is defined as:\n$$ \\chi(M) = V - E + F $$\nwhere:\n*   $V$ is the number of 0-cells (vertices).\n*   $E$ is the number of 1-cells (edges).\n*   $F$ is the number of 2-cells (faces).\n\n**Model of the Manifold:**\nA 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles is known as an **orientable surface of genus $g$**, denoted $\\Sigma_g$.\n*   For $g=0$, $M$ is the sphere $S^2$.\n*   For $g \\ge 1$, $M$ can be constructed from a regular polygon with $4g$ sides by identifying the edges in a specific pattern known as the **fundamental polygon**.\n\n### 2. Proof via Cell Decomposition (Polygonal Model)\n\nWe construct a CW complex structure on $M$ using the standard polygonal representation.\n\n**Step 1: The Fundamental Polygon**\nLet $P$ be a regular polygon with $4g$ edges. We label the edges of the boundary $\\partial P$ in counterclockwise order with the sequence of symbols:\n$$ a_1, b_1, a_1^{-1}, b_1^{-1}, a_2, b_2, a_2^{-1}, b_2^{-1}, \\dots, a_g, b_g, a_g^{-1}, b_g^{-1} $$\nThis word represents the \"commutator\" structure of the handles. To form the manifold $M$, we identify edges with the same letter according to the orientation indicated (the exponent $-1$ implies the edge is identified with the orientation reversed).\n\nThis identification creates a quotient space $M = P / \\sim$. We now count the cells in this quotient space.\n\n**Step 2: Counting 2-cells (Faces)**\nThe interior of the polygon $P$ forms a single open disk. Since no identifications occur in the interior, this maps to exactly one 2-cell in $M$.\n$$ F = 1 $$\n\n**Step 3: Counting 1-cells (Edges)**\nThe polygon boundary has $4g$ edges. The identification scheme pairs each edge $x$ with a unique edge $x^{-1}$.\n*   The edges are $\\{a_i, b_i, a_i^{-1}, b_i^{-1} \\mid i = 1, \\dots, g\\}$.\n*   Since the $4g$ edges are identified in pairs, the number of distinct 1-cells in the quotient manifold is:\n$$ E = \\frac{4g}{2} = 2g $$\n\n**Step 4: Counting 0-cells (Vertices)**\nThis is the non-trivial step. We must determine how the $4g$ vertices of the polygon are identified in the quotient. Let the vertices of $P$ be $v_0, v_1, \\dots, v_{4g-1}$ in counterclockwise order.\n\nLet us trace the identification for the first handle (the edges $a_1, b_1, a_1^{-1}, b_1^{-1}$):\n1.  **Edge $a_1$:** Connects $v_0 \\to v_1$. It is identified with $a_1^{-1}$ (which appears as the 3rd edge).\n2.  **Edge $a_1^{-1}$:** In the boundary sequence, this edge runs from $v_2 \\to v_3$. However, the label $a_1^{-1}$ implies it is identified with $a_1$ but with reversed orientation. Therefore, the geometric edge $a_1$ runs from the vertex identified with $v_3$ to the vertex identified with $v_2$.\n    *   Identification: The head of the original $a_1$ ($v_1$) is identified with the head of the mapped $a_1$ ($v_2$).\n    *   Identification: The tail of the original $a_1$ ($v_0$) is identified with the tail of the mapped $a_1$ ($v_3$).\n    *   Result: $v_1 \\sim v_2$ and $v_0 \\sim v_3$.\n3.  **Edge $b_1$:** Connects $v_1 \\to v_2$. It is identified with $b_1^{-1}$ (the 4th edge).\n4.  **Edge $b_1^{-1}$:** Runs from $v_3 \\to v_4$. Being the inverse, it is identified with $b_1$ reversed.\n    *   Identification: The start of $b_1$ ($v_1$) matches the end of $b_1^{-1}$ ($v_4$). Thus $v_1 \\sim v_4$.\n    *   Identification: The end of $b_1$ ($v_2$) matches the start of $b_1^{-1}$ ($v_3$). Thus $v_2 \\sim v_3$.\n\nCombining these equivalences for the first group of 4 edges:\n$$ v_0 \\sim v_3 \\sim v_2 \\sim v_1 \\sim v_4 $$\nThus, the start of the first sequence ($v_0$) is equivalent to the start of the next sequence ($v_4$). By induction, for any handle $i$, the vertices involved are all identified together, and the vertex at the end of the $i$-th group is identified with the vertex at the start of the $(i+1)$-th group.\n\nSince the boundary is a single connected cycle, **all** $4g$ vertices of the polygon are identified to a single point in the quotient manifold.\n$$ V = 1 $$\n\n**Step 5: Calculation**\nWe substitute the counts into the Euler characteristic formula:\n$$ \\chi(M) = V - E + F $$\n$$ \\chi(M) = 1 - 2g + 1 $$\n$$ \\chi(M) = 2 - 2g $$\n\n---\n\n### 3. Alternative Verification (Surgery / Handle Addition)\n\nWe can also prove this via induction on the number of handles, utilizing the property of the connected sum. A sphere with $g$ handles is homeomorphic to the connected sum of a sphere and $g$ tori, or simply the connected sum of $g$ tori (assuming $g \\ge 1$; for $g=0$ it is the sphere).\n\nLet $S^2$ be the sphere.\n1.  **Base Case ($g=0$):**\n    For a sphere, standard decomposition (e.g., tetrahedron) gives $V=4, E=6, F=4$.\n    $\\chi(S^2) = 4 - 6 + 4 = 2$.\n    The formula yields $2 - 2(0) = 2$. The base case holds.\n\n2.  **Inductive Step:**\n    Adding a \"handle\" is topologically equivalent to forming the connected sum with a torus $T^2$.\n    The operation is $M_{g+1} = M_g \\# T^2$.\n    The Euler characteristic for a connected sum is given by:\n    $$ \\chi(A \\# B) = \\chi(A) + \\chi(B) - 2 $$\n    We know $\\chi(T^2) = 0$ (since $T^2$ can be viewed as a square with opposite sides identified: $V=1, E=2, F=1 \\implies 1-2+1=0$).\n\n    Assume $\\chi(M_g) = 2 - 2g$. Then:\n    $$ \\chi(M_{g+1}) = \\chi(M_g) + \\chi(T^2) - 2 $$\n    $$ \\chi(M_{g+1}) = (2 - 2g) + 0 - 2 $$\n    $$ \\chi(M_{g+1}) = 2 - 2g - 2 $$\n    $$ \\chi(M_{g+1}) = 2 - 2(g + 1) $$\n\nThis confirms the result for all $g \\ge 0$.\n\n### Conclusion\n\nWe have constructed a cell decomposition for the manifold $M$, determined there is 1 face, $2g$ edges, and 1 vertex, and verified the result via the connected sum formula.\n\n**Final Result:**\nThe Euler characteristic of a 2-dimensional manifold homeomorphic to a sphere with $g$ handles is:\n$$ \\chi(M) = 2 - 2g $$",
        "raw_answer": "To provide a rigorous answer to the problem, we will model the manifold $M$ using the standard tools of algebraic topology, specifically the theory of **CW complexes** (cell complexes). We will calculate the Euler characteristic using the definition $\\chi(M) = \\sum (-1)^k c_k$, where $c_k$ is the number of cells of dimension $k$.\n\n### 1. Mathematical Formulation\n\n**Definition:** The Euler characteristic $\\chi(M)$ of a finite cell complex $M$ is defined as:\n$$ \\chi(M) = V - E + F $$\nwhere:\n*   $V$ is the number of 0-cells (vertices).\n*   $E$ is the number of 1-cells (edges).\n*   $F$ is the number of 2-cells (faces).\n\n**Model of the Manifold:**\nA 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles is known as an **orientable surface of genus $g$**, denoted $\\Sigma_g$.\n*   For $g=0$, $M$ is the sphere $S^2$.\n*   For $g \\ge 1$, $M$ can be constructed from a regular polygon with $4g$ sides by identifying the edges in a specific pattern known as the **fundamental polygon**.\n\n### 2. Proof via Cell Decomposition (Polygonal Model)\n\nWe construct a CW complex structure on $M$ using the standard polygonal representation.\n\n**Step 1: The Fundamental Polygon**\nLet $P$ be a regular polygon with $4g$ edges. We label the edges of the boundary $\\partial P$ in counterclockwise order with the sequence of symbols:\n$$ a_1, b_1, a_1^{-1}, b_1^{-1}, a_2, b_2, a_2^{-1}, b_2^{-1}, \\dots, a_g, b_g, a_g^{-1}, b_g^{-1} $$\nThis word represents the \"commutator\" structure of the handles. To form the manifold $M$, we identify edges with the same letter according to the orientation indicated (the exponent $-1$ implies the edge is identified with the orientation reversed).\n\nThis identification creates a quotient space $M = P / \\sim$. We now count the cells in this quotient space.\n\n**Step 2: Counting 2-cells (Faces)**\nThe interior of the polygon $P$ forms a single open disk. Since no identifications occur in the interior, this maps to exactly one 2-cell in $M$.\n$$ F = 1 $$\n\n**Step 3: Counting 1-cells (Edges)**\nThe polygon boundary has $4g$ edges. The identification scheme pairs each edge $x$ with a unique edge $x^{-1}$.\n*   The edges are $\\{a_i, b_i, a_i^{-1}, b_i^{-1} \\mid i = 1, \\dots, g\\}$.\n*   Since the $4g$ edges are identified in pairs, the number of distinct 1-cells in the quotient manifold is:\n$$ E = \\frac{4g}{2} = 2g $$\n\n**Step 4: Counting 0-cells (Vertices)**\nThis is the non-trivial step. We must determine how the $4g$ vertices of the polygon are identified in the quotient. Let the vertices of $P$ be $v_0, v_1, \\dots, v_{4g-1}$ in counterclockwise order.\n\nLet us trace the identification for the first handle (the edges $a_1, b_1, a_1^{-1}, b_1^{-1}$):\n1.  **Edge $a_1$:** Connects $v_0 \\to v_1$. It is identified with $a_1^{-1}$ (which appears as the 3rd edge).\n2.  **Edge $a_1^{-1}$:** In the boundary sequence, this edge runs from $v_2 \\to v_3$. However, the label $a_1^{-1}$ implies it is identified with $a_1$ but with reversed orientation. Therefore, the geometric edge $a_1$ runs from the vertex identified with $v_3$ to the vertex identified with $v_2$.\n    *   Identification: The head of the original $a_1$ ($v_1$) is identified with the head of the mapped $a_1$ ($v_2$).\n    *   Identification: The tail of the original $a_1$ ($v_0$) is identified with the tail of the mapped $a_1$ ($v_3$).\n    *   Result: $v_1 \\sim v_2$ and $v_0 \\sim v_3$.\n3.  **Edge $b_1$:** Connects $v_1 \\to v_2$. It is identified with $b_1^{-1}$ (the 4th edge).\n4.  **Edge $b_1^{-1}$:** Runs from $v_3 \\to v_4$. Being the inverse, it is identified with $b_1$ reversed.\n    *   Identification: The start of $b_1$ ($v_1$) matches the end of $b_1^{-1}$ ($v_4$). Thus $v_1 \\sim v_4$.\n    *   Identification: The end of $b_1$ ($v_2$) matches the start of $b_1^{-1}$ ($v_3$). Thus $v_2 \\sim v_3$.\n\nCombining these equivalences for the first group of 4 edges:\n$$ v_0 \\sim v_3 \\sim v_2 \\sim v_1 \\sim v_4 $$\nThus, the start of the first sequence ($v_0$) is equivalent to the start of the next sequence ($v_4$). By induction, for any handle $i$, the vertices involved are all identified together, and the vertex at the end of the $i$-th group is identified with the vertex at the start of the $(i+1)$-th group.\n\nSince the boundary is a single connected cycle, **all** $4g$ vertices of the polygon are identified to a single point in the quotient manifold.\n$$ V = 1 $$\n\n**Step 5: Calculation**\nWe substitute the counts into the Euler characteristic formula:\n$$ \\chi(M) = V - E + F $$\n$$ \\chi(M) = 1 - 2g + 1 $$\n$$ \\chi(M) = 2 - 2g $$\n\n---\n\n### 3. Alternative Verification (Surgery / Handle Addition)\n\nWe can also prove this via induction on the number of handles, utilizing the property of the connected sum. A sphere with $g$ handles is homeomorphic to the connected sum of a sphere and $g$ tori, or simply the connected sum of $g$ tori (assuming $g \\ge 1$; for $g=0$ it is the sphere).\n\nLet $S^2$ be the sphere.\n1.  **Base Case ($g=0$):**\n    For a sphere, standard decomposition (e.g., tetrahedron) gives $V=4, E=6, F=4$.\n    $\\chi(S^2) = 4 - 6 + 4 = 2$.\n    The formula yields $2 - 2(0) = 2$. The base case holds.\n\n2.  **Inductive Step:**\n    Adding a \"handle\" is topologically equivalent to forming the connected sum with a torus $T^2$.\n    The operation is $M_{g+1} = M_g \\# T^2$.\n    The Euler characteristic for a connected sum is given by:\n    $$ \\chi(A \\# B) = \\chi(A) + \\chi(B) - 2 $$\n    We know $\\chi(T^2) = 0$ (since $T^2$ can be viewed as a square with opposite sides identified: $V=1, E=2, F=1 \\implies 1-2+1=0$).\n\n    Assume $\\chi(M_g) = 2 - 2g$. Then:\n    $$ \\chi(M_{g+1}) = \\chi(M_g) + \\chi(T^2) - 2 $$\n    $$ \\chi(M_{g+1}) = (2 - 2g) + 0 - 2 $$\n    $$ \\chi(M_{g+1}) = 2 - 2g - 2 $$\n    $$ \\chi(M_{g+1}) = 2 - 2(g + 1) $$\n\nThis confirms the result for all $g \\ge 0$.\n\n### Conclusion\n\nWe have constructed a cell decomposition for the manifold $M$, determined there is 1 face, $2g$ edges, and 1 vertex, and verified the result via the connected sum formula.\n\n**Final Result:**\nThe Euler characteristic of a 2-dimensional manifold homeomorphic to a sphere with $g$ handles is:\n$$ \\chi(M) = 2 - 2g $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $g(x) = x^3 - x - 1$. We are tasked with approximating the root of $g(x)$ in the interval $[1,2]$ using the bisection method. Perform two iterations of the bisection method starting with the initial interval $[1,2]$ to find the interval that contains the root after two iterations.",
    "run_id": "44",
    "outer_attempt": 2,
    "topic_slug": "numerical_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the interval that contains the root of the function $g(x) = x^3 - x - 1$ after two iterations of the bisection method, we proceed step-by-step.\n\n### Initial Setup\n\nWe are given the function:\n$$g(x) = x^3 - x - 1$$\nThe initial interval is $[a_0, b_0] = [1, 2]$.\n\nFirst, we verify the existence of a root in this interval using the Intermediate Value Theorem by checking the signs of the function at the endpoints:\n1.  **Evaluate at $x = 1$:**\n    $$g(1) = 1^3 - 1 - 1 = 1 - 2 = -1 \\quad (\\text{Negative})$$\n2.  **Evaluate at $x = 2$:**\n    $$g(2) = 2^3 - 2 - 1 = 8 - 3 = 5 \\quad (\\text{Positive})$$\n\nSince $g(x)$ is a continuous polynomial function and $g(1) < 0 < g(2)$, there is at least one real root in the interval $[1, 2]$.\n\n---\n\n### Iteration 1\n\nWe calculate the midpoint $c_0$ of the current interval $[a_0, b_0] = [1, 2]$.\n\n**1. Calculate Midpoint:**\n$$c_0 = \\frac{1 + 2}{2} = 1.5$$\n\n**2. Evaluate $g(c_0)$:**\n$$g(1.5) = (1.5)^3 - 1.5 - 1$$\n$$g(1.5) = 3.375 - 2.5$$\n$$g(1.5) = 0.875 \\quad (\\text{Positive})$$\n\n**3. Determine New Interval:**\nWe compare the sign of $g(c_0)$ with the signs at the endpoints:\n*   $g(1) = -1$ (Negative)\n*   $g(1.5) = 0.875$ (Positive)\n\nThe sign change occurs between $x=1$ and $x=1.5$. Therefore, the root lies in the interval $[1, 1.5]$.\nThe new interval is $[a_1, b_1] = [1, 1.5]$.\n\n---\n\n### Iteration 2\n\nWe perform the same process on the new interval $[a_1, b_1] = [1, 1.5]$.\n\n**1. Calculate Midpoint:**\n$$c_1 = \\frac{1 + 1.5}{2} = \\frac{2.5}{2} = 1.25$$\n\n**2. Evaluate $g(c_1)$:**\n$$g(1.25) = (1.25)^3 - 1.25 - 1$$\n\nCalculating $(1.25)^3$:\n$$(1.25)^2 = 1.5625$$\n$$(1.25)^3 = 1.5625 \\times 1.25 = 1.953125$$\n\nSubstituting back into $g(x)$:\n$$g(1.25) = 1.953125 - 1.25 - 1$$\n$$g(1.25) = 1.953125 - 2.25$$\n$$g(1.25) = -0.296875 \\quad (\\text{Negative})$$\n\n**3. Determine New Interval:**\nWe compare the sign of $g(c_1)$ with the signs at the endpoints of the current interval $[1, 1.5]$:\n*   $g(1.25) = -0.296875$ (Negative)\n*   $g(1.5) = 0.875$ (Positive)\n\nThe sign change occurs between $x=1.25$ and $x=1.5$. Therefore, the root lies in the interval $[1.25, 1.5]$.\nThe new interval is $[a_2, b_2] = [1.25, 1.5]$.\n\n---\n\n### Conclusion\n\nAfter performing two iterations of the bisection method on $g(x) = x^3 - x - 1$ starting with the interval $[1, 2]$, the interval containing the root is:\n\n$$[1.25, 1.5]$$",
        "raw_answer": "To find the interval that contains the root of the function $g(x) = x^3 - x - 1$ after two iterations of the bisection method, we proceed step-by-step.\n\n### Initial Setup\n\nWe are given the function:\n$$g(x) = x^3 - x - 1$$\nThe initial interval is $[a_0, b_0] = [1, 2]$.\n\nFirst, we verify the existence of a root in this interval using the Intermediate Value Theorem by checking the signs of the function at the endpoints:\n1.  **Evaluate at $x = 1$:**\n    $$g(1) = 1^3 - 1 - 1 = 1 - 2 = -1 \\quad (\\text{Negative})$$\n2.  **Evaluate at $x = 2$:**\n    $$g(2) = 2^3 - 2 - 1 = 8 - 3 = 5 \\quad (\\text{Positive})$$\n\nSince $g(x)$ is a continuous polynomial function and $g(1) < 0 < g(2)$, there is at least one real root in the interval $[1, 2]$.\n\n---\n\n### Iteration 1\n\nWe calculate the midpoint $c_0$ of the current interval $[a_0, b_0] = [1, 2]$.\n\n**1. Calculate Midpoint:**\n$$c_0 = \\frac{1 + 2}{2} = 1.5$$\n\n**2. Evaluate $g(c_0)$:**\n$$g(1.5) = (1.5)^3 - 1.5 - 1$$\n$$g(1.5) = 3.375 - 2.5$$\n$$g(1.5) = 0.875 \\quad (\\text{Positive})$$\n\n**3. Determine New Interval:**\nWe compare the sign of $g(c_0)$ with the signs at the endpoints:\n*   $g(1) = -1$ (Negative)\n*   $g(1.5) = 0.875$ (Positive)\n\nThe sign change occurs between $x=1$ and $x=1.5$. Therefore, the root lies in the interval $[1, 1.5]$.\nThe new interval is $[a_1, b_1] = [1, 1.5]$.\n\n---\n\n### Iteration 2\n\nWe perform the same process on the new interval $[a_1, b_1] = [1, 1.5]$.\n\n**1. Calculate Midpoint:**\n$$c_1 = \\frac{1 + 1.5}{2} = \\frac{2.5}{2} = 1.25$$\n\n**2. Evaluate $g(c_1)$:**\n$$g(1.25) = (1.25)^3 - 1.25 - 1$$\n\nCalculating $(1.25)^3$:\n$$(1.25)^2 = 1.5625$$\n$$(1.25)^3 = 1.5625 \\times 1.25 = 1.953125$$\n\nSubstituting back into $g(x)$:\n$$g(1.25) = 1.953125 - 1.25 - 1$$\n$$g(1.25) = 1.953125 - 2.25$$\n$$g(1.25) = -0.296875 \\quad (\\text{Negative})$$\n\n**3. Determine New Interval:**\nWe compare the sign of $g(c_1)$ with the signs at the endpoints of the current interval $[1, 1.5]$:\n*   $g(1.25) = -0.296875$ (Negative)\n*   $g(1.5) = 0.875$ (Positive)\n\nThe sign change occurs between $x=1.25$ and $x=1.5$. Therefore, the root lies in the interval $[1.25, 1.5]$.\nThe new interval is $[a_2, b_2] = [1.25, 1.5]$.\n\n---\n\n### Conclusion\n\nAfter performing two iterations of the bisection method on $g(x) = x^3 - x - 1$ starting with the interval $[1, 2]$, the interval containing the root is:\n\n$$[1.25, 1.5]$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $P(x)$ be the predicate \"$x$ is a prime number.\" Formalize the statement \"There are infinitely many prime numbers\" using the predicate $P(x)$, and determine whether it is true or false. If true, provide a proof; if false, provide a counterexample.",
    "run_id": "1",
    "outer_attempt": 3,
    "topic_slug": "mathematical_logic_and_foundations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To address the task, we will first formalize the statement using standard first-order logic, determine its truth value, and then provide a rigorous mathematical proof.\n\n### 1. Formalization\n\nTo formalize the statement \"There are infinitely many prime numbers,\" we interpret the concept of \"infinity\" in the context of an ordered set like the integers. A set of numbers is infinite if, for any number in the set (or in the domain), there exists a larger number that belongs to the set.\n\n**Domain of Discourse:** Let the domain be the set of positive integers, $\\mathbb{Z}^+ = \\{1, 2, 3, \\dots\\}$.\n**Predicate:** Let $P(x)$ denote \"$x$ is a prime number.\"\n\nThe statement \"There are infinitely many prime numbers\" is logically equivalent to \"For every positive integer $n$, there exists a prime number $p$ such that $p$ is strictly greater than $n$.\"\n\n**Formal Statement:**\n$$ \\forall n \\in \\mathbb{Z}^+, \\exists p \\in \\mathbb{Z}^+, \\, (p > n \\land P(p)) $$\n\n### 2. Truth Value\n\nThe statement is **True**.\n\nThis is a classic theorem in number theory, first proved by Euclid around 300 BC (Euclid's Elements, Book IX, Proposition 20).\n\n### 3. Proof\n\nWe provide a direct proof of the formalized statement.\n\n**Theorem:** For every positive integer $n$, there exists a prime number $p$ such that $p > n$.\n\n**Proof:**\nLet $n$ be an arbitrary positive integer. We must show that there exists a prime $p$ satisfying $p > n$.\n\n1.  **Construction of a candidate number:**\n    Consider the integer $M$ defined as:\n    $$ M = n! + 1 $$\n    where $n!$ (n-factorial) is the product of all positive integers from $1$ to $n$.\n    Since $n \\geq 1$, we have $n! \\geq 1$, implying $M \\geq 2$.\n\n2.  **Existence of a prime factor:**\n    By the Fundamental Theorem of Arithmetic (or the elementary property that every integer greater than 1 has at least one prime divisor), there exists a prime number $p$ such that $p$ divides $M$ (denoted as $p \\mid M$).\n\n3.  **Proof that $p > n$:**\n    We proceed by contradiction. Assume, for the sake of argument, that $p \\leq n$.\n    \n    *   Since $p$ is a prime, $p$ is a positive integer greater than 1.\n    *   If $p \\leq n$, then $p$ appears as a factor in the product $n! = 1 \\times 2 \\times \\dots \\times p \\times \\dots \\times n$.\n    *   Consequently, $p$ divides $n!$ (denoted as $p \\mid n!$).\n    \n    We now have:\n    *   $p \\mid M$ (by definition of $p$)\n    *   $p \\mid n!$ (by assumption $p \\leq n$)\n    \n    If an integer divides two numbers, it must also divide their difference. Therefore:\n    $$ p \\mid (M - n!) $$\n    Substituting $M = n! + 1$:\n    $$ p \\mid ((n! + 1) - n!) $$\n    $$ p \\mid 1 $$\n    \n    However, $p$ is a prime number, so $p \\geq 2$. It is impossible for a number greater than or equal to 2 to divide 1.\n    \n    This creates a contradiction. Therefore, the assumption that $p \\leq n$ must be false.\n\n4.  **Conclusion:**\n    It follows that $p > n$. Since we established that $p$ is a prime number ($P(p)$ is true), we have found a prime $p$ such that $p > n$.\n\nSince $n$ was chosen arbitrarily, the statement holds for all positive integers $n$.\n\n$$ \\forall n \\in \\mathbb{Z}^+, \\exists p \\in \\mathbb{Z}^+, \\, (p > n \\land P(p)) $$\n\n**Q.E.D.**",
        "raw_answer": "To address the task, we will first formalize the statement using standard first-order logic, determine its truth value, and then provide a rigorous mathematical proof.\n\n### 1. Formalization\n\nTo formalize the statement \"There are infinitely many prime numbers,\" we interpret the concept of \"infinity\" in the context of an ordered set like the integers. A set of numbers is infinite if, for any number in the set (or in the domain), there exists a larger number that belongs to the set.\n\n**Domain of Discourse:** Let the domain be the set of positive integers, $\\mathbb{Z}^+ = \\{1, 2, 3, \\dots\\}$.\n**Predicate:** Let $P(x)$ denote \"$x$ is a prime number.\"\n\nThe statement \"There are infinitely many prime numbers\" is logically equivalent to \"For every positive integer $n$, there exists a prime number $p$ such that $p$ is strictly greater than $n$.\"\n\n**Formal Statement:**\n$$ \\forall n \\in \\mathbb{Z}^+, \\exists p \\in \\mathbb{Z}^+, \\, (p > n \\land P(p)) $$\n\n### 2. Truth Value\n\nThe statement is **True**.\n\nThis is a classic theorem in number theory, first proved by Euclid around 300 BC (Euclid's Elements, Book IX, Proposition 20).\n\n### 3. Proof\n\nWe provide a direct proof of the formalized statement.\n\n**Theorem:** For every positive integer $n$, there exists a prime number $p$ such that $p > n$.\n\n**Proof:**\nLet $n$ be an arbitrary positive integer. We must show that there exists a prime $p$ satisfying $p > n$.\n\n1.  **Construction of a candidate number:**\n    Consider the integer $M$ defined as:\n    $$ M = n! + 1 $$\n    where $n!$ (n-factorial) is the product of all positive integers from $1$ to $n$.\n    Since $n \\geq 1$, we have $n! \\geq 1$, implying $M \\geq 2$.\n\n2.  **Existence of a prime factor:**\n    By the Fundamental Theorem of Arithmetic (or the elementary property that every integer greater than 1 has at least one prime divisor), there exists a prime number $p$ such that $p$ divides $M$ (denoted as $p \\mid M$).\n\n3.  **Proof that $p > n$:**\n    We proceed by contradiction. Assume, for the sake of argument, that $p \\leq n$.\n    \n    *   Since $p$ is a prime, $p$ is a positive integer greater than 1.\n    *   If $p \\leq n$, then $p$ appears as a factor in the product $n! = 1 \\times 2 \\times \\dots \\times p \\times \\dots \\times n$.\n    *   Consequently, $p$ divides $n!$ (denoted as $p \\mid n!$).\n    \n    We now have:\n    *   $p \\mid M$ (by definition of $p$)\n    *   $p \\mid n!$ (by assumption $p \\leq n$)\n    \n    If an integer divides two numbers, it must also divide their difference. Therefore:\n    $$ p \\mid (M - n!) $$\n    Substituting $M = n! + 1$:\n    $$ p \\mid ((n! + 1) - n!) $$\n    $$ p \\mid 1 $$\n    \n    However, $p$ is a prime number, so $p \\geq 2$. It is impossible for a number greater than or equal to 2 to divide 1.\n    \n    This creates a contradiction. Therefore, the assumption that $p \\leq n$ must be false.\n\n4.  **Conclusion:**\n    It follows that $p > n$. Since we established that $p$ is a prime number ($P(p)$ is true), we have found a prime $p$ such that $p > n$.\n\nSince $n$ was chosen arbitrarily, the statement holds for all positive integers $n$.\n\n$$ \\forall n \\in \\mathbb{Z}^+, \\exists p \\in \\mathbb{Z}^+, \\, (p > n \\land P(p)) $$\n\n**Q.E.D.**",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Determine whether the polynomial $p(x) = x^4 + 1$ is irreducible over the field $\\mathbb{Q}$ of rational numbers.",
    "run_id": "6",
    "outer_attempt": 4,
    "topic_slug": "field_theory_and_polynomials",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To determine whether the polynomial $p(x) = x^4 + 1$ is irreducible over the field of rational numbers $\\mathbb{Q}$, we proceed with the following rigorous analysis.\n\n### 1. Preliminaries and Gauss's Lemma\n\nA polynomial in $\\mathbb{Q}[x]$ is irreducible if it cannot be written as a product of two non-constant polynomials with rational coefficients.\n\nSince $p(x) = x^4 + 1$ is a monic polynomial with integer coefficients, Gauss's Lemma states that $p(x)$ is reducible over $\\mathbb{Q}$ if and only if it is reducible over $\\mathbb{Z}$ (the integers). That is, if $p(x)$ factors in $\\mathbb{Q}[x]$, it must factor in $\\mathbb{Z}[x]$.\n\nWe will prove that $p(x)$ is irreducible using **Eisenstein's Criterion** applied to a transformed polynomial.\n\n### 2. Method: Eisenstein's Criterion with a Shift\n\nEisenstein's Criterion states that for a polynomial $f(x) = a_n x^n + \\dots + a_1 x + a_0$ with integer coefficients, if there exists a prime number $q$ such that:\n1. $q$ divides $a_i$ for all $0 \\le i < n$,\n2. $q$ does not divide $a_n$,\n3. $q^2$ does not divide $a_0$,\nthen $f(x)$ is irreducible over $\\mathbb{Q}$.\n\nDirect application of this criterion to $p(x) = x^4 + 1$ is not possible because no prime divides the coefficient of $x$ (which is 0) while dividing the constant term 1. However, irreducibility is preserved under translation. If we define $g(y) = p(y+1)$, then $p(x)$ is irreducible if and only if $g(y)$ is irreducible.\n\n#### Step 2.1: Transformation\n\nLet $x = y+1$. We substitute this into $p(x)$:\n$$ g(y) = p(y+1) = (y+1)^4 + 1 $$\n\nUsing the Binomial Theorem, we expand $(y+1)^4$:\n$$ (y+1)^4 = y^4 + 4y^3 + 6y^2 + 4y + 1 $$\n\nThus:\n$$ g(y) = (y^4 + 4y^3 + 6y^2 + 4y + 1) + 1 $$\n$$ g(y) = y^4 + 4y^3 + 6y^2 + 4y + 2 $$\n\n#### Step 2.2: Apply Eisenstein's Criterion\n\nThe coefficients of $g(y)$ are:\n*   $a_4 = 1$\n*   $a_3 = 4$\n*   $a_2 = 6$\n*   $a_1 = 4$\n*   $a_0 = 2$\n\nWe test the prime $q = 2$:\n1.  **Divisibility of non-leading coefficients:**\n    *   $2 \\mid 4$ ($a_3$)\n    *   $2 \\mid 6$ ($a_2$)\n    *   $2 \\mid 4$ ($a_1$)\n    *   $2 \\mid 2$ ($a_0$)\n    Condition satisfied.\n\n2.  **Non-divisibility of leading coefficient:**\n    *   $a_4 = 1$, and $2 \\nmid 1$.\n    Condition satisfied.\n\n3.  **Non-divisibility of constant term by $q^2$:**\n    *   $a_0 = 2$.\n    *   $q^2 = 2^2 = 4$.\n    *   $4 \\nmid 2$.\n    Condition satisfied.\n\nSince all conditions of Eisenstein's Criterion are met for $g(y)$ with $q=2$, $g(y)$ is irreducible over $\\mathbb{Q}$.\n\n### 3. Conclusion\n\nSince $g(y)$ is irreducible over $\\mathbb{Q}$ and $g(y) = p(y+1)$, the original polynomial $p(x)$ is also irreducible over $\\mathbb{Q}$.\n\n**Answer:** The polynomial $p(x) = x^4 + 1$ is **irreducible** over $\\mathbb{Q}$.",
        "raw_answer": "To determine whether the polynomial $p(x) = x^4 + 1$ is irreducible over the field of rational numbers $\\mathbb{Q}$, we proceed with the following rigorous analysis.\n\n### 1. Preliminaries and Gauss's Lemma\n\nA polynomial in $\\mathbb{Q}[x]$ is irreducible if it cannot be written as a product of two non-constant polynomials with rational coefficients.\n\nSince $p(x) = x^4 + 1$ is a monic polynomial with integer coefficients, Gauss's Lemma states that $p(x)$ is reducible over $\\mathbb{Q}$ if and only if it is reducible over $\\mathbb{Z}$ (the integers). That is, if $p(x)$ factors in $\\mathbb{Q}[x]$, it must factor in $\\mathbb{Z}[x]$.\n\nWe will prove that $p(x)$ is irreducible using **Eisenstein's Criterion** applied to a transformed polynomial.\n\n### 2. Method: Eisenstein's Criterion with a Shift\n\nEisenstein's Criterion states that for a polynomial $f(x) = a_n x^n + \\dots + a_1 x + a_0$ with integer coefficients, if there exists a prime number $q$ such that:\n1. $q$ divides $a_i$ for all $0 \\le i < n$,\n2. $q$ does not divide $a_n$,\n3. $q^2$ does not divide $a_0$,\nthen $f(x)$ is irreducible over $\\mathbb{Q}$.\n\nDirect application of this criterion to $p(x) = x^4 + 1$ is not possible because no prime divides the coefficient of $x$ (which is 0) while dividing the constant term 1. However, irreducibility is preserved under translation. If we define $g(y) = p(y+1)$, then $p(x)$ is irreducible if and only if $g(y)$ is irreducible.\n\n#### Step 2.1: Transformation\n\nLet $x = y+1$. We substitute this into $p(x)$:\n$$ g(y) = p(y+1) = (y+1)^4 + 1 $$\n\nUsing the Binomial Theorem, we expand $(y+1)^4$:\n$$ (y+1)^4 = y^4 + 4y^3 + 6y^2 + 4y + 1 $$\n\nThus:\n$$ g(y) = (y^4 + 4y^3 + 6y^2 + 4y + 1) + 1 $$\n$$ g(y) = y^4 + 4y^3 + 6y^2 + 4y + 2 $$\n\n#### Step 2.2: Apply Eisenstein's Criterion\n\nThe coefficients of $g(y)$ are:\n*   $a_4 = 1$\n*   $a_3 = 4$\n*   $a_2 = 6$\n*   $a_1 = 4$\n*   $a_0 = 2$\n\nWe test the prime $q = 2$:\n1.  **Divisibility of non-leading coefficients:**\n    *   $2 \\mid 4$ ($a_3$)\n    *   $2 \\mid 6$ ($a_2$)\n    *   $2 \\mid 4$ ($a_1$)\n    *   $2 \\mid 2$ ($a_0$)\n    Condition satisfied.\n\n2.  **Non-divisibility of leading coefficient:**\n    *   $a_4 = 1$, and $2 \\nmid 1$.\n    Condition satisfied.\n\n3.  **Non-divisibility of constant term by $q^2$:**\n    *   $a_0 = 2$.\n    *   $q^2 = 2^2 = 4$.\n    *   $4 \\nmid 2$.\n    Condition satisfied.\n\nSince all conditions of Eisenstein's Criterion are met for $g(y)$ with $q=2$, $g(y)$ is irreducible over $\\mathbb{Q}$.\n\n### 3. Conclusion\n\nSince $g(y)$ is irreducible over $\\mathbb{Q}$ and $g(y) = p(y+1)$, the original polynomial $p(x)$ is also irreducible over $\\mathbb{Q}$.\n\n**Answer:** The polynomial $p(x) = x^4 + 1$ is **irreducible** over $\\mathbb{Q}$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $\\mathfrak{sl}(2, \\mathbb{R})$ be the Lie algebra of $2 \\times 2$ real matrices with trace zero, with the Lie bracket $[A, B] = AB - BA$. Show that the matrices $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and compute the structure constants with respect to this basis.",
    "run_id": "11",
    "outer_attempt": 4,
    "topic_slug": "nonassociative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete and rigorous solution to the problem.\n\n### 1. Definition and Basis Verification\n\nThe Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$ is the vector space of all $2 \\times 2$ real matrices with trace zero, equipped with the Lie bracket $[A, B] = AB - BA$.\n\nThe general form of a $2 \\times 2$ matrix $M$ is:\n$$ M = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}, \\quad a,b,c,d \\in \\mathbb{R} $$\nThe condition $\\text{tr}(M) = 0$ implies $a + d = 0$, or $d = -a$. Thus, any matrix in $\\mathfrak{sl}(2, \\mathbb{R})$ can be written as:\n$$ M = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} = a\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + b\\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c\\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} $$\nThis indicates that the space is 3-dimensional.\n\nWe are given the specific matrices:\n$$ H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} $$\n\n**Step 1.1: Verify elements belong to the algebra**\nFirst, we check the trace of each matrix:\n-   $\\text{tr}(H) = 1 + (-1) = 0$\n-   $\\text{tr}(X) = 0 + 0 = 0$\n-   $\\text{tr}(Y) = 0 + 0 = 0$\nAll three matrices belong to $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Step 1.2: Check Linear Independence**\nConsider a linear combination equal to the zero matrix:\n$$ aH + bX + cY = 0 $$\nSubstituting the matrices:\n$$ a\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + b\\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c\\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nComparing entries yields $a=0$, $b=0$, and $c=0$.\nSince the only solution is the trivial one, the set $\\{H, X, Y\\}$ is linearly independent.\n\n**Step 1.3: Conclusion on Basis**\nSince $\\mathfrak{sl}(2, \\mathbb{R})$ has dimension 3 and we have found 3 linearly independent vectors in the space, $\\{H, X, Y\\}$ forms a basis for $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n---\n\n### 2. Computation of Structure Constants\n\nThe structure constants $C_{ij}^k$ are defined by the relation:\n$$ [e_i, e_j] = \\sum_{k=1}^3 C_{ij}^k e_k $$\nwhere $\\{e_1, e_2, e_3\\}$ corresponds to the ordered basis $\\{H, X, Y\\}$. We compute the Lie brackets $[A, B] = AB - BA$ for each pair of basis vectors.\n\n**Calculation 1: $[H, X]$**\n$$ HX = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = X $$\n$$ XH = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix} = -X $$\n$$ [H, X] = HX - XH = X - (-X) = 2X $$\n\n**Calculation 2: $[H, Y]$**\n$$ HY = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix} = -Y $$\n$$ YH = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = Y $$\n$$ [H, Y] = HY - YH = -Y - Y = -2Y $$\n\n**Calculation 3: $[X, Y]$**\n$$ XY = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ YX = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\n$$ [X, Y] = XY - YX = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = H $$\n\n**Commutation Relations Summary**\nThe fundamental commutation relations are:\n1.  $[H, X] = 2X$\n2.  $[H, Y] = -2Y$\n3.  $[X, Y] = H$\n\nFrom the skew-symmetry of the Lie bracket ($[A, B] = -[B, A]$) and $[A, A] = 0$, we have the complete multiplication table.\n\n### 3. Final Result: Structure Constants\n\nLet the ordered basis be $e_1 = H$, $e_2 = X$, and $e_3 = Y$. The structure constants $C_{ij}^k$ are the coefficients of $e_k$ in the expansion of $[e_i, e_j]$.\n\nFrom $[e_1, e_2] = 2e_2$:\n$$ C_{12}^1 = 0, \\quad C_{12}^2 = 2, \\quad C_{12}^3 = 0 $$\n\nFrom $[e_1, e_3] = -2e_3$:\n$$ C_{13}^1 = 0, \\quad C_{13}^2 = 0, \\quad C_{13}^3 = -2 $$\n\nFrom $[e_2, e_3] = e_1$:\n$$ C_{23}^1 = 1, \\quad C_{23}^2 = 0, \\quad C_{23}^3 = 0 $$\n\nBy skew-symmetry ($C_{ji}^k = -C_{ij}^k$), the non-zero structure constants are:\n$$ C_{12}^2 = 2, \\quad C_{21}^2 = -2 $$\n$$ C_{13}^3 = -2, \\quad C_{31}^3 = 2 $$\n$$ C_{23}^1 = 1, \\quad C_{32}^1 = -1 $$\nAll other structure constants are zero.",
        "raw_answer": "Here is the complete and rigorous solution to the problem.\n\n### 1. Definition and Basis Verification\n\nThe Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$ is the vector space of all $2 \\times 2$ real matrices with trace zero, equipped with the Lie bracket $[A, B] = AB - BA$.\n\nThe general form of a $2 \\times 2$ matrix $M$ is:\n$$ M = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}, \\quad a,b,c,d \\in \\mathbb{R} $$\nThe condition $\\text{tr}(M) = 0$ implies $a + d = 0$, or $d = -a$. Thus, any matrix in $\\mathfrak{sl}(2, \\mathbb{R})$ can be written as:\n$$ M = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} = a\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + b\\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c\\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} $$\nThis indicates that the space is 3-dimensional.\n\nWe are given the specific matrices:\n$$ H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} $$\n\n**Step 1.1: Verify elements belong to the algebra**\nFirst, we check the trace of each matrix:\n-   $\\text{tr}(H) = 1 + (-1) = 0$\n-   $\\text{tr}(X) = 0 + 0 = 0$\n-   $\\text{tr}(Y) = 0 + 0 = 0$\nAll three matrices belong to $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Step 1.2: Check Linear Independence**\nConsider a linear combination equal to the zero matrix:\n$$ aH + bX + cY = 0 $$\nSubstituting the matrices:\n$$ a\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + b\\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c\\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nComparing entries yields $a=0$, $b=0$, and $c=0$.\nSince the only solution is the trivial one, the set $\\{H, X, Y\\}$ is linearly independent.\n\n**Step 1.3: Conclusion on Basis**\nSince $\\mathfrak{sl}(2, \\mathbb{R})$ has dimension 3 and we have found 3 linearly independent vectors in the space, $\\{H, X, Y\\}$ forms a basis for $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n---\n\n### 2. Computation of Structure Constants\n\nThe structure constants $C_{ij}^k$ are defined by the relation:\n$$ [e_i, e_j] = \\sum_{k=1}^3 C_{ij}^k e_k $$\nwhere $\\{e_1, e_2, e_3\\}$ corresponds to the ordered basis $\\{H, X, Y\\}$. We compute the Lie brackets $[A, B] = AB - BA$ for each pair of basis vectors.\n\n**Calculation 1: $[H, X]$**\n$$ HX = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = X $$\n$$ XH = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix} = -X $$\n$$ [H, X] = HX - XH = X - (-X) = 2X $$\n\n**Calculation 2: $[H, Y]$**\n$$ HY = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix} = -Y $$\n$$ YH = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = Y $$\n$$ [H, Y] = HY - YH = -Y - Y = -2Y $$\n\n**Calculation 3: $[X, Y]$**\n$$ XY = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ YX = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\n$$ [X, Y] = XY - YX = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = H $$\n\n**Commutation Relations Summary**\nThe fundamental commutation relations are:\n1.  $[H, X] = 2X$\n2.  $[H, Y] = -2Y$\n3.  $[X, Y] = H$\n\nFrom the skew-symmetry of the Lie bracket ($[A, B] = -[B, A]$) and $[A, A] = 0$, we have the complete multiplication table.\n\n### 3. Final Result: Structure Constants\n\nLet the ordered basis be $e_1 = H$, $e_2 = X$, and $e_3 = Y$. The structure constants $C_{ij}^k$ are the coefficients of $e_k$ in the expansion of $[e_i, e_j]$.\n\nFrom $[e_1, e_2] = 2e_2$:\n$$ C_{12}^1 = 0, \\quad C_{12}^2 = 2, \\quad C_{12}^3 = 0 $$\n\nFrom $[e_1, e_3] = -2e_3$:\n$$ C_{13}^1 = 0, \\quad C_{13}^2 = 0, \\quad C_{13}^3 = -2 $$\n\nFrom $[e_2, e_3] = e_1$:\n$$ C_{23}^1 = 1, \\quad C_{23}^2 = 0, \\quad C_{23}^3 = 0 $$\n\nBy skew-symmetry ($C_{ji}^k = -C_{ij}^k$), the non-zero structure constants are:\n$$ C_{12}^2 = 2, \\quad C_{21}^2 = -2 $$\n$$ C_{13}^3 = -2, \\quad C_{31}^3 = 2 $$\n$$ C_{23}^1 = 1, \\quad C_{32}^1 = -1 $$\nAll other structure constants are zero.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the given domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of special functions, along with a complete and verifiable solution. The given domain is special functions, and we need to create a problem that is simpler than the previously attempted questions but still challenging.\n\n## Step 2: Recall the properties and examples of special functions\nSpecial functions include the Gamma function, Bessel functions, elliptic functions, and others. The Gamma function, denoted by $\\Gamma(x)$, is defined as $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$ for $x > 0$. It has various properties and applications in mathematics and physics.\n\n## Step 3: Formulate a problem related to special functions\nTo create a problem, let's consider a basic property or application of special functions. One fundamental property is the Gamma function's relation to factorials for positive integers, given by $\\Gamma(n+1) = n!$. A simple and challenging problem could involve proving or verifying an identity or inequality related to the Gamma function.\n\n## Step 4: Generate a specific problem\nLet's consider the problem: \"Prove that $\\Gamma(x+1) = x\\Gamma(x)$ for $x > 0$, where $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.\"\n\n## Step 5: Provide a solution to the generated problem\nTo prove that $\\Gamma(x+1) = x\\Gamma(x)$, we start with the definition of $\\Gamma(x+1)$:\n$\\Gamma(x+1) = \\int_{0}^{\\infty} t^{x}e^{-t}dt$.\nUsing integration by parts with $u = t^x$ and $dv = e^{-t}dt$, we have $du = xt^{x-1}dt$ and $v = -e^{-t}$. Thus,\n$\\Gamma(x+1) = \\left[-t^xe^{-t}\\right]_{0}^{\\infty} + x\\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.\nThe first term vanishes at both limits because $e^{-t}$ decays faster than $t^x$ grows as $t \\to \\infty$ for $x > 0$, and at $t = 0$, $t^x = 0$ for $x > 0$. Thus,\n$\\Gamma(x+1) = x\\int_{0}^{\\infty} t^{x-1}e^{-t}dt = x\\Gamma(x)$.\n\n## Step 6: Format the problem and solution according to the required output format\n\nProve that $\\Gamma(x+1) = x\\Gamma(x)$ for $x > 0$, where $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.",
    "run_id": "21",
    "outer_attempt": 3,
    "topic_slug": "special_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem:**\nProve that $\\Gamma(x+1) = x\\Gamma(x)$ for $x > 0$, where $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.\n\n**Proof:**\n\n**1. Definition of the term $\\Gamma(x+1)$**\nBy the definition of the Gamma function provided, substitute $x+1$ for the argument:\n$$ \\Gamma(x+1) = \\int_{0}^{\\infty} t^{(x+1)-1}e^{-t} \\, dt = \\int_{0}^{\\infty} t^{x}e^{-t} \\, dt $$\n\n**2. Integration by Parts**\nWe evaluate this integral using integration by parts. Let:\n$$ u = t^x \\quad \\text{and} \\quad dv = e^{-t} \\, dt $$\nThen, differentiating $u$ with respect to $t$ and integrating $dv$:\n$$ du = x t^{x-1} \\, dt \\quad \\text{and} \\quad v = -e^{-t} $$\n\nUsing the integration by parts formula $\\int_{a}^{b} u \\, dv = \\left[ uv \\right]_{a}^{b} - \\int_{a}^{b} v \\, du$, we have:\n$$ \\Gamma(x+1) = \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} - \\int_{0}^{\\infty} (-e^{-t})(x t^{x-1}) \\, dt $$\nSimplifying the signs in the integral term:\n$$ \\Gamma(x+1) = \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} + x \\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt $$\n\n**3. Evaluation of the Boundary Terms**\nWe must evaluate the term $\\left[ -t^x e^{-t} \\right]_{0}^{\\infty}$:\n$$ \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} = \\lim_{t \\to \\infty} (-t^x e^{-t}) - \\lim_{t \\to 0^+} (-t^x e^{-t}) $$\n\n*   **Upper Limit:**\n    Consider $\\lim_{t \\to \\infty} \\frac{t^x}{e^t}$. Since the exponential function $e^t$ grows faster than any power function $t^x$ as $t \\to \\infty$, this limit is 0.\n    $$ \\lim_{t \\to \\infty} -t^x e^{-t} = 0 $$\n*   **Lower Limit:**\n    Consider $\\lim_{t \\to 0^+} -t^x e^{-t}$. Since $x > 0$, $\\lim_{t \\to 0^+} t^x = 0$. Also, $\\lim_{t \\to 0^+} e^{-t} = 1$. Therefore:\n    $$ \\lim_{t \\to 0^+} -t^x e^{-t} = -(0)(1) = 0 $$\n\nThus, the boundary term vanishes entirely.\n\n**4. Identification of the Resulting Integral**\nWe are left with:\n$$ \\Gamma(x+1) = 0 + x \\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt $$\nBy definition, the integral $\\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt$ is exactly $\\Gamma(x)$.\n\n**Conclusion**\nSubstituting $\\Gamma(x)$ back into the equation, we obtain:\n$$ \\Gamma(x+1) = x\\Gamma(x) $$\nThis completes the proof.",
        "raw_answer": "**Problem:**\nProve that $\\Gamma(x+1) = x\\Gamma(x)$ for $x > 0$, where $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.\n\n**Proof:**\n\n**1. Definition of the term $\\Gamma(x+1)$**\nBy the definition of the Gamma function provided, substitute $x+1$ for the argument:\n$$ \\Gamma(x+1) = \\int_{0}^{\\infty} t^{(x+1)-1}e^{-t} \\, dt = \\int_{0}^{\\infty} t^{x}e^{-t} \\, dt $$\n\n**2. Integration by Parts**\nWe evaluate this integral using integration by parts. Let:\n$$ u = t^x \\quad \\text{and} \\quad dv = e^{-t} \\, dt $$\nThen, differentiating $u$ with respect to $t$ and integrating $dv$:\n$$ du = x t^{x-1} \\, dt \\quad \\text{and} \\quad v = -e^{-t} $$\n\nUsing the integration by parts formula $\\int_{a}^{b} u \\, dv = \\left[ uv \\right]_{a}^{b} - \\int_{a}^{b} v \\, du$, we have:\n$$ \\Gamma(x+1) = \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} - \\int_{0}^{\\infty} (-e^{-t})(x t^{x-1}) \\, dt $$\nSimplifying the signs in the integral term:\n$$ \\Gamma(x+1) = \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} + x \\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt $$\n\n**3. Evaluation of the Boundary Terms**\nWe must evaluate the term $\\left[ -t^x e^{-t} \\right]_{0}^{\\infty}$:\n$$ \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} = \\lim_{t \\to \\infty} (-t^x e^{-t}) - \\lim_{t \\to 0^+} (-t^x e^{-t}) $$\n\n*   **Upper Limit:**\n    Consider $\\lim_{t \\to \\infty} \\frac{t^x}{e^t}$. Since the exponential function $e^t$ grows faster than any power function $t^x$ as $t \\to \\infty$, this limit is 0.\n    $$ \\lim_{t \\to \\infty} -t^x e^{-t} = 0 $$\n*   **Lower Limit:**\n    Consider $\\lim_{t \\to 0^+} -t^x e^{-t}$. Since $x > 0$, $\\lim_{t \\to 0^+} t^x = 0$. Also, $\\lim_{t \\to 0^+} e^{-t} = 1$. Therefore:\n    $$ \\lim_{t \\to 0^+} -t^x e^{-t} = -(0)(1) = 0 $$\n\nThus, the boundary term vanishes entirely.\n\n**4. Identification of the Resulting Integral**\nWe are left with:\n$$ \\Gamma(x+1) = 0 + x \\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt $$\nBy definition, the integral $\\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt$ is exactly $\\Gamma(x)$.\n\n**Conclusion**\nSubstituting $\\Gamma(x)$ back into the equation, we obtain:\n$$ \\Gamma(x+1) = x\\Gamma(x) $$\nThis completes the proof.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $G$ be a finite abelian group and $\\mu$ be the counting measure on $G$. For $f \\in L^2(G, \\mu)$, define the Fourier transform $\\hat{f}: \\hat{G} \\to \\mathbb{C}$ by $\\hat{f}(\\chi) = \\sum_{x \\in G} f(x) \\overline{\\chi(x)}$, where $\\hat{G}$ is the dual group of $G$. Prove that the inverse Fourier transform of $\\hat{f}$ is given by $f(x) = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x)$ for all $x \\in G$.",
    "run_id": "29",
    "outer_attempt": 3,
    "topic_slug": "abstract_harmonic_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove the Fourier inversion formula for a function $f$ on a finite abelian group $G$, we will directly evaluate the expression for the inverse transform and show that it equals $f(x)$.\n\n### 1. Setup and Substitution\n\nLet the group operation of $G$ be denoted additively, with identity element $0$. The characters $\\chi \\in \\hat{G}$ are group homomorphisms from $G$ to the multiplicative group of complex numbers $\\mathbb{C}^\\times$. They satisfy the properties:\n*   $\\chi(a + b) = \\chi(a)\\chi(b)$\n*   $\\chi(-a) = \\chi(a)^{-1} = \\overline{\\chi(a)}$ (since $|\\chi(a)| = 1$)\n*   $\\chi(0) = 1$\n\nWe want to prove that for any $x \\in G$:\n$$ f(x) = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x) $$\n\nLet us denote the right-hand side by $S(x)$. We substitute the definition of the Fourier transform, $\\hat{f}(\\chi) = \\sum_{y \\in G} f(y) \\overline{\\chi(y)}$, into the expression for $S(x)$:\n\n$$ S(x) = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\left( \\sum_{y \\in G} f(y) \\overline{\\chi(y)} \\right) \\chi(x) $$\n\n### 2. Rearrangement of Sums\n\nSince $G$ and $\\hat{G}$ are finite, all sums involved are finite. We can change the order of summation without issues of convergence (Fubini's theorem for finite measures):\n\n$$ S(x) = \\frac{1}{|G|} \\sum_{y \\in G} f(y) \\left( \\sum_{\\chi \\in \\hat{G}} \\chi(x) \\overline{\\chi(y)} \\right) $$\n\nUsing the homomorphism property and the property of the complex conjugate for characters, we can combine the terms inside the inner sum:\n$$ \\chi(x) \\overline{\\chi(y)} = \\chi(x) \\chi(-y) = \\chi(x - y) $$\n\nThus, the expression becomes:\n$$ S(x) = \\frac{1}{|G|} \\sum_{y \\in G} f(y) \\left( \\sum_{\\chi \\in \\hat{G}} \\chi(x - y) \\right) $$\n\n### 3. Orthogonality of Characters\n\nTo evaluate the inner sum, we rely on the orthogonality relations for characters. Specifically, we need the \"Dual Orthogonality Relation\" (summing over characters rather than group elements).\n\n**Lemma (Orthogonality on $\\hat{G}$):** For any $g \\in G$:\n$$ \\sum_{\\chi \\in \\hat{G}} \\chi(g) = \\begin{cases} |G| & \\text{if } g = 0 \\\\ 0 & \\text{if } g \\neq 0 \\end{cases} $$\n*(Note: Since $G$ is a finite abelian group, $|\\hat{G}| = |G|$.)*\n\n**Proof of Lemma:**\n**Case 1: $g = 0$.**\nSince $\\chi(0) = 1$ for all characters $\\chi$, the sum is:\n$$ \\sum_{\\chi \\in \\hat{G}} \\chi(0) = \\sum_{\\chi \\in \\hat{G}} 1 = |\\hat{G}| = |G| $$\n\n**Case 2: $g \\neq 0$.**\nSince $G$ is a finite abelian group, the characters separate points. This means that for any $g \\in G$ with $g \\neq 0$, there exists a character $\\psi \\in \\hat{G}$ such that $\\psi(g) \\neq 1$.\nLet $T = \\sum_{\\chi \\in \\hat{G}} \\chi(g)$. Multiply $T$ by $\\psi(g)$:\n$$ \\psi(g) T = \\psi(g) \\sum_{\\chi \\in \\hat{G}} \\chi(g) = \\sum_{\\chi \\in \\hat{G}} \\psi(g)\\chi(g) = \\sum_{\\chi \\in \\hat{G}} (\\psi\\chi)(g) $$\nAs $\\chi$ runs over all elements of the group $\\hat{G}$, the product $\\psi\\chi$ also runs over all elements of $\\hat{G}$ (since multiplication by $\\psi$ is a bijection on the group $\\hat{G}$). Therefore, the sum remains the same:\n$$ \\sum_{\\chi \\in \\hat{G}} (\\psi\\chi)(g) = \\sum_{\\rho \\in \\hat{G}} \\rho(g) = T $$\nSo, we have $\\psi(g) T = T$, which implies:\n$$ T(\\psi(g) - 1) = 0 $$\nSince we chose $\\psi$ such that $\\psi(g) \\neq 1$, it must be that $T = 0$.\n\nThus, the lemma is proved.\n\n### 4. Final Evaluation\n\nWe apply the lemma to the inner sum of our expression for $S(x)$. Let $g = x - y$.\nThe inner sum is $\\sum_{\\chi \\in \\hat{G}} \\chi(x - y)$.\nAccording to the lemma:\n*   If $x - y = 0$ (i.e., $y = x$), the sum is $|G|$.\n*   If $x - y \\neq 0$ (i.e., $y \\neq x$), the sum is $0$.\n\nSubstituting this back into the expression for $S(x)$:\n\n$$ S(x) = \\frac{1}{|G|} \\sum_{y \\in G} f(y) \\cdot \\begin{cases} |G| & \\text{if } y = x \\\\ 0 & \\text{if } y \\neq x \\end{cases} $$\n\nThe summation over $y$ collapses to the single term where $y = x$:\n\n$$ S(x) = \\frac{1}{|G|} \\left( f(x) \\cdot |G| \\right) $$\n\n$$ S(x) = f(x) $$\n\n### Conclusion\n\nWe have shown that:\n$$ \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x) = f(x) $$\nThis completes the proof of the inverse Fourier transform formula.",
        "raw_answer": "To prove the Fourier inversion formula for a function $f$ on a finite abelian group $G$, we will directly evaluate the expression for the inverse transform and show that it equals $f(x)$.\n\n### 1. Setup and Substitution\n\nLet the group operation of $G$ be denoted additively, with identity element $0$. The characters $\\chi \\in \\hat{G}$ are group homomorphisms from $G$ to the multiplicative group of complex numbers $\\mathbb{C}^\\times$. They satisfy the properties:\n*   $\\chi(a + b) = \\chi(a)\\chi(b)$\n*   $\\chi(-a) = \\chi(a)^{-1} = \\overline{\\chi(a)}$ (since $|\\chi(a)| = 1$)\n*   $\\chi(0) = 1$\n\nWe want to prove that for any $x \\in G$:\n$$ f(x) = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x) $$\n\nLet us denote the right-hand side by $S(x)$. We substitute the definition of the Fourier transform, $\\hat{f}(\\chi) = \\sum_{y \\in G} f(y) \\overline{\\chi(y)}$, into the expression for $S(x)$:\n\n$$ S(x) = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\left( \\sum_{y \\in G} f(y) \\overline{\\chi(y)} \\right) \\chi(x) $$\n\n### 2. Rearrangement of Sums\n\nSince $G$ and $\\hat{G}$ are finite, all sums involved are finite. We can change the order of summation without issues of convergence (Fubini's theorem for finite measures):\n\n$$ S(x) = \\frac{1}{|G|} \\sum_{y \\in G} f(y) \\left( \\sum_{\\chi \\in \\hat{G}} \\chi(x) \\overline{\\chi(y)} \\right) $$\n\nUsing the homomorphism property and the property of the complex conjugate for characters, we can combine the terms inside the inner sum:\n$$ \\chi(x) \\overline{\\chi(y)} = \\chi(x) \\chi(-y) = \\chi(x - y) $$\n\nThus, the expression becomes:\n$$ S(x) = \\frac{1}{|G|} \\sum_{y \\in G} f(y) \\left( \\sum_{\\chi \\in \\hat{G}} \\chi(x - y) \\right) $$\n\n### 3. Orthogonality of Characters\n\nTo evaluate the inner sum, we rely on the orthogonality relations for characters. Specifically, we need the \"Dual Orthogonality Relation\" (summing over characters rather than group elements).\n\n**Lemma (Orthogonality on $\\hat{G}$):** For any $g \\in G$:\n$$ \\sum_{\\chi \\in \\hat{G}} \\chi(g) = \\begin{cases} |G| & \\text{if } g = 0 \\\\ 0 & \\text{if } g \\neq 0 \\end{cases} $$\n*(Note: Since $G$ is a finite abelian group, $|\\hat{G}| = |G|$.)*\n\n**Proof of Lemma:**\n**Case 1: $g = 0$.**\nSince $\\chi(0) = 1$ for all characters $\\chi$, the sum is:\n$$ \\sum_{\\chi \\in \\hat{G}} \\chi(0) = \\sum_{\\chi \\in \\hat{G}} 1 = |\\hat{G}| = |G| $$\n\n**Case 2: $g \\neq 0$.**\nSince $G$ is a finite abelian group, the characters separate points. This means that for any $g \\in G$ with $g \\neq 0$, there exists a character $\\psi \\in \\hat{G}$ such that $\\psi(g) \\neq 1$.\nLet $T = \\sum_{\\chi \\in \\hat{G}} \\chi(g)$. Multiply $T$ by $\\psi(g)$:\n$$ \\psi(g) T = \\psi(g) \\sum_{\\chi \\in \\hat{G}} \\chi(g) = \\sum_{\\chi \\in \\hat{G}} \\psi(g)\\chi(g) = \\sum_{\\chi \\in \\hat{G}} (\\psi\\chi)(g) $$\nAs $\\chi$ runs over all elements of the group $\\hat{G}$, the product $\\psi\\chi$ also runs over all elements of $\\hat{G}$ (since multiplication by $\\psi$ is a bijection on the group $\\hat{G}$). Therefore, the sum remains the same:\n$$ \\sum_{\\chi \\in \\hat{G}} (\\psi\\chi)(g) = \\sum_{\\rho \\in \\hat{G}} \\rho(g) = T $$\nSo, we have $\\psi(g) T = T$, which implies:\n$$ T(\\psi(g) - 1) = 0 $$\nSince we chose $\\psi$ such that $\\psi(g) \\neq 1$, it must be that $T = 0$.\n\nThus, the lemma is proved.\n\n### 4. Final Evaluation\n\nWe apply the lemma to the inner sum of our expression for $S(x)$. Let $g = x - y$.\nThe inner sum is $\\sum_{\\chi \\in \\hat{G}} \\chi(x - y)$.\nAccording to the lemma:\n*   If $x - y = 0$ (i.e., $y = x$), the sum is $|G|$.\n*   If $x - y \\neq 0$ (i.e., $y \\neq x$), the sum is $0$.\n\nSubstituting this back into the expression for $S(x)$:\n\n$$ S(x) = \\frac{1}{|G|} \\sum_{y \\in G} f(y) \\cdot \\begin{cases} |G| & \\text{if } y = x \\\\ 0 & \\text{if } y \\neq x \\end{cases} $$\n\nThe summation over $y$ collapses to the single term where $y = x$:\n\n$$ S(x) = \\frac{1}{|G|} \\left( f(x) \\cdot |G| \\right) $$\n\n$$ S(x) = f(x) $$\n\n### Conclusion\n\nWe have shown that:\n$$ \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x) = f(x) $$\nThis completes the proof of the inverse Fourier transform formula.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles. Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.",
    "run_id": "40",
    "outer_attempt": 3,
    "topic_slug": "manifolds_and_cell_complexes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the Euler characteristic of a 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles is $\\chi(M) = 2 - 2g$, we will use the properties of the Euler characteristic under the operation of the **connected sum** or, equivalently, the geometric surgery of **attaching a handle**.\n\n### 1. Definitions and Properties\n\nThe Euler characteristic $\\chi(X)$ for a topological space $X$ (specifically a finite CW-complex or triangulable manifold) is an integer invariant. We rely on the following standard properties:\n\n1.  **Triangulation Definition**: For a surface triangulated with $V$ vertices, $E$ edges, and $F$ faces, $\\chi(X) = V - E + F$.\n2.  **Inclusion-Exclusion Principle**: For spaces $A$ and $B$ whose union and intersection are \"nice\" (e.g., subcomplexes),\n    $$ \\chi(A \\cup B) = \\chi(A) + \\chi(B) - \\chi(A \\cap B) $$\n3.  **Standard Characteristics**:\n    *   Closed disk $D^2$: $\\chi(D^2) = 1$ (contractible).\n    *   Circle $S^1$: $\\chi(S^1) = 0$.\n    *   Cylinder (Annulus) $S^1 \\times [0,1]$: $\\chi = 0$ (homotopy equivalent to $S^1$).\n\n### 2. Base Case: The Sphere ($g=0$)\n\nA sphere with $g=0$ handles is simply the 2-sphere, $S^2$. We can compute its Euler characteristic using a minimal triangulation, such as the boundary of a tetrahedron:\n*   Vertices ($V$): 4\n*   Edges ($E$): 6\n*   Faces ($F$): 4\n\n$$ \\chi(S^2) = 4 - 6 + 4 = 2 $$\nSubstituting $g=0$ into the formula $2 - 2g$, we get $2 - 0 = 2$. The formula holds for the base case.\n\n### 3. Inductive Step: Attaching a Handle\n\nWe define \"adding a handle\" to a surface $M$ as the following surgical operation:\n1.  Remove the interiors of two disjoint closed disks, $D_1$ and $D_2$, from $M$.\n2.  Glue a cylinder (handle) $H \\cong S^1 \\times [0,1]$ to the boundaries of the removed disks. We identify one boundary circle of the cylinder with $\\partial D_1$ and the other with $\\partial D_2$.\n\nLet $M_g$ denote a sphere with $g$ handles. We assume $\\chi(M_g) = 2 - 2g$ and show that $\\chi(M_{g+1}) = 2 - 2(g+1)$.\n\n**Step 3a: Removing the disks**\nLet $M'$ be the manifold $M_g$ with the interiors of the two disks removed. We can express $M_g$ as the union of $M'$ and the two disks:\n$$ M_g = M' \\cup (D_1 \\cup D_2) $$\nThe intersection is the boundary of the disks:\n$$ M' \\cap (D_1 \\cup D_2) = \\partial D_1 \\cup \\partial D_2 \\cong S^1 \\sqcup S^1 $$\n\nUsing the inclusion-exclusion principle:\n$$ \\chi(M_g) = \\chi(M') + \\chi(D_1 \\cup D_2) - \\chi(S^1 \\sqcup S^1) $$\nSubstituting known values ($\\chi(D^2)=1, \\chi(S^1)=0$):\n$$ \\chi(M_g) = \\chi(M') + (1 + 1) - (0 + 0) $$\n$$ \\chi(M_g) = \\chi(M') + 2 \\implies \\chi(M') = \\chi(M_g) - 2 $$\n\n**Step 3b: Attaching the Cylinder**\nTo form $M_{g+1}$, we attach the cylinder $H$ to $M'$ along their boundaries.\n$$ M_{g+1} = M' \\cup H $$\nThe intersection is the boundary of the cylinder (which matches the boundary of the holes in $M'$):\n$$ M' \\cap H = \\partial H \\cong S^1 \\sqcup S^1 $$\n\nAgain using inclusion-exclusion:\n$$ \\chi(M_{g+1}) = \\chi(M') + \\chi(H) - \\chi(M' \\cap H) $$\nSubstituting values ($\\chi(H)=0$ for a cylinder, $\\chi(S^1 \\sqcup S^1)=0$):\n$$ \\chi(M_{g+1}) = \\chi(M') + 0 - 0 = \\chi(M') $$\n\n**Step 3c: Combining results**\nFrom Step 3a, we know $\\chi(M') = \\chi(M_g) - 2$. Therefore:\n$$ \\chi(M_{g+1}) = \\chi(M_g) - 2 $$\n\n### 4. Calculation\n\nWe have established the recurrence relation:\n$$ \\chi(M_{g+1}) = \\chi(M_g) - 2 $$\nwith the base case $\\chi(M_0) = 2$.\n\nBy induction:\n*   $g=0: \\chi(M_0) = 2$\n*   $g=1: \\chi(M_1) = 2 - 2 = 0$ (The Torus)\n*   $g=2: \\chi(M_2) = 0 - 2 = -2$\n*   ...\n*   General $g$:\n    $$ \\chi(M_g) = \\chi(M_0) - 2(g) = 2 - 2g $$\n\n### Conclusion\n\nWe have shown through the base case of the sphere and the inductive step of attaching a handle that the Euler characteristic of a sphere with $g$ handles is:\n\n$$ \\chi(M) = 2 - 2g $$",
        "raw_answer": "To prove that the Euler characteristic of a 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles is $\\chi(M) = 2 - 2g$, we will use the properties of the Euler characteristic under the operation of the **connected sum** or, equivalently, the geometric surgery of **attaching a handle**.\n\n### 1. Definitions and Properties\n\nThe Euler characteristic $\\chi(X)$ for a topological space $X$ (specifically a finite CW-complex or triangulable manifold) is an integer invariant. We rely on the following standard properties:\n\n1.  **Triangulation Definition**: For a surface triangulated with $V$ vertices, $E$ edges, and $F$ faces, $\\chi(X) = V - E + F$.\n2.  **Inclusion-Exclusion Principle**: For spaces $A$ and $B$ whose union and intersection are \"nice\" (e.g., subcomplexes),\n    $$ \\chi(A \\cup B) = \\chi(A) + \\chi(B) - \\chi(A \\cap B) $$\n3.  **Standard Characteristics**:\n    *   Closed disk $D^2$: $\\chi(D^2) = 1$ (contractible).\n    *   Circle $S^1$: $\\chi(S^1) = 0$.\n    *   Cylinder (Annulus) $S^1 \\times [0,1]$: $\\chi = 0$ (homotopy equivalent to $S^1$).\n\n### 2. Base Case: The Sphere ($g=0$)\n\nA sphere with $g=0$ handles is simply the 2-sphere, $S^2$. We can compute its Euler characteristic using a minimal triangulation, such as the boundary of a tetrahedron:\n*   Vertices ($V$): 4\n*   Edges ($E$): 6\n*   Faces ($F$): 4\n\n$$ \\chi(S^2) = 4 - 6 + 4 = 2 $$\nSubstituting $g=0$ into the formula $2 - 2g$, we get $2 - 0 = 2$. The formula holds for the base case.\n\n### 3. Inductive Step: Attaching a Handle\n\nWe define \"adding a handle\" to a surface $M$ as the following surgical operation:\n1.  Remove the interiors of two disjoint closed disks, $D_1$ and $D_2$, from $M$.\n2.  Glue a cylinder (handle) $H \\cong S^1 \\times [0,1]$ to the boundaries of the removed disks. We identify one boundary circle of the cylinder with $\\partial D_1$ and the other with $\\partial D_2$.\n\nLet $M_g$ denote a sphere with $g$ handles. We assume $\\chi(M_g) = 2 - 2g$ and show that $\\chi(M_{g+1}) = 2 - 2(g+1)$.\n\n**Step 3a: Removing the disks**\nLet $M'$ be the manifold $M_g$ with the interiors of the two disks removed. We can express $M_g$ as the union of $M'$ and the two disks:\n$$ M_g = M' \\cup (D_1 \\cup D_2) $$\nThe intersection is the boundary of the disks:\n$$ M' \\cap (D_1 \\cup D_2) = \\partial D_1 \\cup \\partial D_2 \\cong S^1 \\sqcup S^1 $$\n\nUsing the inclusion-exclusion principle:\n$$ \\chi(M_g) = \\chi(M') + \\chi(D_1 \\cup D_2) - \\chi(S^1 \\sqcup S^1) $$\nSubstituting known values ($\\chi(D^2)=1, \\chi(S^1)=0$):\n$$ \\chi(M_g) = \\chi(M') + (1 + 1) - (0 + 0) $$\n$$ \\chi(M_g) = \\chi(M') + 2 \\implies \\chi(M') = \\chi(M_g) - 2 $$\n\n**Step 3b: Attaching the Cylinder**\nTo form $M_{g+1}$, we attach the cylinder $H$ to $M'$ along their boundaries.\n$$ M_{g+1} = M' \\cup H $$\nThe intersection is the boundary of the cylinder (which matches the boundary of the holes in $M'$):\n$$ M' \\cap H = \\partial H \\cong S^1 \\sqcup S^1 $$\n\nAgain using inclusion-exclusion:\n$$ \\chi(M_{g+1}) = \\chi(M') + \\chi(H) - \\chi(M' \\cap H) $$\nSubstituting values ($\\chi(H)=0$ for a cylinder, $\\chi(S^1 \\sqcup S^1)=0$):\n$$ \\chi(M_{g+1}) = \\chi(M') + 0 - 0 = \\chi(M') $$\n\n**Step 3c: Combining results**\nFrom Step 3a, we know $\\chi(M') = \\chi(M_g) - 2$. Therefore:\n$$ \\chi(M_{g+1}) = \\chi(M_g) - 2 $$\n\n### 4. Calculation\n\nWe have established the recurrence relation:\n$$ \\chi(M_{g+1}) = \\chi(M_g) - 2 $$\nwith the base case $\\chi(M_0) = 2$.\n\nBy induction:\n*   $g=0: \\chi(M_0) = 2$\n*   $g=1: \\chi(M_1) = 2 - 2 = 0$ (The Torus)\n*   $g=2: \\chi(M_2) = 0 - 2 = -2$\n*   ...\n*   General $g$:\n    $$ \\chi(M_g) = \\chi(M_0) - 2(g) = 2 - 2g $$\n\n### Conclusion\n\nWe have shown through the base case of the sphere and the inductive step of attaching a handle that the Euler characteristic of a sphere with $g$ handles is:\n\n$$ \\chi(M) = 2 - 2g $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.",
    "run_id": "19",
    "outer_attempt": 5,
    "topic_slug": "potential_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in the unit disk $D = \\{x \\in \\mathbb{R}^2 : |x| < 1\\}$ with the boundary condition $u(x) = \\log|x - (1,0)|$ on $\\partial D$, we proceed as follows.\n\n### 1. Analysis of the Boundary Function\n\nLet $x = (x_1, x_2)$. We identify the boundary point $(1,0)$ as a singularity of the boundary function.\nLet $g(x) = \\log|x - (1,0)|$.\nThe boundary of the domain is the unit circle $\\partial D = \\{x \\in \\mathbb{R}^2 : |x| = 1\\}$.\nOn the boundary, the data is $u(\\theta) = \\log|e^{i\\theta} - 1|$ in complex notation, or $u(x) = \\log\\sqrt{(x_1-1)^2 + x_2^2}$.\n\nThis function has a logarithmic singularity at $x = (1,0)$. However, it is integrable over the boundary $\\partial D$. Specifically, $\\int_{-\\pi}^{\\pi} \\big| \\log|e^{i\\theta} - 1| \\big| d\\theta < \\infty$. Because the boundary data is in $L^1(\\partial D)$, there exists a unique harmonic function in $D$ given by the Poisson integral of the boundary data.\n\n### 2. Constructing the Harmonic Extension\n\nWe observe that the boundary function $g(x)$ is the restriction of a function defined on $\\mathbb{R}^2 \\setminus \\{(1,0)\\}$.\nConsider the function defined on the entire plane (except at $(1,0)$):\n$$ v(x) = \\log|x - (1,0)| $$\nWe check if this candidate function $v(x)$ satisfies the Laplace equation in $D$.\n\n**Harmonicity:**\nThe fundamental solution to the Laplace equation in $\\mathbb{R}^2$ is proportional to $\\log|x|$. Specifically, $\\log|x|$ is harmonic everywhere except at $x=0$.\nBy translation, $v(x) = \\log|x - (1,0)|$ is harmonic everywhere except at $x = (1,0)$.\nSince the point $(1,0)$ lies on the boundary $\\partial D$ and not in the interior $D$, the function $v(x)$ is harmonic throughout the domain $D$. That is:\n$$ \\Delta v(x) = 0 \\quad \\text{for all } x \\in D $$\n\n**Boundary Values:**\nWe are given the boundary condition $u(x) = \\log|x - (1,0)|$ for $x \\in \\partial D$.\nBy definition, our candidate function $v(x)$ coincides with this expression for all $x \\in \\mathbb{R}^2 \\setminus \\{(1,0)\\}$.\nTherefore,\n$$ \\lim_{y \\to x, y \\in D} v(y) = \\log|x - (1,0)| $$\nfor all $x \\in \\partial D \\setminus \\{(1,0)\\}$.\n\n### 3. Verification via Complex Analysis\n\nTo ensure this is the unique solution corresponding to the Poisson integral (the standard solution for the Dirichlet problem), we can use complex variable methods.\nLet $z = x_1 + i x_2$. The domain is $|z| < 1$.\nThe boundary condition is $\\operatorname{Re}(U) = \\log|z - 1|$ on $|z|=1$.\nConsider the analytic function $f(z) = \\log(1 - z)$.\nSince $|z| < 1$, the real part of $1-z$ is positive, so we can take the principal branch of the logarithm, which is holomorphic in $D$.\nThe real part of an analytic function is harmonic. Let:\n$$ u(z) = \\operatorname{Re}(\\log(1 - z)) = \\log|1 - z| $$\nNote that $|1 - z| = |z - 1| = |x - (1,0)|$.\nThus, $u(x) = \\log|x - (1,0)|$ is harmonic in $D$.\nIts radial limit as $z \\to e^{i\\theta}$ ($e^{i\\theta} \\neq 1$) is $\\log|1 - e^{i\\theta}|$, which matches the boundary data.\n\nSince the boundary data is in $L^1$, and $u(x) = \\operatorname{Re}(\\log(1-z))$ belongs to the Hardy space $h^1$ (or generally satisfies the condition that it is the Poisson integral of its boundary values), it is the unique solution to the Dirichlet problem.\n\n### 4. Conclusion\n\nThe function $u(x) = \\log|x - (1,0)|$ is harmonic in $D$ and satisfies the prescribed boundary conditions.\n\nThe solution is:\n$$ u(x) = \\log|x - (1,0)| $$\nor in coordinates $x = (x_1, x_2)$:\n$$ u(x_1, x_2) = \\frac{1}{2} \\ln\\left((x_1 - 1)^2 + x_2^2\\right) $$",
        "raw_answer": "To find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in the unit disk $D = \\{x \\in \\mathbb{R}^2 : |x| < 1\\}$ with the boundary condition $u(x) = \\log|x - (1,0)|$ on $\\partial D$, we proceed as follows.\n\n### 1. Analysis of the Boundary Function\n\nLet $x = (x_1, x_2)$. We identify the boundary point $(1,0)$ as a singularity of the boundary function.\nLet $g(x) = \\log|x - (1,0)|$.\nThe boundary of the domain is the unit circle $\\partial D = \\{x \\in \\mathbb{R}^2 : |x| = 1\\}$.\nOn the boundary, the data is $u(\\theta) = \\log|e^{i\\theta} - 1|$ in complex notation, or $u(x) = \\log\\sqrt{(x_1-1)^2 + x_2^2}$.\n\nThis function has a logarithmic singularity at $x = (1,0)$. However, it is integrable over the boundary $\\partial D$. Specifically, $\\int_{-\\pi}^{\\pi} \\big| \\log|e^{i\\theta} - 1| \\big| d\\theta < \\infty$. Because the boundary data is in $L^1(\\partial D)$, there exists a unique harmonic function in $D$ given by the Poisson integral of the boundary data.\n\n### 2. Constructing the Harmonic Extension\n\nWe observe that the boundary function $g(x)$ is the restriction of a function defined on $\\mathbb{R}^2 \\setminus \\{(1,0)\\}$.\nConsider the function defined on the entire plane (except at $(1,0)$):\n$$ v(x) = \\log|x - (1,0)| $$\nWe check if this candidate function $v(x)$ satisfies the Laplace equation in $D$.\n\n**Harmonicity:**\nThe fundamental solution to the Laplace equation in $\\mathbb{R}^2$ is proportional to $\\log|x|$. Specifically, $\\log|x|$ is harmonic everywhere except at $x=0$.\nBy translation, $v(x) = \\log|x - (1,0)|$ is harmonic everywhere except at $x = (1,0)$.\nSince the point $(1,0)$ lies on the boundary $\\partial D$ and not in the interior $D$, the function $v(x)$ is harmonic throughout the domain $D$. That is:\n$$ \\Delta v(x) = 0 \\quad \\text{for all } x \\in D $$\n\n**Boundary Values:**\nWe are given the boundary condition $u(x) = \\log|x - (1,0)|$ for $x \\in \\partial D$.\nBy definition, our candidate function $v(x)$ coincides with this expression for all $x \\in \\mathbb{R}^2 \\setminus \\{(1,0)\\}$.\nTherefore,\n$$ \\lim_{y \\to x, y \\in D} v(y) = \\log|x - (1,0)| $$\nfor all $x \\in \\partial D \\setminus \\{(1,0)\\}$.\n\n### 3. Verification via Complex Analysis\n\nTo ensure this is the unique solution corresponding to the Poisson integral (the standard solution for the Dirichlet problem), we can use complex variable methods.\nLet $z = x_1 + i x_2$. The domain is $|z| < 1$.\nThe boundary condition is $\\operatorname{Re}(U) = \\log|z - 1|$ on $|z|=1$.\nConsider the analytic function $f(z) = \\log(1 - z)$.\nSince $|z| < 1$, the real part of $1-z$ is positive, so we can take the principal branch of the logarithm, which is holomorphic in $D$.\nThe real part of an analytic function is harmonic. Let:\n$$ u(z) = \\operatorname{Re}(\\log(1 - z)) = \\log|1 - z| $$\nNote that $|1 - z| = |z - 1| = |x - (1,0)|$.\nThus, $u(x) = \\log|x - (1,0)|$ is harmonic in $D$.\nIts radial limit as $z \\to e^{i\\theta}$ ($e^{i\\theta} \\neq 1$) is $\\log|1 - e^{i\\theta}|$, which matches the boundary data.\n\nSince the boundary data is in $L^1$, and $u(x) = \\operatorname{Re}(\\log(1-z))$ belongs to the Hardy space $h^1$ (or generally satisfies the condition that it is the Poisson integral of its boundary values), it is the unique solution to the Dirichlet problem.\n\n### 4. Conclusion\n\nThe function $u(x) = \\log|x - (1,0)|$ is harmonic in $D$ and satisfies the prescribed boundary conditions.\n\nThe solution is:\n$$ u(x) = \\log|x - (1,0)| $$\nor in coordinates $x = (x_1, x_2)$:\n$$ u(x_1, x_2) = \\frac{1}{2} \\ln\\left((x_1 - 1)^2 + x_2^2\\right) $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  }
]