[
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $P(x)$ be the predicate \"$x$ is a prime number\" and $Q(x, y)$ be the predicate \"$y$ is the smallest prime greater than $x$.\" For all natural numbers $n$, consider the statement: \"For every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\" Formalize this statement using the given predicates $P(x)$ and $Q(x, y)$, and determine whether it is true or false. If true, provide a proof; if false, provide a counterexample.",
    "run_id": "1",
    "outer_attempt": 1,
    "topic_slug": "mathematical_logic_and_foundations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the problem, we will first formalize the statement using the provided predicates and then determine its truth value by analyzing the properties of natural numbers and prime numbers.\n\n### 1. Formalization of the Statement\n\nWe are given the following:\n*   **Domain**: The set of natural numbers, denoted as $\\mathbb{N}$. Standard definitions of $\\mathbb{N}$ are either $\\{0, 1, 2, \\dots\\}$ or $\\{1, 2, 3, \\dots\\}$.\n*   **Predicate** $P(x)$: \"$x$ is a prime number.\"\n*   **Predicate** $Q(x, y)$: \"$y$ is the smallest prime greater than $x$.\"\n*   **Statement**: \"For every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\"\n\nWe need to formalize the existence of a prime strictly between $n$ and $2n$. Note that stating \"there exists a prime $p$ such that $n < p < 2n$\" is logically equivalent to stating \"the smallest prime greater than $n$ is strictly less than $2n$.\"\n\n**Reasoning for equivalence:**\n1.  **Forward:** If there exists a prime $p$ such that $n < p < 2n$, let $q$ be the smallest prime greater than $n$. By definition, $n < q \\le p$. Since $p < 2n$, it follows that $n < q < 2n$. Thus, the smallest prime greater than $n$ is strictly less than $2n$.\n2.  **Reverse:** If $y$ is the smallest prime greater than $n$ (i.e., $Q(n, y)$ is true) and $y < 2n$, then $y$ is a prime satisfying $n < y < 2n$.\n\nTherefore, we can formalize the statement compactly using $Q(n, y)$ to represent the prime conditions:\n\n$$ \\forall n \\in \\mathbb{N}, \\exists y \\in \\mathbb{N}, (Q(n, y) \\land y < 2n) $$\n\nAlternatively, using only the basic predicate $P(x)$ inside the quantifier structure explicitly mentioned in the text:\n$$ \\forall n \\in \\mathbb{N}, \\exists p \\in \\mathbb{N}, (P(p) \\land n < p < 2n) $$\n\nGiven the instruction to use the provided predicates (specifically including $Q$), the first formalization is the most precise utilization of the definitions provided.\n\n### 2. Determination of Truth Value\n\nTo determine if the statement is true or false, we examine the statement for specific natural numbers. The statement claims the property holds for **every** natural number $n$.\n\n**Case Analysis:**\n*   **If $n = 1$:**\n    The inequality becomes $1 < p < 2(1)$, which simplifies to $1 < p < 2$.\n    There are no integers strictly between 1 and 2, and consequently, no prime numbers.\n    The smallest prime greater than 1 is 2. Testing the condition $y < 2n$:\n    $$2 < 2(1) \\implies 2 < 2$$\n    This inequality is false.\n\n*   **If $n = 2$:**\n    The inequality is $2 < p < 4$. The prime $p=3$ satisfies this. (True)\n\n*   **If $n = 3$:**\n    The inequality is $3 < p < 6$. The prime $p=5$ satisfies this. (True)\n\n*   **If $n = 0$ (if included in $\\mathbb{N}$):**\n    The inequality is $0 < p < 0$, which is impossible.\n\nSince the statement must hold for **all** natural numbers, a single counterexample is sufficient to disprove it. The case $n=1$ serves as this counterexample.\n\n**Note on Mathematical Context:**\nFor $n > 1$, the statement is true. This is a famous result in number theory known as **Bertrand's Postulate** (or the Bertrand-Chebyshev Theorem), which states that for any integer $n > 1$, there always exists at least one prime $p$ such that $n < p < 2n$. However, because the question specifies \"For every natural number $n$\" and standard definitions of $\\mathbb{N}$ include $1$, the statement is strictly false as written.\n\n### 3. Conclusion and Proof\n\n**Truth Value:** **False**\n\n**Counterexample:**\nLet $n = 1$. The statement asserts the existence of a prime $p$ such that $1 < p < 2$. Since there are no integers between 1 and 2, there is no such prime. Thus, the condition fails for $n=1$.\n\n**Final Formalized Answer:**\nThe formalized statement is:\n$$ \\forall n \\in \\mathbb{N}, \\exists y \\in \\mathbb{N}, (Q(n, y) \\land y < 2n) $$\nThe statement is **false** because for $n=1$, the smallest prime greater than 1 is 2, and $2$ is not strictly less than $2(1)$.",
        "raw_answer": "To solve the problem, we will first formalize the statement using the provided predicates and then determine its truth value by analyzing the properties of natural numbers and prime numbers.\n\n### 1. Formalization of the Statement\n\nWe are given the following:\n*   **Domain**: The set of natural numbers, denoted as $\\mathbb{N}$. Standard definitions of $\\mathbb{N}$ are either $\\{0, 1, 2, \\dots\\}$ or $\\{1, 2, 3, \\dots\\}$.\n*   **Predicate** $P(x)$: \"$x$ is a prime number.\"\n*   **Predicate** $Q(x, y)$: \"$y$ is the smallest prime greater than $x$.\"\n*   **Statement**: \"For every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\"\n\nWe need to formalize the existence of a prime strictly between $n$ and $2n$. Note that stating \"there exists a prime $p$ such that $n < p < 2n$\" is logically equivalent to stating \"the smallest prime greater than $n$ is strictly less than $2n$.\"\n\n**Reasoning for equivalence:**\n1.  **Forward:** If there exists a prime $p$ such that $n < p < 2n$, let $q$ be the smallest prime greater than $n$. By definition, $n < q \\le p$. Since $p < 2n$, it follows that $n < q < 2n$. Thus, the smallest prime greater than $n$ is strictly less than $2n$.\n2.  **Reverse:** If $y$ is the smallest prime greater than $n$ (i.e., $Q(n, y)$ is true) and $y < 2n$, then $y$ is a prime satisfying $n < y < 2n$.\n\nTherefore, we can formalize the statement compactly using $Q(n, y)$ to represent the prime conditions:\n\n$$ \\forall n \\in \\mathbb{N}, \\exists y \\in \\mathbb{N}, (Q(n, y) \\land y < 2n) $$\n\nAlternatively, using only the basic predicate $P(x)$ inside the quantifier structure explicitly mentioned in the text:\n$$ \\forall n \\in \\mathbb{N}, \\exists p \\in \\mathbb{N}, (P(p) \\land n < p < 2n) $$\n\nGiven the instruction to use the provided predicates (specifically including $Q$), the first formalization is the most precise utilization of the definitions provided.\n\n### 2. Determination of Truth Value\n\nTo determine if the statement is true or false, we examine the statement for specific natural numbers. The statement claims the property holds for **every** natural number $n$.\n\n**Case Analysis:**\n*   **If $n = 1$:**\n    The inequality becomes $1 < p < 2(1)$, which simplifies to $1 < p < 2$.\n    There are no integers strictly between 1 and 2, and consequently, no prime numbers.\n    The smallest prime greater than 1 is 2. Testing the condition $y < 2n$:\n    $$2 < 2(1) \\implies 2 < 2$$\n    This inequality is false.\n\n*   **If $n = 2$:**\n    The inequality is $2 < p < 4$. The prime $p=3$ satisfies this. (True)\n\n*   **If $n = 3$:**\n    The inequality is $3 < p < 6$. The prime $p=5$ satisfies this. (True)\n\n*   **If $n = 0$ (if included in $\\mathbb{N}$):**\n    The inequality is $0 < p < 0$, which is impossible.\n\nSince the statement must hold for **all** natural numbers, a single counterexample is sufficient to disprove it. The case $n=1$ serves as this counterexample.\n\n**Note on Mathematical Context:**\nFor $n > 1$, the statement is true. This is a famous result in number theory known as **Bertrand's Postulate** (or the Bertrand-Chebyshev Theorem), which states that for any integer $n > 1$, there always exists at least one prime $p$ such that $n < p < 2n$. However, because the question specifies \"For every natural number $n$\" and standard definitions of $\\mathbb{N}$ include $1$, the statement is strictly false as written.\n\n### 3. Conclusion and Proof\n\n**Truth Value:** **False**\n\n**Counterexample:**\nLet $n = 1$. The statement asserts the existence of a prime $p$ such that $1 < p < 2$. Since there are no integers between 1 and 2, there is no such prime. Thus, the condition fails for $n=1$.\n\n**Final Formalized Answer:**\nThe formalized statement is:\n$$ \\forall n \\in \\mathbb{N}, \\exists y \\in \\mathbb{N}, (Q(n, y) \\land y < 2n) $$\nThe statement is **false** because for $n=1$, the smallest prime greater than 1 is 2, and $2$ is not strictly less than $2(1)$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Combinatorics, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the domain\nThe domain specified is Combinatorics, which involves the study of counting, arranging, and optimizing objects in various ways. It encompasses topics such as permutations, combinations, graph theory, and more.\n\n## Step 3: Generate a problem\nTo create a challenging problem, let's consider a topic within Combinatorics that is both interesting and requires substantial reasoning. A potential topic is graph theory, specifically focusing on graph coloring or connectivity.\n\n## Step 4: Formulate the problem\nLet's formulate a problem: \"Prove that in any simple graph with $n$ vertices, if the graph is connected and has no cycles (i.e., it's a tree), then it has exactly $n-1$ edges.\"\n\n## Step 5: Verify the problem against the quality rubric\n- **Well-Posedness and Completeness**: The problem is self-contained, defines the necessary terms (simple graph, connected, no cycles, tree), and asks for a proof.\n- **Clarity**: The terms used are standard in graph theory, and the task is clear.\n- **Non-Triviality**: The problem requires understanding of graph theory and a proof involving induction or another suitable method, making it non-trivial.\n- **Solvability and Verification**: The statement is a known fact in graph theory and can be proven using established methods.\n\n## Step 6: Provide the solution\nTo solve this, we can use induction on $n$. For $n=1$, a tree has 0 edges, and $1-1=0$, so the statement holds. For $n>1$, assume the statement is true for all trees with fewer than $n$ vertices. A tree with $n$ vertices has at least one leaf (a vertex of degree 1); removing this leaf and its edge gives a tree with $n-1$ vertices. By the induction hypothesis, this smaller tree has $(n-1)-1 = n-2$ edges. Adding back the removed edge gives $n-2 + 1 = n-1$ edges, proving the statement for $n$.\n\n## Step 7: Format the output\nLet's format the problem and solution according to the required structure.\n\n\nLet $G$ be a simple graph with $n$ vertices. Prove that if $G$ is a tree (i.e., it is connected and has no cycles), then it has exactly $n-1$ edges.",
    "run_id": "2",
    "outer_attempt": 1,
    "topic_slug": "combinatorics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that a simple graph $G$ with $n$ vertices that is a tree (connected and acyclic) has exactly $n-1$ edges, we will use the principle of mathematical induction on the number of vertices $n$.\n\n### Proof\n\nLet $P(n)$ be the statement: \"Any tree with $n$ vertices has exactly $n-1$ edges.\"\n\n**1. Base Case ($n=1$)**\nConsider a graph $G$ with $n=1$ vertex. Since $G$ is a simple graph, it contains no self-loops. Since there is only one vertex, there can be no edges connecting distinct vertices. Therefore, the number of edges is 0.\nThe formula gives $n-1 = 1-1 = 0$.\nThus, $P(1)$ is true.\n\n**2. Inductive Hypothesis**\nAssume that $P(k)$ is true for some integer $k \\geq 1$. That is, assume any tree with $k$ vertices has exactly $k-1$ edges.\n\n**3. Inductive Step**\nWe must show that $P(k+1)$ is true. Let $T$ be an arbitrary tree with $n = k+1$ vertices. We need to show that $T$ has $(k+1)-1 = k$ edges.\n\nTo proceed, we utilize the following lemma:\n\n**Lemma:** Every tree with at least 2 vertices has at least two vertices of degree 1 (leaves).\n\n*Proof of Lemma:*\nConsider a simple path of maximal length in $T$. Let this path be $v_1, v_2, \\dots, v_m$. Since the graph is finite, such a path exists.\nConsider the endpoint $v_1$.\n- $v_1$ is connected to $v_2$.\n- If $v_1$ were connected to any other vertex $v_j$ in the path (where $j > 2$), the sequence $v_1, v_2, \\dots, v_j, v_1$ would form a cycle. This contradicts the assumption that $T$ is acyclic.\n- If $v_1$ were connected to any vertex $u$ not in the path, we could extend the path to $u, v_1, \\dots, v_m$, contradicting the assumption that the path is maximal.\nTherefore, $v_1$ has no neighbors other than $v_2$, so $\\deg(v_1) = 1$. The same argument applies to the other endpoint $v_m$. Thus, $T$ has at least two leaves.\n\n**Continuing the Inductive Step:**\nSince $n = k+1 \\geq 2$, by the Lemma, $T$ contains a leaf vertex $v$ with degree 1. Let $e$ be the unique edge incident to $v$, connecting $v$ to some vertex $u$.\n\nNow, consider the graph $T'$ obtained by removing the vertex $v$ and the edge $e$ from $T$.\n$$ V(T') = V(T) \\setminus \\{v\\} $$\n$$ E(T') = E(T) \\setminus \\{e\\} $$\n\nWe must verify that $T'$ is a tree:\n1.  **$T'$ has $k$ vertices:** Since $T$ had $k+1$ vertices, removing one leaves $k$.\n2.  **$T'$ is acyclic:** $T'$ is a subgraph of $T$. Since $T$ has no cycles, $T'$ cannot have cycles.\n3.  **$T'$ is connected:** Let $x$ and $y$ be any two distinct vertices in $T'$. Since $T$ is a tree, there is a unique path between $x$ and $y$ in $T$. Because $v$ is a leaf (degree 1), $v$ cannot be an intermediate vertex on the path between any two other vertices $x$ and $y$. Therefore, the path connecting $x$ and $y$ in $T$ consists entirely of edges and vertices present in $T'$. Thus, $x$ and $y$ are connected in $T'$.\n\nSince $T'$ is a connected acyclic graph with $k$ vertices, $T'$ is a tree. By the **Inductive Hypothesis**, $T'$ has exactly $k-1$ edges.\n\nThe number of edges in the original tree $T$ is the number of edges in $T'$ plus the removed edge $e$.\n$$ |E(T)| = |E(T')| + 1 = (k-1) + 1 = k $$\n\nThis matches the requirement $n-1 = (k+1)-1 = k$. Thus, $P(k+1)$ is true.\n\n**Conclusion**\nBy the principle of mathematical induction, for every integer $n \\geq 1$, a tree with $n$ vertices has exactly $n-1$ edges.",
        "raw_answer": "To prove that a simple graph $G$ with $n$ vertices that is a tree (connected and acyclic) has exactly $n-1$ edges, we will use the principle of mathematical induction on the number of vertices $n$.\n\n### Proof\n\nLet $P(n)$ be the statement: \"Any tree with $n$ vertices has exactly $n-1$ edges.\"\n\n**1. Base Case ($n=1$)**\nConsider a graph $G$ with $n=1$ vertex. Since $G$ is a simple graph, it contains no self-loops. Since there is only one vertex, there can be no edges connecting distinct vertices. Therefore, the number of edges is 0.\nThe formula gives $n-1 = 1-1 = 0$.\nThus, $P(1)$ is true.\n\n**2. Inductive Hypothesis**\nAssume that $P(k)$ is true for some integer $k \\geq 1$. That is, assume any tree with $k$ vertices has exactly $k-1$ edges.\n\n**3. Inductive Step**\nWe must show that $P(k+1)$ is true. Let $T$ be an arbitrary tree with $n = k+1$ vertices. We need to show that $T$ has $(k+1)-1 = k$ edges.\n\nTo proceed, we utilize the following lemma:\n\n**Lemma:** Every tree with at least 2 vertices has at least two vertices of degree 1 (leaves).\n\n*Proof of Lemma:*\nConsider a simple path of maximal length in $T$. Let this path be $v_1, v_2, \\dots, v_m$. Since the graph is finite, such a path exists.\nConsider the endpoint $v_1$.\n- $v_1$ is connected to $v_2$.\n- If $v_1$ were connected to any other vertex $v_j$ in the path (where $j > 2$), the sequence $v_1, v_2, \\dots, v_j, v_1$ would form a cycle. This contradicts the assumption that $T$ is acyclic.\n- If $v_1$ were connected to any vertex $u$ not in the path, we could extend the path to $u, v_1, \\dots, v_m$, contradicting the assumption that the path is maximal.\nTherefore, $v_1$ has no neighbors other than $v_2$, so $\\deg(v_1) = 1$. The same argument applies to the other endpoint $v_m$. Thus, $T$ has at least two leaves.\n\n**Continuing the Inductive Step:**\nSince $n = k+1 \\geq 2$, by the Lemma, $T$ contains a leaf vertex $v$ with degree 1. Let $e$ be the unique edge incident to $v$, connecting $v$ to some vertex $u$.\n\nNow, consider the graph $T'$ obtained by removing the vertex $v$ and the edge $e$ from $T$.\n$$ V(T') = V(T) \\setminus \\{v\\} $$\n$$ E(T') = E(T) \\setminus \\{e\\} $$\n\nWe must verify that $T'$ is a tree:\n1.  **$T'$ has $k$ vertices:** Since $T$ had $k+1$ vertices, removing one leaves $k$.\n2.  **$T'$ is acyclic:** $T'$ is a subgraph of $T$. Since $T$ has no cycles, $T'$ cannot have cycles.\n3.  **$T'$ is connected:** Let $x$ and $y$ be any two distinct vertices in $T'$. Since $T$ is a tree, there is a unique path between $x$ and $y$ in $T$. Because $v$ is a leaf (degree 1), $v$ cannot be an intermediate vertex on the path between any two other vertices $x$ and $y$. Therefore, the path connecting $x$ and $y$ in $T$ consists entirely of edges and vertices present in $T'$. Thus, $x$ and $y$ are connected in $T'$.\n\nSince $T'$ is a connected acyclic graph with $k$ vertices, $T'$ is a tree. By the **Inductive Hypothesis**, $T'$ has exactly $k-1$ edges.\n\nThe number of edges in the original tree $T$ is the number of edges in $T'$ plus the removed edge $e$.\n$$ |E(T)| = |E(T')| + 1 = (k-1) + 1 = k $$\n\nThis matches the requirement $n-1 = (k+1)-1 = k$. Thus, $P(k+1)$ is true.\n\n**Conclusion**\nBy the principle of mathematical induction, for every integer $n \\geq 1$, a tree with $n$ vertices has exactly $n-1$ edges.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the requirements for the problem.\nThe task is to generate a challenging but solvable mathematics problem in the domain of number theory, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within number theory.\nNumber theory encompasses various topics such as divisibility, prime numbers, congruences, and Diophantine equations. A challenging problem could involve proving a property related to prime numbers or solving a specific type of Diophantine equation.\n\n## Step 3: Formulate a problem that meets the criteria.\nLet's consider a problem involving the sum of divisors of a number and its relation to perfect numbers. A perfect number is a positive integer that is equal to the sum of its proper divisors, excluding the number itself.\n\n## Step 4: Specify the problem.\nConsider the following problem: \"Prove that if $n$ is an even perfect number, then $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.\"\n\n## Step 5: Provide the solution to the problem.\nTo solve this, we need to understand the definition of an even perfect number and its relation to Mersenne primes.\n\n## Step 6: Recall the definition and properties of even perfect numbers.\nAn even perfect number $n$ can be written as $n = 2^{k-1}(2^k - 1)$, where $2^k - 1$ is prime. This is known as the Euclid-Euler theorem.\n\n## Step 7: State the Euclid-Euler theorem.\nThe Euclid-Euler theorem states that every even perfect number is of the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime (i.e., $2^p - 1$ is prime).\n\n## Step 8: Provide the proof or reasoning for the given statement.\nThe proof involves two main parts: (1) showing that any number of the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is prime, is perfect, and (2) showing that every even perfect number is of this form.\n\n## Step 9: Outline the proof that $2^{p-1}(2^p - 1)$ is perfect when $2^p - 1$ is prime.\nLet $n = 2^{p-1}(2^p - 1)$. The sum of divisors of $n$, $\\sigma(n)$, is given by $\\sigma(n) = \\sigma(2^{p-1})\\sigma(2^p - 1)$. Since $2^p - 1$ is prime, $\\sigma(2^p - 1) = 2^p$. Also, $\\sigma(2^{p-1}) = 1 + 2 + 2^2 + \\cdots + 2^{p-1} = 2^p - 1$. Thus, $\\sigma(n) = (2^p - 1) \\cdot 2^p = 2 \\cdot 2^{p-1}(2^p - 1) = 2n$, proving $n$ is perfect.\n\n## Step 10: Outline the proof that every even perfect number is of the form $2^{p-1}(2^p - 1)$.\nLet $n$ be an even perfect number. Then $n = 2^k \\cdot m$, where $m$ is odd. Since $n$ is perfect, $\\sigma(n) = 2n$. Using the multiplicative property of $\\sigma$, we have $\\sigma(n) = \\sigma(2^k)\\sigma(m) = (2^{k+1} - 1)\\sigma(m)$. Thus, $(2^{k+1} - 1)\\sigma(m) = 2^{k+1}m$. This implies $2^{k+1} - 1$ divides $m$, so $m = (2^{k+1} - 1)d$ for some $d$. Substituting back gives $\\sigma(m) = 2^{k+1}d$. For $d = 1$, $m = 2^{k+1} - 1$ is prime, and $\\sigma(m) = m + 1 = 2^{k+1}$, which matches our requirement. For $d > 1$, it leads to a contradiction because $\\sigma(m) \\geq m + d > 2d$, unless $d = 1$ and $m$ is prime.\n\n## Step 11: Conclude the solution.\nThe given statement is a direct consequence of the Euclid-Euler theorem, which characterizes even perfect numbers.\n\nThe final answer is: \n\nProve that if $n$ is an even perfect number, then $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.",
    "run_id": "3",
    "outer_attempt": 1,
    "topic_slug": "number_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the rigorous proof of the statement.\n\n### **Theorem**\nIf $n$ is an even perfect number, then $n$ takes the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.\n\n---\n\n### **Proof**\n\n**1. Definitions and Setup**\nLet $n$ be an even perfect number.\nSince $n$ is even, we can write $n$ in the form:\n$$n = 2^k \\cdot m$$\nwhere $k \\geq 1$ is an integer and $m$ is an odd positive integer.\n\nSince $n$ is a perfect number, the sum of its positive divisors, denoted by $\\sigma(n)$, satisfies:\n$$\\sigma(n) = 2n$$\n\n**2. Multiplicative Property of $\\sigma$**\nThe function $\\sigma$ is multiplicative, meaning $\\sigma(ab) = \\sigma(a)\\sigma(b)$ if $\\gcd(a, b) = 1$.\nSince $m$ is odd, $\\gcd(2^k, m) = 1$. Therefore:\n$$\\sigma(n) = \\sigma(2^k \\cdot m) = \\sigma(2^k)\\sigma(m)$$\n\nWe calculate $\\sigma(2^k)$ as the sum of the geometric series $1 + 2 + \\dots + 2^k$:\n$$\\sigma(2^k) = \\frac{2^{k+1} - 1}{2 - 1} = 2^{k+1} - 1$$\n\nSubstituting this back into the perfect number equation $\\sigma(n) = 2n$:\n$$(2^{k+1} - 1)\\sigma(m) = 2(2^k \\cdot m)$$\n$$(2^{k+1} - 1)\\sigma(m) = 2^{k+1}m \\quad (*)$$\n\n**3. Divisibility Analysis**\nFrom equation $(*)$, we see that $2^{k+1} - 1$ divides the product $2^{k+1}m$.\nSince $2^{k+1} - 1$ is an odd number, $\\gcd(2^{k+1} - 1, 2^{k+1}) = 1$.\nBy Euclid's Lemma, $2^{k+1} - 1$ must divide $m$.\n\nThus, there exists an integer $q$ such that:\n$$m = (2^{k+1} - 1)q$$\n\n**4. Analyzing $\\sigma(m)$**\nSubstitute $m = (2^{k+1} - 1)q$ back into equation $(*)$:\n$$(2^{k+1} - 1)\\sigma(m) = 2^{k+1}(2^{k+1} - 1)q$$\nDividing both sides by the non-zero term $(2^{k+1} - 1)$, we obtain:\n$$\\sigma(m) = 2^{k+1}q$$\n\nWe also know that $m = (2^{k+1} - 1)q$. Let us consider the divisors of $m$.\nSince $m$ is a multiple of $q$, both $m$ and $q$ are distinct divisors of $m$. (Note: Since $n$ is even, $k \\geq 1$, which implies $2^{k+1} - 1 \\geq 3$, so $m > q$).\n\nThe sum of the divisors of $m$, $\\sigma(m)$, must include at least $m$ and $q$. Therefore:\n$$\\sigma(m) \\geq m + q$$\n\nSubstituting the expressions in terms of $q$:\n$$\\sigma(m) \\geq (2^{k+1} - 1)q + q$$\n$$\\sigma(m) \\geq 2^{k+1}q - q + q$$\n$$\\sigma(m) \\geq 2^{k+1}q$$\n\n**5. Forcing Primality**\nWe have established two facts:\n1. $\\sigma(m) = 2^{k+1}q$ (from the equation)\n2. $\\sigma(m) \\geq m + q = 2^{k+1}q$ (from the property of divisors)\n\nThe equality $\\sigma(m) = m + q$ holds if and only if $m$ and $q$ are the **only** positive divisors of $m$.\nThis implies two conditions:\n1. The divisor $q$ must be $1$ (since $1$ is always a divisor of any integer).\n2. The number $m$ must be prime (since its only divisors are $1$ and itself).\n\nThus, we determine:\n$$q = 1$$\n$$m = (2^{k+1} - 1)(1) = 2^{k+1} - 1$$\nAnd $m$ is a prime number.\n\n**6. Conclusion**\nWe have shown that $m = 2^{k+1} - 1$ is prime. For a number of the form $2^x - 1$ to be prime, the exponent $x$ must be prime. Let $p = k+1$, where $p$ is prime.\nThen:\n$$m = 2^p - 1$$\nis a Mersenne prime.\n\nSubstituting $k = p - 1$ and $m = 2^p - 1$ back into the expression for $n$:\n$$n = 2^{p-1}(2^p - 1)$$\n\n### **Final Answer**\nWe have proven that any even perfect number $n$ must be of the form $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.",
        "raw_answer": "Here is the rigorous proof of the statement.\n\n### **Theorem**\nIf $n$ is an even perfect number, then $n$ takes the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.\n\n---\n\n### **Proof**\n\n**1. Definitions and Setup**\nLet $n$ be an even perfect number.\nSince $n$ is even, we can write $n$ in the form:\n$$n = 2^k \\cdot m$$\nwhere $k \\geq 1$ is an integer and $m$ is an odd positive integer.\n\nSince $n$ is a perfect number, the sum of its positive divisors, denoted by $\\sigma(n)$, satisfies:\n$$\\sigma(n) = 2n$$\n\n**2. Multiplicative Property of $\\sigma$**\nThe function $\\sigma$ is multiplicative, meaning $\\sigma(ab) = \\sigma(a)\\sigma(b)$ if $\\gcd(a, b) = 1$.\nSince $m$ is odd, $\\gcd(2^k, m) = 1$. Therefore:\n$$\\sigma(n) = \\sigma(2^k \\cdot m) = \\sigma(2^k)\\sigma(m)$$\n\nWe calculate $\\sigma(2^k)$ as the sum of the geometric series $1 + 2 + \\dots + 2^k$:\n$$\\sigma(2^k) = \\frac{2^{k+1} - 1}{2 - 1} = 2^{k+1} - 1$$\n\nSubstituting this back into the perfect number equation $\\sigma(n) = 2n$:\n$$(2^{k+1} - 1)\\sigma(m) = 2(2^k \\cdot m)$$\n$$(2^{k+1} - 1)\\sigma(m) = 2^{k+1}m \\quad (*)$$\n\n**3. Divisibility Analysis**\nFrom equation $(*)$, we see that $2^{k+1} - 1$ divides the product $2^{k+1}m$.\nSince $2^{k+1} - 1$ is an odd number, $\\gcd(2^{k+1} - 1, 2^{k+1}) = 1$.\nBy Euclid's Lemma, $2^{k+1} - 1$ must divide $m$.\n\nThus, there exists an integer $q$ such that:\n$$m = (2^{k+1} - 1)q$$\n\n**4. Analyzing $\\sigma(m)$**\nSubstitute $m = (2^{k+1} - 1)q$ back into equation $(*)$:\n$$(2^{k+1} - 1)\\sigma(m) = 2^{k+1}(2^{k+1} - 1)q$$\nDividing both sides by the non-zero term $(2^{k+1} - 1)$, we obtain:\n$$\\sigma(m) = 2^{k+1}q$$\n\nWe also know that $m = (2^{k+1} - 1)q$. Let us consider the divisors of $m$.\nSince $m$ is a multiple of $q$, both $m$ and $q$ are distinct divisors of $m$. (Note: Since $n$ is even, $k \\geq 1$, which implies $2^{k+1} - 1 \\geq 3$, so $m > q$).\n\nThe sum of the divisors of $m$, $\\sigma(m)$, must include at least $m$ and $q$. Therefore:\n$$\\sigma(m) \\geq m + q$$\n\nSubstituting the expressions in terms of $q$:\n$$\\sigma(m) \\geq (2^{k+1} - 1)q + q$$\n$$\\sigma(m) \\geq 2^{k+1}q - q + q$$\n$$\\sigma(m) \\geq 2^{k+1}q$$\n\n**5. Forcing Primality**\nWe have established two facts:\n1. $\\sigma(m) = 2^{k+1}q$ (from the equation)\n2. $\\sigma(m) \\geq m + q = 2^{k+1}q$ (from the property of divisors)\n\nThe equality $\\sigma(m) = m + q$ holds if and only if $m$ and $q$ are the **only** positive divisors of $m$.\nThis implies two conditions:\n1. The divisor $q$ must be $1$ (since $1$ is always a divisor of any integer).\n2. The number $m$ must be prime (since its only divisors are $1$ and itself).\n\nThus, we determine:\n$$q = 1$$\n$$m = (2^{k+1} - 1)(1) = 2^{k+1} - 1$$\nAnd $m$ is a prime number.\n\n**6. Conclusion**\nWe have shown that $m = 2^{k+1} - 1$ is prime. For a number of the form $2^x - 1$ to be prime, the exponent $x$ must be prime. Let $p = k+1$, where $p$ is prime.\nThen:\n$$m = 2^p - 1$$\nis a Mersenne prime.\n\nSubstituting $k = p - 1$ and $m = 2^p - 1$ back into the expression for $n$:\n$$n = 2^{p-1}(2^p - 1)$$\n\n### **Final Answer**\nWe have proven that any even perfect number $n$ must be of the form $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of \"Order, lattices, ordered algebraic structures\" along with a complete and verifiable solution.\n\n## Step 2: Identify the key elements of the problem domain\nThe domain involves concepts related to order, lattices, and ordered algebraic structures. This includes partially ordered sets (posets), lattices, Boolean algebras, and other related structures.\n\n## Step 3: Formulate a problem that fits the domain\nTo create a problem, we need to consider what aspects of \"Order, lattices, ordered algebraic structures\" can be explored. A potential problem could involve proving a property about a specific type of lattice or ordered structure.\n\n## Step 4: Generate a specific problem\nLet's consider a problem involving a Boolean algebra, which is a type of lattice. A Boolean algebra is a distributive lattice with the additional property that every element has a complement.\n\n## Step 5: State the problem\n\"Let $B$ be a Boolean algebra. Prove that for any elements $a, b \\in B$, the following identity holds: $a \\vee (a \\wedge b) = a$.\"\n\n## Step 6: Provide a solution to the problem\nTo prove $a \\vee (a \\wedge b) = a$, we can use the properties of a Boolean algebra, specifically the absorption laws.\n\n## Step 7: Write out the solution in detail\nFirst, recall that a Boolean algebra is a distributive lattice with complementation. The absorption laws state that for any $a, b$ in the Boolean algebra, $a \\vee (a \\wedge b) = a$ and $a \\wedge (a \\vee b) = a$. We need to prove the first absorption law.\n\n## Step 8: Apply the properties of a lattice to prove the identity\nBy definition of a lattice, $a \\wedge b \\leq a$ because $a$ is an upper bound of $a$ and $a \\wedge b$, and $a \\wedge b$ is the greatest lower bound of $a$ and $b$. Thus, $a \\vee (a \\wedge b) = a$ because $a \\vee x = a$ whenever $x \\leq a$.\n\n## Step 9: Formalize the solution\nGiven $a, b \\in B$, since $a \\wedge b \\leq a$, we have $a \\vee (a \\wedge b) = a$ due to the property that $x \\leq y$ implies $y \\vee x = y$. Thus, $a \\vee (a \\wedge b) = a$.\n\n## Step 10: Present the problem and solution in the required format\n\nLet $B$ be a Boolean algebra. Prove that for any elements $a, b \\in B$, the following identity holds: $a \\vee (a \\wedge b) = a$.",
    "run_id": "4",
    "outer_attempt": 1,
    "topic_slug": "order_lattices_and_ordered_algebraic_structures",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To provide a rigorous proof, we must first establish the axiomatic framework for a Boolean algebra.\n\n### Definition and Axioms\n\nA Boolean algebra is a set $B$ equipped with two binary operations $\\vee$ (join/disjunction) and $\\wedge$ (meet/conjunction), a unary operation $'$ (complement), and two distinct elements $0$ and $1$, satisfying the following axioms for all $x, y, z \\in B$:\n\n1.  **Commutativity**: \n    $x \\vee y = y \\vee x$ and $x \\wedge y = y \\wedge x$.\n2.  **Associativity**: \n    $(x \\vee y) \\vee z = x \\vee (y \\vee z)$ and $(x \\wedge y) \\wedge z = x \\wedge (y \\wedge z)$.\n3.  **Distributivity**: \n    $x \\wedge (y \\vee z) = (x \\wedge y) \\vee (x \\wedge z)$ and $x \\vee (y \\wedge z) = (x \\vee y) \\wedge (x \\vee z)$.\n4.  **Identity**: \n    $x \\vee 0 = x$ and $x \\wedge 1 = x$.\n5.  **Complementation**: \n    $x \\vee x' = 1$ and $x \\wedge x' = 0$.\n\n### Problem Statement\nProve that for any elements $a, b \\in B$, the absorption identity holds:\n$$ a \\vee (a \\wedge b) = a $$\n\n### Proof\n\nWe proceed by algebraic manipulation using the axioms listed above.\n\n**Step 1: Use the Identity Axiom**\nBy the Identity axiom for meet ($x \\wedge 1 = x$), we can rewrite the term $a$ as:\n$$ a = a \\wedge 1 $$\nSubstituting this into our expression:\n$$ a \\vee (a \\wedge b) = (a \\wedge 1) \\vee (a \\wedge b) $$\n\n**Step 2: Apply Distributivity**\nWe apply the Distributivity axiom ($x \\wedge y \\vee x \\wedge z = x \\wedge (y \\vee z)$) to factor out $a$:\n$$ (a \\wedge 1) \\vee (a \\wedge b) = a \\wedge (1 \\vee b) $$\n\n**Step 3: Establish the Boundedness Property**\nWe need to simplify $(1 \\vee b)$. We claim that for any $x \\in B$, $1 \\vee x = 1$.\n*Proof of Claim:*\n$$ \\begin{aligned} 1 \\vee x &= (x \\vee x') \\vee x & & \\text{(Complementation: } 1 = x \\vee x') \\\\ &= x' \\vee (x \\vee x) & & \\text{(Associativity and Commutativity)} \\end{aligned} $$\nFirst, we prove Idempotence ($x \\vee x = x$):\n$$ \\begin{aligned} x &= x \\vee 0 & & \\text{(Identity)} \\\\ &= x \\vee (x \\wedge x') & & \\text{(Complementation)} \\\\ &= (x \\vee x) \\wedge (x \\vee x') & & \\text{(Distributivity)} \\\\ &= (x \\vee x) \\wedge 1 & & \\text{(Complementation)} \\\\ &= x \\vee x & & \\text{(Identity)} \\end{aligned} $$\nReturning to the boundedness proof with $x \\vee x = x$:\n$$ \\begin{aligned} 1 \\vee x &= x' \\vee x \\\\ &= 1 & & \\text{(Complementation)} \\end{aligned} $$\nThus, $1 \\vee b = 1$.\n\n**Step 4: Final Simplification**\nSubstitute $1 \\vee b = 1$ back into the expression from Step 2:\n$$ a \\wedge (1 \\vee b) = a \\wedge 1 $$\nBy the Identity axiom ($a \\wedge 1 = a$):\n$$ a \\wedge 1 = a $$\n\n### Conclusion\nBy the sequence of logical steps derived strictly from the axioms of a Boolean algebra, we have shown:\n$$ a \\vee (a \\wedge b) = a $$",
        "raw_answer": "To provide a rigorous proof, we must first establish the axiomatic framework for a Boolean algebra.\n\n### Definition and Axioms\n\nA Boolean algebra is a set $B$ equipped with two binary operations $\\vee$ (join/disjunction) and $\\wedge$ (meet/conjunction), a unary operation $'$ (complement), and two distinct elements $0$ and $1$, satisfying the following axioms for all $x, y, z \\in B$:\n\n1.  **Commutativity**: \n    $x \\vee y = y \\vee x$ and $x \\wedge y = y \\wedge x$.\n2.  **Associativity**: \n    $(x \\vee y) \\vee z = x \\vee (y \\vee z)$ and $(x \\wedge y) \\wedge z = x \\wedge (y \\wedge z)$.\n3.  **Distributivity**: \n    $x \\wedge (y \\vee z) = (x \\wedge y) \\vee (x \\wedge z)$ and $x \\vee (y \\wedge z) = (x \\vee y) \\wedge (x \\vee z)$.\n4.  **Identity**: \n    $x \\vee 0 = x$ and $x \\wedge 1 = x$.\n5.  **Complementation**: \n    $x \\vee x' = 1$ and $x \\wedge x' = 0$.\n\n### Problem Statement\nProve that for any elements $a, b \\in B$, the absorption identity holds:\n$$ a \\vee (a \\wedge b) = a $$\n\n### Proof\n\nWe proceed by algebraic manipulation using the axioms listed above.\n\n**Step 1: Use the Identity Axiom**\nBy the Identity axiom for meet ($x \\wedge 1 = x$), we can rewrite the term $a$ as:\n$$ a = a \\wedge 1 $$\nSubstituting this into our expression:\n$$ a \\vee (a \\wedge b) = (a \\wedge 1) \\vee (a \\wedge b) $$\n\n**Step 2: Apply Distributivity**\nWe apply the Distributivity axiom ($x \\wedge y \\vee x \\wedge z = x \\wedge (y \\vee z)$) to factor out $a$:\n$$ (a \\wedge 1) \\vee (a \\wedge b) = a \\wedge (1 \\vee b) $$\n\n**Step 3: Establish the Boundedness Property**\nWe need to simplify $(1 \\vee b)$. We claim that for any $x \\in B$, $1 \\vee x = 1$.\n*Proof of Claim:*\n$$ \\begin{aligned} 1 \\vee x &= (x \\vee x') \\vee x & & \\text{(Complementation: } 1 = x \\vee x') \\\\ &= x' \\vee (x \\vee x) & & \\text{(Associativity and Commutativity)} \\end{aligned} $$\nFirst, we prove Idempotence ($x \\vee x = x$):\n$$ \\begin{aligned} x &= x \\vee 0 & & \\text{(Identity)} \\\\ &= x \\vee (x \\wedge x') & & \\text{(Complementation)} \\\\ &= (x \\vee x) \\wedge (x \\vee x') & & \\text{(Distributivity)} \\\\ &= (x \\vee x) \\wedge 1 & & \\text{(Complementation)} \\\\ &= x \\vee x & & \\text{(Identity)} \\end{aligned} $$\nReturning to the boundedness proof with $x \\vee x = x$:\n$$ \\begin{aligned} 1 \\vee x &= x' \\vee x \\\\ &= 1 & & \\text{(Complementation)} \\end{aligned} $$\nThus, $1 \\vee b = 1$.\n\n**Step 4: Final Simplification**\nSubstitute $1 \\vee b = 1$ back into the expression from Step 2:\n$$ a \\wedge (1 \\vee b) = a \\wedge 1 $$\nBy the Identity axiom ($a \\wedge 1 = a$):\n$$ a \\wedge 1 = a $$\n\n### Conclusion\nBy the sequence of logical steps derived strictly from the axioms of a Boolean algebra, we have shown:\n$$ a \\vee (a \\wedge b) = a $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of general algebraic systems, along with a complete and verifiable solution.\n\n## Step 2: Identify the domain\nThe domain is general algebraic systems, which includes topics like groups, rings, fields, and other algebraic structures.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving a specific algebraic structure. A challenging problem could involve proving a property about a certain type of algebraic system.\n\n## Step 4: Create a specific problem\nConsider the following problem: \"Let $G$ be a finite group and $H$ be a subgroup of $G$. Suppose that $|G| = 2|H|$. Prove that $H$ is a normal subgroup of $G$.\"\n\n## Step 5: Verify the problem meets the quality rubric\n- **Well-Posedness and Completeness**: The problem is fully specified with $G$ being a finite group and $H$ a subgroup of $G$, and the condition $|G| = 2|H|$ is given.\n- **Clarity**: The terms are standard in group theory, and the task is clear.\n- **Non-Triviality**: The problem requires understanding of group theory and the concept of normal subgroups, making it non-trivial.\n- **Solvability and Verification**: The problem is solvable using established methods in group theory.\n\n## Step 6: Provide the solution\nTo prove that $H$ is a normal subgroup of $G$, we need to show that for any $g \\in G$ and $h \\in H$, $g^{-1}hg \\in H$.\n\n## Step 7: Break down the solution\nFirst, note that since $|G| = 2|H|$, $H$ has index 2 in $G$. This implies there are exactly two cosets of $H$ in $G$: $H$ itself and $G \\setminus H$.\n\n## Step 8: Analyze cosets\nFor any $g \\in G$, if $g \\in H$, then $gH = H$ and $Hg = H$, so $gH = Hg$. If $g \\notin H$, then $gH = G \\setminus H$ because there are only two cosets and $gH$ cannot be $H$. Similarly, $Hg = G \\setminus H$, so again $gH = Hg$.\n\n## Step 9: Conclude normality\nSince $gH = Hg$ for all $g \\in G$, $H$ is normal in $G$.\n\n## Step 10: Write the problem and solution in the required format\n\nLet $G$ be a finite group and $H$ be a subgroup of $G$. Suppose that $|G| = 2|H|$. Prove that $H$ is a normal subgroup of $G$.",
    "run_id": "5",
    "outer_attempt": 1,
    "topic_slug": "general_algebraic_systems",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem Statement**\nLet $G$ be a finite group and $H$ be a subgroup of $G$. Suppose that $|G| = 2|H|$. Prove that $H$ is a normal subgroup of $G$.\n\n**Proof**\n\nTo prove that $H$ is a normal subgroup of $G$, we must show that the left coset $gH$ is equal to the right coset $Hg$ for all elements $g \\in G$.\n\n**1. Establish the Index of $H$**\nBy Lagrange's Theorem, the index of a subgroup $H$ in a finite group $G$ is given by $[G:H] = \\frac{|G|}{|H|}$.\nGiven that $|G| = 2|H|$, we have:\n$$[G:H] = 2$$\nThis implies that there are exactly two distinct left cosets of $H$ in $G$, and exactly two distinct right cosets of $H$ in $G$.\n\n**2. Analyze the Left Cosets**\nThe left cosets of $H$ in $G$ form a partition of $G$. One of these cosets is $H$ itself (represented by the identity element $e$, since $eH = H$). Let the set of left cosets be $\\{H, L_2\\}$.\nSince the cosets partition $G$, their union is $G$ and their intersection is empty:\n$$H \\cup L_2 = G \\quad \\text{and} \\quad H \\cap L_2 = \\emptyset$$\nThis implies that the second left coset $L_2$ is the set complement of $H$ in $G$:\n$$L_2 = G \\setminus H$$\nNow, consider an arbitrary element $g \\in G$.\n*   **Case 1:** If $g \\in H$, then by the closure property of subgroups, $gH = H$.\n*   **Case 2:** If $g \\notin H$, then $gH$ cannot be $H$ (since $g \\in gH$ but $g \\notin H$). Since there are only two left cosets ($H$ and $G \\setminus H$), $gH$ must be the other coset. Therefore, $gH = G \\setminus H$.\n\n**3. Analyze the Right Cosets**\nSimilarly, the right cosets of $H$ in $G$ form a partition of $G$. One right coset is $H$ itself ($He = H$). Since the index is 2, there is exactly one other right coset, which must be the complement of $H$ in $G$.\nThus, the set of right cosets is $\\{H, G \\setminus H\\}$.\nConsider the same element $g \\in G$.\n*   **Case 1:** If $g \\in H$, then $Hg = H$.\n*   **Case 2:** If $g \\notin H$, then $Hg$ cannot be $H$. Therefore, $Hg$ must be the complement, so $Hg = G \\setminus H$.\n\n**4. Compare Left and Right Cosets**\nWe compare $gH$ and $Hg$ for any $g \\in G$:\n*   If $g \\in H$, then $gH = H$ and $Hg = H$. Thus, $gH = Hg$.\n*   If $g \\notin H$, then $gH = G \\setminus H$ and $Hg = G \\setminus H$. Thus, $gH = Hg$.\n\n**Conclusion**\nSince $gH = Hg$ for all $g \\in G$, $H$ is a normal subgroup of $G$.\n\nQ.E.D.",
        "raw_answer": "**Problem Statement**\nLet $G$ be a finite group and $H$ be a subgroup of $G$. Suppose that $|G| = 2|H|$. Prove that $H$ is a normal subgroup of $G$.\n\n**Proof**\n\nTo prove that $H$ is a normal subgroup of $G$, we must show that the left coset $gH$ is equal to the right coset $Hg$ for all elements $g \\in G$.\n\n**1. Establish the Index of $H$**\nBy Lagrange's Theorem, the index of a subgroup $H$ in a finite group $G$ is given by $[G:H] = \\frac{|G|}{|H|}$.\nGiven that $|G| = 2|H|$, we have:\n$$[G:H] = 2$$\nThis implies that there are exactly two distinct left cosets of $H$ in $G$, and exactly two distinct right cosets of $H$ in $G$.\n\n**2. Analyze the Left Cosets**\nThe left cosets of $H$ in $G$ form a partition of $G$. One of these cosets is $H$ itself (represented by the identity element $e$, since $eH = H$). Let the set of left cosets be $\\{H, L_2\\}$.\nSince the cosets partition $G$, their union is $G$ and their intersection is empty:\n$$H \\cup L_2 = G \\quad \\text{and} \\quad H \\cap L_2 = \\emptyset$$\nThis implies that the second left coset $L_2$ is the set complement of $H$ in $G$:\n$$L_2 = G \\setminus H$$\nNow, consider an arbitrary element $g \\in G$.\n*   **Case 1:** If $g \\in H$, then by the closure property of subgroups, $gH = H$.\n*   **Case 2:** If $g \\notin H$, then $gH$ cannot be $H$ (since $g \\in gH$ but $g \\notin H$). Since there are only two left cosets ($H$ and $G \\setminus H$), $gH$ must be the other coset. Therefore, $gH = G \\setminus H$.\n\n**3. Analyze the Right Cosets**\nSimilarly, the right cosets of $H$ in $G$ form a partition of $G$. One right coset is $H$ itself ($He = H$). Since the index is 2, there is exactly one other right coset, which must be the complement of $H$ in $G$.\nThus, the set of right cosets is $\\{H, G \\setminus H\\}$.\nConsider the same element $g \\in G$.\n*   **Case 1:** If $g \\in H$, then $Hg = H$.\n*   **Case 2:** If $g \\notin H$, then $Hg$ cannot be $H$. Therefore, $Hg$ must be the complement, so $Hg = G \\setminus H$.\n\n**4. Compare Left and Right Cosets**\nWe compare $gH$ and $Hg$ for any $g \\in G$:\n*   If $g \\in H$, then $gH = H$ and $Hg = H$. Thus, $gH = Hg$.\n*   If $g \\notin H$, then $gH = G \\setminus H$ and $Hg = G \\setminus H$. Thus, $gH = Hg$.\n\n**Conclusion**\nSince $gH = Hg$ for all $g \\in G$, $H$ is a normal subgroup of $G$.\n\nQ.E.D.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $F$ be a field and let $p(x) = x^3 + ax + b \\in F[x]$ be a cubic polynomial with distinct roots in some extension field of $F$. Suppose that the discriminant of $p(x)$ is a square in $F$. Prove that the Galois group of $p(x)$ over $F$ is isomorphic to $\\mathbb{Z}/3\\mathbb{Z}$ if and only if $p(x)$ is irreducible over $F$.",
    "run_id": "6",
    "outer_attempt": 1,
    "topic_slug": "field_theory_and_polynomials",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To provide a rigorous proof, we must interpret the properties of the polynomial and its Galois group within the context of Field Theory.\n\n### Preliminaries and Assumptions\n\nLet $F$ be a field and $p(x) = x^3 + ax + b \\in F[x]$.\nLet $K$ be a splitting field of $p(x)$ over $F$.\nLet the roots of $p(x)$ in $K$ be $\\alpha_1, \\alpha_2, \\alpha_3$. The problem states these roots are distinct, so $p(x)$ is separable and the discriminant $\\Delta \\neq 0$.\nThe Galois group of $p(x)$ over $F$ is $G = \\text{Gal}(K/F)$. Since $G$ permutes the three roots, $G$ is isomorphic to a subgroup of the symmetric group $S_3$.\n\n**Assumption regarding Characteristic:**\nWe assume that the characteristic of $F$ is not 2.\n*Reasoning:* The relationship between the discriminant being a square and the Galois group being a subgroup of the alternating group $A_3$ relies on the property that for distinct roots, the square root of the discriminant $\\delta = \\prod_{i<j}(\\alpha_i - \\alpha_j)$ satisfies $\\delta \\neq -\\delta$. In characteristic 2, this distinction vanishes, and the discriminant is always a square in $F$, rendering the condition in the problem statement trivial and the equivalence false (e.g., an irreducible cubic in characteristic 2 can have Galois group $S_3$).\n\n### Step 1: The Discriminant and the Alternating Group\n\nThe discriminant of $p(x)$ is given by $\\Delta = \\prod_{1 \\le i < j \\le 3} (\\alpha_i - \\alpha_j)^2$.\nLet $\\delta = \\prod_{1 \\le i < j \\le 3} (\\alpha_i - \\alpha_j)$. Then $\\delta^2 = \\Delta$.\nFor any $\\sigma \\in G$, the action of $\\sigma$ on $\\delta$ is given by:\n$$ \\sigma(\\delta) = \\text{sgn}(\\sigma) \\delta $$\nwhere $\\text{sgn}(\\sigma)$ is the sign of the permutation ($1$ for even permutations, $-1$ for odd permutations).\n\n**Hypothesis:** The discriminant $\\Delta$ is a square in $F$.\nThis implies $\\delta \\in F$.\nSince $\\delta \\in F$, it is fixed by all automorphisms in the Galois group:\n$$ \\forall \\sigma \\in G, \\quad \\sigma(\\delta) = \\delta $$\nCombining this with the sign property:\n$$ \\text{sgn}(\\sigma) \\delta = \\delta $$\nSince roots are distinct, $\\Delta \\neq 0$, so $\\delta \\neq 0$. In characteristic $\\neq 2$, $\\delta \\neq -\\delta$. Therefore:\n$$ \\text{sgn}(\\sigma) = 1 \\quad \\forall \\sigma \\in G $$\nThis implies that $G$ consists only of even permutations. Thus, $G$ is a subgroup of the alternating group $A_3$.\n\nThe subgroups of $S_3$ contained in $A_3$ are:\n1.  The trivial group $\\{e\\}$ (Order 1).\n2.  The alternating group $A_3 = \\{e, (123), (132)\\}$ (Order 3). Note that $A_3 \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n\nThus, given the discriminant condition, we have established that $G \\cong \\{e\\}$ or $G \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n\n### Step 2: Proof of Equivalence\n\nWe must prove: $G \\cong \\mathbb{Z}/3\\mathbb{Z} \\iff p(x)$ is irreducible over $F$.\n\n#### Part A: ($p(x)$ is irreducible $\\implies G \\cong \\mathbb{Z}/3\\mathbb{Z}$)\n\n1.  Assume $p(x)$ is irreducible over $F$.\n2.  Let $\\alpha_1$ be a root of $p(x)$. Since $p(x)$ is irreducible, the degree of the extension $F(\\alpha_1)/F$ is equal to the degree of the polynomial:\n    $$ [F(\\alpha_1) : F] = 3 $$\n3.  Since $K$ is the splitting field, $F \\subseteq F(\\alpha_1) \\subseteq K$. By the tower law, $[K:F] = [K:F(\\alpha_1)][F(\\alpha_1):F]$.\n4.  Therefore, $[F(\\alpha_1):F]$ divides $[K:F]$. Since $|G| = [K:F]$, we have $3 \\mid |G|$.\n5.  From Step 1, we know $G \\subseteq A_3$, so $|G|$ must divide $|A_3| = 3$.\n6.  The only positive integer that divides 3 and is divisible by 3 is 3.\n7.  Thus, $|G| = 3$. The only group of order 3 is the cyclic group $\\mathbb{Z}/3\\mathbb{Z}$.\n    $$ G \\cong \\mathbb{Z}/3\\mathbb{Z} $$\n\n#### Part B: ($G \\cong \\mathbb{Z}/3\\mathbb{Z} \\implies p(x)$ is irreducible)\n\n1.  Assume $G \\cong \\mathbb{Z}/3\\mathbb{Z}$. The elements of $G$ viewed as permutations of roots $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$ are $\\{e, (123), (132)\\}$.\n2.  The group $G$ acts transitively on the set of roots. (The orbit of any root $\\alpha_i$ is the entire set $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$).\n3.  **Transitivity implies irreducibility:**\n    If $p(x)$ were reducible over $F$, it would factor into polynomials of lower degree in $F[x]$.\n    Let $p(x) = f(x)g(x)$ with $\\deg(f) \\ge 1, \\deg(g) \\ge 1$.\n    The roots of $f(x)$ would form a subset of $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$ that is mapped to itself by all $\\sigma \\in G$ (since $\\sigma$ fixes coefficients in $F$, it maps roots of $f$ to roots of $f$).\n    This would imply the action of $G$ on the roots is not transitive (there would be an orbit of size $\\deg(f) < 3$).\n4.  Since the action is transitive, $p(x)$ cannot satisfy the condition of reducibility.\n    (Alternatively: The orbit of $\\alpha_1$ is the set of roots of its minimal polynomial. The size of the orbit is 3, so the minimal polynomial has degree 3. Since $p(x)$ is monic of degree 3 and shares a root with this minimal polynomial, $p(x)$ is the minimal polynomial, hence irreducible).\n5.  Therefore, $p(x)$ is irreducible over $F$.\n\n### Conclusion\n\nWe have shown that if the discriminant of the cubic polynomial $p(x)$ is a square in $F$ (and char $F \\neq 2$), then $G$ is a subgroup of $A_3$. Under this condition:\n- If $p(x)$ is irreducible, $|G|=3$, so $G \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n- If $G \\cong \\mathbb{Z}/3\\mathbb{Z}$, the transitive action on roots implies $p(x)$ is irreducible.\n\nThus, $\\text{Gal}(p(x)/F) \\cong \\mathbb{Z}/3\\mathbb{Z}$ if and only if $p(x)$ is irreducible over $F$.",
        "raw_answer": "To provide a rigorous proof, we must interpret the properties of the polynomial and its Galois group within the context of Field Theory.\n\n### Preliminaries and Assumptions\n\nLet $F$ be a field and $p(x) = x^3 + ax + b \\in F[x]$.\nLet $K$ be a splitting field of $p(x)$ over $F$.\nLet the roots of $p(x)$ in $K$ be $\\alpha_1, \\alpha_2, \\alpha_3$. The problem states these roots are distinct, so $p(x)$ is separable and the discriminant $\\Delta \\neq 0$.\nThe Galois group of $p(x)$ over $F$ is $G = \\text{Gal}(K/F)$. Since $G$ permutes the three roots, $G$ is isomorphic to a subgroup of the symmetric group $S_3$.\n\n**Assumption regarding Characteristic:**\nWe assume that the characteristic of $F$ is not 2.\n*Reasoning:* The relationship between the discriminant being a square and the Galois group being a subgroup of the alternating group $A_3$ relies on the property that for distinct roots, the square root of the discriminant $\\delta = \\prod_{i<j}(\\alpha_i - \\alpha_j)$ satisfies $\\delta \\neq -\\delta$. In characteristic 2, this distinction vanishes, and the discriminant is always a square in $F$, rendering the condition in the problem statement trivial and the equivalence false (e.g., an irreducible cubic in characteristic 2 can have Galois group $S_3$).\n\n### Step 1: The Discriminant and the Alternating Group\n\nThe discriminant of $p(x)$ is given by $\\Delta = \\prod_{1 \\le i < j \\le 3} (\\alpha_i - \\alpha_j)^2$.\nLet $\\delta = \\prod_{1 \\le i < j \\le 3} (\\alpha_i - \\alpha_j)$. Then $\\delta^2 = \\Delta$.\nFor any $\\sigma \\in G$, the action of $\\sigma$ on $\\delta$ is given by:\n$$ \\sigma(\\delta) = \\text{sgn}(\\sigma) \\delta $$\nwhere $\\text{sgn}(\\sigma)$ is the sign of the permutation ($1$ for even permutations, $-1$ for odd permutations).\n\n**Hypothesis:** The discriminant $\\Delta$ is a square in $F$.\nThis implies $\\delta \\in F$.\nSince $\\delta \\in F$, it is fixed by all automorphisms in the Galois group:\n$$ \\forall \\sigma \\in G, \\quad \\sigma(\\delta) = \\delta $$\nCombining this with the sign property:\n$$ \\text{sgn}(\\sigma) \\delta = \\delta $$\nSince roots are distinct, $\\Delta \\neq 0$, so $\\delta \\neq 0$. In characteristic $\\neq 2$, $\\delta \\neq -\\delta$. Therefore:\n$$ \\text{sgn}(\\sigma) = 1 \\quad \\forall \\sigma \\in G $$\nThis implies that $G$ consists only of even permutations. Thus, $G$ is a subgroup of the alternating group $A_3$.\n\nThe subgroups of $S_3$ contained in $A_3$ are:\n1.  The trivial group $\\{e\\}$ (Order 1).\n2.  The alternating group $A_3 = \\{e, (123), (132)\\}$ (Order 3). Note that $A_3 \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n\nThus, given the discriminant condition, we have established that $G \\cong \\{e\\}$ or $G \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n\n### Step 2: Proof of Equivalence\n\nWe must prove: $G \\cong \\mathbb{Z}/3\\mathbb{Z} \\iff p(x)$ is irreducible over $F$.\n\n#### Part A: ($p(x)$ is irreducible $\\implies G \\cong \\mathbb{Z}/3\\mathbb{Z}$)\n\n1.  Assume $p(x)$ is irreducible over $F$.\n2.  Let $\\alpha_1$ be a root of $p(x)$. Since $p(x)$ is irreducible, the degree of the extension $F(\\alpha_1)/F$ is equal to the degree of the polynomial:\n    $$ [F(\\alpha_1) : F] = 3 $$\n3.  Since $K$ is the splitting field, $F \\subseteq F(\\alpha_1) \\subseteq K$. By the tower law, $[K:F] = [K:F(\\alpha_1)][F(\\alpha_1):F]$.\n4.  Therefore, $[F(\\alpha_1):F]$ divides $[K:F]$. Since $|G| = [K:F]$, we have $3 \\mid |G|$.\n5.  From Step 1, we know $G \\subseteq A_3$, so $|G|$ must divide $|A_3| = 3$.\n6.  The only positive integer that divides 3 and is divisible by 3 is 3.\n7.  Thus, $|G| = 3$. The only group of order 3 is the cyclic group $\\mathbb{Z}/3\\mathbb{Z}$.\n    $$ G \\cong \\mathbb{Z}/3\\mathbb{Z} $$\n\n#### Part B: ($G \\cong \\mathbb{Z}/3\\mathbb{Z} \\implies p(x)$ is irreducible)\n\n1.  Assume $G \\cong \\mathbb{Z}/3\\mathbb{Z}$. The elements of $G$ viewed as permutations of roots $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$ are $\\{e, (123), (132)\\}$.\n2.  The group $G$ acts transitively on the set of roots. (The orbit of any root $\\alpha_i$ is the entire set $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$).\n3.  **Transitivity implies irreducibility:**\n    If $p(x)$ were reducible over $F$, it would factor into polynomials of lower degree in $F[x]$.\n    Let $p(x) = f(x)g(x)$ with $\\deg(f) \\ge 1, \\deg(g) \\ge 1$.\n    The roots of $f(x)$ would form a subset of $\\{\\alpha_1, \\alpha_2, \\alpha_3\\}$ that is mapped to itself by all $\\sigma \\in G$ (since $\\sigma$ fixes coefficients in $F$, it maps roots of $f$ to roots of $f$).\n    This would imply the action of $G$ on the roots is not transitive (there would be an orbit of size $\\deg(f) < 3$).\n4.  Since the action is transitive, $p(x)$ cannot satisfy the condition of reducibility.\n    (Alternatively: The orbit of $\\alpha_1$ is the set of roots of its minimal polynomial. The size of the orbit is 3, so the minimal polynomial has degree 3. Since $p(x)$ is monic of degree 3 and shares a root with this minimal polynomial, $p(x)$ is the minimal polynomial, hence irreducible).\n5.  Therefore, $p(x)$ is irreducible over $F$.\n\n### Conclusion\n\nWe have shown that if the discriminant of the cubic polynomial $p(x)$ is a square in $F$ (and char $F \\neq 2$), then $G$ is a subgroup of $A_3$. Under this condition:\n- If $p(x)$ is irreducible, $|G|=3$, so $G \\cong \\mathbb{Z}/3\\mathbb{Z}$.\n- If $G \\cong \\mathbb{Z}/3\\mathbb{Z}$, the transitive action on roots implies $p(x)$ is irreducible.\n\nThus, $\\text{Gal}(p(x)/F) \\cong \\mathbb{Z}/3\\mathbb{Z}$ if and only if $p(x)$ is irreducible over $F$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of commutative algebra, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic in commutative algebra\nCommutative algebra involves the study of commutative rings and their ideals, modules, and algebras. A challenging problem could involve understanding the properties of ideals, quotient rings, or the behavior of polynomials over certain rings.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the properties of ideals in a polynomial ring. Specifically, we can examine the ideal generated by a set of polynomials and ask questions about its properties, such as whether it is prime or maximal.\n\n## Step 4: Construct the problem\nConsider the polynomial ring $\\mathbb{Q}[x, y]$ and the ideal $I = (x^2 + y^2, xy)$. We can ask: Is the ideal $I$ prime? To make it more challenging and ensure it's well-posed, we can ask to determine whether $I$ is radical, i.e., whether it is equal to its radical $\\sqrt{I}$.\n\n## Step 5: Write down the problem statement\nLet $I = (x^2 + y^2, xy)$ be an ideal in $\\mathbb{Q}[x, y]$. Determine whether $I = \\sqrt{I}$, where $\\sqrt{I} = \\{f \\in \\mathbb{Q}[x, y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N}\\}$.\n\n## Step 6: Provide the solution\nTo determine if $I = \\sqrt{I}$, we first need to understand what $\\sqrt{I}$ is. An element $f \\in \\mathbb{Q}[x, y]$ is in $\\sqrt{I}$ if $f^n \\in I$ for some $n$. We need to check if there are elements in $\\sqrt{I}$ that are not in $I$.\n\n## Step 7: Analyze the ideal $I$\nTo check if $I = \\sqrt{I}$, let's first examine the quotient ring $\\mathbb{Q}[x, y]/I$. The ideal $I$ contains $x^2 + y^2$ and $xy$, which implies that $x^2 + y^2$ and $xy$ are zero in $\\mathbb{Q}[x, y]/I$. We can simplify this by observing that $x^2y + y^3 = 0$ and $x^2y = 0$ in $\\mathbb{Q}[x, y]/I$, implying $y^3 = 0$ in $\\mathbb{Q}[x, y]/I$. Similarly, $x^3 = 0$.\n\n## Step 8: Check if $I$ is radical\nSince $x^3 = 0$ and $y^3 = 0$ in $\\mathbb{Q}[x, y]/I$, it follows that $x, y \\in \\sqrt{I}$ because $x^3, y^3 \\in I$. We need to verify if $x$ and $y$ are in $I$. If not, then $I \\neq \\sqrt{I}$.\n\n## Step 9: Verify if $x$ and $y$ are in $I$\nTo check if $x \\in I$, we need to see if there exist $f, g \\in \\mathbb{Q}[x, y]$ such that $x = f(x^2 + y^2) + g(xy)$. This simplifies to checking if $x$ can be expressed as a combination of $x^2 + y^2$ and $xy$, which is not possible because any element in $I$ is of degree at least 2.\n\n## Step 10: Conclude on $I = \\sqrt{I}$\nSince $x, y \\in \\sqrt{I}$ but $x, y \\notin I$, it follows that $I \\neq \\sqrt{I}$. Thus, $I$ is not radical.\n\nThe final answer is: \n\nLet $I = (x^2 + y^2, xy)$ be an ideal in $\\mathbb{Q}[x, y]$. Determine whether $I = \\sqrt{I}$, where $\\sqrt{I} = \\{f \\in \\mathbb{Q}[x, y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N}\\}$.",
    "run_id": "7",
    "outer_attempt": 1,
    "topic_slug": "commutative_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the rigorous solution to the problem presented.\n\n### Final Result\nThe ideal $I = (x^2 + y^2, xy)$ in $\\mathbb{Q}[x, y]$ is **not** equal to its radical $\\sqrt{I}$. Specifically, the element $x$ (and similarly $y$) belongs to $\\sqrt{I}$ but does not belong to $I$.\n\n### Detailed Reasoning\n\nTo determine whether $I = \\sqrt{I}$, we must check if the ideal is **radical**. An ideal $I$ is radical if for every $f \\in \\mathbb{Q}[x, y]$ and $n \\in \\mathbb{N}_{>0}$, the condition $f^n \\in I$ implies $f \\in I$. If we can find a witness element $f$ such that $f^n \\in I$ for some $n$ but $f \\notin I$, then $I \\neq \\sqrt{I}$.\n\n**Step 1: Analyze the structure of elements in $I$**\nThe ideal $I$ is generated by two homogeneous polynomials of degree $2$:\n$$ g_1 = x^2 + y^2 $$\n$$ g_2 = xy $$\nAny element $h \\in I$ can be written in the form:\n$$ h(x, y) = p(x, y)(x^2 + y^2) + q(x, y)(xy) $$\nwhere $p, q \\in \\mathbb{Q}[x, y]$.\n\nWe examine the degree of non-zero polynomials in $I$. If $p(x, y)$ and $q(x, y)$ are not both zero, the polynomial $h(x, y)$ is a sum of terms where every term in the expansion of $p(x^2+y^2)$ has degree $\\deg(p) + 2 \\ge 2$ and every term in $q(xy)$ has degree $\\deg(q) + 2 \\ge 2$.\nConsequently, $I$ contains no non-zero polynomials of degree less than $2$.\n\n**Step 2: Identify a potential nilpotent element in the quotient ring**\nWe look for an element $f$ such that $f \\notin I$ but a power of $f$ lies in $I$. Let us test $f(x, y) = x$.\n\n**Step 3: Verify that $x \\notin I$**\nThe polynomial $f(x, y) = x$ has degree $1$.\nBased on the analysis in Step 1, every non-zero element in $I$ has degree at least $2$.\nTherefore, $x \\notin I$.\n\n**Step 4: Verify that $x \\in \\sqrt{I}$**\nWe calculate powers of $x$ to see if they lie in $I$.\nConsider $x^3$:\n$$ x^3 = x(x^2) $$\nWe can relate $x^2$ to the generators of $I$. From the generator $x^2 + y^2$, we have:\n$$ x^2 = (x^2 + y^2) - y^2 $$\nMultiplying by $x$:\n$$ x^3 = x(x^2 + y^2) - xy^2 $$\n$$ x^3 = x(x^2 + y^2) - y(xy) $$\nLet's analyze the terms on the right-hand side:\n1.  $x(x^2 + y^2)$ is a multiple of the generator $x^2 + y^2$, so it is in $I$.\n2.  $y(xy)$ is a multiple of the generator $xy$, so it is in $I$.\n\nSince $I$ is closed under subtraction, the linear combination $x(x^2 + y^2) - y(xy)$ is in $I$.\nThus, $x^3 \\in I$.\n\n**Step 5: Conclusion**\nWe have established the following:\n1.  $x \\notin I$ (Step 3).\n2.  $x^3 \\in I$, which implies $x \\in \\sqrt{I}$ by definition (Step 4).\n\nBecause there exists an element $x \\in \\sqrt{I} \\setminus I$, the ideal $I$ is not radical.\n\n$$ I \\neq \\sqrt{I} $$",
        "raw_answer": "Here is the rigorous solution to the problem presented.\n\n### Final Result\nThe ideal $I = (x^2 + y^2, xy)$ in $\\mathbb{Q}[x, y]$ is **not** equal to its radical $\\sqrt{I}$. Specifically, the element $x$ (and similarly $y$) belongs to $\\sqrt{I}$ but does not belong to $I$.\n\n### Detailed Reasoning\n\nTo determine whether $I = \\sqrt{I}$, we must check if the ideal is **radical**. An ideal $I$ is radical if for every $f \\in \\mathbb{Q}[x, y]$ and $n \\in \\mathbb{N}_{>0}$, the condition $f^n \\in I$ implies $f \\in I$. If we can find a witness element $f$ such that $f^n \\in I$ for some $n$ but $f \\notin I$, then $I \\neq \\sqrt{I}$.\n\n**Step 1: Analyze the structure of elements in $I$**\nThe ideal $I$ is generated by two homogeneous polynomials of degree $2$:\n$$ g_1 = x^2 + y^2 $$\n$$ g_2 = xy $$\nAny element $h \\in I$ can be written in the form:\n$$ h(x, y) = p(x, y)(x^2 + y^2) + q(x, y)(xy) $$\nwhere $p, q \\in \\mathbb{Q}[x, y]$.\n\nWe examine the degree of non-zero polynomials in $I$. If $p(x, y)$ and $q(x, y)$ are not both zero, the polynomial $h(x, y)$ is a sum of terms where every term in the expansion of $p(x^2+y^2)$ has degree $\\deg(p) + 2 \\ge 2$ and every term in $q(xy)$ has degree $\\deg(q) + 2 \\ge 2$.\nConsequently, $I$ contains no non-zero polynomials of degree less than $2$.\n\n**Step 2: Identify a potential nilpotent element in the quotient ring**\nWe look for an element $f$ such that $f \\notin I$ but a power of $f$ lies in $I$. Let us test $f(x, y) = x$.\n\n**Step 3: Verify that $x \\notin I$**\nThe polynomial $f(x, y) = x$ has degree $1$.\nBased on the analysis in Step 1, every non-zero element in $I$ has degree at least $2$.\nTherefore, $x \\notin I$.\n\n**Step 4: Verify that $x \\in \\sqrt{I}$**\nWe calculate powers of $x$ to see if they lie in $I$.\nConsider $x^3$:\n$$ x^3 = x(x^2) $$\nWe can relate $x^2$ to the generators of $I$. From the generator $x^2 + y^2$, we have:\n$$ x^2 = (x^2 + y^2) - y^2 $$\nMultiplying by $x$:\n$$ x^3 = x(x^2 + y^2) - xy^2 $$\n$$ x^3 = x(x^2 + y^2) - y(xy) $$\nLet's analyze the terms on the right-hand side:\n1.  $x(x^2 + y^2)$ is a multiple of the generator $x^2 + y^2$, so it is in $I$.\n2.  $y(xy)$ is a multiple of the generator $xy$, so it is in $I$.\n\nSince $I$ is closed under subtraction, the linear combination $x(x^2 + y^2) - y(xy)$ is in $I$.\nThus, $x^3 \\in I$.\n\n**Step 5: Conclusion**\nWe have established the following:\n1.  $x \\notin I$ (Step 3).\n2.  $x^3 \\in I$, which implies $x \\in \\sqrt{I}$ by definition (Step 4).\n\nBecause there exists an element $x \\in \\sqrt{I} \\setminus I$, the ideal $I$ is not radical.\n\n$$ I \\neq \\sqrt{I} $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of algebraic geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within algebraic geometry\nAlgebraic geometry is a broad field that involves the study of geometric objects, such as varieties and schemes, using tools from abstract algebra. A suitable topic could involve the study of curves, surfaces, or higher-dimensional varieties, and their properties.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the intersection of curves on a surface. A classic result in algebraic geometry is B\u00e9zout's theorem, which describes the intersection of two curves on a projective plane. We can formulate a problem related to this.\n\n## Step 4: State the problem\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.\n\n## Step 5: Provide the solution\nTo find the intersection points, we need to solve the system of equations given by $f(x,y,z) = 0$ and $g(x,y,z) = 0$. This means we have to solve $x^2 + y^2 - z^2 = 0$ and $xy - z^2 = 0$ simultaneously.\n\n## Step 6: Solve the system of equations\nFirst, from $xy - z^2 = 0$, we can express $z^2 = xy$. Substituting $z^2$ into the first equation gives $x^2 + y^2 - xy = 0$. This is a homogeneous equation in $x$ and $y$, which can be solved by considering it as a quadratic form.\n\n## Step 7: Analyze the quadratic form\nThe equation $x^2 - xy + y^2 = 0$ can be analyzed by finding its roots. This is equivalent to solving $x^2 - xy + y^2 = 0$ for $x$ in terms of $y$ (or vice versa), treating it as a quadratic equation.\n\n## Step 8: Solve for $x$ in terms of $y$\nUsing the quadratic formula, $x = \\frac{y \\pm \\sqrt{y^2 - 4y^2}}{2} = \\frac{y \\pm \\sqrt{-3y^2}}{2}$. For $y \\neq 0$, this simplifies to $x = \\frac{y(1 \\pm i\\sqrt{3})}{2}$. Thus, $x = y\\omega$ or $x = y\\omega^2$, where $\\omega$ is a primitive third root of unity.\n\n## Step 9: Determine the intersection points\nFor $x = y\\omega$ and $x = y\\omega^2$, substituting back into $xy = z^2$ gives $y^2\\omega = z^2$ and $y^2\\omega^2 = z^2$, respectively. This implies $z = \\pm y\\sqrt{\\omega}$ and $z = \\pm y\\sqrt{\\omega^2}$. However, we must consider the projective nature and the fact that we're working with homogeneous coordinates.\n\n## Step 10: Count the intersection points with multiplicity\nSince $\\omega$ and $\\omega^2$ are not real, and we're working over $\\mathbb{C}$, we need to consider the solutions in $\\mathbb{P}^2(\\mathbb{C})$. The solutions are given by the pairs $(x:y:z)$ satisfying both equations. We need to check if there are any solutions where $y = 0$, which would imply $x = 0$ and thus $z = 0$, but $(0,0,0)$ is not a valid point in $\\mathbb{P}^2$.\n\n## Step 11: Apply B\u00e9zout's theorem for a simpler solution\nB\u00e9zout's theorem states that two curves of degrees $d_1$ and $d_2$ intersect in $d_1d_2$ points, counted with multiplicity, if they have no common components. Here, $C_1$ and $C_2$ are both of degree 2, so they should intersect in $2 \\times 2 = 4$ points.\n\nThe final answer is: \n\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.",
    "run_id": "8",
    "outer_attempt": 1,
    "topic_slug": "algebraic_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the number of intersection points of the curves $C_1$ and $C_2$ in the complex projective plane $\\mathbb{P}^2$, counted with multiplicity, we will analyze the system of homogeneous equations defined by the polynomials $f$ and $g$.\n\n### 1. Problem Statement\nLet the two curves be defined by the homogeneous polynomials:\n$$f(x,y,z) = x^2 + y^2 - z^2 = 0$$\n$$g(x,y,z) = xy - z^2 = 0$$\nWe seek the number of solutions to this system in $\\mathbb{P}^2$, counted with intersection multiplicity. We assume the ground field is the field of complex numbers $\\mathbb{C}$, as is standard for intersection theory in algebraic geometry.\n\n### 2. Application of B\u00e9zout's Theorem\nB\u00e9zout's Theorem states that for two plane projective curves of degrees $d_1$ and $d_2$ defined over an algebraically closed field, if they do not share a common component, the number of intersection points counted with multiplicity is exactly $d_1 \\cdot d_2$.\n\n**Checking Degrees:**\n- $f(x,y,z)$ is a polynomial of degree $d_1 = 2$.\n- $g(x,y,z)$ is a polynomial of degree $d_2 = 2$.\n\n**Checking for Common Components:**\nBoth $f$ and $g$ define conics.\n- $g(x,y,z) = xy - z^2$ is an irreducible quadratic form (it corresponds to a non-degenerate conic, specifically identifiable as the Veronese embedding of $\\mathbb{P}^1$ or simply by noting it cannot be factored into linear terms).\n- $f(x,y,z) = x^2 + y^2 - z^2$ is also irreducible.\n- For them to share a common component, since they are both irreducible and of the same degree, they would have to be proportional. That is, $f = k \\cdot g$ for some constant $k$. Clearly, $x^2 + y^2 - z^2$ is not a scalar multiple of $xy - z^2$.\n\nThus, the curves have no common components. By B\u00e9zout's Theorem, the number of intersection points is:\n$$N = d_1 \\cdot d_2 = 2 \\cdot 2 = 4$$\n\n### 3. Explicit Verification of Intersection Points\nTo ensure rigor and verify that the multiplicities behave as expected (i.e., we don't have tangencies summing to 4, but rather 4 distinct points), we solve the system explicitly.\n\nThe system is:\n1. $x^2 + y^2 = z^2$\n2. $xy = z^2$\n\nSubstitute equation (2) into equation (1):\n$$x^2 + y^2 = xy$$\n$$x^2 - xy + y^2 = 0$$\n\nWe look for solutions $[x:y:z]$ in $\\mathbb{P}^2$. Note that $(0,0,0)$ is not a valid projective point.\nIf $y = 0$, the equation $x^2 - x(0) + 0 = 0$ implies $x = 0$. Then $z^2 = xy = 0 \\implies z=0$. Since $[0:0:0]$ is not valid, we must have $y \\neq 0$.\n\nSince $y \\neq 0$, we can dehomogenize by setting $y = 1$. The equation becomes:\n$$x^2 - x + 1 = 0$$\n\nThe roots of this quadratic equation are:\n$$x = \\frac{1 \\pm \\sqrt{1 - 4}}{2} = \\frac{1 \\pm i\\sqrt{3}}{2}$$\nLet $\\omega = e^{i\\pi/3} = \\frac{1 + i\\sqrt{3}}{2}$ and $\\bar{\\omega} = e^{-i\\pi/3} = \\frac{1 - i\\sqrt{3}}{2}$.\nSo, $x \\in \\{\\omega, \\bar{\\omega}\\}$.\n\nNow we solve for $z$ using $z^2 = xy$. Since $y=1$, $z^2 = x$.\n\n**Case 1: $x = \\omega$**\n$$z^2 = \\omega$$\nThis yields two distinct solutions for $z$: $z_1 = \\sqrt{\\omega}$ and $z_2 = -\\sqrt{\\omega}$.\nThis gives two intersection points:\n$$P_1 = [\\omega : 1 : \\sqrt{\\omega}]$$\n$$P_2 = [\\omega : 1 : -\\sqrt{\\omega}]$$\n\n**Case 2: $x = \\bar{\\omega}$**\n$$z^2 = \\bar{\\omega}$$\nThis yields two distinct solutions for $z$: $z_3 = \\sqrt{\\bar{\\omega}}$ and $z_4 = -\\sqrt{\\bar{\\omega}}$.\nThis gives two intersection points:\n$$P_3 = [\\bar{\\omega} : 1 : \\sqrt{\\bar{\\omega}}]$$\n$$P_4 = [\\bar{\\omega} : 1 : -\\sqrt{\\bar{\\omega}}]$$\n\n**Analysis of Multiplicity:**\nWe have found 4 distinct points ($P_1, P_2, P_3, P_4$).\nSince the sum of multiplicities must be 4 (by B\u00e9zout's Theorem), and there are 4 distinct solutions, each solution must have multiplicity exactly 1. This means the curves intersect transversally at all 4 points.\n\n### 4. Conclusion\nThe curves $C_1$ and $C_2$ intersect at exactly 4 distinct points. Summing their multiplicities:\n\n$$ \\sum_{P \\in C_1 \\cap C_2} m_P(C_1, C_2) = 4 $$\n\n**Answer:**\nThe number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity, is **4**.",
        "raw_answer": "To find the number of intersection points of the curves $C_1$ and $C_2$ in the complex projective plane $\\mathbb{P}^2$, counted with multiplicity, we will analyze the system of homogeneous equations defined by the polynomials $f$ and $g$.\n\n### 1. Problem Statement\nLet the two curves be defined by the homogeneous polynomials:\n$$f(x,y,z) = x^2 + y^2 - z^2 = 0$$\n$$g(x,y,z) = xy - z^2 = 0$$\nWe seek the number of solutions to this system in $\\mathbb{P}^2$, counted with intersection multiplicity. We assume the ground field is the field of complex numbers $\\mathbb{C}$, as is standard for intersection theory in algebraic geometry.\n\n### 2. Application of B\u00e9zout's Theorem\nB\u00e9zout's Theorem states that for two plane projective curves of degrees $d_1$ and $d_2$ defined over an algebraically closed field, if they do not share a common component, the number of intersection points counted with multiplicity is exactly $d_1 \\cdot d_2$.\n\n**Checking Degrees:**\n- $f(x,y,z)$ is a polynomial of degree $d_1 = 2$.\n- $g(x,y,z)$ is a polynomial of degree $d_2 = 2$.\n\n**Checking for Common Components:**\nBoth $f$ and $g$ define conics.\n- $g(x,y,z) = xy - z^2$ is an irreducible quadratic form (it corresponds to a non-degenerate conic, specifically identifiable as the Veronese embedding of $\\mathbb{P}^1$ or simply by noting it cannot be factored into linear terms).\n- $f(x,y,z) = x^2 + y^2 - z^2$ is also irreducible.\n- For them to share a common component, since they are both irreducible and of the same degree, they would have to be proportional. That is, $f = k \\cdot g$ for some constant $k$. Clearly, $x^2 + y^2 - z^2$ is not a scalar multiple of $xy - z^2$.\n\nThus, the curves have no common components. By B\u00e9zout's Theorem, the number of intersection points is:\n$$N = d_1 \\cdot d_2 = 2 \\cdot 2 = 4$$\n\n### 3. Explicit Verification of Intersection Points\nTo ensure rigor and verify that the multiplicities behave as expected (i.e., we don't have tangencies summing to 4, but rather 4 distinct points), we solve the system explicitly.\n\nThe system is:\n1. $x^2 + y^2 = z^2$\n2. $xy = z^2$\n\nSubstitute equation (2) into equation (1):\n$$x^2 + y^2 = xy$$\n$$x^2 - xy + y^2 = 0$$\n\nWe look for solutions $[x:y:z]$ in $\\mathbb{P}^2$. Note that $(0,0,0)$ is not a valid projective point.\nIf $y = 0$, the equation $x^2 - x(0) + 0 = 0$ implies $x = 0$. Then $z^2 = xy = 0 \\implies z=0$. Since $[0:0:0]$ is not valid, we must have $y \\neq 0$.\n\nSince $y \\neq 0$, we can dehomogenize by setting $y = 1$. The equation becomes:\n$$x^2 - x + 1 = 0$$\n\nThe roots of this quadratic equation are:\n$$x = \\frac{1 \\pm \\sqrt{1 - 4}}{2} = \\frac{1 \\pm i\\sqrt{3}}{2}$$\nLet $\\omega = e^{i\\pi/3} = \\frac{1 + i\\sqrt{3}}{2}$ and $\\bar{\\omega} = e^{-i\\pi/3} = \\frac{1 - i\\sqrt{3}}{2}$.\nSo, $x \\in \\{\\omega, \\bar{\\omega}\\}$.\n\nNow we solve for $z$ using $z^2 = xy$. Since $y=1$, $z^2 = x$.\n\n**Case 1: $x = \\omega$**\n$$z^2 = \\omega$$\nThis yields two distinct solutions for $z$: $z_1 = \\sqrt{\\omega}$ and $z_2 = -\\sqrt{\\omega}$.\nThis gives two intersection points:\n$$P_1 = [\\omega : 1 : \\sqrt{\\omega}]$$\n$$P_2 = [\\omega : 1 : -\\sqrt{\\omega}]$$\n\n**Case 2: $x = \\bar{\\omega}$**\n$$z^2 = \\bar{\\omega}$$\nThis yields two distinct solutions for $z$: $z_3 = \\sqrt{\\bar{\\omega}}$ and $z_4 = -\\sqrt{\\bar{\\omega}}$.\nThis gives two intersection points:\n$$P_3 = [\\bar{\\omega} : 1 : \\sqrt{\\bar{\\omega}}]$$\n$$P_4 = [\\bar{\\omega} : 1 : -\\sqrt{\\bar{\\omega}}]$$\n\n**Analysis of Multiplicity:**\nWe have found 4 distinct points ($P_1, P_2, P_3, P_4$).\nSince the sum of multiplicities must be 4 (by B\u00e9zout's Theorem), and there are 4 distinct solutions, each solution must have multiplicity exactly 1. This means the curves intersect transversally at all 4 points.\n\n### 4. Conclusion\nThe curves $C_1$ and $C_2$ intersect at exactly 4 distinct points. Summing their multiplicities:\n\n$$ \\sum_{P \\in C_1 \\cap C_2} m_P(C_1, C_2) = 4 $$\n\n**Answer:**\nThe number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity, is **4**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Linear and multilinear algebra; matrix theory, along with a complete and verifiable solution.\n\n## Step 2: Identify the key elements of a well-posed problem\nThe problem must be fully self-contained, clear, non-trivial, solvable, and verifiable. It should involve sophisticated techniques from linear and multilinear algebra or matrix theory.\n\n## Step 3: Generate a problem that fits the criteria\nLet's consider a problem that involves matrix theory and requires a good understanding of linear algebra concepts. A potential problem could involve proving a property of matrices or finding a specific matrix that satisfies certain conditions.\n\n## Step 4: Formulate the problem\nConsider the following problem: \"Let $A$ be a $3 \\times 3$ real matrix such that $A^3 = I$, where $I$ is the $3 \\times 3$ identity matrix. Prove that $A$ is diagonalizable over $\\mathbb{C}$.\"\n\n## Step 5: Verify that the problem is well-posed and solvable\nThe problem is well-posed because it specifies the domain of $A$ (real $3 \\times 3$ matrices), gives a clear condition ($A^3 = I$), and asks for a specific proof (that $A$ is diagonalizable over $\\mathbb{C}$). It is solvable using established methods in linear algebra.\n\n## Step 6: Provide a complete solution to the problem\nTo solve this, we note that $A$ satisfies the polynomial $x^3 - 1 = 0$. This polynomial factors as $(x-1)(x^2 + x + 1) = 0$. The roots are $1$, $e^{2\\pi i/3}$, and $e^{4\\pi i/3}$. Since $A$ satisfies this polynomial, its eigenvalues must be among these roots. Because the minimal polynomial of $A$ divides $x^3 - 1$ and has distinct roots (since $x^3 - 1$ has distinct roots), $A$ is diagonalizable over $\\mathbb{C}$.\n\n## Step 7: Write the problem and solution in the required format\n\nLet $A$ be a $3 \\times 3$ real matrix such that $A^3 = I$, where $I$ is the $3 \\times 3$ identity matrix. Prove that $A$ is diagonalizable over $\\mathbb{C}$.",
    "run_id": "9",
    "outer_attempt": 1,
    "topic_slug": "linear_and_multilinear_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the $3 \\times 3$ real matrix $A$ is diagonalizable over $\\mathbb{C}$, we will utilize the properties of the minimal polynomial and the criterion for diagonalizability.\n\n**1. Identification of an Annihilating Polynomial**\nWe are given that $A^3 = I$, where $I$ is the identity matrix. This implies that the matrix $A$ satisfies the polynomial equation:\n$$ P(A) = 0 $$\nwhere $P(x) = x^3 - 1$. This polynomial $P(x)$ is an annihilating polynomial for $A$.\n\n**2. Roots of the Annihilating Polynomial**\nWe determine the roots of $P(x) = x^3 - 1$ over the complex field $\\mathbb{C}$. The roots satisfy $x^3 = 1$. These are the three distinct cubic roots of unity:\n$$ \\lambda_1 = 1 $$\n$$ \\lambda_2 = e^{i \\frac{2\\pi}{3}} = -\\frac{1}{2} + i\\frac{\\sqrt{3}}{2} $$\n$$ \\lambda_3 = e^{i \\frac{4\\pi}{3}} = -\\frac{1}{2} - i\\frac{\\sqrt{3}}{2} $$\nThus, in $\\mathbb{C}[x]$, the polynomial factors as:\n$$ P(x) = (x - \\lambda_1)(x - \\lambda_2)(x - \\lambda_3) $$\nImportantly, $\\lambda_1, \\lambda_2$, and $\\lambda_3$ are all distinct.\n\n**3. Analysis of the Minimal Polynomial**\nLet $\\mu_A(x)$ denote the minimal polynomial of matrix $A$. By the definition of the minimal polynomial, $\\mu_A(x)$ must divide any annihilating polynomial of $A$. Therefore:\n$$ \\mu_A(x) \\mid (x^3 - 1) $$\nSince $x^3 - 1$ factors into distinct linear terms $(x - \\lambda_1)(x - \\lambda_2)(x - \\lambda_3)$, any divisor $\\mu_A(x)$ must be a product of distinct linear factors from this set.\nExplicitly, $\\mu_A(x)$ must take the form:\n$$ \\mu_A(x) = (x - r_1)(x - r_2)\\cdots(x - r_k) $$\nwhere $\\{r_1, \\dots, r_k\\}$ is a non-empty subset of distinct roots from $\\{\\lambda_1, \\lambda_2, \\lambda_3\\}$.\n\n**4. Application of the Diagonalizability Criterion**\nA fundamental theorem in linear algebra states:\n> A square matrix $M$ is diagonalizable over a field $\\mathbb{F}$ if and only if its minimal polynomial splits into linear factors over $\\mathbb{F}$ and has no repeated roots (i.e., has distinct roots).\n\nIn our case:\n1.  The field is $\\mathbb{C}$.\n2.  We have established that $\\mu_A(x)$ is a product of distinct linear factors over $\\mathbb{C}$ (since it divides a polynomial with distinct roots).\n\n**Conclusion**\nSince the minimal polynomial $\\mu_A(x)$ has distinct roots, $A$ is diagonalizable over $\\mathbb{C}$.",
        "raw_answer": "To prove that the $3 \\times 3$ real matrix $A$ is diagonalizable over $\\mathbb{C}$, we will utilize the properties of the minimal polynomial and the criterion for diagonalizability.\n\n**1. Identification of an Annihilating Polynomial**\nWe are given that $A^3 = I$, where $I$ is the identity matrix. This implies that the matrix $A$ satisfies the polynomial equation:\n$$ P(A) = 0 $$\nwhere $P(x) = x^3 - 1$. This polynomial $P(x)$ is an annihilating polynomial for $A$.\n\n**2. Roots of the Annihilating Polynomial**\nWe determine the roots of $P(x) = x^3 - 1$ over the complex field $\\mathbb{C}$. The roots satisfy $x^3 = 1$. These are the three distinct cubic roots of unity:\n$$ \\lambda_1 = 1 $$\n$$ \\lambda_2 = e^{i \\frac{2\\pi}{3}} = -\\frac{1}{2} + i\\frac{\\sqrt{3}}{2} $$\n$$ \\lambda_3 = e^{i \\frac{4\\pi}{3}} = -\\frac{1}{2} - i\\frac{\\sqrt{3}}{2} $$\nThus, in $\\mathbb{C}[x]$, the polynomial factors as:\n$$ P(x) = (x - \\lambda_1)(x - \\lambda_2)(x - \\lambda_3) $$\nImportantly, $\\lambda_1, \\lambda_2$, and $\\lambda_3$ are all distinct.\n\n**3. Analysis of the Minimal Polynomial**\nLet $\\mu_A(x)$ denote the minimal polynomial of matrix $A$. By the definition of the minimal polynomial, $\\mu_A(x)$ must divide any annihilating polynomial of $A$. Therefore:\n$$ \\mu_A(x) \\mid (x^3 - 1) $$\nSince $x^3 - 1$ factors into distinct linear terms $(x - \\lambda_1)(x - \\lambda_2)(x - \\lambda_3)$, any divisor $\\mu_A(x)$ must be a product of distinct linear factors from this set.\nExplicitly, $\\mu_A(x)$ must take the form:\n$$ \\mu_A(x) = (x - r_1)(x - r_2)\\cdots(x - r_k) $$\nwhere $\\{r_1, \\dots, r_k\\}$ is a non-empty subset of distinct roots from $\\{\\lambda_1, \\lambda_2, \\lambda_3\\}$.\n\n**4. Application of the Diagonalizability Criterion**\nA fundamental theorem in linear algebra states:\n> A square matrix $M$ is diagonalizable over a field $\\mathbb{F}$ if and only if its minimal polynomial splits into linear factors over $\\mathbb{F}$ and has no repeated roots (i.e., has distinct roots).\n\nIn our case:\n1.  The field is $\\mathbb{C}$.\n2.  We have established that $\\mu_A(x)$ is a product of distinct linear factors over $\\mathbb{C}$ (since it divides a polynomial with distinct roots).\n\n**Conclusion**\nSince the minimal polynomial $\\mu_A(x)$ has distinct roots, $A$ is diagonalizable over $\\mathbb{C}$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of associative rings and algebras, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within associative rings and algebras\nAssociative rings and algebras involve the study of algebraic structures with associative multiplication. A suitable topic could involve properties of ideals, quotient rings, or specific types of algebras like matrix algebras.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving the properties of a specific type of associative algebra. For instance, we could explore the characteristics of a matrix algebra over a ring.\n\n## Step 4: Generate a specific problem\nConsider the ring $R = \\mathbb{Z}/4\\mathbb{Z}$ and the matrix algebra $M_2(R)$ of $2 \\times 2$ matrices with entries in $R$. Let's examine the properties of ideals in $M_2(R)$.\n\n## Step 5: Formulate the problem statement\n\"Let $R = \\mathbb{Z}/4\\mathbb{Z}$ and consider the matrix algebra $M_2(R)$. Prove that $M_2(R)$ is not a simple ring, i.e., it has a non-trivial ideal.\"\n\n## Step 6: Provide the solution\nTo solve this, we need to show that there exists a non-trivial ideal in $M_2(R)$. An ideal $I$ in $M_2(R)$ is a subset that is closed under addition and under multiplication by any element of $M_2(R)$ from either side.\n\n## Step 7: Identify a non-trivial ideal\nConsider the set $I$ of matrices in $M_2(R)$ where all entries are even (i.e., $0$ or $2$ mod $4$). This set is non-empty and not equal to $M_2(R)$ because it does not contain matrices with odd entries.\n\n## Step 8: Verify that $I$ is an ideal\nFor $I$ to be an ideal, it must be closed under addition and under multiplication by elements of $M_2(R)$. For any two matrices $A, B \\in I$, $A + B$ has even entries because the sum of even numbers is even, so $A + B \\in I$. For any $A \\in I$ and $C \\in M_2(R)$, the product $CA$ and $AC$ will have entries that are products and sums of products involving elements of $R$. Since $A$ has even entries, $CA$ and $AC$ will also have even entries because multiplying any element of $R$ by an even element results in an even element.\n\n## Step 9: Check if $I$ is non-trivial\n$I$ is non-trivial if it is not the zero ideal and not the entire ring $M_2(R)$. The zero matrix is in $I$, and there are non-zero matrices in $I$ (e.g., $\\begin{pmatrix} 2 & 0 \\\\ 0 & 0 \\end{pmatrix}$), so $I$ is not the zero ideal. $I$ is not $M_2(R)$ because, for example, $\\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\notin I$.\n\n## Step 10: Conclude the solution\nSince $I$ is a non-trivial ideal, $M_2(R)$ is not a simple ring.\n\nThe final answer is: \n\nLet $R = \\mathbb{Z}/4\\mathbb{Z}$ and consider the matrix algebra $M_2(R)$. Prove that $M_2(R)$ is not a simple ring, i.e., it has a non-trivial ideal.",
    "run_id": "10",
    "outer_attempt": 1,
    "topic_slug": "associative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the matrix algebra $M_2(R)$ over the ring $R = \\mathbb{Z}/4\\mathbb{Z}$ is not a simple ring, we must demonstrate the existence of a **non-trivial two-sided ideal** $I \\subset M_2(R)$. A non-trivial ideal is one such that $I \\neq \\{0\\}$ (the zero ideal) and $I \\neq M_2(R)$ (the entire ring).\n\n### 1. Construction of the Candidate Ideal\n\nFirst, we examine the base ring $R = \\mathbb{Z}/4\\mathbb{Z}$. The elements of $R$ are $\\{\\bar{0}, \\bar{1}, \\bar{2}, \\bar{3}\\}$.\n\nWe observe that $R$ itself is not a simple ring (and not a field) because it contains a non-trivial ideal. Consider the principal ideal generated by $\\bar{2}$:\n$$ J = (\\bar{2}) = \\{ r \\cdot \\bar{2} \\mid r \\in R \\} = \\{ \\bar{0}, \\bar{2} \\} $$\nThis set $J$ is an ideal in $R$ because:\n1.  **Additive closure:** $\\bar{0} + \\bar{0} = \\bar{0}$, $\\bar{0} + \\bar{2} = \\bar{2}$, and $\\bar{2} + \\bar{2} = \\bar{0}$ (since $4 \\equiv 0 \\pmod 4$).\n2.  **Multiplicative absorption:** For any $x \\in R$ and $y \\in J$:\n    *   If $y = \\bar{0}$, $xy = 0 \\in J$.\n    *   If $y = \\bar{2}$, $x\\bar{2}$ is even. Specifically:\n        *   $\\bar{0} \\cdot \\bar{2} = \\bar{0}$\n        *   $\\bar{1} \\cdot \\bar{2} = \\bar{2}$\n        *   $\\bar{2} \\cdot \\bar{2} = \\bar{4} = \\bar{0}$\n        *   $\\bar{3} \\cdot \\bar{2} = \\bar{6} = \\bar{2}$\n    In all cases, $xy \\in J$.\n\nNow, we construct the candidate ideal $I$ in $M_2(R)$ by taking all matrices with entries belonging to $J$:\n$$ I = M_2(J) = \\left\\{ \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\;\\Bigg|\\; a, b, c, d \\in \\{\\bar{0}, \\bar{2}\\} \\right\\} $$\n\n### 2. Verification that $I$ is a Two-Sided Ideal\n\nTo prove $I$ is a two-sided ideal of $M_2(R)$, we must verify it is an additive subgroup and closed under left and right multiplication by any matrix in $M_2(R)$.\n\n**Step 2a: Additive Subgroup**\nLet $A, B \\in I$. Then every entry $A_{ij}$ and $B_{ij}$ is in $J = \\{\\bar{0}, \\bar{2}\\}$.\nSince $J$ is closed under addition ($J$ is an ideal of $R$), the sum $A_{ij} + B_{ij} \\in J$.\nTherefore, the matrix $A + B$ has all entries in $J$, so $A + B \\in I$.\nThe zero matrix has entries all $\\bar{0} \\in J$, so $0 \\in I$.\nThe additive inverse of an entry $\\bar{0}$ is $\\bar{0}$ and $\\bar{2}$ is $\\bar{2}$ (since $\\bar{2}+\\bar{2}=\\bar{0}$), so $-A \\in I$.\nThus, $I$ is an additive subgroup.\n\n**Step 2b: Multiplicative Absorption (Two-Sided)**\nLet $M \\in I$ and $X \\in M_2(R)$.\nBy definition, all entries $M_{ij} \\in J$. Since $J$ is an ideal of $R$, for any $r \\in R$ and $j \\in J$, both $rj \\in J$ and $jr \\in J$.\n\nConsider the product $XM$ (Left Ideal Property):\nThe $(i, k)$-th entry is $(XM)_{ik} = \\sum_{j=1}^2 X_{ij} M_{jk}$.\nSince $M_{jk} \\in J$ and $J$ absorbs multiplication from $R$, each term $X_{ij} M_{jk} \\in J$.\nSince $J$ is closed under addition, the sum $(XM)_{ik} \\in J$.\nSince all entries of $XM$ are in $J$, $XM \\in I$.\n\nConsider the product $MX$ (Right Ideal Property):\nThe $(i, k)$-th entry is $(MX)_{ik} = \\sum_{j=1}^2 M_{ij} X_{jk}$.\nSince $M_{ij} \\in J$, each term $M_{ij} X_{jk} \\in J$.\nConsequently, the sum $(MX)_{ik} \\in J$.\nThus, $MX \\in I$.\n\nTherefore, $I$ is a two-sided ideal.\n\n### 3. Verification of Non-Triviality\n\nWe must show that $I \\neq \\{0\\}$ and $I \\neq M_2(R)$.\n\n1.  **$I \\neq \\{0\\}$**:\n    Consider the matrix $A = \\begin{pmatrix} \\bar{2} & \\bar{0} \\\\ \\bar{0} & \\bar{0} \\end{pmatrix}$.\n    All entries of $A$ are in $\\{\\bar{0}, \\bar{2}\\}$, so $A \\in I$.\n    Since $\\bar{2} \\not\\equiv \\bar{0} \\pmod 4$, $A$ is not the zero matrix. Thus, $I$ contains non-zero elements.\n\n2.  **$I \\neq M_2(R)$**:\n    Consider the identity matrix $E = \\begin{pmatrix} \\bar{1} & \\bar{0} \\\\ \\bar{0} & \\bar{1} \\end{pmatrix}$.\n    The entry $\\bar{1}$ is not in $J = \\{\\bar{0}, \\bar{2}\\}$ (as $\\bar{1}$ is odd and elements of $J$ are even).\n    Therefore, $E \\notin I$.\n    Consequently, $I$ is not the entire ring $M_2(R)$.\n\n### Conclusion\n\nWe have constructed a set $I = M_2(2\\mathbb{Z}/4\\mathbb{Z})$ and proven that:\n1.  $I$ is a two-sided ideal of $M_2(R)$.\n2.  $I$ is not the zero ideal.\n3.  $I$ is not the whole ring.\n\nSince $M_2(R)$ contains a non-trivial two-sided ideal, **$M_2(R)$ is not a simple ring.**",
        "raw_answer": "To prove that the matrix algebra $M_2(R)$ over the ring $R = \\mathbb{Z}/4\\mathbb{Z}$ is not a simple ring, we must demonstrate the existence of a **non-trivial two-sided ideal** $I \\subset M_2(R)$. A non-trivial ideal is one such that $I \\neq \\{0\\}$ (the zero ideal) and $I \\neq M_2(R)$ (the entire ring).\n\n### 1. Construction of the Candidate Ideal\n\nFirst, we examine the base ring $R = \\mathbb{Z}/4\\mathbb{Z}$. The elements of $R$ are $\\{\\bar{0}, \\bar{1}, \\bar{2}, \\bar{3}\\}$.\n\nWe observe that $R$ itself is not a simple ring (and not a field) because it contains a non-trivial ideal. Consider the principal ideal generated by $\\bar{2}$:\n$$ J = (\\bar{2}) = \\{ r \\cdot \\bar{2} \\mid r \\in R \\} = \\{ \\bar{0}, \\bar{2} \\} $$\nThis set $J$ is an ideal in $R$ because:\n1.  **Additive closure:** $\\bar{0} + \\bar{0} = \\bar{0}$, $\\bar{0} + \\bar{2} = \\bar{2}$, and $\\bar{2} + \\bar{2} = \\bar{0}$ (since $4 \\equiv 0 \\pmod 4$).\n2.  **Multiplicative absorption:** For any $x \\in R$ and $y \\in J$:\n    *   If $y = \\bar{0}$, $xy = 0 \\in J$.\n    *   If $y = \\bar{2}$, $x\\bar{2}$ is even. Specifically:\n        *   $\\bar{0} \\cdot \\bar{2} = \\bar{0}$\n        *   $\\bar{1} \\cdot \\bar{2} = \\bar{2}$\n        *   $\\bar{2} \\cdot \\bar{2} = \\bar{4} = \\bar{0}$\n        *   $\\bar{3} \\cdot \\bar{2} = \\bar{6} = \\bar{2}$\n    In all cases, $xy \\in J$.\n\nNow, we construct the candidate ideal $I$ in $M_2(R)$ by taking all matrices with entries belonging to $J$:\n$$ I = M_2(J) = \\left\\{ \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\;\\Bigg|\\; a, b, c, d \\in \\{\\bar{0}, \\bar{2}\\} \\right\\} $$\n\n### 2. Verification that $I$ is a Two-Sided Ideal\n\nTo prove $I$ is a two-sided ideal of $M_2(R)$, we must verify it is an additive subgroup and closed under left and right multiplication by any matrix in $M_2(R)$.\n\n**Step 2a: Additive Subgroup**\nLet $A, B \\in I$. Then every entry $A_{ij}$ and $B_{ij}$ is in $J = \\{\\bar{0}, \\bar{2}\\}$.\nSince $J$ is closed under addition ($J$ is an ideal of $R$), the sum $A_{ij} + B_{ij} \\in J$.\nTherefore, the matrix $A + B$ has all entries in $J$, so $A + B \\in I$.\nThe zero matrix has entries all $\\bar{0} \\in J$, so $0 \\in I$.\nThe additive inverse of an entry $\\bar{0}$ is $\\bar{0}$ and $\\bar{2}$ is $\\bar{2}$ (since $\\bar{2}+\\bar{2}=\\bar{0}$), so $-A \\in I$.\nThus, $I$ is an additive subgroup.\n\n**Step 2b: Multiplicative Absorption (Two-Sided)**\nLet $M \\in I$ and $X \\in M_2(R)$.\nBy definition, all entries $M_{ij} \\in J$. Since $J$ is an ideal of $R$, for any $r \\in R$ and $j \\in J$, both $rj \\in J$ and $jr \\in J$.\n\nConsider the product $XM$ (Left Ideal Property):\nThe $(i, k)$-th entry is $(XM)_{ik} = \\sum_{j=1}^2 X_{ij} M_{jk}$.\nSince $M_{jk} \\in J$ and $J$ absorbs multiplication from $R$, each term $X_{ij} M_{jk} \\in J$.\nSince $J$ is closed under addition, the sum $(XM)_{ik} \\in J$.\nSince all entries of $XM$ are in $J$, $XM \\in I$.\n\nConsider the product $MX$ (Right Ideal Property):\nThe $(i, k)$-th entry is $(MX)_{ik} = \\sum_{j=1}^2 M_{ij} X_{jk}$.\nSince $M_{ij} \\in J$, each term $M_{ij} X_{jk} \\in J$.\nConsequently, the sum $(MX)_{ik} \\in J$.\nThus, $MX \\in I$.\n\nTherefore, $I$ is a two-sided ideal.\n\n### 3. Verification of Non-Triviality\n\nWe must show that $I \\neq \\{0\\}$ and $I \\neq M_2(R)$.\n\n1.  **$I \\neq \\{0\\}$**:\n    Consider the matrix $A = \\begin{pmatrix} \\bar{2} & \\bar{0} \\\\ \\bar{0} & \\bar{0} \\end{pmatrix}$.\n    All entries of $A$ are in $\\{\\bar{0}, \\bar{2}\\}$, so $A \\in I$.\n    Since $\\bar{2} \\not\\equiv \\bar{0} \\pmod 4$, $A$ is not the zero matrix. Thus, $I$ contains non-zero elements.\n\n2.  **$I \\neq M_2(R)$**:\n    Consider the identity matrix $E = \\begin{pmatrix} \\bar{1} & \\bar{0} \\\\ \\bar{0} & \\bar{1} \\end{pmatrix}$.\n    The entry $\\bar{1}$ is not in $J = \\{\\bar{0}, \\bar{2}\\}$ (as $\\bar{1}$ is odd and elements of $J$ are even).\n    Therefore, $E \\notin I$.\n    Consequently, $I$ is not the entire ring $M_2(R)$.\n\n### Conclusion\n\nWe have constructed a set $I = M_2(2\\mathbb{Z}/4\\mathbb{Z})$ and proven that:\n1.  $I$ is a two-sided ideal of $M_2(R)$.\n2.  $I$ is not the zero ideal.\n3.  $I$ is not the whole ring.\n\nSince $M_2(R)$ contains a non-trivial two-sided ideal, **$M_2(R)$ is not a simple ring.**",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of nonassociative rings and algebras, along with a complete and verifiable solution. Nonassociative rings and algebras are mathematical structures where the multiplication operation is not necessarily associative.\n\n## Step 2: Identify a specific area within nonassociative rings and algebras\nA key area within nonassociative rings and algebras is the study of Lie algebras, which are crucial in various branches of mathematics and physics, particularly in the study of symmetries and conservation laws.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving Lie algebras. A Lie algebra is a vector space $\\mathfrak{g}$ over a field $\\mathbb{F}$, together with a binary operation $[\\cdot, \\cdot]: \\mathfrak{g} \\times \\mathfrak{g} \\to \\mathfrak{g}$, called the Lie bracket, that satisfies bilinearity, skew-symmetry, and the Jacobi identity.\n\n## Step 4: Specify the problem\nConsider the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$, which consists of $2 \\times 2$ real matrices with trace zero. The Lie bracket is defined as $[A, B] = AB - BA$. Let $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$. Show that $H, X, Y$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and determine the structure constants with respect to this basis.\n\n## Step 5: Provide the problem statement in the required format\n\nLet $\\mathfrak{sl}(2, \\mathbb{R})$ be the Lie algebra of $2 \\times 2$ real matrices with trace zero, with the Lie bracket $[A, B] = AB - BA$. Show that the matrices $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and compute the structure constants with respect to this basis.",
    "run_id": "11",
    "outer_attempt": 1,
    "topic_slug": "nonassociative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete solution to the problem concerning the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n### 1. Definition and Basis Verification\n\nFirst, we define the vector space $\\mathfrak{sl}(2, \\mathbb{R})$. It consists of all $2 \\times 2$ matrices with real entries such that the trace (the sum of diagonal elements) is zero.\n\nLet $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\in M_2(\\mathbb{R})$.\nThe condition $\\text{tr}(A) = 0$ implies $a + d = 0$, or $d = -a$.\nThus, a general element of $\\mathfrak{sl}(2, \\mathbb{R})$ takes the form:\n$$ A = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} $$\nwhere $a, b, c \\in \\mathbb{R}$. This indicates that the space has dimension 3.\n\nWe are given the matrices:\n$$ H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} $$\n\n**Checking Trace Condition:**\n*   $\\text{tr}(H) = 1 + (-1) = 0$\n*   $\\text{tr}(X) = 0 + 0 = 0$\n*   $\\text{tr}(Y) = 0 + 0 = 0$\nAll three matrices belong to $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Linear Independence:**\nConsider a linear combination equal to the zero matrix:\n$$ c_1 H + c_2 X + c_3 Y = \\mathbf{0} $$\nSubstituting the matrices:\n$$ c_1 \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + c_2 \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c_3 \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ \\begin{pmatrix} c_1 & c_2 \\\\ c_3 & -c_1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nComparing entries implies $c_1 = 0$, $c_2 = 0$, and $c_3 = 0$. Thus, the set $\\{H, X, Y\\}$ is linearly independent.\n\n**Spanning:**\nAny generic matrix $A = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} \\in \\mathfrak{sl}(2, \\mathbb{R})$ can be written as:\n$$ A = a \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + b \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = aH + bX + cY $$\nTherefore, $\\{H, X, Y\\}$ spans $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Conclusion:**\nSince the set is linearly independent and spans the space, $\\{H, X, Y\\}$ forms a basis for $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n---\n\n### 2. Computation of Lie Brackets\n\nThe Lie bracket is defined as $[A, B] = AB - BA$. We compute the brackets for the pairs of basis vectors. Note that $[A, A] = 0$ and $[B, A] = -[A, B]$, so we only need to compute $[H, X]$, $[H, Y]$, and $[X, Y]$.\n\n**1. Computing $[H, X]$:**\n$$ HX = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = X $$\n$$ XH = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix} = -X $$\n$$ [H, X] = HX - XH = X - (-X) = 2X $$\n\n**2. Computing $[H, Y]$:**\n$$ HY = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix} = -Y $$\n$$ YH = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = Y $$\n$$ [H, Y] = HY - YH = -Y - Y = -2Y $$\n\n**3. Computing $[X, Y]$:**\n$$ XY = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ YX = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\n$$ [X, Y] = XY - YX = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = H $$\n\n**Summary of Commutation Relations:**\n$$ [H, X] = 2X $$\n$$ [H, Y] = -2Y $$\n$$ [X, Y] = H $$\n\n---\n\n### 3. Structure Constants\n\nThe structure constants $C_{ij}^k$ with respect to a basis $\\{e_1, e_2, e_3\\}$ are the coefficients defined by the relation $[e_i, e_j] = \\sum_{k=1}^3 C_{ij}^k e_k$.\n\nWe identify the ordered basis as:\n$e_1 = H$, $e_2 = X$, $e_3 = Y$.\n\nFrom the commutation relations derived above:\n\n1.  $[e_1, e_2] = [H, X] = 2X = 0e_1 + 2e_2 + 0e_3$\n    *   $C_{12}^1 = 0$\n    *   $\\mathbf{C_{12}^2 = 2}$\n    *   $C_{12}^3 = 0$\n\n2.  $[e_1, e_3] = [H, Y] = -2Y = 0e_1 + 0e_2 - 2e_3$\n    *   $C_{13}^1 = 0$\n    *   $C_{13}^2 = 0$\n    *   $\\mathbf{C_{13}^3 = -2}$\n\n3.  $[e_2, e_3] = [X, Y] = H = 1e_1 + 0e_2 + 0e_3$\n    *   $\\mathbf{C_{23}^1 = 1}$\n    *   $C_{23}^2 = 0$\n    *   $C_{23}^3 = 0$\n\nDue to the skew-symmetry of the Lie bracket ($[e_j, e_i] = -[e_i, e_j]$), we also have:\n*   $C_{21}^2 = -2$\n*   $C_{31}^3 = 2$\n*   $C_{32}^1 = -1$\n\nAll other structure constants where $i=j$ are zero because $[e_i, e_i] = 0$.\n\n**Final Result:**\n\nThe matrices $H, X, Y$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$. The non-zero structure constants for the ordered basis $(H, X, Y)$ are:\n$$ C_{HX}^X = 2, \\quad C_{HY}^Y = -2, \\quad C_{XY}^H = 1 $$\nand their skew-symmetric counterparts:\n$$ C_{XH}^X = -2, \\quad C_{YH}^Y = 2, \\quad C_{YX}^H = -1 $$",
        "raw_answer": "Here is the complete solution to the problem concerning the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n### 1. Definition and Basis Verification\n\nFirst, we define the vector space $\\mathfrak{sl}(2, \\mathbb{R})$. It consists of all $2 \\times 2$ matrices with real entries such that the trace (the sum of diagonal elements) is zero.\n\nLet $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\in M_2(\\mathbb{R})$.\nThe condition $\\text{tr}(A) = 0$ implies $a + d = 0$, or $d = -a$.\nThus, a general element of $\\mathfrak{sl}(2, \\mathbb{R})$ takes the form:\n$$ A = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} $$\nwhere $a, b, c \\in \\mathbb{R}$. This indicates that the space has dimension 3.\n\nWe are given the matrices:\n$$ H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} $$\n\n**Checking Trace Condition:**\n*   $\\text{tr}(H) = 1 + (-1) = 0$\n*   $\\text{tr}(X) = 0 + 0 = 0$\n*   $\\text{tr}(Y) = 0 + 0 = 0$\nAll three matrices belong to $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Linear Independence:**\nConsider a linear combination equal to the zero matrix:\n$$ c_1 H + c_2 X + c_3 Y = \\mathbf{0} $$\nSubstituting the matrices:\n$$ c_1 \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + c_2 \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c_3 \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ \\begin{pmatrix} c_1 & c_2 \\\\ c_3 & -c_1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nComparing entries implies $c_1 = 0$, $c_2 = 0$, and $c_3 = 0$. Thus, the set $\\{H, X, Y\\}$ is linearly independent.\n\n**Spanning:**\nAny generic matrix $A = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} \\in \\mathfrak{sl}(2, \\mathbb{R})$ can be written as:\n$$ A = a \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + b \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = aH + bX + cY $$\nTherefore, $\\{H, X, Y\\}$ spans $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Conclusion:**\nSince the set is linearly independent and spans the space, $\\{H, X, Y\\}$ forms a basis for $\\mathfrak{sl}(2, \\mathbb{R})$.\n\n---\n\n### 2. Computation of Lie Brackets\n\nThe Lie bracket is defined as $[A, B] = AB - BA$. We compute the brackets for the pairs of basis vectors. Note that $[A, A] = 0$ and $[B, A] = -[A, B]$, so we only need to compute $[H, X]$, $[H, Y]$, and $[X, Y]$.\n\n**1. Computing $[H, X]$:**\n$$ HX = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = X $$\n$$ XH = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix} = -X $$\n$$ [H, X] = HX - XH = X - (-X) = 2X $$\n\n**2. Computing $[H, Y]$:**\n$$ HY = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix} = -Y $$\n$$ YH = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = Y $$\n$$ [H, Y] = HY - YH = -Y - Y = -2Y $$\n\n**3. Computing $[X, Y]$:**\n$$ XY = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ YX = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\n$$ [X, Y] = XY - YX = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = H $$\n\n**Summary of Commutation Relations:**\n$$ [H, X] = 2X $$\n$$ [H, Y] = -2Y $$\n$$ [X, Y] = H $$\n\n---\n\n### 3. Structure Constants\n\nThe structure constants $C_{ij}^k$ with respect to a basis $\\{e_1, e_2, e_3\\}$ are the coefficients defined by the relation $[e_i, e_j] = \\sum_{k=1}^3 C_{ij}^k e_k$.\n\nWe identify the ordered basis as:\n$e_1 = H$, $e_2 = X$, $e_3 = Y$.\n\nFrom the commutation relations derived above:\n\n1.  $[e_1, e_2] = [H, X] = 2X = 0e_1 + 2e_2 + 0e_3$\n    *   $C_{12}^1 = 0$\n    *   $\\mathbf{C_{12}^2 = 2}$\n    *   $C_{12}^3 = 0$\n\n2.  $[e_1, e_3] = [H, Y] = -2Y = 0e_1 + 0e_2 - 2e_3$\n    *   $C_{13}^1 = 0$\n    *   $C_{13}^2 = 0$\n    *   $\\mathbf{C_{13}^3 = -2}$\n\n3.  $[e_2, e_3] = [X, Y] = H = 1e_1 + 0e_2 + 0e_3$\n    *   $\\mathbf{C_{23}^1 = 1}$\n    *   $C_{23}^2 = 0$\n    *   $C_{23}^3 = 0$\n\nDue to the skew-symmetry of the Lie bracket ($[e_j, e_i] = -[e_i, e_j]$), we also have:\n*   $C_{21}^2 = -2$\n*   $C_{31}^3 = 2$\n*   $C_{32}^1 = -1$\n\nAll other structure constants where $i=j$ are zero because $[e_i, e_i] = 0$.\n\n**Final Result:**\n\nThe matrices $H, X, Y$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$. The non-zero structure constants for the ordered basis $(H, X, Y)$ are:\n$$ C_{HX}^X = 2, \\quad C_{HY}^Y = -2, \\quad C_{XY}^H = 1 $$\nand their skew-symmetric counterparts:\n$$ C_{XH}^X = -2, \\quad C_{YH}^Y = 2, \\quad C_{YX}^H = -1 $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of category theory or homological algebra, along with a solution that is verifiable and follows the given guidelines.\n\n## Step 2: Identify the domain\nThe problem should be related to category theory or homological algebra.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we need to ensure it is well-posed, non-trivial, and solvable with the given constraints. Let's consider a problem that involves understanding and applying concepts from category theory.\n\n## Step 4: Generate the problem\nLet's formulate a problem that involves proving a property related to categories and functors.\n\n## Step 5: Write the problem\nProve that the functor $F: \\mathbf{Ab} \\to \\mathbf{Ab}$ defined by $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is exact.\n[/QUESTION]",
    "run_id": "12",
    "outer_attempt": 1,
    "topic_slug": "category_theory_and_homological_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the functor $F: \\mathbf{Ab} \\to \\mathbf{Ab}$ defined by $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is exact, we must show that it preserves short exact sequences.\n\n### 1. Definitions and Setup\n\nLet $\\mathbf{Ab}$ denote the category of abelian groups (equivalently, $\\mathbb{Z}$-modules).\nLet $0 \\to A \\xrightarrow{f} B \\xrightarrow{g} C \\to 0$ be a short exact sequence of abelian groups. This implies:\n1.  $f$ is injective ($\\ker(f) = \\{0\\}$).\n2.  $g$ is surjective ($\\text{im}(g) = C$).\n3.  $\\text{im}(f) = \\ker(g)$.\n\nWe apply the functor $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ to this sequence to obtain:\n$$0 \\to A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{f \\otimes 1} B \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{g \\otimes 1} C \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to 0$$\nTo prove $F$ is exact, we must verify that this induced sequence is also exact.\n\n### 2. Right Exactness\n\nIt is a standard result in homological algebra that the tensor product functor $- \\otimes_R M$ is right exact for any $R$-module $M$. Since $\\mathbb{Q}$ is a $\\mathbb{Z}$-module, the sequence:\n$$A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{f \\otimes 1} B \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{g \\otimes 1} C \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to 0$$\nis exact. This establishes that:\n1.  $g \\otimes 1$ is surjective.\n2.  $\\text{im}(f \\otimes 1) = \\ker(g \\otimes 1)$.\n\nThus, to complete the proof of exactness, we only need to show **Left Exactness**. Specifically, we must prove that $f \\otimes 1$ is injective.\n\n### 3. Left Exactness (Injectivity)\n\nWe need to show that if $f: A \\to B$ is injective, then $f \\otimes 1: A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to B \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is injective.\n\n**Lemma 1 (Structure of the Tensor Product):**\nFor any abelian group $G$, there is a natural isomorphism $\\eta: G \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{\\cong} S^{-1}G$, where $S = \\mathbb{Z} \\setminus \\{0\\}$ is the multiplicative set of non-zero integers, and $S^{-1}G$ is the localization of $G$ at $S$.\nThe isomorphism is given by $\\eta(g \\otimes \\frac{p}{q}) = \\frac{p \\cdot g}{q}$.\n\n**Proof of Lemma 1 (Sketch):**\nThe map $\\phi: G \\times \\mathbb{Q} \\to S^{-1}G$ defined by $(g, \\frac{p}{q}) \\mapsto \\frac{p \\cdot g}{q}$ is $\\mathbb{Z}$-bilinear. By the universal property of tensor products, this induces a homomorphism $\\eta: G \\otimes \\mathbb{Q} \\to S^{-1}G$.\nConversely, define $\\psi: S^{-1}G \\to G \\otimes \\mathbb{Q}$ by $\\frac{g}{q} \\mapsto g \\otimes \\frac{1}{q}$. One can check this is well-defined and inverse to $\\eta$.\n\n**Using the Lemma to prove Injectivity:**\nUsing the isomorphism $G \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\cong S^{-1}G$, checking the injectivity of $f \\otimes 1$ is equivalent to checking the injectivity of the induced map on localizations $S^{-1}f: S^{-1}A \\to S^{-1}B$, defined by $S^{-1}f(\\frac{a}{s}) = \\frac{f(a)}{s}$.\n\nLet $\\frac{a}{s} \\in S^{-1}A$ be an element in the kernel of $S^{-1}f$.\n$$S^{-1}f\\left(\\frac{a}{s}\\right) = \\frac{f(a)}{s} = 0 \\quad \\text{in } S^{-1}B$$\n\nBy the definition of equality in a localization, an element $\\frac{x}{y}$ is zero in $S^{-1}B$ if and only if there exists a $t \\in S$ such that $t \\cdot x = 0$ in $B$.\nApplying this here, there exists an integer $t \\in \\mathbb{Z} \\setminus \\{0\\}$ such that:\n$$t \\cdot f(a) = 0$$\n\nSince $f$ is a homomorphism, $t \\cdot f(a) = f(t \\cdot a)$. Thus:\n$$f(t \\cdot a) = 0$$\n\nSince $f$ is injective (by the hypothesis that the original sequence is exact), the kernel of $f$ is trivial. Therefore:\n$$t \\cdot a = 0$$\n\nNow we return to the element $\\frac{a}{s}$ in $S^{-1}A$. By the definition of localization, $\\frac{a}{s}$ is equal to $\\frac{t \\cdot a}{t \\cdot s}$. Substituting $t \\cdot a = 0$:\n$$\\frac{a}{s} = \\frac{0}{t \\cdot s} = 0 \\quad \\text{in } S^{-1}A$$\n\nSince the only element in the kernel of $S^{-1}f$ is $0$, the map is injective.\n\n### 4. Conclusion\n\nWe have shown:\n1.  The functor preserves surjectivity and exactness at the middle term (Right Exactness) due to general properties of the tensor product.\n2.  The functor preserves injectivity (Left Exactness) due to the properties of localization by non-zero integers (specifically, that $\\mathbb{Q}$ is torsion-free and thus flat over $\\mathbb{Z}$).\n\nSince $F$ preserves short exact sequences, $F$ is an **exact functor**.",
        "raw_answer": "To prove that the functor $F: \\mathbf{Ab} \\to \\mathbf{Ab}$ defined by $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is exact, we must show that it preserves short exact sequences.\n\n### 1. Definitions and Setup\n\nLet $\\mathbf{Ab}$ denote the category of abelian groups (equivalently, $\\mathbb{Z}$-modules).\nLet $0 \\to A \\xrightarrow{f} B \\xrightarrow{g} C \\to 0$ be a short exact sequence of abelian groups. This implies:\n1.  $f$ is injective ($\\ker(f) = \\{0\\}$).\n2.  $g$ is surjective ($\\text{im}(g) = C$).\n3.  $\\text{im}(f) = \\ker(g)$.\n\nWe apply the functor $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ to this sequence to obtain:\n$$0 \\to A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{f \\otimes 1} B \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{g \\otimes 1} C \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to 0$$\nTo prove $F$ is exact, we must verify that this induced sequence is also exact.\n\n### 2. Right Exactness\n\nIt is a standard result in homological algebra that the tensor product functor $- \\otimes_R M$ is right exact for any $R$-module $M$. Since $\\mathbb{Q}$ is a $\\mathbb{Z}$-module, the sequence:\n$$A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{f \\otimes 1} B \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{g \\otimes 1} C \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to 0$$\nis exact. This establishes that:\n1.  $g \\otimes 1$ is surjective.\n2.  $\\text{im}(f \\otimes 1) = \\ker(g \\otimes 1)$.\n\nThus, to complete the proof of exactness, we only need to show **Left Exactness**. Specifically, we must prove that $f \\otimes 1$ is injective.\n\n### 3. Left Exactness (Injectivity)\n\nWe need to show that if $f: A \\to B$ is injective, then $f \\otimes 1: A \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\to B \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is injective.\n\n**Lemma 1 (Structure of the Tensor Product):**\nFor any abelian group $G$, there is a natural isomorphism $\\eta: G \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\xrightarrow{\\cong} S^{-1}G$, where $S = \\mathbb{Z} \\setminus \\{0\\}$ is the multiplicative set of non-zero integers, and $S^{-1}G$ is the localization of $G$ at $S$.\nThe isomorphism is given by $\\eta(g \\otimes \\frac{p}{q}) = \\frac{p \\cdot g}{q}$.\n\n**Proof of Lemma 1 (Sketch):**\nThe map $\\phi: G \\times \\mathbb{Q} \\to S^{-1}G$ defined by $(g, \\frac{p}{q}) \\mapsto \\frac{p \\cdot g}{q}$ is $\\mathbb{Z}$-bilinear. By the universal property of tensor products, this induces a homomorphism $\\eta: G \\otimes \\mathbb{Q} \\to S^{-1}G$.\nConversely, define $\\psi: S^{-1}G \\to G \\otimes \\mathbb{Q}$ by $\\frac{g}{q} \\mapsto g \\otimes \\frac{1}{q}$. One can check this is well-defined and inverse to $\\eta$.\n\n**Using the Lemma to prove Injectivity:**\nUsing the isomorphism $G \\otimes_{\\mathbb{Z}} \\mathbb{Q} \\cong S^{-1}G$, checking the injectivity of $f \\otimes 1$ is equivalent to checking the injectivity of the induced map on localizations $S^{-1}f: S^{-1}A \\to S^{-1}B$, defined by $S^{-1}f(\\frac{a}{s}) = \\frac{f(a)}{s}$.\n\nLet $\\frac{a}{s} \\in S^{-1}A$ be an element in the kernel of $S^{-1}f$.\n$$S^{-1}f\\left(\\frac{a}{s}\\right) = \\frac{f(a)}{s} = 0 \\quad \\text{in } S^{-1}B$$\n\nBy the definition of equality in a localization, an element $\\frac{x}{y}$ is zero in $S^{-1}B$ if and only if there exists a $t \\in S$ such that $t \\cdot x = 0$ in $B$.\nApplying this here, there exists an integer $t \\in \\mathbb{Z} \\setminus \\{0\\}$ such that:\n$$t \\cdot f(a) = 0$$\n\nSince $f$ is a homomorphism, $t \\cdot f(a) = f(t \\cdot a)$. Thus:\n$$f(t \\cdot a) = 0$$\n\nSince $f$ is injective (by the hypothesis that the original sequence is exact), the kernel of $f$ is trivial. Therefore:\n$$t \\cdot a = 0$$\n\nNow we return to the element $\\frac{a}{s}$ in $S^{-1}A$. By the definition of localization, $\\frac{a}{s}$ is equal to $\\frac{t \\cdot a}{t \\cdot s}$. Substituting $t \\cdot a = 0$:\n$$\\frac{a}{s} = \\frac{0}{t \\cdot s} = 0 \\quad \\text{in } S^{-1}A$$\n\nSince the only element in the kernel of $S^{-1}f$ is $0$, the map is injective.\n\n### 4. Conclusion\n\nWe have shown:\n1.  The functor preserves surjectivity and exactness at the middle term (Right Exactness) due to general properties of the tensor product.\n2.  The functor preserves injectivity (Left Exactness) due to the properties of localization by non-zero integers (specifically, that $\\mathbb{Q}$ is torsion-free and thus flat over $\\mathbb{Z}$).\n\nSince $F$ preserves short exact sequences, $F$ is an **exact functor**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of K-theory, along with a solution that is verifiable and follows the given format.\n\n## Step 2: Identify the topic and relevant concepts\nThe topic is K-theory, which is a branch of algebraic topology that studies the properties of vector bundles and their relations to the underlying space. K-theory is crucial in various areas of mathematics and physics.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to understand what kind of questions are typically asked in K-theory. A common type of problem involves calculating the K-theory groups of a specific space or understanding the properties of K-theory groups under certain operations.\n\n## Step 4: Generate a specific problem\nLet's generate a problem related to the K-theory of a particular space. Consider the space $S^2$, the 2-sphere. A relevant problem could be to compute $K^0(S^2)$ and $K^1(S^2)$, which are related to the complex vector bundles on $S^2$.\n\n## Step 5: Formulate the problem in the required format\nWe need to provide a problem in the format: \"Compute $K^0(X)$ and $K^1(X)$ for $X = S^2$,\" where $S^2$ is the 2-sphere.\n\n## Step 6: Provide the solution\nTo solve this, we recall that $K^0(X)$ and $K^1(X)$ are related to the Grothendieck groups of complex vector bundles on $X$. For $S^2$, we know that $K^0(S^2)$ is related to the isomorphism classes of complex vector bundles on $S^2$, and $K^1(S^2)$ is related to the stable homotopy group $\\pi_1(S^2)$.\n\n## Step 7: Write down the problem and its solution\n### Problem\nCompute $K^0(S^2)$ and $K^1(S^2)$.",
    "run_id": "13",
    "outer_attempt": 1,
    "topic_slug": "k_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete, rigorous solution to the problem identified in the task.\n\n**Problem:** Compute the complex K-theory groups $K^0(S^2)$ and $K^1(S^2)$ for the 2-sphere $S^2$.\n\n### **Solution**\n\nWe aim to compute the unreduced complex K-theory groups $K^0(S^2)$ and $K^1(S^2)$. We assume $K^*(X)$ denotes the standard complex topological K-theory of a compact Hausdorff space $X$.\n\n**1. Preliminaries and Decomposition**\n\nFor a compact Hausdorff space $X$ with a chosen basepoint $x_0$, the unreduced K-theory group $K^0(X)$ splits as the direct sum of the reduced K-theory group $\\tilde{K}^0(X)$ and the K-theory of the point:\n$$ K^0(X) \\cong \\tilde{K}^0(X) \\oplus K^0(\\{x_0\\}). $$\nThe group $K^1(X)$ is defined as the reduced K-theory of the suspension of $X$ (up to a shift), specifically $K^1(X) \\cong \\tilde{K}^0(\\Sigma X)$. Note that for a point, $K^0(pt) \\cong \\mathbb{Z}$ and $K^1(pt) = 0$.\n\nFor the 2-sphere $S^2$, we have:\n1.  $K^0(S^2) \\cong \\tilde{K}^0(S^2) \\oplus \\mathbb{Z}$.\n2.  $K^1(S^2) \\cong \\tilde{K}^0(S^3)$.\n\nThe problem reduces to computing the reduced K-groups $\\tilde{K}^0(S^n)$ for $n=2$ and $n=3$.\n\n**2. Connection to Homotopy Groups of the Unitary Group**\n\nReduced K-theory groups of spheres are isomorphic to the homotopy groups of the classifying space of the unitary group (or the unitary group itself, depending on the index). Specifically, there is a standard isomorphism derived from the fact that vector bundles over $S^n$ are classified by the homotopy group of the transition maps on the equator $S^{n-1}$:\n$$ \\tilde{K}^0(S^n) \\cong \\pi_{n-1}(GL(\\infty, \\mathbb{C})) \\cong \\pi_{n-1}(U(\\infty)). $$\nHere $U(\\infty) = \\varinjlim U(n)$ is the stable unitary group.\n\n**3. Application of Bott Periodicity**\n\nBott Periodicity establishes the values of the homotopy groups $\\pi_k(U(\\infty))$. The periodicity theorem states that:\n$$ \\pi_k(U(\\infty)) \\cong \\pi_{k+2}(U(\\infty)) $$\nThe base cases are:\n*   $\\pi_0(U(\\infty)) = 0$ (since $U(n)$ is path-connected).\n*   $\\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\n\nUsing this periodicity, we can determine the groups for any $k \\geq 0$:\n*   For even $k$: $\\pi_k(U(\\infty)) \\cong \\pi_0(U(\\infty)) = 0$.\n*   For odd $k$: $\\pi_k(U(\\infty)) \\cong \\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\n\n**4. Computation of $K^0(S^2)$**\n\nUsing the relation $\\tilde{K}^0(S^n) \\cong \\pi_{n-1}(U(\\infty))$ for $n=2$:\n$$ \\tilde{K}^0(S^2) \\cong \\pi_1(U(\\infty)). $$\nFrom Bott Periodicity, $\\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\nThus, $\\tilde{K}^0(S^2) \\cong \\mathbb{Z}$.\n\nSubstituting this back into the decomposition formula:\n$$ K^0(S^2) \\cong \\tilde{K}^0(S^2) \\oplus \\mathbb{Z} \\cong \\mathbb{Z} \\oplus \\mathbb{Z}. $$\n\n*Note on Generators:* The group is generated by the class of the trivial line bundle, $[1]$, and the class of the tautological line bundle, $[H]$, via the identification $S^2 \\cong \\mathbb{C}P^1$. Alternatively, it is generated by $[1]$ and the reduced element $([H] - [1])$.\n\n**5. Computation of $K^1(S^2)$**\n\nWe use the definition $K^1(S^2) \\cong \\tilde{K}^0(S^3)$ (or equivalently $K^{-1}(S^2) \\cong [S^2, U(\\infty)]$).\nUsing the relation $\\tilde{K}^0(S^n) \\cong \\pi_{n-1}(U(\\infty))$ for $n=3$:\n$$ K^1(S^2) \\cong \\tilde{K}^0(S^3) \\cong \\pi_2(U(\\infty)). $$\nFrom Bott Periodicity, $\\pi_2(U(\\infty)) \\cong \\pi_0(U(\\infty)) = 0$.\nThus,\n$$ K^1(S^2) \\cong 0. $$\n\n**Conclusion**\n\nThe complex K-theory groups of the 2-sphere are:\n\n$$\nK^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}\n$$\n$$\nK^1(S^2) \\cong 0\n$$",
        "raw_answer": "Here is the complete, rigorous solution to the problem identified in the task.\n\n**Problem:** Compute the complex K-theory groups $K^0(S^2)$ and $K^1(S^2)$ for the 2-sphere $S^2$.\n\n### **Solution**\n\nWe aim to compute the unreduced complex K-theory groups $K^0(S^2)$ and $K^1(S^2)$. We assume $K^*(X)$ denotes the standard complex topological K-theory of a compact Hausdorff space $X$.\n\n**1. Preliminaries and Decomposition**\n\nFor a compact Hausdorff space $X$ with a chosen basepoint $x_0$, the unreduced K-theory group $K^0(X)$ splits as the direct sum of the reduced K-theory group $\\tilde{K}^0(X)$ and the K-theory of the point:\n$$ K^0(X) \\cong \\tilde{K}^0(X) \\oplus K^0(\\{x_0\\}). $$\nThe group $K^1(X)$ is defined as the reduced K-theory of the suspension of $X$ (up to a shift), specifically $K^1(X) \\cong \\tilde{K}^0(\\Sigma X)$. Note that for a point, $K^0(pt) \\cong \\mathbb{Z}$ and $K^1(pt) = 0$.\n\nFor the 2-sphere $S^2$, we have:\n1.  $K^0(S^2) \\cong \\tilde{K}^0(S^2) \\oplus \\mathbb{Z}$.\n2.  $K^1(S^2) \\cong \\tilde{K}^0(S^3)$.\n\nThe problem reduces to computing the reduced K-groups $\\tilde{K}^0(S^n)$ for $n=2$ and $n=3$.\n\n**2. Connection to Homotopy Groups of the Unitary Group**\n\nReduced K-theory groups of spheres are isomorphic to the homotopy groups of the classifying space of the unitary group (or the unitary group itself, depending on the index). Specifically, there is a standard isomorphism derived from the fact that vector bundles over $S^n$ are classified by the homotopy group of the transition maps on the equator $S^{n-1}$:\n$$ \\tilde{K}^0(S^n) \\cong \\pi_{n-1}(GL(\\infty, \\mathbb{C})) \\cong \\pi_{n-1}(U(\\infty)). $$\nHere $U(\\infty) = \\varinjlim U(n)$ is the stable unitary group.\n\n**3. Application of Bott Periodicity**\n\nBott Periodicity establishes the values of the homotopy groups $\\pi_k(U(\\infty))$. The periodicity theorem states that:\n$$ \\pi_k(U(\\infty)) \\cong \\pi_{k+2}(U(\\infty)) $$\nThe base cases are:\n*   $\\pi_0(U(\\infty)) = 0$ (since $U(n)$ is path-connected).\n*   $\\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\n\nUsing this periodicity, we can determine the groups for any $k \\geq 0$:\n*   For even $k$: $\\pi_k(U(\\infty)) \\cong \\pi_0(U(\\infty)) = 0$.\n*   For odd $k$: $\\pi_k(U(\\infty)) \\cong \\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\n\n**4. Computation of $K^0(S^2)$**\n\nUsing the relation $\\tilde{K}^0(S^n) \\cong \\pi_{n-1}(U(\\infty))$ for $n=2$:\n$$ \\tilde{K}^0(S^2) \\cong \\pi_1(U(\\infty)). $$\nFrom Bott Periodicity, $\\pi_1(U(\\infty)) \\cong \\mathbb{Z}$.\nThus, $\\tilde{K}^0(S^2) \\cong \\mathbb{Z}$.\n\nSubstituting this back into the decomposition formula:\n$$ K^0(S^2) \\cong \\tilde{K}^0(S^2) \\oplus \\mathbb{Z} \\cong \\mathbb{Z} \\oplus \\mathbb{Z}. $$\n\n*Note on Generators:* The group is generated by the class of the trivial line bundle, $[1]$, and the class of the tautological line bundle, $[H]$, via the identification $S^2 \\cong \\mathbb{C}P^1$. Alternatively, it is generated by $[1]$ and the reduced element $([H] - [1])$.\n\n**5. Computation of $K^1(S^2)$**\n\nWe use the definition $K^1(S^2) \\cong \\tilde{K}^0(S^3)$ (or equivalently $K^{-1}(S^2) \\cong [S^2, U(\\infty)]$).\nUsing the relation $\\tilde{K}^0(S^n) \\cong \\pi_{n-1}(U(\\infty))$ for $n=3$:\n$$ K^1(S^2) \\cong \\tilde{K}^0(S^3) \\cong \\pi_2(U(\\infty)). $$\nFrom Bott Periodicity, $\\pi_2(U(\\infty)) \\cong \\pi_0(U(\\infty)) = 0$.\nThus,\n$$ K^1(S^2) \\cong 0. $$\n\n**Conclusion**\n\nThe complex K-theory groups of the 2-sphere are:\n\n$$\nK^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}\n$$\n$$\nK^1(S^2) \\cong 0\n$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Group theory and generalizations\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Group theory and generalizations\nGroup theory is a branch of abstract algebra that studies the symmetric aspects of objects and the transformations that preserve those symmetries. A suitable topic could involve properties of groups, such as subgroup structures, homomorphisms, or specific types of groups like cyclic or symmetric groups.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider a topic like the classification of groups or the study of group homomorphisms. A potential problem could involve determining the number of homomorphisms between two given groups or analyzing the structure of a specific group.\n\n## Step 4: Generate a specific problem\nLet's consider the problem of finding the number of homomorphisms from the cyclic group of order 12, $\\mathbb{Z}_{12}$, to the symmetric group $S_3$. This involves understanding the structure of both groups and applying knowledge about homomorphisms.\n\n## Step 5: State the problem formally\nThe problem can be stated as: \"Let $\\mathbb{Z}_{12}$ be the cyclic group of order 12 and $S_3$ be the symmetric group on 3 elements. Determine the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\"\n\n## Step 6: Provide the solution\nTo solve this, we need to understand that a homomorphism $f: \\mathbb{Z}_{12} \\to S_3$ is determined by $f(1)$, where $1$ is a generator of $\\mathbb{Z}_{12}$. The element $f(1)$ must have an order that divides 12. $S_3$ has elements of orders 1, 2, and 3. We need to count how many elements in $S_3$ have orders that divide 12.\n\n## Step 7: Analyze the elements of $S_3$\n$S_3 = \\{e, (12), (13), (23), (123), (132)\\}$. The identity $e$ has order 1, the transpositions $(12), (13), (23)$ have order 2, and the 3-cycles $(123), (132)$ have order 3. The orders of elements in $S_3$ that divide 12 are 1, 2, and 3.\n\n## Step 8: Count the possible images of $1 \\in \\mathbb{Z}_{12}$\nThere is 1 element of order 1, 3 elements of order 2, and 2 elements of order 3. So, $f(1)$ can be any of these 6 elements because their orders divide 12.\n\n## Step 9: Conclude the number of homomorphisms\nSince $f(1)$ can be any of the 6 elements (1 of order 1, 3 of order 2, and 2 of order 3), there are 6 possible homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\n\n## Step 10: Format the problem and solution according to the required output format\n\nLet $\\mathbb{Z}_{12}$ be the cyclic group of order 12 and $S_3$ be the symmetric group on 3 elements. Determine the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.",
    "run_id": "14",
    "outer_attempt": 1,
    "topic_slug": "group_theory_and_generalizations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To determine the number of homomorphisms from the cyclic group $\\mathbb{Z}_{12}$ to the symmetric group $S_3$, we analyze the properties of homomorphisms originating from a finite cyclic group and the structure of the target group.\n\n### 1. General Properties of Homomorphisms from Cyclic Groups\n\nLet $G$ be a finite cyclic group of order $n$ generated by an element $g$ (so $G = \\langle g \\rangle$), and let $H$ be any group. A homomorphism $\\phi: G \\to H$ is completely determined by the image of the generator $g$. Let $h = \\phi(g)$.\n\nFor $\\phi$ to be a well-defined homomorphism, the mapping must respect the group relation $g^n = e_G$ (where $e_G$ is the identity in $G$). Applying $\\phi$, we must have:\n$$ \\phi(g^n) = \\phi(e_G) = e_H $$\n$$ (\\phi(g))^n = e_H $$\n$$ h^n = e_H $$\n\nThis implies that the order of the element $h$ in $H$, denoted $|h|$, must divide $n$. Conversely, if $h \\in H$ is an element such that $h^n = e_H$ (equivalently, $|h|$ divides $n$), then the map defined by $\\phi(g^k) = h^k$ is a well-defined homomorphism.\n\nThus, the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$ is equal to the number of elements $\\sigma \\in S_3$ such that the order of $\\sigma$ divides $12$.\n\n### 2. Analysis of the Target Group $S_3$\n\nThe symmetric group $S_3$ consists of all permutations of the set $\\{1, 2, 3\\}$. It has $|S_3| = 3! = 6$ elements. We list the elements and determine their orders:\n\n1.  **Identity:**\n    *   $e = (1)(2)(3)$\n    *   Order: 1\n\n2.  **Transpositions (2-cycles):**\n    *   $(12)$, $(13)$, $(23)$\n    *   Order: 2 (since $(ab)^2 = e$)\n\n3.  **3-cycles:**\n    *   $(123)$, $(132)$\n    *   Order: 3 (since $(abc)^3 = e$)\n\n### 3. Checking the Order Condition\n\nWe are looking for elements $\\sigma \\in S_3$ such that $|\\sigma|$ divides $12$. Let's check the orders found in Step 2:\n\n*   **Order 1:** Does 1 divide 12?\n    *   Yes ($12 = 1 \\times 12$).\n    *   Element: $e$. (1 element)\n\n*   **Order 2:** Does 2 divide 12?\n    *   Yes ($12 = 2 \\times 6$).\n    *   Elements: $(12), (13), (23)$. (3 elements)\n\n*   **Order 3:** Does 3 divide 12?\n    *   Yes ($12 = 3 \\times 4$).\n    *   Elements: $(123), (132)$. (2 elements)\n\n### 4. Conclusion\n\nEvery element in $S_3$ has an order (1, 2, or 3) that divides 12. Therefore, mapping the generator $1 \\in \\mathbb{Z}_{12}$ to any element of $S_3$ yields a valid homomorphism.\n\nSince there are 6 elements in $S_3$, there are 6 possible choices for the image of the generator.\n\n**The set of homomorphisms is:**\n1.  $\\phi_1(x) = e$ (The trivial homomorphism)\n2.  $\\phi_2(x) = (12)^x$ (where $(12)^x$ denotes applying the permutation $x$ times in the group operation sense)\n3.  $\\phi_3(x) = (13)^x$\n4.  $\\phi_4(x) = (23)^x$\n5.  $\\phi_5(x) = (123)^x$\n6.  $\\phi_6(x) = (132)^x$\n\nThe total number of homomorphisms is the sum of the counts of valid images:\n$$ 1 + 3 + 2 = 6 $$\n\n**Final Answer:**\nThere are **6** homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.",
        "raw_answer": "To determine the number of homomorphisms from the cyclic group $\\mathbb{Z}_{12}$ to the symmetric group $S_3$, we analyze the properties of homomorphisms originating from a finite cyclic group and the structure of the target group.\n\n### 1. General Properties of Homomorphisms from Cyclic Groups\n\nLet $G$ be a finite cyclic group of order $n$ generated by an element $g$ (so $G = \\langle g \\rangle$), and let $H$ be any group. A homomorphism $\\phi: G \\to H$ is completely determined by the image of the generator $g$. Let $h = \\phi(g)$.\n\nFor $\\phi$ to be a well-defined homomorphism, the mapping must respect the group relation $g^n = e_G$ (where $e_G$ is the identity in $G$). Applying $\\phi$, we must have:\n$$ \\phi(g^n) = \\phi(e_G) = e_H $$\n$$ (\\phi(g))^n = e_H $$\n$$ h^n = e_H $$\n\nThis implies that the order of the element $h$ in $H$, denoted $|h|$, must divide $n$. Conversely, if $h \\in H$ is an element such that $h^n = e_H$ (equivalently, $|h|$ divides $n$), then the map defined by $\\phi(g^k) = h^k$ is a well-defined homomorphism.\n\nThus, the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$ is equal to the number of elements $\\sigma \\in S_3$ such that the order of $\\sigma$ divides $12$.\n\n### 2. Analysis of the Target Group $S_3$\n\nThe symmetric group $S_3$ consists of all permutations of the set $\\{1, 2, 3\\}$. It has $|S_3| = 3! = 6$ elements. We list the elements and determine their orders:\n\n1.  **Identity:**\n    *   $e = (1)(2)(3)$\n    *   Order: 1\n\n2.  **Transpositions (2-cycles):**\n    *   $(12)$, $(13)$, $(23)$\n    *   Order: 2 (since $(ab)^2 = e$)\n\n3.  **3-cycles:**\n    *   $(123)$, $(132)$\n    *   Order: 3 (since $(abc)^3 = e$)\n\n### 3. Checking the Order Condition\n\nWe are looking for elements $\\sigma \\in S_3$ such that $|\\sigma|$ divides $12$. Let's check the orders found in Step 2:\n\n*   **Order 1:** Does 1 divide 12?\n    *   Yes ($12 = 1 \\times 12$).\n    *   Element: $e$. (1 element)\n\n*   **Order 2:** Does 2 divide 12?\n    *   Yes ($12 = 2 \\times 6$).\n    *   Elements: $(12), (13), (23)$. (3 elements)\n\n*   **Order 3:** Does 3 divide 12?\n    *   Yes ($12 = 3 \\times 4$).\n    *   Elements: $(123), (132)$. (2 elements)\n\n### 4. Conclusion\n\nEvery element in $S_3$ has an order (1, 2, or 3) that divides 12. Therefore, mapping the generator $1 \\in \\mathbb{Z}_{12}$ to any element of $S_3$ yields a valid homomorphism.\n\nSince there are 6 elements in $S_3$, there are 6 possible choices for the image of the generator.\n\n**The set of homomorphisms is:**\n1.  $\\phi_1(x) = e$ (The trivial homomorphism)\n2.  $\\phi_2(x) = (12)^x$ (where $(12)^x$ denotes applying the permutation $x$ times in the group operation sense)\n3.  $\\phi_3(x) = (13)^x$\n4.  $\\phi_4(x) = (23)^x$\n5.  $\\phi_5(x) = (123)^x$\n6.  $\\phi_6(x) = (132)^x$\n\nThe total number of homomorphisms is the sum of the counts of valid images:\n$$ 1 + 3 + 2 = 6 $$\n\n**Final Answer:**\nThere are **6** homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $G$ be a connected Lie group with Lie algebra $\\mathfrak{g}$. Suppose that $\\mathfrak{g}$ is simple and that $G$ has a discrete subgroup $\\Gamma$ such that $G/\\Gamma$ is compact. Prove that $\\Gamma$ is contained in the center of $G$ if and only if the adjoint representation of $G$ on $\\mathfrak{g}$ descends to a representation of $G/\\Gamma$.",
    "run_id": "15",
    "outer_attempt": 1,
    "topic_slug": "topological_groups_and_lie_groups",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve this problem, we must establish the logical equivalence between the condition that $\\Gamma$ is contained in the center of $G$ and the condition that the adjoint representation descends to $G/\\Gamma$.\n\n### Mathematical Setup and Definitions\n\nLet $G$ be a connected Lie group with simple Lie algebra $\\mathfrak{g}$. Let $\\Gamma$ be a discrete subgroup of $G$ such that the quotient space $G/\\Gamma$ is compact.\n\n1.  **The Adjoint Representation**:\n    The adjoint representation is the homomorphism $\\operatorname{Ad}: G \\to \\operatorname{GL}(\\mathfrak{g})$ defined by $\\operatorname{Ad}(g) = d(I_g)_e$, where $I_g(x) = gxg^{-1}$ is the conjugation map.\n    \n    The kernel of the adjoint representation is given by:\n    $$ \\ker(\\operatorname{Ad}) = \\{ g \\in G \\mid \\operatorname{Ad}(g) = \\operatorname{id}_{\\mathfrak{g}} \\} $$\n\n2.  **Center of $G$**:\n    The center of $G$ is $Z(G) = \\{ g \\in G \\mid gx = xg \\text{ for all } x \\in G \\}$.\n\n3.  **Descending a Representation**:\n    We say the representation $\\operatorname{Ad}: G \\to \\operatorname{GL}(\\mathfrak{g})$ **descends** to a representation of $G/\\Gamma$ if there exists a homomorphism $\\rho: G/\\Gamma \\to \\operatorname{GL}(\\mathfrak{g})$ such that $\\rho \\circ \\pi = \\operatorname{Ad}$, where $\\pi: G \\to G/\\Gamma$ is the canonical projection.\n    \n    For such a representation $\\rho$ to be well-defined:\n    - $G/\\Gamma$ must possess a group structure compatible with $\\pi$, which requires $\\Gamma$ to be a normal subgroup of $G$.\n    - The map $\\operatorname{Ad}$ must be constant on the fibers of $\\pi$, meaning $\\operatorname{Ad}(g\\gamma) = \\operatorname{Ad}(g)$ for all $g \\in G, \\gamma \\in \\Gamma$. This is equivalent to $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$.\n\n### Proof\n\nWe prove the equivalence in two directions.\n\n#### Direction 1: $(\\implies)$\n**Assume $\\Gamma \\subseteq Z(G)$. We must prove that $\\operatorname{Ad}$ descends to a representation of $G/\\Gamma$.**\n\n1.  **Group Structure of Quotient**:\n    Since $\\Gamma \\subseteq Z(G)$, $\\Gamma$ commutes with all elements of $G$. Therefore, $\\Gamma$ is a normal subgroup of $G$. Consequently, the quotient space $G/\\Gamma$ has a natural Lie group structure making the projection $\\pi: G \\to G/\\Gamma$ a Lie group homomorphism.\n\n2.  **Kernel of Adjoint**:\n    We examine the relationship between $Z(G)$ and $\\ker(\\operatorname{Ad})$.\n    For any $z \\in Z(G)$, $zgz^{-1} = g$ for all $g \\in G$. Differentiating with respect to $g$ at the identity $e$, we get $\\operatorname{Ad}(z) = \\operatorname{id}_{\\mathfrak{g}}$. Thus, $Z(G) \\subseteq \\ker(\\operatorname{Ad})$.\n    \n    Since $\\Gamma \\subseteq Z(G)$, it follows that $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$.\n\n3.  **Construction of Descended Map**:\n    Because $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$, the map $\\operatorname{Ad}: G \\to \\operatorname{GL}(\\mathfrak{g})$ factors through the quotient $G/\\Gamma$. Specifically, we define $\\rho: G/\\Gamma \\to \\operatorname{GL}(\\mathfrak{g})$ by\n    $$ \\rho(g\\Gamma) = \\operatorname{Ad}(g). $$\n    This map is well-defined because if $g_1\\Gamma = g_2\\Gamma$, then $g_2^{-1}g_1 \\in \\Gamma \\subseteq \\ker(\\operatorname{Ad})$, implying $\\operatorname{Ad}(g_1) = \\operatorname{Ad}(g_2)$. Since $\\pi$ is a surjective homomorphism and $\\operatorname{Ad}$ is a homomorphism, $\\rho$ is a homomorphism (a representation).\n\nThus, the adjoint representation descends to $G/\\Gamma$.\n\n#### Direction 2: $(\\Longleftarrow)$\n**Assume the adjoint representation of $G$ on $\\mathfrak{g}$ descends to a representation of $G/\\Gamma$. We must prove $\\Gamma \\subseteq Z(G)$.**\n\n1.  **Normality of $\\Gamma$**:\n    The existence of a representation of $G/\\Gamma$ presupposes that $G/\\Gamma$ is a group and the projection $\\pi: G \\to G/\\Gamma$ is a homomorphism. This implies that $\\Gamma = \\ker(\\pi)$ is a normal subgroup of $G$.\n\n2.  **Centrality of Discrete Normal Subgroups**:\n    We use the fact that $G$ is a connected Lie group and $\\Gamma$ is a discrete subgroup.\n    Consider the continuous map $\\phi: G \\times \\Gamma \\to \\Gamma$ defined by conjugation: $\\phi(g, \\gamma) = g\\gamma g^{-1}$. Since $\\Gamma$ is normal, the image lies in $\\Gamma$.\n    Fix an element $\\gamma \\in \\Gamma$. The map $f_{\\gamma}: G \\to \\Gamma$ defined by $g \\mapsto g\\gamma g^{-1}$ is continuous. Since $G$ is connected, the image $f_{\\gamma}(G)$ must be a connected subset of $\\Gamma$.\n    Because $\\Gamma$ is discrete, its only connected subsets are singletons. Therefore, $f_{\\gamma}(G)$ is a single point. Evaluating at $g=e$, we find $f_{\\gamma}(e) = \\gamma$.\n    Thus, $g\\gamma g^{-1} = \\gamma$ for all $g \\in G$.\n    This implies $\\gamma$ commutes with every element of $G$, so $\\gamma \\in Z(G)$.\n\n3.  **Conclusion**:\n    Since this holds for any $\\gamma \\in \\Gamma$, we have $\\Gamma \\subseteq Z(G)$.\n\n### Discussion of Constraints\n\nWhile the proof relies primarily on the connectivity of $G$ and the discreteness of $\\Gamma$, the additional assumptions ensure the setting is non-trivial and mathematically consistent:\n-   **$\\mathfrak{g}$ is simple**: This implies the center of the Lie algebra $\\mathfrak{z}(\\mathfrak{g})$ is trivial. Since the Lie algebra of $Z(G)$ is $\\mathfrak{z}(\\mathfrak{g})$, $Z(G)$ is a discrete subgroup. This is consistent with the assumption that $\\Gamma$ is discrete.\n-   **$G/\\Gamma$ is compact**: This ensures $\\Gamma$ is a uniform lattice. While not strictly required for the local algebraic logic of the equivalence, it frames the problem within the standard context of lattice theory in Lie groups. For instance, if $G$ is non-compact and simple, $Z(G)$ is the only source of finite normal subgroups, and any infinite normal subgroup would be dense (by simplicity), further constraining $\\Gamma$ to be central.\n\n### Final Answer\n\nWe have shown that if $\\Gamma \\subseteq Z(G)$, then $\\Gamma$ is a normal subgroup contained in $\\ker(\\operatorname{Ad})$, which allows the adjoint map to factor through the quotient group $G/\\Gamma$. Conversely, if the representation descends, $G/\\Gamma$ must be a group, implying $\\Gamma$ is normal. Since $G$ is connected and $\\Gamma$ is discrete, normality implies centrality.\n\nTherefore, $\\Gamma$ is contained in the center of $G$ if and only if the adjoint representation of $G$ on $\\mathfrak{g}$ descends to a representation of $G/\\Gamma$.",
        "raw_answer": "To solve this problem, we must establish the logical equivalence between the condition that $\\Gamma$ is contained in the center of $G$ and the condition that the adjoint representation descends to $G/\\Gamma$.\n\n### Mathematical Setup and Definitions\n\nLet $G$ be a connected Lie group with simple Lie algebra $\\mathfrak{g}$. Let $\\Gamma$ be a discrete subgroup of $G$ such that the quotient space $G/\\Gamma$ is compact.\n\n1.  **The Adjoint Representation**:\n    The adjoint representation is the homomorphism $\\operatorname{Ad}: G \\to \\operatorname{GL}(\\mathfrak{g})$ defined by $\\operatorname{Ad}(g) = d(I_g)_e$, where $I_g(x) = gxg^{-1}$ is the conjugation map.\n    \n    The kernel of the adjoint representation is given by:\n    $$ \\ker(\\operatorname{Ad}) = \\{ g \\in G \\mid \\operatorname{Ad}(g) = \\operatorname{id}_{\\mathfrak{g}} \\} $$\n\n2.  **Center of $G$**:\n    The center of $G$ is $Z(G) = \\{ g \\in G \\mid gx = xg \\text{ for all } x \\in G \\}$.\n\n3.  **Descending a Representation**:\n    We say the representation $\\operatorname{Ad}: G \\to \\operatorname{GL}(\\mathfrak{g})$ **descends** to a representation of $G/\\Gamma$ if there exists a homomorphism $\\rho: G/\\Gamma \\to \\operatorname{GL}(\\mathfrak{g})$ such that $\\rho \\circ \\pi = \\operatorname{Ad}$, where $\\pi: G \\to G/\\Gamma$ is the canonical projection.\n    \n    For such a representation $\\rho$ to be well-defined:\n    - $G/\\Gamma$ must possess a group structure compatible with $\\pi$, which requires $\\Gamma$ to be a normal subgroup of $G$.\n    - The map $\\operatorname{Ad}$ must be constant on the fibers of $\\pi$, meaning $\\operatorname{Ad}(g\\gamma) = \\operatorname{Ad}(g)$ for all $g \\in G, \\gamma \\in \\Gamma$. This is equivalent to $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$.\n\n### Proof\n\nWe prove the equivalence in two directions.\n\n#### Direction 1: $(\\implies)$\n**Assume $\\Gamma \\subseteq Z(G)$. We must prove that $\\operatorname{Ad}$ descends to a representation of $G/\\Gamma$.**\n\n1.  **Group Structure of Quotient**:\n    Since $\\Gamma \\subseteq Z(G)$, $\\Gamma$ commutes with all elements of $G$. Therefore, $\\Gamma$ is a normal subgroup of $G$. Consequently, the quotient space $G/\\Gamma$ has a natural Lie group structure making the projection $\\pi: G \\to G/\\Gamma$ a Lie group homomorphism.\n\n2.  **Kernel of Adjoint**:\n    We examine the relationship between $Z(G)$ and $\\ker(\\operatorname{Ad})$.\n    For any $z \\in Z(G)$, $zgz^{-1} = g$ for all $g \\in G$. Differentiating with respect to $g$ at the identity $e$, we get $\\operatorname{Ad}(z) = \\operatorname{id}_{\\mathfrak{g}}$. Thus, $Z(G) \\subseteq \\ker(\\operatorname{Ad})$.\n    \n    Since $\\Gamma \\subseteq Z(G)$, it follows that $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$.\n\n3.  **Construction of Descended Map**:\n    Because $\\Gamma \\subseteq \\ker(\\operatorname{Ad})$, the map $\\operatorname{Ad}: G \\to \\operatorname{GL}(\\mathfrak{g})$ factors through the quotient $G/\\Gamma$. Specifically, we define $\\rho: G/\\Gamma \\to \\operatorname{GL}(\\mathfrak{g})$ by\n    $$ \\rho(g\\Gamma) = \\operatorname{Ad}(g). $$\n    This map is well-defined because if $g_1\\Gamma = g_2\\Gamma$, then $g_2^{-1}g_1 \\in \\Gamma \\subseteq \\ker(\\operatorname{Ad})$, implying $\\operatorname{Ad}(g_1) = \\operatorname{Ad}(g_2)$. Since $\\pi$ is a surjective homomorphism and $\\operatorname{Ad}$ is a homomorphism, $\\rho$ is a homomorphism (a representation).\n\nThus, the adjoint representation descends to $G/\\Gamma$.\n\n#### Direction 2: $(\\Longleftarrow)$\n**Assume the adjoint representation of $G$ on $\\mathfrak{g}$ descends to a representation of $G/\\Gamma$. We must prove $\\Gamma \\subseteq Z(G)$.**\n\n1.  **Normality of $\\Gamma$**:\n    The existence of a representation of $G/\\Gamma$ presupposes that $G/\\Gamma$ is a group and the projection $\\pi: G \\to G/\\Gamma$ is a homomorphism. This implies that $\\Gamma = \\ker(\\pi)$ is a normal subgroup of $G$.\n\n2.  **Centrality of Discrete Normal Subgroups**:\n    We use the fact that $G$ is a connected Lie group and $\\Gamma$ is a discrete subgroup.\n    Consider the continuous map $\\phi: G \\times \\Gamma \\to \\Gamma$ defined by conjugation: $\\phi(g, \\gamma) = g\\gamma g^{-1}$. Since $\\Gamma$ is normal, the image lies in $\\Gamma$.\n    Fix an element $\\gamma \\in \\Gamma$. The map $f_{\\gamma}: G \\to \\Gamma$ defined by $g \\mapsto g\\gamma g^{-1}$ is continuous. Since $G$ is connected, the image $f_{\\gamma}(G)$ must be a connected subset of $\\Gamma$.\n    Because $\\Gamma$ is discrete, its only connected subsets are singletons. Therefore, $f_{\\gamma}(G)$ is a single point. Evaluating at $g=e$, we find $f_{\\gamma}(e) = \\gamma$.\n    Thus, $g\\gamma g^{-1} = \\gamma$ for all $g \\in G$.\n    This implies $\\gamma$ commutes with every element of $G$, so $\\gamma \\in Z(G)$.\n\n3.  **Conclusion**:\n    Since this holds for any $\\gamma \\in \\Gamma$, we have $\\Gamma \\subseteq Z(G)$.\n\n### Discussion of Constraints\n\nWhile the proof relies primarily on the connectivity of $G$ and the discreteness of $\\Gamma$, the additional assumptions ensure the setting is non-trivial and mathematically consistent:\n-   **$\\mathfrak{g}$ is simple**: This implies the center of the Lie algebra $\\mathfrak{z}(\\mathfrak{g})$ is trivial. Since the Lie algebra of $Z(G)$ is $\\mathfrak{z}(\\mathfrak{g})$, $Z(G)$ is a discrete subgroup. This is consistent with the assumption that $\\Gamma$ is discrete.\n-   **$G/\\Gamma$ is compact**: This ensures $\\Gamma$ is a uniform lattice. While not strictly required for the local algebraic logic of the equivalence, it frames the problem within the standard context of lattice theory in Lie groups. For instance, if $G$ is non-compact and simple, $Z(G)$ is the only source of finite normal subgroups, and any infinite normal subgroup would be dense (by simplicity), further constraining $\\Gamma$ to be central.\n\n### Final Answer\n\nWe have shown that if $\\Gamma \\subseteq Z(G)$, then $\\Gamma$ is a normal subgroup contained in $\\ker(\\operatorname{Ad})$, which allows the adjoint map to factor through the quotient group $G/\\Gamma$. Conversely, if the representation descends, $G/\\Gamma$ must be a group, implying $\\Gamma$ is normal. Since $G$ is connected and $\\Gamma$ is discrete, normality implies centrality.\n\nTherefore, $\\Gamma$ is contained in the center of $G$ if and only if the adjoint representation of $G$ on $\\mathfrak{g}$ descends to a representation of $G/\\Gamma$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the requirements for the problem.\nThe task is to generate a challenging but solvable mathematics problem in the domain of real functions, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Determine the specific area within real functions to focus on.\nGiven the broad domain of real functions, we can consider various aspects such as differentiation, integration, functional equations, or properties of specific types of functions (e.g., continuous, differentiable, integrable).\n\n## Step 3: Choose a specific topic within real functions that can be used to create a challenging problem.\nLet's consider the topic of functional equations, which involves finding a function that satisfies a given equation involving the function and its inputs.\n\n## Step 4: Generate a challenging problem in the chosen topic.\nConsider the functional equation $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for $x, y \\in \\mathbb{R}$, where $f: \\mathbb{R} \\to \\mathbb{R}$. The task is to find all $f$ that satisfy this equation.\n\n## Step 5: Ensure the problem is well-posed and meets the quality rubric.\nThe given functional equation is well-defined, and the task is clear. We need to verify that it's non-trivial and solvable.\n\n## Step 6: Provide a solution to the generated problem.\nTo solve $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$, let's first check if there are any obvious solutions. For $y = 0$, we get $f(x) = \\frac{f(x) + f(0)}{1 - f(x)f(0)}$. This simplifies to $f(x)(1 - f(x)f(0)) = f(x) + f(0)$, or $f(x) - f(x)^2f(0) = f(x) + f(0)$, leading to $-f(x)^2f(0) = f(0)$. If $f(0) \\neq 0$, this gives $f(x)^2 = -1$ for all $x$, which is impossible for real-valued $f$. Thus, $f(0) = 0$.\n\n## Step 7: Continue solving the functional equation.\nSetting $y = x$, we have $f(2x) = \\frac{2f(x)}{1 - f(x)^2}$. This is a useful relation but let's first explore the derivative of $f$ if it exists. Assuming $f$ is differentiable, differentiating both sides with respect to $y$ and then setting $y = 0$ gives $f'(x) = \\frac{f'(0)(1 + f(x)^2)}{(1 - f(x)f(0))^2} = f'(0)(1 + f(x)^2)$ because $f(0) = 0$. So, $f'(x) = f'(0)(1 + f(x)^2)$.\n\n## Step 8: Solve the differential equation obtained from the functional equation.\nThe differential equation $f'(x) = f'(0)(1 + f(x)^2)$ can be solved by separation of variables: $\\frac{df}{1 + f^2} = f'(0)dx$. Integrating both sides gives $\\arctan(f(x)) = f'(0)x + C$, where $C$ is a constant. Since $f(0) = 0$, we have $C = 0$. Thus, $f(x) = \\tan(f'(0)x)$.\n\n## Step 9: Verify that the solution satisfies the original functional equation.\nSubstituting $f(x) = \\tan(f'(0)x)$ into the original equation: $\\tan(f'(0)(x+y)) = \\frac{\\tan(f'(0)x) + \\tan(f'(0)y)}{1 - \\tan(f'(0)x)\\tan(f'(0)y)}$, which is a known trigonometric identity, thus verifying that $f(x) = \\tan(f'(0)x)$ is a solution.\n\n## Step 10: Check if there are any constraints on $f'(0)$.\nFor $f(x) = \\tan(f'(0)x)$ to be defined for all $x \\in \\mathbb{R}$, $f'(0)$ must be $0$, otherwise, $f(x)$ will have discontinuities. If $f'(0) = 0$, then $f(x) = 0$ for all $x$, which is indeed a solution.\n\n## Step 11: Formulate the final problem and solution.\nLet's formulate the problem: \"Find all $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for all $x, y \\in \\mathbb{R}$.\"\n\n\nFind all $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for all $x, y \\in \\mathbb{R}$.",
    "run_id": "16",
    "outer_attempt": 1,
    "topic_slug": "real_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ satisfying the equation\n$$f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$$\nfor all $x, y \\in \\mathbb{R}$, we proceed with the following steps.\n\n### Step 1: Preliminary Analysis and Values\n\nFirst, we determine the value of $f(0)$. Letting $y = 0$ in the functional equation, we get:\n$$f(x) = \\frac{f(x) + f(0)}{1 - f(x)f(0)}$$\nAssuming the denominator is non-zero, we multiply through:\n$$f(x) [1 - f(x)f(0)] = f(x) + f(0)$$\n$$f(x) - f(x)^2 f(0) = f(x) + f(0)$$\n$$- f(x)^2 f(0) = f(0)$$\n$$f(0) [1 + f(x)^2] = 0$$\nSince $1 + f(x)^2 \\geq 1$ for any real $f(x)$, it is never zero. Therefore, we must have:\n$$f(0) = 0$$\n\nNext, we establish that $f(x)$ is an odd function. Letting $y = -x$, and using $f(0)=0$:\n$$f(0) = \\frac{f(x) + f(-x)}{1 - f(x)f(-x)} \\implies 0 = \\frac{f(x) + f(-x)}{1 - f(x)f(-x)}$$\nThis implies the numerator must be zero:\n$$f(x) + f(-x) = 0 \\implies f(-x) = -f(x)$$\n\n### Step 2: Domain Constraints and Range\n\nThe functional equation is valid only if the denominator $1 - f(x)f(y)$ is never zero. Thus, for all $x, y \\in \\mathbb{R}$:\n$$f(x)f(y) \\neq 1$$\nSetting $y = x$, we have $f(x)^2 \\neq 1$. This implies:\n$$f(x) \\neq 1 \\quad \\text{and} \\quad f(x) \\neq -1 \\quad \\text{for all } x \\in \\mathbb{R}.$$\n\n### Step 3: Transforming the Equation\n\nSince $f(x)$ never takes the values $\\pm 1$, the function $\\arctan(f(x))$ is well-defined. However, the standard arctangent maps to $(-\\pi/2, \\pi/2)$, while the general solution to $\\tan \\theta = z$ is $\\theta = \\arctan z + k\\pi$.\n\nLet us express $f(x)$ in terms of an auxiliary function $L(x)$:\n$$f(x) = \\tan(L(x))$$\nwhere $L(x)$ is a real-valued function. Substituting this into the original equation:\n$$\\tan(L(x+y)) = \\frac{\\tan(L(x)) + \\tan(L(y))}{1 - \\tan(L(x))\\tan(L(y))}$$\nBy the tangent addition formula, the right-hand side is $\\tan(L(x) + L(y))$. Thus:\n$$\\tan(L(x+y)) = \\tan(L(x) + L(y))$$\nThe general solution to $\\tan \\alpha = \\tan \\beta$ is $\\alpha = \\beta + k\\pi$ for some integer $k$. Therefore:\n$$L(x+y) = L(x) + L(y) + \\pi k(x, y)$$\nwhere $k(x, y)$ is an integer-valued function. This indicates that $L$ behaves like an additive function modulo $\\pi$. We can choose $L$ specifically to be an additive function $A: \\mathbb{R} \\to \\mathbb{R}$ satisfying the Cauchy functional equation:\n$$A(x+y) = A(x) + A(y)$$\nThen $f(x) = \\tan(A(x))$ satisfies the functional equation, provided the denominator condition is met.\n\n### Step 4: Validating the Constraint\n\nWe must ensure that the denominator in the original equation is never zero.\n$$1 - f(x)f(y) \\neq 0 \\iff 1 - \\tan(A(x))\\tan(A(y)) \\neq 0$$\nUsing the identity $\\cos(A+B) = \\cos A \\cos B - \\sin A \\sin B = \\cos A \\cos B (1 - \\tan A \\tan B)$, the condition is equivalent to:\n$$\\cos(A(x) + A(y)) \\neq 0$$\nThis holds if and only if:\n$$A(x) + A(y) \\neq \\frac{\\pi}{2} + n\\pi \\quad \\text{for all } n \\in \\mathbb{Z}$$\nSince $A$ is additive, $A(x+y) = A(x) + A(y)$. Let $z = x+y$. As $x$ and $y$ vary over $\\mathbb{R}$, $z$ varies over $\\mathbb{R}$. The condition simplifies to:\n$$\\text{Range}(A) \\cap \\left\\{ \\frac{\\pi}{2} + n\\pi \\mid n \\in \\mathbb{Z} \\right\\} = \\emptyset$$\n\n### Step 5: Classifying Solutions\n\n**Case 1: Continuous or Measurable Solutions**\nIf $f$ is continuous (or even Lebesgue measurable), then $A(x) = \\arctan(f(x))$ (lifted continuously) must be continuous. The only continuous solutions to the Cauchy functional equation $A(x+y) = A(x) + A(y)$ are of the form $A(x) = cx$ for some constant $c \\in \\mathbb{R}$.\nThe condition that the range of $A(x) = cx$ avoids the set $\\{\\pi/2 + n\\pi\\}$ implies that the range cannot be all of $\\mathbb{R}$. Since the range of $A(x) = cx$ is $\\mathbb{R}$ unless $c=0$ (in which case the range is $\\{0\\}$), we must have $c = 0$.\nIf $c = 0$, then $A(x) = 0$ for all $x$, which implies $f(x) = \\tan(0) = 0$.\n\n**Case 2: General Solutions**\nUsing the Axiom of Choice, there exist non-continuous additive functions (constructed using a Hamel basis of $\\mathbb{R}$ over $\\mathbb{Q}$).\nLet $A: \\mathbb{R} \\to \\mathbb{R}$ be an additive function. For $f(x) = \\tan(A(x))$ to be a solution, the image of $A$ must avoid the values $\\frac{\\pi}{2} + n\\pi$.\nOne class of such functions can be constructed by defining $A: \\mathbb{R} \\to \\mathbb{Q}$ (viewing $\\mathbb{R}$ as a vector space over $\\mathbb{Q}$ and mapping basis elements to rationals). Since $\\pi$ is irrational, the set $\\mathbb{Q}$ contains no elements of the form $\\frac{\\pi}{2} + n\\pi$ (which are irrational). Thus, any additive function with a rational range yields a valid non-trivial solution.\n\n### Conclusion\n\nThe solutions fall into two categories depending on regularity assumptions:\n\n1.  **Continuous Solution:** The only continuous function satisfying the equation is the zero function:\n    $$f(x) = 0$$\n\n2.  **General Solution:** The set of all solutions is given by:\n    $$f(x) = \\tan(A(x))$$\n    where $A: \\mathbb{R} \\to \\mathbb{R}$ is an additive function (i.e., $A(x+y) = A(x) + A(y)$) such that the range of $A$ contains no values of the form $\\frac{\\pi}{2} + n\\pi$ for any integer $n$.",
        "raw_answer": "To find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ satisfying the equation\n$$f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$$\nfor all $x, y \\in \\mathbb{R}$, we proceed with the following steps.\n\n### Step 1: Preliminary Analysis and Values\n\nFirst, we determine the value of $f(0)$. Letting $y = 0$ in the functional equation, we get:\n$$f(x) = \\frac{f(x) + f(0)}{1 - f(x)f(0)}$$\nAssuming the denominator is non-zero, we multiply through:\n$$f(x) [1 - f(x)f(0)] = f(x) + f(0)$$\n$$f(x) - f(x)^2 f(0) = f(x) + f(0)$$\n$$- f(x)^2 f(0) = f(0)$$\n$$f(0) [1 + f(x)^2] = 0$$\nSince $1 + f(x)^2 \\geq 1$ for any real $f(x)$, it is never zero. Therefore, we must have:\n$$f(0) = 0$$\n\nNext, we establish that $f(x)$ is an odd function. Letting $y = -x$, and using $f(0)=0$:\n$$f(0) = \\frac{f(x) + f(-x)}{1 - f(x)f(-x)} \\implies 0 = \\frac{f(x) + f(-x)}{1 - f(x)f(-x)}$$\nThis implies the numerator must be zero:\n$$f(x) + f(-x) = 0 \\implies f(-x) = -f(x)$$\n\n### Step 2: Domain Constraints and Range\n\nThe functional equation is valid only if the denominator $1 - f(x)f(y)$ is never zero. Thus, for all $x, y \\in \\mathbb{R}$:\n$$f(x)f(y) \\neq 1$$\nSetting $y = x$, we have $f(x)^2 \\neq 1$. This implies:\n$$f(x) \\neq 1 \\quad \\text{and} \\quad f(x) \\neq -1 \\quad \\text{for all } x \\in \\mathbb{R}.$$\n\n### Step 3: Transforming the Equation\n\nSince $f(x)$ never takes the values $\\pm 1$, the function $\\arctan(f(x))$ is well-defined. However, the standard arctangent maps to $(-\\pi/2, \\pi/2)$, while the general solution to $\\tan \\theta = z$ is $\\theta = \\arctan z + k\\pi$.\n\nLet us express $f(x)$ in terms of an auxiliary function $L(x)$:\n$$f(x) = \\tan(L(x))$$\nwhere $L(x)$ is a real-valued function. Substituting this into the original equation:\n$$\\tan(L(x+y)) = \\frac{\\tan(L(x)) + \\tan(L(y))}{1 - \\tan(L(x))\\tan(L(y))}$$\nBy the tangent addition formula, the right-hand side is $\\tan(L(x) + L(y))$. Thus:\n$$\\tan(L(x+y)) = \\tan(L(x) + L(y))$$\nThe general solution to $\\tan \\alpha = \\tan \\beta$ is $\\alpha = \\beta + k\\pi$ for some integer $k$. Therefore:\n$$L(x+y) = L(x) + L(y) + \\pi k(x, y)$$\nwhere $k(x, y)$ is an integer-valued function. This indicates that $L$ behaves like an additive function modulo $\\pi$. We can choose $L$ specifically to be an additive function $A: \\mathbb{R} \\to \\mathbb{R}$ satisfying the Cauchy functional equation:\n$$A(x+y) = A(x) + A(y)$$\nThen $f(x) = \\tan(A(x))$ satisfies the functional equation, provided the denominator condition is met.\n\n### Step 4: Validating the Constraint\n\nWe must ensure that the denominator in the original equation is never zero.\n$$1 - f(x)f(y) \\neq 0 \\iff 1 - \\tan(A(x))\\tan(A(y)) \\neq 0$$\nUsing the identity $\\cos(A+B) = \\cos A \\cos B - \\sin A \\sin B = \\cos A \\cos B (1 - \\tan A \\tan B)$, the condition is equivalent to:\n$$\\cos(A(x) + A(y)) \\neq 0$$\nThis holds if and only if:\n$$A(x) + A(y) \\neq \\frac{\\pi}{2} + n\\pi \\quad \\text{for all } n \\in \\mathbb{Z}$$\nSince $A$ is additive, $A(x+y) = A(x) + A(y)$. Let $z = x+y$. As $x$ and $y$ vary over $\\mathbb{R}$, $z$ varies over $\\mathbb{R}$. The condition simplifies to:\n$$\\text{Range}(A) \\cap \\left\\{ \\frac{\\pi}{2} + n\\pi \\mid n \\in \\mathbb{Z} \\right\\} = \\emptyset$$\n\n### Step 5: Classifying Solutions\n\n**Case 1: Continuous or Measurable Solutions**\nIf $f$ is continuous (or even Lebesgue measurable), then $A(x) = \\arctan(f(x))$ (lifted continuously) must be continuous. The only continuous solutions to the Cauchy functional equation $A(x+y) = A(x) + A(y)$ are of the form $A(x) = cx$ for some constant $c \\in \\mathbb{R}$.\nThe condition that the range of $A(x) = cx$ avoids the set $\\{\\pi/2 + n\\pi\\}$ implies that the range cannot be all of $\\mathbb{R}$. Since the range of $A(x) = cx$ is $\\mathbb{R}$ unless $c=0$ (in which case the range is $\\{0\\}$), we must have $c = 0$.\nIf $c = 0$, then $A(x) = 0$ for all $x$, which implies $f(x) = \\tan(0) = 0$.\n\n**Case 2: General Solutions**\nUsing the Axiom of Choice, there exist non-continuous additive functions (constructed using a Hamel basis of $\\mathbb{R}$ over $\\mathbb{Q}$).\nLet $A: \\mathbb{R} \\to \\mathbb{R}$ be an additive function. For $f(x) = \\tan(A(x))$ to be a solution, the image of $A$ must avoid the values $\\frac{\\pi}{2} + n\\pi$.\nOne class of such functions can be constructed by defining $A: \\mathbb{R} \\to \\mathbb{Q}$ (viewing $\\mathbb{R}$ as a vector space over $\\mathbb{Q}$ and mapping basis elements to rationals). Since $\\pi$ is irrational, the set $\\mathbb{Q}$ contains no elements of the form $\\frac{\\pi}{2} + n\\pi$ (which are irrational). Thus, any additive function with a rational range yields a valid non-trivial solution.\n\n### Conclusion\n\nThe solutions fall into two categories depending on regularity assumptions:\n\n1.  **Continuous Solution:** The only continuous function satisfying the equation is the zero function:\n    $$f(x) = 0$$\n\n2.  **General Solution:** The set of all solutions is given by:\n    $$f(x) = \\tan(A(x))$$\n    where $A: \\mathbb{R} \\to \\mathbb{R}$ is an additive function (i.e., $A(x+y) = A(x) + A(y)$) such that the range of $A$ contains no values of the form $\\frac{\\pi}{2} + n\\pi$ for any integer $n$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $f: [0,1] \\to \\mathbb{R}$ be a bounded measurable function. Prove that $\\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) dx = 0$.",
    "run_id": "17",
    "outer_attempt": 1,
    "topic_slug": "measure_and_integration",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that $\\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) \\, dx = 0$ for a bounded measurable function $f: [0,1] \\to \\mathbb{R}$, we will utilize the density of step functions in $L^1([0,1])$. This result is a specific instance of the Riemann-Lebesgue Lemma.\n\n### 1. Preliminary: Integrability of $f$\n\nSince $f$ is measurable and bounded on the finite interval $[0,1]$, it is Lebesgue integrable.\nLet $M > 0$ be a bound such that $|f(x)| \\le M$ for all $x \\in [0,1]$.\n$$ \\|f\\|_{L^1} = \\int_{0}^{1} |f(x)| \\, dx \\le \\int_{0}^{1} M \\, dx = M < \\infty. $$\nThus, $f \\in L^1([0,1])$.\n\n### 2. Approximation Strategy\n\nWe aim to show that for any $\\epsilon > 0$, the magnitude of the integral is eventually less than $\\epsilon$. The strategy is to approximate $f$ by a simpler function $\\phi$ (a step function) for which the limit is easily calculated, and then bound the error.\n\nLet $\\epsilon > 0$ be given.\n\nBecause the set of step functions (finite linear combinations of characteristic functions of intervals) is dense in $L^1([0,1])$, there exists a step function $\\phi: [0,1] \\to \\mathbb{R}$ such that:\n$$ \\int_{0}^{1} |f(x) - \\phi(x)| \\, dx < \\frac{\\epsilon}{2}. $$\n\n**Justification for density:**\n1.  Simple functions (linear combinations of characteristic functions of measurable sets) are dense in $L^1$ (by definition of the Lebesgue integral and the Dominated Convergence Theorem).\n2.  For any measurable set $E \\subset [0,1]$ and $\\delta > 0$, there exists a finite union of intervals $U$ such that the measure of the symmetric difference $\\mu(E \\Delta U) < \\delta$ (Regularity of Lebesgue measure).\n3.  Consequently, characteristic functions of intervals can approximate simple functions in the $L^1$ norm.\n\n### 3. Decomposition of the Integral\n\nLet $I_n = \\int_{0}^{1} f(x) \\sin(nx) \\, dx$. We decompose $I_n$ based on the approximation $\\phi$:\n$$ I_n = \\int_{0}^{1} (f(x) - \\phi(x)) \\sin(nx) \\, dx + \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx. $$\n\nApplying the triangle inequality:\n$$ |I_n| \\le \\left| \\int_{0}^{1} (f(x) - \\phi(x)) \\sin(nx) \\, dx \\right| + \\left| \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx \\right|. $$\n\n### 4. Bounding the First Term (Approximation Error)\n\nUsing the fact that $|\\sin(nx)| \\le 1$ for all real $x$ and $n$:\n$$ \\left| \\int_{0}^{1} (f(x) - \\phi(x)) \\sin(nx) \\, dx \\right| \\le \\int_{0}^{1} |f(x) - \\phi(x)| |\\sin(nx)| \\, dx \\le \\int_{0}^{1} |f(x) - \\phi(x)| \\, dx. $$\nBy our choice of $\\phi$ in Step 2:\n$$ \\int_{0}^{1} |f(x) - \\phi(x)| \\, dx < \\frac{\\epsilon}{2}. $$\n\n### 5. Bounding the Second Term (Calculation for Step Functions)\n\nThe step function $\\phi$ can be written as:\n$$ \\phi(x) = \\sum_{j=1}^{k} c_j \\chi_{(a_j, b_j)}(x), $$\nwhere $c_j \\in \\mathbb{R}$ are constants and $(a_j, b_j) \\subseteq [0,1]$ are sub-intervals.\n\nBy linearity of the integral:\n$$ \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx = \\sum_{j=1}^{k} c_j \\int_{a_j}^{b_j} \\sin(nx) \\, dx. $$\n\nWe compute the integral for a single interval $(a, b)$:\n$$ \\int_{a}^{b} \\sin(nx) \\, dx = \\left[ -\\frac{\\cos(nx)}{n} \\right]_{a}^{b} = \\frac{\\cos(na) - \\cos(nb)}{n}. $$\nSince $|\\cos(y)| \\le 1$, we have:\n$$ \\left| \\int_{a}^{b} \\sin(nx) \\, dx \\right| \\le \\frac{|\\cos(na)| + |\\cos(nb)|}{n} \\le \\frac{2}{n}. $$\n\nApplying this bound to the sum:\n$$ \\left| \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx \\right| = \\left| \\sum_{j=1}^{k} c_j \\int_{a_j}^{b_j} \\sin(nx) \\, dx \\right| \\le \\sum_{j=1}^{k} |c_j| \\frac{2}{n} = \\frac{2}{n} \\sum_{j=1}^{k} |c_j|. $$\n\nLet $C = 2 \\sum_{j=1}^{k} |c_j|$. Note that $C$ is a constant independent of $n$ (though it depends on $\\phi$, and thus on $\\epsilon$).\nWe can choose an integer $N$ sufficiently large such that for all $n > N$:\n$$ \\frac{C}{n} < \\frac{\\epsilon}{2}. $$\nSpecifically, choose $N > \\frac{2C}{\\epsilon}$.\n\n### 6. Conclusion\n\nFor the chosen $\\epsilon$, we found $N$ such that for all $n > N$:\n$$ |I_n| < \\frac{\\epsilon}{2} \\quad (\\text{from the approximation error}) $$\n$$ + \\frac{\\epsilon}{2} \\quad (\\text{from the step function integral}) $$\n$$ = \\epsilon. $$\n\nSince $\\epsilon$ was arbitrary, we conclude:\n$$ \\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) \\, dx = 0. $$",
        "raw_answer": "To prove that $\\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) \\, dx = 0$ for a bounded measurable function $f: [0,1] \\to \\mathbb{R}$, we will utilize the density of step functions in $L^1([0,1])$. This result is a specific instance of the Riemann-Lebesgue Lemma.\n\n### 1. Preliminary: Integrability of $f$\n\nSince $f$ is measurable and bounded on the finite interval $[0,1]$, it is Lebesgue integrable.\nLet $M > 0$ be a bound such that $|f(x)| \\le M$ for all $x \\in [0,1]$.\n$$ \\|f\\|_{L^1} = \\int_{0}^{1} |f(x)| \\, dx \\le \\int_{0}^{1} M \\, dx = M < \\infty. $$\nThus, $f \\in L^1([0,1])$.\n\n### 2. Approximation Strategy\n\nWe aim to show that for any $\\epsilon > 0$, the magnitude of the integral is eventually less than $\\epsilon$. The strategy is to approximate $f$ by a simpler function $\\phi$ (a step function) for which the limit is easily calculated, and then bound the error.\n\nLet $\\epsilon > 0$ be given.\n\nBecause the set of step functions (finite linear combinations of characteristic functions of intervals) is dense in $L^1([0,1])$, there exists a step function $\\phi: [0,1] \\to \\mathbb{R}$ such that:\n$$ \\int_{0}^{1} |f(x) - \\phi(x)| \\, dx < \\frac{\\epsilon}{2}. $$\n\n**Justification for density:**\n1.  Simple functions (linear combinations of characteristic functions of measurable sets) are dense in $L^1$ (by definition of the Lebesgue integral and the Dominated Convergence Theorem).\n2.  For any measurable set $E \\subset [0,1]$ and $\\delta > 0$, there exists a finite union of intervals $U$ such that the measure of the symmetric difference $\\mu(E \\Delta U) < \\delta$ (Regularity of Lebesgue measure).\n3.  Consequently, characteristic functions of intervals can approximate simple functions in the $L^1$ norm.\n\n### 3. Decomposition of the Integral\n\nLet $I_n = \\int_{0}^{1} f(x) \\sin(nx) \\, dx$. We decompose $I_n$ based on the approximation $\\phi$:\n$$ I_n = \\int_{0}^{1} (f(x) - \\phi(x)) \\sin(nx) \\, dx + \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx. $$\n\nApplying the triangle inequality:\n$$ |I_n| \\le \\left| \\int_{0}^{1} (f(x) - \\phi(x)) \\sin(nx) \\, dx \\right| + \\left| \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx \\right|. $$\n\n### 4. Bounding the First Term (Approximation Error)\n\nUsing the fact that $|\\sin(nx)| \\le 1$ for all real $x$ and $n$:\n$$ \\left| \\int_{0}^{1} (f(x) - \\phi(x)) \\sin(nx) \\, dx \\right| \\le \\int_{0}^{1} |f(x) - \\phi(x)| |\\sin(nx)| \\, dx \\le \\int_{0}^{1} |f(x) - \\phi(x)| \\, dx. $$\nBy our choice of $\\phi$ in Step 2:\n$$ \\int_{0}^{1} |f(x) - \\phi(x)| \\, dx < \\frac{\\epsilon}{2}. $$\n\n### 5. Bounding the Second Term (Calculation for Step Functions)\n\nThe step function $\\phi$ can be written as:\n$$ \\phi(x) = \\sum_{j=1}^{k} c_j \\chi_{(a_j, b_j)}(x), $$\nwhere $c_j \\in \\mathbb{R}$ are constants and $(a_j, b_j) \\subseteq [0,1]$ are sub-intervals.\n\nBy linearity of the integral:\n$$ \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx = \\sum_{j=1}^{k} c_j \\int_{a_j}^{b_j} \\sin(nx) \\, dx. $$\n\nWe compute the integral for a single interval $(a, b)$:\n$$ \\int_{a}^{b} \\sin(nx) \\, dx = \\left[ -\\frac{\\cos(nx)}{n} \\right]_{a}^{b} = \\frac{\\cos(na) - \\cos(nb)}{n}. $$\nSince $|\\cos(y)| \\le 1$, we have:\n$$ \\left| \\int_{a}^{b} \\sin(nx) \\, dx \\right| \\le \\frac{|\\cos(na)| + |\\cos(nb)|}{n} \\le \\frac{2}{n}. $$\n\nApplying this bound to the sum:\n$$ \\left| \\int_{0}^{1} \\phi(x) \\sin(nx) \\, dx \\right| = \\left| \\sum_{j=1}^{k} c_j \\int_{a_j}^{b_j} \\sin(nx) \\, dx \\right| \\le \\sum_{j=1}^{k} |c_j| \\frac{2}{n} = \\frac{2}{n} \\sum_{j=1}^{k} |c_j|. $$\n\nLet $C = 2 \\sum_{j=1}^{k} |c_j|$. Note that $C$ is a constant independent of $n$ (though it depends on $\\phi$, and thus on $\\epsilon$).\nWe can choose an integer $N$ sufficiently large such that for all $n > N$:\n$$ \\frac{C}{n} < \\frac{\\epsilon}{2}. $$\nSpecifically, choose $N > \\frac{2C}{\\epsilon}$.\n\n### 6. Conclusion\n\nFor the chosen $\\epsilon$, we found $N$ such that for all $n > N$:\n$$ |I_n| < \\frac{\\epsilon}{2} \\quad (\\text{from the approximation error}) $$\n$$ + \\frac{\\epsilon}{2} \\quad (\\text{from the step function integral}) $$\n$$ = \\epsilon. $$\n\nSince $\\epsilon$ was arbitrary, we conclude:\n$$ \\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) \\, dx = 0. $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of \"Functions of a complex variable\" along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the domain and requirements\nThe domain is \"Functions of a complex variable.\" This involves complex analysis, including topics like analytic functions, contour integration, and possibly properties of specific functions like the exponential or logarithmic function in the complex plane.\n\n## Step 3: Generate a problem\nTo create a challenging problem, we should consider a topic that requires a good understanding of complex analysis. One such topic is contour integration and the application of Cauchy's Integral Formula or the Residue Theorem.\n\n## Step 4: Formulate the problem\nLet's consider a problem that involves evaluating a contour integral using the Residue Theorem, which is a fundamental technique in complex analysis.\n\n## Step 5: Specify the problem\nThe problem could be: \"Evaluate the integral $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, where the contour $|z| = 2$ is traversed in the positive direction.\"\n\n## Step 6: Provide the solution\nTo solve $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, first identify the singularities of the integrand within the contour $|z| = 2$. The singularities occur at $z = \\pm i$, both of which are inside $|z| = 2$ since $|i| = |-i| = 1 < 2$.\n\n## Step 7: Apply the Residue Theorem\nThe Residue Theorem states that $\\oint_C f(z) dz = 2\\pi i \\sum \\text{Res}(f, z_j)$, where $z_j$ are the singularities enclosed by $C$. We need to calculate the residues at $z = i$ and $z = -i$.\n\n## Step 8: Calculate the residue at $z = i$\nThe residue of $\\frac{e^z}{z^2 + 1}$ at $z = i$ can be found using the formula for simple poles: $\\text{Res}(f, z_0) = \\lim_{z \\to z_0} (z - z_0)f(z)$. So, $\\text{Res}(f, i) = \\lim_{z \\to i} (z - i)\\frac{e^z}{(z - i)(z + i)} = \\lim_{z \\to i} \\frac{e^z}{z + i} = \\frac{e^i}{2i}$.\n\n## Step 9: Calculate the residue at $z = -i$\nSimilarly, $\\text{Res}(f, -i) = \\lim_{z \\to -i} (z + i)\\frac{e^z}{(z + i)(z - i)} = \\lim_{z \\to -i} \\frac{e^z}{z - i} = \\frac{e^{-i}}{-2i}$.\n\n## Step 10: Sum the residues and apply the Residue Theorem\n$\\sum \\text{Res} = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i} = \\sin(1)$, because $e^i - e^{-i} = 2i\\sin(1)$.\n\n## Step 11: Calculate the integral\n$\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz = 2\\pi i \\sin(1)$.\n\n## Step 12: Write the final answer in the required format\n\nEvaluate the integral $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, where the contour $|z| = 2$ is traversed in the positive direction.",
    "run_id": "18",
    "outer_attempt": 1,
    "topic_slug": "functions_of_a_complex_variable",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To evaluate the integral\n$$ I = \\oint_{|z|=2} \\frac{e^z}{z^2 + 1} \\, dz $$\nwhere the contour $C = \\{z \\in \\mathbb{C} : |z|=2\\}$ is traversed in the positive (counter-clockwise) direction, we will use Cauchy's Residue Theorem.\n\n### 1. Identify Singularities\nLet $f(z) = \\frac{e^z}{z^2 + 1}$. The function $f(z)$ is analytic everywhere in the complex plane except where the denominator is zero.\n$$ z^2 + 1 = 0 \\implies z^2 = -1 \\implies z = i \\text{ or } z = -i $$\nThus, $f(z)$ has simple poles at $z_1 = i$ and $z_2 = -i$.\n\n### 2. Check Singularities within the Contour\nThe contour is a circle centered at the origin with radius $R=2$. We check if the poles lie inside this region ($|z| < 2$).\n- For $z_1 = i$: $|i| = 1 < 2$.\n- For $z_2 = -i$: $|-i| = 1 < 2$.\n\nBoth singularities lie inside the contour. Therefore, by the Residue Theorem:\n$$ \\oint_{C} f(z) \\, dz = 2\\pi i \\left( \\text{Res}(f, i) + \\text{Res}(f, -i) \\right) $$\n\n### 3. Compute Residues\nSince the poles are simple, we can compute the residue at a pole $z_0$ using the formula:\n$$ \\text{Res}(f, z_0) = \\lim_{z \\to z_0} (z - z_0) f(z) $$\nAlternatively, for $f(z) = \\frac{P(z)}{Q(z)}$ where $P(z_0) \\neq 0$, $Q(z_0) = 0$, and $Q'(z_0) \\neq 0$, the residue is $\\frac{P(z_0)}{Q'(z_0)}$. Here $P(z)=e^z$ and $Q(z)=z^2+1$, so $Q'(z)=2z$.\n\n**Residue at $z = i$:**\n$$ \\text{Res}(f, i) = \\frac{e^i}{2(i)} = \\frac{e^i}{2i} $$\n\n**Residue at $z = -i$:**\n$$ \\text{Res}(f, -i) = \\frac{e^{-i}}{2(-i)} = -\\frac{e^{-i}}{2i} $$\n\n### 4. Sum the Residues and Evaluate Integral\nSum of residues:\n$$ \\sum \\text{Res} = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i} $$\nRecall the definition of the sine function for complex arguments: $\\sin(z) = \\frac{e^{iz} - e^{-iz}}{2i}$. Here, with argument $1$, we have:\n$$ \\frac{e^i - e^{-i}}{2i} = \\sin(1) $$\n\nSubstitute this back into the Residue Theorem formula:\n$$ I = 2\\pi i (\\sin(1)) $$\n\n### Final Answer\n$$ \\oint_{|z|=2} \\frac{e^z}{z^2 + 1} \\, dz = 2\\pi i \\sin(1) $$",
        "raw_answer": "To evaluate the integral\n$$ I = \\oint_{|z|=2} \\frac{e^z}{z^2 + 1} \\, dz $$\nwhere the contour $C = \\{z \\in \\mathbb{C} : |z|=2\\}$ is traversed in the positive (counter-clockwise) direction, we will use Cauchy's Residue Theorem.\n\n### 1. Identify Singularities\nLet $f(z) = \\frac{e^z}{z^2 + 1}$. The function $f(z)$ is analytic everywhere in the complex plane except where the denominator is zero.\n$$ z^2 + 1 = 0 \\implies z^2 = -1 \\implies z = i \\text{ or } z = -i $$\nThus, $f(z)$ has simple poles at $z_1 = i$ and $z_2 = -i$.\n\n### 2. Check Singularities within the Contour\nThe contour is a circle centered at the origin with radius $R=2$. We check if the poles lie inside this region ($|z| < 2$).\n- For $z_1 = i$: $|i| = 1 < 2$.\n- For $z_2 = -i$: $|-i| = 1 < 2$.\n\nBoth singularities lie inside the contour. Therefore, by the Residue Theorem:\n$$ \\oint_{C} f(z) \\, dz = 2\\pi i \\left( \\text{Res}(f, i) + \\text{Res}(f, -i) \\right) $$\n\n### 3. Compute Residues\nSince the poles are simple, we can compute the residue at a pole $z_0$ using the formula:\n$$ \\text{Res}(f, z_0) = \\lim_{z \\to z_0} (z - z_0) f(z) $$\nAlternatively, for $f(z) = \\frac{P(z)}{Q(z)}$ where $P(z_0) \\neq 0$, $Q(z_0) = 0$, and $Q'(z_0) \\neq 0$, the residue is $\\frac{P(z_0)}{Q'(z_0)}$. Here $P(z)=e^z$ and $Q(z)=z^2+1$, so $Q'(z)=2z$.\n\n**Residue at $z = i$:**\n$$ \\text{Res}(f, i) = \\frac{e^i}{2(i)} = \\frac{e^i}{2i} $$\n\n**Residue at $z = -i$:**\n$$ \\text{Res}(f, -i) = \\frac{e^{-i}}{2(-i)} = -\\frac{e^{-i}}{2i} $$\n\n### 4. Sum the Residues and Evaluate Integral\nSum of residues:\n$$ \\sum \\text{Res} = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i} $$\nRecall the definition of the sine function for complex arguments: $\\sin(z) = \\frac{e^{iz} - e^{-iz}}{2i}$. Here, with argument $1$, we have:\n$$ \\frac{e^i - e^{-i}}{2i} = \\sin(1) $$\n\nSubstitute this back into the Residue Theorem formula:\n$$ I = 2\\pi i (\\sin(1)) $$\n\n### Final Answer\n$$ \\oint_{|z|=2} \\frac{e^z}{z^2 + 1} \\, dz = 2\\pi i \\sin(1) $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Potential theory, along with a complete and verifiable solution. Potential theory is a branch of mathematics that deals with the study of potentials and their properties, particularly in relation to partial differential equations, especially Laplace's equation.\n\n## Step 2: Identify key concepts in Potential theory\nPotential theory involves the study of harmonic functions, potentials (such as Newtonian or logarithmic potentials), and their applications. Key concepts include the Laplace equation ($\\Delta u = 0$), Poisson's equation ($\\Delta u = f$), and boundary value problems (Dirichlet and Neumann problems).\n\n## Step 3: Formulate a problem\nTo create a challenging problem, we need to involve some of the advanced concepts or techniques from Potential theory. Let's consider a problem involving the Dirichlet problem for the Laplace equation on a specific domain.\n\n## Step 4: Specify the problem\nLet's consider the following problem: \"Let $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.\"\n\n## Step 5: Provide the solution\nTo solve this problem, we can use the Poisson integral formula, which gives the solution to the Dirichlet problem on the unit disk. The Poisson integral formula is given by $u(x) = \\frac{1}{2\\pi} \\int_{\\partial D} \\frac{1 - |x|^2}{|x - y|^2} f(y) ds(y)$, where $f(y)$ is the boundary data.\n\n## Step 6: Apply the Poisson integral formula\nFor $x = (r\\cos\\theta, r\\sin\\theta)$ and $y = (\\cos\\phi, \\sin\\phi)$, we have $|x - y|^2 = r^2 - 2r\\cos(\\theta - \\phi) + 1$ and $ds(y) = d\\phi$. The boundary data is $f(y) = \\log|y - (1,0)| = \\log\\sqrt{2 - 2\\cos\\phi}$. So, $u(x) = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} \\frac{1 - r^2}{r^2 - 2r\\cos(\\theta - \\phi) + 1} \\log\\sqrt{2 - 2\\cos\\phi} d\\phi$.\n\n## Step 7: Simplify the integral\nThe integral can be simplified by recognizing that $\\log\\sqrt{2 - 2\\cos\\phi} = \\log|1 - e^{i\\phi}| = \\log|1 - e^{i\\phi}| = \\Re(\\log(1 - e^{i\\phi}))$. However, directly evaluating this integral is complex and typically involves recognizing it as a special case that can be related to the properties of harmonic functions and the Poisson kernel.\n\n## Step 8: Evaluate the solution using properties of harmonic functions\nFor $x \\in D$, the solution can be found by directly applying properties of harmonic functions and recognizing that the given boundary condition corresponds to a specific harmonic function. The function $u(x) = \\log|x - (1,0)|$ is harmonic in $D$ except at $x = (1,0)$, which is outside $D$ since $|1,0| = 1$ is on $\\partial D$. Thus, we directly check if $u(x)$ satisfies the given boundary condition and is harmonic.\n\n## Step 9: Check if the given boundary data directly provides the solution\nSince $\\log|x - (1,0)|$ is harmonic in $D$ and equals $\\log|y - (1,0)|$ on $\\partial D$, it is the solution to the Dirichlet problem.\n\nThe final answer is: \n\nLet $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.",
    "run_id": "19",
    "outer_attempt": 1,
    "topic_slug": "potential_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the solution to the Dirichlet problem for the Laplace equation on the unit disk with the specified boundary condition, we will proceed through a rigorous mathematical derivation.\n\n### 1. Problem Statement\n\nLet $D = \\{x \\in \\mathbb{R}^2 : |x| < 1\\}$ be the open unit disk. We seek a function $u: D \\to \\mathbb{R}$ satisfying:\n1.  **Laplace's Equation:** $\\Delta u(x) = 0$ for all $x \\in D$.\n2.  **Boundary Condition:** $\\lim_{x \\to y, x \\in D} u(x) = \\log|y - (1,0)|$ for $y \\in \\partial D \\setminus \\{(1,0)\\}$.\n\nThe boundary data is given by $f(y) = \\log|y - (1,0)|$. We note that the point $(1,0)$ lies on the boundary $\\partial D$. The function $f(y)$ is singular at $(1,0)$ (approaching $-\\infty$), so we interpret the boundary condition in the sense of the Poisson integral for $L^1$ boundary data.\n\n### 2. Analysis of the Candidate Solution\n\nA powerful technique in potential theory is to inspect whether the function defining the boundary data is itself harmonic in the interior domain.\n\nConsider the function defined on $\\mathbb{R}^2 \\setminus \\{(1,0)\\}$:\n$$ v(x) = \\log|x - (1,0)| $$\n\n**Step 2.1: Verify Harmonicity**\nWe identify $\\mathbb{R}^2$ with the complex plane $\\mathbb{C}$. Let $x \\cong z = x_1 + i x_2$. Then $(1,0) \\cong 1$.\nThe function becomes $v(z) = \\log|z - 1|$.\nRecall that for any holomorphic function $g(z)$, its real part $\\Re(g(z))$ is harmonic.\nConsider the principal branch of the complex logarithm, $\\log(z - 1)$. This function is holomorphic on $\\mathbb{C} \\setminus (-\\infty, 1]$.\nHowever, we only need the function to be harmonic in the domain $D$ (the unit disk).\nThe singularity of $\\log(z - 1)$ is at $z = 1$. The branch cut can be taken along the ray $[1, \\infty)$ on the real axis, or any ray starting at 1 that does not intersect $D$.\nRegardless of the branch cut, the real part is well-defined:\n$$ \\Re(\\log(z - 1)) = \\log|z - 1| $$\nSince $\\log(z - 1)$ is holomorphic locally around any point in $D$ (as $1 \\notin D$), its real part $v(z) = \\log|z - 1|$ is harmonic in $D$.\n$$ \\Delta v = 0 \\quad \\text{for } x \\in D $$\n\n**Step 2.2: Verify Boundary Conditions**\nFor any $y \\in \\partial D \\setminus \\{(1,0)\\}$, the proposed solution $v(y)$ is exactly $\\log|y - (1,0)|$.\nThus, $v(x)$ satisfies the boundary condition pointwise everywhere except at the singularity $(1,0)$.\n\n### 3. Rigorous Derivation via Fourier Series\n\nTo ensure $v(x)$ is the unique solution in the appropriate class (Poisson integral of $L^1$ data), we derive it constructively using Fourier series.\n\nParametrize the boundary $\\partial D$ by $y(\\theta) = e^{i\\theta}$ for $\\theta \\in (0, 2\\pi)$.\nThe boundary data is:\n$$ f(\\theta) = \\log|e^{i\\theta} - 1| $$\nUsing the identity $|e^{i\\theta} - 1| = 2|\\sin(\\frac{\\theta}{2})|$, we have $f(\\theta) = \\log(2|\\sin(\\frac{\\theta}{2})|)$.\n\nWe utilize the known Fourier series expansion for this function. Recall the Taylor series for the principal logarithm for $|z| < 1$:\n$$ \\log(1 - z) = -\\sum_{n=1}^{\\infty} \\frac{z^n}{n} $$\nLet $z = r e^{i\\theta}$ with $r < 1$. Taking the real part:\n$$ \\Re(\\log(1 - r e^{i\\theta})) = -\\sum_{n=1}^{\\infty} \\frac{r^n \\cos(n\\theta)}{n} $$\nAccording to Abel's theorem, as $r \\to 1^-$, this series converges to the boundary function almost everywhere (specifically for $\\theta \\neq 0$):\n$$ \\Re(\\log(1 - e^{i\\theta})) = \\log|1 - e^{i\\theta}| = \\log|e^{i\\theta} - 1| $$\nThus, the Fourier series of our boundary data is:\n$$ f(\\theta) \\sim -\\sum_{n=1}^{\\infty} \\frac{\\cos(n\\theta)}{n} $$\nThe solution to the Dirichlet problem is the harmonic extension of this series into the interior $D$ (where $x \\cong r e^{i\\theta}$):\n$$ u(r, \\theta) = -\\sum_{n=1}^{\\infty} r^n \\frac{\\cos(n\\theta)}{n} $$\nRecognizing this sum as the real part of the Taylor series for $\\log(1-z)$ evaluated at $z = r e^{i\\theta}$:\n$$ u(r, \\theta) = \\Re\\left( \\log(1 - r e^{i\\theta}) \\right) = \\log|1 - r e^{i\\theta}| $$\nIn Cartesian coordinates, $|1 - r e^{i\\theta}| = |1 - x| = |x - (1,0)|$.\n\n### 4. Conclusion\n\nThe function $u(x) = \\log|x - (1,0)|$ is harmonic in $D$ and satisfies the prescribed boundary conditions. It is the unique solution given by the Poisson integral of the boundary data.\n\n**Final Answer:**\nThe solution to the Dirichlet problem is:\n$$ u(x) = \\log|x - (1,0)| $$",
        "raw_answer": "To find the solution to the Dirichlet problem for the Laplace equation on the unit disk with the specified boundary condition, we will proceed through a rigorous mathematical derivation.\n\n### 1. Problem Statement\n\nLet $D = \\{x \\in \\mathbb{R}^2 : |x| < 1\\}$ be the open unit disk. We seek a function $u: D \\to \\mathbb{R}$ satisfying:\n1.  **Laplace's Equation:** $\\Delta u(x) = 0$ for all $x \\in D$.\n2.  **Boundary Condition:** $\\lim_{x \\to y, x \\in D} u(x) = \\log|y - (1,0)|$ for $y \\in \\partial D \\setminus \\{(1,0)\\}$.\n\nThe boundary data is given by $f(y) = \\log|y - (1,0)|$. We note that the point $(1,0)$ lies on the boundary $\\partial D$. The function $f(y)$ is singular at $(1,0)$ (approaching $-\\infty$), so we interpret the boundary condition in the sense of the Poisson integral for $L^1$ boundary data.\n\n### 2. Analysis of the Candidate Solution\n\nA powerful technique in potential theory is to inspect whether the function defining the boundary data is itself harmonic in the interior domain.\n\nConsider the function defined on $\\mathbb{R}^2 \\setminus \\{(1,0)\\}$:\n$$ v(x) = \\log|x - (1,0)| $$\n\n**Step 2.1: Verify Harmonicity**\nWe identify $\\mathbb{R}^2$ with the complex plane $\\mathbb{C}$. Let $x \\cong z = x_1 + i x_2$. Then $(1,0) \\cong 1$.\nThe function becomes $v(z) = \\log|z - 1|$.\nRecall that for any holomorphic function $g(z)$, its real part $\\Re(g(z))$ is harmonic.\nConsider the principal branch of the complex logarithm, $\\log(z - 1)$. This function is holomorphic on $\\mathbb{C} \\setminus (-\\infty, 1]$.\nHowever, we only need the function to be harmonic in the domain $D$ (the unit disk).\nThe singularity of $\\log(z - 1)$ is at $z = 1$. The branch cut can be taken along the ray $[1, \\infty)$ on the real axis, or any ray starting at 1 that does not intersect $D$.\nRegardless of the branch cut, the real part is well-defined:\n$$ \\Re(\\log(z - 1)) = \\log|z - 1| $$\nSince $\\log(z - 1)$ is holomorphic locally around any point in $D$ (as $1 \\notin D$), its real part $v(z) = \\log|z - 1|$ is harmonic in $D$.\n$$ \\Delta v = 0 \\quad \\text{for } x \\in D $$\n\n**Step 2.2: Verify Boundary Conditions**\nFor any $y \\in \\partial D \\setminus \\{(1,0)\\}$, the proposed solution $v(y)$ is exactly $\\log|y - (1,0)|$.\nThus, $v(x)$ satisfies the boundary condition pointwise everywhere except at the singularity $(1,0)$.\n\n### 3. Rigorous Derivation via Fourier Series\n\nTo ensure $v(x)$ is the unique solution in the appropriate class (Poisson integral of $L^1$ data), we derive it constructively using Fourier series.\n\nParametrize the boundary $\\partial D$ by $y(\\theta) = e^{i\\theta}$ for $\\theta \\in (0, 2\\pi)$.\nThe boundary data is:\n$$ f(\\theta) = \\log|e^{i\\theta} - 1| $$\nUsing the identity $|e^{i\\theta} - 1| = 2|\\sin(\\frac{\\theta}{2})|$, we have $f(\\theta) = \\log(2|\\sin(\\frac{\\theta}{2})|)$.\n\nWe utilize the known Fourier series expansion for this function. Recall the Taylor series for the principal logarithm for $|z| < 1$:\n$$ \\log(1 - z) = -\\sum_{n=1}^{\\infty} \\frac{z^n}{n} $$\nLet $z = r e^{i\\theta}$ with $r < 1$. Taking the real part:\n$$ \\Re(\\log(1 - r e^{i\\theta})) = -\\sum_{n=1}^{\\infty} \\frac{r^n \\cos(n\\theta)}{n} $$\nAccording to Abel's theorem, as $r \\to 1^-$, this series converges to the boundary function almost everywhere (specifically for $\\theta \\neq 0$):\n$$ \\Re(\\log(1 - e^{i\\theta})) = \\log|1 - e^{i\\theta}| = \\log|e^{i\\theta} - 1| $$\nThus, the Fourier series of our boundary data is:\n$$ f(\\theta) \\sim -\\sum_{n=1}^{\\infty} \\frac{\\cos(n\\theta)}{n} $$\nThe solution to the Dirichlet problem is the harmonic extension of this series into the interior $D$ (where $x \\cong r e^{i\\theta}$):\n$$ u(r, \\theta) = -\\sum_{n=1}^{\\infty} r^n \\frac{\\cos(n\\theta)}{n} $$\nRecognizing this sum as the real part of the Taylor series for $\\log(1-z)$ evaluated at $z = r e^{i\\theta}$:\n$$ u(r, \\theta) = \\Re\\left( \\log(1 - r e^{i\\theta}) \\right) = \\log|1 - r e^{i\\theta}| $$\nIn Cartesian coordinates, $|1 - r e^{i\\theta}| = |1 - x| = |x - (1,0)|$.\n\n### 4. Conclusion\n\nThe function $u(x) = \\log|x - (1,0)|$ is harmonic in $D$ and satisfies the prescribed boundary conditions. It is the unique solution given by the Poisson integral of the boundary data.\n\n**Final Answer:**\nThe solution to the Dirichlet problem is:\n$$ u(x) = \\log|x - (1,0)| $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Several complex variables and analytic spaces\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify key concepts in the domain\nSeveral complex variables and analytic spaces involve the study of functions of multiple complex variables and the spaces on which these functions are defined. Key concepts include holomorphic functions, complex manifolds, analytic continuation, and various types of domains (e.g., domains of holomorphy, pseudoconvex domains).\n\n## Step 3: Formulate a problem\nTo create a problem, we need to focus on a specific aspect of several complex variables. Let's consider the concept of holomorphic functions on a domain in $\\mathbb{C}^n$. A potential problem could involve characterizing or analyzing the properties of such functions.\n\n## Step 4: Specify the problem\nLet's formulate a problem related to the extension of holomorphic functions. A well-known result in several complex variables is the Hartogs' extension theorem, which states that any holomorphic function defined on a domain in $\\mathbb{C}^n$ ($n > 1$) with a compact hole can be extended holomorphically to the whole domain. We can create a problem related to this concept.\n\n## Step 5: Create the problem statement\nConsider the domain $\\Omega = \\{z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1\\}$ and the subset $S = \\{z \\in \\Omega : |z_1| < \\frac{1}{2}\\}$. Let $f$ be a holomorphic function on $\\Omega \\setminus S$. Show that $f$ can be extended to a holomorphic function on $\\Omega$.\n\n## Step 6: Provide the solution\nTo solve this, we recognize that $\\Omega \\setminus S$ is not a compact hole in $\\Omega$, so we cannot directly apply Hartogs' theorem. However, we can analyze the problem by considering the properties of holomorphic functions in $\\mathbb{C}^2$ and the specific geometry of $\\Omega$ and $S$.\n\n## Step 7: Detail the solution\nFor $z = (z_1, z_2) \\in \\Omega \\setminus S$, $f(z)$ is holomorphic. We need to show that $f$ can be extended holomorphically to $\\Omega$. For any fixed $z_2$ with $|z_2| < 1$, $f(z_1, z_2)$ is holomorphic in $z_1$ for $\\frac{1}{2} \\leq |z_1| < 1$. By the principle of analytic continuation in one variable, if $f(z_1, z_2)$ is holomorphic for $|z_1| < 1$ except on a smaller disk, it can be extended. However, the direct application of Hartogs' theorem is not possible here due to the shape of $S$. Instead, we can use the fact that for each $z_2$, $f(\\cdot, z_2)$ can be extended to $|z_1| < 1$ because the singularity set is contained within $|z_1| \\leq \\frac{1}{2}$, and then apply Hartogs' theorem or a similar principle to conclude the extension is holomorphic in both variables.\n\n## Step 8: Write the problem and solution in the required format\n\nLet $\\Omega = \\{z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1\\}$ and $S = \\{z \\in \\Omega : |z_1| < \\frac{1}{2}\\}$. Suppose $f$ is a holomorphic function on $\\Omega \\setminus S$. Prove that $f$ can be extended to a holomorphic function on $\\Omega$.",
    "run_id": "20",
    "outer_attempt": 1,
    "topic_slug": "several_complex_variables_and_analytic_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The question presented in Step 8 is **ill-posed** because it asks for a proof of a mathematical assertion that is **false**. The problem violates the **Contradictory Premises** validity condition, as it assumes that a specific class of functions always admits a holomorphic extension when, in fact, it does not.\n\nBelow is the rigorous demonstration that the assertion is false, provided via a counterexample, followed by an analysis of the geometric obstruction.\n\n### 1. Analysis of the Domain and Statement\n\nLet us explicitly define the sets given in the problem statement:\n- The domain $\\Omega = \\{ z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1 \\}$ is the unit polydisc $\\Delta^2$.\n- The subset $S = \\{ z \\in \\Omega : |z_1| < \\frac{1}{2} \\}$.\n\nThe domain of definition for the function $f$ is $D = \\Omega \\setminus S$. We can determine the explicit structure of $D$:\n$$\nD = \\{ (z_1, z_2) \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1 \\} \\setminus \\{ (z_1, z_2) \\in \\mathbb{C}^2 : |z_1| < \\frac{1}{2}, |z_2| < 1 \\}\n$$\n$$\nD = \\{ (z_1, z_2) \\in \\mathbb{C}^2 : \\frac{1}{2} \\leq |z_1| < 1, \\, |z_2| < 1 \\}\n$$\nGeometrically, $D$ is the Cartesian product of an annulus $A = \\{ z_1 \\in \\mathbb{C} : \\frac{1}{2} \\leq |z_1| < 1 \\}$ and the unit disc $\\Delta = \\{ z_2 \\in \\mathbb{C} : |z_2| < 1 \\}$.\n\nThe question asks to prove that **any** holomorphic function $f$ on $D$ can be extended to a holomorphic function on $\\Omega$.\n\n### 2. Counterexample\n\nWe construct a function $f$ that is holomorphic on $D$ but cannot be extended holomorphically to $\\Omega$.\n\nConsider the function:\n$$\nf(z_1, z_2) = \\frac{1}{z_1}\n$$\n\n**Verification of Holomorphy on $D$:**\nFor any point $(z_1, z_2) \\in D$, we have the constraint $\\frac{1}{2} \\leq |z_1| < 1$.\nSince $|z_1| \\geq \\frac{1}{2}$, it follows that $z_1 \\neq 0$. The function $z \\mapsto \\frac{1}{z_1}$ is a rational function singular only at $z_1 = 0$. Since the singular locus $\\{z_1 = 0\\}$ is disjoint from $D$, $f$ is holomorphic on $D$.\n\n**Impossibility of Extension to $\\Omega$:**\nThe domain $\\Omega$ contains the set $\\{ (0, z_2) : |z_2| < 1 \\}$, which corresponds to $z_1 = 0$.\nSuppose there exists a holomorphic function $F: \\Omega \\to \\mathbb{C}$ such that $F|_D = f$.\nConsider the restriction of $F$ to the slice $z_2 = 0$. Let $g(z_1) = F(z_1, 0)$.\nSince $F$ is holomorphic on $\\Omega$, $g$ must be holomorphic on the unit disc $\\{ z_1 \\in \\mathbb{C} : |z_1| < 1 \\}$.\nHowever, for $\\frac{1}{2} \\leq |z_1| < 1$, we have $g(z_1) = f(z_1, 0) = \\frac{1}{z_1}$.\nBy the Identity Theorem for holomorphic functions, $g(z_1)$ must equal $\\frac{1}{z_1}$ everywhere on its domain of definition.\nBut $\\lim_{z_1 \\to 0} |g(z_1)| = \\lim_{z_1 \\to 0} \\frac{1}{|z_1|} = \\infty$.\nThis contradicts the requirement that $g$ is holomorphic (and thus continuous and finite) at $z_1 = 0$.\n\nTherefore, $f$ cannot be extended to a holomorphic function on $\\Omega$.\n\n### 3. Mathematical Context and Correction\n\nThe assertion fails because the domain $D = A \\times \\Delta$ is a **domain of holomorphy**. A fundamental result in Several Complex Variables states that a product domain $D_1 \\times D_2$ is a domain of holomorphy if and only if $D_1$ and $D_2$ are domains of holomorphy in their respective spaces.\n- The annulus $A = \\{ 1/2 \\leq |z_1| < 1 \\}$ is a domain of holomorphy in $\\mathbb{C}$.\n- The disc $\\Delta = \\{ |z_2| < 1 \\}$ is a domain of holomorphy in $\\mathbb{C}$.\nThus, $D$ is a domain of holomorphy, meaning there exists a holomorphic function on $D$ that cannot be extended to any larger domain.\n\n**To make the question answerable (Well-Posedness):**\nThe problem likely intended to describe a **Hartogs figure**, where extension is forced. A modification that would make the assertion true is:\nDefine $S = \\{ z \\in \\Omega : |z_1| < \\frac{1}{2} \\text{ and } |z_2| < \\frac{1}{2} \\}$.\nIn this case, $\\Omega \\setminus S$ is connected and \"surrounds\" the compact hole (or thick hole) in such a way that Hartogs' Extension Theorem applies, allowing every holomorphic function on $\\Omega \\setminus S$ to extend to $\\Omega$.\n\nHowever, as stated with $S$ defined solely by $|z_1| < 1/2$, the statement is false.",
        "raw_answer": "The question presented in Step 8 is **ill-posed** because it asks for a proof of a mathematical assertion that is **false**. The problem violates the **Contradictory Premises** validity condition, as it assumes that a specific class of functions always admits a holomorphic extension when, in fact, it does not.\n\nBelow is the rigorous demonstration that the assertion is false, provided via a counterexample, followed by an analysis of the geometric obstruction.\n\n### 1. Analysis of the Domain and Statement\n\nLet us explicitly define the sets given in the problem statement:\n- The domain $\\Omega = \\{ z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1 \\}$ is the unit polydisc $\\Delta^2$.\n- The subset $S = \\{ z \\in \\Omega : |z_1| < \\frac{1}{2} \\}$.\n\nThe domain of definition for the function $f$ is $D = \\Omega \\setminus S$. We can determine the explicit structure of $D$:\n$$\nD = \\{ (z_1, z_2) \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1 \\} \\setminus \\{ (z_1, z_2) \\in \\mathbb{C}^2 : |z_1| < \\frac{1}{2}, |z_2| < 1 \\}\n$$\n$$\nD = \\{ (z_1, z_2) \\in \\mathbb{C}^2 : \\frac{1}{2} \\leq |z_1| < 1, \\, |z_2| < 1 \\}\n$$\nGeometrically, $D$ is the Cartesian product of an annulus $A = \\{ z_1 \\in \\mathbb{C} : \\frac{1}{2} \\leq |z_1| < 1 \\}$ and the unit disc $\\Delta = \\{ z_2 \\in \\mathbb{C} : |z_2| < 1 \\}$.\n\nThe question asks to prove that **any** holomorphic function $f$ on $D$ can be extended to a holomorphic function on $\\Omega$.\n\n### 2. Counterexample\n\nWe construct a function $f$ that is holomorphic on $D$ but cannot be extended holomorphically to $\\Omega$.\n\nConsider the function:\n$$\nf(z_1, z_2) = \\frac{1}{z_1}\n$$\n\n**Verification of Holomorphy on $D$:**\nFor any point $(z_1, z_2) \\in D$, we have the constraint $\\frac{1}{2} \\leq |z_1| < 1$.\nSince $|z_1| \\geq \\frac{1}{2}$, it follows that $z_1 \\neq 0$. The function $z \\mapsto \\frac{1}{z_1}$ is a rational function singular only at $z_1 = 0$. Since the singular locus $\\{z_1 = 0\\}$ is disjoint from $D$, $f$ is holomorphic on $D$.\n\n**Impossibility of Extension to $\\Omega$:**\nThe domain $\\Omega$ contains the set $\\{ (0, z_2) : |z_2| < 1 \\}$, which corresponds to $z_1 = 0$.\nSuppose there exists a holomorphic function $F: \\Omega \\to \\mathbb{C}$ such that $F|_D = f$.\nConsider the restriction of $F$ to the slice $z_2 = 0$. Let $g(z_1) = F(z_1, 0)$.\nSince $F$ is holomorphic on $\\Omega$, $g$ must be holomorphic on the unit disc $\\{ z_1 \\in \\mathbb{C} : |z_1| < 1 \\}$.\nHowever, for $\\frac{1}{2} \\leq |z_1| < 1$, we have $g(z_1) = f(z_1, 0) = \\frac{1}{z_1}$.\nBy the Identity Theorem for holomorphic functions, $g(z_1)$ must equal $\\frac{1}{z_1}$ everywhere on its domain of definition.\nBut $\\lim_{z_1 \\to 0} |g(z_1)| = \\lim_{z_1 \\to 0} \\frac{1}{|z_1|} = \\infty$.\nThis contradicts the requirement that $g$ is holomorphic (and thus continuous and finite) at $z_1 = 0$.\n\nTherefore, $f$ cannot be extended to a holomorphic function on $\\Omega$.\n\n### 3. Mathematical Context and Correction\n\nThe assertion fails because the domain $D = A \\times \\Delta$ is a **domain of holomorphy**. A fundamental result in Several Complex Variables states that a product domain $D_1 \\times D_2$ is a domain of holomorphy if and only if $D_1$ and $D_2$ are domains of holomorphy in their respective spaces.\n- The annulus $A = \\{ 1/2 \\leq |z_1| < 1 \\}$ is a domain of holomorphy in $\\mathbb{C}$.\n- The disc $\\Delta = \\{ |z_2| < 1 \\}$ is a domain of holomorphy in $\\mathbb{C}$.\nThus, $D$ is a domain of holomorphy, meaning there exists a holomorphic function on $D$ that cannot be extended to any larger domain.\n\n**To make the question answerable (Well-Posedness):**\nThe problem likely intended to describe a **Hartogs figure**, where extension is forced. A modification that would make the assertion true is:\nDefine $S = \\{ z \\in \\Omega : |z_1| < \\frac{1}{2} \\text{ and } |z_2| < \\frac{1}{2} \\}$.\nIn this case, $\\Omega \\setminus S$ is connected and \"surrounds\" the compact hole (or thick hole) in such a way that Hartogs' Extension Theorem applies, allowing every holomorphic function on $\\Omega \\setminus S$ to extend to $\\Omega$.\n\nHowever, as stated with $S$ defined solely by $|z_1| < 1/2$, the statement is false.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of special functions, along with a clear and detailed solution, following specific guidelines.\n[/QUESTION]",
    "run_id": "21",
    "outer_attempt": 1,
    "topic_slug": "special_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Based on the task requirements, I have generated a challenging problem involving special functions (specifically the Gamma function and properties of improper integrals) and provided a complete, rigorous solution.\n\n---\n\n### **Problem Statement**\n\n**Problem:** For a real parameter $n > 1$, evaluate the definite integral:\n\n$$ I(n) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx $$\n\nProvide a closed-form expression for $I(n)$ in terms of standard mathematical constants and trigonometric functions. Justify all steps, including the convergence of the integral and the validity of any operations involving differentiation under the integral sign.\n\n---\n\n### **Solution**\n\nWe aim to evaluate the integral $I(n) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx$ for $n > 1$.\n\n#### **1. Convergence Analysis**\n\nFirst, we establish that the integral is well-defined.\nLet $f(x) = \\frac{\\ln x}{1+x^n}$.\n*   **Near $x \\to 0^+$:** The denominator $1+x^n \\approx 1$. Thus, $f(x) \\sim \\ln x$. Since $\\int_0^1 \\ln x \\, dx$ is absolutely convergent (calculating to $-1$), the integral converges at the lower bound.\n*   **Near $x \\to \\infty$:** For large $x$, $1+x^n \\sim x^n$. Thus, $f(x) \\sim \\frac{\\ln x}{x^n}$. Since $n > 1$, let $\\epsilon = \\frac{n-1}{2} > 0$. We have $\\frac{\\ln x}{x^n} = \\frac{\\ln x}{x^\\epsilon} \\cdot \\frac{1}{x^{n-\\epsilon}}$. Since $\\frac{\\ln x}{x^\\epsilon} \\to 0$, the tail is bounded by $C \\cdot \\frac{1}{x^{1+\\epsilon}}$, which converges by the $p$-test ($p = 1 + \\epsilon > 1$).\n\nThus, $I(n)$ converges for all $n > 1$.\n\n#### **2. Introduction of a Parameterized Integral**\n\nWe introduce a parameterized auxiliary integral (the Mellin transform of the function $\\frac{1}{1+x^n}$):\n$$ J(s) = \\int_0^{\\infty} \\frac{x^{s-1}}{1+x^n} \\, dx $$\nNotice that\n$$ \\frac{\\partial}{\\partial s} \\left( \\frac{x^{s-1}}{1+x^n} \\right) = \\frac{x^{s-1} \\ln x}{1+x^n} $$\nEvaluating this derivative at $s=1$ yields our target integrand:\n$$ J'(1) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx = I(n) $$\n\nTo rigorously justify differentiation under the integral sign, we verify the uniform convergence of the integral of the derivative. Let $s \\in [1-\\delta, 1+\\delta]$. We require the domain of integration for $s$ to satisfy $0 < s < n$ for $J(s)$ to converge. Since $n > 1$, we can choose $\\delta > 0$ such that $[1-\\delta, 1+\\delta] \\subset (0, n)$.\n*   On $(0, 1]$, $|x^{s-1}| \\le x^{-\\delta}$.\n*   On $[1, \\infty)$, $|x^{s-1}| \\le x^{\\delta}$.\nThe dominating function $g(x) = \\frac{|\\ln x| (x^{-\\delta} + x^{\\delta})}{1+x^n}$ is integrable on $(0, \\infty)$ given the choice of $\\delta$. By the Leibniz Integral Rule, $I(n) = J'(1)$.\n\n#### **3. Evaluation of $J(s)$ via Beta and Gamma Functions**\n\nWe evaluate $J(s)$ using a substitution to map it to the Beta function definition, $B(a, b) = \\int_0^\\infty \\frac{t^{a-1}}{(1+t)^{a+b}} \\, dt$.\n\nLet $u = x^n$. Then $x = u^{1/n}$ and $dx = \\frac{1}{n} u^{1/n - 1} \\, du$.\nSubstituting into $J(s)$:\n$$ J(s) = \\int_0^{\\infty} \\frac{(u^{1/n})^{s-1}}{1+u} \\cdot \\frac{1}{n} u^{1/n - 1} \\, du $$\n$$ J(s) = \\frac{1}{n} \\int_0^{\\infty} \\frac{u^{s/n - 1/n + 1/n - 1}}{1+u} \\, du $$\n$$ J(s) = \\frac{1}{n} \\int_0^{\\infty} \\frac{u^{s/n - 1}}{1+u} \\, du $$\n\nComparing this to the Beta function form $B(a, b)$ with $a = s/n$:\nSince the denominator is $(1+u)^1$, we must have $a+b=1$, implying $b = 1 - s/n$.\nThus:\n$$ J(s) = \\frac{1}{n} B\\left(\\frac{s}{n}, 1 - \\frac{s}{n}\\right) $$\n\nWe relate the Beta function to the Gamma function using the identity $B(x, y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$:\n$$ J(s) = \\frac{1}{n} \\frac{\\Gamma(s/n)\\Gamma(1 - s/n)}{\\Gamma(1)} $$\nSince $\\Gamma(1) = 1$, we invoke Euler's Reflection Formula, $\\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)}$, with $z = s/n$:\n$$ J(s) = \\frac{1}{n} \\cdot \\frac{\\pi}{\\sin(\\pi s/n)} $$\nThis closed form is valid for $0 < s < n$.\n\n#### **4. Computing the Derivative**\n\nWe now compute $I(n) = J'(1)$.\n$$ J(s) = \\frac{\\pi}{n} \\csc\\left(\\frac{\\pi s}{n}\\right) $$\nDifferentiating with respect to $s$:\n$$ J'(s) = \\frac{\\pi}{n} \\cdot \\frac{d}{ds} \\left( \\csc\\left(\\frac{\\pi s}{n}\\right) \\right) $$\nUsing the chain rule $\\frac{d}{dx} \\csc(u) = -\\csc(u)\\cot(u) \\frac{du}{dx}$:\n$$ J'(s) = \\frac{\\pi}{n} \\left( -\\csc\\left(\\frac{\\pi s}{n}\\right) \\cot\\left(\\frac{\\pi s}{n}\\right) \\cdot \\frac{\\pi}{n} \\right) $$\n$$ J'(s) = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\pi s/n)}{\\sin^2(\\pi s/n)} $$\n\nNow, evaluate at $s=1$:\n$$ I(n) = J'(1) = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\pi/n)}{\\sin^2(\\pi/n)} $$\n\n#### **Conclusion**\n\nThe value of the integral for $n > 1$ is:\n\n$$ \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\frac{\\pi}{n})}{\\sin^2(\\frac{\\pi}{n})} $$\n\n**Verification of Special Cases:**\n1.  **$n=2$**: $\\cos(\\pi/2) = 0$. The formula gives $0$.\n    *   Check: $\\int_0^\\infty \\frac{\\ln x}{1+x^2} dx$. Let $x=1/t$, $dx = -1/t^2 dt$.\n    *   $I = \\int_\\infty^0 \\frac{\\ln(1/t)}{1+1/t^2} (-1/t^2) dt = \\int_0^\\infty \\frac{-\\ln t}{t^2+1} dt = -I \\implies 2I=0 \\implies I=0$. Consistent.\n2.  **Sign check**: For large $n$, $\\frac{\\pi}{n}$ is small and positive. $\\cos(\\pi/n) \\approx 1$, $\\sin^2(\\pi/n) > 0$. The result is negative.\n    *   In the integral, for $x \\in (0,1)$, $\\ln x < 0$. For $x > 1$, $\\ln x > 0$.\n    *   For large $n$, $\\frac{1}{1+x^n} \\approx 1$ on $(0,1)$ and $\\approx 0$ on $(1, \\infty)$. The negative contribution from $(0,1)$ dominates. The negative sign is consistent.",
        "raw_answer": "Based on the task requirements, I have generated a challenging problem involving special functions (specifically the Gamma function and properties of improper integrals) and provided a complete, rigorous solution.\n\n---\n\n### **Problem Statement**\n\n**Problem:** For a real parameter $n > 1$, evaluate the definite integral:\n\n$$ I(n) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx $$\n\nProvide a closed-form expression for $I(n)$ in terms of standard mathematical constants and trigonometric functions. Justify all steps, including the convergence of the integral and the validity of any operations involving differentiation under the integral sign.\n\n---\n\n### **Solution**\n\nWe aim to evaluate the integral $I(n) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx$ for $n > 1$.\n\n#### **1. Convergence Analysis**\n\nFirst, we establish that the integral is well-defined.\nLet $f(x) = \\frac{\\ln x}{1+x^n}$.\n*   **Near $x \\to 0^+$:** The denominator $1+x^n \\approx 1$. Thus, $f(x) \\sim \\ln x$. Since $\\int_0^1 \\ln x \\, dx$ is absolutely convergent (calculating to $-1$), the integral converges at the lower bound.\n*   **Near $x \\to \\infty$:** For large $x$, $1+x^n \\sim x^n$. Thus, $f(x) \\sim \\frac{\\ln x}{x^n}$. Since $n > 1$, let $\\epsilon = \\frac{n-1}{2} > 0$. We have $\\frac{\\ln x}{x^n} = \\frac{\\ln x}{x^\\epsilon} \\cdot \\frac{1}{x^{n-\\epsilon}}$. Since $\\frac{\\ln x}{x^\\epsilon} \\to 0$, the tail is bounded by $C \\cdot \\frac{1}{x^{1+\\epsilon}}$, which converges by the $p$-test ($p = 1 + \\epsilon > 1$).\n\nThus, $I(n)$ converges for all $n > 1$.\n\n#### **2. Introduction of a Parameterized Integral**\n\nWe introduce a parameterized auxiliary integral (the Mellin transform of the function $\\frac{1}{1+x^n}$):\n$$ J(s) = \\int_0^{\\infty} \\frac{x^{s-1}}{1+x^n} \\, dx $$\nNotice that\n$$ \\frac{\\partial}{\\partial s} \\left( \\frac{x^{s-1}}{1+x^n} \\right) = \\frac{x^{s-1} \\ln x}{1+x^n} $$\nEvaluating this derivative at $s=1$ yields our target integrand:\n$$ J'(1) = \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx = I(n) $$\n\nTo rigorously justify differentiation under the integral sign, we verify the uniform convergence of the integral of the derivative. Let $s \\in [1-\\delta, 1+\\delta]$. We require the domain of integration for $s$ to satisfy $0 < s < n$ for $J(s)$ to converge. Since $n > 1$, we can choose $\\delta > 0$ such that $[1-\\delta, 1+\\delta] \\subset (0, n)$.\n*   On $(0, 1]$, $|x^{s-1}| \\le x^{-\\delta}$.\n*   On $[1, \\infty)$, $|x^{s-1}| \\le x^{\\delta}$.\nThe dominating function $g(x) = \\frac{|\\ln x| (x^{-\\delta} + x^{\\delta})}{1+x^n}$ is integrable on $(0, \\infty)$ given the choice of $\\delta$. By the Leibniz Integral Rule, $I(n) = J'(1)$.\n\n#### **3. Evaluation of $J(s)$ via Beta and Gamma Functions**\n\nWe evaluate $J(s)$ using a substitution to map it to the Beta function definition, $B(a, b) = \\int_0^\\infty \\frac{t^{a-1}}{(1+t)^{a+b}} \\, dt$.\n\nLet $u = x^n$. Then $x = u^{1/n}$ and $dx = \\frac{1}{n} u^{1/n - 1} \\, du$.\nSubstituting into $J(s)$:\n$$ J(s) = \\int_0^{\\infty} \\frac{(u^{1/n})^{s-1}}{1+u} \\cdot \\frac{1}{n} u^{1/n - 1} \\, du $$\n$$ J(s) = \\frac{1}{n} \\int_0^{\\infty} \\frac{u^{s/n - 1/n + 1/n - 1}}{1+u} \\, du $$\n$$ J(s) = \\frac{1}{n} \\int_0^{\\infty} \\frac{u^{s/n - 1}}{1+u} \\, du $$\n\nComparing this to the Beta function form $B(a, b)$ with $a = s/n$:\nSince the denominator is $(1+u)^1$, we must have $a+b=1$, implying $b = 1 - s/n$.\nThus:\n$$ J(s) = \\frac{1}{n} B\\left(\\frac{s}{n}, 1 - \\frac{s}{n}\\right) $$\n\nWe relate the Beta function to the Gamma function using the identity $B(x, y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$:\n$$ J(s) = \\frac{1}{n} \\frac{\\Gamma(s/n)\\Gamma(1 - s/n)}{\\Gamma(1)} $$\nSince $\\Gamma(1) = 1$, we invoke Euler's Reflection Formula, $\\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)}$, with $z = s/n$:\n$$ J(s) = \\frac{1}{n} \\cdot \\frac{\\pi}{\\sin(\\pi s/n)} $$\nThis closed form is valid for $0 < s < n$.\n\n#### **4. Computing the Derivative**\n\nWe now compute $I(n) = J'(1)$.\n$$ J(s) = \\frac{\\pi}{n} \\csc\\left(\\frac{\\pi s}{n}\\right) $$\nDifferentiating with respect to $s$:\n$$ J'(s) = \\frac{\\pi}{n} \\cdot \\frac{d}{ds} \\left( \\csc\\left(\\frac{\\pi s}{n}\\right) \\right) $$\nUsing the chain rule $\\frac{d}{dx} \\csc(u) = -\\csc(u)\\cot(u) \\frac{du}{dx}$:\n$$ J'(s) = \\frac{\\pi}{n} \\left( -\\csc\\left(\\frac{\\pi s}{n}\\right) \\cot\\left(\\frac{\\pi s}{n}\\right) \\cdot \\frac{\\pi}{n} \\right) $$\n$$ J'(s) = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\pi s/n)}{\\sin^2(\\pi s/n)} $$\n\nNow, evaluate at $s=1$:\n$$ I(n) = J'(1) = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\pi/n)}{\\sin^2(\\pi/n)} $$\n\n#### **Conclusion**\n\nThe value of the integral for $n > 1$ is:\n\n$$ \\int_0^{\\infty} \\frac{\\ln x}{1+x^n} \\, dx = - \\frac{\\pi^2}{n^2} \\frac{\\cos(\\frac{\\pi}{n})}{\\sin^2(\\frac{\\pi}{n})} $$\n\n**Verification of Special Cases:**\n1.  **$n=2$**: $\\cos(\\pi/2) = 0$. The formula gives $0$.\n    *   Check: $\\int_0^\\infty \\frac{\\ln x}{1+x^2} dx$. Let $x=1/t$, $dx = -1/t^2 dt$.\n    *   $I = \\int_\\infty^0 \\frac{\\ln(1/t)}{1+1/t^2} (-1/t^2) dt = \\int_0^\\infty \\frac{-\\ln t}{t^2+1} dt = -I \\implies 2I=0 \\implies I=0$. Consistent.\n2.  **Sign check**: For large $n$, $\\frac{\\pi}{n}$ is small and positive. $\\cos(\\pi/n) \\approx 1$, $\\sin^2(\\pi/n) > 0$. The result is negative.\n    *   In the integral, for $x \\in (0,1)$, $\\ln x < 0$. For $x > 1$, $\\ln x > 0$.\n    *   For large $n$, $\\frac{1}{1+x^n} \\approx 1$ on $(0,1)$ and $\\approx 0$ on $(1, \\infty)$. The negative contribution from $(0,1)$ dominates. The negative sign is consistent.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of ordinary differential equations (ODEs), along with a complete and clear solution. The problem should be solvable, verifiable, and not require external resources or conjectures.\n\n## Step 2: Formulate the problem\nTo create a meaningful problem, we need to consider an ODE that is not trivial and involves some level of mathematical sophistication. Let's consider a second-order linear homogeneous differential equation with constant coefficients, which is a standard topic in ODEs.\n\n## Step 3: Propose a specific problem\nConsider the differential equation $y'' + 4y' + 4y = 0$. The task is to find the general solution to this equation.\n\n## Step 4: Verify the problem meets the criteria\n- **Non-trivial**: The equation is not straightforward to solve by inspection.\n- **Solvable**: The equation can be solved using standard methods for linear differential equations with constant coefficients.\n- **Verifiable**: The solution can be verified by substitution into the differential equation.",
    "run_id": "22",
    "outer_attempt": 1,
    "topic_slug": "ordinary_differential_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Based on the problem formulation provided in the question text, the task is to find the general solution to the ordinary differential equation given in Step 3.\n\n**Problem Statement**\nFind the general solution to the second-order linear homogeneous differential equation:\n$$ y'' + 4y' + 4y = 0 $$\nwhere $y$ is a function of the independent variable $x$, i.e., $y = y(x)$.\n\n---\n\n### **Solution Derivation**\n\nWe will solve this differential equation using the method of characteristic equations. To ensure a complete reasoning chain and rigor, we will also justify the form of the solution for the repeated root case using operator factorization.\n\n**1. Characteristic Equation Method**\n\nWe seek solutions of the form $y(x) = e^{rx}$, where $r$ is a constant. Differentiating $y$ with respect to $x$:\n$$ y' = r e^{rx} $$\n$$ y'' = r^2 e^{rx} $$\n\nSubstituting these into the original differential equation:\n$$ r^2 e^{rx} + 4(r e^{rx}) + 4(e^{rx}) = 0 $$\n\nFactoring out the non-zero term $e^{rx}$:\n$$ e^{rx} (r^2 + 4r + 4) = 0 $$\n\nSince $e^{rx} \\neq 0$ for any real $x$, we must have:\n$$ r^2 + 4r + 4 = 0 $$\n\nThis is the **characteristic equation**. We solve for $r$ by factoring:\n$$ (r + 2)^2 = 0 $$\n\nThis yields a repeated real root:\n$$ r = -2 \\quad (\\text{with multiplicity } 2) $$\n\n**2. Constructing the General Solution**\n\nSince we have a repeated root $r = -2$, we know that one linearly independent solution is:\n$$ y_1(x) = e^{-2x} $$\n\nTo find the second linearly independent solution required for a second-order equation, we can use the method of **reduction of order** or **operator factorization**. We will demonstrate the operator factorization approach to rigorously derive the second solution.\n\nRewrite the differential equation using the differential operator $D = \\frac{d}{dx}$:\n$$ (D^2 + 4D + 4)y = 0 $$\n$$ (D + 2)(D + 2)y = 0 $$\n\nLet $u = (D + 2)y$. Then the equation becomes:\n$$ (D + 2)u = 0 $$\nThis is a first-order linear equation: $u' + 2u = 0$. The general solution is:\n$$ u(x) = c_1 e^{-2x} $$\nwhere $c_1$ is an arbitrary constant.\n\nNow substitute back $u = (D + 2)y$:\n$$ y' + 2y = c_1 e^{-2x} $$\n\nThis is a first-order linear non-homogeneous differential equation for $y$. We solve it using the integrating factor method.\nThe integrating factor is $I(x) = e^{\\int 2 \\, dx} = e^{2x}$.\nMultiplying both sides by $e^{2x}$:\n$$ e^{2x}y' + 2e^{2x}y = c_1 e^{-2x} \\cdot e^{2x} $$\n$$ \\frac{d}{dx} (e^{2x} y) = c_1 $$\n\nIntegrating both sides with respect to $x$:\n$$ e^{2x} y = \\int c_1 \\, dx $$\n$$ e^{2x} y = c_1 x + c_2 $$\nwhere $c_2$ is the second arbitrary constant.\n\nSolving for $y(x)$ by multiplying by $e^{-2x}$:\n$$ y(x) = (c_1 x + c_2) e^{-2x} $$\n$$ y(x) = c_1 x e^{-2x} + c_2 e^{-2x} $$\n\nThus, the fundamental set of solutions is $\\{e^{-2x}, x e^{-2x}\\}$.\n\n---\n\n### **Verification**\n\nWe verify that $y(x) = c_1 x e^{-2x} + c_2 e^{-2x}$ satisfies the original ODE $y'' + 4y' + 4y = 0$.\n\nCompute the derivatives:\n1.  **First Derivative ($y'$):**\n    $$ y' = \\frac{d}{dx}(c_1 x e^{-2x} + c_2 e^{-2x}) $$\n    $$ y' = c_1(1 \\cdot e^{-2x} + x(-2)e^{-2x}) - 2c_2 e^{-2x} $$\n    $$ y' = (c_1 - 2c_2)e^{-2x} - 2c_1 x e^{-2x} $$\n\n2.  **Second Derivative ($y''$):**\n    $$ y'' = \\frac{d}{dx}((c_1 - 2c_2)e^{-2x} - 2c_1 x e^{-2x}) $$\n    $$ y'' = -2(c_1 - 2c_2)e^{-2x} - 2c_1(e^{-2x} - 2x e^{-2x}) $$\n    $$ y'' = (-2c_1 + 4c_2 - 2c_1)e^{-2x} + 4c_1 x e^{-2x} $$\n    $$ y'' = (4c_2 - 4c_1)e^{-2x} + 4c_1 x e^{-2x} $$\n\n**Substitute into the ODE:**\n$$ y'' + 4y' + 4y = \\left[ (4c_2 - 4c_1)e^{-2x} + 4c_1 x e^{-2x} \\right] + 4\\left[ (c_1 - 2c_2)e^{-2x} - 2c_1 x e^{-2x} \\right] + 4\\left[ c_1 x e^{-2x} + c_2 e^{-2x} \\right] $$\n\n**Group by terms:**\n- **$x e^{-2x}$ terms:**\n  $$ 4c_1 - 8c_1 + 4c_1 = 0 $$\n- **$e^{-2x}$ terms:**\n  $$ (4c_2 - 4c_1) + (4c_1 - 8c_2) + 4c_2 $$\n  $$ = -4c_1 + 4c_1 + 4c_2 - 8c_2 + 4c_2 = 0 $$\n\nThe sum is identically zero. The solution is verified.\n\n---\n\n### **Final Answer**\n\nThe general solution to the differential equation $y'' + 4y' + 4y = 0$ is:\n$$ y(x) = c_1 e^{-2x} + c_2 x e^{-2x} $$\nwhere $c_1$ and $c_2$ are arbitrary real constants and $x \\in \\mathbb{R}$.",
        "raw_answer": "Based on the problem formulation provided in the question text, the task is to find the general solution to the ordinary differential equation given in Step 3.\n\n**Problem Statement**\nFind the general solution to the second-order linear homogeneous differential equation:\n$$ y'' + 4y' + 4y = 0 $$\nwhere $y$ is a function of the independent variable $x$, i.e., $y = y(x)$.\n\n---\n\n### **Solution Derivation**\n\nWe will solve this differential equation using the method of characteristic equations. To ensure a complete reasoning chain and rigor, we will also justify the form of the solution for the repeated root case using operator factorization.\n\n**1. Characteristic Equation Method**\n\nWe seek solutions of the form $y(x) = e^{rx}$, where $r$ is a constant. Differentiating $y$ with respect to $x$:\n$$ y' = r e^{rx} $$\n$$ y'' = r^2 e^{rx} $$\n\nSubstituting these into the original differential equation:\n$$ r^2 e^{rx} + 4(r e^{rx}) + 4(e^{rx}) = 0 $$\n\nFactoring out the non-zero term $e^{rx}$:\n$$ e^{rx} (r^2 + 4r + 4) = 0 $$\n\nSince $e^{rx} \\neq 0$ for any real $x$, we must have:\n$$ r^2 + 4r + 4 = 0 $$\n\nThis is the **characteristic equation**. We solve for $r$ by factoring:\n$$ (r + 2)^2 = 0 $$\n\nThis yields a repeated real root:\n$$ r = -2 \\quad (\\text{with multiplicity } 2) $$\n\n**2. Constructing the General Solution**\n\nSince we have a repeated root $r = -2$, we know that one linearly independent solution is:\n$$ y_1(x) = e^{-2x} $$\n\nTo find the second linearly independent solution required for a second-order equation, we can use the method of **reduction of order** or **operator factorization**. We will demonstrate the operator factorization approach to rigorously derive the second solution.\n\nRewrite the differential equation using the differential operator $D = \\frac{d}{dx}$:\n$$ (D^2 + 4D + 4)y = 0 $$\n$$ (D + 2)(D + 2)y = 0 $$\n\nLet $u = (D + 2)y$. Then the equation becomes:\n$$ (D + 2)u = 0 $$\nThis is a first-order linear equation: $u' + 2u = 0$. The general solution is:\n$$ u(x) = c_1 e^{-2x} $$\nwhere $c_1$ is an arbitrary constant.\n\nNow substitute back $u = (D + 2)y$:\n$$ y' + 2y = c_1 e^{-2x} $$\n\nThis is a first-order linear non-homogeneous differential equation for $y$. We solve it using the integrating factor method.\nThe integrating factor is $I(x) = e^{\\int 2 \\, dx} = e^{2x}$.\nMultiplying both sides by $e^{2x}$:\n$$ e^{2x}y' + 2e^{2x}y = c_1 e^{-2x} \\cdot e^{2x} $$\n$$ \\frac{d}{dx} (e^{2x} y) = c_1 $$\n\nIntegrating both sides with respect to $x$:\n$$ e^{2x} y = \\int c_1 \\, dx $$\n$$ e^{2x} y = c_1 x + c_2 $$\nwhere $c_2$ is the second arbitrary constant.\n\nSolving for $y(x)$ by multiplying by $e^{-2x}$:\n$$ y(x) = (c_1 x + c_2) e^{-2x} $$\n$$ y(x) = c_1 x e^{-2x} + c_2 e^{-2x} $$\n\nThus, the fundamental set of solutions is $\\{e^{-2x}, x e^{-2x}\\}$.\n\n---\n\n### **Verification**\n\nWe verify that $y(x) = c_1 x e^{-2x} + c_2 e^{-2x}$ satisfies the original ODE $y'' + 4y' + 4y = 0$.\n\nCompute the derivatives:\n1.  **First Derivative ($y'$):**\n    $$ y' = \\frac{d}{dx}(c_1 x e^{-2x} + c_2 e^{-2x}) $$\n    $$ y' = c_1(1 \\cdot e^{-2x} + x(-2)e^{-2x}) - 2c_2 e^{-2x} $$\n    $$ y' = (c_1 - 2c_2)e^{-2x} - 2c_1 x e^{-2x} $$\n\n2.  **Second Derivative ($y''$):**\n    $$ y'' = \\frac{d}{dx}((c_1 - 2c_2)e^{-2x} - 2c_1 x e^{-2x}) $$\n    $$ y'' = -2(c_1 - 2c_2)e^{-2x} - 2c_1(e^{-2x} - 2x e^{-2x}) $$\n    $$ y'' = (-2c_1 + 4c_2 - 2c_1)e^{-2x} + 4c_1 x e^{-2x} $$\n    $$ y'' = (4c_2 - 4c_1)e^{-2x} + 4c_1 x e^{-2x} $$\n\n**Substitute into the ODE:**\n$$ y'' + 4y' + 4y = \\left[ (4c_2 - 4c_1)e^{-2x} + 4c_1 x e^{-2x} \\right] + 4\\left[ (c_1 - 2c_2)e^{-2x} - 2c_1 x e^{-2x} \\right] + 4\\left[ c_1 x e^{-2x} + c_2 e^{-2x} \\right] $$\n\n**Group by terms:**\n- **$x e^{-2x}$ terms:**\n  $$ 4c_1 - 8c_1 + 4c_1 = 0 $$\n- **$e^{-2x}$ terms:**\n  $$ (4c_2 - 4c_1) + (4c_1 - 8c_2) + 4c_2 $$\n  $$ = -4c_1 + 4c_1 + 4c_2 - 8c_2 + 4c_2 = 0 $$\n\nThe sum is identically zero. The solution is verified.\n\n---\n\n### **Final Answer**\n\nThe general solution to the differential equation $y'' + 4y' + 4y = 0$ is:\n$$ y(x) = c_1 e^{-2x} + c_2 x e^{-2x} $$\nwhere $c_1$ and $c_2$ are arbitrary real constants and $x \\in \\mathbb{R}$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Consider the one-dimensional heat equation given by $\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}$, where $\\alpha > 0$ is a constant, $x \\in [0, L]$, and $t \\geq 0$. The boundary conditions are $u(0, t) = u(L, t) = 0$ for all $t \\geq 0$, and the initial condition is $u(x, 0) = \\sin(\\frac{\\pi x}{L}) + 2\\sin(\\frac{3\\pi x}{L})$. Find the solution $u(x, t)$ for $x \\in [0, L]$ and $t \\geq 0$.",
    "run_id": "23",
    "outer_attempt": 1,
    "topic_slug": "partial_differential_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the one-dimensional heat equation subject to the given boundary and initial conditions, we will use the method of separation of variables.\n\n### 1. Problem Formulation\n\nWe are solving the partial differential equation (PDE):\n$$ \\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2} $$\nfor $x \\in [0, L]$ and $t \\geq 0$, with $\\alpha > 0$.\n\n**Boundary Conditions (BCs):**\n$$ u(0, t) = 0, \\quad u(L, t) = 0, \\quad \\text{for } t \\geq 0 $$\n\n**Initial Condition (IC):**\n$$ u(x, 0) = \\sin\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\left(\\frac{3\\pi x}{L}\\right) $$\n\n### 2. Separation of Variables\n\nWe look for separable solutions of the form:\n$$ u(x, t) = X(x)T(t) $$\n\nSubstituting this into the PDE gives:\n$$ X(x)T'(t) = \\alpha X''(x)T(t) $$\n\nDividing both sides by $\\alpha X(x)T(t)$ (assuming non-zero solution) separates the variables:\n$$ \\frac{T'(t)}{\\alpha T(t)} = \\frac{X''(x)}{X(x)} $$\n\nSince the left side depends only on $t$ and the right side depends only on $x$, both must equal a constant. Let this separation constant be $-\\lambda$. Thus, we obtain two ordinary differential equations:\n1.  **Spatial Equation:** $X''(x) + \\lambda X(x) = 0$\n2.  **Temporal Equation:** $T'(t) + \\alpha \\lambda T(t) = 0$\n\n### 3. Solving the Spatial Problem (Eigenvalue Problem)\n\nWe solve the spatial equation subject to the boundary conditions derived from $u(0, t) = 0$ and $u(L, t) = 0$, which imply $X(0) = 0$ and $X(L) = 0$.\n\n$$ X''(x) + \\lambda X(x) = 0, \\quad X(0) = 0, \\quad X(L) = 0 $$\n\nWe analyze the possible cases for $\\lambda$:\n\n*   **Case 1: $\\lambda < 0$**. Let $\\lambda = -k^2$ where $k > 0$.\n    The general solution is $X(x) = c_1 e^{kx} + c_2 e^{-kx}$.\n    $X(0) = c_1 + c_2 = 0 \\implies c_2 = -c_1$.\n    $X(L) = c_1 (e^{kL} - e^{-kL}) = 2c_1 \\sinh(kL) = 0$. Since $\\sinh(kL) \\neq 0$ for $k, L > 0$, we must have $c_1 = 0$, leading to the trivial solution $u \\equiv 0$.\n\n*   **Case 2: $\\lambda = 0$**.\n    The general solution is $X(x) = c_1 x + c_2$.\n    $X(0) = c_2 = 0$.\n    $X(L) = c_1 L = 0 \\implies c_1 = 0$. This also leads to the trivial solution.\n\n*   **Case 3: $\\lambda > 0$**. Let $\\lambda = k^2$ where $k > 0$.\n    The general solution is $X(x) = c_1 \\cos(kx) + c_2 \\sin(kx)$.\n    Applying $X(0) = 0$:\n    $$ c_1 \\cos(0) + c_2 \\sin(0) = c_1 = 0 $$\n    So, $X(x) = c_2 \\sin(kx)$.\n    Applying $X(L) = 0$:\n    $$ c_2 \\sin(kL) = 0 $$\n    For a non-trivial solution ($c_2 \\neq 0$), we require $\\sin(kL) = 0$. This implies:\n    $$ kL = n\\pi, \\quad n = 1, 2, 3, \\dots $$\n    Thus, $k_n = \\frac{n\\pi}{L}$.\n\nThis yields the eigenvalues and corresponding eigenfunctions:\n$$ \\lambda_n = \\left(\\frac{n\\pi}{L}\\right)^2, \\quad X_n(x) = \\sin\\left(\\frac{n\\pi x}{L}\\right), \\quad n = 1, 2, \\dots $$\n\n### 4. Solving the Temporal Problem\n\nSubstitute $\\lambda_n$ into the temporal equation:\n$$ T_n'(t) + \\alpha \\left(\\frac{n\\pi}{L}\\right)^2 T_n(t) = 0 $$\n\nThe solution to this first-order linear ODE is:\n$$ T_n(t) = B_n e^{-\\alpha \\left(\\frac{n\\pi}{L}\\right)^2 t} $$\nwhere $B_n$ is an arbitrary constant.\n\n### 5. General Solution\n\nBy the principle of superposition, the general solution is the sum of all fundamental solutions $u_n(x, t) = X_n(x)T_n(t)$:\n$$ u(x, t) = \\sum_{n=1}^{\\infty} B_n \\sin\\left(\\frac{n\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{n\\pi}{L}\\right)^2 t} $$\n\n### 6. Applying the Initial Condition\n\nWe determine the coefficients $B_n$ using the initial condition at $t = 0$:\n$$ u(x, 0) = \\sum_{n=1}^{\\infty} B_n \\sin\\left(\\frac{n\\pi x}{L}\\right) $$\n\nWe are given:\n$$ u(x, 0) = \\sin\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\left(\\frac{3\\pi x}{L}\\right) $$\n\nComparing the series expansion with the given function, we can determine the coefficients $B_n$ by inspection (due to the orthogonality of the sine functions $\\sin(\\frac{n\\pi x}{L})$ over $[0, L]$):\n\n1.  The term for $n=1$ in the series is $B_1 \\sin(\\frac{\\pi x}{L})$. Matching this with the IC term $\\sin(\\frac{\\pi x}{L})$, we get:\n    $$ B_1 = 1 $$\n\n2.  The term for $n=3$ in the series is $B_3 \\sin(\\frac{3\\pi x}{L})$. Matching this with the IC term $2\\sin(\\frac{3\\pi x}{L})$, we get:\n    $$ B_3 = 2 $$\n\n3.  For all other $n$ (i.e., $n \\neq 1$ and $n \\neq 3$), the coefficients are zero:\n    $$ B_n = 0 $$\n\n### 7. Final Solution\n\nSubstitute the non-zero coefficients $B_1$ and $B_3$ back into the general solution series:\n\nFor $n=1$:\n$$ \\text{Term}_1 = 1 \\cdot \\sin\\left(\\frac{\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{\\pi}{L}\\right)^2 t} $$\n\nFor $n=3$:\n$$ \\text{Term}_3 = 2 \\cdot \\sin\\left(\\frac{3\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{3\\pi}{L}\\right)^2 t} $$\n\nCombining these, the solution is:\n$$ u(x, t) = e^{-\\frac{\\alpha \\pi^2}{L^2} t} \\sin\\left(\\frac{\\pi x}{L}\\right) + 2 e^{-\\frac{9\\alpha \\pi^2}{L^2} t} \\sin\\left(\\frac{3\\pi x}{L}\\right) $$\n\n**Answer:**\nThe solution to the heat equation is:\n$$ u(x, t) = e^{-\\frac{\\alpha \\pi^2 t}{L^2}} \\sin\\left(\\frac{\\pi x}{L}\\right) + 2 e^{-\\frac{9\\alpha \\pi^2 t}{L^2}} \\sin\\left(\\frac{3\\pi x}{L}\\right) $$",
        "raw_answer": "To solve the one-dimensional heat equation subject to the given boundary and initial conditions, we will use the method of separation of variables.\n\n### 1. Problem Formulation\n\nWe are solving the partial differential equation (PDE):\n$$ \\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2} $$\nfor $x \\in [0, L]$ and $t \\geq 0$, with $\\alpha > 0$.\n\n**Boundary Conditions (BCs):**\n$$ u(0, t) = 0, \\quad u(L, t) = 0, \\quad \\text{for } t \\geq 0 $$\n\n**Initial Condition (IC):**\n$$ u(x, 0) = \\sin\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\left(\\frac{3\\pi x}{L}\\right) $$\n\n### 2. Separation of Variables\n\nWe look for separable solutions of the form:\n$$ u(x, t) = X(x)T(t) $$\n\nSubstituting this into the PDE gives:\n$$ X(x)T'(t) = \\alpha X''(x)T(t) $$\n\nDividing both sides by $\\alpha X(x)T(t)$ (assuming non-zero solution) separates the variables:\n$$ \\frac{T'(t)}{\\alpha T(t)} = \\frac{X''(x)}{X(x)} $$\n\nSince the left side depends only on $t$ and the right side depends only on $x$, both must equal a constant. Let this separation constant be $-\\lambda$. Thus, we obtain two ordinary differential equations:\n1.  **Spatial Equation:** $X''(x) + \\lambda X(x) = 0$\n2.  **Temporal Equation:** $T'(t) + \\alpha \\lambda T(t) = 0$\n\n### 3. Solving the Spatial Problem (Eigenvalue Problem)\n\nWe solve the spatial equation subject to the boundary conditions derived from $u(0, t) = 0$ and $u(L, t) = 0$, which imply $X(0) = 0$ and $X(L) = 0$.\n\n$$ X''(x) + \\lambda X(x) = 0, \\quad X(0) = 0, \\quad X(L) = 0 $$\n\nWe analyze the possible cases for $\\lambda$:\n\n*   **Case 1: $\\lambda < 0$**. Let $\\lambda = -k^2$ where $k > 0$.\n    The general solution is $X(x) = c_1 e^{kx} + c_2 e^{-kx}$.\n    $X(0) = c_1 + c_2 = 0 \\implies c_2 = -c_1$.\n    $X(L) = c_1 (e^{kL} - e^{-kL}) = 2c_1 \\sinh(kL) = 0$. Since $\\sinh(kL) \\neq 0$ for $k, L > 0$, we must have $c_1 = 0$, leading to the trivial solution $u \\equiv 0$.\n\n*   **Case 2: $\\lambda = 0$**.\n    The general solution is $X(x) = c_1 x + c_2$.\n    $X(0) = c_2 = 0$.\n    $X(L) = c_1 L = 0 \\implies c_1 = 0$. This also leads to the trivial solution.\n\n*   **Case 3: $\\lambda > 0$**. Let $\\lambda = k^2$ where $k > 0$.\n    The general solution is $X(x) = c_1 \\cos(kx) + c_2 \\sin(kx)$.\n    Applying $X(0) = 0$:\n    $$ c_1 \\cos(0) + c_2 \\sin(0) = c_1 = 0 $$\n    So, $X(x) = c_2 \\sin(kx)$.\n    Applying $X(L) = 0$:\n    $$ c_2 \\sin(kL) = 0 $$\n    For a non-trivial solution ($c_2 \\neq 0$), we require $\\sin(kL) = 0$. This implies:\n    $$ kL = n\\pi, \\quad n = 1, 2, 3, \\dots $$\n    Thus, $k_n = \\frac{n\\pi}{L}$.\n\nThis yields the eigenvalues and corresponding eigenfunctions:\n$$ \\lambda_n = \\left(\\frac{n\\pi}{L}\\right)^2, \\quad X_n(x) = \\sin\\left(\\frac{n\\pi x}{L}\\right), \\quad n = 1, 2, \\dots $$\n\n### 4. Solving the Temporal Problem\n\nSubstitute $\\lambda_n$ into the temporal equation:\n$$ T_n'(t) + \\alpha \\left(\\frac{n\\pi}{L}\\right)^2 T_n(t) = 0 $$\n\nThe solution to this first-order linear ODE is:\n$$ T_n(t) = B_n e^{-\\alpha \\left(\\frac{n\\pi}{L}\\right)^2 t} $$\nwhere $B_n$ is an arbitrary constant.\n\n### 5. General Solution\n\nBy the principle of superposition, the general solution is the sum of all fundamental solutions $u_n(x, t) = X_n(x)T_n(t)$:\n$$ u(x, t) = \\sum_{n=1}^{\\infty} B_n \\sin\\left(\\frac{n\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{n\\pi}{L}\\right)^2 t} $$\n\n### 6. Applying the Initial Condition\n\nWe determine the coefficients $B_n$ using the initial condition at $t = 0$:\n$$ u(x, 0) = \\sum_{n=1}^{\\infty} B_n \\sin\\left(\\frac{n\\pi x}{L}\\right) $$\n\nWe are given:\n$$ u(x, 0) = \\sin\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\left(\\frac{3\\pi x}{L}\\right) $$\n\nComparing the series expansion with the given function, we can determine the coefficients $B_n$ by inspection (due to the orthogonality of the sine functions $\\sin(\\frac{n\\pi x}{L})$ over $[0, L]$):\n\n1.  The term for $n=1$ in the series is $B_1 \\sin(\\frac{\\pi x}{L})$. Matching this with the IC term $\\sin(\\frac{\\pi x}{L})$, we get:\n    $$ B_1 = 1 $$\n\n2.  The term for $n=3$ in the series is $B_3 \\sin(\\frac{3\\pi x}{L})$. Matching this with the IC term $2\\sin(\\frac{3\\pi x}{L})$, we get:\n    $$ B_3 = 2 $$\n\n3.  For all other $n$ (i.e., $n \\neq 1$ and $n \\neq 3$), the coefficients are zero:\n    $$ B_n = 0 $$\n\n### 7. Final Solution\n\nSubstitute the non-zero coefficients $B_1$ and $B_3$ back into the general solution series:\n\nFor $n=1$:\n$$ \\text{Term}_1 = 1 \\cdot \\sin\\left(\\frac{\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{\\pi}{L}\\right)^2 t} $$\n\nFor $n=3$:\n$$ \\text{Term}_3 = 2 \\cdot \\sin\\left(\\frac{3\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{3\\pi}{L}\\right)^2 t} $$\n\nCombining these, the solution is:\n$$ u(x, t) = e^{-\\frac{\\alpha \\pi^2}{L^2} t} \\sin\\left(\\frac{\\pi x}{L}\\right) + 2 e^{-\\frac{9\\alpha \\pi^2}{L^2} t} \\sin\\left(\\frac{3\\pi x}{L}\\right) $$\n\n**Answer:**\nThe solution to the heat equation is:\n$$ u(x, t) = e^{-\\frac{\\alpha \\pi^2 t}{L^2}} \\sin\\left(\\frac{\\pi x}{L}\\right) + 2 e^{-\\frac{9\\alpha \\pi^2 t}{L^2}} \\sin\\left(\\frac{3\\pi x}{L}\\right) $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of dynamical systems and ergodic theory, along with a complete and verifiable solution.\n\n## Step 2: Identify key concepts in dynamical systems and ergodic theory\nDynamical systems involve the study of the behavior of systems that change over time according to certain rules. Ergodic theory is a branch of mathematics that studies the behavior of dynamical systems over time, focusing on their statistical properties. Key concepts include ergodicity, measure-preserving transformations, and the ergodic theorem.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to incorporate concepts from dynamical systems and ergodic theory. A potential problem could involve analyzing the behavior of a specific dynamical system, such as determining if it is ergodic or calculating its invariant measures.\n\n## Step 4: Specify the problem\nLet's consider a simple yet challenging example: the rotation map on the unit circle. The unit circle can be represented as $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$, and a rotation map $T: \\mathbb{T} \\to \\mathbb{T}$ is defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$.\n\n## Step 5: Formulate the question\nWe can ask whether the rotation map $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$ when $\\alpha$ is irrational.\n\n## Step 6: Write the problem statement\n\"Let $T: \\mathbb{T} \\to \\mathbb{T}$ be defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$ is irrational. Prove that $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$.\"\n\n## Step 7: Provide the solution\nTo prove that $T$ is ergodic, we need to show that if $A \\subset \\mathbb{T}$ is $T$-invariant (i.e., $T(A) = A$) and measurable, then either $m(A) = 0$ or $m(A) = 1$, where $m$ denotes the Lebesgue measure.\n\n## Step 8: Detail the solution\nFirst, recall that $T$ is measure-preserving because $m(T^{-1}(A)) = m(A)$ for any measurable $A \\subset \\mathbb{T}$. For $T$ to be ergodic, we must show that $T$-invariant sets have measure 0 or 1.\n\n## Step 9: Use Fourier analysis to prove ergodicity\nConsider a $T$-invariant set $A$. The characteristic function $\\chi_A$ of $A$ is $T$-invariant, meaning $\\chi_A(T(x)) = \\chi_A(x)$. We can expand $\\chi_A$ in a Fourier series: $\\chi_A(x) = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi inx}$, where $c_n = \\int_{\\mathbb{T}} \\chi_A(x)e^{-2\\pi inx} dx$.\n\n## Step 10: Apply $T$-invariance to the Fourier series\nSince $\\chi_A(T(x)) = \\chi_A(x + \\alpha) = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi in(x + \\alpha)} = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi in\\alpha}e^{2\\pi inx}$, and this equals $\\chi_A(x)$, we have $c_n = c_n e^{2\\pi in\\alpha}$ for all $n$. For $\\alpha$ irrational, $e^{2\\pi in\\alpha} \\neq 1$ unless $n = 0$. Thus, $c_n = 0$ for $n \\neq 0$.\n\n## Step 11: Conclude ergodicity from the Fourier analysis\nThis implies $\\chi_A(x) = c_0 = \\int_{\\mathbb{T}} \\chi_A(x) dx = m(A)$, meaning $\\chi_A$ is constant. Hence, $A$ is either $\\mathbb{T}$ (if $m(A) = 1$) or $\\emptyset$ (if $m(A) = 0$), proving $T$ is ergodic.\n\n## Step 12: Format the question and answer according to the required structure\n\nLet $T: \\mathbb{T} \\to \\mathbb{T}$ be defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$ is irrational. Prove that $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$.",
    "run_id": "24",
    "outer_attempt": 1,
    "topic_slug": "dynamical_systems_and_ergodic_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete and rigorous proof for the problem posed.\n\n### Problem Statement\n\n**Assume:** Let $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$ be the unit circle (torus) equipped with the Borel $\\sigma$-algebra and the Lebesgue probability measure $\\mu$. Let $\\alpha \\in \\mathbb{R}$ be an irrational number. Define the rotation map $T: \\mathbb{T} \\to \\mathbb{T}$ by:\n$$T(x) = x + \\alpha \\pmod 1$$\n\n**Task:** Prove that $T$ is ergodic with respect to $\\mu$.\n\n---\n\n### Solution\n\nTo prove that the transformation $T$ is ergodic, we must show that the only measurable sets $A \\subseteq \\mathbb{T}$ that are invariant under $T$ (meaning $T^{-1}(A) = A$ almost everywhere) are trivial sets, i.e., $\\mu(A) = 0$ or $\\mu(A) = 1$.\n\nAn equivalent and often more powerful characterization of ergodicity involves $L^2$ functions. A measure-preserving transformation $T$ is ergodic if and only if every function $f \\in L^2(\\mathbb{T}, \\mu)$ that is $T$-invariant (meaning $f \\circ T = f$ almost everywhere) is constant almost everywhere.\n\nWe will proceed using this functional analytic approach relying on Fourier series.\n\n#### Step 1: Verification of Measure Preservation\nFirst, we observe that $T$ preserves the Lebesgue measure $\\mu$. For any interval $I = [a, b) \\subseteq \\mathbb{T}$, the pre-image $T^{-1}(I) = [a-\\alpha, b-\\alpha)$ (modulo 1). Since the Lebesgue measure is translation invariant, $\\mu(T^{-1}(I)) = (b-\\alpha) - (a-\\alpha) = b-a = \\mu(I)$. Since this holds for intervals which generate the Borel $\\sigma$-algebra, $T$ is measure-preserving.\n\n#### Step 2: Fourier Expansion of an Invariant Function\nLet $f \\in L^2(\\mathbb{T}, \\mu)$ be a $T$-invariant function. That is:\n$$f(T(x)) = f(x) \\quad \\text{for } \\mu\\text{-almost every } x \\in \\mathbb{T}.$$\n\nSince $\\{e_n(x) = e^{2\\pi i n x} \\mid n \\in \\mathbb{Z}\\}$ forms an orthonormal basis for $L^2(\\mathbb{T}, \\mu)$, we can expand $f$ into a Fourier series:\n$$f(x) = \\sum_{n \\in \\mathbb{Z}} \\hat{f}(n) e^{2\\pi i n x}$$\nwhere the convergence is in the $L^2$ norm, and the Fourier coefficients are given by $\\hat{f}(n) = \\int_{\\mathbb{T}} f(x) e^{-2\\pi i n x} \\, d\\mu(x)$.\n\n#### Step 3: Analysis of the Transformed Function\nWe evaluate the composition $f \\circ T$. Substituting $T(x) = x + \\alpha$:\n$$f(T(x)) = f(x + \\alpha) = \\sum_{n \\in \\mathbb{Z}} \\hat{f}(n) e^{2\\pi i n (x + \\alpha)}$$\nUsing the properties of the exponential function:\n$$f(T(x)) = \\sum_{n \\in \\mathbb{Z}} \\left( \\hat{f}(n) e^{2\\pi i n \\alpha} \\right) e^{2\\pi i n x}$$\nThis series represents the Fourier expansion of the function $f \\circ T$.\n\n#### Step 4: Comparing Fourier Coefficients\nBy the hypothesis of invariance, $f(x) = f(T(x))$ almost everywhere. Since the Fourier coefficients of an $L^2$ function are unique, we equate the coefficients of $e^{2\\pi i n x}$ from the expansions in Step 2 and Step 3:\n$$\\hat{f}(n) = \\hat{f}(n) e^{2\\pi i n \\alpha} \\quad \\text{for all } n \\in \\mathbb{Z}.$$\n\nWe can rewrite this equation as:\n$$\\hat{f}(n) \\left( 1 - e^{2\\pi i n \\alpha} \\right) = 0.$$\n\n#### Step 5: Utilizing the Irrationality of $\\alpha$\nTo satisfy the equation derived in Step 4, for each $n$, at least one of the factors must be zero. We analyze the term $(1 - e^{2\\pi i n \\alpha})$:\n\n$$1 - e^{2\\pi i n \\alpha} = 0 \\iff e^{2\\pi i n \\alpha} = 1 \\iff n\\alpha \\in \\mathbb{Z}.$$\n\nSince $\\alpha$ is given to be **irrational**, the product $n\\alpha$ is an integer if and only if $n = 0$.\n- **Case $n = 0$:** The condition $0\\alpha \\in \\mathbb{Z}$ holds. The equation becomes $\\hat{f}(0)(0) = 0$, which imposes no constraint on $\\hat{f}(0)$.\n- **Case $n \\neq 0$:** Since $\\alpha \\notin \\mathbb{Q}$, $n\\alpha \\notin \\mathbb{Z}$. Therefore, $1 - e^{2\\pi i n \\alpha} \\neq 0$. To satisfy the product equation, we must have:\n  $$\\hat{f}(n) = 0 \\quad \\text{for all } n \\neq 0.$$\n\n#### Step 6: Conclusion\nThe Fourier series for $f$ reduces to a single term:\n$$f(x) = \\sum_{n \\in \\mathbb{Z}} \\hat{f}(n) e^{2\\pi i n x} = \\hat{f}(0) e^{2\\pi i (0) x} = \\hat{f}(0).$$\nThus, $f$ is equal to the constant $\\hat{f}(0)$ almost everywhere.\n\nWe have shown that any $T$-invariant $L^2$ function is essentially constant. To relate this back to sets:\nLet $A \\subseteq \\mathbb{T}$ be a measurable set such that $T^{-1}(A) = A$ (up to a set of measure zero).\nConsider the indicator function $\\chi_A(x)$. Since $A$ is invariant, $\\chi_A(T(x)) = \\chi_A(x)$ a.e.\nAlso, $\\chi_A \\in L^2(\\mathbb{T})$ because the space has finite measure.\nBy the result above, $\\chi_A$ is constant almost everywhere.\nSince an indicator function can only take values 0 or 1, $\\chi_A$ must be 0 a.e. or 1 a.e.\nTherefore, $\\mu(A) = 0$ or $\\mu(A) = 1$.\n\n**Final Result:**\nThe irrational rotation $T(x) = x + \\alpha \\pmod 1$ is ergodic with respect to the Lebesgue measure.",
        "raw_answer": "Here is the complete and rigorous proof for the problem posed.\n\n### Problem Statement\n\n**Assume:** Let $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$ be the unit circle (torus) equipped with the Borel $\\sigma$-algebra and the Lebesgue probability measure $\\mu$. Let $\\alpha \\in \\mathbb{R}$ be an irrational number. Define the rotation map $T: \\mathbb{T} \\to \\mathbb{T}$ by:\n$$T(x) = x + \\alpha \\pmod 1$$\n\n**Task:** Prove that $T$ is ergodic with respect to $\\mu$.\n\n---\n\n### Solution\n\nTo prove that the transformation $T$ is ergodic, we must show that the only measurable sets $A \\subseteq \\mathbb{T}$ that are invariant under $T$ (meaning $T^{-1}(A) = A$ almost everywhere) are trivial sets, i.e., $\\mu(A) = 0$ or $\\mu(A) = 1$.\n\nAn equivalent and often more powerful characterization of ergodicity involves $L^2$ functions. A measure-preserving transformation $T$ is ergodic if and only if every function $f \\in L^2(\\mathbb{T}, \\mu)$ that is $T$-invariant (meaning $f \\circ T = f$ almost everywhere) is constant almost everywhere.\n\nWe will proceed using this functional analytic approach relying on Fourier series.\n\n#### Step 1: Verification of Measure Preservation\nFirst, we observe that $T$ preserves the Lebesgue measure $\\mu$. For any interval $I = [a, b) \\subseteq \\mathbb{T}$, the pre-image $T^{-1}(I) = [a-\\alpha, b-\\alpha)$ (modulo 1). Since the Lebesgue measure is translation invariant, $\\mu(T^{-1}(I)) = (b-\\alpha) - (a-\\alpha) = b-a = \\mu(I)$. Since this holds for intervals which generate the Borel $\\sigma$-algebra, $T$ is measure-preserving.\n\n#### Step 2: Fourier Expansion of an Invariant Function\nLet $f \\in L^2(\\mathbb{T}, \\mu)$ be a $T$-invariant function. That is:\n$$f(T(x)) = f(x) \\quad \\text{for } \\mu\\text{-almost every } x \\in \\mathbb{T}.$$\n\nSince $\\{e_n(x) = e^{2\\pi i n x} \\mid n \\in \\mathbb{Z}\\}$ forms an orthonormal basis for $L^2(\\mathbb{T}, \\mu)$, we can expand $f$ into a Fourier series:\n$$f(x) = \\sum_{n \\in \\mathbb{Z}} \\hat{f}(n) e^{2\\pi i n x}$$\nwhere the convergence is in the $L^2$ norm, and the Fourier coefficients are given by $\\hat{f}(n) = \\int_{\\mathbb{T}} f(x) e^{-2\\pi i n x} \\, d\\mu(x)$.\n\n#### Step 3: Analysis of the Transformed Function\nWe evaluate the composition $f \\circ T$. Substituting $T(x) = x + \\alpha$:\n$$f(T(x)) = f(x + \\alpha) = \\sum_{n \\in \\mathbb{Z}} \\hat{f}(n) e^{2\\pi i n (x + \\alpha)}$$\nUsing the properties of the exponential function:\n$$f(T(x)) = \\sum_{n \\in \\mathbb{Z}} \\left( \\hat{f}(n) e^{2\\pi i n \\alpha} \\right) e^{2\\pi i n x}$$\nThis series represents the Fourier expansion of the function $f \\circ T$.\n\n#### Step 4: Comparing Fourier Coefficients\nBy the hypothesis of invariance, $f(x) = f(T(x))$ almost everywhere. Since the Fourier coefficients of an $L^2$ function are unique, we equate the coefficients of $e^{2\\pi i n x}$ from the expansions in Step 2 and Step 3:\n$$\\hat{f}(n) = \\hat{f}(n) e^{2\\pi i n \\alpha} \\quad \\text{for all } n \\in \\mathbb{Z}.$$\n\nWe can rewrite this equation as:\n$$\\hat{f}(n) \\left( 1 - e^{2\\pi i n \\alpha} \\right) = 0.$$\n\n#### Step 5: Utilizing the Irrationality of $\\alpha$\nTo satisfy the equation derived in Step 4, for each $n$, at least one of the factors must be zero. We analyze the term $(1 - e^{2\\pi i n \\alpha})$:\n\n$$1 - e^{2\\pi i n \\alpha} = 0 \\iff e^{2\\pi i n \\alpha} = 1 \\iff n\\alpha \\in \\mathbb{Z}.$$\n\nSince $\\alpha$ is given to be **irrational**, the product $n\\alpha$ is an integer if and only if $n = 0$.\n- **Case $n = 0$:** The condition $0\\alpha \\in \\mathbb{Z}$ holds. The equation becomes $\\hat{f}(0)(0) = 0$, which imposes no constraint on $\\hat{f}(0)$.\n- **Case $n \\neq 0$:** Since $\\alpha \\notin \\mathbb{Q}$, $n\\alpha \\notin \\mathbb{Z}$. Therefore, $1 - e^{2\\pi i n \\alpha} \\neq 0$. To satisfy the product equation, we must have:\n  $$\\hat{f}(n) = 0 \\quad \\text{for all } n \\neq 0.$$\n\n#### Step 6: Conclusion\nThe Fourier series for $f$ reduces to a single term:\n$$f(x) = \\sum_{n \\in \\mathbb{Z}} \\hat{f}(n) e^{2\\pi i n x} = \\hat{f}(0) e^{2\\pi i (0) x} = \\hat{f}(0).$$\nThus, $f$ is equal to the constant $\\hat{f}(0)$ almost everywhere.\n\nWe have shown that any $T$-invariant $L^2$ function is essentially constant. To relate this back to sets:\nLet $A \\subseteq \\mathbb{T}$ be a measurable set such that $T^{-1}(A) = A$ (up to a set of measure zero).\nConsider the indicator function $\\chi_A(x)$. Since $A$ is invariant, $\\chi_A(T(x)) = \\chi_A(x)$ a.e.\nAlso, $\\chi_A \\in L^2(\\mathbb{T})$ because the space has finite measure.\nBy the result above, $\\chi_A$ is constant almost everywhere.\nSince an indicator function can only take values 0 or 1, $\\chi_A$ must be 0 a.e. or 1 a.e.\nTherefore, $\\mu(A) = 0$ or $\\mu(A) = 1$.\n\n**Final Result:**\nThe irrational rotation $T(x) = x + \\alpha \\pmod 1$ is ergodic with respect to the Lebesgue measure.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of difference and functional equations, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the key elements of a good problem in the domain\nA good problem in the domain of difference and functional equations should involve a functional equation or a difference equation that requires substantive mathematical reasoning to solve. It should be fully specified, with clear notation and constraints.\n\n## Step 3: Generate a problem\nLet's generate a problem: \"Find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation $f(x + y) = f(x) + f(y) + xy$ for all $x, y \\in \\mathbb{R}$, and $f(1) = 1$.\"\n\n## Step 4: Verify that the generated problem meets the quality rubric\n- **Well-Posedness and Completeness**: The problem is fully self-contained, with the domain and codomain of $f$ specified, and the functional equation given.\n- **Clarity**: The notation is standard, and the task is clear.\n- **Non-Triviality**: The problem requires solving a functional equation, which is non-trivial.\n- **Solvability and Verification**: The problem is solvable using established methods for functional equations.\n\n## Step 5: Solve the generated problem\nTo solve $f(x + y) = f(x) + f(y) + xy$, let's first try substituting specific values for $x$ and $y$ to derive additional information.\n\n## Step 6: Substitute $x = y = 0$ into the equation\n$f(0 + 0) = f(0) + f(0) + 0 \\cdot 0$ simplifies to $f(0) = 2f(0)$, which implies $f(0) = 0$.\n\n## Step 7: Substitute $y = 1$ into the original equation\n$f(x + 1) = f(x) + f(1) + x = f(x) + x + 1$, since $f(1) = 1$. This gives a recursive formula to find $f(x)$ for integer values of $x$.\n\n## Step 8: Use the recursive formula to find $f(n)$ for any integer $n$\nStarting from $f(0) = 0$ and $f(1) = 1$, we can derive $f(2)$, $f(3)$, etc., to look for a pattern. $f(2) = f(1) + f(1) + 1 = 3$, $f(3) = f(2) + f(1) + 2 = 6$. It appears that $f(n) = \\frac{n(n+1)}{2}$ for positive integers $n$.\n\n## Step 9: Check if $f(x) = \\frac{x(x+1)}{2}$ satisfies the original functional equation\nSubstitute $f(x) = \\frac{x(x+1)}{2}$ into $f(x + y) = f(x) + f(y) + xy$:\n- LHS: $f(x + y) = \\frac{(x+y)(x+y+1)}{2} = \\frac{x^2 + 2xy + y^2 + x + y}{2}$\n- RHS: $f(x) + f(y) + xy = \\frac{x(x+1)}{2} + \\frac{y(y+1)}{2} + xy = \\frac{x^2 + x + y^2 + y + 2xy}{2}$\nBoth sides are equal, so $f(x) = \\frac{x(x+1)}{2}$ is a solution.\n\n## Step 10: Verify that the solution satisfies the initial condition\n$f(1) = \\frac{1(1+1)}{2} = 1$, which matches the given condition.\n\nThe final answer is: \n\nFind all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation $f(x + y) = f(x) + f(y) + xy$ for all $x, y \\in \\mathbb{R}$, and $f(1) = 1$.",
    "run_id": "25",
    "outer_attempt": 1,
    "topic_slug": "difference_and_functional_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation\n$$ f(x + y) = f(x) + f(y) + xy $$\nfor all $x, y \\in \\mathbb{R}$, subject to the condition $f(1) = 1$, we proceed with the following steps.\n\n### Step 1: Reduce the Non-Homogeneous Equation\nThe term $xy$ in the functional equation makes it non-homogeneous. We seek to eliminate this term by finding a particular solution.\n\nConsider a polynomial solution of the form $p(x) = ax^2$. Substituting this into the equation:\n$$ a(x+y)^2 = ax^2 + ay^2 + xy $$\n$$ a(x^2 + 2xy + y^2) = ax^2 + ay^2 + xy $$\n$$ ax^2 + 2axy + ay^2 = ax^2 + ay^2 + xy $$\nComparing the terms, we must have $2axy = xy$, which implies $2a = 1$, or $a = \\frac{1}{2}$.\n\nThus, $p(x) = \\frac{1}{2}x^2$ satisfies the non-homogeneous part of the recurrence. We can now express the general function $f(x)$ as the sum of this particular solution and a homogeneous part. Let:\n$$ f(x) = \\frac{1}{2}x^2 + g(x) $$\nwhere $g: \\mathbb{R} \\to \\mathbb{R}$ is a new function to be determined.\n\n### Step 2: Determine the Equation for $g(x)$\nSubstitute $f(x) = \\frac{1}{2}x^2 + g(x)$ into the original functional equation:\n$$ \\frac{1}{2}(x+y)^2 + g(x+y) = \\left(\\frac{1}{2}x^2 + g(x)\\right) + \\left(\\frac{1}{2}y^2 + g(y)\\right) + xy $$\nExpand the left side:\n$$ \\frac{1}{2}(x^2 + 2xy + y^2) + g(x+y) = \\frac{1}{2}x^2 + g(x) + \\frac{1}{2}y^2 + g(y) + xy $$\n$$ \\frac{1}{2}x^2 + xy + \\frac{1}{2}y^2 + g(x+y) = \\frac{1}{2}x^2 + \\frac{1}{2}y^2 + xy + g(x) + g(y) $$\nSubtracting $\\frac{1}{2}x^2 + \\frac{1}{2}y^2 + xy$ from both sides yields:\n$$ g(x+y) = g(x) + g(y) $$\nThis is the **Cauchy Functional Equation**.\n\n### Step 3: Apply the Initial Condition\nWe are given $f(1) = 1$. Using the definition of $g(x)$:\n$$ f(1) = \\frac{1}{2}(1)^2 + g(1) = 1 $$\n$$ \\frac{1}{2} + g(1) = 1 \\implies g(1) = \\frac{1}{2} $$\n\n### Step 4: Solve the Cauchy Functional Equation\nThe function $g: \\mathbb{R} \\to \\mathbb{R}$ must satisfy:\n1. $g(x+y) = g(x) + g(y)$ for all $x, y \\in \\mathbb{R}$\n2. $g(1) = \\frac{1}{2}$\n\nFrom the additivity property $g(x+y) = g(x) + g(y)$, we can prove by induction that $g(nx) = n g(x)$ for all integers $n$. Furthermore, for any rational number $q = \\frac{m}{n}$ (where $m, n \\in \\mathbb{Z}, n \\neq 0$), we have $g(q) = q g(1)$.\n\nProof for rationals:\nSince $g(1) = \\frac{1}{2}$, for any integer $n$:\n$$ g(n) = g(n \\cdot 1) = n g(1) = \\frac{n}{2} $$\nFor any rational $x = \\frac{m}{n}$:\n$$ g\\left(n \\cdot \\frac{m}{n}\\right) = n g\\left(\\frac{m}{n}\\right) $$\n$$ g(m) = n g\\left(\\frac{m}{n}\\right) $$\n$$ \\frac{m}{2} = n g\\left(\\frac{m}{n}\\right) \\implies g\\left(\\frac{m}{n}\\right) = \\frac{1}{n} \\cdot \\frac{m}{2} = \\frac{1}{2} \\cdot \\frac{m}{n} $$\nThus, for all $x \\in \\mathbb{Q}$, $g(x) = \\frac{1}{2}x$.\n\nHowever, for $x \\notin \\mathbb{Q}$, $g(x)$ is not uniquely determined by the value at $1$ without additional assumptions (such as continuity, monotonicity, or boundedness). The general solution to the Cauchy Functional Equation is any additive function $A: \\mathbb{R} \\to \\mathbb{R}$.\n\nLet $A(x)$ be any additive function (i.e., $A(x+y)=A(x)+A(y)$). The condition $g(1) = 1/2$ restricts $A$ such that $A(1) = 1/2$.\nWe can write this as $g(x) = A(x)$, where $A(1) = 1/2$. Alternatively, we can define $H(x) = A(x) - \\frac{1}{2}x$. Then $H$ is an additive function with $H(1) = A(1) - \\frac{1}{2} = 0$. Since $H(1)=0$ and $H$ is additive, $H(q) = 0$ for all $q \\in \\mathbb{Q}$.\nThus, the most general form for $g(x)$ is:\n$$ g(x) = \\frac{1}{2}x + H(x) $$\nwhere $H: \\mathbb{R} \\to \\mathbb{R}$ is an additive function such that $H(x) = 0$ for all $x \\in \\mathbb{Q}$.\n\n### Step 5: Construct the Final Solution\nSubstituting $g(x)$ back into the expression for $f(x)$:\n$$ f(x) = \\frac{1}{2}x^2 + g(x) $$\n$$ f(x) = \\frac{1}{2}x^2 + \\frac{1}{2}x + H(x) $$\n$$ f(x) = \\frac{x(x+1)}{2} + H(x) $$\n\n**Verification:**\nLHS: $f(x+y) = \\frac{(x+y)^2 + (x+y)}{2} + H(x+y)$\nRHS: $f(x) + f(y) + xy = \\left(\\frac{x^2+x}{2} + H(x)\\right) + \\left(\\frac{y^2+y}{2} + H(y)\\right) + xy$\n\nExpanding terms:\nLHS: $\\frac{x^2 + 2xy + y^2 + x + y}{2} + H(x) + H(y)$ (since H is additive)\nRHS: $\\frac{x^2 + x + y^2 + y + 2xy}{2} + H(x) + H(y)$\nThe sides are identical.\nCondition $f(1) = \\frac{1(2)}{2} + H(1) = 1 + 0 = 1$. The condition holds.\n\n### Conclusion\n\nThe set of all solutions depends on whether any regularity conditions (like continuity) are assumed. Since the problem statement does not impose such conditions, we provide the general solution.\n\nThe complete set of functions $f: \\mathbb{R} \\to \\mathbb{R}$ satisfying the conditions is given by:\n$$ f(x) = \\frac{x(x+1)}{2} + H(x) $$\nwhere $H: \\mathbb{R} \\to \\mathbb{R}$ is any additive function (satisfying $H(x+y) = H(x) + H(y)$) that vanishes on all rational numbers (i.e., $H(q) = 0$ for all $q \\in \\mathbb{Q}$).\n\n*Note: If $f$ is assumed to be continuous, then $H(x)$ must be identically zero, and the unique solution is $f(x) = \\frac{x(x+1)}{2}$.*",
        "raw_answer": "To find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation\n$$ f(x + y) = f(x) + f(y) + xy $$\nfor all $x, y \\in \\mathbb{R}$, subject to the condition $f(1) = 1$, we proceed with the following steps.\n\n### Step 1: Reduce the Non-Homogeneous Equation\nThe term $xy$ in the functional equation makes it non-homogeneous. We seek to eliminate this term by finding a particular solution.\n\nConsider a polynomial solution of the form $p(x) = ax^2$. Substituting this into the equation:\n$$ a(x+y)^2 = ax^2 + ay^2 + xy $$\n$$ a(x^2 + 2xy + y^2) = ax^2 + ay^2 + xy $$\n$$ ax^2 + 2axy + ay^2 = ax^2 + ay^2 + xy $$\nComparing the terms, we must have $2axy = xy$, which implies $2a = 1$, or $a = \\frac{1}{2}$.\n\nThus, $p(x) = \\frac{1}{2}x^2$ satisfies the non-homogeneous part of the recurrence. We can now express the general function $f(x)$ as the sum of this particular solution and a homogeneous part. Let:\n$$ f(x) = \\frac{1}{2}x^2 + g(x) $$\nwhere $g: \\mathbb{R} \\to \\mathbb{R}$ is a new function to be determined.\n\n### Step 2: Determine the Equation for $g(x)$\nSubstitute $f(x) = \\frac{1}{2}x^2 + g(x)$ into the original functional equation:\n$$ \\frac{1}{2}(x+y)^2 + g(x+y) = \\left(\\frac{1}{2}x^2 + g(x)\\right) + \\left(\\frac{1}{2}y^2 + g(y)\\right) + xy $$\nExpand the left side:\n$$ \\frac{1}{2}(x^2 + 2xy + y^2) + g(x+y) = \\frac{1}{2}x^2 + g(x) + \\frac{1}{2}y^2 + g(y) + xy $$\n$$ \\frac{1}{2}x^2 + xy + \\frac{1}{2}y^2 + g(x+y) = \\frac{1}{2}x^2 + \\frac{1}{2}y^2 + xy + g(x) + g(y) $$\nSubtracting $\\frac{1}{2}x^2 + \\frac{1}{2}y^2 + xy$ from both sides yields:\n$$ g(x+y) = g(x) + g(y) $$\nThis is the **Cauchy Functional Equation**.\n\n### Step 3: Apply the Initial Condition\nWe are given $f(1) = 1$. Using the definition of $g(x)$:\n$$ f(1) = \\frac{1}{2}(1)^2 + g(1) = 1 $$\n$$ \\frac{1}{2} + g(1) = 1 \\implies g(1) = \\frac{1}{2} $$\n\n### Step 4: Solve the Cauchy Functional Equation\nThe function $g: \\mathbb{R} \\to \\mathbb{R}$ must satisfy:\n1. $g(x+y) = g(x) + g(y)$ for all $x, y \\in \\mathbb{R}$\n2. $g(1) = \\frac{1}{2}$\n\nFrom the additivity property $g(x+y) = g(x) + g(y)$, we can prove by induction that $g(nx) = n g(x)$ for all integers $n$. Furthermore, for any rational number $q = \\frac{m}{n}$ (where $m, n \\in \\mathbb{Z}, n \\neq 0$), we have $g(q) = q g(1)$.\n\nProof for rationals:\nSince $g(1) = \\frac{1}{2}$, for any integer $n$:\n$$ g(n) = g(n \\cdot 1) = n g(1) = \\frac{n}{2} $$\nFor any rational $x = \\frac{m}{n}$:\n$$ g\\left(n \\cdot \\frac{m}{n}\\right) = n g\\left(\\frac{m}{n}\\right) $$\n$$ g(m) = n g\\left(\\frac{m}{n}\\right) $$\n$$ \\frac{m}{2} = n g\\left(\\frac{m}{n}\\right) \\implies g\\left(\\frac{m}{n}\\right) = \\frac{1}{n} \\cdot \\frac{m}{2} = \\frac{1}{2} \\cdot \\frac{m}{n} $$\nThus, for all $x \\in \\mathbb{Q}$, $g(x) = \\frac{1}{2}x$.\n\nHowever, for $x \\notin \\mathbb{Q}$, $g(x)$ is not uniquely determined by the value at $1$ without additional assumptions (such as continuity, monotonicity, or boundedness). The general solution to the Cauchy Functional Equation is any additive function $A: \\mathbb{R} \\to \\mathbb{R}$.\n\nLet $A(x)$ be any additive function (i.e., $A(x+y)=A(x)+A(y)$). The condition $g(1) = 1/2$ restricts $A$ such that $A(1) = 1/2$.\nWe can write this as $g(x) = A(x)$, where $A(1) = 1/2$. Alternatively, we can define $H(x) = A(x) - \\frac{1}{2}x$. Then $H$ is an additive function with $H(1) = A(1) - \\frac{1}{2} = 0$. Since $H(1)=0$ and $H$ is additive, $H(q) = 0$ for all $q \\in \\mathbb{Q}$.\nThus, the most general form for $g(x)$ is:\n$$ g(x) = \\frac{1}{2}x + H(x) $$\nwhere $H: \\mathbb{R} \\to \\mathbb{R}$ is an additive function such that $H(x) = 0$ for all $x \\in \\mathbb{Q}$.\n\n### Step 5: Construct the Final Solution\nSubstituting $g(x)$ back into the expression for $f(x)$:\n$$ f(x) = \\frac{1}{2}x^2 + g(x) $$\n$$ f(x) = \\frac{1}{2}x^2 + \\frac{1}{2}x + H(x) $$\n$$ f(x) = \\frac{x(x+1)}{2} + H(x) $$\n\n**Verification:**\nLHS: $f(x+y) = \\frac{(x+y)^2 + (x+y)}{2} + H(x+y)$\nRHS: $f(x) + f(y) + xy = \\left(\\frac{x^2+x}{2} + H(x)\\right) + \\left(\\frac{y^2+y}{2} + H(y)\\right) + xy$\n\nExpanding terms:\nLHS: $\\frac{x^2 + 2xy + y^2 + x + y}{2} + H(x) + H(y)$ (since H is additive)\nRHS: $\\frac{x^2 + x + y^2 + y + 2xy}{2} + H(x) + H(y)$\nThe sides are identical.\nCondition $f(1) = \\frac{1(2)}{2} + H(1) = 1 + 0 = 1$. The condition holds.\n\n### Conclusion\n\nThe set of all solutions depends on whether any regularity conditions (like continuity) are assumed. Since the problem statement does not impose such conditions, we provide the general solution.\n\nThe complete set of functions $f: \\mathbb{R} \\to \\mathbb{R}$ satisfying the conditions is given by:\n$$ f(x) = \\frac{x(x+1)}{2} + H(x) $$\nwhere $H: \\mathbb{R} \\to \\mathbb{R}$ is any additive function (satisfying $H(x+y) = H(x) + H(y)$) that vanishes on all rational numbers (i.e., $H(q) = 0$ for all $q \\in \\mathbb{Q}$).\n\n*Note: If $f$ is assumed to be continuous, then $H(x)$ must be identically zero, and the unique solution is $f(x) = \\frac{x(x+1)}{2}$.*",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$.",
    "run_id": "26",
    "outer_attempt": 1,
    "topic_slug": "sequences_series_and_summability",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$, we will proceed by decomposing the general term into partial fractions, expressing the series in terms of partial sums, and utilizing the known series expansion for $\\ln(2)$.\n\n### 1. Partial Fraction Decomposition\n\nFirst, we analyze the term $a_n = \\frac{(-1)^{n+1}}{n(n+1)}$. We can decompose the rational part $\\frac{1}{n(n+1)}$ as follows:\n$$ \\frac{1}{n(n+1)} = \\frac{1}{n} - \\frac{1}{n+1} $$\nThus, the general term of the series becomes:\n$$ a_n = (-1)^{n+1} \\left( \\frac{1}{n} - \\frac{1}{n+1} \\right) = \\frac{(-1)^{n+1}}{n} - \\frac{(-1)^{n+1}}{n+1} $$\nNoting that $-(-1)^{n+1} = (-1)^{n+2}$, we can rewrite this as:\n$$ a_n = \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{n+2}}{n+1} $$\n\n### 2. Analysis of Partial Sums\n\nLet $S_N$ be the partial sum of the first $N$ terms. By the linearity of finite summation, we can split $S_N$ into two separate sums:\n$$ S_N = \\sum_{n=1}^{N} \\left( \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{n+2}}{n+1} \\right) = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{n=1}^{N} \\frac{(-1)^{n+2}}{n+1} $$\n\nWe will shift the index of the second sum to align the denominators with the first sum. Let $k = n + 1$. When $n=1$, $k=2$, and when $n=N$, $k=N+1$.\n$$ \\sum_{n=1}^{N} \\frac{(-1)^{n+2}}{n+1} = \\sum_{k=2}^{N+1} \\frac{(-1)^{k+1}}{k} $$\n\nNow, substitute this back into the expression for $S_N$:\n$$ S_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{k=2}^{N+1} \\frac{(-1)^{k+1}}{k} $$\n\nWe can isolate the first term of the first sum ($n=1$) and the last term of the second sum ($k=N+1$) to align the ranges of summation from $2$ to $N$:\n1. The first sum is: $1 + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n}$\n2. The second sum is: $\\sum_{k=2}^{N} \\frac{(-1)^{k+1}}{k} + \\frac{(-1)^{N+2}}{N+1}$\n\nCombining these (and noting that the summation index variable is a dummy variable, so we can set $k=n$):\n$$ S_N = 1 + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{N+2}}{N+1} $$\n$$ S_N = 1 + 2\\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{N}}{N+1} $$\n*(Note: $(-1)^{N+2} = (-1)^N$)*\n\n### 3. Evaluating the Limit\n\nWe now take the limit as $N \\to \\infty$.\n$$ S = \\lim_{N \\to \\infty} S_N = 1 + 2 \\lim_{N \\to \\infty} \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\lim_{N \\to \\infty} \\frac{(-1)^{N}}{N+1} $$\n\nThe last term clearly approaches 0:\n$$ \\lim_{N \\to \\infty} \\frac{(-1)^{N}}{N+1} = 0 $$\n\nTo evaluate the infinite sum, recall the Mercator series for $\\ln(1+x)$ evaluated at $x=1$:\n$$ \\ln(2) = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n} = 1 - \\frac{1}{2} + \\frac{1}{3} - \\frac{1}{4} + \\dots $$\nWe can isolate the first term ($n=1$) from this series:\n$$ \\ln(2) = 1 + \\sum_{n=2}^{\\infty} \\frac{(-1)^{n+1}}{n} $$\nTherefore:\n$$ \\sum_{n=2}^{\\infty} \\frac{(-1)^{n+1}}{n} = \\ln(2) - 1 $$\n\nSubstituting this result back into our expression for the total sum $S$:\n$$ S = 1 + 2(\\ln(2) - 1) + 0 $$\n$$ S = 1 + 2\\ln(2) - 2 $$\n$$ S = 2\\ln(2) - 1 $$\n\n### Conclusion\n\nThe value of the infinite series is:\n$$ \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)} = 2\\ln(2) - 1 $$",
        "raw_answer": "To evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$, we will proceed by decomposing the general term into partial fractions, expressing the series in terms of partial sums, and utilizing the known series expansion for $\\ln(2)$.\n\n### 1. Partial Fraction Decomposition\n\nFirst, we analyze the term $a_n = \\frac{(-1)^{n+1}}{n(n+1)}$. We can decompose the rational part $\\frac{1}{n(n+1)}$ as follows:\n$$ \\frac{1}{n(n+1)} = \\frac{1}{n} - \\frac{1}{n+1} $$\nThus, the general term of the series becomes:\n$$ a_n = (-1)^{n+1} \\left( \\frac{1}{n} - \\frac{1}{n+1} \\right) = \\frac{(-1)^{n+1}}{n} - \\frac{(-1)^{n+1}}{n+1} $$\nNoting that $-(-1)^{n+1} = (-1)^{n+2}$, we can rewrite this as:\n$$ a_n = \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{n+2}}{n+1} $$\n\n### 2. Analysis of Partial Sums\n\nLet $S_N$ be the partial sum of the first $N$ terms. By the linearity of finite summation, we can split $S_N$ into two separate sums:\n$$ S_N = \\sum_{n=1}^{N} \\left( \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{n+2}}{n+1} \\right) = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{n=1}^{N} \\frac{(-1)^{n+2}}{n+1} $$\n\nWe will shift the index of the second sum to align the denominators with the first sum. Let $k = n + 1$. When $n=1$, $k=2$, and when $n=N$, $k=N+1$.\n$$ \\sum_{n=1}^{N} \\frac{(-1)^{n+2}}{n+1} = \\sum_{k=2}^{N+1} \\frac{(-1)^{k+1}}{k} $$\n\nNow, substitute this back into the expression for $S_N$:\n$$ S_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{k=2}^{N+1} \\frac{(-1)^{k+1}}{k} $$\n\nWe can isolate the first term of the first sum ($n=1$) and the last term of the second sum ($k=N+1$) to align the ranges of summation from $2$ to $N$:\n1. The first sum is: $1 + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n}$\n2. The second sum is: $\\sum_{k=2}^{N} \\frac{(-1)^{k+1}}{k} + \\frac{(-1)^{N+2}}{N+1}$\n\nCombining these (and noting that the summation index variable is a dummy variable, so we can set $k=n$):\n$$ S_N = 1 + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{N+2}}{N+1} $$\n$$ S_N = 1 + 2\\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\frac{(-1)^{N}}{N+1} $$\n*(Note: $(-1)^{N+2} = (-1)^N$)*\n\n### 3. Evaluating the Limit\n\nWe now take the limit as $N \\to \\infty$.\n$$ S = \\lim_{N \\to \\infty} S_N = 1 + 2 \\lim_{N \\to \\infty} \\sum_{n=2}^{N} \\frac{(-1)^{n+1}}{n} + \\lim_{N \\to \\infty} \\frac{(-1)^{N}}{N+1} $$\n\nThe last term clearly approaches 0:\n$$ \\lim_{N \\to \\infty} \\frac{(-1)^{N}}{N+1} = 0 $$\n\nTo evaluate the infinite sum, recall the Mercator series for $\\ln(1+x)$ evaluated at $x=1$:\n$$ \\ln(2) = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n} = 1 - \\frac{1}{2} + \\frac{1}{3} - \\frac{1}{4} + \\dots $$\nWe can isolate the first term ($n=1$) from this series:\n$$ \\ln(2) = 1 + \\sum_{n=2}^{\\infty} \\frac{(-1)^{n+1}}{n} $$\nTherefore:\n$$ \\sum_{n=2}^{\\infty} \\frac{(-1)^{n+1}}{n} = \\ln(2) - 1 $$\n\nSubstituting this result back into our expression for the total sum $S$:\n$$ S = 1 + 2(\\ln(2) - 1) + 0 $$\n$$ S = 1 + 2\\ln(2) - 2 $$\n$$ S = 2\\ln(2) - 1 $$\n\n### Conclusion\n\nThe value of the infinite series is:\n$$ \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)} = 2\\ln(2) - 1 $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the topic\nThe task is to generate a challenging mathematics problem along with a complete and verifiable solution in the domain of \"Approximations and expansions.\" The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within \"Approximations and expansions\"\nA suitable topic could involve Taylor series expansions, asymptotic approximations, or other related areas where mathematical functions are approximated.\n\n## Step 3: Formulate a challenging problem\nLet's consider a problem involving the approximation of a function using its Taylor series expansion. A classic example is approximating $e^x$ or $\\sin(x)$ around $x = 0$. However, to make it more challenging, we could involve a less straightforward function or require the derivation of an approximation under certain conditions.\n\n## Step 4: Create a specific problem\nConsider the function $f(x) = \\frac{1}{\\sqrt{1 + x}}$. We can ask to find the Taylor series expansion of $f(x)$ around $x = 0$ up to the third term and then use this expansion to approximate $f(0.1)$.\n\n## Step 5: Formulate the problem statement\nLet's refine the problem: \"Find the Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to and including the term involving $x^3$. Then, use this expansion to approximate $f(0.1)$ and compare it with the exact value.\"\n\n## Step 6: Write the problem in the required format\n\nFind the Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to and including the term involving $x^3$. Then, use this expansion to approximate $f(0.1)$ and compare it with the exact value.",
    "run_id": "27",
    "outer_attempt": 1,
    "topic_slug": "approximations_and_expansions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete solution to the problem.\n\n### Part 1: Derivation of the Taylor Series Expansion\n\nWe are asked to find the Taylor series expansion of the function $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to and including the term involving $x^3$. This is equivalent to finding the 3rd-degree Maclaurin polynomial.\n\nThe general formula for the Taylor series of $f(x)$ centered at $x=0$ is:\n$$ f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(0)}{n!} x^n = f(0) + f'(0)x + \\frac{f''(0)}{2!}x^2 + \\frac{f'''(0)}{3!}x^3 + \\dots $$\n\nFirst, we rewrite the function using a negative exponent:\n$$ f(x) = (1 + x)^{-\\frac{1}{2}} $$\n\nNow, we compute the necessary derivatives and evaluate them at $x = 0$:\n\n**1. Zeroth derivative ($n=0$):**\n$$ f(0) = (1 + 0)^{-\\frac{1}{2}} = 1 $$\n\n**2. First derivative ($n=1$):**\nUsing the power rule $\\frac{d}{dx}u^n = nu^{n-1}u'$:\n$$ f'(x) = -\\frac{1}{2}(1 + x)^{-\\frac{3}{2}} $$\nEvaluating at $x=0$:\n$$ f'(0) = -\\frac{1}{2}(1)^{-\\frac{3}{2}} = -\\frac{1}{2} $$\n\n**3. Second derivative ($n=2$):**\n$$ f''(x) = \\frac{d}{dx} \\left( -\\frac{1}{2}(1 + x)^{-\\frac{3}{2}} \\right) = \\left(-\\frac{1}{2}\\right)\\left(-\\frac{3}{2}\\right)(1 + x)^{-\\frac{5}{2}} = \\frac{3}{4}(1 + x)^{-\\frac{5}{2}} $$\nEvaluating at $x=0$:\n$$ f''(0) = \\frac{3}{4}(1)^{-\\frac{5}{2}} = \\frac{3}{4} $$\n\n**4. Third derivative ($n=3$):**\n$$ f'''(x) = \\frac{d}{dx} \\left( \\frac{3}{4}(1 + x)^{-\\frac{5}{2}} \\right) = \\left(\\frac{3}{4}\\right)\\left(-\\frac{5}{2}\\right)(1 + x)^{-\\frac{7}{2}} = -\\frac{15}{8}(1 + x)^{-\\frac{7}{2}} $$\nEvaluating at $x=0$:\n$$ f'''(0) = -\\frac{15}{8}(1)^{-\\frac{7}{2}} = -\\frac{15}{8} $$\n\nNow, we substitute these coefficients into the Taylor series formula:\n\n$$ P_3(x) = 1 + \\left(-\\frac{1}{2}\\right)x + \\frac{\\frac{3}{4}}{2!}x^2 + \\frac{-\\frac{15}{8}}{3!}x^3 $$\n\nSimplifying the factorials ($2! = 2$, $3! = 6$):\n\n$$ \\frac{\\frac{3}{4}}{2} = \\frac{3}{8} $$\n$$ \\frac{-\\frac{15}{8}}{6} = -\\frac{15}{48} = -\\frac{5}{16} $$\n\nThus, the Taylor series expansion up to $x^3$ is:\n$$ P_3(x) = 1 - \\frac{1}{2}x + \\frac{3}{8}x^2 - \\frac{5}{16}x^3 $$\n\n*Note: This result can be verified using the Generalized Binomial Theorem for $(1+x)^\\alpha$ with $\\alpha = -1/2$. The binomial coefficient $\\binom{\\alpha}{k}$ yields the same coefficients.*\n\n### Part 2: Approximation of $f(0.1)$\n\nWe substitute $x = 0.1$ into our polynomial $P_3(x)$. Note that since $|0.1| < 1$, the series converges.\n\n$$ P_3(0.1) = 1 - \\frac{1}{2}(0.1) + \\frac{3}{8}(0.1)^2 - \\frac{5}{16}(0.1)^3 $$\n\nCalculating term by term:\n\n1.  **Constant:** $1$\n2.  **Linear term:** $-\\frac{1}{2}(0.1) = -0.05$\n3.  **Quadratic term:** $\\frac{3}{8}(0.01) = 0.375 \\times 0.01 = 0.00375$\n4.  **Cubic term:** $-\\frac{5}{16}(0.001) = -0.3125 \\times 0.001 = -0.0003125$\n\nSumming these values:\n$$ P_3(0.1) = 1 - 0.05 + 0.00375 - 0.0003125 $$\n$$ P_3(0.1) = 0.95 + 0.00375 - 0.0003125 $$\n$$ P_3(0.1) = 0.95375 - 0.0003125 $$\n$$ P_3(0.1) = 0.9534375 $$\n\n### Part 3: Comparison with Exact Value\n\nThe exact value of the function at $x=0.1$ is:\n$$ f(0.1) = \\frac{1}{\\sqrt{1 + 0.1}} = \\frac{1}{\\sqrt{1.1}} $$\n\nUsing a calculator for high precision:\n$$ \\sqrt{1.1} \\approx 1.04880884817 $$\n$$ f(0.1) = \\frac{1}{1.04880884817} \\approx 0.95346258925 $$\n\nNow, we compare the approximation ($P_{approx}$) with the exact value ($V_{exact}$):\n\n$$ V_{exact} \\approx 0.95346259 $$\n$$ P_{approx} = 0.95343750 $$\n\n**Absolute Error:**\n$$ |V_{exact} - P_{approx}| = |0.95346259 - 0.95343750| \\approx 0.00002509 $$\n\nThe approximation is accurate to four decimal places. The error is approximately $2.5 \\times 10^{-5}$.\n\n### Conclusion\n\n**1. The Taylor series expansion up to $x^3$ is:**\n$$ \\frac{1}{\\sqrt{1+x}} \\approx 1 - \\frac{1}{2}x + \\frac{3}{8}x^2 - \\frac{5}{16}x^3 $$\n\n**2. The approximate value at $x=0.1$ is:**\n$$ 0.9534375 $$\n\n**3. Comparison:**\nThe approximation differs from the exact value ($\\approx 0.9534626$) by approximately $0.0000251$, demonstrating that the third-order polynomial provides a high degree of accuracy for small $x$.",
        "raw_answer": "Here is the complete solution to the problem.\n\n### Part 1: Derivation of the Taylor Series Expansion\n\nWe are asked to find the Taylor series expansion of the function $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to and including the term involving $x^3$. This is equivalent to finding the 3rd-degree Maclaurin polynomial.\n\nThe general formula for the Taylor series of $f(x)$ centered at $x=0$ is:\n$$ f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(0)}{n!} x^n = f(0) + f'(0)x + \\frac{f''(0)}{2!}x^2 + \\frac{f'''(0)}{3!}x^3 + \\dots $$\n\nFirst, we rewrite the function using a negative exponent:\n$$ f(x) = (1 + x)^{-\\frac{1}{2}} $$\n\nNow, we compute the necessary derivatives and evaluate them at $x = 0$:\n\n**1. Zeroth derivative ($n=0$):**\n$$ f(0) = (1 + 0)^{-\\frac{1}{2}} = 1 $$\n\n**2. First derivative ($n=1$):**\nUsing the power rule $\\frac{d}{dx}u^n = nu^{n-1}u'$:\n$$ f'(x) = -\\frac{1}{2}(1 + x)^{-\\frac{3}{2}} $$\nEvaluating at $x=0$:\n$$ f'(0) = -\\frac{1}{2}(1)^{-\\frac{3}{2}} = -\\frac{1}{2} $$\n\n**3. Second derivative ($n=2$):**\n$$ f''(x) = \\frac{d}{dx} \\left( -\\frac{1}{2}(1 + x)^{-\\frac{3}{2}} \\right) = \\left(-\\frac{1}{2}\\right)\\left(-\\frac{3}{2}\\right)(1 + x)^{-\\frac{5}{2}} = \\frac{3}{4}(1 + x)^{-\\frac{5}{2}} $$\nEvaluating at $x=0$:\n$$ f''(0) = \\frac{3}{4}(1)^{-\\frac{5}{2}} = \\frac{3}{4} $$\n\n**4. Third derivative ($n=3$):**\n$$ f'''(x) = \\frac{d}{dx} \\left( \\frac{3}{4}(1 + x)^{-\\frac{5}{2}} \\right) = \\left(\\frac{3}{4}\\right)\\left(-\\frac{5}{2}\\right)(1 + x)^{-\\frac{7}{2}} = -\\frac{15}{8}(1 + x)^{-\\frac{7}{2}} $$\nEvaluating at $x=0$:\n$$ f'''(0) = -\\frac{15}{8}(1)^{-\\frac{7}{2}} = -\\frac{15}{8} $$\n\nNow, we substitute these coefficients into the Taylor series formula:\n\n$$ P_3(x) = 1 + \\left(-\\frac{1}{2}\\right)x + \\frac{\\frac{3}{4}}{2!}x^2 + \\frac{-\\frac{15}{8}}{3!}x^3 $$\n\nSimplifying the factorials ($2! = 2$, $3! = 6$):\n\n$$ \\frac{\\frac{3}{4}}{2} = \\frac{3}{8} $$\n$$ \\frac{-\\frac{15}{8}}{6} = -\\frac{15}{48} = -\\frac{5}{16} $$\n\nThus, the Taylor series expansion up to $x^3$ is:\n$$ P_3(x) = 1 - \\frac{1}{2}x + \\frac{3}{8}x^2 - \\frac{5}{16}x^3 $$\n\n*Note: This result can be verified using the Generalized Binomial Theorem for $(1+x)^\\alpha$ with $\\alpha = -1/2$. The binomial coefficient $\\binom{\\alpha}{k}$ yields the same coefficients.*\n\n### Part 2: Approximation of $f(0.1)$\n\nWe substitute $x = 0.1$ into our polynomial $P_3(x)$. Note that since $|0.1| < 1$, the series converges.\n\n$$ P_3(0.1) = 1 - \\frac{1}{2}(0.1) + \\frac{3}{8}(0.1)^2 - \\frac{5}{16}(0.1)^3 $$\n\nCalculating term by term:\n\n1.  **Constant:** $1$\n2.  **Linear term:** $-\\frac{1}{2}(0.1) = -0.05$\n3.  **Quadratic term:** $\\frac{3}{8}(0.01) = 0.375 \\times 0.01 = 0.00375$\n4.  **Cubic term:** $-\\frac{5}{16}(0.001) = -0.3125 \\times 0.001 = -0.0003125$\n\nSumming these values:\n$$ P_3(0.1) = 1 - 0.05 + 0.00375 - 0.0003125 $$\n$$ P_3(0.1) = 0.95 + 0.00375 - 0.0003125 $$\n$$ P_3(0.1) = 0.95375 - 0.0003125 $$\n$$ P_3(0.1) = 0.9534375 $$\n\n### Part 3: Comparison with Exact Value\n\nThe exact value of the function at $x=0.1$ is:\n$$ f(0.1) = \\frac{1}{\\sqrt{1 + 0.1}} = \\frac{1}{\\sqrt{1.1}} $$\n\nUsing a calculator for high precision:\n$$ \\sqrt{1.1} \\approx 1.04880884817 $$\n$$ f(0.1) = \\frac{1}{1.04880884817} \\approx 0.95346258925 $$\n\nNow, we compare the approximation ($P_{approx}$) with the exact value ($V_{exact}$):\n\n$$ V_{exact} \\approx 0.95346259 $$\n$$ P_{approx} = 0.95343750 $$\n\n**Absolute Error:**\n$$ |V_{exact} - P_{approx}| = |0.95346259 - 0.95343750| \\approx 0.00002509 $$\n\nThe approximation is accurate to four decimal places. The error is approximately $2.5 \\times 10^{-5}$.\n\n### Conclusion\n\n**1. The Taylor series expansion up to $x^3$ is:**\n$$ \\frac{1}{\\sqrt{1+x}} \\approx 1 - \\frac{1}{2}x + \\frac{3}{8}x^2 - \\frac{5}{16}x^3 $$\n\n**2. The approximate value at $x=0.1$ is:**\n$$ 0.9534375 $$\n\n**3. Comparison:**\nThe approximation differs from the exact value ($\\approx 0.9534626$) by approximately $0.0000251$, demonstrating that the third-order polynomial provides a high degree of accuracy for small $x$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ and suppose that its Fourier transform $\\hat{f}$ is supported in the ball $B(0,1) = \\{ \\xi \\in \\mathbb{R}^n : |\\xi| \\leq 1 \\}$. Prove that $f$ is smooth, i.e., $f \\in C^\\infty(\\mathbb{R}^n)$, and that for any multi-index $\\alpha$, there exists a constant $C_\\alpha > 0$ such that $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$ for all $x \\in \\mathbb{R}^n$.",
    "run_id": "28",
    "outer_attempt": 1,
    "topic_slug": "harmonic_analysis_on_euclidean_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The problem asks us to prove two properties for a function $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ whose Fourier transform $\\hat{f}$ is supported in the unit ball $B(0,1)$. The two properties are:\n1.  $f$ is smooth, i.e., $f \\in C^\\infty(\\mathbb{R}^n)$.\n2.  $f$ and its derivatives satisfy the decay estimate $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$.\n\nWhile the first assertion (smoothness) is true and can be proven rigorously, the second assertion (decay rate) is **false** as stated. There exist functions satisfying the given hypotheses that do not decay as fast as $(1+|x|)^{-n-1}$.\n\nBelow, we provide the proof of smoothness and then demonstrate via counterexample why the decay estimate does not hold in general.\n\n### Part 1: Proof of Smoothness\n\nWe are given that $f \\in L^1(\\mathbb{R}^n)$. By the Riemann-Lebesgue lemma, the Fourier transform $\\hat{f}$ is continuous and bounded. We are also given that $\\text{supp}(\\hat{f}) \\subseteq B(0,1)$.\nSince $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$, we can recover $f$ from $\\hat{f}$ via the inverse Fourier transform (which holds pointwise or almost everywhere; since $\\hat{f} \\in L^1$, it holds pointwise and $f$ is continuous):\n$$ f(x) = \\int_{\\mathbb{R}^n} \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nUsing the support condition, the integral is restricted to the unit ball:\n$$ f(x) = \\int_{B(0,1)} \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nTo prove that $f \\in C^\\infty(\\mathbb{R}^n)$, consider the partial derivative with respect to $x$ corresponding to a multi-index $\\alpha$. Formally differentiating under the integral sign gives the integrand:\n$$ g_\\alpha(x, \\xi) = (2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} $$\nWe must verify that this differentiation is valid.\n1.  For any fixed $x$, the function $\\xi \\mapsto g_\\alpha(x, \\xi)$ is continuous on $B(0,1)$ (since $\\hat{f}$ is continuous) and zero outside. Thus, it is integrable.\n2.  We can bound the integrand uniformly in $x$:\n    $$ |(2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi}| \\leq (2\\pi)^ {|\\alpha|} |\\xi|^{|\\alpha|} |\\hat{f}(\\xi)| $$\n    Since $|\\xi| \\leq 1$ on the support of $\\hat{f}$, and $\\hat{f}$ is bounded (let $\\|\\hat{f}\\|_\\infty = M$), we have:\n    $$ |(2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi}| \\leq (2\\pi)^{|\\alpha|} M \\chi_{B(0,1)}(\\xi) $$\n    The dominating function $G(\\xi) = (2\\pi)^{|\\alpha|} M \\chi_{B(0,1)}(\\xi)$ is in $L^1(\\mathbb{R}^n)$ because the volume of the ball is finite.\n\nBy the standard theorem on differentiation under the integral sign (a consequence of the Dominated Convergence Theorem), $f$ is infinitely differentiable, and\n$$ \\partial^\\alpha f(x) = \\int_{B(0,1)} (2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nThus, $f \\in C^\\infty(\\mathbb{R}^n)$. Furthermore, by the bound on the integrand, $\\partial^\\alpha f$ is bounded on $\\mathbb{R}^n$.\n\n---\n\n### Part 2: Analysis of the Decay Estimate\n\nThe problem asserts that $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$. This implies that $f(x)$ must decay at least as fast as $|x|^{-n-1}$ as $|x| \\to \\infty$. We will show this is false by constructing a counterexample.\n\nConsider the family of radial functions defined by their Fourier transforms. Let $\\delta > 0$ and define $\\hat{f}_\\delta$ on $\\mathbb{R}^n$ by:\n$$ \\hat{f}_\\delta(\\xi) = \\begin{cases} (1 - |\\xi|^2)^\\delta & \\text{if } |\\xi| \\leq 1 \\\\ 0 & \\text{if } |\\xi| > 1 \\end{cases} $$\nThis function is supported in $B(0,1)$. Since $\\delta > 0$, $\\hat{f}_\\delta$ is continuous everywhere (vanishing at the boundary $|\\xi|=1$).\n\nThe inverse Fourier transform $f_\\delta(x)$ is related to the Bessel function of the first kind. Specifically, for $x \\in \\mathbb{R}^n$:\n$$ f_\\delta(x) = \\frac{\\Gamma(\\delta+1)}{\\pi^\\delta} |x|^{-(n/2 + \\delta)} J_{n/2 + \\delta}(2\\pi |x|) $$\nUsing the asymptotic expansion of the Bessel function for large argument $r$, $J_\\nu(r) \\approx \\sqrt{\\frac{2}{\\pi r}} \\cos(r - \\dots)$, the decay of $f_\\delta(x)$ as $|x| \\to \\infty$ is:\n$$ |f_\\delta(x)| \\sim C |x|^{-(n/2 + \\delta)} |x|^{-1/2} = C |x|^{-\\frac{n+1}{2} - \\delta} $$\nLet $\\gamma = \\frac{n+1}{2} + \\delta$. So $|f_\\delta(x)| \\sim |x|^{-\\gamma}$.\n\n**Condition 1: Integrability ($f \\in L^1$)**\nFor $f_\\delta$ to be in $L^1(\\mathbb{R}^n)$, we require the integral of $|x|^{-\\gamma}$ to converge at infinity (it is bounded near 0). Using polar coordinates, we need:\n$$ \\int_1^\\infty r^{-\\gamma} r^{n-1} \\, dr < \\infty \\iff -\\gamma + n - 1 < -1 \\iff \\gamma > n $$\nSubstituting $\\gamma$:\n$$ \\frac{n+1}{2} + \\delta > n \\iff \\delta > \\frac{n-1}{2} $$\n\n**Condition 2: The Claimed Decay**\nThe problem claims decay of order $|x|^{-n-1}$. This requires:\n$$ \\gamma \\ge n+1 \\iff \\frac{n+1}{2} + \\delta \\ge n+1 \\iff \\delta \\ge \\frac{n+1}{2} $$\n\n**The Contradiction**\nWe observe a gap between the condition for $L^1$ membership and the condition for the claimed decay. If we choose $\\delta$ such that:\n$$ \\frac{n-1}{2} < \\delta < \\frac{n+1}{2} $$\nthen $f_\\delta \\in L^1(\\mathbb{R}^n)$ (and $L^2$, as $\\hat{f}_\\delta \\in L^2$ trivially), and $\\text{supp}(\\hat{f}_\\delta) \\subset B(0,1)$, but $f_\\delta(x)$ decays like $|x|^{-\\frac{n+1}{2}-\\delta}$, which is **slower** than $|x|^{-n-1}$.\n\n**Specific Counterexample in 1D ($n=1$):**\nWe need $0 < \\delta < 1$. Let $\\delta = 0.5$.\nThen $\\hat{f}_{0.5}(\\xi) = (1-\\xi^2)^{0.5} \\chi_{[-1,1]}(\\xi)$.\nThe function $f_{0.5}(x)$ behaves asymptotically as $|x|^{-(1+1)/2 - 0.5} = |x|^{-1.5}$.\nSince $1.5 > 1$, $f_{0.5} \\in L^1(\\mathbb{R})$.\nHowever, the claimed decay is $(1+|x|)^{-2}$.\nSince $|x|^{-1.5}$ decays slower than $|x|^{-2}$, the inequality $|\\partial^\\alpha f(x)| \\leq C (1+|x|)^{-2}$ fails for $\\alpha=0$ and large $x$.\n\n### Conclusion\nThe function $f$ is guaranteed to be smooth ($C^\\infty$), but the decay estimate $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$ is **not necessarily true** under the stated assumptions. The estimate holds only if stronger regularity assumptions are imposed on $\\hat{f}$ at the boundary of the unit ball (e.g., if $\\hat{f} \\in C_c^\\infty(B(0,1))$).",
        "raw_answer": "The problem asks us to prove two properties for a function $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ whose Fourier transform $\\hat{f}$ is supported in the unit ball $B(0,1)$. The two properties are:\n1.  $f$ is smooth, i.e., $f \\in C^\\infty(\\mathbb{R}^n)$.\n2.  $f$ and its derivatives satisfy the decay estimate $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$.\n\nWhile the first assertion (smoothness) is true and can be proven rigorously, the second assertion (decay rate) is **false** as stated. There exist functions satisfying the given hypotheses that do not decay as fast as $(1+|x|)^{-n-1}$.\n\nBelow, we provide the proof of smoothness and then demonstrate via counterexample why the decay estimate does not hold in general.\n\n### Part 1: Proof of Smoothness\n\nWe are given that $f \\in L^1(\\mathbb{R}^n)$. By the Riemann-Lebesgue lemma, the Fourier transform $\\hat{f}$ is continuous and bounded. We are also given that $\\text{supp}(\\hat{f}) \\subseteq B(0,1)$.\nSince $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$, we can recover $f$ from $\\hat{f}$ via the inverse Fourier transform (which holds pointwise or almost everywhere; since $\\hat{f} \\in L^1$, it holds pointwise and $f$ is continuous):\n$$ f(x) = \\int_{\\mathbb{R}^n} \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nUsing the support condition, the integral is restricted to the unit ball:\n$$ f(x) = \\int_{B(0,1)} \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nTo prove that $f \\in C^\\infty(\\mathbb{R}^n)$, consider the partial derivative with respect to $x$ corresponding to a multi-index $\\alpha$. Formally differentiating under the integral sign gives the integrand:\n$$ g_\\alpha(x, \\xi) = (2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} $$\nWe must verify that this differentiation is valid.\n1.  For any fixed $x$, the function $\\xi \\mapsto g_\\alpha(x, \\xi)$ is continuous on $B(0,1)$ (since $\\hat{f}$ is continuous) and zero outside. Thus, it is integrable.\n2.  We can bound the integrand uniformly in $x$:\n    $$ |(2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi}| \\leq (2\\pi)^ {|\\alpha|} |\\xi|^{|\\alpha|} |\\hat{f}(\\xi)| $$\n    Since $|\\xi| \\leq 1$ on the support of $\\hat{f}$, and $\\hat{f}$ is bounded (let $\\|\\hat{f}\\|_\\infty = M$), we have:\n    $$ |(2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi}| \\leq (2\\pi)^{|\\alpha|} M \\chi_{B(0,1)}(\\xi) $$\n    The dominating function $G(\\xi) = (2\\pi)^{|\\alpha|} M \\chi_{B(0,1)}(\\xi)$ is in $L^1(\\mathbb{R}^n)$ because the volume of the ball is finite.\n\nBy the standard theorem on differentiation under the integral sign (a consequence of the Dominated Convergence Theorem), $f$ is infinitely differentiable, and\n$$ \\partial^\\alpha f(x) = \\int_{B(0,1)} (2\\pi i \\xi)^\\alpha \\hat{f}(\\xi) e^{2\\pi i x \\cdot \\xi} \\, d\\xi $$\nThus, $f \\in C^\\infty(\\mathbb{R}^n)$. Furthermore, by the bound on the integrand, $\\partial^\\alpha f$ is bounded on $\\mathbb{R}^n$.\n\n---\n\n### Part 2: Analysis of the Decay Estimate\n\nThe problem asserts that $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$. This implies that $f(x)$ must decay at least as fast as $|x|^{-n-1}$ as $|x| \\to \\infty$. We will show this is false by constructing a counterexample.\n\nConsider the family of radial functions defined by their Fourier transforms. Let $\\delta > 0$ and define $\\hat{f}_\\delta$ on $\\mathbb{R}^n$ by:\n$$ \\hat{f}_\\delta(\\xi) = \\begin{cases} (1 - |\\xi|^2)^\\delta & \\text{if } |\\xi| \\leq 1 \\\\ 0 & \\text{if } |\\xi| > 1 \\end{cases} $$\nThis function is supported in $B(0,1)$. Since $\\delta > 0$, $\\hat{f}_\\delta$ is continuous everywhere (vanishing at the boundary $|\\xi|=1$).\n\nThe inverse Fourier transform $f_\\delta(x)$ is related to the Bessel function of the first kind. Specifically, for $x \\in \\mathbb{R}^n$:\n$$ f_\\delta(x) = \\frac{\\Gamma(\\delta+1)}{\\pi^\\delta} |x|^{-(n/2 + \\delta)} J_{n/2 + \\delta}(2\\pi |x|) $$\nUsing the asymptotic expansion of the Bessel function for large argument $r$, $J_\\nu(r) \\approx \\sqrt{\\frac{2}{\\pi r}} \\cos(r - \\dots)$, the decay of $f_\\delta(x)$ as $|x| \\to \\infty$ is:\n$$ |f_\\delta(x)| \\sim C |x|^{-(n/2 + \\delta)} |x|^{-1/2} = C |x|^{-\\frac{n+1}{2} - \\delta} $$\nLet $\\gamma = \\frac{n+1}{2} + \\delta$. So $|f_\\delta(x)| \\sim |x|^{-\\gamma}$.\n\n**Condition 1: Integrability ($f \\in L^1$)**\nFor $f_\\delta$ to be in $L^1(\\mathbb{R}^n)$, we require the integral of $|x|^{-\\gamma}$ to converge at infinity (it is bounded near 0). Using polar coordinates, we need:\n$$ \\int_1^\\infty r^{-\\gamma} r^{n-1} \\, dr < \\infty \\iff -\\gamma + n - 1 < -1 \\iff \\gamma > n $$\nSubstituting $\\gamma$:\n$$ \\frac{n+1}{2} + \\delta > n \\iff \\delta > \\frac{n-1}{2} $$\n\n**Condition 2: The Claimed Decay**\nThe problem claims decay of order $|x|^{-n-1}$. This requires:\n$$ \\gamma \\ge n+1 \\iff \\frac{n+1}{2} + \\delta \\ge n+1 \\iff \\delta \\ge \\frac{n+1}{2} $$\n\n**The Contradiction**\nWe observe a gap between the condition for $L^1$ membership and the condition for the claimed decay. If we choose $\\delta$ such that:\n$$ \\frac{n-1}{2} < \\delta < \\frac{n+1}{2} $$\nthen $f_\\delta \\in L^1(\\mathbb{R}^n)$ (and $L^2$, as $\\hat{f}_\\delta \\in L^2$ trivially), and $\\text{supp}(\\hat{f}_\\delta) \\subset B(0,1)$, but $f_\\delta(x)$ decays like $|x|^{-\\frac{n+1}{2}-\\delta}$, which is **slower** than $|x|^{-n-1}$.\n\n**Specific Counterexample in 1D ($n=1$):**\nWe need $0 < \\delta < 1$. Let $\\delta = 0.5$.\nThen $\\hat{f}_{0.5}(\\xi) = (1-\\xi^2)^{0.5} \\chi_{[-1,1]}(\\xi)$.\nThe function $f_{0.5}(x)$ behaves asymptotically as $|x|^{-(1+1)/2 - 0.5} = |x|^{-1.5}$.\nSince $1.5 > 1$, $f_{0.5} \\in L^1(\\mathbb{R})$.\nHowever, the claimed decay is $(1+|x|)^{-2}$.\nSince $|x|^{-1.5}$ decays slower than $|x|^{-2}$, the inequality $|\\partial^\\alpha f(x)| \\leq C (1+|x|)^{-2}$ fails for $\\alpha=0$ and large $x$.\n\n### Conclusion\nThe function $f$ is guaranteed to be smooth ($C^\\infty$), but the decay estimate $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$ is **not necessarily true** under the stated assumptions. The estimate holds only if stronger regularity assumptions are imposed on $\\hat{f}$ at the boundary of the unit ball (e.g., if $\\hat{f} \\in C_c^\\infty(B(0,1))$).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task requires generating a challenging mathematics problem in the domain of abstract harmonic analysis. The problem should be well-posed, solvable, and verifiable.\n[/QUESTION]",
    "run_id": "29",
    "outer_attempt": 1,
    "topic_slug": "abstract_harmonic_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Based on the instruction to act as a testee generating a challenging problem in abstract harmonic analysis, here is the generated problem followed by a complete, rigorous solution.\n\n---\n\n### **Generated Problem**\n\n**Topic:** Harmonic Analysis on Local Fields ($p$-adic Analysis)\n\n**Problem Statement:**\nLet $p$ be a prime number and let $\\mathbb{Q}_p$ denote the field of $p$-adic numbers. Let $\\mu$ be the additive Haar measure on $\\mathbb{Q}_p$, normalized such that $\\mu(\\mathbb{Z}_p) = 1$, where $\\mathbb{Z}_p$ is the ring of $p$-adic integers. Let $\\psi$ be the standard additive character of $\\mathbb{Q}_p$ defined by $\\psi(x) = e^{2\\pi i \\{x\\}_p}$, where $\\{x\\}_p$ denotes the fractional part of $x$.\n\nConsider the function $f: \\mathbb{Q}_p \\to \\mathbb{R}$ defined by:\n$$ f(x) = \\begin{cases} 1 & \\text{if } |x|_p \\le 1, \\\\ |x|_p^{-2} & \\text{if } |x|_p > 1. \\end{cases} $$\n\n1.  Prove that $f \\in L^1(\\mathbb{Q}_p) \\cap L^2(\\mathbb{Q}_p)$.\n2.  Compute the Fourier transform $\\widehat{f}(\\xi)$, defined by\n    $$ \\widehat{f}(\\xi) = \\int_{\\mathbb{Q}_p} f(x) \\psi(x\\xi) \\, d\\mu(x). $$\n    Express $\\widehat{f}(\\xi)$ explicitly as a function of $|\\xi|_p$.\n3.  Verify the Plancherel theorem for this function by explicitly computing $\\|f\\|_{L^2}^2$ and $\\|\\widehat{f}\\|_{L^2}^2$.\n\n---\n\n### **Solution**\n\n#### **Part 1: Integrability of $f$**\n\nThe group $\\mathbb{Q}_p$ can be decomposed into disjoint spherical shells $S_k = \\{ x \\in \\mathbb{Q}_p : |x|_p = p^k \\}$ for $k \\in \\mathbb{Z}$.\nThe measure of a shell $S_k$ is given by:\n$$ \\mu(S_k) = \\mu(p^{-k}\\mathbb{Z}_p) - \\mu(p^{-k+1}\\mathbb{Z}_p) = p^k - p^{k-1} = p^k(1 - p^{-1}). $$\n\n**Checking $L^1$ norm:**\n$$ \\|f\\|_1 = \\int_{\\mathbb{Q}_p} |f(x)| \\, d\\mu(x) = \\int_{|x|_p \\le 1} 1 \\, d\\mu(x) + \\sum_{k=1}^{\\infty} \\int_{S_k} |x|_p^{-2} \\, d\\mu(x). $$\nThe first term is $\\mu(\\mathbb{Z}_p) = 1$.\nFor the sum, on $S_k$, $|x|_p = p^k$, so $f(x) = p^{-2k}$.\n$$ \\sum_{k=1}^{\\infty} p^{-2k} \\mu(S_k) = \\sum_{k=1}^{\\infty} p^{-2k} \\cdot p^k (1 - p^{-1}) = (1 - p^{-1}) \\sum_{k=1}^{\\infty} p^{-k}. $$\nThis is a geometric series with ratio $1/p < 1$.\n$$ \\sum_{k=1}^{\\infty} p^{-k} = \\frac{1/p}{1 - 1/p} = \\frac{1}{p-1}. $$\nThus,\n$$ \\|f\\|_1 = 1 + (1 - p^{-1}) \\frac{1}{p-1} = 1 + \\frac{p-1}{p} \\frac{1}{p-1} = 1 + \\frac{1}{p} < \\infty. $$\nSo $f \\in L^1(\\mathbb{Q}_p)$.\n\n**Checking $L^2$ norm:**\n$$ \\|f\\|_2^2 = \\int_{\\mathbb{Q}_p} |f(x)|^2 \\, d\\mu(x) = \\int_{|x|_p \\le 1} 1^2 \\, d\\mu(x) + \\sum_{k=1}^{\\infty} \\int_{S_k} (p^{-2k})^2 \\, d\\mu(x). $$\n$$ \\|f\\|_2^2 = 1 + \\sum_{k=1}^{\\infty} p^{-4k} p^k (1 - p^{-1}) = 1 + (1 - p^{-1}) \\sum_{k=1}^{\\infty} p^{-3k}. $$\nThe geometric series sum is $\\frac{p^{-3}}{1 - p^{-3}} = \\frac{1}{p^3 - 1}$.\n$$ \\|f\\|_2^2 = 1 + \\frac{p-1}{p} \\frac{1}{(p-1)(p^2+p+1)} = 1 + \\frac{1}{p(p^2+p+1)} < \\infty. $$\nSo $f \\in L^2(\\mathbb{Q}_p)$.\n\n---\n\n#### **Part 2: Computing the Fourier Transform**\n\nSince $f$ is a radial function (depends only on $|x|_p$), $\\widehat{f}$ will also be radial. Let $|\\xi|_p = p^m$ for some integer $m$.\n$$ \\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{\\infty} \\int_{S_k} f(x) \\psi(x\\xi) \\, d\\mu(x). $$\nSubstituting the values of $f(x)$:\n$$ \\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{0} \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x) + \\sum_{k=1}^{\\infty} p^{-2k} \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x). $$\nLet $I_k(\\xi) = \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x)$.\nWe define the ball $B_k = \\{ x : |x|_p \\le p^k \\}$. Then $S_k = B_k \\setminus B_{k-1}$.\nThe integral of the character over a ball is a standard result:\n$$ \\int_{B_k} \\psi(x\\xi) \\, d\\mu(x) = \\begin{cases} \\mu(B_k) = p^k & \\text{if } |\\xi|_p \\le p^{-k}, \\\\ 0 & \\text{if } |\\xi|_p > p^{-k}. \\end{cases} $$\nGiven $|\\xi|_p = p^m$, the condition $|\\xi|_p \\le p^{-k}$ is equivalent to $p^m \\le p^{-k} \\iff m \\le -k \\iff k \\le -m$.\n\nThus,\n$$ I_k(\\xi) = \\int_{B_k} \\psi(x\\xi) \\, d\\mu - \\int_{B_{k-1}} \\psi(x\\xi) \\, d\\mu. $$\nWe analyze $I_k(\\xi)$ based on the relation between $k$ and $-m$:\n1.  If $k \\le -m - 1$ (so $k-1 < k \\le -m$), both integrals are non-zero.\n    $I_k(\\xi) = p^k - p^{k-1}$. (Note: In this range, the character oscillates slowly enough to be effectively 1).\n2.  If $k = -m$:\n    The integral over $B_k$ is $p^k$ (since $k \\le -m$ holds).\n    The integral over $B_{k-1}$ is $p^{k-1}$ (since $k-1 \\le -m$ holds).\n    Wait, the condition is strict for the cutoff. Let's re-evaluate carefully.\n    \n    Let $J_k = \\mathbb{1}_{k \\le -m} p^k$. Then $I_k = J_k - J_{k-1}$.\n    \n    -   **Case $k < -m$**: $k \\le -m$ and $k-1 \\le -m$.\n        $I_k = p^k - p^{k-1}$.\n    -   **Case $k = -m$**: $k \\le -m$ is true. $k-1 \\le -m$ is true.\n        $I_k = p^{-m} - p^{-m-1}$.\n    -   **Case $k = -m+1$**: $k \\le -m$ is false ($J_k=0$). $k-1 = -m \\le -m$ is true ($J_{k-1}=p^{-m}$).\n        $I_k = 0 - p^{-m} = -p^{-m}$.\n    -   **Case $k > -m+1$**: Both are 0. $I_k = 0$.\n\nSo the only non-zero terms in the sum for $\\widehat{f}(\\xi)$ are for $k \\le -m+1$.\nWe split the calculation into cases for $m$ (the magnitude of $\\xi$).\n\n**Case A: $|\\xi|_p \\le 1$ (i.e., $m \\le 0$).**\nThe critical index is $-m+1 \\ge 1$.\nThe sum has two parts: $k \\le 0$ where $f(x)=1$, and $k \\ge 1$ where $f(x)=p^{-2k}$.\nSince $m \\le 0$, the \"cutoff\" $k = -m+1$ occurs in the $k \\ge 1$ region.\n\n1.  Sum for $k \\le 0$:\n    $$ \\sum_{k=-\\infty}^{0} 1 \\cdot (p^k - p^{k-1}) = \\lim_{N\\to-\\infty} (p^0 - p^{N-1}) = 1. $$\n    (This is simply $\\int_{|x|_p \\le 1} \\psi(x\\xi) d\\mu$, which is 1 since $|\\xi|_p \\le 1$).\n\n2.  Sum for $1 \\le k \\le -m$:\n    Here $I_k = p^k - p^{k-1}$.\n    $$ \\sum_{k=1}^{-m} p^{-2k} (p^k - p^{k-1}) = (1 - p^{-1}) \\sum_{k=1}^{-m} p^{-k} = (1 - p^{-1}) \\frac{p^{-1}(1 - p^{m})}{1 - p^{-1}} = p^{-1} - p^{m-1}. $$\n    If $-m < 1$ (i.e., $m=0$), this sum is empty (equals 0).\n\n3.  Term for $k = -m+1$:\n    $I_k = -p^{-m}$. $f(p^k) = p^{-2(-m+1)} = p^{2m-2}$.\n    $$ \\text{Term} = p^{2m-2} (-p^{-m}) = -p^{m-2}. $$\n\n**Subcase A1: $m=0$ ($|\\xi|_p=1$).**\nSum 1 (for $k \\le 0$) = 1.\nSum 2 (empty) = 0.\nTerm $k=1$: $I_1 = -1$ (since $m=0, -m+1=1$). $f(p)=p^{-2}$.\nContribution: $-p^{-2}$.\n$$ \\widehat{f}(\\xi) = 1 - p^{-2}. $$\n\n**Subcase A2: $m < 0$ ($|\\xi|_p < 1$).**\nTotal = (Sum 1) + (Sum 2) + (Term $k=-m+1$).\n$$ \\widehat{f}(\\xi) = 1 + (p^{-1} - p^{m-1}) - p^{m-2} = 1 + p^{-1} - p^{m-2}(p+1). $$\n\n**Case B: $|\\xi|_p > 1$ (i.e., $m \\ge 1$).**\nHere $-m+1 \\le 0$. The cutoff happens within the region where $f(x)=1$.\nThe terms for $k \\ge 1$ are all zero because $I_k=0$ there.\nWe only sum for $k \\le -m+1 \\le 0$.\nIn this range $f(p^k) = 1$.\nThe integral is over the ball $B_{-m+1}$.\n$$ \\widehat{f}(\\xi) = \\int_{|x|_p \\le p^{-m+1}} 1 \\cdot \\psi(x\\xi) \\, d\\mu(x). $$\nWe use the ball integral formula with radius $R = p^{-m+1}$.\nCondition for non-zero: $|\\xi|_p \\le 1/R = p^{m-1}$.\nBut we know $|\\xi|_p = p^m$.\nSince $p^m > p^{m-1}$, the condition is **false**.\nThus, $\\int_{B_{-m+1}} \\psi(x\\xi) \\, d\\mu(x) = 0$.\nWait, let's re-verify the cutoff summation logic.\n$\\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{-m+1} f(p^k) I_k$.\nSince $k \\le -m+1 \\le 0$, $f(p^k) = 1$ everywhere in the sum.\nSo $\\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{-m+1} (J_k - J_{k-1}) = J_{-m+1} - \\lim_{N\\to-\\infty} J_N$.\n$J_{-m+1} = p^{-m+1} \\mathbb{1}_{-m+1 \\le -m}$.\nIs $-m+1 \\le -m$? $1 \\le 0$? False.\nSo $J_{-m+1} = 0$.\nHence $\\widehat{f}(\\xi) = 0$ for all $m \\ge 1$.\n\n**Summary of $\\widehat{f}(\\xi)$:**\n$$ \\widehat{f}(\\xi) = \\begin{cases} 1 + p^{-1} - p^{-2}(p+1)|\\xi|_p & \\text{if } |\\xi|_p < 1, \\\\ 1 - p^{-2} & \\text{if } |\\xi|_p = 1, \\\\ 0 & \\text{if } |\\xi|_p > 1. \\end{cases} $$\nLet's check continuity at $|\\xi|_p \\to 1^-$ (i.e., $m \\to 0^-$? No, $p$-adic norm is discrete).\nAt $m=0$, formula 1 gives $1 + p^{-1} - p^{-2}(p+1) = 1 + p^{-1} - p^{-1} - p^{-2} = 1 - p^{-2}$. Matches.\nSo we can combine them:\n$$ \\widehat{f}(\\xi) = \\left( 1 + \\frac{1}{p} - \\frac{p+1}{p^2} |\\xi|_p \\right) \\mathbf{1}_{|\\xi|_p \\le 1}. $$\n\n---\n\n#### **Part 3: Verification of Plancherel Theorem**\n\nWe previously computed $\\|f\\|_2^2 = 1 + \\frac{1}{p(p^2+p+1)}$.\n\nNow we compute $\\|\\widehat{f}\\|_2^2$:\n$$ \\|\\widehat{f}\\|_2^2 = \\int_{\\mathbb{Q}_p} |\\widehat{f}(\\xi)|^2 \\, d\\mu(\\xi). $$\nSince $\\widehat{f}$ is supported on $|\\xi|_p \\le 1$ ($m \\le 0$):\n$$ \\|\\widehat{f}\\|_2^2 = \\sum_{m=-\\infty}^{0} \\int_{S_m} \\left( 1 + p^{-1} - p^{-2}(p+1)p^m \\right)^2 \\, d\\mu(\\xi). $$\nLet $A = 1 + p^{-1}$. Let $B = p^{-2}(p+1)$.\nTerm in square: $(A - B p^m)^2 = A^2 - 2AB p^m + B^2 p^{2m}$.\nMeasure of $S_m$ ($m \\le 0$): $p^m(1 - p^{-1})$.\n\n$$ \\|\\widehat{f}\\|_2^2 = \\sum_{m=-\\infty}^{0} (A^2 - 2AB p^m + B^2 p^{2m}) p^m (1 - p^{-1}). $$\nLet $C = 1 - p^{-1}$. Sum over $j = -m$ where $j \\in [0, \\infty)$. $p^m = p^{-j}$.\nTerms:\n1.  $A^2 \\sum p^m \\cdot p^m C$? No, integrand is constant on shell. Integral is Value$^2 \\times$ Volume.\n    $\\sum_{m=-\\infty}^0 (A - B p^m)^2 p^m C$.\n    Let $x = p^m$. Summing geometric series $\\sum_{k=0}^\\infty x^{k}$ with $x=1/p$.\n    Series 1: $\\sum_{m \\le 0} A^2 p^m = A^2 \\frac{1}{1-1/p} = A^2 \\frac{p}{p-1} = A^2 / C$.\n    Series 2: $\\sum_{m \\le 0} (-2AB) p^{2m} = -2AB \\frac{1}{1-1/p^2}$.\n    Series 3: $\\sum_{m \\le 0} B^2 p^{3m} = B^2 \\frac{1}{1-1/p^3}$.\n\nTotal $\\|\\widehat{f}\\|_2^2 = C \\left[ \\frac{A^2}{1-p^{-1}} - \\frac{2AB}{1-p^{-2}} + \\frac{B^2}{1-p^{-3}} \\right]$.\nNote $C = 1 - p^{-1}$.\nTerm 1: $C \\frac{A^2}{C} = A^2 = (1 + p^{-1})^2 = 1 + 2p^{-1} + p^{-2}$.\nTerm 2: $C \\frac{2AB}{C(1+p^{-1})} = \\frac{2AB}{1+p^{-1}} = \\frac{2A(p^{-2}(p+1))}{A} = 2 p^{-2}(p+1) = 2p^{-1} + 2p^{-2}$.\n    (Since $A = 1+1/p = (p+1)/p$, $2AB/(1+1/p) = 2B ((p+1)/p) / ((p+1)/p) = 2B$).\n    Wait, $1-p^{-2} = (1-p^{-1})(1+p^{-1})$. So denominator cancels $C$.\n    Left with $2AB/(1+p^{-1})$. Recall $A = 1+p^{-1}$. So it is just $2B$.\n    $2B = 2(p^{-2}(p+1)) = 2p^{-2} + 2p^{-1}$.\nTerm 3: $C \\frac{B^2}{1-p^{-3}} = (1-p^{-1}) \\frac{B^2}{(1-p^{-1})(1+p^{-1}+p^{-2})} = \\frac{B^2}{1+p^{-1}+p^{-2}}$.\n    $B = p^{-2}(p+1)$. $B^2 = p^{-4}(p+1)^2$.\n    Term 3 = $\\frac{p^{-4}(p+1)^2}{1+p^{-1}+p^{-2}} \\cdot \\frac{p^2}{p^2} = \\frac{p^{-4}(p+1)^2 p^2}{p^2+p+1} = \\frac{p^{-2}(p+1)^2}{p^2+p+1}$.\n\nSum = (Term 1) - (Term 2) + (Term 3).\n$(1 + 2p^{-1} + p^{-2}) - (2p^{-1} + 2p^{-2}) + \\text{Term 3}$\n$= 1 - p^{-2} + \\frac{p^{-2}(p+1)^2}{p^2+p+1}$\n$= 1 + p^{-2} \\left( -1 + \\frac{p^2+2p+1}{p^2+p+1} \\right)$\n$= 1 + p^{-2} \\left( \\frac{-(p^2+p+1) + p^2+2p+1}{p^2+p+1} \\right)$\n$= 1 + p^{-2} \\left( \\frac{p}{p^2+p+1} \\right)$\n$= 1 + \\frac{p^{-1}}{p^2+p+1} = 1 + \\frac{1}{p(p^2+p+1)}$.\n\nThis matches the result for $\\|f\\|_2^2$ exactly.\n\n**Conclusion:**\nThe Plancherel theorem is verified: $\\|f\\|_2^2 = \\|\\widehat{f}\\|_2^2$.",
        "raw_answer": "Based on the instruction to act as a testee generating a challenging problem in abstract harmonic analysis, here is the generated problem followed by a complete, rigorous solution.\n\n---\n\n### **Generated Problem**\n\n**Topic:** Harmonic Analysis on Local Fields ($p$-adic Analysis)\n\n**Problem Statement:**\nLet $p$ be a prime number and let $\\mathbb{Q}_p$ denote the field of $p$-adic numbers. Let $\\mu$ be the additive Haar measure on $\\mathbb{Q}_p$, normalized such that $\\mu(\\mathbb{Z}_p) = 1$, where $\\mathbb{Z}_p$ is the ring of $p$-adic integers. Let $\\psi$ be the standard additive character of $\\mathbb{Q}_p$ defined by $\\psi(x) = e^{2\\pi i \\{x\\}_p}$, where $\\{x\\}_p$ denotes the fractional part of $x$.\n\nConsider the function $f: \\mathbb{Q}_p \\to \\mathbb{R}$ defined by:\n$$ f(x) = \\begin{cases} 1 & \\text{if } |x|_p \\le 1, \\\\ |x|_p^{-2} & \\text{if } |x|_p > 1. \\end{cases} $$\n\n1.  Prove that $f \\in L^1(\\mathbb{Q}_p) \\cap L^2(\\mathbb{Q}_p)$.\n2.  Compute the Fourier transform $\\widehat{f}(\\xi)$, defined by\n    $$ \\widehat{f}(\\xi) = \\int_{\\mathbb{Q}_p} f(x) \\psi(x\\xi) \\, d\\mu(x). $$\n    Express $\\widehat{f}(\\xi)$ explicitly as a function of $|\\xi|_p$.\n3.  Verify the Plancherel theorem for this function by explicitly computing $\\|f\\|_{L^2}^2$ and $\\|\\widehat{f}\\|_{L^2}^2$.\n\n---\n\n### **Solution**\n\n#### **Part 1: Integrability of $f$**\n\nThe group $\\mathbb{Q}_p$ can be decomposed into disjoint spherical shells $S_k = \\{ x \\in \\mathbb{Q}_p : |x|_p = p^k \\}$ for $k \\in \\mathbb{Z}$.\nThe measure of a shell $S_k$ is given by:\n$$ \\mu(S_k) = \\mu(p^{-k}\\mathbb{Z}_p) - \\mu(p^{-k+1}\\mathbb{Z}_p) = p^k - p^{k-1} = p^k(1 - p^{-1}). $$\n\n**Checking $L^1$ norm:**\n$$ \\|f\\|_1 = \\int_{\\mathbb{Q}_p} |f(x)| \\, d\\mu(x) = \\int_{|x|_p \\le 1} 1 \\, d\\mu(x) + \\sum_{k=1}^{\\infty} \\int_{S_k} |x|_p^{-2} \\, d\\mu(x). $$\nThe first term is $\\mu(\\mathbb{Z}_p) = 1$.\nFor the sum, on $S_k$, $|x|_p = p^k$, so $f(x) = p^{-2k}$.\n$$ \\sum_{k=1}^{\\infty} p^{-2k} \\mu(S_k) = \\sum_{k=1}^{\\infty} p^{-2k} \\cdot p^k (1 - p^{-1}) = (1 - p^{-1}) \\sum_{k=1}^{\\infty} p^{-k}. $$\nThis is a geometric series with ratio $1/p < 1$.\n$$ \\sum_{k=1}^{\\infty} p^{-k} = \\frac{1/p}{1 - 1/p} = \\frac{1}{p-1}. $$\nThus,\n$$ \\|f\\|_1 = 1 + (1 - p^{-1}) \\frac{1}{p-1} = 1 + \\frac{p-1}{p} \\frac{1}{p-1} = 1 + \\frac{1}{p} < \\infty. $$\nSo $f \\in L^1(\\mathbb{Q}_p)$.\n\n**Checking $L^2$ norm:**\n$$ \\|f\\|_2^2 = \\int_{\\mathbb{Q}_p} |f(x)|^2 \\, d\\mu(x) = \\int_{|x|_p \\le 1} 1^2 \\, d\\mu(x) + \\sum_{k=1}^{\\infty} \\int_{S_k} (p^{-2k})^2 \\, d\\mu(x). $$\n$$ \\|f\\|_2^2 = 1 + \\sum_{k=1}^{\\infty} p^{-4k} p^k (1 - p^{-1}) = 1 + (1 - p^{-1}) \\sum_{k=1}^{\\infty} p^{-3k}. $$\nThe geometric series sum is $\\frac{p^{-3}}{1 - p^{-3}} = \\frac{1}{p^3 - 1}$.\n$$ \\|f\\|_2^2 = 1 + \\frac{p-1}{p} \\frac{1}{(p-1)(p^2+p+1)} = 1 + \\frac{1}{p(p^2+p+1)} < \\infty. $$\nSo $f \\in L^2(\\mathbb{Q}_p)$.\n\n---\n\n#### **Part 2: Computing the Fourier Transform**\n\nSince $f$ is a radial function (depends only on $|x|_p$), $\\widehat{f}$ will also be radial. Let $|\\xi|_p = p^m$ for some integer $m$.\n$$ \\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{\\infty} \\int_{S_k} f(x) \\psi(x\\xi) \\, d\\mu(x). $$\nSubstituting the values of $f(x)$:\n$$ \\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{0} \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x) + \\sum_{k=1}^{\\infty} p^{-2k} \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x). $$\nLet $I_k(\\xi) = \\int_{S_k} \\psi(x\\xi) \\, d\\mu(x)$.\nWe define the ball $B_k = \\{ x : |x|_p \\le p^k \\}$. Then $S_k = B_k \\setminus B_{k-1}$.\nThe integral of the character over a ball is a standard result:\n$$ \\int_{B_k} \\psi(x\\xi) \\, d\\mu(x) = \\begin{cases} \\mu(B_k) = p^k & \\text{if } |\\xi|_p \\le p^{-k}, \\\\ 0 & \\text{if } |\\xi|_p > p^{-k}. \\end{cases} $$\nGiven $|\\xi|_p = p^m$, the condition $|\\xi|_p \\le p^{-k}$ is equivalent to $p^m \\le p^{-k} \\iff m \\le -k \\iff k \\le -m$.\n\nThus,\n$$ I_k(\\xi) = \\int_{B_k} \\psi(x\\xi) \\, d\\mu - \\int_{B_{k-1}} \\psi(x\\xi) \\, d\\mu. $$\nWe analyze $I_k(\\xi)$ based on the relation between $k$ and $-m$:\n1.  If $k \\le -m - 1$ (so $k-1 < k \\le -m$), both integrals are non-zero.\n    $I_k(\\xi) = p^k - p^{k-1}$. (Note: In this range, the character oscillates slowly enough to be effectively 1).\n2.  If $k = -m$:\n    The integral over $B_k$ is $p^k$ (since $k \\le -m$ holds).\n    The integral over $B_{k-1}$ is $p^{k-1}$ (since $k-1 \\le -m$ holds).\n    Wait, the condition is strict for the cutoff. Let's re-evaluate carefully.\n    \n    Let $J_k = \\mathbb{1}_{k \\le -m} p^k$. Then $I_k = J_k - J_{k-1}$.\n    \n    -   **Case $k < -m$**: $k \\le -m$ and $k-1 \\le -m$.\n        $I_k = p^k - p^{k-1}$.\n    -   **Case $k = -m$**: $k \\le -m$ is true. $k-1 \\le -m$ is true.\n        $I_k = p^{-m} - p^{-m-1}$.\n    -   **Case $k = -m+1$**: $k \\le -m$ is false ($J_k=0$). $k-1 = -m \\le -m$ is true ($J_{k-1}=p^{-m}$).\n        $I_k = 0 - p^{-m} = -p^{-m}$.\n    -   **Case $k > -m+1$**: Both are 0. $I_k = 0$.\n\nSo the only non-zero terms in the sum for $\\widehat{f}(\\xi)$ are for $k \\le -m+1$.\nWe split the calculation into cases for $m$ (the magnitude of $\\xi$).\n\n**Case A: $|\\xi|_p \\le 1$ (i.e., $m \\le 0$).**\nThe critical index is $-m+1 \\ge 1$.\nThe sum has two parts: $k \\le 0$ where $f(x)=1$, and $k \\ge 1$ where $f(x)=p^{-2k}$.\nSince $m \\le 0$, the \"cutoff\" $k = -m+1$ occurs in the $k \\ge 1$ region.\n\n1.  Sum for $k \\le 0$:\n    $$ \\sum_{k=-\\infty}^{0} 1 \\cdot (p^k - p^{k-1}) = \\lim_{N\\to-\\infty} (p^0 - p^{N-1}) = 1. $$\n    (This is simply $\\int_{|x|_p \\le 1} \\psi(x\\xi) d\\mu$, which is 1 since $|\\xi|_p \\le 1$).\n\n2.  Sum for $1 \\le k \\le -m$:\n    Here $I_k = p^k - p^{k-1}$.\n    $$ \\sum_{k=1}^{-m} p^{-2k} (p^k - p^{k-1}) = (1 - p^{-1}) \\sum_{k=1}^{-m} p^{-k} = (1 - p^{-1}) \\frac{p^{-1}(1 - p^{m})}{1 - p^{-1}} = p^{-1} - p^{m-1}. $$\n    If $-m < 1$ (i.e., $m=0$), this sum is empty (equals 0).\n\n3.  Term for $k = -m+1$:\n    $I_k = -p^{-m}$. $f(p^k) = p^{-2(-m+1)} = p^{2m-2}$.\n    $$ \\text{Term} = p^{2m-2} (-p^{-m}) = -p^{m-2}. $$\n\n**Subcase A1: $m=0$ ($|\\xi|_p=1$).**\nSum 1 (for $k \\le 0$) = 1.\nSum 2 (empty) = 0.\nTerm $k=1$: $I_1 = -1$ (since $m=0, -m+1=1$). $f(p)=p^{-2}$.\nContribution: $-p^{-2}$.\n$$ \\widehat{f}(\\xi) = 1 - p^{-2}. $$\n\n**Subcase A2: $m < 0$ ($|\\xi|_p < 1$).**\nTotal = (Sum 1) + (Sum 2) + (Term $k=-m+1$).\n$$ \\widehat{f}(\\xi) = 1 + (p^{-1} - p^{m-1}) - p^{m-2} = 1 + p^{-1} - p^{m-2}(p+1). $$\n\n**Case B: $|\\xi|_p > 1$ (i.e., $m \\ge 1$).**\nHere $-m+1 \\le 0$. The cutoff happens within the region where $f(x)=1$.\nThe terms for $k \\ge 1$ are all zero because $I_k=0$ there.\nWe only sum for $k \\le -m+1 \\le 0$.\nIn this range $f(p^k) = 1$.\nThe integral is over the ball $B_{-m+1}$.\n$$ \\widehat{f}(\\xi) = \\int_{|x|_p \\le p^{-m+1}} 1 \\cdot \\psi(x\\xi) \\, d\\mu(x). $$\nWe use the ball integral formula with radius $R = p^{-m+1}$.\nCondition for non-zero: $|\\xi|_p \\le 1/R = p^{m-1}$.\nBut we know $|\\xi|_p = p^m$.\nSince $p^m > p^{m-1}$, the condition is **false**.\nThus, $\\int_{B_{-m+1}} \\psi(x\\xi) \\, d\\mu(x) = 0$.\nWait, let's re-verify the cutoff summation logic.\n$\\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{-m+1} f(p^k) I_k$.\nSince $k \\le -m+1 \\le 0$, $f(p^k) = 1$ everywhere in the sum.\nSo $\\widehat{f}(\\xi) = \\sum_{k=-\\infty}^{-m+1} (J_k - J_{k-1}) = J_{-m+1} - \\lim_{N\\to-\\infty} J_N$.\n$J_{-m+1} = p^{-m+1} \\mathbb{1}_{-m+1 \\le -m}$.\nIs $-m+1 \\le -m$? $1 \\le 0$? False.\nSo $J_{-m+1} = 0$.\nHence $\\widehat{f}(\\xi) = 0$ for all $m \\ge 1$.\n\n**Summary of $\\widehat{f}(\\xi)$:**\n$$ \\widehat{f}(\\xi) = \\begin{cases} 1 + p^{-1} - p^{-2}(p+1)|\\xi|_p & \\text{if } |\\xi|_p < 1, \\\\ 1 - p^{-2} & \\text{if } |\\xi|_p = 1, \\\\ 0 & \\text{if } |\\xi|_p > 1. \\end{cases} $$\nLet's check continuity at $|\\xi|_p \\to 1^-$ (i.e., $m \\to 0^-$? No, $p$-adic norm is discrete).\nAt $m=0$, formula 1 gives $1 + p^{-1} - p^{-2}(p+1) = 1 + p^{-1} - p^{-1} - p^{-2} = 1 - p^{-2}$. Matches.\nSo we can combine them:\n$$ \\widehat{f}(\\xi) = \\left( 1 + \\frac{1}{p} - \\frac{p+1}{p^2} |\\xi|_p \\right) \\mathbf{1}_{|\\xi|_p \\le 1}. $$\n\n---\n\n#### **Part 3: Verification of Plancherel Theorem**\n\nWe previously computed $\\|f\\|_2^2 = 1 + \\frac{1}{p(p^2+p+1)}$.\n\nNow we compute $\\|\\widehat{f}\\|_2^2$:\n$$ \\|\\widehat{f}\\|_2^2 = \\int_{\\mathbb{Q}_p} |\\widehat{f}(\\xi)|^2 \\, d\\mu(\\xi). $$\nSince $\\widehat{f}$ is supported on $|\\xi|_p \\le 1$ ($m \\le 0$):\n$$ \\|\\widehat{f}\\|_2^2 = \\sum_{m=-\\infty}^{0} \\int_{S_m} \\left( 1 + p^{-1} - p^{-2}(p+1)p^m \\right)^2 \\, d\\mu(\\xi). $$\nLet $A = 1 + p^{-1}$. Let $B = p^{-2}(p+1)$.\nTerm in square: $(A - B p^m)^2 = A^2 - 2AB p^m + B^2 p^{2m}$.\nMeasure of $S_m$ ($m \\le 0$): $p^m(1 - p^{-1})$.\n\n$$ \\|\\widehat{f}\\|_2^2 = \\sum_{m=-\\infty}^{0} (A^2 - 2AB p^m + B^2 p^{2m}) p^m (1 - p^{-1}). $$\nLet $C = 1 - p^{-1}$. Sum over $j = -m$ where $j \\in [0, \\infty)$. $p^m = p^{-j}$.\nTerms:\n1.  $A^2 \\sum p^m \\cdot p^m C$? No, integrand is constant on shell. Integral is Value$^2 \\times$ Volume.\n    $\\sum_{m=-\\infty}^0 (A - B p^m)^2 p^m C$.\n    Let $x = p^m$. Summing geometric series $\\sum_{k=0}^\\infty x^{k}$ with $x=1/p$.\n    Series 1: $\\sum_{m \\le 0} A^2 p^m = A^2 \\frac{1}{1-1/p} = A^2 \\frac{p}{p-1} = A^2 / C$.\n    Series 2: $\\sum_{m \\le 0} (-2AB) p^{2m} = -2AB \\frac{1}{1-1/p^2}$.\n    Series 3: $\\sum_{m \\le 0} B^2 p^{3m} = B^2 \\frac{1}{1-1/p^3}$.\n\nTotal $\\|\\widehat{f}\\|_2^2 = C \\left[ \\frac{A^2}{1-p^{-1}} - \\frac{2AB}{1-p^{-2}} + \\frac{B^2}{1-p^{-3}} \\right]$.\nNote $C = 1 - p^{-1}$.\nTerm 1: $C \\frac{A^2}{C} = A^2 = (1 + p^{-1})^2 = 1 + 2p^{-1} + p^{-2}$.\nTerm 2: $C \\frac{2AB}{C(1+p^{-1})} = \\frac{2AB}{1+p^{-1}} = \\frac{2A(p^{-2}(p+1))}{A} = 2 p^{-2}(p+1) = 2p^{-1} + 2p^{-2}$.\n    (Since $A = 1+1/p = (p+1)/p$, $2AB/(1+1/p) = 2B ((p+1)/p) / ((p+1)/p) = 2B$).\n    Wait, $1-p^{-2} = (1-p^{-1})(1+p^{-1})$. So denominator cancels $C$.\n    Left with $2AB/(1+p^{-1})$. Recall $A = 1+p^{-1}$. So it is just $2B$.\n    $2B = 2(p^{-2}(p+1)) = 2p^{-2} + 2p^{-1}$.\nTerm 3: $C \\frac{B^2}{1-p^{-3}} = (1-p^{-1}) \\frac{B^2}{(1-p^{-1})(1+p^{-1}+p^{-2})} = \\frac{B^2}{1+p^{-1}+p^{-2}}$.\n    $B = p^{-2}(p+1)$. $B^2 = p^{-4}(p+1)^2$.\n    Term 3 = $\\frac{p^{-4}(p+1)^2}{1+p^{-1}+p^{-2}} \\cdot \\frac{p^2}{p^2} = \\frac{p^{-4}(p+1)^2 p^2}{p^2+p+1} = \\frac{p^{-2}(p+1)^2}{p^2+p+1}$.\n\nSum = (Term 1) - (Term 2) + (Term 3).\n$(1 + 2p^{-1} + p^{-2}) - (2p^{-1} + 2p^{-2}) + \\text{Term 3}$\n$= 1 - p^{-2} + \\frac{p^{-2}(p+1)^2}{p^2+p+1}$\n$= 1 + p^{-2} \\left( -1 + \\frac{p^2+2p+1}{p^2+p+1} \\right)$\n$= 1 + p^{-2} \\left( \\frac{-(p^2+p+1) + p^2+2p+1}{p^2+p+1} \\right)$\n$= 1 + p^{-2} \\left( \\frac{p}{p^2+p+1} \\right)$\n$= 1 + \\frac{p^{-1}}{p^2+p+1} = 1 + \\frac{1}{p(p^2+p+1)}$.\n\nThis matches the result for $\\|f\\|_2^2$ exactly.\n\n**Conclusion:**\nThe Plancherel theorem is verified: $\\|f\\|_2^2 = \\|\\widehat{f}\\|_2^2$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging mathematics problem in the domain of \"Integral transforms, operational calculus\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Choose a specific topic within the domain\nLet's focus on the Laplace transform, a key concept within integral transforms and operational calculus. The Laplace transform is defined as $\\mathcal{L}\\{f(t)\\} = \\int_{0}^{\\infty} e^{-st}f(t)dt = F(s)$, where $f(t)$ is a function defined for $t \\geq 0$.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider applying the Laplace transform to solve a differential equation, as this involves understanding both the transform and its inverse. A suitable problem could involve solving an initial value problem (IVP) using the Laplace transform.\n\n## Step 4: Specify the problem\nLet's consider the following IVP: $y'' + 4y = \\sin(2t)$, with initial conditions $y(0) = 0$ and $y'(0) = 0$. The task is to solve for $y(t)$ using the Laplace transform.\n\n## Step 5: Write the problem statement\n\nUse the Laplace transform to solve the initial value problem $y'' + 4y = \\sin(2t)$, where $y(0) = 0$ and $y'(0) = 0$.\n\n## Step 6: Provide the solution\nTo solve the given IVP using the Laplace transform, we first apply the Laplace transform to both sides of the differential equation.\n\n## Step 7: Apply the Laplace transform to the differential equation\n$\\mathcal{L}\\{y'' + 4y\\} = \\mathcal{L}\\{\\sin(2t)\\}$. Using linearity, we get $\\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\}$.\n\n## Step 8: Evaluate the Laplace transforms\n$\\mathcal{L}\\{y''\\} = s^2Y(s) - sy(0) - y'(0)$ and $\\mathcal{L}\\{y\\} = Y(s)$, where $Y(s) = \\mathcal{L}\\{y(t)\\}$. Given $y(0) = 0$ and $y'(0) = 0$, $\\mathcal{L}\\{y''\\} = s^2Y(s)$. $\\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4}$.\n\n## Step 9: Substitute the known values and simplify\n$s^2Y(s) + 4Y(s) = \\frac{2}{s^2 + 4}$. Thus, $Y(s)(s^2 + 4) = \\frac{2}{s^2 + 4}$, which simplifies to $Y(s) = \\frac{2}{(s^2 + 4)^2}$.\n\n## Step 10: Find the inverse Laplace transform of $Y(s)$\nTo find $y(t)$, we need $\\mathcal{L}^{-1}\\{Y(s)\\} = \\mathcal{L}^{-1}\\left\\{\\frac{2}{(s^2 + 4)^2}\\right\\}$. Recall that $\\mathcal{L}\\{\\sin(at)\\} = \\frac{a}{s^2 + a^2}$, and use the property that $\\mathcal{L}^{-1}\\{F(s)\\} = f(t)$ implies $\\mathcal{L}^{-1}\\left\\{\\frac{d}{ds}F(s)\\right\\} = -tf(t)$, or more directly, utilize the convolution or known transforms.\n\n## Step 11: Evaluate the inverse Laplace transform\nUsing the formula for $\\mathcal{L}^{-1}\\left\\{\\frac{2a^3}{(s^2 + a^2)^2}\\right\\} = \\sin(at) - at\\cos(at)$ with $a = 2$, we adjust for our case: $\\mathcal{L}^{-1}\\left\\{\\frac{2}{(s^2 + 4)^2}\\right\\} = \\frac{1}{4}\\mathcal{L}^{-1}\\left\\{\\frac{2 \\cdot 2^3}{(s^2 + 2^2)^2}\\right\\} = \\frac{1}{4}(\\sin(2t) - 2t\\cos(2t))$.\n\n## Step 12: Write the complete solution",
    "run_id": "30",
    "outer_attempt": 1,
    "topic_slug": "integral_transforms_and_operational_calculus",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the initial value problem (IVP) given by\n$$y'' + 4y = \\sin(2t)$$\nwith initial conditions $y(0) = 0$ and $y'(0) = 0$, we will use the Laplace transform method.\n\n### Step 1: Apply the Laplace Transform\n\nLet $Y(s) = \\mathcal{L}\\{y(t)\\}$ be the Laplace transform of the unknown function $y(t)$. Applying the Laplace transform to both sides of the differential equation, we utilize the linearity property:\n$$ \\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\} $$\n\nRecall the derivative property for the Laplace transform:\n$$ \\mathcal{L}\\{y''\\} = s^2 Y(s) - s y(0) - y'(0) $$\n\nSubstitute the given initial conditions $y(0) = 0$ and $y'(0) = 0$:\n$$ \\mathcal{L}\\{y''\\} = s^2 Y(s) - s(0) - 0 = s^2 Y(s) $$\n\nNext, recall the standard transform for sine:\n$$ \\mathcal{L}\\{\\sin(at)\\} = \\frac{a}{s^2 + a^2} $$\nFor $\\sin(2t)$, where $a=2$:\n$$ \\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4} $$\n\nSubstituting these back into the transformed equation yields:\n$$ s^2 Y(s) + 4 Y(s) = \\frac{2}{s^2 + 4} $$\n\n### Step 2: Solve for $Y(s)$\n\nFactor out $Y(s)$ on the left side:\n$$ (s^2 + 4) Y(s) = \\frac{2}{s^2 + 4} $$\n\nDivide by $(s^2 + 4)$ to isolate $Y(s)$:\n$$ Y(s) = \\frac{2}{(s^2 + 4)^2} $$\n\n### Step 3: Compute the Inverse Laplace Transform\n\nWe now need to find $y(t) = \\mathcal{L}^{-1}\\{Y(s)\\}$. We are looking for the inverse transform of:\n$$ Y(s) = \\frac{2}{(s^2 + 4)^2} $$\n\nWe can derive this inverse using the property of the derivative of a transform, specifically regarding the term $t \\cos(at)$.\nRecall that if $F(s) = \\mathcal{L}\\{f(t)\\}$, then $F'(s) = \\mathcal{L}\\{-t f(t)\\}$.\n\nLet us consider the transform of $\\cos(2t)$:\n$$ \\mathcal{L}\\{\\cos(2t)\\} = \\frac{s}{s^2 + 4} $$\nDifferentiating with respect to $s$:\n$$ \\frac{d}{ds} \\left( \\frac{s}{s^2 + 4} \\right) = \\frac{1 \\cdot (s^2 + 4) - s \\cdot (2s)}{(s^2 + 4)^2} = \\frac{4 - s^2}{(s^2 + 4)^2} $$\nUsing the property $\\mathcal{L}\\{t f(t)\\} = -F'(s)$, we have:\n$$ \\mathcal{L}\\{t \\cos(2t)\\} = - \\frac{4 - s^2}{(s^2 + 4)^2} = \\frac{s^2 - 4}{(s^2 + 4)^2} $$\n\nThis does not immediately match our target $Y(s)$. However, we can also look at the transform of $\\sin(2t)$:\n$$ \\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4} = \\frac{2(s^2 + 4)}{(s^2 + 4)^2} = \\frac{2s^2 + 8}{(s^2 + 4)^2} $$\n\nWe seek a linear combination of these known transforms that equals $\\frac{2}{(s^2 + 4)^2}$. Let us check the expression $\\sin(2t) - 2t \\cos(2t)$.\n$$ \\mathcal{L}\\{\\sin(2t) - 2t \\cos(2t)\\} = \\mathcal{L}\\{\\sin(2t)\\} - 2\\mathcal{L}\\{t \\cos(2t)\\} $$\n$$ = \\frac{2s^2 + 8}{(s^2 + 4)^2} - 2 \\left( \\frac{s^2 - 4}{(s^2 + 4)^2} \\right) $$\n$$ = \\frac{2s^2 + 8 - 2s^2 + 8}{(s^2 + 4)^2} $$\n$$ = \\frac{16}{(s^2 + 4)^2} $$\n\nWe have obtained a numerator of 16. Our target numerator is 2. Therefore, we must divide by 8:\n$$ \\mathcal{L}^{-1} \\left\\{ \\frac{2}{(s^2 + 4)^2} \\right\\} = \\frac{1}{8} \\mathcal{L}^{-1} \\left\\{ \\frac{16}{(s^2 + 4)^2} \\right\\} $$\n$$ y(t) = \\frac{1}{8} \\left( \\sin(2t) - 2t \\cos(2t) \\right) $$\n\n### Step 4: Final Solution and Verification\n\nSimplifying the expression:\n$$ y(t) = \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) $$\n\n**Verification:**\nLet us verify this solution satisfies the original IVP.\n1.  **Initial Conditions:**\n    *   $y(0) = \\frac{1}{8}(0) - 0 = 0$. (Check)\n    *   $y'(t) = \\frac{1}{8}(2\\cos(2t)) - \\frac{1}{4}(\\cos(2t) - 2t\\sin(2t)) = \\frac{1}{4}\\cos(2t) - \\frac{1}{4}\\cos(2t) + \\frac{1}{2}t\\sin(2t) = \\frac{1}{2}t\\sin(2t)$.\n    *   $y'(0) = 0$. (Check)\n\n2.  **Differential Equation:**\n    *   Calculate $y''(t)$:\n        $y''(t) = \\frac{d}{dt} \\left( \\frac{1}{2}t\\sin(2t) \\right) = \\frac{1}{2}(\\sin(2t) + 2t\\cos(2t)) = \\frac{1}{2}\\sin(2t) + t\\cos(2t)$.\n    *   Substitute into $y'' + 4y$:\n        $$ \\left( \\frac{1}{2}\\sin(2t) + t\\cos(2t) \\right) + 4 \\left( \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) \\right) $$\n        $$ = \\frac{1}{2}\\sin(2t) + t\\cos(2t) + \\frac{1}{2}\\sin(2t) - t\\cos(2t) $$\n        $$ = \\sin(2t) $$\n    The solution satisfies the differential equation.\n\n**Conclusion:**\nThe solution to the initial value problem is:\n$$ y(t) = \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) $$",
        "raw_answer": "To solve the initial value problem (IVP) given by\n$$y'' + 4y = \\sin(2t)$$\nwith initial conditions $y(0) = 0$ and $y'(0) = 0$, we will use the Laplace transform method.\n\n### Step 1: Apply the Laplace Transform\n\nLet $Y(s) = \\mathcal{L}\\{y(t)\\}$ be the Laplace transform of the unknown function $y(t)$. Applying the Laplace transform to both sides of the differential equation, we utilize the linearity property:\n$$ \\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\} $$\n\nRecall the derivative property for the Laplace transform:\n$$ \\mathcal{L}\\{y''\\} = s^2 Y(s) - s y(0) - y'(0) $$\n\nSubstitute the given initial conditions $y(0) = 0$ and $y'(0) = 0$:\n$$ \\mathcal{L}\\{y''\\} = s^2 Y(s) - s(0) - 0 = s^2 Y(s) $$\n\nNext, recall the standard transform for sine:\n$$ \\mathcal{L}\\{\\sin(at)\\} = \\frac{a}{s^2 + a^2} $$\nFor $\\sin(2t)$, where $a=2$:\n$$ \\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4} $$\n\nSubstituting these back into the transformed equation yields:\n$$ s^2 Y(s) + 4 Y(s) = \\frac{2}{s^2 + 4} $$\n\n### Step 2: Solve for $Y(s)$\n\nFactor out $Y(s)$ on the left side:\n$$ (s^2 + 4) Y(s) = \\frac{2}{s^2 + 4} $$\n\nDivide by $(s^2 + 4)$ to isolate $Y(s)$:\n$$ Y(s) = \\frac{2}{(s^2 + 4)^2} $$\n\n### Step 3: Compute the Inverse Laplace Transform\n\nWe now need to find $y(t) = \\mathcal{L}^{-1}\\{Y(s)\\}$. We are looking for the inverse transform of:\n$$ Y(s) = \\frac{2}{(s^2 + 4)^2} $$\n\nWe can derive this inverse using the property of the derivative of a transform, specifically regarding the term $t \\cos(at)$.\nRecall that if $F(s) = \\mathcal{L}\\{f(t)\\}$, then $F'(s) = \\mathcal{L}\\{-t f(t)\\}$.\n\nLet us consider the transform of $\\cos(2t)$:\n$$ \\mathcal{L}\\{\\cos(2t)\\} = \\frac{s}{s^2 + 4} $$\nDifferentiating with respect to $s$:\n$$ \\frac{d}{ds} \\left( \\frac{s}{s^2 + 4} \\right) = \\frac{1 \\cdot (s^2 + 4) - s \\cdot (2s)}{(s^2 + 4)^2} = \\frac{4 - s^2}{(s^2 + 4)^2} $$\nUsing the property $\\mathcal{L}\\{t f(t)\\} = -F'(s)$, we have:\n$$ \\mathcal{L}\\{t \\cos(2t)\\} = - \\frac{4 - s^2}{(s^2 + 4)^2} = \\frac{s^2 - 4}{(s^2 + 4)^2} $$\n\nThis does not immediately match our target $Y(s)$. However, we can also look at the transform of $\\sin(2t)$:\n$$ \\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4} = \\frac{2(s^2 + 4)}{(s^2 + 4)^2} = \\frac{2s^2 + 8}{(s^2 + 4)^2} $$\n\nWe seek a linear combination of these known transforms that equals $\\frac{2}{(s^2 + 4)^2}$. Let us check the expression $\\sin(2t) - 2t \\cos(2t)$.\n$$ \\mathcal{L}\\{\\sin(2t) - 2t \\cos(2t)\\} = \\mathcal{L}\\{\\sin(2t)\\} - 2\\mathcal{L}\\{t \\cos(2t)\\} $$\n$$ = \\frac{2s^2 + 8}{(s^2 + 4)^2} - 2 \\left( \\frac{s^2 - 4}{(s^2 + 4)^2} \\right) $$\n$$ = \\frac{2s^2 + 8 - 2s^2 + 8}{(s^2 + 4)^2} $$\n$$ = \\frac{16}{(s^2 + 4)^2} $$\n\nWe have obtained a numerator of 16. Our target numerator is 2. Therefore, we must divide by 8:\n$$ \\mathcal{L}^{-1} \\left\\{ \\frac{2}{(s^2 + 4)^2} \\right\\} = \\frac{1}{8} \\mathcal{L}^{-1} \\left\\{ \\frac{16}{(s^2 + 4)^2} \\right\\} $$\n$$ y(t) = \\frac{1}{8} \\left( \\sin(2t) - 2t \\cos(2t) \\right) $$\n\n### Step 4: Final Solution and Verification\n\nSimplifying the expression:\n$$ y(t) = \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) $$\n\n**Verification:**\nLet us verify this solution satisfies the original IVP.\n1.  **Initial Conditions:**\n    *   $y(0) = \\frac{1}{8}(0) - 0 = 0$. (Check)\n    *   $y'(t) = \\frac{1}{8}(2\\cos(2t)) - \\frac{1}{4}(\\cos(2t) - 2t\\sin(2t)) = \\frac{1}{4}\\cos(2t) - \\frac{1}{4}\\cos(2t) + \\frac{1}{2}t\\sin(2t) = \\frac{1}{2}t\\sin(2t)$.\n    *   $y'(0) = 0$. (Check)\n\n2.  **Differential Equation:**\n    *   Calculate $y''(t)$:\n        $y''(t) = \\frac{d}{dt} \\left( \\frac{1}{2}t\\sin(2t) \\right) = \\frac{1}{2}(\\sin(2t) + 2t\\cos(2t)) = \\frac{1}{2}\\sin(2t) + t\\cos(2t)$.\n    *   Substitute into $y'' + 4y$:\n        $$ \\left( \\frac{1}{2}\\sin(2t) + t\\cos(2t) \\right) + 4 \\left( \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) \\right) $$\n        $$ = \\frac{1}{2}\\sin(2t) + t\\cos(2t) + \\frac{1}{2}\\sin(2t) - t\\cos(2t) $$\n        $$ = \\sin(2t) $$\n    The solution satisfies the differential equation.\n\n**Conclusion:**\nThe solution to the initial value problem is:\n$$ y(t) = \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t) $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of integral equations, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the specific domain within integral equations\nIntegral equations involve equations where the unknown function appears under an integral sign. A common type is the Fredholm integral equation of the second kind, given by $f(x) = g(x) + \\lambda \\int_{a}^{b} K(x, t)f(t)dt$, where $f(x)$ is the unknown function, $g(x)$ and $K(x, t)$ are known functions, and $\\lambda$ is a parameter.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider a specific case of the Fredholm integral equation of the second kind with a given kernel $K(x, t)$ and a function $g(x)$, and ask to solve for $f(x)$.\n\n## Step 4: Specify the problem\nLet's consider the integral equation $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$. This is a Fredholm integral equation of the second kind. We need to find $f(x)$.\n\n## Step 5: Provide the solution\nTo solve $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$, let's first simplify the integral.\n$f(x) = x + x\\int_{0}^{1} tf(t)dt + x\\int_{0}^{1} f(t)dt + \\int_{0}^{1} tf(t)dt$.\nLet $A = \\int_{0}^{1} f(t)dt$ and $B = \\int_{0}^{1} tf(t)dt$. Then, $f(x) = x + xB + xA + B = x(1 + A + B) + B$.\n\n## Step 6: Calculate A and B using the definitions\nSubstitute $f(x)$ from Step 5 into the definitions of $A$ and $B$.\n$A = \\int_{0}^{1} [t(1 + A + B) + B]dt = \\left[\\frac{t^2}{2}(1 + A + B) + Bt\\right]_{0}^{1} = \\frac{1}{2}(1 + A + B) + B$.\n$B = \\int_{0}^{1} t[t(1 + A + B) + B]dt = \\left[\\frac{t^3}{3}(1 + A + B) + \\frac{Bt^2}{2}\\right]_{0}^{1} = \\frac{1}{3}(1 + A + B) + \\frac{B}{2}$.\n\n## Step 7: Solve for A and B\nFrom Step 6, we have:\n1. $A = \\frac{1}{2}(1 + A + B) + B$\n2. $B = \\frac{1}{3}(1 + A + B) + \\frac{B}{2}$.\n\nSimplifying these equations:\n1. $A = \\frac{1}{2} + \\frac{A}{2} + \\frac{B}{2} + B$ implies $\\frac{A}{2} = \\frac{1}{2} + \\frac{3B}{2}$, so $A = 1 + 3B$.\n2. $B = \\frac{1}{3} + \\frac{A}{3} + \\frac{B}{3} + \\frac{B}{2}$ implies $B - \\frac{B}{2} - \\frac{B}{3} = \\frac{1}{3} + \\frac{A}{3}$, so $\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3}$.\n\n## Step 8: Continue solving for A and B\nFrom equation 2 in Step 7: $\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3}$, we get $B = 2 + 2A$.\nSubstitute $A = 1 + 3B$ from Step 7 into $B = 2 + 2A$:\n$B = 2 + 2(1 + 3B)$, so $B = 2 + 2 + 6B$, which simplifies to $B = 4 + 6B$, hence $-5B = 4$, and $B = -\\frac{4}{5}$.\n\n## Step 9: Find A using B\nSubstitute $B = -\\frac{4}{5}$ into $A = 1 + 3B$:\n$A = 1 + 3(-\\frac{4}{5}) = 1 - \\frac{12}{5} = -\\frac{7}{5}$.\n\n## Step 10: Substitute A and B back into f(x)\n$f(x) = x(1 + A + B) + B = x(1 - \\frac{7}{5} - \\frac{4}{5}) - \\frac{4}{5}$.\n$f(x) = x(1 - \\frac{11}{5}) - \\frac{4}{5} = x(-\\frac{6}{5}) - \\frac{4}{5}$.\n$f(x) = -\\frac{6}{5}x - \\frac{4}{5}$.\n\nThe final answer is: \n\nSolve the integral equation $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$ for $f(x)$.",
    "run_id": "31",
    "outer_attempt": 1,
    "topic_slug": "integral_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the integral equation for the function $f(x)$, we proceed by analyzing the structure of the equation and reducing it to a system of linear algebraic equations.\n\n### 1. Problem Statement\nWe are asked to find the function $f(x)$ that satisfies the Fredholm integral equation of the second kind:\n$$ f(x) = x + \\int_{0}^{1} (xt + x + t)f(t) \\, dt $$\n\n### 2. Decomposition of the Kernel\nThe kernel of the integral equation is $K(x, t) = xt + x + t$. Since this kernel is separable (degenerate), we can separate the terms depending on $x$ from those depending on $t$ within the integral.\n\nFirst, expand the integrand:\n$$ f(x) = x + \\int_{0}^{1} \\left[ x t f(t) + x f(t) + t f(t) \\right] \\, dt $$\n\nNext, use the linearity of the integral to factor out terms involving $x$:\n$$ f(x) = x + x \\int_{0}^{1} t f(t) \\, dt + x \\int_{0}^{1} f(t) \\, dt + \\int_{0}^{1} t f(t) \\, dt $$\n\nWe can group the terms involving $x$:\n$$ f(x) = x \\left( 1 + \\int_{0}^{1} t f(t) \\, dt + \\int_{0}^{1} f(t) \\, dt \\right) + \\int_{0}^{1} t f(t) \\, dt $$\n\n### 3. Reduction to Algebraic Equations\nThe definite integrals in the expression above result in constant values. Let us define two constants, $A$ and $B$, corresponding to these integrals:\n$$ A = \\int_{0}^{1} f(t) \\, dt $$\n$$ B = \\int_{0}^{1} t f(t) \\, dt $$\n\nSubstituting these constants into our expression for $f(x)$ yields a linear form for the solution:\n$$ f(x) = x(1 + B + A) + B $$\n\nLet $C = 1 + A + B$. Then, $f(x) = C x + B$. This confirms that the solution $f(x)$ must be a linear polynomial. To find the explicit function, we must determine the values of $A$ and $B$.\n\n### 4. System of Linear Equations\nWe substitute the form $f(t) = t(1 + A + B) + B$ back into the defining equations for $A$ and $B$.\n\n**Equation for A:**\n$$ A = \\int_{0}^{1} f(t) \\, dt = \\int_{0}^{1} \\left[ t(1 + A + B) + B \\right] \\, dt $$\nCompute the integrals:\n$$ \\int_{0}^{1} t \\, dt = \\left[ \\frac{t^2}{2} \\right]_0^1 = \\frac{1}{2}, \\quad \\int_{0}^{1} 1 \\, dt = \\left[ t \\right]_0^1 = 1 $$\nSubstitute these values:\n$$ A = (1 + A + B)\\left(\\frac{1}{2}\\right) + B(1) $$\n$$ A = \\frac{1}{2} + \\frac{1}{2}A + \\frac{1}{2}B + B $$\n$$ A = \\frac{1}{2} + \\frac{1}{2}A + \\frac{3}{2}B $$\nMultiply by 2 to clear the denominators:\n$$ 2A = 1 + A + 3B $$\n$$ A - 3B = 1 \\quad \\text{--- (Eq. 1)} $$\n\n**Equation for B:**\n$$ B = \\int_{0}^{1} t f(t) \\, dt = \\int_{0}^{1} t \\left[ t(1 + A + B) + B \\right] \\, dt $$\n$$ B = (1 + A + B) \\int_{0}^{1} t^2 \\, dt + B \\int_{0}^{1} t \\, dt $$\nCompute the integrals:\n$$ \\int_{0}^{1} t^2 \\, dt = \\left[ \\frac{t^3}{3} \\right]_0^1 = \\frac{1}{3}, \\quad \\int_{0}^{1} t \\, dt = \\frac{1}{2} $$\nSubstitute these values:\n$$ B = (1 + A + B)\\left(\\frac{1}{3}\\right) + B\\left(\\frac{1}{2}\\right) $$\n$$ B = \\frac{1}{3} + \\frac{1}{3}A + \\frac{1}{3}B + \\frac{1}{2}B $$\nMultiply by 6 to clear the denominators:\n$$ 6B = 2 + 2A + 2B + 3B $$\n$$ 6B = 2 + 2A + 5B $$\n$$ B - 2A = 2 \\quad \\text{--- (Eq. 2)} $$\n\n### 5. Solving the System\nWe have the system:\n1. $A - 3B = 1$\n2. $-2A + B = 2$\n\nFrom (1), we have $A = 1 + 3B$. Substitute this into (2):\n$$ -2(1 + 3B) + B = 2 $$\n$$ -2 - 6B + B = 2 $$\n$$ -5B = 4 $$\n$$ B = -\\frac{4}{5} $$\n\nNow, substitute $B$ back into the expression for $A$:\n$$ A = 1 + 3\\left(-\\frac{4}{5}\\right) $$\n$$ A = 1 - \\frac{12}{5} $$\n$$ A = -\\frac{7}{5} $$\n\nSince the determinant of the coefficient matrix $\\begin{vmatrix} 1 & -3 \\\\ -2 & 1 \\end{vmatrix} = 1 - 6 = -5 \\neq 0$, this solution is unique.\n\n### 6. Constructing the Final Function\nRecall the expression for $f(x)$:\n$$ f(x) = x(1 + A + B) + B $$\nSubstitute the values $A = -\\frac{7}{5}$ and $B = -\\frac{4}{5}$:\n$$ 1 + A + B = 1 + \\left(-\\frac{7}{5}\\right) + \\left(-\\frac{4}{5}\\right) = 1 - \\frac{11}{5} = -\\frac{6}{5} $$\nThus:\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$\n\n### 7. Verification\nWe verify the solution by substituting $f(x) = -\\frac{6}{5}x - \\frac{4}{5}$ into the original equation.\n\n**Left Hand Side (LHS):**\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$\n\n**Right Hand Side (RHS):**\n$$ RHS = x + \\int_{0}^{1} (xt + x + t) \\left( -\\frac{6}{5}t - \\frac{4}{5} \\right) \\, dt $$\nFactor out $-\\frac{1}{5}$:\n$$ RHS = x - \\frac{1}{5} \\int_{0}^{1} (xt + x + t)(6t + 4) \\, dt $$\nExpand the integrand $(xt + x + t)(6t + 4)$:\n$$ = xt(6t + 4) + x(6t + 4) + t(6t + 4) $$\n$$ = 6xt^2 + 4xt + 6xt + 4x + 6t^2 + 4t $$\n$$ = 6xt^2 + 10xt + 4x + 6t^2 + 4t $$\nIntegrate term by term with respect to $t$:\n$$ \\int_{0}^{1} (6xt^2 + 10xt + 4x + 6t^2 + 4t) \\, dt = \\left[ 2xt^3 + 5xt^2 + 4xt + 2t^3 + 2t^2 \\right]_{0}^{1} $$\n$$ = (2x(1) + 5x(1) + 4x(1) + 2(1) + 2(1)) - 0 $$\n$$ = 11x + 4 $$\nSubstitute back into the RHS expression:\n$$ RHS = x - \\frac{1}{5}(11x + 4) $$\n$$ RHS = x - \\frac{11}{5}x - \\frac{4}{5} $$\n$$ RHS = -\\frac{6}{5}x - \\frac{4}{5} $$\n\nSince LHS = RHS, the solution is correct.\n\n### Final Answer\nThe solution to the integral equation is:\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$",
        "raw_answer": "To solve the integral equation for the function $f(x)$, we proceed by analyzing the structure of the equation and reducing it to a system of linear algebraic equations.\n\n### 1. Problem Statement\nWe are asked to find the function $f(x)$ that satisfies the Fredholm integral equation of the second kind:\n$$ f(x) = x + \\int_{0}^{1} (xt + x + t)f(t) \\, dt $$\n\n### 2. Decomposition of the Kernel\nThe kernel of the integral equation is $K(x, t) = xt + x + t$. Since this kernel is separable (degenerate), we can separate the terms depending on $x$ from those depending on $t$ within the integral.\n\nFirst, expand the integrand:\n$$ f(x) = x + \\int_{0}^{1} \\left[ x t f(t) + x f(t) + t f(t) \\right] \\, dt $$\n\nNext, use the linearity of the integral to factor out terms involving $x$:\n$$ f(x) = x + x \\int_{0}^{1} t f(t) \\, dt + x \\int_{0}^{1} f(t) \\, dt + \\int_{0}^{1} t f(t) \\, dt $$\n\nWe can group the terms involving $x$:\n$$ f(x) = x \\left( 1 + \\int_{0}^{1} t f(t) \\, dt + \\int_{0}^{1} f(t) \\, dt \\right) + \\int_{0}^{1} t f(t) \\, dt $$\n\n### 3. Reduction to Algebraic Equations\nThe definite integrals in the expression above result in constant values. Let us define two constants, $A$ and $B$, corresponding to these integrals:\n$$ A = \\int_{0}^{1} f(t) \\, dt $$\n$$ B = \\int_{0}^{1} t f(t) \\, dt $$\n\nSubstituting these constants into our expression for $f(x)$ yields a linear form for the solution:\n$$ f(x) = x(1 + B + A) + B $$\n\nLet $C = 1 + A + B$. Then, $f(x) = C x + B$. This confirms that the solution $f(x)$ must be a linear polynomial. To find the explicit function, we must determine the values of $A$ and $B$.\n\n### 4. System of Linear Equations\nWe substitute the form $f(t) = t(1 + A + B) + B$ back into the defining equations for $A$ and $B$.\n\n**Equation for A:**\n$$ A = \\int_{0}^{1} f(t) \\, dt = \\int_{0}^{1} \\left[ t(1 + A + B) + B \\right] \\, dt $$\nCompute the integrals:\n$$ \\int_{0}^{1} t \\, dt = \\left[ \\frac{t^2}{2} \\right]_0^1 = \\frac{1}{2}, \\quad \\int_{0}^{1} 1 \\, dt = \\left[ t \\right]_0^1 = 1 $$\nSubstitute these values:\n$$ A = (1 + A + B)\\left(\\frac{1}{2}\\right) + B(1) $$\n$$ A = \\frac{1}{2} + \\frac{1}{2}A + \\frac{1}{2}B + B $$\n$$ A = \\frac{1}{2} + \\frac{1}{2}A + \\frac{3}{2}B $$\nMultiply by 2 to clear the denominators:\n$$ 2A = 1 + A + 3B $$\n$$ A - 3B = 1 \\quad \\text{--- (Eq. 1)} $$\n\n**Equation for B:**\n$$ B = \\int_{0}^{1} t f(t) \\, dt = \\int_{0}^{1} t \\left[ t(1 + A + B) + B \\right] \\, dt $$\n$$ B = (1 + A + B) \\int_{0}^{1} t^2 \\, dt + B \\int_{0}^{1} t \\, dt $$\nCompute the integrals:\n$$ \\int_{0}^{1} t^2 \\, dt = \\left[ \\frac{t^3}{3} \\right]_0^1 = \\frac{1}{3}, \\quad \\int_{0}^{1} t \\, dt = \\frac{1}{2} $$\nSubstitute these values:\n$$ B = (1 + A + B)\\left(\\frac{1}{3}\\right) + B\\left(\\frac{1}{2}\\right) $$\n$$ B = \\frac{1}{3} + \\frac{1}{3}A + \\frac{1}{3}B + \\frac{1}{2}B $$\nMultiply by 6 to clear the denominators:\n$$ 6B = 2 + 2A + 2B + 3B $$\n$$ 6B = 2 + 2A + 5B $$\n$$ B - 2A = 2 \\quad \\text{--- (Eq. 2)} $$\n\n### 5. Solving the System\nWe have the system:\n1. $A - 3B = 1$\n2. $-2A + B = 2$\n\nFrom (1), we have $A = 1 + 3B$. Substitute this into (2):\n$$ -2(1 + 3B) + B = 2 $$\n$$ -2 - 6B + B = 2 $$\n$$ -5B = 4 $$\n$$ B = -\\frac{4}{5} $$\n\nNow, substitute $B$ back into the expression for $A$:\n$$ A = 1 + 3\\left(-\\frac{4}{5}\\right) $$\n$$ A = 1 - \\frac{12}{5} $$\n$$ A = -\\frac{7}{5} $$\n\nSince the determinant of the coefficient matrix $\\begin{vmatrix} 1 & -3 \\\\ -2 & 1 \\end{vmatrix} = 1 - 6 = -5 \\neq 0$, this solution is unique.\n\n### 6. Constructing the Final Function\nRecall the expression for $f(x)$:\n$$ f(x) = x(1 + A + B) + B $$\nSubstitute the values $A = -\\frac{7}{5}$ and $B = -\\frac{4}{5}$:\n$$ 1 + A + B = 1 + \\left(-\\frac{7}{5}\\right) + \\left(-\\frac{4}{5}\\right) = 1 - \\frac{11}{5} = -\\frac{6}{5} $$\nThus:\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$\n\n### 7. Verification\nWe verify the solution by substituting $f(x) = -\\frac{6}{5}x - \\frac{4}{5}$ into the original equation.\n\n**Left Hand Side (LHS):**\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$\n\n**Right Hand Side (RHS):**\n$$ RHS = x + \\int_{0}^{1} (xt + x + t) \\left( -\\frac{6}{5}t - \\frac{4}{5} \\right) \\, dt $$\nFactor out $-\\frac{1}{5}$:\n$$ RHS = x - \\frac{1}{5} \\int_{0}^{1} (xt + x + t)(6t + 4) \\, dt $$\nExpand the integrand $(xt + x + t)(6t + 4)$:\n$$ = xt(6t + 4) + x(6t + 4) + t(6t + 4) $$\n$$ = 6xt^2 + 4xt + 6xt + 4x + 6t^2 + 4t $$\n$$ = 6xt^2 + 10xt + 4x + 6t^2 + 4t $$\nIntegrate term by term with respect to $t$:\n$$ \\int_{0}^{1} (6xt^2 + 10xt + 4x + 6t^2 + 4t) \\, dt = \\left[ 2xt^3 + 5xt^2 + 4xt + 2t^3 + 2t^2 \\right]_{0}^{1} $$\n$$ = (2x(1) + 5x(1) + 4x(1) + 2(1) + 2(1)) - 0 $$\n$$ = 11x + 4 $$\nSubstitute back into the RHS expression:\n$$ RHS = x - \\frac{1}{5}(11x + 4) $$\n$$ RHS = x - \\frac{11}{5}x - \\frac{4}{5} $$\n$$ RHS = -\\frac{6}{5}x - \\frac{4}{5} $$\n\nSince LHS = RHS, the solution is correct.\n\n### Final Answer\nThe solution to the integral equation is:\n$$ f(x) = -\\frac{6}{5}x - \\frac{4}{5} $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $H$ be a Hilbert space and $T: H \\to H$ be a bounded linear operator. Suppose that $T$ is self-adjoint and satisfies the condition $\\|T\\| \\leq 1$. Prove that the operator $I - T^2$ is positive, where $I$ denotes the identity operator on $H$.",
    "run_id": "32",
    "outer_attempt": 1,
    "topic_slug": "functional_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the operator $I - T^2$ is positive, we must verify two properties:\n1.  $I - T^2$ is a self-adjoint operator.\n2.  $\\langle (I - T^2)x, x \\rangle \\geq 0$ for all $x \\in H$.\n\n### 1. Verification of Self-Adjointness\n\nLet $T^*$ denote the adjoint of the operator $T$. We are given that $T$ is self-adjoint, which means $T = T^*$.\nWe determine the adjoint of $I - T^2$ using the properties of the adjoint operation (linearity and $(AB)^* = B^* A^*$):\n\n$$\n(I - T^2)^* = I^* - (T^2)^* = I - (T \\cdot T)^* = I - T^* T^*.\n$$\n\nSince $T$ is self-adjoint ($T^* = T$), we substitute $T$ for $T^*$:\n\n$$\n(I - T^2)^* = I - T \\cdot T = I - T^2.\n$$\n\nThus, the operator $I - T^2$ is self-adjoint.\n\n### 2. Verification of Non-Negativity\n\nWe must show that the quadratic form associated with the operator is non-negative. Let $x$ be an arbitrary vector in the Hilbert space $H$. We compute the inner product $\\langle (I - T^2)x, x \\rangle$:\n\n$$\n\\langle (I - T^2)x, x \\rangle = \\langle Ix - T^2x, x \\rangle = \\langle Ix, x \\rangle - \\langle T^2x, x \\rangle.\n$$\n\nUsing the definition of the identity operator ($Ix = x$) and the inner product norm relation ($\\langle x, x \\rangle = \\|x\\|^2$):\n\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\langle T(Tx), x \\rangle.\n$$\n\nUsing the definition of the adjoint operator ($\\langle Ay, z \\rangle = \\langle y, A^*z \\rangle$) on the term $\\langle T(Tx), x \\rangle$:\n\n$$\n\\langle T(Tx), x \\rangle = \\langle Tx, T^*x \\rangle.\n$$\n\nSince $T$ is self-adjoint ($T^* = T$):\n\n$$\n\\langle Tx, T^*x \\rangle = \\langle Tx, Tx \\rangle = \\|Tx\\|^2.\n$$\n\nSubstituting this back into our expression for the operator quadratic form:\n\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2.\n$$\n\n### 3. Application of the Norm Bound\n\nWe are given the condition $\\|T\\| \\leq 1$. By the definition of the operator norm, for any $x \\in H$:\n\n$$\n\\|Tx\\| \\leq \\|T\\| \\|x\\|.\n$$\n\nSince $\\|T\\| \\leq 1$, it follows that:\n\n$$\n\\|Tx\\| \\leq 1 \\cdot \\|x\\| = \\|x\\|.\n$$\n\nSince norms are non-negative, we can square both sides of the inequality:\n\n$$\n\\|Tx\\|^2 \\leq \\|x\\|^2.\n$$\n\nRearranging this inequality gives:\n\n$$\n\\|x\\|^2 - \\|Tx\\|^2 \\geq 0.\n$$\n\n### Conclusion\n\nCombining the results from steps 2 and 3, we have shown that for all $x \\in H$:\n\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2 \\geq 0.\n$$\n\nSince $I - T^2$ is self-adjoint and satisfies $\\langle (I - T^2)x, x \\rangle \\geq 0$ for all $x \\in H$, the operator $I - T^2$ is positive.",
        "raw_answer": "To prove that the operator $I - T^2$ is positive, we must verify two properties:\n1.  $I - T^2$ is a self-adjoint operator.\n2.  $\\langle (I - T^2)x, x \\rangle \\geq 0$ for all $x \\in H$.\n\n### 1. Verification of Self-Adjointness\n\nLet $T^*$ denote the adjoint of the operator $T$. We are given that $T$ is self-adjoint, which means $T = T^*$.\nWe determine the adjoint of $I - T^2$ using the properties of the adjoint operation (linearity and $(AB)^* = B^* A^*$):\n\n$$\n(I - T^2)^* = I^* - (T^2)^* = I - (T \\cdot T)^* = I - T^* T^*.\n$$\n\nSince $T$ is self-adjoint ($T^* = T$), we substitute $T$ for $T^*$:\n\n$$\n(I - T^2)^* = I - T \\cdot T = I - T^2.\n$$\n\nThus, the operator $I - T^2$ is self-adjoint.\n\n### 2. Verification of Non-Negativity\n\nWe must show that the quadratic form associated with the operator is non-negative. Let $x$ be an arbitrary vector in the Hilbert space $H$. We compute the inner product $\\langle (I - T^2)x, x \\rangle$:\n\n$$\n\\langle (I - T^2)x, x \\rangle = \\langle Ix - T^2x, x \\rangle = \\langle Ix, x \\rangle - \\langle T^2x, x \\rangle.\n$$\n\nUsing the definition of the identity operator ($Ix = x$) and the inner product norm relation ($\\langle x, x \\rangle = \\|x\\|^2$):\n\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\langle T(Tx), x \\rangle.\n$$\n\nUsing the definition of the adjoint operator ($\\langle Ay, z \\rangle = \\langle y, A^*z \\rangle$) on the term $\\langle T(Tx), x \\rangle$:\n\n$$\n\\langle T(Tx), x \\rangle = \\langle Tx, T^*x \\rangle.\n$$\n\nSince $T$ is self-adjoint ($T^* = T$):\n\n$$\n\\langle Tx, T^*x \\rangle = \\langle Tx, Tx \\rangle = \\|Tx\\|^2.\n$$\n\nSubstituting this back into our expression for the operator quadratic form:\n\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2.\n$$\n\n### 3. Application of the Norm Bound\n\nWe are given the condition $\\|T\\| \\leq 1$. By the definition of the operator norm, for any $x \\in H$:\n\n$$\n\\|Tx\\| \\leq \\|T\\| \\|x\\|.\n$$\n\nSince $\\|T\\| \\leq 1$, it follows that:\n\n$$\n\\|Tx\\| \\leq 1 \\cdot \\|x\\| = \\|x\\|.\n$$\n\nSince norms are non-negative, we can square both sides of the inequality:\n\n$$\n\\|Tx\\|^2 \\leq \\|x\\|^2.\n$$\n\nRearranging this inequality gives:\n\n$$\n\\|x\\|^2 - \\|Tx\\|^2 \\geq 0.\n$$\n\n### Conclusion\n\nCombining the results from steps 2 and 3, we have shown that for all $x \\in H$:\n\n$$\n\\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2 \\geq 0.\n$$\n\nSince $I - T^2$ is self-adjoint and satisfies $\\langle (I - T^2)x, x \\rangle \\geq 0$ for all $x \\in H$, the operator $I - T^2$ is positive.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $T: L^2[0,1] \\to L^2[0,1]$ be defined by $Tf(x) = \\int_{0}^{x} f(t) dt$. Prove that $T$ is compact and find its spectrum.",
    "run_id": "33",
    "outer_attempt": 1,
    "topic_slug": "operator_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the problem regarding the Volterra operator $T: L^2[0,1] \\to L^2[0,1]$ defined by \n$$ (Tf)(x) = \\int_{0}^{x} f(t) \\, dt, $$\nwe proceed in two parts: first proving that $T$ is a compact operator, and then determining its spectrum $\\sigma(T)$. We treat $L^2[0,1]$ as a complex Hilbert space.\n\n---\n\n### Part 1: Proof of Compactness\n\nWe prove that $T$ is compact by showing it is a Hilbert-Schmidt operator.\n\n**Step 1: Express $T$ as an Integral Operator**\nThe operator $T$ can be written in the form of a Fredholm integral operator:\n$$ (Tf)(x) = \\int_{0}^{1} K(x,t) f(t) \\, dt, $$\nwhere the kernel $K(x,t)$ is defined by the characteristic function of the region $0 \\le t \\le x \\le 1$:\n$$ K(x,t) = \\begin{cases} \n1 & \\text{if } 0 \\le t \\le x, \\\\\n0 & \\text{if } x < t \\le 1.\n\\end{cases} $$\n\n**Step 2: Verify the Hilbert-Schmidt Condition**\nA linear integral operator on $L^2[0,1]$ is a Hilbert-Schmidt operator if its kernel $K$ belongs to $L^2([0,1] \\times [0,1])$. We compute the $L^2$ norm of the kernel:\n$$ \\|K\\|_{L^2}^2 = \\int_{0}^{1} \\int_{0}^{1} |K(x,t)|^2 \\, dt \\, dx. $$\nSubstituting the definition of $K(x,t)$:\n$$ \\|K\\|_{L^2}^2 = \\int_{0}^{1} \\left( \\int_{0}^{x} 1^2 \\, dt \\right) dx = \\int_{0}^{1} [t]_{0}^{x} \\, dx = \\int_{0}^{1} x \\, dx. $$\nEvaluating the final integral:\n$$ \\int_{0}^{1} x \\, dx = \\left[ \\frac{1}{2}x^2 \\right]_{0}^{1} = \\frac{1}{2}. $$\nSince $\\|K\\|_{L^2}^2 = \\frac{1}{2} < \\infty$, the kernel $K$ is square-integrable.\n\n**Conclusion for Part 1**\nEvery Hilbert-Schmidt operator on a separable Hilbert space is a compact operator. Therefore, $T$ is compact.\n\n---\n\n### Part 2: Determination of the Spectrum\n\nLet $\\sigma(T)$ denote the spectrum of $T$. Since $T$ is a compact operator on an infinite-dimensional Banach space, the Riesz-Schauder theorem applies. This theorem states:\n1. $0 \\in \\sigma(T)$.\n2. The non-zero elements of the spectrum, $\\sigma(T) \\setminus \\{0\\}$, consist entirely of eigenvalues (the point spectrum $\\sigma_p(T)$).\n\nThus, to find $\\sigma(T)$, we must determine if $0$ is an eigenvalue and find all non-zero eigenvalues.\n\n**Step 1: Check if $\\lambda = 0$ is an eigenvalue**\nWe check for non-trivial solutions to $Tf = 0$:\n$$ \\int_{0}^{x} f(t) \\, dt = 0 \\quad \\text{for almost every } x \\in [0,1]. $$\nSince $f \\in L^2[0,1] \\subset L^1[0,1]$, the integral $F(x) = \\int_0^x f(t) dt$ is absolutely continuous. Differentiating both sides with respect to $x$ (using the Lebesgue differentiation theorem) gives:\n$$ f(x) = 0 \\quad \\text{almost everywhere}. $$\nThus, the kernel of $T$ is trivial ($\\text{Ker}(T) = \\{0\\}$), so $\\lambda = 0$ is **not** an eigenvalue.\nHowever, as noted above, $0 \\in \\sigma(T)$ because $T$ is a compact operator on an infinite-dimensional space (implying $T$ cannot be boundedly invertible).\n\n**Step 2: Check for eigenvalues $\\lambda \\neq 0$**\nSuppose there exists $\\lambda \\in \\mathbb{C} \\setminus \\{0\\}$ and a non-zero function $f \\in L^2[0,1]$ such that $Tf = \\lambda f$.\n$$ \\int_{0}^{x} f(t) \\, dt = \\lambda f(x). \\quad (*)$$\n\n*Regularity Argument:*\nSince $f \\in L^2[0,1]$, the left-hand side of $(*)$ is an absolutely continuous function of $x$. Therefore, $\\lambda f(x)$ is continuous. Since $\\lambda \\neq 0$, $f(x)$ must be continuous.\nSince $f$ is continuous, the integrand in the left-hand side is continuous, making the integral continuously differentiable ($C^1$). Therefore, $f$ must be a $C^1$ function.\n\n*Differential Equation:*\nWe can now differentiate $(*)$ with respect to $x$:\n$$ \\frac{d}{dx} \\int_{0}^{x} f(t) \\, dt = \\frac{d}{dx} (\\lambda f(x)) $$\n$$ f(x) = \\lambda f'(x). $$\nThis can be rewritten as a first-order linear ordinary differential equation:\n$$ f'(x) - \\frac{1}{\\lambda} f(x) = 0. $$\nThe general solution is:\n$$ f(x) = C e^{x/\\lambda}, $$\nwhere $C$ is an arbitrary constant.\n\n*Boundary Condition:*\nWe must ensure the solution satisfies the original integral equation $(*)$ at a specific point, typically $x=0$, to determine $C$.\nEvaluating $(*)$ at $x=0$:\n$$ \\text{LHS} = \\int_{0}^{0} f(t) \\, dt = 0, $$\n$$ \\text{RHS} = \\lambda f(0). $$\nSince $\\lambda \\neq 0$, we must have $f(0) = 0$.\n\nSubstituting the general solution into this boundary condition:\n$$ f(0) = C e^{0/\\lambda} = C \\cdot 1 = C. $$\nThus, $C = 0$.\n\nThis implies $f(x) = 0$ for all $x \\in [0,1]$. Since an eigenvector must be non-zero, there are no eigenvalues $\\lambda \\neq 0$.\n\n**Conclusion for Part 2**\nThe point spectrum of $T$ is empty ($\\sigma_p(T) = \\emptyset$). Since $T$ is compact and the space is infinite-dimensional, the spectrum contains $0$ but no other values.\n\n### Final Answer\n\n1. The operator $T$ is **compact** because it is a Hilbert-Schmidt operator with kernel norm $\\|K\\|_{L^2} = 1/\\sqrt{2}$.\n2. The spectrum of $T$ is **$\\sigma(T) = \\{0\\}$**.",
        "raw_answer": "To solve the problem regarding the Volterra operator $T: L^2[0,1] \\to L^2[0,1]$ defined by \n$$ (Tf)(x) = \\int_{0}^{x} f(t) \\, dt, $$\nwe proceed in two parts: first proving that $T$ is a compact operator, and then determining its spectrum $\\sigma(T)$. We treat $L^2[0,1]$ as a complex Hilbert space.\n\n---\n\n### Part 1: Proof of Compactness\n\nWe prove that $T$ is compact by showing it is a Hilbert-Schmidt operator.\n\n**Step 1: Express $T$ as an Integral Operator**\nThe operator $T$ can be written in the form of a Fredholm integral operator:\n$$ (Tf)(x) = \\int_{0}^{1} K(x,t) f(t) \\, dt, $$\nwhere the kernel $K(x,t)$ is defined by the characteristic function of the region $0 \\le t \\le x \\le 1$:\n$$ K(x,t) = \\begin{cases} \n1 & \\text{if } 0 \\le t \\le x, \\\\\n0 & \\text{if } x < t \\le 1.\n\\end{cases} $$\n\n**Step 2: Verify the Hilbert-Schmidt Condition**\nA linear integral operator on $L^2[0,1]$ is a Hilbert-Schmidt operator if its kernel $K$ belongs to $L^2([0,1] \\times [0,1])$. We compute the $L^2$ norm of the kernel:\n$$ \\|K\\|_{L^2}^2 = \\int_{0}^{1} \\int_{0}^{1} |K(x,t)|^2 \\, dt \\, dx. $$\nSubstituting the definition of $K(x,t)$:\n$$ \\|K\\|_{L^2}^2 = \\int_{0}^{1} \\left( \\int_{0}^{x} 1^2 \\, dt \\right) dx = \\int_{0}^{1} [t]_{0}^{x} \\, dx = \\int_{0}^{1} x \\, dx. $$\nEvaluating the final integral:\n$$ \\int_{0}^{1} x \\, dx = \\left[ \\frac{1}{2}x^2 \\right]_{0}^{1} = \\frac{1}{2}. $$\nSince $\\|K\\|_{L^2}^2 = \\frac{1}{2} < \\infty$, the kernel $K$ is square-integrable.\n\n**Conclusion for Part 1**\nEvery Hilbert-Schmidt operator on a separable Hilbert space is a compact operator. Therefore, $T$ is compact.\n\n---\n\n### Part 2: Determination of the Spectrum\n\nLet $\\sigma(T)$ denote the spectrum of $T$. Since $T$ is a compact operator on an infinite-dimensional Banach space, the Riesz-Schauder theorem applies. This theorem states:\n1. $0 \\in \\sigma(T)$.\n2. The non-zero elements of the spectrum, $\\sigma(T) \\setminus \\{0\\}$, consist entirely of eigenvalues (the point spectrum $\\sigma_p(T)$).\n\nThus, to find $\\sigma(T)$, we must determine if $0$ is an eigenvalue and find all non-zero eigenvalues.\n\n**Step 1: Check if $\\lambda = 0$ is an eigenvalue**\nWe check for non-trivial solutions to $Tf = 0$:\n$$ \\int_{0}^{x} f(t) \\, dt = 0 \\quad \\text{for almost every } x \\in [0,1]. $$\nSince $f \\in L^2[0,1] \\subset L^1[0,1]$, the integral $F(x) = \\int_0^x f(t) dt$ is absolutely continuous. Differentiating both sides with respect to $x$ (using the Lebesgue differentiation theorem) gives:\n$$ f(x) = 0 \\quad \\text{almost everywhere}. $$\nThus, the kernel of $T$ is trivial ($\\text{Ker}(T) = \\{0\\}$), so $\\lambda = 0$ is **not** an eigenvalue.\nHowever, as noted above, $0 \\in \\sigma(T)$ because $T$ is a compact operator on an infinite-dimensional space (implying $T$ cannot be boundedly invertible).\n\n**Step 2: Check for eigenvalues $\\lambda \\neq 0$**\nSuppose there exists $\\lambda \\in \\mathbb{C} \\setminus \\{0\\}$ and a non-zero function $f \\in L^2[0,1]$ such that $Tf = \\lambda f$.\n$$ \\int_{0}^{x} f(t) \\, dt = \\lambda f(x). \\quad (*)$$\n\n*Regularity Argument:*\nSince $f \\in L^2[0,1]$, the left-hand side of $(*)$ is an absolutely continuous function of $x$. Therefore, $\\lambda f(x)$ is continuous. Since $\\lambda \\neq 0$, $f(x)$ must be continuous.\nSince $f$ is continuous, the integrand in the left-hand side is continuous, making the integral continuously differentiable ($C^1$). Therefore, $f$ must be a $C^1$ function.\n\n*Differential Equation:*\nWe can now differentiate $(*)$ with respect to $x$:\n$$ \\frac{d}{dx} \\int_{0}^{x} f(t) \\, dt = \\frac{d}{dx} (\\lambda f(x)) $$\n$$ f(x) = \\lambda f'(x). $$\nThis can be rewritten as a first-order linear ordinary differential equation:\n$$ f'(x) - \\frac{1}{\\lambda} f(x) = 0. $$\nThe general solution is:\n$$ f(x) = C e^{x/\\lambda}, $$\nwhere $C$ is an arbitrary constant.\n\n*Boundary Condition:*\nWe must ensure the solution satisfies the original integral equation $(*)$ at a specific point, typically $x=0$, to determine $C$.\nEvaluating $(*)$ at $x=0$:\n$$ \\text{LHS} = \\int_{0}^{0} f(t) \\, dt = 0, $$\n$$ \\text{RHS} = \\lambda f(0). $$\nSince $\\lambda \\neq 0$, we must have $f(0) = 0$.\n\nSubstituting the general solution into this boundary condition:\n$$ f(0) = C e^{0/\\lambda} = C \\cdot 1 = C. $$\nThus, $C = 0$.\n\nThis implies $f(x) = 0$ for all $x \\in [0,1]$. Since an eigenvector must be non-zero, there are no eigenvalues $\\lambda \\neq 0$.\n\n**Conclusion for Part 2**\nThe point spectrum of $T$ is empty ($\\sigma_p(T) = \\emptyset$). Since $T$ is compact and the space is infinite-dimensional, the spectrum contains $0$ but no other values.\n\n### Final Answer\n\n1. The operator $T$ is **compact** because it is a Hilbert-Schmidt operator with kernel norm $\\|K\\|_{L^2} = 1/\\sqrt{2}$.\n2. The spectrum of $T$ is **$\\sigma(T) = \\{0\\}$**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of calculus of variations and optimal control, along with a complete solution. The problem should be solvable, verifiable, and adhere to the specified format.",
    "run_id": "34",
    "outer_attempt": 1,
    "topic_slug": "calculus_of_variations_and_optimization",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is a challenging mathematical problem in the domain of **Calculus of Variations**, followed by a complete and rigorous solution.\n\n***\n\n### **Problem Statement**\n\nFind the function $y(x)$ continuously differentiable on the interval $[0, 1]$ that minimizes the functional:\n$$ J[y] = \\int_{0}^{1} \\left( (y'(x))^2 + y(x)^2 \\right) \\, dx $$\nsubject to the boundary conditions:\n$$ y(0) = 0, \\quad y(1) = 0 $$\nand the isoperimetric constraint:\n$$ \\int_{0}^{1} y(x) \\, dx = 1 $$\nProvide the explicit analytical expression for the optimal curve $y(x)$ and calculate the minimum value of the functional $J[y]$.\n\n***\n\n### **Solution**\n\nTo solve this constrained optimization problem, we employ the method of Lagrange multipliers in the calculus of variations.\n\n#### **1. Formulation of the Auxiliary Functional**\n\nWe introduce a Lagrange multiplier constant $\\lambda$ associated with the integral constraint. We define the auxiliary functional $L[y]$:\n$$ L[y] = \\int_{0}^{1} \\left( (y')^2 + y^2 \\right) \\, dx + \\lambda \\left( \\int_{0}^{1} y \\, dx - 1 \\right) $$\nThis can be rewritten as maximizing/minimizing the integral of the auxiliary Lagrangian $\\mathcal{F}$:\n$$ L[y] = \\int_{0}^{1} \\mathcal{F}(x, y, y') \\, dx - \\lambda $$\nwhere $\\mathcal{F}(x, y, y') = (y')^2 + y^2 + \\lambda y$.\n\n#### **2. The Euler-Lagrange Equation**\n\nA necessary condition for $y(x)$ to be an extremal is that it satisfies the Euler-Lagrange equation:\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y} - \\frac{d}{dx} \\left( \\frac{\\partial \\mathcal{F}}{\\partial y'} \\right) = 0 $$\nCalculating the partial derivatives:\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y} = 2y + \\lambda $$\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y'} = 2y' $$\nSubstitute these into the equation:\n$$ (2y + \\lambda) - \\frac{d}{dx}(2y') = 0 $$\n$$ 2y + \\lambda - 2y'' = 0 $$\nDividing by 2, we obtain the non-homogeneous linear differential equation:\n$$ y'' - y = \\frac{\\lambda}{2} $$\n\n#### **3. Solving the Differential Equation**\n\nThe general solution to the differential equation $y'' - y = \\frac{\\lambda}{2}$ consists of the homogeneous solution $y_h$ and a particular solution $y_p$.\n\n**Homogeneous solution** ($y'' - y = 0$):\n$$ y_h(x) = c_1 \\cosh(x) + c_2 \\sinh(x) $$\n\n**Particular solution**:\nSince the right-hand side is a constant, we posit a constant particular solution $y_p = A$.\n$$ 0 - A = \\frac{\\lambda}{2} \\implies A = -\\frac{\\lambda}{2} $$\n\nThus, the general solution is:\n$$ y(x) = c_1 \\cosh(x) + c_2 \\sinh(x) - \\frac{\\lambda}{2} $$\n\n#### **4. Applying Boundary Conditions**\n\nWe apply the boundary conditions $y(0)=0$ and $y(1)=0$ to determine constants $c_1$ and $c_2$ in terms of $\\lambda$.\n\n**At $x=0$:**\n$$ y(0) = c_1 \\cosh(0) + c_2 \\sinh(0) - \\frac{\\lambda}{2} = 0 $$\n$$ c_1 (1) + 0 - \\frac{\\lambda}{2} = 0 \\implies c_1 = \\frac{\\lambda}{2} $$\n\n**At $x=1$:**\n$$ y(1) = c_1 \\cosh(1) + c_2 \\sinh(1) - \\frac{\\lambda}{2} = 0 $$\nSubstitute $c_1 = \\frac{\\lambda}{2}$:\n$$ \\frac{\\lambda}{2} \\cosh(1) + c_2 \\sinh(1) - \\frac{\\lambda}{2} = 0 $$\n$$ c_2 \\sinh(1) = \\frac{\\lambda}{2} (1 - \\cosh(1)) $$\n$$ c_2 = \\frac{\\lambda}{2} \\frac{1 - \\cosh(1)}{\\sinh(1)} $$\n\nUsing the half-angle hyperbolic identities $\\cosh(x) - 1 = 2\\sinh^2(x/2)$ and $\\sinh(x) = 2\\sinh(x/2)\\cosh(x/2)$:\n$$ \\frac{1 - \\cosh(1)}{\\sinh(1)} = \\frac{-2\\sinh^2(1/2)}{2\\sinh(1/2)\\cosh(1/2)} = -\\tanh(1/2) $$\nSo,\n$$ c_2 = -\\frac{\\lambda}{2} \\tanh(1/2) $$\n\nSubstituting $c_1$ and $c_2$ back into the expression for $y(x)$:\n$$ y(x) = \\frac{\\lambda}{2} \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] $$\n\n#### **5. Determining the Lagrange Multiplier**\n\nWe use the isoperimetric constraint $\\int_{0}^{1} y(x) \\, dx = 1$ to solve for $\\lambda$.\n$$ \\int_{0}^{1} \\frac{\\lambda}{2} \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] dx = 1 $$\nFactor out $\\frac{\\lambda}{2}$:\n$$ \\frac{\\lambda}{2} \\left( \\left[ \\sinh(x) \\right]_0^1 - \\tanh(1/2) \\left[ \\cosh(x) \\right]_0^1 - \\left[ x \\right]_0^1 \\right) = 1 $$\nEvaluate the terms:\n1.  $\\left[ \\sinh(x) \\right]_0^1 = \\sinh(1)$\n2.  $\\left[ \\cosh(x) \\right]_0^1 = \\cosh(1) - 1$\n3.  $\\left[ x \\right]_0^1 = 1$\n\nThe equation becomes:\n$$ \\frac{\\lambda}{2} \\left( \\sinh(1) - \\frac{\\cosh(1)-1}{\\sinh(1)}(\\cosh(1)-1) - 1 \\right) = 1 $$\nSimplify the term inside the parenthesis:\n$$ \\sinh(1) - 1 - \\frac{(\\cosh(1)-1)^2}{\\sinh(1)} $$\nFind a common denominator ($\\sinh(1)$):\n$$ \\frac{\\sinh^2(1) - \\sinh(1) - (\\cosh^2(1) - 2\\cosh(1) + 1)}{\\sinh(1)} $$\nRecall the identity $\\cosh^2(x) - \\sinh^2(x) = 1$, so $\\sinh^2(x) - \\cosh^2(x) = -1$:\n$$ \\frac{-1 - \\sinh(1) + 2\\cosh(1) - 1}{\\sinh(1)} = \\frac{2\\cosh(1) - \\sinh(1) - 2}{\\sinh(1)} $$\n\nThus, the constraint equation is:\n$$ \\frac{\\lambda}{2} \\left( \\frac{2\\cosh(1) - \\sinh(1) - 2}{\\sinh(1)} \\right) = 1 $$\n$$ \\lambda = \\frac{2\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} $$\n\n#### **6. Final Expression for $y(x)$**\n\nSubstitute $\\lambda$ back into the expression for $y(x)$:\n$$ y(x) = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} \\left[ \\cosh(x) - \\frac{\\cosh(1)-1}{\\sinh(1)}\\sinh(x) - 1 \\right] $$\nThis simplifies slightly by grouping the hyperbolic terms. Let $K = \\frac{\\lambda}{2}$.\n$$ y(x) = K \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] $$\nwhere $K = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2}$.\n\n#### **7. Calculation of the Minimum Functional Value**\n\nWe calculate $J[y]$. Note that the Euler-Lagrange equation implies $y'' = y + \\frac{\\lambda}{2}$.\nIntegration by parts on the first term of $J$:\n$$ \\int_0^1 (y')^2 dx = [y y']_0^1 - \\int_0^1 y y'' dx $$\nSince $y(0)=y(1)=0$, the boundary term $[y y']_0^1$ vanishes.\n$$ \\int_0^1 (y')^2 dx = - \\int_0^1 y (y + \\frac{\\lambda}{2}) dx = - \\int_0^1 (y^2 + \\frac{\\lambda}{2} y) dx $$\nSubstitute this back into $J[y]$:\n$$ J[y] = \\int_0^1 \\left( -y^2 - \\frac{\\lambda}{2} y + y^2 \\right) dx = -\\frac{\\lambda}{2} \\int_0^1 y \\, dx $$\nUsing the constraint $\\int_0^1 y \\, dx = 1$:\n$$ J[y] = -\\frac{\\lambda}{2} $$\nSubstituting the value of $\\lambda$:\n$$ J_{min} = -K = -\\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} $$\nUsing numerical values ($\\sinh(1) \\approx 1.1752$, $\\cosh(1) \\approx 1.5431$):\n$$ 2(1.5431) - 1.1752 - 2 = 3.0862 - 3.1752 = -0.089 $$\n$$ J_{min} \\approx -\\frac{1.1752}{-0.089} \\approx 13.2 $$\n(Exact values should be preserved).\n\n**Check for Minimality:**\nThe integrand $\\mathcal{F} = y'^2 + y^2 + \\lambda y$ is convex with respect to $y$ and $y'$ (Hessian with respect to $y, y'$ is positive definite diagonal matrix $\\text{diag}(2, 2)$). Therefore, the extremal found is a global minimum.\n\n### **Final Answer**\n\nThe optimal curve is:\n$$ y(x) = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} \\left( \\cosh(x) - \\tanh\\left(\\frac{1}{2}\\right)\\sinh(x) - 1 \\right) $$\nThe minimum value of the functional is:\n$$ J_{min} = \\frac{\\sinh(1)}{2 + \\sinh(1) - 2\\cosh(1)} $$",
        "raw_answer": "Here is a challenging mathematical problem in the domain of **Calculus of Variations**, followed by a complete and rigorous solution.\n\n***\n\n### **Problem Statement**\n\nFind the function $y(x)$ continuously differentiable on the interval $[0, 1]$ that minimizes the functional:\n$$ J[y] = \\int_{0}^{1} \\left( (y'(x))^2 + y(x)^2 \\right) \\, dx $$\nsubject to the boundary conditions:\n$$ y(0) = 0, \\quad y(1) = 0 $$\nand the isoperimetric constraint:\n$$ \\int_{0}^{1} y(x) \\, dx = 1 $$\nProvide the explicit analytical expression for the optimal curve $y(x)$ and calculate the minimum value of the functional $J[y]$.\n\n***\n\n### **Solution**\n\nTo solve this constrained optimization problem, we employ the method of Lagrange multipliers in the calculus of variations.\n\n#### **1. Formulation of the Auxiliary Functional**\n\nWe introduce a Lagrange multiplier constant $\\lambda$ associated with the integral constraint. We define the auxiliary functional $L[y]$:\n$$ L[y] = \\int_{0}^{1} \\left( (y')^2 + y^2 \\right) \\, dx + \\lambda \\left( \\int_{0}^{1} y \\, dx - 1 \\right) $$\nThis can be rewritten as maximizing/minimizing the integral of the auxiliary Lagrangian $\\mathcal{F}$:\n$$ L[y] = \\int_{0}^{1} \\mathcal{F}(x, y, y') \\, dx - \\lambda $$\nwhere $\\mathcal{F}(x, y, y') = (y')^2 + y^2 + \\lambda y$.\n\n#### **2. The Euler-Lagrange Equation**\n\nA necessary condition for $y(x)$ to be an extremal is that it satisfies the Euler-Lagrange equation:\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y} - \\frac{d}{dx} \\left( \\frac{\\partial \\mathcal{F}}{\\partial y'} \\right) = 0 $$\nCalculating the partial derivatives:\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y} = 2y + \\lambda $$\n$$ \\frac{\\partial \\mathcal{F}}{\\partial y'} = 2y' $$\nSubstitute these into the equation:\n$$ (2y + \\lambda) - \\frac{d}{dx}(2y') = 0 $$\n$$ 2y + \\lambda - 2y'' = 0 $$\nDividing by 2, we obtain the non-homogeneous linear differential equation:\n$$ y'' - y = \\frac{\\lambda}{2} $$\n\n#### **3. Solving the Differential Equation**\n\nThe general solution to the differential equation $y'' - y = \\frac{\\lambda}{2}$ consists of the homogeneous solution $y_h$ and a particular solution $y_p$.\n\n**Homogeneous solution** ($y'' - y = 0$):\n$$ y_h(x) = c_1 \\cosh(x) + c_2 \\sinh(x) $$\n\n**Particular solution**:\nSince the right-hand side is a constant, we posit a constant particular solution $y_p = A$.\n$$ 0 - A = \\frac{\\lambda}{2} \\implies A = -\\frac{\\lambda}{2} $$\n\nThus, the general solution is:\n$$ y(x) = c_1 \\cosh(x) + c_2 \\sinh(x) - \\frac{\\lambda}{2} $$\n\n#### **4. Applying Boundary Conditions**\n\nWe apply the boundary conditions $y(0)=0$ and $y(1)=0$ to determine constants $c_1$ and $c_2$ in terms of $\\lambda$.\n\n**At $x=0$:**\n$$ y(0) = c_1 \\cosh(0) + c_2 \\sinh(0) - \\frac{\\lambda}{2} = 0 $$\n$$ c_1 (1) + 0 - \\frac{\\lambda}{2} = 0 \\implies c_1 = \\frac{\\lambda}{2} $$\n\n**At $x=1$:**\n$$ y(1) = c_1 \\cosh(1) + c_2 \\sinh(1) - \\frac{\\lambda}{2} = 0 $$\nSubstitute $c_1 = \\frac{\\lambda}{2}$:\n$$ \\frac{\\lambda}{2} \\cosh(1) + c_2 \\sinh(1) - \\frac{\\lambda}{2} = 0 $$\n$$ c_2 \\sinh(1) = \\frac{\\lambda}{2} (1 - \\cosh(1)) $$\n$$ c_2 = \\frac{\\lambda}{2} \\frac{1 - \\cosh(1)}{\\sinh(1)} $$\n\nUsing the half-angle hyperbolic identities $\\cosh(x) - 1 = 2\\sinh^2(x/2)$ and $\\sinh(x) = 2\\sinh(x/2)\\cosh(x/2)$:\n$$ \\frac{1 - \\cosh(1)}{\\sinh(1)} = \\frac{-2\\sinh^2(1/2)}{2\\sinh(1/2)\\cosh(1/2)} = -\\tanh(1/2) $$\nSo,\n$$ c_2 = -\\frac{\\lambda}{2} \\tanh(1/2) $$\n\nSubstituting $c_1$ and $c_2$ back into the expression for $y(x)$:\n$$ y(x) = \\frac{\\lambda}{2} \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] $$\n\n#### **5. Determining the Lagrange Multiplier**\n\nWe use the isoperimetric constraint $\\int_{0}^{1} y(x) \\, dx = 1$ to solve for $\\lambda$.\n$$ \\int_{0}^{1} \\frac{\\lambda}{2} \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] dx = 1 $$\nFactor out $\\frac{\\lambda}{2}$:\n$$ \\frac{\\lambda}{2} \\left( \\left[ \\sinh(x) \\right]_0^1 - \\tanh(1/2) \\left[ \\cosh(x) \\right]_0^1 - \\left[ x \\right]_0^1 \\right) = 1 $$\nEvaluate the terms:\n1.  $\\left[ \\sinh(x) \\right]_0^1 = \\sinh(1)$\n2.  $\\left[ \\cosh(x) \\right]_0^1 = \\cosh(1) - 1$\n3.  $\\left[ x \\right]_0^1 = 1$\n\nThe equation becomes:\n$$ \\frac{\\lambda}{2} \\left( \\sinh(1) - \\frac{\\cosh(1)-1}{\\sinh(1)}(\\cosh(1)-1) - 1 \\right) = 1 $$\nSimplify the term inside the parenthesis:\n$$ \\sinh(1) - 1 - \\frac{(\\cosh(1)-1)^2}{\\sinh(1)} $$\nFind a common denominator ($\\sinh(1)$):\n$$ \\frac{\\sinh^2(1) - \\sinh(1) - (\\cosh^2(1) - 2\\cosh(1) + 1)}{\\sinh(1)} $$\nRecall the identity $\\cosh^2(x) - \\sinh^2(x) = 1$, so $\\sinh^2(x) - \\cosh^2(x) = -1$:\n$$ \\frac{-1 - \\sinh(1) + 2\\cosh(1) - 1}{\\sinh(1)} = \\frac{2\\cosh(1) - \\sinh(1) - 2}{\\sinh(1)} $$\n\nThus, the constraint equation is:\n$$ \\frac{\\lambda}{2} \\left( \\frac{2\\cosh(1) - \\sinh(1) - 2}{\\sinh(1)} \\right) = 1 $$\n$$ \\lambda = \\frac{2\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} $$\n\n#### **6. Final Expression for $y(x)$**\n\nSubstitute $\\lambda$ back into the expression for $y(x)$:\n$$ y(x) = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} \\left[ \\cosh(x) - \\frac{\\cosh(1)-1}{\\sinh(1)}\\sinh(x) - 1 \\right] $$\nThis simplifies slightly by grouping the hyperbolic terms. Let $K = \\frac{\\lambda}{2}$.\n$$ y(x) = K \\left[ \\cosh(x) - \\tanh(1/2)\\sinh(x) - 1 \\right] $$\nwhere $K = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2}$.\n\n#### **7. Calculation of the Minimum Functional Value**\n\nWe calculate $J[y]$. Note that the Euler-Lagrange equation implies $y'' = y + \\frac{\\lambda}{2}$.\nIntegration by parts on the first term of $J$:\n$$ \\int_0^1 (y')^2 dx = [y y']_0^1 - \\int_0^1 y y'' dx $$\nSince $y(0)=y(1)=0$, the boundary term $[y y']_0^1$ vanishes.\n$$ \\int_0^1 (y')^2 dx = - \\int_0^1 y (y + \\frac{\\lambda}{2}) dx = - \\int_0^1 (y^2 + \\frac{\\lambda}{2} y) dx $$\nSubstitute this back into $J[y]$:\n$$ J[y] = \\int_0^1 \\left( -y^2 - \\frac{\\lambda}{2} y + y^2 \\right) dx = -\\frac{\\lambda}{2} \\int_0^1 y \\, dx $$\nUsing the constraint $\\int_0^1 y \\, dx = 1$:\n$$ J[y] = -\\frac{\\lambda}{2} $$\nSubstituting the value of $\\lambda$:\n$$ J_{min} = -K = -\\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} $$\nUsing numerical values ($\\sinh(1) \\approx 1.1752$, $\\cosh(1) \\approx 1.5431$):\n$$ 2(1.5431) - 1.1752 - 2 = 3.0862 - 3.1752 = -0.089 $$\n$$ J_{min} \\approx -\\frac{1.1752}{-0.089} \\approx 13.2 $$\n(Exact values should be preserved).\n\n**Check for Minimality:**\nThe integrand $\\mathcal{F} = y'^2 + y^2 + \\lambda y$ is convex with respect to $y$ and $y'$ (Hessian with respect to $y, y'$ is positive definite diagonal matrix $\\text{diag}(2, 2)$). Therefore, the extremal found is a global minimum.\n\n### **Final Answer**\n\nThe optimal curve is:\n$$ y(x) = \\frac{\\sinh(1)}{2\\cosh(1) - \\sinh(1) - 2} \\left( \\cosh(x) - \\tanh\\left(\\frac{1}{2}\\right)\\sinh(x) - 1 \\right) $$\nThe minimum value of the functional is:\n$$ J_{min} = \\frac{\\sinh(1)}{2 + \\sinh(1) - 2\\cosh(1)} $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Geometry, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Choose a geometry topic\nTo create a challenging problem, we need to select a topic within geometry that is rich enough to allow for a non-trivial question. Let's consider problems related to geometric shapes, such as triangles, circles, or more complex figures.\n\n## Step 3: Formulate a problem\nLet's formulate a problem involving a triangle and a circle, as these are fundamental geometric objects. A potential problem could involve the properties of inscribed angles, the relationship between a triangle and its circumcircle, or the application of geometric theorems like Ptolemy's theorem.\n\n## Step 4: Create a specific problem\nConsider the following problem: \"Let $ABC$ be a triangle with $AB = 5$, $AC = 6$, and $BC = 7$. The circumcircle of triangle $ABC$ has center $O$. Let $D$ be the point on $BC$ such that $AD$ is the angle bisector of $\\angle BAC$. Find the length of $AD$.\"\n\n## Step 5: Verify the problem meets the criteria\n- **Well-Posedness and Completeness**: The triangle $ABC$ is well-defined by its side lengths (5, 6, 7), and $D$ is defined as the point on $BC$ where $AD$ bisects $\\angle BAC$. The circumcircle and its center $O$ are also well-defined.\n- **Clarity**: The problem statement is clear and unambiguous.\n- **Non-Triviality**: The problem requires applying geometric principles, such as the Angle Bisector Theorem and possibly properties of the circumcircle.\n- **Solvability and Verification**: The problem is solvable using established geometric methods.\n\n## Step 6: Solve the problem\nTo solve this, we can use the Angle Bisector Theorem to find $BD$ and $DC$, and then apply the Stewart's Theorem to find $AD$.\n\n### Step 6.1: Apply the Angle Bisector Theorem\nThe Angle Bisector Theorem states that $\\frac{BD}{DC} = \\frac{AB}{AC}$. So, $\\frac{BD}{DC} = \\frac{5}{6}$.\n\n### Step 6.2: Calculate $BD$ and $DC$\nGiven $BC = 7$, we have $BD + DC = 7$. From the Angle Bisector Theorem, we can write $BD = \\frac{5}{11} \\times 7$ and $DC = \\frac{6}{11} \\times 7$. Thus, $BD = \\frac{35}{11}$ and $DC = \\frac{42}{11}$.\n\n### Step 6.3: Apply Stewart's Theorem to find $AD$\nStewart's Theorem states that $b^2n + c^2m = a(d^2 + m*n)$, where $a = BC = 7$, $b = AC = 6$, $c = AB = 5$, $d = AD$, $m = BD = \\frac{35}{11}$, and $n = DC = \\frac{42}{11}$. Substituting these values gives us an equation to solve for $d = AD$.\n\n## Step 7: Perform Stewart's Theorem calculation\nLet's substitute the given values into Stewart's Theorem:\n$6^2(\\frac{35}{11}) + 5^2(\\frac{42}{11}) = 7(AD^2 + \\frac{35}{11}*\\frac{42}{11})$.\nSimplifying yields:\n$36(\\frac{35}{11}) + 25(\\frac{42}{11}) = 7(AD^2 + \\frac{1470}{121})$.\nThis simplifies to:\n$\\frac{1260}{11} + \\frac{1050}{11} = 7AD^2 + \\frac{7*1470}{121}$.\nFurther simplification gives:\n$\\frac{2310}{11} = 7AD^2 + \\frac{10290}{121}$.\nConverting to a common denominator:\n$\\frac{2310*11}{121} = 7AD^2 + \\frac{10290}{121}$,\n$\\frac{25410}{121} = 7AD^2 + \\frac{10290}{121}$.\nSimplifying:\n$7AD^2 = \\frac{25410 - 10290}{121}$,\n$7AD^2 = \\frac{15120}{121}$,\n$AD^2 = \\frac{15120}{7*121}$,\n$AD^2 = \\frac{2160}{121}$,\n$AD = \\sqrt{\\frac{2160}{121}}$.\n\n## Step 8: Simplify $AD$\n$AD = \\sqrt{\\frac{2160}{121}} = \\sqrt{\\frac{16*135}{121}} = \\sqrt{\\frac{16*9*15}{121}} = \\frac{4*3}{11}\\sqrt{15} = \\frac{12\\sqrt{15}}{11}$.\n\nThe final answer is: \n\nLet $ABC$ be a triangle with $AB = 5$, $AC = 6$, and $BC = 7$. The circumcircle of triangle $ABC$ has center $O$. Let $D$ be the point on $BC$ such that $AD$ is the angle bisector of $\\angle BAC$. Find the length of $AD$.",
    "run_id": "35",
    "outer_attempt": 1,
    "topic_slug": "geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the length of the segment $AD$, where $AD$ is the angle bisector of $\\angle BAC$ in triangle $ABC$, we will proceed using the properties of the angle bisector and algebraic computation.\n\n### 1. Problem Setup and Identification of Variables\n\nWe are given triangle $ABC$ with side lengths:\n*   $c = AB = 5$\n*   $b = AC = 6$\n*   $a = BC = 7$\n\nPoint $D$ lies on the segment $BC$ such that $AD$ bisects $\\angle BAC$. We must find the length $AD$. Note that the information regarding the circumcircle center $O$ is extraneous to the calculation of the internal angle bisector's length given the side lengths.\n\n### 2. Application of the Angle Bisector Theorem\n\nThe Angle Bisector Theorem states that if a point $D$ lies on side $BC$ of triangle $ABC$ and $AD$ bisects $\\angle BAC$, then $D$ divides $BC$ in a ratio proportional to the adjacent sides $AB$ and $AC$.\n\n$$ \\frac{BD}{DC} = \\frac{AB}{AC} $$\n\nSubstituting the known values:\n$$ \\frac{BD}{DC} = \\frac{5}{6} $$\n\nSince $D$ lies on $BC$, we know that $BD + DC = BC = 7$.\nLet $BD = 5k$ and $DC = 6k$ for some constant $k$.\n$$ 5k + 6k = 7 $$\n$$ 11k = 7 \\implies k = \\frac{7}{11} $$\n\nNow we can determine the lengths of segments $BD$ and $DC$:\n$$ BD = 5 \\left( \\frac{7}{11} \\right) = \\frac{35}{11} $$\n$$ DC = 6 \\left( \\frac{7}{11} \\right) = \\frac{42}{11} $$\n\n### 3. Calculation of Length $AD$\n\nThe length of the angle bisector $AD$ can be found using the standard formula derived from Stewart's Theorem:\n$$ AD^2 = AB \\cdot AC - BD \\cdot DC $$\n\nSubstitute the values we have established:\n$$ AD^2 = (5)(6) - \\left( \\frac{35}{11} \\right) \\left( \\frac{42}{11} \\right) $$\n\nCalculate the product of the segments on the base:\n$$ \\frac{35}{11} \\cdot \\frac{42}{11} = \\frac{1470}{121} $$\n\nSubstitute this back into the equation for $AD^2$:\n$$ AD^2 = 30 - \\frac{1470}{121} $$\n\nTo combine these terms, find a common denominator:\n$$ 30 = \\frac{30 \\cdot 121}{121} = \\frac{3630}{121} $$\n\n$$ AD^2 = \\frac{3630 - 1470}{121} $$\n$$ AD^2 = \\frac{2160}{121} $$\n\n### 4. Simplification of the Result\n\nTake the square root of both sides to find $AD$:\n$$ AD = \\sqrt{\\frac{2160}{121}} = \\frac{\\sqrt{2160}}{11} $$\n\nSimplify the radical $\\sqrt{2160}$:\nPrime factorization of $2160$:\n$$ 2160 = 10 \\cdot 216 = 2 \\cdot 5 \\cdot 6^3 = 2 \\cdot 5 \\cdot (2 \\cdot 3)^3 $$\n$$ 2160 = 2 \\cdot 5 \\cdot 2^3 \\cdot 3^3 = 2^4 \\cdot 3^3 \\cdot 5 $$\n\nExtract perfect squares:\n$$ \\sqrt{2160} = \\sqrt{2^4 \\cdot 3^2 \\cdot 3 \\cdot 5} $$\n$$ \\sqrt{2160} = \\sqrt{(2^2)^2 \\cdot 3^2 \\cdot 15} $$\n$$ \\sqrt{2160} = 2^2 \\cdot 3 \\sqrt{15} = 4 \\cdot 3 \\sqrt{15} = 12\\sqrt{15} $$\n\nThus:\n$$ AD = \\frac{12\\sqrt{15}}{11} $$\n\n### Alternative Verification (Trigonometry)\n\nWe can verify this result using the formula $AD = \\frac{2bc \\cos(A/2)}{b+c}$.\nFirst, find $\\cos A$ using the Law of Cosines:\n$$ a^2 = b^2 + c^2 - 2bc \\cos A $$\n$$ 49 = 36 + 25 - 60 \\cos A $$\n$$ 49 = 61 - 60 \\cos A $$\n$$ 60 \\cos A = 12 \\implies \\cos A = \\frac{1}{5} $$\n\nUsing the half-angle identity $\\cos \\frac{A}{2} = \\sqrt{\\frac{1 + \\cos A}{2}}$:\n$$ \\cos \\frac{A}{2} = \\sqrt{\\frac{1 + 1/5}{2}} = \\sqrt{\\frac{6/5}{2}} = \\sqrt{\\frac{3}{5}} $$\n\nSubstitute into the bisector formula:\n$$ AD = \\frac{2(6)(5) \\sqrt{3/5}}{6+5} = \\frac{60}{11} \\frac{\\sqrt{3}}{\\sqrt{5}} = \\frac{60\\sqrt{15}}{11 \\cdot 5} = \\frac{12\\sqrt{15}}{11} $$\n\nThe results match.\n\n### Final Answer\n\nThe length of $AD$ is $\\frac{12\\sqrt{15}}{11}$.",
        "raw_answer": "To find the length of the segment $AD$, where $AD$ is the angle bisector of $\\angle BAC$ in triangle $ABC$, we will proceed using the properties of the angle bisector and algebraic computation.\n\n### 1. Problem Setup and Identification of Variables\n\nWe are given triangle $ABC$ with side lengths:\n*   $c = AB = 5$\n*   $b = AC = 6$\n*   $a = BC = 7$\n\nPoint $D$ lies on the segment $BC$ such that $AD$ bisects $\\angle BAC$. We must find the length $AD$. Note that the information regarding the circumcircle center $O$ is extraneous to the calculation of the internal angle bisector's length given the side lengths.\n\n### 2. Application of the Angle Bisector Theorem\n\nThe Angle Bisector Theorem states that if a point $D$ lies on side $BC$ of triangle $ABC$ and $AD$ bisects $\\angle BAC$, then $D$ divides $BC$ in a ratio proportional to the adjacent sides $AB$ and $AC$.\n\n$$ \\frac{BD}{DC} = \\frac{AB}{AC} $$\n\nSubstituting the known values:\n$$ \\frac{BD}{DC} = \\frac{5}{6} $$\n\nSince $D$ lies on $BC$, we know that $BD + DC = BC = 7$.\nLet $BD = 5k$ and $DC = 6k$ for some constant $k$.\n$$ 5k + 6k = 7 $$\n$$ 11k = 7 \\implies k = \\frac{7}{11} $$\n\nNow we can determine the lengths of segments $BD$ and $DC$:\n$$ BD = 5 \\left( \\frac{7}{11} \\right) = \\frac{35}{11} $$\n$$ DC = 6 \\left( \\frac{7}{11} \\right) = \\frac{42}{11} $$\n\n### 3. Calculation of Length $AD$\n\nThe length of the angle bisector $AD$ can be found using the standard formula derived from Stewart's Theorem:\n$$ AD^2 = AB \\cdot AC - BD \\cdot DC $$\n\nSubstitute the values we have established:\n$$ AD^2 = (5)(6) - \\left( \\frac{35}{11} \\right) \\left( \\frac{42}{11} \\right) $$\n\nCalculate the product of the segments on the base:\n$$ \\frac{35}{11} \\cdot \\frac{42}{11} = \\frac{1470}{121} $$\n\nSubstitute this back into the equation for $AD^2$:\n$$ AD^2 = 30 - \\frac{1470}{121} $$\n\nTo combine these terms, find a common denominator:\n$$ 30 = \\frac{30 \\cdot 121}{121} = \\frac{3630}{121} $$\n\n$$ AD^2 = \\frac{3630 - 1470}{121} $$\n$$ AD^2 = \\frac{2160}{121} $$\n\n### 4. Simplification of the Result\n\nTake the square root of both sides to find $AD$:\n$$ AD = \\sqrt{\\frac{2160}{121}} = \\frac{\\sqrt{2160}}{11} $$\n\nSimplify the radical $\\sqrt{2160}$:\nPrime factorization of $2160$:\n$$ 2160 = 10 \\cdot 216 = 2 \\cdot 5 \\cdot 6^3 = 2 \\cdot 5 \\cdot (2 \\cdot 3)^3 $$\n$$ 2160 = 2 \\cdot 5 \\cdot 2^3 \\cdot 3^3 = 2^4 \\cdot 3^3 \\cdot 5 $$\n\nExtract perfect squares:\n$$ \\sqrt{2160} = \\sqrt{2^4 \\cdot 3^2 \\cdot 3 \\cdot 5} $$\n$$ \\sqrt{2160} = \\sqrt{(2^2)^2 \\cdot 3^2 \\cdot 15} $$\n$$ \\sqrt{2160} = 2^2 \\cdot 3 \\sqrt{15} = 4 \\cdot 3 \\sqrt{15} = 12\\sqrt{15} $$\n\nThus:\n$$ AD = \\frac{12\\sqrt{15}}{11} $$\n\n### Alternative Verification (Trigonometry)\n\nWe can verify this result using the formula $AD = \\frac{2bc \\cos(A/2)}{b+c}$.\nFirst, find $\\cos A$ using the Law of Cosines:\n$$ a^2 = b^2 + c^2 - 2bc \\cos A $$\n$$ 49 = 36 + 25 - 60 \\cos A $$\n$$ 49 = 61 - 60 \\cos A $$\n$$ 60 \\cos A = 12 \\implies \\cos A = \\frac{1}{5} $$\n\nUsing the half-angle identity $\\cos \\frac{A}{2} = \\sqrt{\\frac{1 + \\cos A}{2}}$:\n$$ \\cos \\frac{A}{2} = \\sqrt{\\frac{1 + 1/5}{2}} = \\sqrt{\\frac{6/5}{2}} = \\sqrt{\\frac{3}{5}} $$\n\nSubstitute into the bisector formula:\n$$ AD = \\frac{2(6)(5) \\sqrt{3/5}}{6+5} = \\frac{60}{11} \\frac{\\sqrt{3}}{\\sqrt{5}} = \\frac{60\\sqrt{15}}{11 \\cdot 5} = \\frac{12\\sqrt{15}}{11} $$\n\nThe results match.\n\n### Final Answer\n\nThe length of $AD$ is $\\frac{12\\sqrt{15}}{11}$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Convex and discrete geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Convex and discrete geometry\nConvex and discrete geometry encompasses a broad range of topics including the geometry of convex sets, polytopes, and discrete geometric structures. A suitable topic could involve properties of convex polytopes, such as their faces, volumes, or the relationships between their vertices and facets.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem related to the properties of a specific convex polytope. A well-known result in convex geometry is the characterization of regular polytopes. However, a more challenging and less straightforward problem could involve understanding the relationship between the number of vertices, edges, and faces of a polytope.\n\n## Step 4: Generate a problem statement\nConsider a 3-dimensional convex polytope $P$ that is simple (every vertex is incident to exactly 3 edges) and has $V$ vertices, $E$ edges, and $F$ faces. The problem is to prove that for such a polytope, Euler's formula ($V - E + F = 2$) holds, and then use this to derive a relationship between $V$ and $F$.\n\n## Step 5: Write down the problem in the required format\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces. Prove that $V - E + F = 2$ and derive a formula relating $V$ and $F$ using the fact that $P$ is simple.",
    "run_id": "36",
    "outer_attempt": 1,
    "topic_slug": "convex_and_discrete_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete, rigorous solution to the problem presented.\n\n### Problem Statement\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces.\n1. Prove that $V - E + F = 2$.\n2. Derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n---\n\n### Part 1: Proof of Euler's Formula for 3-Polytopes\n\n**Theorem:** For any convex 3-dimensional polytope, the number of vertices ($V$), edges ($E$), and faces ($F$) satisfy $V - E + F = 2$.\n\n**Proof:**\n\n**1. Reduction to Planar Graphs**\nThe boundary of a convex 3-polytope $P$ is homeomorphic to the 2-sphere $S^2$. We can project this boundary onto the Euclidean plane $\\mathbb{R}^2$ to form a planar graph $G$. A standard method is using a Schlegel diagram: we choose a face of the polytope to act as the \"window\" and project the remaining structure through this face onto the plane.\n- The vertices and edges of $P$ correspond one-to-one with the vertices and edges of $G$. Thus, $V_G = V$ and $E_G = E$.\n- The faces of $P$ correspond to the bounded regions of the plane graph $G$, plus the one unbounded region (the exterior) which corresponds to the face we projected through. Thus, $F_G = F$.\n- Since $P$ is a convex polytope, its 1-skeleton is connected; thus $G$ is a connected planar graph.\n\nThe problem reduces to proving Euler's formula for a connected planar graph $G$: $V_G - E_G + F_G = 2$.\n\n**2. Inductive Proof for Planar Graphs**\nWe proceed by induction on the number of faces, $F_G$.\n\n**Base Case:** $F_G = 1$.\nIf the graph has only one face (the unbounded region), it cannot contain any cycles (a cycle would enclose a bounded face). Since $G$ is connected and has no cycles, it is a tree.\nFor a tree with $V_G$ vertices and $E_G$ edges, we know that $E_G = V_G - 1$.\nSubstituting into Euler's expression:\n$$V_G - E_G + F_G = V_G - (V_G - 1) + 1 = 1 + 1 = 2$$\nThe formula holds for the base case.\n\n**Inductive Step:**\nAssume that for any connected planar graph with $k$ faces, $V - E + k = 2$.\nConsider a connected planar graph $G$ with $k+1$ faces ($k \\geq 1$).\nSince $k+1 \\geq 2$, the graph is not a tree and must contain at least one cycle. Furthermore, there must exist an edge $e$ that lies on the boundary between two distinct faces (an internal edge).\nRemove this edge $e$.\n- The number of edges becomes $E' = E - 1$.\n- The number of vertices remains $V' = V$.\n- Removing the boundary between two faces merges them into one. Thus, the number of faces becomes $F' = (k+1) - 1 = k$.\n- Removing an edge from a cycle does not disconnect the graph, so the resulting graph $G'$ is still connected.\n\nBy the inductive hypothesis, Euler's formula holds for $G'$:\n$$V' - E' + F' = 2$$\nSubstitute the relations back in terms of $G$:\n$$V - (E - 1) + (F - 1) = 2$$\n$$V - E + 1 + F - 1 = 2$$\n$$V - E + F = 2$$\n\n**Conclusion:**\nBy the principle of mathematical induction, $V - E + F = 2$ holds for all connected planar graphs, and consequently for all convex 3-polytopes.\n\n---\n\n### Part 2: Derivation of the Relation for Simple Polytopes\n\n**Definition:** A 3-dimensional polytope is **simple** if every vertex is incident to exactly 3 edges.\n\n**1. Establish the Vertex-Edge Relation**\nLet $\\deg(v)$ denote the degree of a vertex $v$ (the number of edges incident to it).\nSince $P$ is simple, for every vertex $v_i$, $\\deg(v_i) = 3$.\nWe sum the degrees of all vertices:\n$$\\sum_{i=1}^{V} \\deg(v_i) = 3V$$\n\nBy the Handshaking Lemma (graph theory), the sum of the degrees of the vertices in a graph is equal to twice the number of edges, because each edge connects two vertices and is counted exactly twice in the sum.\n$$2E = \\sum_{i=1}^{V} \\deg(v_i)$$\n\nEquating the two expressions:\n$$2E = 3V \\implies E = \\frac{3}{2}V$$\n\n**2. Substitute into Euler's Formula**\nWe start with Euler's formula proven in Part 1:\n$$V - E + F = 2$$\n\nSubstitute $E = \\frac{3}{2}V$ into the equation:\n$$V - \\frac{3}{2}V + F = 2$$\n\nSimplify the terms with $V$:\n$$-\\frac{1}{2}V + F = 2$$\n\n**3. Final Formula**\nTo express the relationship cleanly, we can solve for $V$ in terms of $F$:\n$$\\frac{1}{2}V = F - 2$$\n$$V = 2F - 4$$\n\nAlternatively, we can write it as $2F - V = 4$.\n\n### Final Answer\n\n1.  **Proof**: The relation $V - E + F = 2$ is proven by mapping the polytope to a connected planar graph and using induction on the number of faces.\n2.  **Relation**: For a simple 3-dimensional convex polytope, the relationship between the number of vertices and faces is:\n    $$V = 2F - 4$$",
        "raw_answer": "Here is the complete, rigorous solution to the problem presented.\n\n### Problem Statement\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces.\n1. Prove that $V - E + F = 2$.\n2. Derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n---\n\n### Part 1: Proof of Euler's Formula for 3-Polytopes\n\n**Theorem:** For any convex 3-dimensional polytope, the number of vertices ($V$), edges ($E$), and faces ($F$) satisfy $V - E + F = 2$.\n\n**Proof:**\n\n**1. Reduction to Planar Graphs**\nThe boundary of a convex 3-polytope $P$ is homeomorphic to the 2-sphere $S^2$. We can project this boundary onto the Euclidean plane $\\mathbb{R}^2$ to form a planar graph $G$. A standard method is using a Schlegel diagram: we choose a face of the polytope to act as the \"window\" and project the remaining structure through this face onto the plane.\n- The vertices and edges of $P$ correspond one-to-one with the vertices and edges of $G$. Thus, $V_G = V$ and $E_G = E$.\n- The faces of $P$ correspond to the bounded regions of the plane graph $G$, plus the one unbounded region (the exterior) which corresponds to the face we projected through. Thus, $F_G = F$.\n- Since $P$ is a convex polytope, its 1-skeleton is connected; thus $G$ is a connected planar graph.\n\nThe problem reduces to proving Euler's formula for a connected planar graph $G$: $V_G - E_G + F_G = 2$.\n\n**2. Inductive Proof for Planar Graphs**\nWe proceed by induction on the number of faces, $F_G$.\n\n**Base Case:** $F_G = 1$.\nIf the graph has only one face (the unbounded region), it cannot contain any cycles (a cycle would enclose a bounded face). Since $G$ is connected and has no cycles, it is a tree.\nFor a tree with $V_G$ vertices and $E_G$ edges, we know that $E_G = V_G - 1$.\nSubstituting into Euler's expression:\n$$V_G - E_G + F_G = V_G - (V_G - 1) + 1 = 1 + 1 = 2$$\nThe formula holds for the base case.\n\n**Inductive Step:**\nAssume that for any connected planar graph with $k$ faces, $V - E + k = 2$.\nConsider a connected planar graph $G$ with $k+1$ faces ($k \\geq 1$).\nSince $k+1 \\geq 2$, the graph is not a tree and must contain at least one cycle. Furthermore, there must exist an edge $e$ that lies on the boundary between two distinct faces (an internal edge).\nRemove this edge $e$.\n- The number of edges becomes $E' = E - 1$.\n- The number of vertices remains $V' = V$.\n- Removing the boundary between two faces merges them into one. Thus, the number of faces becomes $F' = (k+1) - 1 = k$.\n- Removing an edge from a cycle does not disconnect the graph, so the resulting graph $G'$ is still connected.\n\nBy the inductive hypothesis, Euler's formula holds for $G'$:\n$$V' - E' + F' = 2$$\nSubstitute the relations back in terms of $G$:\n$$V - (E - 1) + (F - 1) = 2$$\n$$V - E + 1 + F - 1 = 2$$\n$$V - E + F = 2$$\n\n**Conclusion:**\nBy the principle of mathematical induction, $V - E + F = 2$ holds for all connected planar graphs, and consequently for all convex 3-polytopes.\n\n---\n\n### Part 2: Derivation of the Relation for Simple Polytopes\n\n**Definition:** A 3-dimensional polytope is **simple** if every vertex is incident to exactly 3 edges.\n\n**1. Establish the Vertex-Edge Relation**\nLet $\\deg(v)$ denote the degree of a vertex $v$ (the number of edges incident to it).\nSince $P$ is simple, for every vertex $v_i$, $\\deg(v_i) = 3$.\nWe sum the degrees of all vertices:\n$$\\sum_{i=1}^{V} \\deg(v_i) = 3V$$\n\nBy the Handshaking Lemma (graph theory), the sum of the degrees of the vertices in a graph is equal to twice the number of edges, because each edge connects two vertices and is counted exactly twice in the sum.\n$$2E = \\sum_{i=1}^{V} \\deg(v_i)$$\n\nEquating the two expressions:\n$$2E = 3V \\implies E = \\frac{3}{2}V$$\n\n**2. Substitute into Euler's Formula**\nWe start with Euler's formula proven in Part 1:\n$$V - E + F = 2$$\n\nSubstitute $E = \\frac{3}{2}V$ into the equation:\n$$V - \\frac{3}{2}V + F = 2$$\n\nSimplify the terms with $V$:\n$$-\\frac{1}{2}V + F = 2$$\n\n**3. Final Formula**\nTo express the relationship cleanly, we can solve for $V$ in terms of $F$:\n$$\\frac{1}{2}V = F - 2$$\n$$V = 2F - 4$$\n\nAlternatively, we can write it as $2F - V = 4$.\n\n### Final Answer\n\n1.  **Proof**: The relation $V - E + F = 2$ is proven by mapping the polytope to a connected planar graph and using induction on the number of faces.\n2.  **Relation**: For a simple 3-dimensional convex polytope, the relationship between the number of vertices and faces is:\n    $$V = 2F - 4$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of differential geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within differential geometry\nDifferential geometry is a broad field that includes the study of curves and surfaces, Riemannian geometry, and more. A suitable topic could involve the properties of curves or surfaces, such as curvature, geodesics, or the application of differential geometry to other areas like physics.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the curvature of a surface. A classic result in differential geometry is the Theorema Egregium of Gauss, which states that the Gaussian curvature of a surface is invariant under isometric deformations. A challenging problem could involve calculating or utilizing this curvature.\n\n## Step 4: Construct the problem statement\nTo create a problem, let's consider a specific surface and ask a question about its geometric properties. For example, we could examine the surface given by $z = x^2 + y^2$ and ask to compute its Gaussian curvature at a given point.\n\n## Step 5: Write the problem statement\nLet's define the problem: \"Let $S$ be the surface given by $z = x^2 + y^2$. Compute the Gaussian curvature $K$ of $S$ at the point $(1,1,2)$.\"\n\n## Step 6: Provide the solution\nTo solve this, we first need to parameterize the surface. The surface $S$ can be parameterized by $\\vec{r}(x,y) = (x, y, x^2 + y^2)$. The Gaussian curvature $K$ can be found using the formula $K = \\frac{LN - M^2}{EG - F^2}$, where $E, F, G$ are coefficients of the first fundamental form, and $L, M, N$ are coefficients of the second fundamental form.\n\n## Step 7: Calculate the first and second fundamental forms\nFirst, compute $\\vec{r}_x = (1, 0, 2x)$ and $\\vec{r}_y = (0, 1, 2y)$. Then, $E = \\vec{r}_x \\cdot \\vec{r}_x = 1 + 4x^2$, $F = \\vec{r}_x \\cdot \\vec{r}_y = 4xy$, and $G = \\vec{r}_y \\cdot \\vec{r}_y = 1 + 4y^2$. The normal vector $\\vec{n} = \\frac{\\vec{r}_x \\times \\vec{r}_y}{\\|\\vec{r}_x \\times \\vec{r}_y\\|}$, and $\\vec{r}_x \\times \\vec{r}_y = (-2x, -2y, 1)$, so $\\|\\vec{r}_x \\times \\vec{r}_y\\| = \\sqrt{4x^2 + 4y^2 + 1}$. Thus, $\\vec{n} = \\frac{1}{\\sqrt{4x^2 + 4y^2 + 1}}(-2x, -2y, 1)$.\n\n## Step 8: Continue with the calculation of $L, M, N$\n$L = \\vec{r}_{xx} \\cdot \\vec{n}$, $M = \\vec{r}_{xy} \\cdot \\vec{n}$, and $N = \\vec{r}_{yy} \\cdot \\vec{n}$. We have $\\vec{r}_{xx} = (0, 0, 2)$, $\\vec{r}_{xy} = (0, 0, 0)$, and $\\vec{r}_{yy} = (0, 0, 2)$. So, $L = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}}$, $M = 0$, and $N = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}}$.\n\n## Step 9: Evaluate $K$ at $(1,1,2)$\nAt $(1,1,2)$, $x = 1$, $y = 1$, so $E = 5$, $F = 4$, $G = 5$, $L = \\frac{2}{3}$, $M = 0$, and $N = \\frac{2}{3}$. Thus, $EG - F^2 = 25 - 16 = 9$ and $LN - M^2 = \\frac{4}{9}$.\n\n## Step 10: Calculate $K$\n$K = \\frac{LN - M^2}{EG - F^2} = \\frac{\\frac{4}{9}}{9} = \\frac{4}{81}$.\n\nThe final answer is: \n\nLet $S$ be the surface given by $z = x^2 + y^2$. Compute the Gaussian curvature $K$ of $S$ at the point $(1,1,2)$.",
    "run_id": "37",
    "outer_attempt": 1,
    "topic_slug": "differential_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete solution to the problem.\n\n### Problem Statement\nLet $S$ be the surface defined by the equation $z = x^2 + y^2$. Compute the Gaussian curvature $K$ of $S$ at the point $(1,1,2)$.\n\n### Solution\n\nTo find the Gaussian curvature $K$, we will:\n1.  Parametrize the surface $S$.\n2.  Calculate the coefficients of the First Fundamental Form ($E, F, G$).\n3.  Calculate the unit normal vector $\\mathbf{n}$.\n4.  Calculate the coefficients of the Second Fundamental Form ($L, M, N$).\n5.  Apply the formula for Gaussian curvature and evaluate at the given point.\n\n#### 1. Parametrization\nThe surface is given as the graph of a function $f(x,y) = x^2 + y^2$. We can parametrize $S$ using $x$ and $y$ as parameters:\n$$ \\mathbf{r}(x,y) = (x, y, x^2 + y^2) $$\nThe point of interest is $(1,1,2)$, which corresponds to the parameters $x=1$ and $y=1$.\n\n#### 2. First Fundamental Form\nWe compute the first-order partial derivatives of $\\mathbf{r}$:\n$$ \\mathbf{r}_x = \\frac{\\partial \\mathbf{r}}{\\partial x} = (1, 0, 2x) $$\n$$ \\mathbf{r}_y = \\frac{\\partial \\mathbf{r}}{\\partial y} = (0, 1, 2y) $$\n\nThe coefficients of the First Fundamental Form are given by the dot products:\n$$ E = \\mathbf{r}_x \\cdot \\mathbf{r}_x = 1^2 + 0^2 + (2x)^2 = 1 + 4x^2 $$\n$$ F = \\mathbf{r}_x \\cdot \\mathbf{r}_y = 1(0) + 0(1) + (2x)(2y) = 4xy $$\n$$ G = \\mathbf{r}_y \\cdot \\mathbf{r}_y = 0^2 + 1^2 + (2y)^2 = 1 + 4y^2 $$\n\nEvaluating these at the point $(x,y) = (1,1)$:\n$$ E = 1 + 4(1)^2 = 5 $$\n$$ F = 4(1)(1) = 4 $$\n$$ G = 1 + 4(1)^2 = 5 $$\n\nThe determinant of the First Fundamental Form is:\n$$ EG - F^2 = (5)(5) - (4)^2 = 25 - 16 = 9 $$\n\n#### 3. Unit Normal Vector\nTo find the unit normal vector $\\mathbf{n}$, we first compute the cross product $\\mathbf{r}_x \\times \\mathbf{r}_y$:\n$$ \\mathbf{r}_x \\times \\mathbf{r}_y = \\begin{vmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ 1 & 0 & 2x \\\\ 0 & 1 & 2y \\end{vmatrix} = (-2x)\\mathbf{i} - (2y)\\mathbf{j} + (1)\\mathbf{k} = (-2x, -2y, 1) $$\n\nNext, we find the magnitude of this vector:\n$$ \\|\\mathbf{r}_x \\times \\mathbf{r}_y\\| = \\sqrt{(-2x)^2 + (-2y)^2 + 1^2} = \\sqrt{4x^2 + 4y^2 + 1} $$\n\nAt the point $(1,1)$:\n$$ \\|\\mathbf{r}_x \\times \\mathbf{r}_y\\| = \\sqrt{4(1)^2 + 4(1)^2 + 1} = \\sqrt{9} = 3 $$\n\nThus, the unit normal vector at $(1,1)$ is:\n$$ \\mathbf{n} = \\frac{1}{3}(-2, -2, 1) $$\n\n#### 4. Second Fundamental Form\nWe compute the second-order partial derivatives of $\\mathbf{r}$:\n$$ \\mathbf{r}_{xx} = (0, 0, 2) $$\n$$ \\mathbf{r}_{xy} = (0, 0, 0) $$\n$$ \\mathbf{r}_{yy} = (0, 0, 2) $$\n\nThe coefficients of the Second Fundamental Form are the projections of these second derivatives onto the normal vector $\\mathbf{n}$. Using the values at $(1,1)$:\n\n$$ L = \\mathbf{r}_{xx} \\cdot \\mathbf{n} = (0, 0, 2) \\cdot \\frac{1}{3}(-2, -2, 1) = \\frac{1}{3}(0 + 0 + 2) = \\frac{2}{3} $$\n$$ M = \\mathbf{r}_{xy} \\cdot \\mathbf{n} = (0, 0, 0) \\cdot \\mathbf{n} = 0 $$\n$$ N = \\mathbf{r}_{yy} \\cdot \\mathbf{n} = (0, 0, 2) \\cdot \\frac{1}{3}(-2, -2, 1) = \\frac{1}{3}(0 + 0 + 2) = \\frac{2}{3} $$\n\nThe determinant of the Second Fundamental Form is:\n$$ LN - M^2 = \\left(\\frac{2}{3}\\right)\\left(\\frac{2}{3}\\right) - 0^2 = \\frac{4}{9} $$\n\n#### 5. Gaussian Curvature Calculation\nThe Gaussian curvature $K$ is the ratio of the determinants of the two fundamental forms:\n$$ K = \\frac{LN - M^2}{EG - F^2} $$\n\nSubstituting the values we calculated:\n$$ K = \\frac{4/9}{9} = \\frac{4}{9 \\cdot 9} = \\frac{4}{81} $$\n\n### Final Answer\nThe Gaussian curvature of the surface $S$ at the point $(1,1,2)$ is $\\boxed{\\frac{4}{81}}$.",
        "raw_answer": "Here is the complete solution to the problem.\n\n### Problem Statement\nLet $S$ be the surface defined by the equation $z = x^2 + y^2$. Compute the Gaussian curvature $K$ of $S$ at the point $(1,1,2)$.\n\n### Solution\n\nTo find the Gaussian curvature $K$, we will:\n1.  Parametrize the surface $S$.\n2.  Calculate the coefficients of the First Fundamental Form ($E, F, G$).\n3.  Calculate the unit normal vector $\\mathbf{n}$.\n4.  Calculate the coefficients of the Second Fundamental Form ($L, M, N$).\n5.  Apply the formula for Gaussian curvature and evaluate at the given point.\n\n#### 1. Parametrization\nThe surface is given as the graph of a function $f(x,y) = x^2 + y^2$. We can parametrize $S$ using $x$ and $y$ as parameters:\n$$ \\mathbf{r}(x,y) = (x, y, x^2 + y^2) $$\nThe point of interest is $(1,1,2)$, which corresponds to the parameters $x=1$ and $y=1$.\n\n#### 2. First Fundamental Form\nWe compute the first-order partial derivatives of $\\mathbf{r}$:\n$$ \\mathbf{r}_x = \\frac{\\partial \\mathbf{r}}{\\partial x} = (1, 0, 2x) $$\n$$ \\mathbf{r}_y = \\frac{\\partial \\mathbf{r}}{\\partial y} = (0, 1, 2y) $$\n\nThe coefficients of the First Fundamental Form are given by the dot products:\n$$ E = \\mathbf{r}_x \\cdot \\mathbf{r}_x = 1^2 + 0^2 + (2x)^2 = 1 + 4x^2 $$\n$$ F = \\mathbf{r}_x \\cdot \\mathbf{r}_y = 1(0) + 0(1) + (2x)(2y) = 4xy $$\n$$ G = \\mathbf{r}_y \\cdot \\mathbf{r}_y = 0^2 + 1^2 + (2y)^2 = 1 + 4y^2 $$\n\nEvaluating these at the point $(x,y) = (1,1)$:\n$$ E = 1 + 4(1)^2 = 5 $$\n$$ F = 4(1)(1) = 4 $$\n$$ G = 1 + 4(1)^2 = 5 $$\n\nThe determinant of the First Fundamental Form is:\n$$ EG - F^2 = (5)(5) - (4)^2 = 25 - 16 = 9 $$\n\n#### 3. Unit Normal Vector\nTo find the unit normal vector $\\mathbf{n}$, we first compute the cross product $\\mathbf{r}_x \\times \\mathbf{r}_y$:\n$$ \\mathbf{r}_x \\times \\mathbf{r}_y = \\begin{vmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ 1 & 0 & 2x \\\\ 0 & 1 & 2y \\end{vmatrix} = (-2x)\\mathbf{i} - (2y)\\mathbf{j} + (1)\\mathbf{k} = (-2x, -2y, 1) $$\n\nNext, we find the magnitude of this vector:\n$$ \\|\\mathbf{r}_x \\times \\mathbf{r}_y\\| = \\sqrt{(-2x)^2 + (-2y)^2 + 1^2} = \\sqrt{4x^2 + 4y^2 + 1} $$\n\nAt the point $(1,1)$:\n$$ \\|\\mathbf{r}_x \\times \\mathbf{r}_y\\| = \\sqrt{4(1)^2 + 4(1)^2 + 1} = \\sqrt{9} = 3 $$\n\nThus, the unit normal vector at $(1,1)$ is:\n$$ \\mathbf{n} = \\frac{1}{3}(-2, -2, 1) $$\n\n#### 4. Second Fundamental Form\nWe compute the second-order partial derivatives of $\\mathbf{r}$:\n$$ \\mathbf{r}_{xx} = (0, 0, 2) $$\n$$ \\mathbf{r}_{xy} = (0, 0, 0) $$\n$$ \\mathbf{r}_{yy} = (0, 0, 2) $$\n\nThe coefficients of the Second Fundamental Form are the projections of these second derivatives onto the normal vector $\\mathbf{n}$. Using the values at $(1,1)$:\n\n$$ L = \\mathbf{r}_{xx} \\cdot \\mathbf{n} = (0, 0, 2) \\cdot \\frac{1}{3}(-2, -2, 1) = \\frac{1}{3}(0 + 0 + 2) = \\frac{2}{3} $$\n$$ M = \\mathbf{r}_{xy} \\cdot \\mathbf{n} = (0, 0, 0) \\cdot \\mathbf{n} = 0 $$\n$$ N = \\mathbf{r}_{yy} \\cdot \\mathbf{n} = (0, 0, 2) \\cdot \\frac{1}{3}(-2, -2, 1) = \\frac{1}{3}(0 + 0 + 2) = \\frac{2}{3} $$\n\nThe determinant of the Second Fundamental Form is:\n$$ LN - M^2 = \\left(\\frac{2}{3}\\right)\\left(\\frac{2}{3}\\right) - 0^2 = \\frac{4}{9} $$\n\n#### 5. Gaussian Curvature Calculation\nThe Gaussian curvature $K$ is the ratio of the determinants of the two fundamental forms:\n$$ K = \\frac{LN - M^2}{EG - F^2} $$\n\nSubstituting the values we calculated:\n$$ K = \\frac{4/9}{9} = \\frac{4}{9 \\cdot 9} = \\frac{4}{81} $$\n\n### Final Answer\nThe Gaussian curvature of the surface $S$ at the point $(1,1,2)$ is $\\boxed{\\frac{4}{81}}$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of general topology, along with a complete solution, following specific guidelines.\n[/QUESTION]",
    "run_id": "38",
    "outer_attempt": 1,
    "topic_slug": "general_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is a challenging problem in general topology concerning metrization theorems for compact spaces, followed by a complete and rigorous solution.\n\n***\n\n# Problem: Metrizability of Compact Hausdorff Spaces via the Diagonal\n\n**Problem Statement:**\nLet $X$ be a compact Hausdorff topological space. Let $\\Delta = \\{(x, x) \\in X \\times X \\mid x \\in X\\}$ denote the diagonal subset of the product space $X \\times X$.\n\nProve that $X$ is metrizable if and only if $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n\n(Note: A set is a $G_\\delta$ set if it can be written as a countable intersection of open sets.)\n\n***\n\n# Solution\n\nWe must prove the equivalence of two statements for a compact Hausdorff space $X$:\n1. $X$ is metrizable.\n2. The diagonal $\\Delta$ is a $G_\\delta$ set in $X \\times X$ (with the product topology).\n\n## Part 1: Forward Implication ($\\implies$)\n\n**Hypothesis:** Assume $X$ is metrizable.\n**Goal:** Show that $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n\n1.  Since $X$ is metrizable, let $d: X \\times X \\to [0, \\infty)$ be a metric that induces the topology of $X$.\n2.  The metric function $d$ is continuous on $X \\times X$ (with respect to the product topology induced by the metric on $X$).\n3.  The diagonal $\\Delta$ is precisely the zero set of the metric:\n    $$ \\Delta = \\{(x, y) \\in X \\times X \\mid d(x, y) = 0 \\} = d^{-1}(\\{0\\}). $$\n4.  Consider the sets $U_n$ defined by:\n    $$ U_n = \\{(x, y) \\in X \\times X \\mid d(x, y) < \\frac{1}{n} \\} = d^{-1}\\left(\\left[0, \\frac{1}{n}\\right)\\right). $$\n5.  Since $d$ is continuous and $[0, 1/n)$ is open in $[0, \\infty)$, each set $U_n$ is open in $X \\times X$.\n6.  The intersection of these sets is:\n    $$ \\bigcap_{n=1}^{\\infty} U_n = \\{(x, y) \\in X \\times X \\mid d(x, y) < \\frac{1}{n} \\text{ for all } n \\in \\mathbb{Z}^+\\} = \\{(x, y) \\mid d(x, y) = 0\\} = \\Delta. $$\n7.  Therefore, $\\Delta$ is the intersection of a countable collection of open sets. By definition, $\\Delta$ is a $G_\\delta$ set.\n\nThis direction holds for any metrizable space (compactness is not required here).\n\n## Part 2: Reverse Implication ($\\impliedby$)\n\n**Hypothesis:** Assume $X$ is compact Hausdorff and $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n**Goal:** Show that $X$ is metrizable.\n\n**Strategy:** A standard metrization theorem states that a compact Hausdorff space is metrizable if and only if it is second-countable. Since we are given that $X$ is compact Hausdorff, it suffices to prove that $X$ is second-countable (i.e., has a countable basis).\n\n### Step 2.1: Properties of the Diagonal and Covers\n\n1.  Since $\\Delta$ is a $G_\\delta$ set, there exist open sets $W_1, W_2, \\dots$ in $X \\times X$ such that $\\Delta = \\bigcap_{n=1}^\\infty W_n$.\n2.  Since $X$ is Hausdorff, $\\Delta$ is closed in $X \\times X$.\n3.  Since $X$ is compact Hausdorff, the product space $X \\times X$ is also compact Hausdorff.\n4.  Compact Hausdorff spaces are normal ($T_4$). In a normal space, for any closed $G_\\delta$ set $F$, there exists a sequence of open sets $G_n$ such that $F = \\bigcap G_n$ and $\\overline{G_{n+1}} \\subseteq G_n$ for all $n$.\n    *Justification:* We have $\\Delta = \\bigcap W_n$. Since $X \\times X$ is normal, we can use Urysohn's Lemma or simple normality properties to construct the sequence $G_n$ inductively. Let $G_1 = W_1$. Since $\\Delta \\subseteq G_1$ is closed and $G_1$ is open, normality implies there exists an open $V$ such that $\\Delta \\subseteq V \\subseteq \\overline{V} \\subseteq G_1$. Intersect with $W_2$ to maintain the limit, i.e., set $G_2 = V \\cap W_2$. Proceeding inductively, we construct a sequence $G_n$ such that $\\Delta = \\bigcap_{n=1}^\\infty G_n$ and $\\overline{G_{n+1}} \\subseteq G_n$.\n\n### Step 2.2: Constructing Countable Covers of $X$\n\nFor each $n \\in \\mathbb{Z}^+$, we construct a finite open cover $\\mathcal{U}_n$ of $X$ with a specific \"smallness\" property relative to $G_n$.\n\n1.  Fix $n$. For each $x \\in X$, we have $(x, x) \\in \\Delta \\subseteq G_n$.\n2.  Since $G_n$ is open in the product topology, there exists an open neighborhood $V_x$ of $x$ in $X$ such that $V_x \\times V_x \\subseteq G_n$.\n3.  The collection $\\{V_x \\mid x \\in X\\}$ covers $X$. Since $X$ is compact, there exists a finite subcover. Let us denote this finite cover by $\\mathcal{U}_n$.\n4.  Property of $\\mathcal{U}_n$: For every $U \\in \\mathcal{U}_n$, $U \\times U \\subseteq G_n$.\n\nLet $\\mathcal{B} = \\bigcup_{n=1}^\\infty \\mathcal{U}_n$. Since each $\\mathcal{U}_n$ is finite, $\\mathcal{B}$ is a countable collection of open sets.\n\n### Step 2.3: Proving $\\mathcal{B}$ forms a Basis\n\nWe claim that for every $x \\in X$ and every open neighborhood $O$ of $x$, there exists a set $U \\in \\mathcal{B}$ such that $x \\in U \\subseteq O$. If this holds, $\\mathcal{B}$ is a basis for $X$.\n\nLet's define the star of $x$ with respect to a cover $\\mathcal{C}$ as $St(x, \\mathcal{C}) = \\bigcup \\{ U \\in \\mathcal{C} \\mid x \\in U \\}$.\n\n**Claim:** The collection $\\{ St(x, \\mathcal{U}_n) \\}_{n \\ge 1}$ forms a neighborhood basis for $x$. That is, for any open $O$ containing $x$, there exists $N$ such that $St(x, \\mathcal{U}_N) \\subseteq O$.\n\n**Proof of Claim (by contradiction):**\n1.  Suppose there exists an open neighborhood $O$ of $x$ such that for all $n$, $St(x, \\mathcal{U}_n) \\not\\subseteq O$.\n2.  Then for each $n$, there exists a point $y_n \\in St(x, \\mathcal{U}_n) \\setminus O$.\n3.  The sequence $(y_n)$ lies in the set $X \\setminus O$, which is closed in the compact space $X$. Therefore, $X \\setminus O$ is compact.\n4.  The sequence $(y_n)$ must have a cluster point $z \\in X \\setminus O$.\n5.  Since $x \\in O$ and $z \\in X \\setminus O$, we have $x \\neq z$. Thus $(x, z) \\notin \\Delta$.\n6.  Consider the relation established by the covers. Since $y_n \\in St(x, \\mathcal{U}_n)$, there exists some $U \\in \\mathcal{U}_n$ such that $x \\in U$ and $y_n \\in U$.\n7.  By the construction of $\\mathcal{U}_n$, $U \\times U \\subseteq G_n$. Therefore, $(x, y_n) \\in G_n$.\n8.  Now, fix an integer $k$. For all $n \\geq k$, we have $(x, y_n) \\in G_n \\subseteq G_k$.\n9.  Since $z$ is a cluster point of $(y_n)$, the point $(x, z)$ is a cluster point of the sequence $((x, y_n))$ in $X \\times X$.\n10. Since all terms $(x, y_n)$ for $n \\ge k$ lie in $G_k$, the cluster point $(x, z)$ must lie in the closure $\\overline{G_k}$.\n11. Recall our construction in Step 2.1: $\\overline{G_{k+1}} \\subseteq G_k$.\n12. Since $(x, z) \\in \\overline{G_{k+1}}$ (applying the logic from step 10 to $k+1$), we have $(x, z) \\in G_k$.\n13. This holds for *all* $k$. Therefore, $(x, z) \\in \\bigcap_{k=1}^\\infty G_k = \\Delta$.\n14. This implies $x = z$.\n15. This contradicts the fact that $x \\in O$ and $z \\in X \\setminus O$.\n\nTherefore, the assumption was false. There exists some $N$ such that $St(x, \\mathcal{U}_N) \\subseteq O$.\n\n**Conclusion of Step 2.3:**\nSince $St(x, \\mathcal{U}_N)$ is a union of finitely many sets from $\\mathcal{U}_N$ (all of which contain $x$), any single $U \\in \\mathcal{U}_N$ containing $x$ satisfies $x \\in U \\subseteq St(x, \\mathcal{U}_N) \\subseteq O$. Since $U \\in \\mathcal{U}_N \\subset \\mathcal{B}$, we have found a basis element inside $O$ containing $x$. Thus, $\\mathcal{B}$ is a countable basis for the topology of $X$.\n\n### Step 2.4: Final Conclusion\n\n1.  $X$ is a compact Hausdorff space.\n2.  We have shown that if $\\Delta$ is a $G_\\delta$ set, then $X$ admits a countable basis (is second-countable).\n3.  By the Urysohn Metrization Theorem (or the specific version for compact spaces: A compact Hausdorff space is metrizable iff it is second-countable), $X$ is metrizable.\n\nThus, both directions are proven.\n\n**Q.E.D.**",
        "raw_answer": "Here is a challenging problem in general topology concerning metrization theorems for compact spaces, followed by a complete and rigorous solution.\n\n***\n\n# Problem: Metrizability of Compact Hausdorff Spaces via the Diagonal\n\n**Problem Statement:**\nLet $X$ be a compact Hausdorff topological space. Let $\\Delta = \\{(x, x) \\in X \\times X \\mid x \\in X\\}$ denote the diagonal subset of the product space $X \\times X$.\n\nProve that $X$ is metrizable if and only if $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n\n(Note: A set is a $G_\\delta$ set if it can be written as a countable intersection of open sets.)\n\n***\n\n# Solution\n\nWe must prove the equivalence of two statements for a compact Hausdorff space $X$:\n1. $X$ is metrizable.\n2. The diagonal $\\Delta$ is a $G_\\delta$ set in $X \\times X$ (with the product topology).\n\n## Part 1: Forward Implication ($\\implies$)\n\n**Hypothesis:** Assume $X$ is metrizable.\n**Goal:** Show that $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n\n1.  Since $X$ is metrizable, let $d: X \\times X \\to [0, \\infty)$ be a metric that induces the topology of $X$.\n2.  The metric function $d$ is continuous on $X \\times X$ (with respect to the product topology induced by the metric on $X$).\n3.  The diagonal $\\Delta$ is precisely the zero set of the metric:\n    $$ \\Delta = \\{(x, y) \\in X \\times X \\mid d(x, y) = 0 \\} = d^{-1}(\\{0\\}). $$\n4.  Consider the sets $U_n$ defined by:\n    $$ U_n = \\{(x, y) \\in X \\times X \\mid d(x, y) < \\frac{1}{n} \\} = d^{-1}\\left(\\left[0, \\frac{1}{n}\\right)\\right). $$\n5.  Since $d$ is continuous and $[0, 1/n)$ is open in $[0, \\infty)$, each set $U_n$ is open in $X \\times X$.\n6.  The intersection of these sets is:\n    $$ \\bigcap_{n=1}^{\\infty} U_n = \\{(x, y) \\in X \\times X \\mid d(x, y) < \\frac{1}{n} \\text{ for all } n \\in \\mathbb{Z}^+\\} = \\{(x, y) \\mid d(x, y) = 0\\} = \\Delta. $$\n7.  Therefore, $\\Delta$ is the intersection of a countable collection of open sets. By definition, $\\Delta$ is a $G_\\delta$ set.\n\nThis direction holds for any metrizable space (compactness is not required here).\n\n## Part 2: Reverse Implication ($\\impliedby$)\n\n**Hypothesis:** Assume $X$ is compact Hausdorff and $\\Delta$ is a $G_\\delta$ set in $X \\times X$.\n**Goal:** Show that $X$ is metrizable.\n\n**Strategy:** A standard metrization theorem states that a compact Hausdorff space is metrizable if and only if it is second-countable. Since we are given that $X$ is compact Hausdorff, it suffices to prove that $X$ is second-countable (i.e., has a countable basis).\n\n### Step 2.1: Properties of the Diagonal and Covers\n\n1.  Since $\\Delta$ is a $G_\\delta$ set, there exist open sets $W_1, W_2, \\dots$ in $X \\times X$ such that $\\Delta = \\bigcap_{n=1}^\\infty W_n$.\n2.  Since $X$ is Hausdorff, $\\Delta$ is closed in $X \\times X$.\n3.  Since $X$ is compact Hausdorff, the product space $X \\times X$ is also compact Hausdorff.\n4.  Compact Hausdorff spaces are normal ($T_4$). In a normal space, for any closed $G_\\delta$ set $F$, there exists a sequence of open sets $G_n$ such that $F = \\bigcap G_n$ and $\\overline{G_{n+1}} \\subseteq G_n$ for all $n$.\n    *Justification:* We have $\\Delta = \\bigcap W_n$. Since $X \\times X$ is normal, we can use Urysohn's Lemma or simple normality properties to construct the sequence $G_n$ inductively. Let $G_1 = W_1$. Since $\\Delta \\subseteq G_1$ is closed and $G_1$ is open, normality implies there exists an open $V$ such that $\\Delta \\subseteq V \\subseteq \\overline{V} \\subseteq G_1$. Intersect with $W_2$ to maintain the limit, i.e., set $G_2 = V \\cap W_2$. Proceeding inductively, we construct a sequence $G_n$ such that $\\Delta = \\bigcap_{n=1}^\\infty G_n$ and $\\overline{G_{n+1}} \\subseteq G_n$.\n\n### Step 2.2: Constructing Countable Covers of $X$\n\nFor each $n \\in \\mathbb{Z}^+$, we construct a finite open cover $\\mathcal{U}_n$ of $X$ with a specific \"smallness\" property relative to $G_n$.\n\n1.  Fix $n$. For each $x \\in X$, we have $(x, x) \\in \\Delta \\subseteq G_n$.\n2.  Since $G_n$ is open in the product topology, there exists an open neighborhood $V_x$ of $x$ in $X$ such that $V_x \\times V_x \\subseteq G_n$.\n3.  The collection $\\{V_x \\mid x \\in X\\}$ covers $X$. Since $X$ is compact, there exists a finite subcover. Let us denote this finite cover by $\\mathcal{U}_n$.\n4.  Property of $\\mathcal{U}_n$: For every $U \\in \\mathcal{U}_n$, $U \\times U \\subseteq G_n$.\n\nLet $\\mathcal{B} = \\bigcup_{n=1}^\\infty \\mathcal{U}_n$. Since each $\\mathcal{U}_n$ is finite, $\\mathcal{B}$ is a countable collection of open sets.\n\n### Step 2.3: Proving $\\mathcal{B}$ forms a Basis\n\nWe claim that for every $x \\in X$ and every open neighborhood $O$ of $x$, there exists a set $U \\in \\mathcal{B}$ such that $x \\in U \\subseteq O$. If this holds, $\\mathcal{B}$ is a basis for $X$.\n\nLet's define the star of $x$ with respect to a cover $\\mathcal{C}$ as $St(x, \\mathcal{C}) = \\bigcup \\{ U \\in \\mathcal{C} \\mid x \\in U \\}$.\n\n**Claim:** The collection $\\{ St(x, \\mathcal{U}_n) \\}_{n \\ge 1}$ forms a neighborhood basis for $x$. That is, for any open $O$ containing $x$, there exists $N$ such that $St(x, \\mathcal{U}_N) \\subseteq O$.\n\n**Proof of Claim (by contradiction):**\n1.  Suppose there exists an open neighborhood $O$ of $x$ such that for all $n$, $St(x, \\mathcal{U}_n) \\not\\subseteq O$.\n2.  Then for each $n$, there exists a point $y_n \\in St(x, \\mathcal{U}_n) \\setminus O$.\n3.  The sequence $(y_n)$ lies in the set $X \\setminus O$, which is closed in the compact space $X$. Therefore, $X \\setminus O$ is compact.\n4.  The sequence $(y_n)$ must have a cluster point $z \\in X \\setminus O$.\n5.  Since $x \\in O$ and $z \\in X \\setminus O$, we have $x \\neq z$. Thus $(x, z) \\notin \\Delta$.\n6.  Consider the relation established by the covers. Since $y_n \\in St(x, \\mathcal{U}_n)$, there exists some $U \\in \\mathcal{U}_n$ such that $x \\in U$ and $y_n \\in U$.\n7.  By the construction of $\\mathcal{U}_n$, $U \\times U \\subseteq G_n$. Therefore, $(x, y_n) \\in G_n$.\n8.  Now, fix an integer $k$. For all $n \\geq k$, we have $(x, y_n) \\in G_n \\subseteq G_k$.\n9.  Since $z$ is a cluster point of $(y_n)$, the point $(x, z)$ is a cluster point of the sequence $((x, y_n))$ in $X \\times X$.\n10. Since all terms $(x, y_n)$ for $n \\ge k$ lie in $G_k$, the cluster point $(x, z)$ must lie in the closure $\\overline{G_k}$.\n11. Recall our construction in Step 2.1: $\\overline{G_{k+1}} \\subseteq G_k$.\n12. Since $(x, z) \\in \\overline{G_{k+1}}$ (applying the logic from step 10 to $k+1$), we have $(x, z) \\in G_k$.\n13. This holds for *all* $k$. Therefore, $(x, z) \\in \\bigcap_{k=1}^\\infty G_k = \\Delta$.\n14. This implies $x = z$.\n15. This contradicts the fact that $x \\in O$ and $z \\in X \\setminus O$.\n\nTherefore, the assumption was false. There exists some $N$ such that $St(x, \\mathcal{U}_N) \\subseteq O$.\n\n**Conclusion of Step 2.3:**\nSince $St(x, \\mathcal{U}_N)$ is a union of finitely many sets from $\\mathcal{U}_N$ (all of which contain $x$), any single $U \\in \\mathcal{U}_N$ containing $x$ satisfies $x \\in U \\subseteq St(x, \\mathcal{U}_N) \\subseteq O$. Since $U \\in \\mathcal{U}_N \\subset \\mathcal{B}$, we have found a basis element inside $O$ containing $x$. Thus, $\\mathcal{B}$ is a countable basis for the topology of $X$.\n\n### Step 2.4: Final Conclusion\n\n1.  $X$ is a compact Hausdorff space.\n2.  We have shown that if $\\Delta$ is a $G_\\delta$ set, then $X$ admits a countable basis (is second-countable).\n3.  By the Urysohn Metrization Theorem (or the specific version for compact spaces: A compact Hausdorff space is metrizable iff it is second-countable), $X$ is metrizable.\n\nThus, both directions are proven.\n\n**Q.E.D.**",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $X = S^1 \\vee S^1$ be the wedge sum of two circles, where the wedge point is $x_0$. Compute $\\pi_1(X, x_0)$.",
    "run_id": "39",
    "outer_attempt": 1,
    "topic_slug": "algebraic_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To compute the fundamental group $\\pi_1(X, x_0)$ of the wedge sum of two circles $X = S^1 \\vee S^1$, we will use the **Seifert-van Kampen Theorem**.\n\n### 1. Description of the Space\nLet the two circles be denoted by $C_1$ and $C_2$. The space $X$ is defined as the quotient of the disjoint union $C_1 \\sqcup C_2$ by identifying a point $p_1 \\in C_1$ with a point $p_2 \\in C_2$. Let $x_0$ denote this wedge point (the base point) in $X$. Thus, $X = C_1 \\cup C_2$ and $C_1 \\cap C_2 = \\{x_0\\}$.\n\n### 2. Choice of Open Sets\nTo apply the Seifert-van Kampen Theorem, we construct two open, path-connected subsets $U$ and $V$ of $X$ such that $X = U \\cup V$ and $U \\cap V$ is path-connected and contains $x_0$.\n\nLet $y_1 \\in C_1$ and $y_2 \\in C_2$ be points distinct from the base point $x_0$. We define the open sets as follows:\n- $U = X \\setminus \\{y_2\\}$\n- $V = X \\setminus \\{y_1\\}$\n\n**Analysis of $U$:**\nThe set $U$ consists of the entire circle $C_1$ and the circle $C_2$ with the point $y_2$ removed. The space $C_2 \\setminus \\{y_2\\}$ is homeomorphic to an open interval, which is contractible. Therefore, $U$ deformation retracts onto $C_1$.\nSince $C_1$ is homeomorphic to $S^1$, the fundamental group of $U$ is:\n$$ \\pi_1(U, x_0) \\cong \\pi_1(S^1, x_0) \\cong \\mathbb{Z} $$\nLet $\\alpha$ be the generator of this group, represented by a loop traversing $C_1$ once.\n\n**Analysis of $V$:**\nSimilarly, the set $V$ consists of the circle $C_2$ and the circle $C_1$ with the point $y_1$ removed. $C_1 \\setminus \\{y_1\\}$ is contractible. Therefore, $V$ deformation retracts onto $C_2$.\nThe fundamental group of $V$ is:\n$$ \\pi_1(V, x_0) \\cong \\pi_1(S^1, x_0) \\cong \\mathbb{Z} $$\nLet $\\beta$ be the generator of this group, represented by a loop traversing $C_2$ once.\n\n**Analysis of $U \\cap V$:**\nThe intersection is $U \\cap V = X \\setminus \\{y_1, y_2\\}$. This set consists of $C_1 \\setminus \\{y_1\\}$ and $C_2 \\setminus \\{y_2\\}$ joined at $x_0$. Since both components are contractible (homeomorphic to open intervals) and joined at a single point, the entire space $U \\cap V$ is contractible to the point $x_0$.\nTherefore, the fundamental group of the intersection is trivial:\n$$ \\pi_1(U \\cap V, x_0) \\cong \\{1\\} $$\n\n### 3. Application of the Seifert-van Kampen Theorem\nThe theorem states that $\\pi_1(X, x_0)$ is the free product of $\\pi_1(U, x_0)$ and $\\pi_1(V, x_0)$ amalgamated over $\\pi_1(U \\cap V, x_0)$.\n\n$$ \\pi_1(X, x_0) \\cong \\pi_1(U, x_0) *_{\\pi_1(U \\cap V, x_0)} \\pi_1(V, x_0) $$\n\nSubstituting the groups we found:\n$$ \\pi_1(X, x_0) \\cong \\mathbb{Z} *_{\\{1\\}} \\mathbb{Z} $$\n\nSince the amalgamation is over the trivial group, this reduces to the standard free product of the groups:\n$$ \\pi_1(X, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} $$\n\nThis is the free group on two generators. If we let $a$ denote the class of the loop around $C_1$ and $b$ denote the class of the loop around $C_2$, then $\\pi_1(X, x_0)$ consists of all reduced words formed by $a, b, a^{-1}, b^{-1}$.\n\n### Conclusion\n\nThe fundamental group of the wedge sum of two circles is the free group on two generators.\n\n$$ \\pi_1(S^1 \\vee S^1, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} \\cong F_2 $$",
        "raw_answer": "To compute the fundamental group $\\pi_1(X, x_0)$ of the wedge sum of two circles $X = S^1 \\vee S^1$, we will use the **Seifert-van Kampen Theorem**.\n\n### 1. Description of the Space\nLet the two circles be denoted by $C_1$ and $C_2$. The space $X$ is defined as the quotient of the disjoint union $C_1 \\sqcup C_2$ by identifying a point $p_1 \\in C_1$ with a point $p_2 \\in C_2$. Let $x_0$ denote this wedge point (the base point) in $X$. Thus, $X = C_1 \\cup C_2$ and $C_1 \\cap C_2 = \\{x_0\\}$.\n\n### 2. Choice of Open Sets\nTo apply the Seifert-van Kampen Theorem, we construct two open, path-connected subsets $U$ and $V$ of $X$ such that $X = U \\cup V$ and $U \\cap V$ is path-connected and contains $x_0$.\n\nLet $y_1 \\in C_1$ and $y_2 \\in C_2$ be points distinct from the base point $x_0$. We define the open sets as follows:\n- $U = X \\setminus \\{y_2\\}$\n- $V = X \\setminus \\{y_1\\}$\n\n**Analysis of $U$:**\nThe set $U$ consists of the entire circle $C_1$ and the circle $C_2$ with the point $y_2$ removed. The space $C_2 \\setminus \\{y_2\\}$ is homeomorphic to an open interval, which is contractible. Therefore, $U$ deformation retracts onto $C_1$.\nSince $C_1$ is homeomorphic to $S^1$, the fundamental group of $U$ is:\n$$ \\pi_1(U, x_0) \\cong \\pi_1(S^1, x_0) \\cong \\mathbb{Z} $$\nLet $\\alpha$ be the generator of this group, represented by a loop traversing $C_1$ once.\n\n**Analysis of $V$:**\nSimilarly, the set $V$ consists of the circle $C_2$ and the circle $C_1$ with the point $y_1$ removed. $C_1 \\setminus \\{y_1\\}$ is contractible. Therefore, $V$ deformation retracts onto $C_2$.\nThe fundamental group of $V$ is:\n$$ \\pi_1(V, x_0) \\cong \\pi_1(S^1, x_0) \\cong \\mathbb{Z} $$\nLet $\\beta$ be the generator of this group, represented by a loop traversing $C_2$ once.\n\n**Analysis of $U \\cap V$:**\nThe intersection is $U \\cap V = X \\setminus \\{y_1, y_2\\}$. This set consists of $C_1 \\setminus \\{y_1\\}$ and $C_2 \\setminus \\{y_2\\}$ joined at $x_0$. Since both components are contractible (homeomorphic to open intervals) and joined at a single point, the entire space $U \\cap V$ is contractible to the point $x_0$.\nTherefore, the fundamental group of the intersection is trivial:\n$$ \\pi_1(U \\cap V, x_0) \\cong \\{1\\} $$\n\n### 3. Application of the Seifert-van Kampen Theorem\nThe theorem states that $\\pi_1(X, x_0)$ is the free product of $\\pi_1(U, x_0)$ and $\\pi_1(V, x_0)$ amalgamated over $\\pi_1(U \\cap V, x_0)$.\n\n$$ \\pi_1(X, x_0) \\cong \\pi_1(U, x_0) *_{\\pi_1(U \\cap V, x_0)} \\pi_1(V, x_0) $$\n\nSubstituting the groups we found:\n$$ \\pi_1(X, x_0) \\cong \\mathbb{Z} *_{\\{1\\}} \\mathbb{Z} $$\n\nSince the amalgamation is over the trivial group, this reduces to the standard free product of the groups:\n$$ \\pi_1(X, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} $$\n\nThis is the free group on two generators. If we let $a$ denote the class of the loop around $C_1$ and $b$ denote the class of the loop around $C_2$, then $\\pi_1(X, x_0)$ consists of all reduced words formed by $a, b, a^{-1}, b^{-1}$.\n\n### Conclusion\n\nThe fundamental group of the wedge sum of two circles is the free group on two generators.\n\n$$ \\pi_1(S^1 \\vee S^1, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} \\cong F_2 $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Manifolds and cell complexes\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within the domain\nA suitable topic within \"Manifolds and cell complexes\" could involve the properties or constructions related to manifolds or cell complexes, such as their topology, geometry, or algebraic invariants.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the Euler characteristic of a manifold, which is a fundamental concept in algebraic topology that relates to both manifolds and cell complexes. The Euler characteristic is a topological invariant that can be computed using a cell decomposition of a manifold.\n\n## Step 4: Construct the problem statement\nConsider a 2-dimensional manifold $M$ that is homeomorphic to a sphere with $g$ handles (i.e., a surface of genus $g$). The task is to prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.\n\n## Step 5: Provide the problem statement in the required format\n\nLet $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles. Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.",
    "run_id": "40",
    "outer_attempt": 1,
    "topic_slug": "manifolds_and_cell_complexes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the comprehensive solution to the problem.\n\n### Problem Statement\nLet $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles (an orientable surface of genus $g$). Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.\n\n---\n\n### Solution\n\nTo prove this result, we will construct a specific cell decomposition (CW-complex structure) for the surface $M$ and calculate the Euler characteristic using the definition $\\chi(M) = V - E + F$, where $V, E,$ and $F$ correspond to the number of 0-cells (vertices), 1-cells (edges), and 2-cells (faces), respectively.\n\nWe treat the cases $g=0$ and $g \\geq 1$ separately to ensure rigor, although the formula holds for both.\n\n#### Case 1: The Sphere ($g=0$)\nA sphere with 0 handles is simply the 2-sphere, $S^2$.\nWe can compute its Euler characteristic using a standard triangulation, such as the boundary of a tetrahedron.\n1.  **Vertices ($V$)**: 4\n2.  **Edges ($E$)**: 6\n3.  **Faces ($F$)**: 4\n\nCalculating $\\chi(S^2)$:\n$$ \\chi(S^2) = V - E + F = 4 - 6 + 4 = 2 $$\nUsing the formula $2 - 2g$ with $g=0$:\n$$ 2 - 2(0) = 2 $$\nThe formula holds for $g=0$.\n\n#### Case 2: Surface of Genus $g \\geq 1$\nFor $g \\geq 1$, the surface $M$ can be constructed as a quotient space of a regular polygon. This is the **standard polygonal presentation** of an orientable surface.\n\n**1. The Polygonal Model**\nA surface of genus $g$ is homeomorphic to the quotient of a regular $4g$-sided polygon $P$ in the Euclidean plane. The edges of the polygon are identified in pairs according to the standard word $W$:\n$$ W = a_1 b_1 a_1^{-1} b_1^{-1} a_2 b_2 a_2^{-1} b_2^{-1} \\dots a_g b_g a_g^{-1} b_g^{-1} $$\nHere, each letter represents an edge of the polygon. The exponent $-1$ indicates that the edge is traversed in the direction opposite to the boundary orientation.\n\n**2. Cell Decomposition**\nWe define a CW-complex structure on $M$ induced by this identification:\n*   **Faces ($F$):** The interior of the polygon $P$ forms a single 2-cell. Thus, $F = 1$.\n*   **Edges ($E$):** The boundary of the polygon consists of $4g$ edges. The identification word pairs every edge $x$ with a corresponding edge $x^{-1}$. Since every edge is identified with exactly one other edge, the number of distinct 1-cells in the quotient is:\n    $$ E = \\frac{4g}{2} = 2g $$\n\n**3. Vertices ($V$):**\nWe must determine how the vertices of the polygon are identified. Let the vertices of the $4g$-gon be $v_0, v_1, \\dots, v_{4g-1}$ in counterclockwise order.\nConsider the $i$-th handle represented by the sequence of edges $a_i, b_i, a_i^{-1}, b_i^{-1}$. Let the vertices involved in this sequence locally be $p_0, p_1, p_2, p_3, p_4$ such that:\n*   $a_i$ connects $p_0 \\to p_1$\n*   $b_i$ connects $p_1 \\to p_2$\n*   $a_i^{-1}$ connects $p_2 \\to p_3$\n*   $b_i^{-1}$ connects $p_3 \\to p_4$\n\nThe identification of edges dictates the identification of their endpoints:\n1.  **Identify $a_i$ with $a_i^{-1}$:**\n    The edge $a_i$ (directed $p_0 \\to p_1$) is identified with $a_i^{-1}$ (which corresponds to the geometric edge $p_2 \\to p_3$ traversed backwards, i.e., $p_3 \\to p_2$).\n    Therefore, the start of $a_i$ is identified with the start of the traversal of $a_i^{-1}$, and the end with the end.\n    $$ p_0 \\sim p_3 \\quad \\text{and} \\quad p_1 \\sim p_2 $$\n\n2.  **Identify $b_i$ with $b_i^{-1}$:**\n    The edge $b_i$ (directed $p_1 \\to p_2$) is identified with $b_i^{-1}$ (geometric edge $p_3 \\to p_4$ traversed backwards, i.e., $p_4 \\to p_3$).\n    $$ p_1 \\sim p_4 \\quad \\text{and} \\quad p_2 \\sim p_3 $$\n\n**Analyzing the Equivalence Class:**\nCombining these identifications for the $i$-th group:\n*   From $a_i$: $p_1 \\sim p_2$ and $p_0 \\sim p_3$.\n*   From $b_i$: $p_2 \\sim p_3$ and $p_1 \\sim p_4$.\n*   Chaining these: $p_0 \\sim p_3 \\sim p_2 \\sim p_1 \\sim p_4$.\n\nThus, all vertices associated with the $i$-th handle ($p_0$ through $p_4$) are identified to a single point. Since $p_4$ is the starting vertex ($p_0$) of the $(i+1)$-th handle group (or wraps around to the start of the polygon if $i=g$), the equivalence relation propagates through all $g$ groups.\n\nConsequently, all $4g$ vertices of the polygon are identified to a single vertex in the quotient manifold.\n$$ V = 1 $$\n\n**4. Calculation**\nWe now compute the Euler characteristic $\\chi(M)$:\n$$ \\chi(M) = V - E + F $$\nSubstituting the values derived above ($V=1, E=2g, F=1$):\n$$ \\chi(M) = 1 - 2g + 1 $$\n$$ \\chi(M) = 2 - 2g $$\n\n### Alternative Approach: Connected Sums\nWe can also verify this result using the properties of the connected sum operation $\\#$.\nA surface of genus $g$ is the connected sum of $g$ tori: $M_g = T^2 \\# T^2 \\# \\dots \\# T^2$.\nThe Euler characteristic of a connected sum is given by:\n$$ \\chi(A \\# B) = \\chi(A) + \\chi(B) - 2 $$\nWe proceed by induction:\n1.  **Base Case ($g=1$):** For a torus $T^2$, we have the identification $aba^{-1}b^{-1}$. Here $V=1, E=2, F=1$, so $\\chi(T^2) = 1 - 2 + 1 = 0$.\n    Formula: $2 - 2(1) = 0$. (Verified)\n2.  **Inductive Step:** Assume $\\chi(M_{k}) = 2 - 2k$.\n    $$ M_{k+1} = M_k \\# T^2 $$\n    $$ \\chi(M_{k+1}) = \\chi(M_k) + \\chi(T^2) - 2 $$\n    $$ \\chi(M_{k+1}) = (2 - 2k) + 0 - 2 $$\n    $$ \\chi(M_{k+1}) = 2 - 2k - 2 = 2 - 2(k+1) $$\n\nThis confirms the result for all $g \\geq 1$.\n\n### Conclusion\nWe have shown through explicit cell decomposition and the connected sum formula that for a 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles, the Euler characteristic is:\n$$ \\chi(M) = 2 - 2g $$",
        "raw_answer": "Here is the comprehensive solution to the problem.\n\n### Problem Statement\nLet $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles (an orientable surface of genus $g$). Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.\n\n---\n\n### Solution\n\nTo prove this result, we will construct a specific cell decomposition (CW-complex structure) for the surface $M$ and calculate the Euler characteristic using the definition $\\chi(M) = V - E + F$, where $V, E,$ and $F$ correspond to the number of 0-cells (vertices), 1-cells (edges), and 2-cells (faces), respectively.\n\nWe treat the cases $g=0$ and $g \\geq 1$ separately to ensure rigor, although the formula holds for both.\n\n#### Case 1: The Sphere ($g=0$)\nA sphere with 0 handles is simply the 2-sphere, $S^2$.\nWe can compute its Euler characteristic using a standard triangulation, such as the boundary of a tetrahedron.\n1.  **Vertices ($V$)**: 4\n2.  **Edges ($E$)**: 6\n3.  **Faces ($F$)**: 4\n\nCalculating $\\chi(S^2)$:\n$$ \\chi(S^2) = V - E + F = 4 - 6 + 4 = 2 $$\nUsing the formula $2 - 2g$ with $g=0$:\n$$ 2 - 2(0) = 2 $$\nThe formula holds for $g=0$.\n\n#### Case 2: Surface of Genus $g \\geq 1$\nFor $g \\geq 1$, the surface $M$ can be constructed as a quotient space of a regular polygon. This is the **standard polygonal presentation** of an orientable surface.\n\n**1. The Polygonal Model**\nA surface of genus $g$ is homeomorphic to the quotient of a regular $4g$-sided polygon $P$ in the Euclidean plane. The edges of the polygon are identified in pairs according to the standard word $W$:\n$$ W = a_1 b_1 a_1^{-1} b_1^{-1} a_2 b_2 a_2^{-1} b_2^{-1} \\dots a_g b_g a_g^{-1} b_g^{-1} $$\nHere, each letter represents an edge of the polygon. The exponent $-1$ indicates that the edge is traversed in the direction opposite to the boundary orientation.\n\n**2. Cell Decomposition**\nWe define a CW-complex structure on $M$ induced by this identification:\n*   **Faces ($F$):** The interior of the polygon $P$ forms a single 2-cell. Thus, $F = 1$.\n*   **Edges ($E$):** The boundary of the polygon consists of $4g$ edges. The identification word pairs every edge $x$ with a corresponding edge $x^{-1}$. Since every edge is identified with exactly one other edge, the number of distinct 1-cells in the quotient is:\n    $$ E = \\frac{4g}{2} = 2g $$\n\n**3. Vertices ($V$):**\nWe must determine how the vertices of the polygon are identified. Let the vertices of the $4g$-gon be $v_0, v_1, \\dots, v_{4g-1}$ in counterclockwise order.\nConsider the $i$-th handle represented by the sequence of edges $a_i, b_i, a_i^{-1}, b_i^{-1}$. Let the vertices involved in this sequence locally be $p_0, p_1, p_2, p_3, p_4$ such that:\n*   $a_i$ connects $p_0 \\to p_1$\n*   $b_i$ connects $p_1 \\to p_2$\n*   $a_i^{-1}$ connects $p_2 \\to p_3$\n*   $b_i^{-1}$ connects $p_3 \\to p_4$\n\nThe identification of edges dictates the identification of their endpoints:\n1.  **Identify $a_i$ with $a_i^{-1}$:**\n    The edge $a_i$ (directed $p_0 \\to p_1$) is identified with $a_i^{-1}$ (which corresponds to the geometric edge $p_2 \\to p_3$ traversed backwards, i.e., $p_3 \\to p_2$).\n    Therefore, the start of $a_i$ is identified with the start of the traversal of $a_i^{-1}$, and the end with the end.\n    $$ p_0 \\sim p_3 \\quad \\text{and} \\quad p_1 \\sim p_2 $$\n\n2.  **Identify $b_i$ with $b_i^{-1}$:**\n    The edge $b_i$ (directed $p_1 \\to p_2$) is identified with $b_i^{-1}$ (geometric edge $p_3 \\to p_4$ traversed backwards, i.e., $p_4 \\to p_3$).\n    $$ p_1 \\sim p_4 \\quad \\text{and} \\quad p_2 \\sim p_3 $$\n\n**Analyzing the Equivalence Class:**\nCombining these identifications for the $i$-th group:\n*   From $a_i$: $p_1 \\sim p_2$ and $p_0 \\sim p_3$.\n*   From $b_i$: $p_2 \\sim p_3$ and $p_1 \\sim p_4$.\n*   Chaining these: $p_0 \\sim p_3 \\sim p_2 \\sim p_1 \\sim p_4$.\n\nThus, all vertices associated with the $i$-th handle ($p_0$ through $p_4$) are identified to a single point. Since $p_4$ is the starting vertex ($p_0$) of the $(i+1)$-th handle group (or wraps around to the start of the polygon if $i=g$), the equivalence relation propagates through all $g$ groups.\n\nConsequently, all $4g$ vertices of the polygon are identified to a single vertex in the quotient manifold.\n$$ V = 1 $$\n\n**4. Calculation**\nWe now compute the Euler characteristic $\\chi(M)$:\n$$ \\chi(M) = V - E + F $$\nSubstituting the values derived above ($V=1, E=2g, F=1$):\n$$ \\chi(M) = 1 - 2g + 1 $$\n$$ \\chi(M) = 2 - 2g $$\n\n### Alternative Approach: Connected Sums\nWe can also verify this result using the properties of the connected sum operation $\\#$.\nA surface of genus $g$ is the connected sum of $g$ tori: $M_g = T^2 \\# T^2 \\# \\dots \\# T^2$.\nThe Euler characteristic of a connected sum is given by:\n$$ \\chi(A \\# B) = \\chi(A) + \\chi(B) - 2 $$\nWe proceed by induction:\n1.  **Base Case ($g=1$):** For a torus $T^2$, we have the identification $aba^{-1}b^{-1}$. Here $V=1, E=2, F=1$, so $\\chi(T^2) = 1 - 2 + 1 = 0$.\n    Formula: $2 - 2(1) = 0$. (Verified)\n2.  **Inductive Step:** Assume $\\chi(M_{k}) = 2 - 2k$.\n    $$ M_{k+1} = M_k \\# T^2 $$\n    $$ \\chi(M_{k+1}) = \\chi(M_k) + \\chi(T^2) - 2 $$\n    $$ \\chi(M_{k+1}) = (2 - 2k) + 0 - 2 $$\n    $$ \\chi(M_{k+1}) = 2 - 2k - 2 = 2 - 2(k+1) $$\n\nThis confirms the result for all $g \\geq 1$.\n\n### Conclusion\nWe have shown through explicit cell decomposition and the connected sum formula that for a 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles, the Euler characteristic is:\n$$ \\chi(M) = 2 - 2g $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Global analysis, analysis on manifolds\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify key concepts in the domain\nGlobal analysis and analysis on manifolds involve the study of geometric and topological properties of manifolds using analytical techniques. Key concepts include differential forms, integration on manifolds, Stokes' theorem, and the study of differential equations on manifolds.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to identify a specific concept or technique within global analysis or analysis on manifolds that can be used to formulate a challenging yet solvable question. One such concept is the application of Stokes' theorem, which relates the integral of a differential form over a manifold to the integral of its exterior derivative over the boundary of the manifold.\n\n## Step 4: Construct the problem\nLet's consider a specific manifold and a differential form. A common example is the unit sphere $S^2$ in $\\mathbb{R}^3$. We can formulate a problem involving the integration of a differential form over $S^2$ and applying Stokes' theorem.\n\n## Step 5: Specify the problem\nLet $\\omega = y \\, dx \\wedge dz$ be a 2-form on $\\mathbb{R}^3$. Consider the unit sphere $S^2 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 = 1 \\}$ oriented with the outward unit normal. Evaluate $\\int_{S^2} \\omega$.\n\n## Step 6: Provide the solution\nTo solve this, we can directly integrate $\\omega$ over $S^2$ or apply Stokes' theorem. Stokes' theorem states that $\\int_M d\\omega = \\int_{\\partial M} \\omega$, where $M$ is a manifold with boundary $\\partial M$. Here, we can consider $M = B^3 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 \\leq 1 \\}$, so $\\partial M = S^2$.\n\n## Step 7: Calculate $d\\omega$\n$d\\omega = d(y \\, dx \\wedge dz) = dy \\wedge dx \\wedge dz = -dx \\wedge dy \\wedge dz$ because $d(y) = dy$, $d(dx) = 0$, and $d(dz) = 0$. So, $d\\omega = -dx \\wedge dy \\wedge dz$.\n\n## Step 8: Apply Stokes' theorem\n$\\int_{S^2} \\omega = \\int_{B^3} d\\omega = \\int_{B^3} -dx \\wedge dy \\wedge dz = -\\int_{B^3} dV$, where $dV = dx \\wedge dy \\wedge dz$ is the volume form on $\\mathbb{R}^3$. Thus, $\\int_{S^2} \\omega = -\\text{Vol}(B^3)$.\n\n## Step 9: Calculate the volume of $B^3$\nThe volume of the unit ball $B^3$ is given by $\\frac{4}{3}\\pi(1)^3 = \\frac{4}{3}\\pi$.\n\n## Step 10: Conclude the solution\n$\\int_{S^2} \\omega = -\\frac{4}{3}\\pi$.\n\nThe final answer is: \n\nLet $\\omega = y \\, dx \\wedge dz$ be a 2-form on $\\mathbb{R}^3$. Consider the unit sphere $S^2 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 = 1 \\}$ oriented with the outward unit normal. Evaluate $\\int_{S^2} \\omega$.",
    "run_id": "41",
    "outer_attempt": 1,
    "topic_slug": "global_analysis_on_manifolds",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To evaluate the integral $\\int_{S^2} \\omega$ where $\\omega = y \\, dx \\wedge dz$ and $S^2$ is the unit sphere oriented with the outward unit normal, we can use the **Generalized Stokes' Theorem**.\n\n### 1. Application of Stokes' Theorem\n\nThe Generalized Stokes' Theorem states that for a compact oriented manifold $M$ with boundary $\\partial M$ and a smooth differential form $\\omega$ of degree $\\dim(\\partial M)$:\n$$\n\\int_{\\partial M} \\omega = \\int_{M} d\\omega\n$$\nIn this problem:\n*   Let $M$ be the closed unit ball in $\\mathbb{R}^3$, denoted by $B^3 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 \\leq 1 \\}$.\n*   The boundary of $M$ is the unit sphere, $\\partial M = S^2$.\n*   The standard orientation of $\\mathbb{R}^3$ induces the outward normal orientation on the boundary $\\partial M$. Since the problem specifies that $S^2$ is oriented with the outward unit normal, the orientations are consistent.\n\nThus, we can compute the integral over the volume of the ball $B^3$ instead of the surface $S^2$:\n$$\n\\int_{S^2} \\omega = \\int_{B^3} d\\omega\n$$\n\n### 2. Computing the Exterior Derivative\n\nWe need to compute the exterior derivative $d\\omega$ of the 2-form $\\omega = y \\, dx \\wedge dz$.\n\nUsing the properties of the exterior derivative (linearity and the product rule $d(f \\eta) = df \\wedge \\eta + f \\, d\\eta$):\n$$\nd\\omega = d(y \\, dx \\wedge dz) = dy \\wedge dx \\wedge dz + y \\, d(dx \\wedge dz)\n$$\nSince $d(dx) = 0$ and $d(dz) = 0$, the term $d(dx \\wedge dz) = 0$. Therefore:\n$$\nd\\omega = dy \\wedge dx \\wedge dz\n$$\nTo express this in terms of the standard volume form $dx \\wedge dy \\wedge dz$, we use the anticommutativity property of the wedge product ($\\alpha \\wedge \\beta = - \\beta \\wedge \\alpha$ for 1-forms):\n$$\ndy \\wedge dx = - (dx \\wedge dy)\n$$\nSubstituting this back into the expression for $d\\omega$:\n$$\nd\\omega = -(dx \\wedge dy) \\wedge dz = - dx \\wedge dy \\wedge dz\n$$\n\n### 3. Evaluating the Volume Integral\n\nNow we substitute $d\\omega$ into the integral over $B^3$:\n$$\n\\int_{S^2} \\omega = \\int_{B^3} (- dx \\wedge dy \\wedge dz) = - \\int_{B^3} dx \\wedge dy \\wedge dz\n$$\nThe integral $\\int_{B^3} dx \\wedge dy \\wedge dz$ represents the volume of the unit ball $B^3$.\n\nThe volume of a sphere of radius $r$ is given by $V = \\frac{4}{3}\\pi r^3$. For the unit ball ($r=1$):\n$$\n\\text{Vol}(B^3) = \\frac{4}{3}\\pi (1)^3 = \\frac{4}{3}\\pi\n$$\n\nTherefore:\n$$\n\\int_{S^2} \\omega = - \\left( \\frac{4}{3}\\pi \\right)\n$$\n\n### Conclusion\n\nThe value of the integral is:\n$$\n-\\frac{4}{3}\\pi\n$$",
        "raw_answer": "To evaluate the integral $\\int_{S^2} \\omega$ where $\\omega = y \\, dx \\wedge dz$ and $S^2$ is the unit sphere oriented with the outward unit normal, we can use the **Generalized Stokes' Theorem**.\n\n### 1. Application of Stokes' Theorem\n\nThe Generalized Stokes' Theorem states that for a compact oriented manifold $M$ with boundary $\\partial M$ and a smooth differential form $\\omega$ of degree $\\dim(\\partial M)$:\n$$\n\\int_{\\partial M} \\omega = \\int_{M} d\\omega\n$$\nIn this problem:\n*   Let $M$ be the closed unit ball in $\\mathbb{R}^3$, denoted by $B^3 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 \\leq 1 \\}$.\n*   The boundary of $M$ is the unit sphere, $\\partial M = S^2$.\n*   The standard orientation of $\\mathbb{R}^3$ induces the outward normal orientation on the boundary $\\partial M$. Since the problem specifies that $S^2$ is oriented with the outward unit normal, the orientations are consistent.\n\nThus, we can compute the integral over the volume of the ball $B^3$ instead of the surface $S^2$:\n$$\n\\int_{S^2} \\omega = \\int_{B^3} d\\omega\n$$\n\n### 2. Computing the Exterior Derivative\n\nWe need to compute the exterior derivative $d\\omega$ of the 2-form $\\omega = y \\, dx \\wedge dz$.\n\nUsing the properties of the exterior derivative (linearity and the product rule $d(f \\eta) = df \\wedge \\eta + f \\, d\\eta$):\n$$\nd\\omega = d(y \\, dx \\wedge dz) = dy \\wedge dx \\wedge dz + y \\, d(dx \\wedge dz)\n$$\nSince $d(dx) = 0$ and $d(dz) = 0$, the term $d(dx \\wedge dz) = 0$. Therefore:\n$$\nd\\omega = dy \\wedge dx \\wedge dz\n$$\nTo express this in terms of the standard volume form $dx \\wedge dy \\wedge dz$, we use the anticommutativity property of the wedge product ($\\alpha \\wedge \\beta = - \\beta \\wedge \\alpha$ for 1-forms):\n$$\ndy \\wedge dx = - (dx \\wedge dy)\n$$\nSubstituting this back into the expression for $d\\omega$:\n$$\nd\\omega = -(dx \\wedge dy) \\wedge dz = - dx \\wedge dy \\wedge dz\n$$\n\n### 3. Evaluating the Volume Integral\n\nNow we substitute $d\\omega$ into the integral over $B^3$:\n$$\n\\int_{S^2} \\omega = \\int_{B^3} (- dx \\wedge dy \\wedge dz) = - \\int_{B^3} dx \\wedge dy \\wedge dz\n$$\nThe integral $\\int_{B^3} dx \\wedge dy \\wedge dz$ represents the volume of the unit ball $B^3$.\n\nThe volume of a sphere of radius $r$ is given by $V = \\frac{4}{3}\\pi r^3$. For the unit ball ($r=1$):\n$$\n\\text{Vol}(B^3) = \\frac{4}{3}\\pi (1)^3 = \\frac{4}{3}\\pi\n$$\n\nTherefore:\n$$\n\\int_{S^2} \\omega = - \\left( \\frac{4}{3}\\pi \\right)\n$$\n\n### Conclusion\n\nThe value of the integral is:\n$$\n-\\frac{4}{3}\\pi\n$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $X$ and $Y$ be independent random variables with $X \\sim \\text{Exp}(\\lambda)$ and $Y \\sim \\text{Exp}(\\mu)$, where $\\lambda > 0$ and $\\mu > 0$ are the rate parameters. Define $Z = \\min(X, Y)$. Derive the probability density function (pdf) of $Z$ and compute $\\mathbb{E}[Z]$.",
    "run_id": "42",
    "outer_attempt": 1,
    "topic_slug": "probability_theory_and_stochastic_processes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To derive the probability density function (pdf) of $Z$ and compute $\\mathbb{E}[Z]$, we proceed through the following steps using the properties of exponential distributions and the independence of $X$ and $Y$.\n\n### 1. Definitions and Preliminaries\n\nLet $X \\sim \\text{Exp}(\\lambda)$ and $Y \\sim \\text{Exp}(\\mu)$. The probability density functions (pdf) for $X$ and $Y$ are given by:\n$$\nf_X(x) = \\begin{cases} \\lambda e^{-\\lambda x} & x \\ge 0 \\\\ 0 & x < 0 \\end{cases}\n$$\n$$\nf_Y(y) = \\begin{cases} \\mu e^{-\\mu y} & y \\ge 0 \\\\ 0 & y < 0 \\end{cases}\n$$\n\nThe survival functions, defined as $S(t) = P(T > t)$, are:\n$$\nP(X > x) = \\int_x^\\infty \\lambda e^{-\\lambda u} \\, du = e^{-\\lambda x}, \\quad \\text{for } x \\ge 0\n$$\n$$\nP(Y > y) = \\int_y^\\infty \\mu e^{-\\mu v} \\, dv = e^{-\\mu y}, \\quad \\text{for } y \\ge 0\n$$\n\n### 2. Derivation of the PDF of $Z$\n\nLet $Z = \\min(X, Y)$. To find the pdf of $Z$, it is most convenient to first determine the survival function of $Z$, denoted $S_Z(z) = P(Z > z)$.\n\nFor any $z \\ge 0$:\n$$\nP(Z > z) = P(\\min(X, Y) > z)\n$$\n\nThe minimum of two numbers is greater than $z$ if and only if **both** numbers are greater than $z$. Therefore:\n$$\nP(\\min(X, Y) > z) = P(X > z \\text{ and } Y > z)\n$$\n\nSince $X$ and $Y$ are independent random variables, the joint probability factorizes:\n$$\nP(X > z \\text{ and } Y > z) = P(X > z) \\cdot P(Y > z)\n$$\n\nSubstituting the survival functions for $X$ and $Y$:\n$$\nS_Z(z) = e^{-\\lambda z} \\cdot e^{-\\mu z} = e^{-(\\lambda + \\mu) z}\n$$\nFor $z < 0$, since $X$ and $Y$ are non-negative, $Z$ is non-negative, so $P(Z > z) = 1$.\n\nNow, we find the cumulative distribution function (CDF) of $Z$, denoted $F_Z(z)$:\n$$\nF_Z(z) = 1 - S_Z(z) = \\begin{cases} 1 - e^{-(\\lambda + \\mu) z} & z \\ge 0 \\\\ 0 & z < 0 \\end{cases}\n$$\n\nThe probability density function $f_Z(z)$ is the derivative of the CDF with respect to $z$ for $z > 0$:\n$$\nf_Z(z) = \\frac{d}{dz} F_Z(z) = \\frac{d}{dz} \\left( 1 - e^{-(\\lambda + \\mu) z} \\right)\n$$\n$$\nf_Z(z) = (\\lambda + \\mu) e^{-(\\lambda + \\mu) z}\n$$\n\nThus, the pdf of $Z$ is:\n$$\nf_Z(z) = \\begin{cases} (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} & z \\ge 0 \\\\ 0 & z < 0 \\end{cases}\n$$\n\n**Observation:** This is the pdf of an exponential distribution with rate parameter $\\lambda + \\mu$. Therefore, $Z \\sim \\text{Exp}(\\lambda + \\mu)$.\n\n### 3. Computation of $\\mathbb{E}[Z]$\n\nSince we have identified that $Z \\sim \\text{Exp}(\\lambda + \\mu)$, we can recall the standard property of the exponential distribution $\\text{Exp}(\\alpha)$, which has mean $\\frac{1}{\\alpha}$. Here $\\alpha = \\lambda + \\mu$.\n\nHowever, to provide a complete derivation, we compute the expectation directly using the definition $\\mathbb{E}[Z] = \\int_{-\\infty}^{\\infty} z f_Z(z) \\, dz$.\n\n$$\n\\mathbb{E}[Z] = \\int_0^\\infty z (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} \\, dz\n$$\n\nLet $k = \\lambda + \\mu$. The integral becomes:\n$$\n\\mathbb{E}[Z] = k \\int_0^\\infty z e^{-kz} \\, dz\n$$\n\nWe use integration by parts. Let $u = z$ and $dv = e^{-kz} dz$. Then $du = dz$ and $v = -\\frac{1}{k} e^{-kz}$.\n\n$$\n\\begin{aligned}\n\\int_0^\\infty z e^{-kz} \\, dz &= \\left[ z \\left( -\\frac{1}{k} e^{-kz} \\right) \\right]_0^\\infty - \\int_0^\\infty \\left( -\\frac{1}{k} e^{-kz} \\right) \\, dz \\\\\n&= \\left[ -\\frac{z}{k} e^{-kz} \\right]_0^\\infty + \\frac{1}{k} \\int_0^\\infty e^{-kz} \\, dz\n\\end{aligned}\n$$\n\nEvaluate the boundary term:\n- As $z \\to \\infty$, $z e^{-kz} \\to 0$ (exponential decay dominates linear growth).\n- At $z = 0$, the term is 0.\nThus, the boundary term is 0.\n\nEvaluate the remaining integral:\n$$\n\\frac{1}{k} \\int_0^\\infty e^{-kz} \\, dz = \\frac{1}{k} \\left[ -\\frac{1}{k} e^{-kz} \\right]_0^\\infty = \\frac{1}{k} \\left( 0 - \\left( -\\frac{1}{k} \\right) \\right) = \\frac{1}{k^2}\n$$\n\nSubstituting this back into the expression for expectation:\n$$\n\\mathbb{E}[Z] = k \\cdot \\frac{1}{k^2} = \\frac{1}{k}\n$$\n\nSubstituting $k = \\lambda + \\mu$:\n$$\n\\mathbb{E}[Z] = \\frac{1}{\\lambda + \\mu}\n$$\n\n### Final Answer\n\nThe probability density function of $Z$ is:\n$$\nf_Z(z) = \\begin{cases} (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} & z \\ge 0 \\\\ 0 & z < 0 \\end{cases}\n$$\nThe expected value of $Z$ is:\n$$\n\\mathbb{E}[Z] = \\frac{1}{\\lambda + \\mu}\n$$",
        "raw_answer": "To derive the probability density function (pdf) of $Z$ and compute $\\mathbb{E}[Z]$, we proceed through the following steps using the properties of exponential distributions and the independence of $X$ and $Y$.\n\n### 1. Definitions and Preliminaries\n\nLet $X \\sim \\text{Exp}(\\lambda)$ and $Y \\sim \\text{Exp}(\\mu)$. The probability density functions (pdf) for $X$ and $Y$ are given by:\n$$\nf_X(x) = \\begin{cases} \\lambda e^{-\\lambda x} & x \\ge 0 \\\\ 0 & x < 0 \\end{cases}\n$$\n$$\nf_Y(y) = \\begin{cases} \\mu e^{-\\mu y} & y \\ge 0 \\\\ 0 & y < 0 \\end{cases}\n$$\n\nThe survival functions, defined as $S(t) = P(T > t)$, are:\n$$\nP(X > x) = \\int_x^\\infty \\lambda e^{-\\lambda u} \\, du = e^{-\\lambda x}, \\quad \\text{for } x \\ge 0\n$$\n$$\nP(Y > y) = \\int_y^\\infty \\mu e^{-\\mu v} \\, dv = e^{-\\mu y}, \\quad \\text{for } y \\ge 0\n$$\n\n### 2. Derivation of the PDF of $Z$\n\nLet $Z = \\min(X, Y)$. To find the pdf of $Z$, it is most convenient to first determine the survival function of $Z$, denoted $S_Z(z) = P(Z > z)$.\n\nFor any $z \\ge 0$:\n$$\nP(Z > z) = P(\\min(X, Y) > z)\n$$\n\nThe minimum of two numbers is greater than $z$ if and only if **both** numbers are greater than $z$. Therefore:\n$$\nP(\\min(X, Y) > z) = P(X > z \\text{ and } Y > z)\n$$\n\nSince $X$ and $Y$ are independent random variables, the joint probability factorizes:\n$$\nP(X > z \\text{ and } Y > z) = P(X > z) \\cdot P(Y > z)\n$$\n\nSubstituting the survival functions for $X$ and $Y$:\n$$\nS_Z(z) = e^{-\\lambda z} \\cdot e^{-\\mu z} = e^{-(\\lambda + \\mu) z}\n$$\nFor $z < 0$, since $X$ and $Y$ are non-negative, $Z$ is non-negative, so $P(Z > z) = 1$.\n\nNow, we find the cumulative distribution function (CDF) of $Z$, denoted $F_Z(z)$:\n$$\nF_Z(z) = 1 - S_Z(z) = \\begin{cases} 1 - e^{-(\\lambda + \\mu) z} & z \\ge 0 \\\\ 0 & z < 0 \\end{cases}\n$$\n\nThe probability density function $f_Z(z)$ is the derivative of the CDF with respect to $z$ for $z > 0$:\n$$\nf_Z(z) = \\frac{d}{dz} F_Z(z) = \\frac{d}{dz} \\left( 1 - e^{-(\\lambda + \\mu) z} \\right)\n$$\n$$\nf_Z(z) = (\\lambda + \\mu) e^{-(\\lambda + \\mu) z}\n$$\n\nThus, the pdf of $Z$ is:\n$$\nf_Z(z) = \\begin{cases} (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} & z \\ge 0 \\\\ 0 & z < 0 \\end{cases}\n$$\n\n**Observation:** This is the pdf of an exponential distribution with rate parameter $\\lambda + \\mu$. Therefore, $Z \\sim \\text{Exp}(\\lambda + \\mu)$.\n\n### 3. Computation of $\\mathbb{E}[Z]$\n\nSince we have identified that $Z \\sim \\text{Exp}(\\lambda + \\mu)$, we can recall the standard property of the exponential distribution $\\text{Exp}(\\alpha)$, which has mean $\\frac{1}{\\alpha}$. Here $\\alpha = \\lambda + \\mu$.\n\nHowever, to provide a complete derivation, we compute the expectation directly using the definition $\\mathbb{E}[Z] = \\int_{-\\infty}^{\\infty} z f_Z(z) \\, dz$.\n\n$$\n\\mathbb{E}[Z] = \\int_0^\\infty z (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} \\, dz\n$$\n\nLet $k = \\lambda + \\mu$. The integral becomes:\n$$\n\\mathbb{E}[Z] = k \\int_0^\\infty z e^{-kz} \\, dz\n$$\n\nWe use integration by parts. Let $u = z$ and $dv = e^{-kz} dz$. Then $du = dz$ and $v = -\\frac{1}{k} e^{-kz}$.\n\n$$\n\\begin{aligned}\n\\int_0^\\infty z e^{-kz} \\, dz &= \\left[ z \\left( -\\frac{1}{k} e^{-kz} \\right) \\right]_0^\\infty - \\int_0^\\infty \\left( -\\frac{1}{k} e^{-kz} \\right) \\, dz \\\\\n&= \\left[ -\\frac{z}{k} e^{-kz} \\right]_0^\\infty + \\frac{1}{k} \\int_0^\\infty e^{-kz} \\, dz\n\\end{aligned}\n$$\n\nEvaluate the boundary term:\n- As $z \\to \\infty$, $z e^{-kz} \\to 0$ (exponential decay dominates linear growth).\n- At $z = 0$, the term is 0.\nThus, the boundary term is 0.\n\nEvaluate the remaining integral:\n$$\n\\frac{1}{k} \\int_0^\\infty e^{-kz} \\, dz = \\frac{1}{k} \\left[ -\\frac{1}{k} e^{-kz} \\right]_0^\\infty = \\frac{1}{k} \\left( 0 - \\left( -\\frac{1}{k} \\right) \\right) = \\frac{1}{k^2}\n$$\n\nSubstituting this back into the expression for expectation:\n$$\n\\mathbb{E}[Z] = k \\cdot \\frac{1}{k^2} = \\frac{1}{k}\n$$\n\nSubstituting $k = \\lambda + \\mu$:\n$$\n\\mathbb{E}[Z] = \\frac{1}{\\lambda + \\mu}\n$$\n\n### Final Answer\n\nThe probability density function of $Z$ is:\n$$\nf_Z(z) = \\begin{cases} (\\lambda + \\mu) e^{-(\\lambda + \\mu) z} & z \\ge 0 \\\\ 0 & z < 0 \\end{cases}\n$$\nThe expected value of $Z$ is:\n$$\n\\mathbb{E}[Z] = \\frac{1}{\\lambda + \\mu}\n$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $X$ and $Y$ be independent random variables with $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ and $Y \\sim \\mathcal{N}(0, 1)$, where $\\mu \\in \\mathbb{R}$ and $\\sigma > 0$ are unknown parameters. Suppose we have a sample of $n$ independent observations from $X$ and $m$ independent observations from $Y$, denoted as $x_1, x_2, \\ldots, x_n$ and $y_1, y_2, \\ldots, y_m$, respectively. Derive the likelihood ratio test statistic for testing $H_0: \\mu = 0, \\sigma = 1$ against $H_1: \\mu \\neq 0 \\text{ or } \\sigma \\neq 1$.",
    "run_id": "43",
    "outer_attempt": 1,
    "topic_slug": "statistics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To derive the likelihood ratio test (LRT) statistic for the given hypothesis testing problem, we proceed through the following steps: establishing the likelihood function, maximizing it under the null hypothesis, maximizing it over the entire parameter space, and forming the likelihood ratio.\n\n### 1. The Model and Likelihood Function\n\nLet $\\theta = (\\mu, \\sigma^2)$ be the unknown parameters for the distribution of $X$, where $\\mu \\in \\mathbb{R}$ and $\\sigma^2 > 0$. The distribution of $Y$ is fixed as $\\mathcal{N}(0, 1)$ and contains no unknown parameters.\n\nThe observed data consists of two independent samples:\n- $\\mathbf{x} = (x_1, \\ldots, x_n)$ from $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$\n- $\\mathbf{y} = (y_1, \\ldots, y_m)$ from $Y \\sim \\mathcal{N}(0, 1)$\n\nThe joint probability density function (likelihood function) for the complete data $(\\mathbf{x}, \\mathbf{y})$ is the product of the individual densities due to independence:\n\n$$\nL(\\mu, \\sigma^2; \\mathbf{x}, \\mathbf{y}) = \\left( \\prod_{i=1}^n f_X(x_i; \\mu, \\sigma^2) \\right) \\left( \\prod_{j=1}^m f_Y(y_j) \\right)\n$$\n\nSubstituting the normal density functions:\n\n$$\nL(\\mu, \\sigma^2) = \\left[ (2\\pi \\sigma^2)^{-n/2} \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2 \\right) \\right] \\cdot \\left[ (2\\pi)^{-m/2} \\exp\\left( -\\frac{1}{2} \\sum_{j=1}^m y_j^2 \\right) \\right]\n$$\n\nLet $L_Y(\\mathbf{y}) = (2\\pi)^{-m/2} \\exp\\left( -\\frac{1}{2} \\sum_{j=1}^m y_j^2 \\right)$. This term does not depend on the parameters $\\mu$ and $\\sigma^2$. Thus, we can write:\n\n$$\nL(\\mu, \\sigma^2) = L_Y(\\mathbf{y}) \\cdot (2\\pi \\sigma^2)^{-n/2} \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2 \\right)\n$$\n\n### 2. The Hypotheses\n\nWe are testing:\n- $H_0: \\mu = 0, \\sigma = 1$ (which implies $\\sigma^2 = 1$)\n- $H_1: \\mu \\neq 0 \\text{ or } \\sigma \\neq 1$\n\nThe likelihood ratio statistic is defined as:\n$$\n\\Lambda = \\frac{\\sup_{(\\mu, \\sigma^2) \\in \\Theta_0} L(\\mu, \\sigma^2)}{\\sup_{(\\mu, \\sigma^2) \\in \\Theta} L(\\mu, \\sigma^2)}\n$$\nwhere $\\Theta_0 = \\{(0, 1)\\}$ and $\\Theta = \\mathbb{R} \\times (0, \\infty)$.\n\n### 3. Maximization under the Null Hypothesis ($H_0$)\n\nUnder $H_0$, the parameters are fixed at $\\mu = 0$ and $\\sigma^2 = 1$. The likelihood is:\n\n$$\nL_0 = L(0, 1) = L_Y(\\mathbf{y}) \\cdot (2\\pi)^{-n/2} \\exp\\left( -\\frac{1}{2} \\sum_{i=1}^n x_i^2 \\right)\n$$\n\n### 4. Maximization under the Alternative ($H_1$)\n\nUnder the general parameter space, we maximize $L(\\mu, \\sigma^2)$ with respect to $\\mu$ and $\\sigma^2$. Since $L_Y(\\mathbf{y})$ is constant with respect to $\\theta$, maximizing the joint likelihood is equivalent to maximizing the likelihood of the $X$ sample.\n\nThe log-likelihood for the $X$ component (ignoring constants) is:\n$$\n\\ell(\\mu, \\sigma^2) = -\\frac{n}{2}\\ln(\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (x_i - \\mu)^2\n$$\n\nStandard Maximum Likelihood Estimation (MLE) for a normal distribution yields:\n$$\n\\hat{\\mu} = \\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i\n$$\n$$\n\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2\n$$\n*Assumption: We assume $n \\geq 2$ and $\\sum (x_i - \\bar{x})^2 > 0$ so that the variance is well-defined and positive.*\n\nSubstituting these estimates back into the likelihood function:\n$$\n\\sum_{i=1}^n (x_i - \\hat{\\mu})^2 = \\sum_{i=1}^n (x_i - \\bar{x})^2 = n\\hat{\\sigma}^2\n$$\n\nThus, the exponential term becomes:\n$$\n\\exp\\left( -\\frac{1}{2\\hat{\\sigma}^2} (n\\hat{\\sigma}^2) \\right) = e^{-n/2}\n$$\n\nThe maximized likelihood is:\n$$\nL_1 = \\sup_{\\theta \\in \\Theta} L(\\theta) = L_Y(\\mathbf{y}) \\cdot (2\\pi \\hat{\\sigma}^2)^{-n/2} e^{-n/2}\n$$\n\n### 5. Derivation of the Likelihood Ratio $\\Lambda$\n\nWe compute the ratio $\\Lambda = \\frac{L_0}{L_1}$:\n\n$$\n\\Lambda = \\frac{L_Y(\\mathbf{y}) \\cdot (2\\pi)^{-n/2} \\exp\\left( -\\frac{1}{2} \\sum_{i=1}^n x_i^2 \\right)}{L_Y(\\mathbf{y}) \\cdot (2\\pi \\hat{\\sigma}^2)^{-n/2} e^{-n/2}}\n$$\n\nThe term $L_Y(\\mathbf{y})$ and the constant factors $(2\\pi)^{-n/2}$ cancel out:\n\n$$\n\\Lambda = \\frac{\\exp\\left( -\\frac{1}{2} \\sum_{i=1}^n x_i^2 \\right)}{(\\hat{\\sigma}^2)^{-n/2} e^{-n/2}}\n$$\n\nRearranging terms:\n$$\n\\Lambda = (\\hat{\\sigma}^2)^{n/2} e^{n/2} \\exp\\left( -\\frac{1}{2} \\sum_{i=1}^n x_i^2 \\right)\n$$\n\nWe use the algebraic identity $\\sum_{i=1}^n x_i^2 = \\sum_{i=1}^n (x_i - \\bar{x})^2 + n\\bar{x}^2 = n\\hat{\\sigma}^2 + n\\bar{x}^2$ to simplify the exponent:\n\n$$\n\\exp\\left( -\\frac{1}{2} \\sum_{i=1}^n x_i^2 \\right) = \\exp\\left( -\\frac{1}{2} (n\\hat{\\sigma}^2 + n\\bar{x}^2) \\right)\n$$\n\nSubstituting this back into the expression for $\\Lambda$:\n\n$$\n\\Lambda = (\\hat{\\sigma}^2)^{n/2} \\cdot e^{n/2} \\cdot \\exp\\left( -\\frac{n}{2}\\hat{\\sigma}^2 - \\frac{n}{2}\\bar{x}^2 \\right)\n$$\n$$\n\\Lambda = (\\hat{\\sigma}^2)^{n/2} \\exp\\left( \\frac{n}{2} (1 - \\hat{\\sigma}^2 - \\bar{x}^2) \\right)\n$$\n\n### Final Answer\n\nThe likelihood ratio test statistic $\\Lambda$ is given by:\n\n$$\n\\Lambda = \\left( \\hat{\\sigma}^2 \\right)^{n/2} \\exp\\left( \\frac{n}{2} \\left( 1 - \\hat{\\sigma}^2 - \\bar{x}^2 \\right) \\right)\n$$\n\nwhere $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$ and $\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2$.\n\nIt is common to utilize the log-likelihood ratio statistic, $-2 \\ln \\Lambda$, which asymptotically follows a Chi-square distribution. This is derived as:\n\n$$\n-2 \\ln \\Lambda = n \\left[ (\\hat{\\sigma}^2 - 1 - \\ln \\hat{\\sigma}^2) + \\bar{x}^2 \\right]\n$$\n\nNote that the observations from $Y$ ($y_1, \\ldots, y_m$) do not appear in the final statistic because the distribution of $Y$ is completely specified under both the null and alternative hypotheses.",
        "raw_answer": "To derive the likelihood ratio test (LRT) statistic for the given hypothesis testing problem, we proceed through the following steps: establishing the likelihood function, maximizing it under the null hypothesis, maximizing it over the entire parameter space, and forming the likelihood ratio.\n\n### 1. The Model and Likelihood Function\n\nLet $\\theta = (\\mu, \\sigma^2)$ be the unknown parameters for the distribution of $X$, where $\\mu \\in \\mathbb{R}$ and $\\sigma^2 > 0$. The distribution of $Y$ is fixed as $\\mathcal{N}(0, 1)$ and contains no unknown parameters.\n\nThe observed data consists of two independent samples:\n- $\\mathbf{x} = (x_1, \\ldots, x_n)$ from $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$\n- $\\mathbf{y} = (y_1, \\ldots, y_m)$ from $Y \\sim \\mathcal{N}(0, 1)$\n\nThe joint probability density function (likelihood function) for the complete data $(\\mathbf{x}, \\mathbf{y})$ is the product of the individual densities due to independence:\n\n$$\nL(\\mu, \\sigma^2; \\mathbf{x}, \\mathbf{y}) = \\left( \\prod_{i=1}^n f_X(x_i; \\mu, \\sigma^2) \\right) \\left( \\prod_{j=1}^m f_Y(y_j) \\right)\n$$\n\nSubstituting the normal density functions:\n\n$$\nL(\\mu, \\sigma^2) = \\left[ (2\\pi \\sigma^2)^{-n/2} \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2 \\right) \\right] \\cdot \\left[ (2\\pi)^{-m/2} \\exp\\left( -\\frac{1}{2} \\sum_{j=1}^m y_j^2 \\right) \\right]\n$$\n\nLet $L_Y(\\mathbf{y}) = (2\\pi)^{-m/2} \\exp\\left( -\\frac{1}{2} \\sum_{j=1}^m y_j^2 \\right)$. This term does not depend on the parameters $\\mu$ and $\\sigma^2$. Thus, we can write:\n\n$$\nL(\\mu, \\sigma^2) = L_Y(\\mathbf{y}) \\cdot (2\\pi \\sigma^2)^{-n/2} \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2 \\right)\n$$\n\n### 2. The Hypotheses\n\nWe are testing:\n- $H_0: \\mu = 0, \\sigma = 1$ (which implies $\\sigma^2 = 1$)\n- $H_1: \\mu \\neq 0 \\text{ or } \\sigma \\neq 1$\n\nThe likelihood ratio statistic is defined as:\n$$\n\\Lambda = \\frac{\\sup_{(\\mu, \\sigma^2) \\in \\Theta_0} L(\\mu, \\sigma^2)}{\\sup_{(\\mu, \\sigma^2) \\in \\Theta} L(\\mu, \\sigma^2)}\n$$\nwhere $\\Theta_0 = \\{(0, 1)\\}$ and $\\Theta = \\mathbb{R} \\times (0, \\infty)$.\n\n### 3. Maximization under the Null Hypothesis ($H_0$)\n\nUnder $H_0$, the parameters are fixed at $\\mu = 0$ and $\\sigma^2 = 1$. The likelihood is:\n\n$$\nL_0 = L(0, 1) = L_Y(\\mathbf{y}) \\cdot (2\\pi)^{-n/2} \\exp\\left( -\\frac{1}{2} \\sum_{i=1}^n x_i^2 \\right)\n$$\n\n### 4. Maximization under the Alternative ($H_1$)\n\nUnder the general parameter space, we maximize $L(\\mu, \\sigma^2)$ with respect to $\\mu$ and $\\sigma^2$. Since $L_Y(\\mathbf{y})$ is constant with respect to $\\theta$, maximizing the joint likelihood is equivalent to maximizing the likelihood of the $X$ sample.\n\nThe log-likelihood for the $X$ component (ignoring constants) is:\n$$\n\\ell(\\mu, \\sigma^2) = -\\frac{n}{2}\\ln(\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (x_i - \\mu)^2\n$$\n\nStandard Maximum Likelihood Estimation (MLE) for a normal distribution yields:\n$$\n\\hat{\\mu} = \\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i\n$$\n$$\n\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2\n$$\n*Assumption: We assume $n \\geq 2$ and $\\sum (x_i - \\bar{x})^2 > 0$ so that the variance is well-defined and positive.*\n\nSubstituting these estimates back into the likelihood function:\n$$\n\\sum_{i=1}^n (x_i - \\hat{\\mu})^2 = \\sum_{i=1}^n (x_i - \\bar{x})^2 = n\\hat{\\sigma}^2\n$$\n\nThus, the exponential term becomes:\n$$\n\\exp\\left( -\\frac{1}{2\\hat{\\sigma}^2} (n\\hat{\\sigma}^2) \\right) = e^{-n/2}\n$$\n\nThe maximized likelihood is:\n$$\nL_1 = \\sup_{\\theta \\in \\Theta} L(\\theta) = L_Y(\\mathbf{y}) \\cdot (2\\pi \\hat{\\sigma}^2)^{-n/2} e^{-n/2}\n$$\n\n### 5. Derivation of the Likelihood Ratio $\\Lambda$\n\nWe compute the ratio $\\Lambda = \\frac{L_0}{L_1}$:\n\n$$\n\\Lambda = \\frac{L_Y(\\mathbf{y}) \\cdot (2\\pi)^{-n/2} \\exp\\left( -\\frac{1}{2} \\sum_{i=1}^n x_i^2 \\right)}{L_Y(\\mathbf{y}) \\cdot (2\\pi \\hat{\\sigma}^2)^{-n/2} e^{-n/2}}\n$$\n\nThe term $L_Y(\\mathbf{y})$ and the constant factors $(2\\pi)^{-n/2}$ cancel out:\n\n$$\n\\Lambda = \\frac{\\exp\\left( -\\frac{1}{2} \\sum_{i=1}^n x_i^2 \\right)}{(\\hat{\\sigma}^2)^{-n/2} e^{-n/2}}\n$$\n\nRearranging terms:\n$$\n\\Lambda = (\\hat{\\sigma}^2)^{n/2} e^{n/2} \\exp\\left( -\\frac{1}{2} \\sum_{i=1}^n x_i^2 \\right)\n$$\n\nWe use the algebraic identity $\\sum_{i=1}^n x_i^2 = \\sum_{i=1}^n (x_i - \\bar{x})^2 + n\\bar{x}^2 = n\\hat{\\sigma}^2 + n\\bar{x}^2$ to simplify the exponent:\n\n$$\n\\exp\\left( -\\frac{1}{2} \\sum_{i=1}^n x_i^2 \\right) = \\exp\\left( -\\frac{1}{2} (n\\hat{\\sigma}^2 + n\\bar{x}^2) \\right)\n$$\n\nSubstituting this back into the expression for $\\Lambda$:\n\n$$\n\\Lambda = (\\hat{\\sigma}^2)^{n/2} \\cdot e^{n/2} \\cdot \\exp\\left( -\\frac{n}{2}\\hat{\\sigma}^2 - \\frac{n}{2}\\bar{x}^2 \\right)\n$$\n$$\n\\Lambda = (\\hat{\\sigma}^2)^{n/2} \\exp\\left( \\frac{n}{2} (1 - \\hat{\\sigma}^2 - \\bar{x}^2) \\right)\n$$\n\n### Final Answer\n\nThe likelihood ratio test statistic $\\Lambda$ is given by:\n\n$$\n\\Lambda = \\left( \\hat{\\sigma}^2 \\right)^{n/2} \\exp\\left( \\frac{n}{2} \\left( 1 - \\hat{\\sigma}^2 - \\bar{x}^2 \\right) \\right)\n$$\n\nwhere $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$ and $\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2$.\n\nIt is common to utilize the log-likelihood ratio statistic, $-2 \\ln \\Lambda$, which asymptotically follows a Chi-square distribution. This is derived as:\n\n$$\n-2 \\ln \\Lambda = n \\left[ (\\hat{\\sigma}^2 - 1 - \\ln \\hat{\\sigma}^2) + \\bar{x}^2 \\right]\n$$\n\nNote that the observations from $Y$ ($y_1, \\ldots, y_m$) do not appear in the final statistic because the distribution of $Y$ is completely specified under both the null and alternative hypotheses.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Consider the function $f(x) = e^x - 2x - 1$. We want to approximate the root of $f(x)$ in the interval $[0,1]$ using the Newton-Raphson method. Starting with $x_0 = 1$, perform two iterations of the Newton-Raphson method to find $x_2$. Provide the exact value of $x_2$.",
    "run_id": "44",
    "outer_attempt": 1,
    "topic_slug": "numerical_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the problem, we will perform two iterations of the Newton-Raphson method for the function $f(x) = e^x - 2x - 1$ starting with $x_0 = 1$.\n\n### 1. The Newton-Raphson Method\n\nThe Newton-Raphson iteration formula is given by:\n$$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$$\n\nFirst, we determine the derivative of $f(x)$ with respect to $x$:\n$$f(x) = e^x - 2x - 1$$\n$$f'(x) = \\frac{d}{dx}(e^x - 2x - 1) = e^x - 2$$\n\n### 2. Iteration 1: Finding $x_1$\n\nWe are given the initial guess $x_0 = 1$. We calculate $f(x_0)$ and $f'(x_0)$:\n$$f(1) = e^1 - 2(1) - 1 = e - 3$$\n$$f'(1) = e^1 - 2 = e - 2$$\n\nNow, we compute $x_1$:\n$$x_1 = 1 - \\frac{e - 3}{e - 2}$$\n\nTo simplify this expression, we find a common denominator:\n$$x_1 = \\frac{e - 2}{e - 2} - \\frac{e - 3}{e - 2}$$\n$$x_1 = \\frac{(e - 2) - (e - 3)}{e - 2}$$\n$$x_1 = \\frac{e - 2 - e + 3}{e - 2}$$\n$$x_1 = \\frac{1}{e - 2}$$\n\n### 3. Iteration 2: Finding $x_2$\n\nNow we use $x_1 = \\frac{1}{e - 2}$ to find $x_2$. The formula is:\n$$x_2 = x_1 - \\frac{f(x_1)}{f'(x_1)}$$\n\nSubstituting the function and derivative expressions:\n$$x_2 = x_1 - \\frac{e^{x_1} - 2x_1 - 1}{e^{x_1} - 2}$$\n\nTo simplify, we combine the terms into a single fraction:\n$$x_2 = \\frac{x_1(e^{x_1} - 2) - (e^{x_1} - 2x_1 - 1)}{e^{x_1} - 2}$$\n$$x_2 = \\frac{x_1 e^{x_1} - 2x_1 - e^{x_1} + 2x_1 + 1}{e^{x_1} - 2}$$\n\nNotice that the $-2x_1$ and $+2x_1$ terms cancel out:\n$$x_2 = \\frac{x_1 e^{x_1} - e^{x_1} + 1}{e^{x_1} - 2}$$\n$$x_2 = \\frac{e^{x_1}(x_1 - 1) + 1}{e^{x_1} - 2}$$\n\nNow, we substitute the exact value of $x_1 = \\frac{1}{e - 2}$.\nFirst, let's simplify the term $(x_1 - 1)$:\n$$x_1 - 1 = \\frac{1}{e - 2} - 1 = \\frac{1 - (e - 2)}{e - 2} = \\frac{1 - e + 2}{e - 2} = \\frac{3 - e}{e - 2}$$\n\nNow substitute this back into the expression for $x_2$:\n$$x_2 = \\frac{e^{\\frac{1}{e - 2}} \\left( \\frac{3 - e}{e - 2} \\right) + 1}{e^{\\frac{1}{e - 2}} - 2}$$\n\nTo express this as a single fraction, we multiply the numerator and the denominator by $(e - 2)$:\n$$x_2 = \\frac{(3 - e)e^{\\frac{1}{e - 2}} + (e - 2)}{(e - 2)(e^{\\frac{1}{e - 2}} - 2)}$$\n\n### Final Answer\n\nThe exact value of $x_2$ is:\n$$x_2 = \\frac{(3 - e)e^{\\frac{1}{e - 2}} + e - 2}{(e - 2)(e^{\\frac{1}{e - 2}} - 2)}$$",
        "raw_answer": "To solve the problem, we will perform two iterations of the Newton-Raphson method for the function $f(x) = e^x - 2x - 1$ starting with $x_0 = 1$.\n\n### 1. The Newton-Raphson Method\n\nThe Newton-Raphson iteration formula is given by:\n$$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$$\n\nFirst, we determine the derivative of $f(x)$ with respect to $x$:\n$$f(x) = e^x - 2x - 1$$\n$$f'(x) = \\frac{d}{dx}(e^x - 2x - 1) = e^x - 2$$\n\n### 2. Iteration 1: Finding $x_1$\n\nWe are given the initial guess $x_0 = 1$. We calculate $f(x_0)$ and $f'(x_0)$:\n$$f(1) = e^1 - 2(1) - 1 = e - 3$$\n$$f'(1) = e^1 - 2 = e - 2$$\n\nNow, we compute $x_1$:\n$$x_1 = 1 - \\frac{e - 3}{e - 2}$$\n\nTo simplify this expression, we find a common denominator:\n$$x_1 = \\frac{e - 2}{e - 2} - \\frac{e - 3}{e - 2}$$\n$$x_1 = \\frac{(e - 2) - (e - 3)}{e - 2}$$\n$$x_1 = \\frac{e - 2 - e + 3}{e - 2}$$\n$$x_1 = \\frac{1}{e - 2}$$\n\n### 3. Iteration 2: Finding $x_2$\n\nNow we use $x_1 = \\frac{1}{e - 2}$ to find $x_2$. The formula is:\n$$x_2 = x_1 - \\frac{f(x_1)}{f'(x_1)}$$\n\nSubstituting the function and derivative expressions:\n$$x_2 = x_1 - \\frac{e^{x_1} - 2x_1 - 1}{e^{x_1} - 2}$$\n\nTo simplify, we combine the terms into a single fraction:\n$$x_2 = \\frac{x_1(e^{x_1} - 2) - (e^{x_1} - 2x_1 - 1)}{e^{x_1} - 2}$$\n$$x_2 = \\frac{x_1 e^{x_1} - 2x_1 - e^{x_1} + 2x_1 + 1}{e^{x_1} - 2}$$\n\nNotice that the $-2x_1$ and $+2x_1$ terms cancel out:\n$$x_2 = \\frac{x_1 e^{x_1} - e^{x_1} + 1}{e^{x_1} - 2}$$\n$$x_2 = \\frac{e^{x_1}(x_1 - 1) + 1}{e^{x_1} - 2}$$\n\nNow, we substitute the exact value of $x_1 = \\frac{1}{e - 2}$.\nFirst, let's simplify the term $(x_1 - 1)$:\n$$x_1 - 1 = \\frac{1}{e - 2} - 1 = \\frac{1 - (e - 2)}{e - 2} = \\frac{1 - e + 2}{e - 2} = \\frac{3 - e}{e - 2}$$\n\nNow substitute this back into the expression for $x_2$:\n$$x_2 = \\frac{e^{\\frac{1}{e - 2}} \\left( \\frac{3 - e}{e - 2} \\right) + 1}{e^{\\frac{1}{e - 2}} - 2}$$\n\nTo express this as a single fraction, we multiply the numerator and the denominator by $(e - 2)$:\n$$x_2 = \\frac{(3 - e)e^{\\frac{1}{e - 2}} + (e - 2)}{(e - 2)(e^{\\frac{1}{e - 2}} - 2)}$$\n\n### Final Answer\n\nThe exact value of $x_2$ is:\n$$x_2 = \\frac{(3 - e)e^{\\frac{1}{e - 2}} + e - 2}{(e - 2)(e^{\\frac{1}{e - 2}} - 2)}$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $G$ be a simple graph with $n$ vertices. Prove that if $G$ is a tree (i.e., it is connected and has no cycles), then it has exactly $n-1$ edges.",
    "run_id": "2",
    "outer_attempt": 2,
    "topic_slug": "combinatorics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We proceed by mathematical induction on $n$, the number of vertices in the graph.\n\n**Theorem:** Let $G = (V, E)$ be a simple graph with $n$ vertices. If $G$ is a tree (connected and acyclic), then $|E| = n - 1$.\n\n### Proof\n\n**1. Base Case ($n=1$)**\nLet $G$ be a tree with $n=1$ vertex. Since $G$ is a simple graph, it contains no self-loops. Since there is only one vertex, there are no other vertices to form an edge with. Therefore, the number of edges is $|E| = 0$.\nChecking the formula: $n - 1 = 1 - 1 = 0$.\nThe base case holds.\n\n**2. Inductive Hypothesis**\nAssume that for an arbitrary integer $k \\geq 1$, any tree with $k$ vertices has exactly $k-1$ edges.\n\n**3. Inductive Step**\nLet $G = (V, E)$ be a tree with $n = k + 1$ vertices. We must show that $|E| = (k+1) - 1 = k$.\n\nTo proceed, we require the following lemma regarding the structure of finite trees.\n\n> **Lemma:** Every tree with at least 2 vertices contains at least two vertices of degree 1 (leaves).\n>\n> *Proof of Lemma:* Consider a longest simple path in $G$, denoted by $P = (v_1, v_2, \\dots, v_m)$. Since $G$ is a finite graph, such a path exists.\n> Examine the endpoint $v_1$. Since $P$ is a path, $v_1$ is adjacent to $v_2$. If $v_1$ were adjacent to any other vertex $v_j$ in the path (where $j > 2$), it would form a cycle $(v_1, v_2, \\dots, v_j, v_1)$, contradicting the assumption that $G$ is acyclic.\n> If $v_1$ were adjacent to any vertex $u$ not in $P$, then $(u, v_1, v_2, \\dots, v_m)$ would be a path longer than $P$, contradicting the maximality of $P$.\n> Therefore, $v_1$ has exactly one neighbor ($v_2$), so $\\deg(v_1) = 1$. The same logic applies to $v_m$. Thus, $G$ has at least two leaves.\n\nUsing the Lemma, we know $G$ (which has $k+1 \\geq 2$ vertices) contains a vertex $v$ such that $\\deg(v) = 1$. Let $u$ be the unique neighbor of $v$.\n\nNow, consider the graph $G'$ obtained by removing the vertex $v$ and its incident edge $e = \\{u, v\\}$ from $G$.\n$$ V' = V \\setminus \\{v\\} $$\n$$ E' = E \\setminus \\{e\\} $$\n\nWe must verify that $G'$ satisfies the conditions of the inductive hypothesis:\n1.  **Number of vertices:** $|V'| = (k+1) - 1 = k$.\n2.  **Acyclic:** Since $G$ contains no cycles, removing a vertex and an edge cannot create a cycle. Thus, $G'$ is acyclic.\n3.  **Connected:** Since $G$ is connected, there is a path between any two vertices $x, y \\in V$. If $x, y \\neq v$, the path between them in $G$ cannot pass through $v$ (except as an endpoint, which is excluded). Because $\\deg(v)=1$, $v$ is not an internal vertex of any simple path between other vertices. Therefore, the path between $x$ and $y$ remains intact in $G'$. Thus, $G'$ is connected.\n\nSince $G'$ is a connected acyclic graph with $k$ vertices, it is a tree. By the **Inductive Hypothesis**, $G'$ has exactly $k-1$ edges.\n\nThe number of edges in the original graph $G$ is:\n$$ |E| = |E'| + 1 $$\nSubstituting the value from the inductive hypothesis:\n$$ |E| = (k - 1) + 1 = k $$\n\nThis matches the requirement $|E| = n - 1$ for $n = k+1$.\n\n**Conclusion**\nBy the principle of mathematical induction, for every integer $n \\geq 1$, if a simple graph $G$ with $n$ vertices is a tree, it has exactly $n-1$ edges.",
        "raw_answer": "We proceed by mathematical induction on $n$, the number of vertices in the graph.\n\n**Theorem:** Let $G = (V, E)$ be a simple graph with $n$ vertices. If $G$ is a tree (connected and acyclic), then $|E| = n - 1$.\n\n### Proof\n\n**1. Base Case ($n=1$)**\nLet $G$ be a tree with $n=1$ vertex. Since $G$ is a simple graph, it contains no self-loops. Since there is only one vertex, there are no other vertices to form an edge with. Therefore, the number of edges is $|E| = 0$.\nChecking the formula: $n - 1 = 1 - 1 = 0$.\nThe base case holds.\n\n**2. Inductive Hypothesis**\nAssume that for an arbitrary integer $k \\geq 1$, any tree with $k$ vertices has exactly $k-1$ edges.\n\n**3. Inductive Step**\nLet $G = (V, E)$ be a tree with $n = k + 1$ vertices. We must show that $|E| = (k+1) - 1 = k$.\n\nTo proceed, we require the following lemma regarding the structure of finite trees.\n\n> **Lemma:** Every tree with at least 2 vertices contains at least two vertices of degree 1 (leaves).\n>\n> *Proof of Lemma:* Consider a longest simple path in $G$, denoted by $P = (v_1, v_2, \\dots, v_m)$. Since $G$ is a finite graph, such a path exists.\n> Examine the endpoint $v_1$. Since $P$ is a path, $v_1$ is adjacent to $v_2$. If $v_1$ were adjacent to any other vertex $v_j$ in the path (where $j > 2$), it would form a cycle $(v_1, v_2, \\dots, v_j, v_1)$, contradicting the assumption that $G$ is acyclic.\n> If $v_1$ were adjacent to any vertex $u$ not in $P$, then $(u, v_1, v_2, \\dots, v_m)$ would be a path longer than $P$, contradicting the maximality of $P$.\n> Therefore, $v_1$ has exactly one neighbor ($v_2$), so $\\deg(v_1) = 1$. The same logic applies to $v_m$. Thus, $G$ has at least two leaves.\n\nUsing the Lemma, we know $G$ (which has $k+1 \\geq 2$ vertices) contains a vertex $v$ such that $\\deg(v) = 1$. Let $u$ be the unique neighbor of $v$.\n\nNow, consider the graph $G'$ obtained by removing the vertex $v$ and its incident edge $e = \\{u, v\\}$ from $G$.\n$$ V' = V \\setminus \\{v\\} $$\n$$ E' = E \\setminus \\{e\\} $$\n\nWe must verify that $G'$ satisfies the conditions of the inductive hypothesis:\n1.  **Number of vertices:** $|V'| = (k+1) - 1 = k$.\n2.  **Acyclic:** Since $G$ contains no cycles, removing a vertex and an edge cannot create a cycle. Thus, $G'$ is acyclic.\n3.  **Connected:** Since $G$ is connected, there is a path between any two vertices $x, y \\in V$. If $x, y \\neq v$, the path between them in $G$ cannot pass through $v$ (except as an endpoint, which is excluded). Because $\\deg(v)=1$, $v$ is not an internal vertex of any simple path between other vertices. Therefore, the path between $x$ and $y$ remains intact in $G'$. Thus, $G'$ is connected.\n\nSince $G'$ is a connected acyclic graph with $k$ vertices, it is a tree. By the **Inductive Hypothesis**, $G'$ has exactly $k-1$ edges.\n\nThe number of edges in the original graph $G$ is:\n$$ |E| = |E'| + 1 $$\nSubstituting the value from the inductive hypothesis:\n$$ |E| = (k - 1) + 1 = k $$\n\nThis matches the requirement $|E| = n - 1$ for $n = k+1$.\n\n**Conclusion**\nBy the principle of mathematical induction, for every integer $n \\geq 1$, if a simple graph $G$ with $n$ vertices is a tree, it has exactly $n-1$ edges.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of algebraic geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within algebraic geometry\nAlgebraic geometry is a broad field that involves the study of geometric objects, such as varieties and schemes, using tools from abstract algebra. A suitable topic could involve the study of curves, surfaces, or higher-dimensional varieties, and their properties.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the intersection of curves on a surface. A classic result in algebraic geometry is B\u00e9zout's theorem, which describes the intersection of two curves on a projective plane. We can formulate a problem related to this.\n\n## Step 4: State the problem\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.\n\n## Step 5: Provide the solution\nTo find the intersection points, we need to solve the system of equations given by $f(x,y,z) = 0$ and $g(x,y,z) = 0$. This means we have to solve $x^2 + y^2 - z^2 = 0$ and $xy - z^2 = 0$ simultaneously.\n\n## Step 6: Solve the system of equations using B\u00e9zout's theorem\nB\u00e9zout's theorem states that two curves of degrees $d_1$ and $d_2$ intersect in $d_1d_2$ points, counted with multiplicity, if they have no common components. Here, $C_1$ and $C_2$ are both of degree 2, so they should intersect in $2 \\times 2 = 4$ points.\n\n## Step 7: Verify if $C_1$ and $C_2$ have any common components\nTo check if $C_1$ and $C_2$ have common components, we need to see if $f$ and $g$ have a common factor. This involves checking if there's a non-constant polynomial that divides both $f$ and $g$.\n\n## Step 8: Check for common factors\nWe examine if there's a linear combination of $f$ and $g$ that simplifies to a constant or a factorable expression. However, given the nature of $f$ and $g$, and without loss of generality, we can directly apply B\u00e9zout's theorem if we confirm they don't share a component.\n\n## Step 9: Apply B\u00e9zout's theorem\nSince both $f$ and $g$ are of degree 2 and there's no immediate indication they share a factor (which would be a linear factor given their degree), we can conclude they intersect in 4 points counted with multiplicity.\n\n## Step 10: Conclude the number of intersection points\nBy B\u00e9zout's theorem, $C_1$ and $C_2$ intersect in 4 points.\n\nThe final answer is: \n\n\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.",
    "run_id": "8",
    "outer_attempt": 2,
    "topic_slug": "algebraic_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To find the number of intersection points of the two curves $C_1$ and $C_2$ in the projective plane $\\mathbb{P}^2$, we will utilize B\u00e9zout's Theorem and verify the result by explicitly solving the system of equations.\n\n### 1. Problem Setup and Assumptions\n\nLet $K$ be an algebraically closed field (such as the complex numbers $\\mathbb{C}$). We work in the projective plane $\\mathbb{P}^2$ over $K$.\n\nThe curves are defined by the homogeneous polynomials:\n1.  $C_1: f(x, y, z) = x^2 + y^2 - z^2 = 0$\n2.  $C_2: g(x, y, z) = xy - z^2 = 0$\n\n### 2. Application of B\u00e9zout's Theorem\n\n**B\u00e9zout's Theorem** states that if two projective plane curves of degrees $d_1$ and $d_2$ defined over an algebraically closed field have no common components (i.e., their defining polynomials do not share a non-constant common factor), then they intersect in exactly $d_1 \\cdot d_2$ points, counted with multiplicity.\n\n**Step 2a: Determine the degrees**\nThe polynomial $f(x, y, z)$ has degree $d_1 = 2$.\nThe polynomial $g(x, y, z)$ has degree $d_2 = 2$.\n\n**Step 2b: Check for common components**\nWe must verify that $f$ and $g$ are coprime.\n- The polynomial $f = x^2 + y^2 - z^2$ defines a non-degenerate conic (a smooth quadric). It is irreducible.\n- The polynomial $g = xy - z^2$ also defines a non-degenerate conic. It is irreducible.\n- Since both are irreducible and monic with respect to $z^2$ (up to coefficient adjustment), they would only share a component if they were scalar multiples of each other.\n- Clearly, $x^2 + y^2 - z^2$ is not a scalar multiple of $xy - z^2$.\n\nTherefore, $C_1$ and $C_2$ have no common components.\n\n**Step 2c: Calculate the intersection number**\nBy B\u00e9zout's Theorem, the number of intersection points (counted with multiplicity) is:\n$$N = d_1 \\cdot d_2 = 2 \\cdot 2 = 4$$\n\n### 3. Explicit Verification\n\nTo ensure the result is robust and to determine the nature of the multiplicities, we solve the system explicitly.\n\n$$\n\\begin{cases}\nx^2 + y^2 - z^2 = 0 & (1) \\\\\nxy - z^2 = 0 & (2)\n\\end{cases}\n$$\n\nSubstitute equation (2) into equation (1) by replacing $z^2$ with $xy$:\n$$x^2 + y^2 - xy = 0$$\n\nWe look for solutions in $\\mathbb{P}^2$, so $(x, y, z) \\neq (0, 0, 0)$.\nIf $y = 0$, then $x^2 = 0 \\implies x = 0$. From (2), $z^2 = 0 \\implies z = 0$. This gives the trivial solution, which is not a point in $\\mathbb{P}^2$. Thus, $y \\neq 0$.\n\nDivide the equation by $y^2$ and let $t = \\frac{x}{y}$:\n$$\\left(\\frac{x}{y}\\right)^2 - \\frac{x}{y} + 1 = 0 \\implies t^2 - t + 1 = 0$$\n\nThe roots of this quadratic equation are:\n$$t = \\frac{1 \\pm \\sqrt{1 - 4}}{2} = \\frac{1 \\pm i\\sqrt{3}}{2} = e^{\\pm i\\pi/3}$$\n\nLet $\\omega = e^{i\\pi/3}$. The two distinct values for the ratio $x:y$ are $\\omega$ and $\\bar{\\omega}$ (where $\\bar{\\omega} = \\omega^{-1}$).\n\n**Case 1: $x = \\omega y$**\nSubstitute back into $z^2 = xy$:\n$$z^2 = (\\omega y)(y) = \\omega y^2 \\implies z = \\pm \\sqrt{\\omega} \\, y$$\nThis yields two points in projective coordinates (setting $y=1$):\n$P_1 = [\\omega : 1 : \\sqrt{\\omega}]$\n$P_2 = [\\omega : 1 : -\\sqrt{\\omega}]$\n\n**Case 2: $x = \\bar{\\omega} y$**\nSubstitute back into $z^2 = xy$:\n$$z^2 = (\\bar{\\omega} y)(y) = \\bar{\\omega} y^2 \\implies z = \\pm \\sqrt{\\bar{\\omega}} \\, y$$\nThis yields two more points:\n$P_3 = [\\bar{\\omega} : 1 : \\sqrt{\\bar{\\omega}}]$\n$P_4 = [\\bar{\\omega} : 1 : -\\sqrt{\\bar{\\omega}}]$\n\n**Analysis of Multiplicities:**\nWe have found 4 distinct points $P_1, P_2, P_3, P_4$.\nSince the sum of the intersection multiplicities must be 4 (by B\u00e9zout's Theorem) and there are 4 distinct geometric points, each intersection point must have multiplicity exactly 1. This means the curves intersect transversally at these points.\n\n### 4. Conclusion\n\nThe curves $C_1$ and $C_2$ intersect in exactly **4** points in $\\mathbb{P}^2$, counted with multiplicity.\n\n**Final Answer:** 4",
        "raw_answer": "To find the number of intersection points of the two curves $C_1$ and $C_2$ in the projective plane $\\mathbb{P}^2$, we will utilize B\u00e9zout's Theorem and verify the result by explicitly solving the system of equations.\n\n### 1. Problem Setup and Assumptions\n\nLet $K$ be an algebraically closed field (such as the complex numbers $\\mathbb{C}$). We work in the projective plane $\\mathbb{P}^2$ over $K$.\n\nThe curves are defined by the homogeneous polynomials:\n1.  $C_1: f(x, y, z) = x^2 + y^2 - z^2 = 0$\n2.  $C_2: g(x, y, z) = xy - z^2 = 0$\n\n### 2. Application of B\u00e9zout's Theorem\n\n**B\u00e9zout's Theorem** states that if two projective plane curves of degrees $d_1$ and $d_2$ defined over an algebraically closed field have no common components (i.e., their defining polynomials do not share a non-constant common factor), then they intersect in exactly $d_1 \\cdot d_2$ points, counted with multiplicity.\n\n**Step 2a: Determine the degrees**\nThe polynomial $f(x, y, z)$ has degree $d_1 = 2$.\nThe polynomial $g(x, y, z)$ has degree $d_2 = 2$.\n\n**Step 2b: Check for common components**\nWe must verify that $f$ and $g$ are coprime.\n- The polynomial $f = x^2 + y^2 - z^2$ defines a non-degenerate conic (a smooth quadric). It is irreducible.\n- The polynomial $g = xy - z^2$ also defines a non-degenerate conic. It is irreducible.\n- Since both are irreducible and monic with respect to $z^2$ (up to coefficient adjustment), they would only share a component if they were scalar multiples of each other.\n- Clearly, $x^2 + y^2 - z^2$ is not a scalar multiple of $xy - z^2$.\n\nTherefore, $C_1$ and $C_2$ have no common components.\n\n**Step 2c: Calculate the intersection number**\nBy B\u00e9zout's Theorem, the number of intersection points (counted with multiplicity) is:\n$$N = d_1 \\cdot d_2 = 2 \\cdot 2 = 4$$\n\n### 3. Explicit Verification\n\nTo ensure the result is robust and to determine the nature of the multiplicities, we solve the system explicitly.\n\n$$\n\\begin{cases}\nx^2 + y^2 - z^2 = 0 & (1) \\\\\nxy - z^2 = 0 & (2)\n\\end{cases}\n$$\n\nSubstitute equation (2) into equation (1) by replacing $z^2$ with $xy$:\n$$x^2 + y^2 - xy = 0$$\n\nWe look for solutions in $\\mathbb{P}^2$, so $(x, y, z) \\neq (0, 0, 0)$.\nIf $y = 0$, then $x^2 = 0 \\implies x = 0$. From (2), $z^2 = 0 \\implies z = 0$. This gives the trivial solution, which is not a point in $\\mathbb{P}^2$. Thus, $y \\neq 0$.\n\nDivide the equation by $y^2$ and let $t = \\frac{x}{y}$:\n$$\\left(\\frac{x}{y}\\right)^2 - \\frac{x}{y} + 1 = 0 \\implies t^2 - t + 1 = 0$$\n\nThe roots of this quadratic equation are:\n$$t = \\frac{1 \\pm \\sqrt{1 - 4}}{2} = \\frac{1 \\pm i\\sqrt{3}}{2} = e^{\\pm i\\pi/3}$$\n\nLet $\\omega = e^{i\\pi/3}$. The two distinct values for the ratio $x:y$ are $\\omega$ and $\\bar{\\omega}$ (where $\\bar{\\omega} = \\omega^{-1}$).\n\n**Case 1: $x = \\omega y$**\nSubstitute back into $z^2 = xy$:\n$$z^2 = (\\omega y)(y) = \\omega y^2 \\implies z = \\pm \\sqrt{\\omega} \\, y$$\nThis yields two points in projective coordinates (setting $y=1$):\n$P_1 = [\\omega : 1 : \\sqrt{\\omega}]$\n$P_2 = [\\omega : 1 : -\\sqrt{\\omega}]$\n\n**Case 2: $x = \\bar{\\omega} y$**\nSubstitute back into $z^2 = xy$:\n$$z^2 = (\\bar{\\omega} y)(y) = \\bar{\\omega} y^2 \\implies z = \\pm \\sqrt{\\bar{\\omega}} \\, y$$\nThis yields two more points:\n$P_3 = [\\bar{\\omega} : 1 : \\sqrt{\\bar{\\omega}}]$\n$P_4 = [\\bar{\\omega} : 1 : -\\sqrt{\\bar{\\omega}}]$\n\n**Analysis of Multiplicities:**\nWe have found 4 distinct points $P_1, P_2, P_3, P_4$.\nSince the sum of the intersection multiplicities must be 4 (by B\u00e9zout's Theorem) and there are 4 distinct geometric points, each intersection point must have multiplicity exactly 1. This means the curves intersect transversally at these points.\n\n### 4. Conclusion\n\nThe curves $C_1$ and $C_2$ intersect in exactly **4** points in $\\mathbb{P}^2$, counted with multiplicity.\n\n**Final Answer:** 4",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $x > 0$ and consider the function $f(x) = \\frac{\\Gamma(x+1)}{x^x \\sqrt{x}}$, where $\\Gamma(x)$ denotes the Gamma function. Prove that $f(x)$ is strictly decreasing for $x > 0$.",
    "run_id": "21",
    "outer_attempt": 2,
    "topic_slug": "special_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the function $f(x) = \\frac{\\Gamma(x+1)}{x^x \\sqrt{x}}$ is strictly decreasing for $x > 0$, we will analyze the first derivative of its natural logarithm.\n\n### 1. Logarithmic Transformation\n\nLet $g(x) = \\ln f(x)$. Since the natural logarithm is a strictly increasing function, $f(x)$ is strictly decreasing if and only if $g(x)$ is strictly decreasing.\n\nFirst, simplify the expression for $f(x)$:\n$$f(x) = \\frac{\\Gamma(x+1)}{x^x \\cdot x^{1/2}} = \\frac{\\Gamma(x+1)}{x^{x + 1/2}}$$\nUsing the property $\\Gamma(x+1) = x\\Gamma(x)$, we can also write this as:\n$$f(x) = \\frac{x\\Gamma(x)}{x^{x + 1/2}} = \\frac{\\Gamma(x)}{x^{x - 1/2}}$$\nHowever, using the form involving $\\Gamma(x+1)$ directly is convenient. Taking the natural logarithm:\n$$g(x) = \\ln \\Gamma(x+1) - \\left(x + \\frac{1}{2}\\right)\\ln x$$\n\n### 2. Differentiation\n\nWe compute the derivative $g'(x)$ with respect to $x$. Recall that $\\frac{d}{dx} \\ln \\Gamma(z) = \\psi(z)$, where $\\psi(z)$ is the digamma function.\n$$g'(x) = \\frac{d}{dx} \\left( \\ln \\Gamma(x+1) \\right) - \\frac{d}{dx} \\left( \\left(x + \\frac{1}{2}\\right)\\ln x \\right)$$\n$$g'(x) = \\psi(x+1) - \\left[ 1 \\cdot \\ln x + \\left(x + \\frac{1}{2}\\right) \\cdot \\frac{1}{x} \\right]$$\n$$g'(x) = \\psi(x+1) - \\ln x - 1 - \\frac{1}{2x}$$\n\nUsing the recurrence relation $\\psi(x+1) = \\psi(x) + \\frac{1}{x}$, we substitute for $\\psi(x+1)$:\n$$g'(x) = \\left( \\psi(x) + \\frac{1}{x} \\right) - \\ln x - 1 - \\frac{1}{2x}$$\n$$g'(x) = \\psi(x) - \\ln x - 1 + \\frac{1}{2x}$$\n\nTo prove that $f(x)$ is strictly decreasing, we must show that $g'(x) < 0$ for all $x > 0$. In fact, we will prove the stronger inequality $g'(x) < -1$.\n\n### 3. Bound on the Digamma Function\n\nWe utilize the integral representation of the digamma function derived from Binet's second formula for $\\ln \\Gamma(x)$. For $x > 0$:\n$$\\psi(x) = \\ln x - \\frac{1}{2x} - \\int_0^\\infty \\left( \\frac{1}{e^t - 1} - \\frac{1}{t} + \\frac{1}{2} \\right) e^{-xt} \\, dt$$\nLet $\\phi(t) = \\frac{1}{e^t - 1} - \\frac{1}{t} + \\frac{1}{2}$. We investigate the sign of $\\phi(t)$ for $t > 0$.\nRewriting $\\phi(t)$:\n$$\\phi(t) = \\frac{2t - 2(e^t - 1) + t(e^t - 1)}{2t(e^t - 1)} = \\frac{2t - 2e^t + 2 + te^t - t}{2t(e^t - 1)} = \\frac{t + 2 + (t-2)e^t}{2t(e^t - 1)}$$\nSince $2t(e^t - 1) > 0$ for $t > 0$, the sign depends on the numerator $N(t) = t + 2 + (t-2)e^t$.\nWe compute the derivatives of $N(t)$:\n1. $N'(t) = 1 + [1 \\cdot e^t + (t-2)e^t] = 1 + (t-1)e^t$\n2. $N''(t) = [1 \\cdot e^t + (t-1)e^t] = te^t$\n\nFor $t > 0$, $N''(t) > 0$, so $N'(t)$ is strictly increasing.\nSince $N'(0) = 1 + (0-1)(1) = 0$, we have $N'(t) > 0$ for all $t > 0$.\nConsequently, $N(t)$ is strictly increasing.\nSince $N(0) = 0 + 2 + (-2)(1) = 0$, we have $N(t) > 0$ for all $t > 0$.\n\nThus, $\\phi(t) > 0$ for all $t > 0$. Since the integrand is strictly positive, the integral term is strictly positive:\n$$\\int_0^\\infty \\phi(t) e^{-xt} \\, dt > 0$$\nSubstituting this back into the expression for $\\psi(x)$:\n$$\\psi(x) < \\ln x - \\frac{1}{2x}$$\n\n### 4. Establishing the Sign of the Derivative\n\nNow we substitute the inequality for $\\psi(x)$ into our expression for $g'(x)$:\n$$g'(x) = \\psi(x) - \\ln x + \\frac{1}{2x} - 1$$\n$$g'(x) < \\left( \\ln x - \\frac{1}{2x} \\right) - \\ln x + \\frac{1}{2x} - 1$$\n$$g'(x) < -1$$\n\nSince $g'(x) < -1$ for all $x > 0$, it follows that $g'(x) < 0$.\n\n### Conclusion\n\nWe have shown that the derivative of $\\ln f(x)$ is strictly negative for all $x > 0$. Since a function with a strictly negative derivative is strictly decreasing, $g(x)$ is strictly decreasing. Therefore, $f(x) = e^{g(x)}$ is strictly decreasing for $x > 0$.\n\n**Final Result:** The function $f(x)$ is strictly decreasing for $x > 0$.",
        "raw_answer": "To prove that the function $f(x) = \\frac{\\Gamma(x+1)}{x^x \\sqrt{x}}$ is strictly decreasing for $x > 0$, we will analyze the first derivative of its natural logarithm.\n\n### 1. Logarithmic Transformation\n\nLet $g(x) = \\ln f(x)$. Since the natural logarithm is a strictly increasing function, $f(x)$ is strictly decreasing if and only if $g(x)$ is strictly decreasing.\n\nFirst, simplify the expression for $f(x)$:\n$$f(x) = \\frac{\\Gamma(x+1)}{x^x \\cdot x^{1/2}} = \\frac{\\Gamma(x+1)}{x^{x + 1/2}}$$\nUsing the property $\\Gamma(x+1) = x\\Gamma(x)$, we can also write this as:\n$$f(x) = \\frac{x\\Gamma(x)}{x^{x + 1/2}} = \\frac{\\Gamma(x)}{x^{x - 1/2}}$$\nHowever, using the form involving $\\Gamma(x+1)$ directly is convenient. Taking the natural logarithm:\n$$g(x) = \\ln \\Gamma(x+1) - \\left(x + \\frac{1}{2}\\right)\\ln x$$\n\n### 2. Differentiation\n\nWe compute the derivative $g'(x)$ with respect to $x$. Recall that $\\frac{d}{dx} \\ln \\Gamma(z) = \\psi(z)$, where $\\psi(z)$ is the digamma function.\n$$g'(x) = \\frac{d}{dx} \\left( \\ln \\Gamma(x+1) \\right) - \\frac{d}{dx} \\left( \\left(x + \\frac{1}{2}\\right)\\ln x \\right)$$\n$$g'(x) = \\psi(x+1) - \\left[ 1 \\cdot \\ln x + \\left(x + \\frac{1}{2}\\right) \\cdot \\frac{1}{x} \\right]$$\n$$g'(x) = \\psi(x+1) - \\ln x - 1 - \\frac{1}{2x}$$\n\nUsing the recurrence relation $\\psi(x+1) = \\psi(x) + \\frac{1}{x}$, we substitute for $\\psi(x+1)$:\n$$g'(x) = \\left( \\psi(x) + \\frac{1}{x} \\right) - \\ln x - 1 - \\frac{1}{2x}$$\n$$g'(x) = \\psi(x) - \\ln x - 1 + \\frac{1}{2x}$$\n\nTo prove that $f(x)$ is strictly decreasing, we must show that $g'(x) < 0$ for all $x > 0$. In fact, we will prove the stronger inequality $g'(x) < -1$.\n\n### 3. Bound on the Digamma Function\n\nWe utilize the integral representation of the digamma function derived from Binet's second formula for $\\ln \\Gamma(x)$. For $x > 0$:\n$$\\psi(x) = \\ln x - \\frac{1}{2x} - \\int_0^\\infty \\left( \\frac{1}{e^t - 1} - \\frac{1}{t} + \\frac{1}{2} \\right) e^{-xt} \\, dt$$\nLet $\\phi(t) = \\frac{1}{e^t - 1} - \\frac{1}{t} + \\frac{1}{2}$. We investigate the sign of $\\phi(t)$ for $t > 0$.\nRewriting $\\phi(t)$:\n$$\\phi(t) = \\frac{2t - 2(e^t - 1) + t(e^t - 1)}{2t(e^t - 1)} = \\frac{2t - 2e^t + 2 + te^t - t}{2t(e^t - 1)} = \\frac{t + 2 + (t-2)e^t}{2t(e^t - 1)}$$\nSince $2t(e^t - 1) > 0$ for $t > 0$, the sign depends on the numerator $N(t) = t + 2 + (t-2)e^t$.\nWe compute the derivatives of $N(t)$:\n1. $N'(t) = 1 + [1 \\cdot e^t + (t-2)e^t] = 1 + (t-1)e^t$\n2. $N''(t) = [1 \\cdot e^t + (t-1)e^t] = te^t$\n\nFor $t > 0$, $N''(t) > 0$, so $N'(t)$ is strictly increasing.\nSince $N'(0) = 1 + (0-1)(1) = 0$, we have $N'(t) > 0$ for all $t > 0$.\nConsequently, $N(t)$ is strictly increasing.\nSince $N(0) = 0 + 2 + (-2)(1) = 0$, we have $N(t) > 0$ for all $t > 0$.\n\nThus, $\\phi(t) > 0$ for all $t > 0$. Since the integrand is strictly positive, the integral term is strictly positive:\n$$\\int_0^\\infty \\phi(t) e^{-xt} \\, dt > 0$$\nSubstituting this back into the expression for $\\psi(x)$:\n$$\\psi(x) < \\ln x - \\frac{1}{2x}$$\n\n### 4. Establishing the Sign of the Derivative\n\nNow we substitute the inequality for $\\psi(x)$ into our expression for $g'(x)$:\n$$g'(x) = \\psi(x) - \\ln x + \\frac{1}{2x} - 1$$\n$$g'(x) < \\left( \\ln x - \\frac{1}{2x} \\right) - \\ln x + \\frac{1}{2x} - 1$$\n$$g'(x) < -1$$\n\nSince $g'(x) < -1$ for all $x > 0$, it follows that $g'(x) < 0$.\n\n### Conclusion\n\nWe have shown that the derivative of $\\ln f(x)$ is strictly negative for all $x > 0$. Since a function with a strictly negative derivative is strictly decreasing, $g(x)$ is strictly decreasing. Therefore, $f(x) = e^{g(x)}$ is strictly decreasing for $x > 0$.\n\n**Final Result:** The function $f(x)$ is strictly decreasing for $x > 0$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the given topic\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Sequences, series, summability\" along with a complete and verifiable solution. The problem should be simpler than the given previous attempt and must adhere to the quality rubric provided.\n\n## Step 2: Review the quality rubric for question generation\nThe question must be well-posed, clear, non-trivial, solvable, and verifiable. It should not have missing constraints, contradictory premises, multiple incompatible interpretations, undefined objects, or external dependencies.\n\n## Step 3: Analyze the previous attempt\nThe previous attempt was to evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$. This problem involves series and summability, indicating the topic is appropriate. However, the new problem should be simpler.\n\n## Step 4: Generate a new problem that is simpler and well-posed\nTo create a simpler problem, consider a basic series that is well-known and easy to compute. A good candidate could be evaluating a finite series or a simple infinite series that converges to a known value.\n\n## Step 5: Propose a specific problem\nLet's consider the series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$. This is a geometric series with the first term $a = \\frac{1}{2}$ and common ratio $r = \\frac{1}{2}$. The sum of an infinite geometric series is given by $\\frac{a}{1 - r}$ when $|r| < 1$, which applies here.\n\n## Step 6: Formulate the problem statement\nThe problem statement could be: \"Evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$.\"\n\n## Step 7: Provide a complete solution\nTo solve $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$, recognize it as a geometric series. The sum $S$ of the first $n$ terms of a geometric series can be calculated using $S_n = a\\frac{1-r^n}{1-r}$, where $a$ is the first term and $r$ is the common ratio. For an infinite geometric series where $|r| < 1$, the sum is $S = \\frac{a}{1-r}$.\n\n## Step 8: Calculate the sum\nHere, $a = \\frac{1}{2}$ and $r = \\frac{1}{2}$. So, $S = \\frac{\\frac{1}{2}}{1 - \\frac{1}{2}} = \\frac{\\frac{1}{2}}{\\frac{1}{2}} = 1$.\n\n## Step 9: Write the problem and solution in the required format\n\nEvaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$.",
    "run_id": "26",
    "outer_attempt": 2,
    "topic_slug": "sequences_series_and_summability",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$, we identify it as a geometric series and determine its sum based on the properties of such series.\n\n### 1. Identification of the Series\nThe given series is:\n$$ S = \\sum_{n=1}^{\\infty} \\frac{1}{2^n} = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\dots $$\n\nA series is **geometric** if the ratio of any term to its preceding term is constant. Let the $n$-th term be $a_n = \\frac{1}{2^n}$. We calculate the common ratio $r$:\n$$ r = \\frac{a_{n+1}}{a_n} = \\frac{\\frac{1}{2^{n+1}}}{\\frac{1}{2^n}} = \\frac{2^n}{2^{n+1}} = \\frac{1}{2} $$\nSince the ratio is constant for all $n \\ge 1$, this is a geometric series with:\n*   **First term** ($a$): $a_1 = \\frac{1}{2^1} = \\frac{1}{2}$\n*   **Common ratio** ($r$): $\\frac{1}{2}$\n\n### 2. Condition for Convergence\nAn infinite geometric series $\\sum_{n=1}^{\\infty} ar^{n-1}$ converges if and only if the absolute value of the common ratio $|r| < 1$.\n\nIn this case:\n$$ |r| = \\left| \\frac{1}{2} \\right| = \\frac{1}{2} $$\nSince $\\frac{1}{2} < 1$, the series converges to a finite value.\n\n### 3. Calculation of the Sum\nThe sum $S$ of a convergent infinite geometric series is given by the formula:\n$$ S = \\frac{a}{1 - r} $$\nSubstituting the values $a = \\frac{1}{2}$ and $r = \\frac{1}{2}$:\n$$ S = \\frac{\\frac{1}{2}}{1 - \\frac{1}{2}} $$\n$$ S = \\frac{\\frac{1}{2}}{\\frac{1}{2}} $$\n$$ S = 1 $$\n\n### Alternative Verification using Partial Sums\nWe can also verify this by examining the sequence of partial sums $S_N$. The sum of the first $N$ terms of a geometric series is:\n$$ S_N = a \\frac{1 - r^N}{1 - r} $$\nSubstituting our values:\n$$ S_N = \\frac{1}{2} \\cdot \\frac{1 - \\left(\\frac{1}{2}\\right)^N}{1 - \\frac{1}{2}} = \\frac{1}{2} \\cdot \\frac{1 - \\left(\\frac{1}{2}\\right)^N}{\\frac{1}{2}} = 1 - \\left(\\frac{1}{2}\\right)^N $$\nThe sum of the infinite series is the limit of the partial sums as $N \\to \\infty$:\n$$ S = \\lim_{N \\to \\infty} S_N = \\lim_{N \\to \\infty} \\left( 1 - \\left(\\frac{1}{2}\\right)^N \\right) $$\nSince $\\lim_{N \\to \\infty} \\left(\\frac{1}{2}\\right)^N = 0$:\n$$ S = 1 - 0 = 1 $$\n\n### Final Answer\nThe value of the infinite series is:\n$$ \\sum_{n=1}^{\\infty} \\frac{1}{2^n} = 1 $$",
        "raw_answer": "To evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$, we identify it as a geometric series and determine its sum based on the properties of such series.\n\n### 1. Identification of the Series\nThe given series is:\n$$ S = \\sum_{n=1}^{\\infty} \\frac{1}{2^n} = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\dots $$\n\nA series is **geometric** if the ratio of any term to its preceding term is constant. Let the $n$-th term be $a_n = \\frac{1}{2^n}$. We calculate the common ratio $r$:\n$$ r = \\frac{a_{n+1}}{a_n} = \\frac{\\frac{1}{2^{n+1}}}{\\frac{1}{2^n}} = \\frac{2^n}{2^{n+1}} = \\frac{1}{2} $$\nSince the ratio is constant for all $n \\ge 1$, this is a geometric series with:\n*   **First term** ($a$): $a_1 = \\frac{1}{2^1} = \\frac{1}{2}$\n*   **Common ratio** ($r$): $\\frac{1}{2}$\n\n### 2. Condition for Convergence\nAn infinite geometric series $\\sum_{n=1}^{\\infty} ar^{n-1}$ converges if and only if the absolute value of the common ratio $|r| < 1$.\n\nIn this case:\n$$ |r| = \\left| \\frac{1}{2} \\right| = \\frac{1}{2} $$\nSince $\\frac{1}{2} < 1$, the series converges to a finite value.\n\n### 3. Calculation of the Sum\nThe sum $S$ of a convergent infinite geometric series is given by the formula:\n$$ S = \\frac{a}{1 - r} $$\nSubstituting the values $a = \\frac{1}{2}$ and $r = \\frac{1}{2}$:\n$$ S = \\frac{\\frac{1}{2}}{1 - \\frac{1}{2}} $$\n$$ S = \\frac{\\frac{1}{2}}{\\frac{1}{2}} $$\n$$ S = 1 $$\n\n### Alternative Verification using Partial Sums\nWe can also verify this by examining the sequence of partial sums $S_N$. The sum of the first $N$ terms of a geometric series is:\n$$ S_N = a \\frac{1 - r^N}{1 - r} $$\nSubstituting our values:\n$$ S_N = \\frac{1}{2} \\cdot \\frac{1 - \\left(\\frac{1}{2}\\right)^N}{1 - \\frac{1}{2}} = \\frac{1}{2} \\cdot \\frac{1 - \\left(\\frac{1}{2}\\right)^N}{\\frac{1}{2}} = 1 - \\left(\\frac{1}{2}\\right)^N $$\nThe sum of the infinite series is the limit of the partial sums as $N \\to \\infty$:\n$$ S = \\lim_{N \\to \\infty} S_N = \\lim_{N \\to \\infty} \\left( 1 - \\left(\\frac{1}{2}\\right)^N \\right) $$\nSince $\\lim_{N \\to \\infty} \\left(\\frac{1}{2}\\right)^N = 0$:\n$$ S = 1 - 0 = 1 $$\n\n### Final Answer\nThe value of the infinite series is:\n$$ \\sum_{n=1}^{\\infty} \\frac{1}{2^n} = 1 $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the given topic\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Harmonic analysis on Euclidean spaces\" along with a complete and verifiable solution. The problem should be simpler than the given previous attempts but still challenging.\n\n## Step 2: Review the previous attempts and identify the complexity\nThe previous attempt was to prove that a function $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ with its Fourier transform $\\hat{f}$ supported in $B(0,1)$ is smooth and satisfies a certain decay condition. This involves understanding the properties of the Fourier transform, its relation to smoothness, and decay properties of functions.\n\n## Step 3: Simplify the problem while maintaining relevance to the topic\nTo simplify, we can consider a specific case or a related property. For instance, examining the properties of the Fourier transform on $L^2(\\mathbb{R}^n)$ or exploring the smoothness and decay properties for a specific class of functions.\n\n## Step 4: Formulate a new problem\nLet's consider a problem that involves understanding the Fourier transform and its properties. A potential problem could be: \"Let $f(x) = e^{-\\pi|x|^2}$ for $x \\in \\mathbb{R}^n$. Show that $f$ is an eigenfunction of the Fourier transform, i.e., $\\hat{f}(\\xi) = c f(\\xi)$ for some constant $c$, and determine $c$.\"\n\n## Step 5: Verify that the new problem is well-posed and solvable\nThe function $f(x) = e^{-\\pi|x|^2}$ is well-defined and belongs to $L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$. The Fourier transform of $f$ is given by $\\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} e^{-\\pi|x|^2} e^{-2\\pi i x \\cdot \\xi} dx$. This is a standard Gaussian integral, which can be evaluated.\n\n## Step 6: Solve the problem\nTo solve, we compute $\\hat{f}(\\xi)$. For $n=1$, $\\hat{f}(\\xi) = \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} e^{-2\\pi i x \\xi} dx = e^{-\\pi \\xi^2}$, using the known Fourier transform of a Gaussian. For $\\mathbb{R}^n$, the result generalizes to $\\hat{f}(\\xi) = e^{-\\pi |\\xi|^2}$ because the integral separates into $n$ one-dimensional integrals.\n\n## Step 7: Determine the constant $c$\nSince $\\hat{f}(\\xi) = e^{-\\pi |\\xi|^2} = f(\\xi)$, we have $c = 1$.\n\n## Step 8: Present the problem and solution in the required format\n\nLet $f(x) = e^{-\\pi|x|^2}$ for $x \\in \\mathbb{R}^n$. Show that $f$ is an eigenfunction of the Fourier transform, i.e., $\\hat{f}(\\xi) = c f(\\xi)$ for some constant $c$, and determine $c$.",
    "run_id": "28",
    "outer_attempt": 2,
    "topic_slug": "harmonic_analysis_on_euclidean_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the problem of showing that $f(x) = e^{-\\pi|x|^2}$ is an eigenfunction of the Fourier transform and determining the eigenvalue $c$, we proceed through the following steps:\n\n1.  **Decompose the $n$-dimensional integral** into a product of one-dimensional integrals.\n2.  **Evaluate the one-dimensional Fourier transform** of the Gaussian function $g(x) = e^{-\\pi x^2}$ using complex analysis techniques (completing the square and contour integration).\n3.  **Combine the results** to find the Fourier transform of the $n$-dimensional function $f$.\n4.  **Determine the constant $c$**.\n\n### 1. Decomposition of the $n$-dimensional integral\n\nLet $x = (x_1, \\dots, x_n) \\in \\mathbb{R}^n$ and $\\xi = (\\xi_1, \\dots, \\xi_n) \\in \\mathbb{R}^n$. The Euclidean norm squared is $|x|^2 = \\sum_{j=1}^n x_j^2$, and the dot product is $x \\cdot \\xi = \\sum_{j=1}^n x_j \\xi_j$.\n\nThe function $f(x)$ can be written as a product of univariate functions:\n$$ f(x) = e^{-\\pi \\sum_{j=1}^n x_j^2} = \\prod_{j=1}^n e^{-\\pi x_j^2}. $$\n\nThe Fourier transform of $f$ is defined by:\n$$ \\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} f(x) e^{-2\\pi i x \\cdot \\xi} \\, dx. $$\n\nSubstituting the product form of $f(x)$ and the dot product expansion:\n$$ \\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} \\left( \\prod_{j=1}^n e^{-\\pi x_j^2} \\right) e^{-2\\pi i \\sum_{j=1}^n x_j \\xi_j} \\, dx_1 \\dots dx_n. $$\n\nUsing the property of the exponential function $e^{\\sum a_j} = \\prod e^{a_j}$, the integrand becomes:\n$$ \\prod_{j=1}^n \\left( e^{-\\pi x_j^2} e^{-2\\pi i x_j \\xi_j} \\right). $$\n\nSince $f \\in L^1(\\mathbb{R}^n)$, by Fubini's Theorem, we can separate the integral over $\\mathbb{R}^n$ into a product of $n$ integrals over $\\mathbb{R}$:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi x_j^2} e^{-2\\pi i x_j \\xi_j} \\, dx_j \\right). $$\n\nLet $g(t) = e^{-\\pi t^2}$ for $t \\in \\mathbb{R}$. The term inside the product is the one-dimensional Fourier transform of $g$ evaluated at $\\xi_j$, denoted $\\hat{g}(\\xi_j)$. Thus:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n \\hat{g}(\\xi_j). $$\n\n### 2. Evaluation of the 1D Fourier Transform\n\nWe calculate $\\hat{g}(k) = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2} e^{-2\\pi i t k} \\, dt$ for an arbitrary variable $k \\in \\mathbb{R}$.\n\nCombine the exponents:\n$$ -\\pi t^2 - 2\\pi i t k = -\\pi \\left( t^2 + 2i t k \\right). $$\nWe complete the square for the term in the parentheses:\n$$ t^2 + 2i t k = (t + ik)^2 - (ik)^2 = (t + ik)^2 + k^2. $$\nSubstituting this back into the exponent:\n$$ -\\pi (t^2 + 2i t k) = -\\pi \\left( (t + ik)^2 + k^2 \\right) = -\\pi (t + ik)^2 - \\pi k^2. $$\nThus, the integral becomes:\n$$ \\hat{g}(k) = e^{-\\pi k^2} \\int_{-\\infty}^{\\infty} e^{-\\pi (t + ik)^2} \\, dt. $$\n\nTo evaluate the integral $I = \\int_{-\\infty}^{\\infty} e^{-\\pi (t + ik)^2} \\, dt$, we consider the complex function $h(z) = e^{-\\pi z^2}$. We integrate $h(z)$ over a rectangular contour $C_R$ in the complex plane with vertices at $-R$, $R$, $R+ik$, and $-R+ik$.\n\nSince $h(z)$ is an entire function, by Cauchy's Integral Theorem:\n$$ \\oint_{C_R} e^{-\\pi z^2} \\, dz = 0. $$\nThis integral splits into four segments:\n1.  From $-R$ to $R$ (real axis): $\\int_{-R}^{R} e^{-\\pi x^2} \\, dx$.\n2.  From $R$ to $R+ik$: $\\int_{0}^{k} e^{-\\pi (R+iy)^2} i \\, dy$.\n3.  From $R+ik$ to $-R+ik$: $\\int_{R}^{-R} e^{-\\pi (x+ik)^2} \\, dx = -\\int_{-R}^{R} e^{-\\pi (x+ik)^2} \\, dx$.\n4.  From $-R+ik$ to $-R$: $\\int_{k}^{0} e^{-\\pi (-R+iy)^2} i \\, dy$.\n\nWe analyze the vertical segments (2 and 4). For $z = \\pm R + iy$ where $y \\in [0, k]$ (assuming $k>0$ without loss of generality):\n$$ |e^{-\\pi (\\pm R + iy)^2}| = e^{-\\pi (R^2 - y^2)} = e^{-\\pi R^2} e^{\\pi y^2}. $$\nThe magnitude of the integral is bounded by $k e^{\\pi k^2} e^{-\\pi R^2}$. As $R \\to \\infty$, $e^{-\\pi R^2} \\to 0$, so the integrals over the vertical sides vanish.\n\nTaking the limit $R \\to \\infty$, we have:\n$$ \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} \\, dx - \\int_{-\\infty}^{\\infty} e^{-\\pi (x+ik)^2} \\, dx = 0. $$\nTherefore:\n$$ \\int_{-\\infty}^{\\infty} e^{-\\pi (t + ik)^2} \\, dt = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2} \\, dt. $$\n\nNow we compute the standard Gaussian integral $J = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2} \\, dt$.\n$$ J^2 = \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} \\, dx \\right) \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi y^2} \\, dy \\right) = \\int_{\\mathbb{R}^2} e^{-\\pi (x^2+y^2)} \\, dx \\, dy. $$\nSwitching to polar coordinates ($r, \\theta$):\n$$ J^2 = \\int_{0}^{2\\pi} d\\theta \\int_{0}^{\\infty} e^{-\\pi r^2} r \\, dr = 2\\pi \\left[ -\\frac{1}{2\\pi} e^{-\\pi r^2} \\right]_0^{\\infty} = 2\\pi \\left( 0 - \\left(-\\frac{1}{2\\pi}\\right) \\right) = 1. $$\nSince $e^{-\\pi t^2}$ is positive, $J = 1$.\n\nSubstituting this back into the expression for $\\hat{g}(k)$:\n$$ \\hat{g}(k) = e^{-\\pi k^2} \\cdot 1 = e^{-\\pi k^2}. $$\n\n### 3. Synthesis for the $n$-dimensional function\n\nUsing the result from Step 2 in the product formula from Step 1:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n \\hat{g}(\\xi_j) = \\prod_{j=1}^n e^{-\\pi \\xi_j^2} = e^{-\\pi \\sum_{j=1}^n \\xi_j^2} = e^{-\\pi |\\xi|^2}. $$\n\n### 4. Conclusion and Determination of $c$\n\nWe have shown that:\n$$ \\hat{f}(\\xi) = e^{-\\pi |\\xi|^2}. $$\nRecall that $f(x) = e^{-\\pi |x|^2}$, so $f(\\xi) = e^{-\\pi |\\xi|^2}$.\nThus:\n$$ \\hat{f}(\\xi) = 1 \\cdot f(\\xi). $$\nComparing this to the eigenfunction equation $\\hat{f}(\\xi) = c f(\\xi)$, we determine that the constant $c$ is:\n\n**Answer:**\nThe function $f(x) = e^{-\\pi|x|^2}$ is an eigenfunction of the Fourier transform with eigenvalue **$c = 1$**.",
        "raw_answer": "To solve the problem of showing that $f(x) = e^{-\\pi|x|^2}$ is an eigenfunction of the Fourier transform and determining the eigenvalue $c$, we proceed through the following steps:\n\n1.  **Decompose the $n$-dimensional integral** into a product of one-dimensional integrals.\n2.  **Evaluate the one-dimensional Fourier transform** of the Gaussian function $g(x) = e^{-\\pi x^2}$ using complex analysis techniques (completing the square and contour integration).\n3.  **Combine the results** to find the Fourier transform of the $n$-dimensional function $f$.\n4.  **Determine the constant $c$**.\n\n### 1. Decomposition of the $n$-dimensional integral\n\nLet $x = (x_1, \\dots, x_n) \\in \\mathbb{R}^n$ and $\\xi = (\\xi_1, \\dots, \\xi_n) \\in \\mathbb{R}^n$. The Euclidean norm squared is $|x|^2 = \\sum_{j=1}^n x_j^2$, and the dot product is $x \\cdot \\xi = \\sum_{j=1}^n x_j \\xi_j$.\n\nThe function $f(x)$ can be written as a product of univariate functions:\n$$ f(x) = e^{-\\pi \\sum_{j=1}^n x_j^2} = \\prod_{j=1}^n e^{-\\pi x_j^2}. $$\n\nThe Fourier transform of $f$ is defined by:\n$$ \\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} f(x) e^{-2\\pi i x \\cdot \\xi} \\, dx. $$\n\nSubstituting the product form of $f(x)$ and the dot product expansion:\n$$ \\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} \\left( \\prod_{j=1}^n e^{-\\pi x_j^2} \\right) e^{-2\\pi i \\sum_{j=1}^n x_j \\xi_j} \\, dx_1 \\dots dx_n. $$\n\nUsing the property of the exponential function $e^{\\sum a_j} = \\prod e^{a_j}$, the integrand becomes:\n$$ \\prod_{j=1}^n \\left( e^{-\\pi x_j^2} e^{-2\\pi i x_j \\xi_j} \\right). $$\n\nSince $f \\in L^1(\\mathbb{R}^n)$, by Fubini's Theorem, we can separate the integral over $\\mathbb{R}^n$ into a product of $n$ integrals over $\\mathbb{R}$:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi x_j^2} e^{-2\\pi i x_j \\xi_j} \\, dx_j \\right). $$\n\nLet $g(t) = e^{-\\pi t^2}$ for $t \\in \\mathbb{R}$. The term inside the product is the one-dimensional Fourier transform of $g$ evaluated at $\\xi_j$, denoted $\\hat{g}(\\xi_j)$. Thus:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n \\hat{g}(\\xi_j). $$\n\n### 2. Evaluation of the 1D Fourier Transform\n\nWe calculate $\\hat{g}(k) = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2} e^{-2\\pi i t k} \\, dt$ for an arbitrary variable $k \\in \\mathbb{R}$.\n\nCombine the exponents:\n$$ -\\pi t^2 - 2\\pi i t k = -\\pi \\left( t^2 + 2i t k \\right). $$\nWe complete the square for the term in the parentheses:\n$$ t^2 + 2i t k = (t + ik)^2 - (ik)^2 = (t + ik)^2 + k^2. $$\nSubstituting this back into the exponent:\n$$ -\\pi (t^2 + 2i t k) = -\\pi \\left( (t + ik)^2 + k^2 \\right) = -\\pi (t + ik)^2 - \\pi k^2. $$\nThus, the integral becomes:\n$$ \\hat{g}(k) = e^{-\\pi k^2} \\int_{-\\infty}^{\\infty} e^{-\\pi (t + ik)^2} \\, dt. $$\n\nTo evaluate the integral $I = \\int_{-\\infty}^{\\infty} e^{-\\pi (t + ik)^2} \\, dt$, we consider the complex function $h(z) = e^{-\\pi z^2}$. We integrate $h(z)$ over a rectangular contour $C_R$ in the complex plane with vertices at $-R$, $R$, $R+ik$, and $-R+ik$.\n\nSince $h(z)$ is an entire function, by Cauchy's Integral Theorem:\n$$ \\oint_{C_R} e^{-\\pi z^2} \\, dz = 0. $$\nThis integral splits into four segments:\n1.  From $-R$ to $R$ (real axis): $\\int_{-R}^{R} e^{-\\pi x^2} \\, dx$.\n2.  From $R$ to $R+ik$: $\\int_{0}^{k} e^{-\\pi (R+iy)^2} i \\, dy$.\n3.  From $R+ik$ to $-R+ik$: $\\int_{R}^{-R} e^{-\\pi (x+ik)^2} \\, dx = -\\int_{-R}^{R} e^{-\\pi (x+ik)^2} \\, dx$.\n4.  From $-R+ik$ to $-R$: $\\int_{k}^{0} e^{-\\pi (-R+iy)^2} i \\, dy$.\n\nWe analyze the vertical segments (2 and 4). For $z = \\pm R + iy$ where $y \\in [0, k]$ (assuming $k>0$ without loss of generality):\n$$ |e^{-\\pi (\\pm R + iy)^2}| = e^{-\\pi (R^2 - y^2)} = e^{-\\pi R^2} e^{\\pi y^2}. $$\nThe magnitude of the integral is bounded by $k e^{\\pi k^2} e^{-\\pi R^2}$. As $R \\to \\infty$, $e^{-\\pi R^2} \\to 0$, so the integrals over the vertical sides vanish.\n\nTaking the limit $R \\to \\infty$, we have:\n$$ \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} \\, dx - \\int_{-\\infty}^{\\infty} e^{-\\pi (x+ik)^2} \\, dx = 0. $$\nTherefore:\n$$ \\int_{-\\infty}^{\\infty} e^{-\\pi (t + ik)^2} \\, dt = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2} \\, dt. $$\n\nNow we compute the standard Gaussian integral $J = \\int_{-\\infty}^{\\infty} e^{-\\pi t^2} \\, dt$.\n$$ J^2 = \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} \\, dx \\right) \\left( \\int_{-\\infty}^{\\infty} e^{-\\pi y^2} \\, dy \\right) = \\int_{\\mathbb{R}^2} e^{-\\pi (x^2+y^2)} \\, dx \\, dy. $$\nSwitching to polar coordinates ($r, \\theta$):\n$$ J^2 = \\int_{0}^{2\\pi} d\\theta \\int_{0}^{\\infty} e^{-\\pi r^2} r \\, dr = 2\\pi \\left[ -\\frac{1}{2\\pi} e^{-\\pi r^2} \\right]_0^{\\infty} = 2\\pi \\left( 0 - \\left(-\\frac{1}{2\\pi}\\right) \\right) = 1. $$\nSince $e^{-\\pi t^2}$ is positive, $J = 1$.\n\nSubstituting this back into the expression for $\\hat{g}(k)$:\n$$ \\hat{g}(k) = e^{-\\pi k^2} \\cdot 1 = e^{-\\pi k^2}. $$\n\n### 3. Synthesis for the $n$-dimensional function\n\nUsing the result from Step 2 in the product formula from Step 1:\n$$ \\hat{f}(\\xi) = \\prod_{j=1}^n \\hat{g}(\\xi_j) = \\prod_{j=1}^n e^{-\\pi \\xi_j^2} = e^{-\\pi \\sum_{j=1}^n \\xi_j^2} = e^{-\\pi |\\xi|^2}. $$\n\n### 4. Conclusion and Determination of $c$\n\nWe have shown that:\n$$ \\hat{f}(\\xi) = e^{-\\pi |\\xi|^2}. $$\nRecall that $f(x) = e^{-\\pi |x|^2}$, so $f(\\xi) = e^{-\\pi |\\xi|^2}$.\nThus:\n$$ \\hat{f}(\\xi) = 1 \\cdot f(\\xi). $$\nComparing this to the eigenfunction equation $\\hat{f}(\\xi) = c f(\\xi)$, we determine that the constant $c$ is:\n\n**Answer:**\nThe function $f(x) = e^{-\\pi|x|^2}$ is an eigenfunction of the Fourier transform with eigenvalue **$c = 1$**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $G$ be a locally compact abelian group with Haar measure $\\mu$. Suppose $f \\in L^1(G, \\mu) \\cap L^2(G, \\mu)$ and that the Fourier transform of $f$, denoted $\\hat{f}$, is also in $L^1(G, \\mu)$. Prove that $f$ is equal almost everywhere to a continuous function on $G$.",
    "run_id": "29",
    "outer_attempt": 2,
    "topic_slug": "abstract_harmonic_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Analysis of the Problem Statement**\n\nThe question asks for a proof regarding a function $f$ on a locally compact abelian group $G$. However, the problem statement contains a fundamental mathematical inconsistency regarding the domain of the Fourier transform. Therefore, the question is **ill-posed** and cannot be answered rigorously as stated.\n\n**Specific Violation: Undefined Objects and Domain Mismatch**\n\n1.  **Definitions and Domains:**\n    *   Let $G$ be a locally compact abelian group with Haar measure $\\mu$.\n    *   The function $f$ is given to be in $L^1(G, \\mu) \\cap L^2(G, \\mu)$, meaning $f$ is a function defined on the group $G$.\n    *   The Fourier transform of $f$, denoted $\\hat{f}$, is a function defined on the **dual group** $\\widehat{G}$. That is, $\\hat{f}: \\widehat{G} \\to \\mathbb{C}$, defined (for $f \\in L^1$) by $\\hat{f}(\\gamma) = \\int_G f(x) \\overline{\\gamma(x)} \\, d\\mu(x)$ for $\\gamma \\in \\widehat{G}$.\n\n2.  **The Error:**\n    *   The problem states: \"the Fourier transform of $f$... is also in $L^1(G, \\mu)$.\"\n    *   The space $L^1(G, \\mu)$ consists of equivalence classes of integrable functions defined on the group $G$.\n    *   Since $\\hat{f}$ is defined on the dual group $\\widehat{G}$, it cannot belong to $L^1(G, \\mu)$ unless $G$ and $\\widehat{G}$ are the same space.\n    *   For a general locally compact abelian group, $G$ and $\\widehat{G}$ are distinct. For example, if $G$ is the circle group $\\mathbb{T}$, then $\\widehat{G}$ is the group of integers $\\mathbb{Z}$. A function defined on $\\mathbb{Z}$ (a sequence) cannot belong to $L^1(\\mathbb{T})$ (functions on the circle).\n\n**Conclusion**\n\nThe premise $\\hat{f} \\in L^1(G, \\mu)$ treats a function defined on the dual group $\\widehat{G}$ as a function on the primal group $G$. Without a specific canonical identification between $G$ and $\\widehat{G}$ (which does not exist for general LCA groups), this condition is mathematically undefined.\n\n**Suggestion for Clarification**\n\nTo make the question well-posed and answerable, the condition on the Fourier transform should be defined on the appropriate measure space. The likely intended hypothesis is:\n$$ \\hat{f} \\in L^1(\\widehat{G}, \\widehat{\\mu}) $$\nwhere $\\widehat{\\mu}$ is the Haar measure on the dual group $\\widehat{G}$. Under this corrected hypothesis, the problem becomes a standard application of the Fourier Inversion Theorem, which states that if $f \\in L^1(G)$ and $\\hat{f} \\in L^1(\\widehat{G})$, then $f$ agrees almost everywhere with a continuous function (specifically, the inverse Fourier transform of $\\hat{f}$).",
        "raw_answer": "**Analysis of the Problem Statement**\n\nThe question asks for a proof regarding a function $f$ on a locally compact abelian group $G$. However, the problem statement contains a fundamental mathematical inconsistency regarding the domain of the Fourier transform. Therefore, the question is **ill-posed** and cannot be answered rigorously as stated.\n\n**Specific Violation: Undefined Objects and Domain Mismatch**\n\n1.  **Definitions and Domains:**\n    *   Let $G$ be a locally compact abelian group with Haar measure $\\mu$.\n    *   The function $f$ is given to be in $L^1(G, \\mu) \\cap L^2(G, \\mu)$, meaning $f$ is a function defined on the group $G$.\n    *   The Fourier transform of $f$, denoted $\\hat{f}$, is a function defined on the **dual group** $\\widehat{G}$. That is, $\\hat{f}: \\widehat{G} \\to \\mathbb{C}$, defined (for $f \\in L^1$) by $\\hat{f}(\\gamma) = \\int_G f(x) \\overline{\\gamma(x)} \\, d\\mu(x)$ for $\\gamma \\in \\widehat{G}$.\n\n2.  **The Error:**\n    *   The problem states: \"the Fourier transform of $f$... is also in $L^1(G, \\mu)$.\"\n    *   The space $L^1(G, \\mu)$ consists of equivalence classes of integrable functions defined on the group $G$.\n    *   Since $\\hat{f}$ is defined on the dual group $\\widehat{G}$, it cannot belong to $L^1(G, \\mu)$ unless $G$ and $\\widehat{G}$ are the same space.\n    *   For a general locally compact abelian group, $G$ and $\\widehat{G}$ are distinct. For example, if $G$ is the circle group $\\mathbb{T}$, then $\\widehat{G}$ is the group of integers $\\mathbb{Z}$. A function defined on $\\mathbb{Z}$ (a sequence) cannot belong to $L^1(\\mathbb{T})$ (functions on the circle).\n\n**Conclusion**\n\nThe premise $\\hat{f} \\in L^1(G, \\mu)$ treats a function defined on the dual group $\\widehat{G}$ as a function on the primal group $G$. Without a specific canonical identification between $G$ and $\\widehat{G}$ (which does not exist for general LCA groups), this condition is mathematically undefined.\n\n**Suggestion for Clarification**\n\nTo make the question well-posed and answerable, the condition on the Fourier transform should be defined on the appropriate measure space. The likely intended hypothesis is:\n$$ \\hat{f} \\in L^1(\\widehat{G}, \\widehat{\\mu}) $$\nwhere $\\widehat{\\mu}$ is the Haar measure on the dual group $\\widehat{G}$. Under this corrected hypothesis, the problem becomes a standard application of the Fourier Inversion Theorem, which states that if $f \\in L^1(G)$ and $\\hat{f} \\in L^1(\\widehat{G})$, then $f$ agrees almost everywhere with a continuous function (specifically, the inverse Fourier transform of $\\hat{f}$).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Operator Theory, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Review the given topic and previous attempts\nThe topic is Operator Theory, and a previous attempt was made with the question: \"Let $T: L^2[0,1] \\to L^2[0,1]$ be defined by $Tf(x) = \\int_{0}^{x} f(t) dt$. Prove that $T$ is compact and find its spectrum.\" This question was adjudicated incorrect, and we need to generate a materially different, well-posed, and simpler question.\n\n## Step 3: Identify key concepts in Operator Theory\nOperator Theory involves the study of linear operators between vector spaces, particularly focusing on their properties such as boundedness, compactness, and spectral properties. A simpler question should still involve these concepts but in a more straightforward manner.\n\n## Step 4: Generate a new problem\nTo create a simpler problem, consider a basic operator and ask a fundamental question about its properties. For example, consider the operator $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ defined by a matrix. We can ask to determine if $T$ is bounded and find its spectrum.\n\n## Step 5: Formulate the problem\nLet's define $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ by $T(x, y) = (x + y, y)$. This can be represented by the matrix $\\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$. The task is to show that $T$ is bounded and to find its spectrum.\n\n## Step 6: Write the problem statement\n\"Let $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ be defined by $T(x, y) = (x + y, y)$. Show that $T$ is a bounded operator and find its spectrum.\"\n\n## Step 7: Provide the solution\nTo show $T$ is bounded, we need to show there exists a constant $M$ such that $\\|T(x, y)\\| \\leq M\\|(x, y)\\|$ for all $(x, y) \\in \\mathbb{C}^2$. Using the standard Euclidean norm, $\\|(x, y)\\| = \\sqrt{|x|^2 + |y|^2}$, we have $\\|T(x, y)\\| = \\|(x + y, y)\\| = \\sqrt{|x + y|^2 + |y|^2}$. By the triangle inequality, $|x + y| \\leq |x| + |y|$, so $|x + y|^2 \\leq (|x| + |y|)^2 \\leq 2(|x|^2 + |y|^2)$, hence $\\|T(x, y)\\| = \\sqrt{|x + y|^2 + |y|^2} \\leq \\sqrt{2(|x|^2 + |y|^2) + |y|^2} = \\sqrt{2|x|^2 + 3|y|^2} \\leq \\sqrt{3(|x|^2 + |y|^2)} = \\sqrt{3}\\|(x, y)\\|$. Thus, $T$ is bounded with $M = \\sqrt{3}$.\n\nTo find the spectrum, we need to find $\\lambda$ such that $T - \\lambda I$ is not invertible. The matrix representation of $T - \\lambda I$ is $\\begin{pmatrix} 1 - \\lambda & 1 \\\\ 0 & 1 - \\lambda \\end{pmatrix}$. This matrix is not invertible if its determinant is zero, i.e., $(1 - \\lambda)^2 = 0$. Thus, $\\lambda = 1$ is the only eigenvalue, and since $T$ is a bounded operator on a finite-dimensional space, its spectrum consists of its eigenvalues. Hence, the spectrum of $T$ is $\\{1\\}$.\n\n## Step 8: Format the output\n\nLet $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ be defined by $T(x, y) = (x + y, y)$. Show that $T$ is a bounded operator and find its spectrum.",
    "run_id": "33",
    "outer_attempt": 2,
    "topic_slug": "operator_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete solution to the problem.\n\n### Problem Statement\nLet $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ be defined by $T(x, y) = (x + y, y)$. Show that $T$ is a bounded operator and find its spectrum.\n\n### Solution\n\n#### Part 1: Matrix Representation\nFirst, we express the operator $T$ as a matrix with respect to the standard basis $e_1 = (1,0), e_2 = (0,1)$ of $\\mathbb{C}^2$.\nWe have:\n$$T(e_1) = T(1, 0) = (1+0, 0) = (1, 0) = 1e_1 + 0e_2$$\n$$T(e_2) = T(0, 1) = (0+1, 1) = (1, 1) = 1e_1 + 1e_2$$\n\nThus, the matrix representation $A$ of $T$ is:\n$$A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$$\nFor any vector $v = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$, $Tv = Av$.\n\n#### Part 2: Proof of Boundedness\n**Definition:** A linear operator $T$ on a normed vector space $X$ is **bounded** if there exists a real constant $M \\geq 0$ such that for all $v \\in X$:\n$$ \\|Tv\\| \\leq M \\|v\\| $$\n\nWe will use the standard Euclidean 2-norm on $\\mathbb{C}^2$, defined by $\\|(x,y)\\|_2 = \\sqrt{|x|^2 + |y|^2}$. Note that since $\\mathbb{C}^2$ is finite-dimensional, all norms are equivalent; proving boundedness in one norm implies boundedness in all others.\n\nLet $v = (x, y) \\in \\mathbb{C}^2$. Then:\n$$ \\|Tv\\|_2^2 = \\|(x+y, y)\\|_2^2 = |x+y|^2 + |y|^2 $$\n\nUsing the triangle inequality $|x+y| \\leq |x| + |y|$ and the inequality $(a+b)^2 \\leq 2(a^2 + b^2)$ for non-negative real numbers $a, b$:\n$$ |x+y|^2 \\leq (|x| + |y|)^2 \\leq 2(|x|^2 + |y|^2) $$\n\nSubstituting this back into the expression for $\\|Tv\\|_2^2$:\n$$ \\|Tv\\|_2^2 \\leq 2(|x|^2 + |y|^2) + |y|^2 = 2|x|^2 + 3|y|^2 $$\n\nSince $2|x|^2 + 3|y|^2 \\leq 3(|x|^2 + |y|^2)$:\n$$ \\|Tv\\|_2^2 \\leq 3(\\|v\\|_2^2) $$\n\nTaking the square root of both sides gives:\n$$ \\|Tv\\|_2 \\leq \\sqrt{3} \\|v\\|_2 $$\n\n**Conclusion for Part 2:**\nSince there exists a constant $M = \\sqrt{3}$ such that $\\|Tv\\| \\leq M\\|v\\|$ for all $v \\in \\mathbb{C}^2$, **$T$ is a bounded operator.**\n\n*(Note: It is a general theorem that every linear operator on a finite-dimensional normed space is bounded, but the derivation above provides the explicit verification requested.)*\n\n#### Part 3: Finding the Spectrum\n**Definition:** For a bounded linear operator on a finite-dimensional space, the **spectrum** $\\sigma(T)$ consists of the set of eigenvalues of $T$. Specifically, $\\lambda \\in \\sigma(T)$ if and only if the operator $(T - \\lambda I)$ is not invertible (i.e., singular).\n\nThis corresponds to finding the roots of the characteristic polynomial $p(\\lambda) = \\det(A - \\lambda I)$.\n\nUsing the matrix representation $A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$:\n$$ A - \\lambda I = \\begin{pmatrix} 1 - \\lambda & 1 \\\\ 0 & 1 - \\lambda \\end{pmatrix} $$\n\nCompute the determinant:\n$$ \\det(A - \\lambda I) = (1 - \\lambda)(1 - \\lambda) - (1)(0) = (1 - \\lambda)^2 $$\n\nSet the determinant to zero to find the eigenvalues:\n$$ (1 - \\lambda)^2 = 0 $$\n\nThis equation has a single root $\\lambda = 1$ with algebraic multiplicity 2.\n\n**Conclusion for Part 3:**\nThe spectrum of $T$ is the set containing this eigenvalue.\n$$ \\sigma(T) = \\{1\\} $$\n\n### Final Answer\nThe operator $T$ is **bounded** (with operator norm $\\|T\\| \\leq \\sqrt{3}$ under the Euclidean norm), and its spectrum is **$\\sigma(T) = \\{1\\}$**.",
        "raw_answer": "Here is the complete solution to the problem.\n\n### Problem Statement\nLet $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ be defined by $T(x, y) = (x + y, y)$. Show that $T$ is a bounded operator and find its spectrum.\n\n### Solution\n\n#### Part 1: Matrix Representation\nFirst, we express the operator $T$ as a matrix with respect to the standard basis $e_1 = (1,0), e_2 = (0,1)$ of $\\mathbb{C}^2$.\nWe have:\n$$T(e_1) = T(1, 0) = (1+0, 0) = (1, 0) = 1e_1 + 0e_2$$\n$$T(e_2) = T(0, 1) = (0+1, 1) = (1, 1) = 1e_1 + 1e_2$$\n\nThus, the matrix representation $A$ of $T$ is:\n$$A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$$\nFor any vector $v = \\begin{pmatrix} x \\\\ y \\end{pmatrix}$, $Tv = Av$.\n\n#### Part 2: Proof of Boundedness\n**Definition:** A linear operator $T$ on a normed vector space $X$ is **bounded** if there exists a real constant $M \\geq 0$ such that for all $v \\in X$:\n$$ \\|Tv\\| \\leq M \\|v\\| $$\n\nWe will use the standard Euclidean 2-norm on $\\mathbb{C}^2$, defined by $\\|(x,y)\\|_2 = \\sqrt{|x|^2 + |y|^2}$. Note that since $\\mathbb{C}^2$ is finite-dimensional, all norms are equivalent; proving boundedness in one norm implies boundedness in all others.\n\nLet $v = (x, y) \\in \\mathbb{C}^2$. Then:\n$$ \\|Tv\\|_2^2 = \\|(x+y, y)\\|_2^2 = |x+y|^2 + |y|^2 $$\n\nUsing the triangle inequality $|x+y| \\leq |x| + |y|$ and the inequality $(a+b)^2 \\leq 2(a^2 + b^2)$ for non-negative real numbers $a, b$:\n$$ |x+y|^2 \\leq (|x| + |y|)^2 \\leq 2(|x|^2 + |y|^2) $$\n\nSubstituting this back into the expression for $\\|Tv\\|_2^2$:\n$$ \\|Tv\\|_2^2 \\leq 2(|x|^2 + |y|^2) + |y|^2 = 2|x|^2 + 3|y|^2 $$\n\nSince $2|x|^2 + 3|y|^2 \\leq 3(|x|^2 + |y|^2)$:\n$$ \\|Tv\\|_2^2 \\leq 3(\\|v\\|_2^2) $$\n\nTaking the square root of both sides gives:\n$$ \\|Tv\\|_2 \\leq \\sqrt{3} \\|v\\|_2 $$\n\n**Conclusion for Part 2:**\nSince there exists a constant $M = \\sqrt{3}$ such that $\\|Tv\\| \\leq M\\|v\\|$ for all $v \\in \\mathbb{C}^2$, **$T$ is a bounded operator.**\n\n*(Note: It is a general theorem that every linear operator on a finite-dimensional normed space is bounded, but the derivation above provides the explicit verification requested.)*\n\n#### Part 3: Finding the Spectrum\n**Definition:** For a bounded linear operator on a finite-dimensional space, the **spectrum** $\\sigma(T)$ consists of the set of eigenvalues of $T$. Specifically, $\\lambda \\in \\sigma(T)$ if and only if the operator $(T - \\lambda I)$ is not invertible (i.e., singular).\n\nThis corresponds to finding the roots of the characteristic polynomial $p(\\lambda) = \\det(A - \\lambda I)$.\n\nUsing the matrix representation $A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$:\n$$ A - \\lambda I = \\begin{pmatrix} 1 - \\lambda & 1 \\\\ 0 & 1 - \\lambda \\end{pmatrix} $$\n\nCompute the determinant:\n$$ \\det(A - \\lambda I) = (1 - \\lambda)(1 - \\lambda) - (1)(0) = (1 - \\lambda)^2 $$\n\nSet the determinant to zero to find the eigenvalues:\n$$ (1 - \\lambda)^2 = 0 $$\n\nThis equation has a single root $\\lambda = 1$ with algebraic multiplicity 2.\n\n**Conclusion for Part 3:**\nThe spectrum of $T$ is the set containing this eigenvalue.\n$$ \\sigma(T) = \\{1\\} $$\n\n### Final Answer\nThe operator $T$ is **bounded** (with operator norm $\\|T\\| \\leq \\sqrt{3}$ under the Euclidean norm), and its spectrum is **$\\sigma(T) = \\{1\\}$**.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task requires generating a challenging but solvable mathematics problem in the domain of calculus of variations and optimal control, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable problem in the domain\nA classic problem in calculus of variations is finding the curve that minimizes the distance between two points. However, to make it more challenging and relevant to optimal control, we can consider a problem that involves optimizing a functional subject to certain constraints.\n\n## Step 3: Formulate the problem\nLet's consider the problem of finding the function $y(x)$ that minimizes the functional $J[y] = \\int_{0}^{1} (y'^2 + y) \\,dx$, subject to the boundary conditions $y(0) = 0$ and $y(1) = 1$. This problem is relevant to the calculus of variations and involves optimizing a functional.\n\n## Step 4: Write down the problem statement\nThe problem can be stated as: \"Minimize $J[y] = \\int_{0}^{1} (y'^2 + y) \\,dx$ subject to $y(0) = 0$ and $y(1) = 1$, where $y(x)$ is a continuously differentiable function on $[0,1]$.\"\n\n## Step 5: Provide the solution to the problem\nTo solve this, we use the Euler-Lagrange equation, which states that for a functional $J[y] = \\int_{a}^{b} F(x, y, y') \\,dx$, the extremal $y(x)$ satisfies $\\frac{\\partial F}{\\partial y} - \\frac{d}{dx}(\\frac{\\partial F}{\\partial y'}) = 0$. Here, $F = y'^2 + y$, so $\\frac{\\partial F}{\\partial y} = 1$ and $\\frac{\\partial F}{\\partial y'} = 2y'$.\n\n## Step 6: Apply the Euler-Lagrange equation\nSubstituting into the Euler-Lagrange equation gives $1 - \\frac{d}{dx}(2y') = 0$, which simplifies to $1 - 2y'' = 0$. Thus, $y'' = \\frac{1}{2}$.\n\n## Step 7: Solve the differential equation\nIntegrating $y'' = \\frac{1}{2}$ twice gives $y(x) = \\frac{x^2}{4} + Ax + B$, where $A$ and $B$ are constants.\n\n## Step 8: Apply the boundary conditions\nUsing $y(0) = 0$ gives $B = 0$, and $y(1) = 1$ gives $1 = \\frac{1}{4} + A$, so $A = \\frac{3}{4}$.\n\n## Step 9: Write the solution\nThus, $y(x) = \\frac{x^2}{4} + \\frac{3x}{4}$.\n\n## Step 10: Verify the solution\nTo verify, we check that $y(x)$ satisfies the boundary conditions and the Euler-Lagrange equation. $y(0) = 0$ and $y(1) = \\frac{1}{4} + \\frac{3}{4} = 1$, so the boundary conditions are satisfied. The function $y(x)$ is also continuously differentiable.\n\nThe final answer is:\n\n\n\nMinimize $J[y] = \\int_{0}^{1} (y'^2 + y) \\,dx$ subject to $y(0) = 0$ and $y(1) = 1$, where $y(x)$ is a continuously differentiable function on $[0,1]$.",
    "run_id": "34",
    "outer_attempt": 2,
    "topic_slug": "calculus_of_variations_and_optimization",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the optimization problem presented, we seek a function $y(x) \\in C^1[0,1]$ that minimizes the functional:\n$$ J[y] = \\int_{0}^{1} (y'^2 + y) \\, dx $$\nsubject to the boundary conditions:\n$$ y(0) = 0 \\quad \\text{and} \\quad y(1) = 1 $$\n\n### 1. The Euler-Lagrange Equation\n\nThe fundamental lemma of the calculus of variations states that if $y(x)$ provides a local extremum for the functional $J[y] = \\int_{a}^{b} F(x, y, y') \\, dx$, and $y(x)$ is twice continuously differentiable, it must satisfy the Euler-Lagrange equation:\n$$ \\frac{\\partial F}{\\partial y} - \\frac{d}{dx} \\left( \\frac{\\partial F}{\\partial y'} \\right) = 0 $$\n\nFor this problem, the integrand is:\n$$ F(x, y, y') = (y')^2 + y $$\n\nWe compute the necessary partial derivatives:\n1.  **Partial with respect to $y$:**\n    $$ \\frac{\\partial F}{\\partial y} = \\frac{\\partial}{\\partial y} \\left( (y')^2 + y \\right) = 1 $$\n\n2.  **Partial with respect to $y'$:**\n    $$ \\frac{\\partial F}{\\partial y'} = \\frac{\\partial}{\\partial y'} \\left( (y')^2 + y \\right) = 2y' $$\n\nSubstituting these into the Euler-Lagrange equation:\n$$ 1 - \\frac{d}{dx} (2y') = 0 $$\n$$ 1 - 2y'' = 0 $$\n$$ y'' = \\frac{1}{2} $$\n\n### 2. Solving the Differential Equation\n\nWe now solve the second-order ordinary differential equation $y'' = \\frac{1}{2}$.\n\nIntegrating with respect to $x$ once:\n$$ y'(x) = \\int \\frac{1}{2} \\, dx = \\frac{1}{2}x + C_1 $$\nwhere $C_1$ is an integration constant.\n\nIntegrating a second time to find $y(x)$:\n$$ y(x) = \\int \\left( \\frac{1}{2}x + C_1 \\right) dx = \\frac{1}{4}x^2 + C_1 x + C_2 $$\nwhere $C_2$ is the second integration constant.\n\n### 3. Applying Boundary Conditions\n\nWe determine the constants $C_1$ and $C_2$ using the given boundary conditions.\n\n1.  **Apply $y(0) = 0$:**\n    $$ y(0) = \\frac{1}{4}(0)^2 + C_1(0) + C_2 = 0 $$\n    $$ C_2 = 0 $$\n\n    So the function simplifies to $y(x) = \\frac{1}{4}x^2 + C_1 x$.\n\n2.  **Apply $y(1) = 1$:**\n    $$ y(1) = \\frac{1}{4}(1)^2 + C_1(1) = 1 $$\n    $$ \\frac{1}{4} + C_1 = 1 $$\n    $$ C_1 = 1 - \\frac{1}{4} = \\frac{3}{4} $$\n\nSubstituting the constants back into the general solution yields:\n$$ y(x) = \\frac{1}{4}x^2 + \\frac{3}{4}x $$\n\n### 4. Verification of Minimality\n\nTo ensure this solution is a minimum (and not a maximum or a saddle point), we check the convexity of the integrand $F(x, y, y') = (y')^2 + y$.\n\nThe Hessian matrix of $F$ with respect to $y$ and $y'$ is:\n$$\nH_F = \\begin{pmatrix} \\frac{\\partial^2 F}{\\partial y^2} & \\frac{\\partial^2 F}{\\partial y \\partial y'} \\\\ \\frac{\\partial^2 F}{\\partial y' \\partial y} & \\frac{\\partial^2 F}{\\partial y'^2} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 2 \\end{pmatrix}\n$$\nSince the matrix is positive semi-definite (eigenvalues are 0 and 2), the function $F$ is jointly convex in $y$ and $y'$. For a convex functional, any function satisfying the Euler-Lagrange equation and the boundary conditions is a global minimizer.\n\nAlternatively, using the **Legendre Condition**:\n$$ \\frac{\\partial^2 F}{\\partial y'^2} = 2 > 0 $$\nThe strict positivity indicates that the stationary path is a local minimum.\n\n### Conclusion\n\nThe function that minimizes the functional is:\n\n$$ y(x) = \\frac{1}{4}x^2 + \\frac{3}{4}x $$\n\n*(Optional: The minimum value of the functional is $J[y] = \\frac{71}{48}$.)*",
        "raw_answer": "To solve the optimization problem presented, we seek a function $y(x) \\in C^1[0,1]$ that minimizes the functional:\n$$ J[y] = \\int_{0}^{1} (y'^2 + y) \\, dx $$\nsubject to the boundary conditions:\n$$ y(0) = 0 \\quad \\text{and} \\quad y(1) = 1 $$\n\n### 1. The Euler-Lagrange Equation\n\nThe fundamental lemma of the calculus of variations states that if $y(x)$ provides a local extremum for the functional $J[y] = \\int_{a}^{b} F(x, y, y') \\, dx$, and $y(x)$ is twice continuously differentiable, it must satisfy the Euler-Lagrange equation:\n$$ \\frac{\\partial F}{\\partial y} - \\frac{d}{dx} \\left( \\frac{\\partial F}{\\partial y'} \\right) = 0 $$\n\nFor this problem, the integrand is:\n$$ F(x, y, y') = (y')^2 + y $$\n\nWe compute the necessary partial derivatives:\n1.  **Partial with respect to $y$:**\n    $$ \\frac{\\partial F}{\\partial y} = \\frac{\\partial}{\\partial y} \\left( (y')^2 + y \\right) = 1 $$\n\n2.  **Partial with respect to $y'$:**\n    $$ \\frac{\\partial F}{\\partial y'} = \\frac{\\partial}{\\partial y'} \\left( (y')^2 + y \\right) = 2y' $$\n\nSubstituting these into the Euler-Lagrange equation:\n$$ 1 - \\frac{d}{dx} (2y') = 0 $$\n$$ 1 - 2y'' = 0 $$\n$$ y'' = \\frac{1}{2} $$\n\n### 2. Solving the Differential Equation\n\nWe now solve the second-order ordinary differential equation $y'' = \\frac{1}{2}$.\n\nIntegrating with respect to $x$ once:\n$$ y'(x) = \\int \\frac{1}{2} \\, dx = \\frac{1}{2}x + C_1 $$\nwhere $C_1$ is an integration constant.\n\nIntegrating a second time to find $y(x)$:\n$$ y(x) = \\int \\left( \\frac{1}{2}x + C_1 \\right) dx = \\frac{1}{4}x^2 + C_1 x + C_2 $$\nwhere $C_2$ is the second integration constant.\n\n### 3. Applying Boundary Conditions\n\nWe determine the constants $C_1$ and $C_2$ using the given boundary conditions.\n\n1.  **Apply $y(0) = 0$:**\n    $$ y(0) = \\frac{1}{4}(0)^2 + C_1(0) + C_2 = 0 $$\n    $$ C_2 = 0 $$\n\n    So the function simplifies to $y(x) = \\frac{1}{4}x^2 + C_1 x$.\n\n2.  **Apply $y(1) = 1$:**\n    $$ y(1) = \\frac{1}{4}(1)^2 + C_1(1) = 1 $$\n    $$ \\frac{1}{4} + C_1 = 1 $$\n    $$ C_1 = 1 - \\frac{1}{4} = \\frac{3}{4} $$\n\nSubstituting the constants back into the general solution yields:\n$$ y(x) = \\frac{1}{4}x^2 + \\frac{3}{4}x $$\n\n### 4. Verification of Minimality\n\nTo ensure this solution is a minimum (and not a maximum or a saddle point), we check the convexity of the integrand $F(x, y, y') = (y')^2 + y$.\n\nThe Hessian matrix of $F$ with respect to $y$ and $y'$ is:\n$$\nH_F = \\begin{pmatrix} \\frac{\\partial^2 F}{\\partial y^2} & \\frac{\\partial^2 F}{\\partial y \\partial y'} \\\\ \\frac{\\partial^2 F}{\\partial y' \\partial y} & \\frac{\\partial^2 F}{\\partial y'^2} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 2 \\end{pmatrix}\n$$\nSince the matrix is positive semi-definite (eigenvalues are 0 and 2), the function $F$ is jointly convex in $y$ and $y'$. For a convex functional, any function satisfying the Euler-Lagrange equation and the boundary conditions is a global minimizer.\n\nAlternatively, using the **Legendre Condition**:\n$$ \\frac{\\partial^2 F}{\\partial y'^2} = 2 > 0 $$\nThe strict positivity indicates that the stationary path is a local minimum.\n\n### Conclusion\n\nThe function that minimizes the functional is:\n\n$$ y(x) = \\frac{1}{4}x^2 + \\frac{3}{4}x $$\n\n*(Optional: The minimum value of the functional is $J[y] = \\frac{71}{48}$.)*",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Convex and discrete geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Convex and discrete geometry\nConvex and discrete geometry encompasses a broad range of topics including the geometry of convex sets, polytopes, and discrete geometric structures. A suitable topic could involve properties of convex polytopes, such as their faces, volumes, or the relationships between their vertices and facets.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem related to the properties of a specific convex polytope. A well-known result in convex geometry is the characterization of regular polytopes. However, a more challenging and less straightforward problem could involve understanding the relationship between the number of vertices, edges, and faces of a polytope.\n\n## Step 4: Generate a problem statement\nConsider a 3-dimensional convex polytope $P$ that is simple (every vertex is incident to exactly 3 edges) and has $V$ vertices, $E$ edges, and $F$ faces. The problem is to prove that for such a polytope, Euler's formula ($V - E + F = 2$) holds, and then use this to derive a relationship between $V$ and $F$.\n\n## Step 5: Write down the problem in the required format\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces. Prove that $V - E + F = 2$ and derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces. Prove that $V - E + F = 2$ and derive a formula relating $V$ and $F$ using the fact that $P$ is simple.",
    "run_id": "36",
    "outer_attempt": 2,
    "topic_slug": "convex_and_discrete_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "Here is the complete, rigorous solution to the mathematics problem regarding simple 3-dimensional convex polytopes.\n\n### **Problem Statement**\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces.\n1.  Prove that Euler's formula holds for $P$: $V - E + F = 2$.\n2.  Derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n---\n\n### **Part 1: Proof of Euler's Formula**\n\nTo prove $V - E + F = 2$ for a convex 3-polytope, we relate the combinatorial structure of the polytope to a planar graph and prove the formula for the graph.\n\n**Step 1.1: Projection to a Planar Graph**\nThe boundary of a 3-dimensional convex polytope is homeomorphic to the 2-sphere $\\mathbb{S}^2$. We can map the vertices and edges of $P$ to a graph $G$ embedded in the plane $\\mathbb{R}^2$ without edge crossings (a planar graph) using a Schlegel diagram or stereographic projection.\n\n1.  Select a face $f_{outer}$ of the polytope $P$.\n2.  Project the vertices and edges of $P$ onto the plane of $f_{outer}$ from a point just outside $f_{outer}$.\n3.  This projection creates a planar graph $G$ where:\n    -   The vertices of $G$ correspond one-to-one with the vertices of $P$ ($v = V$).\n    -   The edges of $G$ correspond one-to-one with the edges of $P$ ($e = E$).\n    -   The bounded regions (faces) of the graph $G$ correspond to the faces of $P$ other than $f_{outer}$.\n    -   The unbounded exterior region of $G$ corresponds to the face $f_{outer}$.\n    -   Thus, the number of faces in the planar graph embedding (including the exterior) is $f = F$.\n\nIt suffices to prove that for any connected planar graph $G$ with $v$ vertices, $e$ edges, and $f$ faces, $v - e + f = 2$.\n\n**Step 1.2: Proof for Connected Planar Graphs**\nWe proceed by induction on the number of edges, or equivalently, by reconstructing the graph from a spanning tree.\n\n**Base Case (Spanning Tree):**\nLet $T$ be a spanning tree of the graph $G$. Since $G$ is connected and has $v$ vertices, such a tree exists and contains all $v$ vertices.\nFor a tree $T$:\n-   Number of vertices $v_T = v$.\n-   Number of edges $e_T = v - 1$.\n-   A tree contains no cycles, so it encloses no bounded regions. The only face is the unbounded exterior. Thus, $f_T = 1$.\n\nCheck Euler's formula for $T$:\n$$v_T - e_T + f_T = v - (v - 1) + 1 = 1 + 1 = 2$$\nThe formula holds for the spanning tree.\n\n**Inductive Step (Adding Edges):**\nWe reconstruct $G$ by adding the remaining edges $e - e_T$ one by one. Let $G_k$ be the graph after adding $k$ edges to $T$. Assume $v_{G_k} - e_{G_k} + f_{G_k} = 2$.\nConsider adding the next edge $\\epsilon$ to form $G_{k+1}$.\n1.  **Vertices:** The edge connects two vertices already present in the graph (since $T$ contains all vertices). Thus, $v_{G_{k+1}} = v_{G_k}$.\n2.  **Edges:** We add one edge, so $e_{G_{k+1}} = e_{G_k} + 1$.\n3.  **Faces:** Since $u$ and $w$ (the endpoints of $\\epsilon$) are already connected in $G_k$, adding $\\epsilon$ creates a cycle. By the Jordan Curve Theorem, a cycle in the plane separates a region into two distinct components. Therefore, adding this edge splits an existing face into two faces. Thus, $f_{G_{k+1}} = f_{G_k} + 1$.\n\nNow, calculate the Euler characteristic for $G_{k+1}$:\n$$ \\begin{aligned} v_{G_{k+1}} - e_{G_{k+1}} + f_{G_{k+1}} &= v_{G_k} - (e_{G_k} + 1) + (f_{G_k} + 1) \\\\ &= v_{G_k} - e_{G_k} + f_{G_k} \\\\ &= 2 \\quad (\\text{by inductive hypothesis}) \\end{aligned} $$\n\nBy induction, the formula holds for the complete graph $G$. Since $G$ is combinatorially equivalent to $P$, we have proven:\n$$V - E + F = 2$$\n\n---\n\n### **Part 2: Derivation of the Formula Relating $V$ and $F$**\n\nWe are given that $P$ is a **simple** polytope.\n\n**Step 2.1: Implication of Simplicity**\nA 3-dimensional polytope is defined as *simple* if every vertex is adjacent to exactly 3 edges (and consequently 3 faces).\nLet $d(v)$ denote the degree of vertex $v$. For a simple polytope:\n$$d(v) = 3 \\quad \\forall v \\in \\text{Vertices of } P$$\n\n**Step 2.2: The Handshaking Lemma**\nThe sum of degrees of all vertices in a graph is equal to twice the number of edges (since each edge is incident to two vertices).\n$$ \\sum_{i=1}^{V} d(v_i) = 2E $$\nSubstituting $d(v_i) = 3$:\n$$ 3V = 2E \\implies E = \\frac{3}{2}V $$\n\n**Step 2.3: Substitution into Euler's Formula**\nWe substitute the expression for $E$ into Euler's formula ($V - E + F = 2$):\n$$ V - \\left(\\frac{3}{2}V\\right) + F = 2 $$\n\nSimplify the equation:\n$$ -\\frac{1}{2}V + F = 2 $$\n\nRearrange to solve for $V$ in terms of $F$:\n$$ F - 2 = \\frac{1}{2}V $$\n$$ V = 2(F - 2) $$\n$$ V = 2F - 4 $$\n\n(Alternatively, we can express $F$ in terms of $V$ as $F = \\frac{V}{2} + 2$).\n\n---\n\n### **Conclusion**\n\n1.  **Euler's Formula:** We have proven that for any convex 3-polytope, $V - E + F = 2$.\n2.  **Relation for Simple Polytopes:** For a simple convex 3-polytope, the number of vertices $V$ is determined by the number of faces $F$ by the formula:\n    $$ V = 2F - 4 $$",
        "raw_answer": "Here is the complete, rigorous solution to the mathematics problem regarding simple 3-dimensional convex polytopes.\n\n### **Problem Statement**\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces.\n1.  Prove that Euler's formula holds for $P$: $V - E + F = 2$.\n2.  Derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n---\n\n### **Part 1: Proof of Euler's Formula**\n\nTo prove $V - E + F = 2$ for a convex 3-polytope, we relate the combinatorial structure of the polytope to a planar graph and prove the formula for the graph.\n\n**Step 1.1: Projection to a Planar Graph**\nThe boundary of a 3-dimensional convex polytope is homeomorphic to the 2-sphere $\\mathbb{S}^2$. We can map the vertices and edges of $P$ to a graph $G$ embedded in the plane $\\mathbb{R}^2$ without edge crossings (a planar graph) using a Schlegel diagram or stereographic projection.\n\n1.  Select a face $f_{outer}$ of the polytope $P$.\n2.  Project the vertices and edges of $P$ onto the plane of $f_{outer}$ from a point just outside $f_{outer}$.\n3.  This projection creates a planar graph $G$ where:\n    -   The vertices of $G$ correspond one-to-one with the vertices of $P$ ($v = V$).\n    -   The edges of $G$ correspond one-to-one with the edges of $P$ ($e = E$).\n    -   The bounded regions (faces) of the graph $G$ correspond to the faces of $P$ other than $f_{outer}$.\n    -   The unbounded exterior region of $G$ corresponds to the face $f_{outer}$.\n    -   Thus, the number of faces in the planar graph embedding (including the exterior) is $f = F$.\n\nIt suffices to prove that for any connected planar graph $G$ with $v$ vertices, $e$ edges, and $f$ faces, $v - e + f = 2$.\n\n**Step 1.2: Proof for Connected Planar Graphs**\nWe proceed by induction on the number of edges, or equivalently, by reconstructing the graph from a spanning tree.\n\n**Base Case (Spanning Tree):**\nLet $T$ be a spanning tree of the graph $G$. Since $G$ is connected and has $v$ vertices, such a tree exists and contains all $v$ vertices.\nFor a tree $T$:\n-   Number of vertices $v_T = v$.\n-   Number of edges $e_T = v - 1$.\n-   A tree contains no cycles, so it encloses no bounded regions. The only face is the unbounded exterior. Thus, $f_T = 1$.\n\nCheck Euler's formula for $T$:\n$$v_T - e_T + f_T = v - (v - 1) + 1 = 1 + 1 = 2$$\nThe formula holds for the spanning tree.\n\n**Inductive Step (Adding Edges):**\nWe reconstruct $G$ by adding the remaining edges $e - e_T$ one by one. Let $G_k$ be the graph after adding $k$ edges to $T$. Assume $v_{G_k} - e_{G_k} + f_{G_k} = 2$.\nConsider adding the next edge $\\epsilon$ to form $G_{k+1}$.\n1.  **Vertices:** The edge connects two vertices already present in the graph (since $T$ contains all vertices). Thus, $v_{G_{k+1}} = v_{G_k}$.\n2.  **Edges:** We add one edge, so $e_{G_{k+1}} = e_{G_k} + 1$.\n3.  **Faces:** Since $u$ and $w$ (the endpoints of $\\epsilon$) are already connected in $G_k$, adding $\\epsilon$ creates a cycle. By the Jordan Curve Theorem, a cycle in the plane separates a region into two distinct components. Therefore, adding this edge splits an existing face into two faces. Thus, $f_{G_{k+1}} = f_{G_k} + 1$.\n\nNow, calculate the Euler characteristic for $G_{k+1}$:\n$$ \\begin{aligned} v_{G_{k+1}} - e_{G_{k+1}} + f_{G_{k+1}} &= v_{G_k} - (e_{G_k} + 1) + (f_{G_k} + 1) \\\\ &= v_{G_k} - e_{G_k} + f_{G_k} \\\\ &= 2 \\quad (\\text{by inductive hypothesis}) \\end{aligned} $$\n\nBy induction, the formula holds for the complete graph $G$. Since $G$ is combinatorially equivalent to $P$, we have proven:\n$$V - E + F = 2$$\n\n---\n\n### **Part 2: Derivation of the Formula Relating $V$ and $F$**\n\nWe are given that $P$ is a **simple** polytope.\n\n**Step 2.1: Implication of Simplicity**\nA 3-dimensional polytope is defined as *simple* if every vertex is adjacent to exactly 3 edges (and consequently 3 faces).\nLet $d(v)$ denote the degree of vertex $v$. For a simple polytope:\n$$d(v) = 3 \\quad \\forall v \\in \\text{Vertices of } P$$\n\n**Step 2.2: The Handshaking Lemma**\nThe sum of degrees of all vertices in a graph is equal to twice the number of edges (since each edge is incident to two vertices).\n$$ \\sum_{i=1}^{V} d(v_i) = 2E $$\nSubstituting $d(v_i) = 3$:\n$$ 3V = 2E \\implies E = \\frac{3}{2}V $$\n\n**Step 2.3: Substitution into Euler's Formula**\nWe substitute the expression for $E$ into Euler's formula ($V - E + F = 2$):\n$$ V - \\left(\\frac{3}{2}V\\right) + F = 2 $$\n\nSimplify the equation:\n$$ -\\frac{1}{2}V + F = 2 $$\n\nRearrange to solve for $V$ in terms of $F$:\n$$ F - 2 = \\frac{1}{2}V $$\n$$ V = 2(F - 2) $$\n$$ V = 2F - 4 $$\n\n(Alternatively, we can express $F$ in terms of $V$ as $F = \\frac{V}{2} + 2$).\n\n---\n\n### **Conclusion**\n\n1.  **Euler's Formula:** We have proven that for any convex 3-polytope, $V - E + F = 2$.\n2.  **Relation for Simple Polytopes:** For a simple convex 3-polytope, the number of vertices $V$ is determined by the number of faces $F$ by the formula:\n    $$ V = 2F - 4 $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of general topology, along with a complete solution, following specific guidelines.\n\n## Step 2: Review the guidelines for a well-posed question\nThe question must be self-contained, clear, non-trivial, and solvable with established mathematical methods. It should not require external dependencies or be culturally dependent.\n\n## Step 3: Identify a topic within general topology\nGeneral topology involves the study of topological spaces, continuous functions, and topological properties. A suitable topic could involve properties of specific topological spaces or the behavior of continuous functions.\n\n## Step 4: Generate a problem\nLet's consider a problem involving the concept of compactness and continuous functions. A well-known result in general topology is that the continuous image of a compact space is compact.\n\n## Step 5: Formulate the problem\n\"Let $X = [0,1] \\cup [2,3]$ be a subspace of $\\mathbb{R}$ with the standard topology. Define a function $f: X \\to \\mathbb{R}$ by $f(x) = x^2$. Prove that $f(X)$ is compact.\"\n\n## Step 6: Verify that the problem is well-posed\n- The domain $X$ is explicitly defined.\n- The function $f$ is clearly defined.\n- The task is to prove a specific property ($f(X)$ being compact) which is a well-defined mathematical concept.\n- The problem does not require external dependencies.\n\n## Step 7: Provide a solution to the problem\nTo prove that $f(X)$ is compact, we need to show that it is closed and bounded since $f(X) \\subset \\mathbb{R}$ and $\\mathbb{R}$ is a metric space.\n\n## Step 8: Calculate $f(X)$\nGiven $X = [0,1] \\cup [2,3]$, $f(X) = f([0,1]) \\cup f([2,3]) = [0,1] \\cup [4,9]$.\n\n## Step 9: Show that $f(X)$ is compact\n$f(X) = [0,1] \\cup [4,9]$ is a union of two closed and bounded intervals, hence it is closed and bounded. Therefore, $f(X)$ is compact because it is a closed and bounded subset of $\\mathbb{R}$.\n\n## Step 10: Write the problem and solution in the required format\n\nLet $X = [0,1] \\cup [2,3]$ be a subspace of $\\mathbb{R}$ with the standard topology. Define a function $f: X \\to \\mathbb{R}$ by $f(x) = x^2$. Prove that $f(X)$ is compact.",
    "run_id": "38",
    "outer_attempt": 2,
    "topic_slug": "general_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the image set $f(X)$ is compact, we will proceed by establishing the topological properties of the domain $X$ and the function $f$, and then applying a fundamental theorem of general topology. We will also verify the result by explicitly calculating the set $f(X)$.\n\n### 1. Determining the Topological Properties of the Domain $X$\n\nLet $X = [0,1] \\cup [2,3]$ be a subspace of $\\mathbb{R}$ with the standard topology.\n\n**Compactness of $X$:**\nBy the **Heine-Borel Theorem**, a subset of Euclidean space $\\mathbb{R}^n$ is compact if and only if it is both closed and bounded.\n\n1.  **Boundedness:**\n    The set $X$ is contained in the interval $[0, 3]$. Since there exist real numbers $m=0$ and $M=3$ such that for all $x \\in X$, $m \\leq x \\leq M$, the set $X$ is bounded.\n\n2.  **Closedness:**\n    The intervals $[0,1]$ and $[2,3]$ are closed intervals in $\\mathbb{R}$. The union of a finite number of closed sets is closed. Therefore, $X = [0,1] \\cup [2,3]$ is a closed set.\n\nSince $X$ is a closed and bounded subset of $\\mathbb{R}$, $X$ is compact.\n\n### 2. Establishing the Continuity of $f$\n\nThe function is defined as $f: X \\to \\mathbb{R}$ with $f(x) = x^2$.\n\nConsider the function $g: \\mathbb{R} \\to \\mathbb{R}$ defined by $g(x) = x^2$. Since $g$ is a polynomial function, it is continuous everywhere on $\\mathbb{R}$.\nThe function $f$ is the restriction of $g$ to the subspace $X$ (i.e., $f = g|_X$). A standard result in topology states that the restriction of a continuous function to a subspace is continuous with respect to the subspace topology.\n\nTherefore, $f$ is continuous on $X$.\n\n### 3. Proof via Topological Theorem\n\nWe apply the following standard theorem from general topology:\n\n**Theorem:** *The continuous image of a compact space is compact.*\n(Formally: If $f: A \\to B$ is a continuous function and $A$ is a compact space, then the image set $f(A)$ is a compact subset of $B$.)\n\n**Application:**\n1.  We established in Step 1 that the domain $X$ is compact.\n2.  We established in Step 2 that the function $f$ is continuous.\n3.  By the theorem, the image set $f(X)$ must be compact.\n\n### 4. Verification via Explicit Calculation\n\nTo confirm the result and ensure completeness, we explicitly calculate the set $f(X)$ and verify its compactness using the Heine-Borel Theorem.\n\nThe function $f(x) = x^2$ is strictly increasing on the domain $X \\subset [0, \\infty)$. Therefore, it maps closed intervals to closed intervals preserving the endpoints.\n\n-   **Image of the first interval:**\n    $f([0,1]) = \\{ x^2 \\mid 0 \\le x \\le 1 \\} = [0^2, 1^2] = [0,1]$.\n\n-   **Image of the second interval:**\n    $f([2,3]) = \\{ x^2 \\mid 2 \\le x \\le 3 \\} = [2^2, 3^2] = [4,9]$.\n\n-   **Total Image:**\n    $f(X) = f([0,1]) \\cup f([2,3]) = [0,1] \\cup [4,9]$.\n\n**Check for Compactness:**\nThe set $f(X) = [0,1] \\cup [4,9]$ is the union of two closed intervals.\n1.  It is **closed** (finite union of closed sets).\n2.  It is **bounded** (contained in $[0,9]$).\n\nThus, by the Heine-Borel Theorem, $f(X)$ is compact.\n\n### Conclusion\n\nWe have proven that $f(X)$ is compact by showing that $X$ is compact and $f$ is continuous, and we have verified this by calculating explicitly that $f(X) = [0,1] \\cup [4,9]$, which is a closed and bounded subset of $\\mathbb{R}$.\n\n**Final Answer:** The set $f(X)$ is compact.",
        "raw_answer": "To prove that the image set $f(X)$ is compact, we will proceed by establishing the topological properties of the domain $X$ and the function $f$, and then applying a fundamental theorem of general topology. We will also verify the result by explicitly calculating the set $f(X)$.\n\n### 1. Determining the Topological Properties of the Domain $X$\n\nLet $X = [0,1] \\cup [2,3]$ be a subspace of $\\mathbb{R}$ with the standard topology.\n\n**Compactness of $X$:**\nBy the **Heine-Borel Theorem**, a subset of Euclidean space $\\mathbb{R}^n$ is compact if and only if it is both closed and bounded.\n\n1.  **Boundedness:**\n    The set $X$ is contained in the interval $[0, 3]$. Since there exist real numbers $m=0$ and $M=3$ such that for all $x \\in X$, $m \\leq x \\leq M$, the set $X$ is bounded.\n\n2.  **Closedness:**\n    The intervals $[0,1]$ and $[2,3]$ are closed intervals in $\\mathbb{R}$. The union of a finite number of closed sets is closed. Therefore, $X = [0,1] \\cup [2,3]$ is a closed set.\n\nSince $X$ is a closed and bounded subset of $\\mathbb{R}$, $X$ is compact.\n\n### 2. Establishing the Continuity of $f$\n\nThe function is defined as $f: X \\to \\mathbb{R}$ with $f(x) = x^2$.\n\nConsider the function $g: \\mathbb{R} \\to \\mathbb{R}$ defined by $g(x) = x^2$. Since $g$ is a polynomial function, it is continuous everywhere on $\\mathbb{R}$.\nThe function $f$ is the restriction of $g$ to the subspace $X$ (i.e., $f = g|_X$). A standard result in topology states that the restriction of a continuous function to a subspace is continuous with respect to the subspace topology.\n\nTherefore, $f$ is continuous on $X$.\n\n### 3. Proof via Topological Theorem\n\nWe apply the following standard theorem from general topology:\n\n**Theorem:** *The continuous image of a compact space is compact.*\n(Formally: If $f: A \\to B$ is a continuous function and $A$ is a compact space, then the image set $f(A)$ is a compact subset of $B$.)\n\n**Application:**\n1.  We established in Step 1 that the domain $X$ is compact.\n2.  We established in Step 2 that the function $f$ is continuous.\n3.  By the theorem, the image set $f(X)$ must be compact.\n\n### 4. Verification via Explicit Calculation\n\nTo confirm the result and ensure completeness, we explicitly calculate the set $f(X)$ and verify its compactness using the Heine-Borel Theorem.\n\nThe function $f(x) = x^2$ is strictly increasing on the domain $X \\subset [0, \\infty)$. Therefore, it maps closed intervals to closed intervals preserving the endpoints.\n\n-   **Image of the first interval:**\n    $f([0,1]) = \\{ x^2 \\mid 0 \\le x \\le 1 \\} = [0^2, 1^2] = [0,1]$.\n\n-   **Image of the second interval:**\n    $f([2,3]) = \\{ x^2 \\mid 2 \\le x \\le 3 \\} = [2^2, 3^2] = [4,9]$.\n\n-   **Total Image:**\n    $f(X) = f([0,1]) \\cup f([2,3]) = [0,1] \\cup [4,9]$.\n\n**Check for Compactness:**\nThe set $f(X) = [0,1] \\cup [4,9]$ is the union of two closed intervals.\n1.  It is **closed** (finite union of closed sets).\n2.  It is **bounded** (contained in $[0,9]$).\n\nThus, by the Heine-Borel Theorem, $f(X)$ is compact.\n\n### Conclusion\n\nWe have proven that $f(X)$ is compact by showing that $X$ is compact and $f$ is continuous, and we have verified this by calculating explicitly that $f(X) = [0,1] \\cup [4,9]$, which is a closed and bounded subset of $\\mathbb{R}$.\n\n**Final Answer:** The set $f(X)$ is compact.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Manifolds and cell complexes\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within the domain\nA suitable topic within \"Manifolds and cell complexes\" could involve the properties or constructions related to manifolds or cell complexes, such as their topology, geometry, or algebraic invariants.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the Euler characteristic of a manifold, which is a fundamental concept in algebraic topology that relates to both manifolds and cell complexes. The Euler characteristic is a topological invariant that can be computed using a cell decomposition of a manifold.\n\n## Step 4: Construct the problem statement\nConsider a 2-dimensional manifold $M$ that is homeomorphic to a sphere with $g$ handles (i.e., a surface of genus $g$). The task is to prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.\n\n## Step 5: Provide the problem statement in the required format\n\n\nLet $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles. Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.",
    "run_id": "40",
    "outer_attempt": 2,
    "topic_slug": "manifolds_and_cell_complexes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To provide a rigorous answer to the problem, we will model the manifold $M$ using the standard tools of algebraic topology, specifically the theory of **CW complexes** (cell complexes). We will calculate the Euler characteristic using the definition $\\chi(M) = \\sum (-1)^k c_k$, where $c_k$ is the number of cells of dimension $k$.\n\n### 1. Mathematical Formulation\n\n**Definition:** The Euler characteristic $\\chi(M)$ of a finite cell complex $M$ is defined as:\n$$ \\chi(M) = V - E + F $$\nwhere:\n*   $V$ is the number of 0-cells (vertices).\n*   $E$ is the number of 1-cells (edges).\n*   $F$ is the number of 2-cells (faces).\n\n**Model of the Manifold:**\nA 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles is known as an **orientable surface of genus $g$**, denoted $\\Sigma_g$.\n*   For $g=0$, $M$ is the sphere $S^2$.\n*   For $g \\ge 1$, $M$ can be constructed from a regular polygon with $4g$ sides by identifying the edges in a specific pattern known as the **fundamental polygon**.\n\n### 2. Proof via Cell Decomposition (Polygonal Model)\n\nWe construct a CW complex structure on $M$ using the standard polygonal representation.\n\n**Step 1: The Fundamental Polygon**\nLet $P$ be a regular polygon with $4g$ edges. We label the edges of the boundary $\\partial P$ in counterclockwise order with the sequence of symbols:\n$$ a_1, b_1, a_1^{-1}, b_1^{-1}, a_2, b_2, a_2^{-1}, b_2^{-1}, \\dots, a_g, b_g, a_g^{-1}, b_g^{-1} $$\nThis word represents the \"commutator\" structure of the handles. To form the manifold $M$, we identify edges with the same letter according to the orientation indicated (the exponent $-1$ implies the edge is identified with the orientation reversed).\n\nThis identification creates a quotient space $M = P / \\sim$. We now count the cells in this quotient space.\n\n**Step 2: Counting 2-cells (Faces)**\nThe interior of the polygon $P$ forms a single open disk. Since no identifications occur in the interior, this maps to exactly one 2-cell in $M$.\n$$ F = 1 $$\n\n**Step 3: Counting 1-cells (Edges)**\nThe polygon boundary has $4g$ edges. The identification scheme pairs each edge $x$ with a unique edge $x^{-1}$.\n*   The edges are $\\{a_i, b_i, a_i^{-1}, b_i^{-1} \\mid i = 1, \\dots, g\\}$.\n*   Since the $4g$ edges are identified in pairs, the number of distinct 1-cells in the quotient manifold is:\n$$ E = \\frac{4g}{2} = 2g $$\n\n**Step 4: Counting 0-cells (Vertices)**\nThis is the non-trivial step. We must determine how the $4g$ vertices of the polygon are identified in the quotient. Let the vertices of $P$ be $v_0, v_1, \\dots, v_{4g-1}$ in counterclockwise order.\n\nLet us trace the identification for the first handle (the edges $a_1, b_1, a_1^{-1}, b_1^{-1}$):\n1.  **Edge $a_1$:** Connects $v_0 \\to v_1$. It is identified with $a_1^{-1}$ (which appears as the 3rd edge).\n2.  **Edge $a_1^{-1}$:** In the boundary sequence, this edge runs from $v_2 \\to v_3$. However, the label $a_1^{-1}$ implies it is identified with $a_1$ but with reversed orientation. Therefore, the geometric edge $a_1$ runs from the vertex identified with $v_3$ to the vertex identified with $v_2$.\n    *   Identification: The head of the original $a_1$ ($v_1$) is identified with the head of the mapped $a_1$ ($v_2$).\n    *   Identification: The tail of the original $a_1$ ($v_0$) is identified with the tail of the mapped $a_1$ ($v_3$).\n    *   Result: $v_1 \\sim v_2$ and $v_0 \\sim v_3$.\n3.  **Edge $b_1$:** Connects $v_1 \\to v_2$. It is identified with $b_1^{-1}$ (the 4th edge).\n4.  **Edge $b_1^{-1}$:** Runs from $v_3 \\to v_4$. Being the inverse, it is identified with $b_1$ reversed.\n    *   Identification: The start of $b_1$ ($v_1$) matches the end of $b_1^{-1}$ ($v_4$). Thus $v_1 \\sim v_4$.\n    *   Identification: The end of $b_1$ ($v_2$) matches the start of $b_1^{-1}$ ($v_3$). Thus $v_2 \\sim v_3$.\n\nCombining these equivalences for the first group of 4 edges:\n$$ v_0 \\sim v_3 \\sim v_2 \\sim v_1 \\sim v_4 $$\nThus, the start of the first sequence ($v_0$) is equivalent to the start of the next sequence ($v_4$). By induction, for any handle $i$, the vertices involved are all identified together, and the vertex at the end of the $i$-th group is identified with the vertex at the start of the $(i+1)$-th group.\n\nSince the boundary is a single connected cycle, **all** $4g$ vertices of the polygon are identified to a single point in the quotient manifold.\n$$ V = 1 $$\n\n**Step 5: Calculation**\nWe substitute the counts into the Euler characteristic formula:\n$$ \\chi(M) = V - E + F $$\n$$ \\chi(M) = 1 - 2g + 1 $$\n$$ \\chi(M) = 2 - 2g $$\n\n---\n\n### 3. Alternative Verification (Surgery / Handle Addition)\n\nWe can also prove this via induction on the number of handles, utilizing the property of the connected sum. A sphere with $g$ handles is homeomorphic to the connected sum of a sphere and $g$ tori, or simply the connected sum of $g$ tori (assuming $g \\ge 1$; for $g=0$ it is the sphere).\n\nLet $S^2$ be the sphere.\n1.  **Base Case ($g=0$):**\n    For a sphere, standard decomposition (e.g., tetrahedron) gives $V=4, E=6, F=4$.\n    $\\chi(S^2) = 4 - 6 + 4 = 2$.\n    The formula yields $2 - 2(0) = 2$. The base case holds.\n\n2.  **Inductive Step:**\n    Adding a \"handle\" is topologically equivalent to forming the connected sum with a torus $T^2$.\n    The operation is $M_{g+1} = M_g \\# T^2$.\n    The Euler characteristic for a connected sum is given by:\n    $$ \\chi(A \\# B) = \\chi(A) + \\chi(B) - 2 $$\n    We know $\\chi(T^2) = 0$ (since $T^2$ can be viewed as a square with opposite sides identified: $V=1, E=2, F=1 \\implies 1-2+1=0$).\n\n    Assume $\\chi(M_g) = 2 - 2g$. Then:\n    $$ \\chi(M_{g+1}) = \\chi(M_g) + \\chi(T^2) - 2 $$\n    $$ \\chi(M_{g+1}) = (2 - 2g) + 0 - 2 $$\n    $$ \\chi(M_{g+1}) = 2 - 2g - 2 $$\n    $$ \\chi(M_{g+1}) = 2 - 2(g + 1) $$\n\nThis confirms the result for all $g \\ge 0$.\n\n### Conclusion\n\nWe have constructed a cell decomposition for the manifold $M$, determined there is 1 face, $2g$ edges, and 1 vertex, and verified the result via the connected sum formula.\n\n**Final Result:**\nThe Euler characteristic of a 2-dimensional manifold homeomorphic to a sphere with $g$ handles is:\n$$ \\chi(M) = 2 - 2g $$",
        "raw_answer": "To provide a rigorous answer to the problem, we will model the manifold $M$ using the standard tools of algebraic topology, specifically the theory of **CW complexes** (cell complexes). We will calculate the Euler characteristic using the definition $\\chi(M) = \\sum (-1)^k c_k$, where $c_k$ is the number of cells of dimension $k$.\n\n### 1. Mathematical Formulation\n\n**Definition:** The Euler characteristic $\\chi(M)$ of a finite cell complex $M$ is defined as:\n$$ \\chi(M) = V - E + F $$\nwhere:\n*   $V$ is the number of 0-cells (vertices).\n*   $E$ is the number of 1-cells (edges).\n*   $F$ is the number of 2-cells (faces).\n\n**Model of the Manifold:**\nA 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles is known as an **orientable surface of genus $g$**, denoted $\\Sigma_g$.\n*   For $g=0$, $M$ is the sphere $S^2$.\n*   For $g \\ge 1$, $M$ can be constructed from a regular polygon with $4g$ sides by identifying the edges in a specific pattern known as the **fundamental polygon**.\n\n### 2. Proof via Cell Decomposition (Polygonal Model)\n\nWe construct a CW complex structure on $M$ using the standard polygonal representation.\n\n**Step 1: The Fundamental Polygon**\nLet $P$ be a regular polygon with $4g$ edges. We label the edges of the boundary $\\partial P$ in counterclockwise order with the sequence of symbols:\n$$ a_1, b_1, a_1^{-1}, b_1^{-1}, a_2, b_2, a_2^{-1}, b_2^{-1}, \\dots, a_g, b_g, a_g^{-1}, b_g^{-1} $$\nThis word represents the \"commutator\" structure of the handles. To form the manifold $M$, we identify edges with the same letter according to the orientation indicated (the exponent $-1$ implies the edge is identified with the orientation reversed).\n\nThis identification creates a quotient space $M = P / \\sim$. We now count the cells in this quotient space.\n\n**Step 2: Counting 2-cells (Faces)**\nThe interior of the polygon $P$ forms a single open disk. Since no identifications occur in the interior, this maps to exactly one 2-cell in $M$.\n$$ F = 1 $$\n\n**Step 3: Counting 1-cells (Edges)**\nThe polygon boundary has $4g$ edges. The identification scheme pairs each edge $x$ with a unique edge $x^{-1}$.\n*   The edges are $\\{a_i, b_i, a_i^{-1}, b_i^{-1} \\mid i = 1, \\dots, g\\}$.\n*   Since the $4g$ edges are identified in pairs, the number of distinct 1-cells in the quotient manifold is:\n$$ E = \\frac{4g}{2} = 2g $$\n\n**Step 4: Counting 0-cells (Vertices)**\nThis is the non-trivial step. We must determine how the $4g$ vertices of the polygon are identified in the quotient. Let the vertices of $P$ be $v_0, v_1, \\dots, v_{4g-1}$ in counterclockwise order.\n\nLet us trace the identification for the first handle (the edges $a_1, b_1, a_1^{-1}, b_1^{-1}$):\n1.  **Edge $a_1$:** Connects $v_0 \\to v_1$. It is identified with $a_1^{-1}$ (which appears as the 3rd edge).\n2.  **Edge $a_1^{-1}$:** In the boundary sequence, this edge runs from $v_2 \\to v_3$. However, the label $a_1^{-1}$ implies it is identified with $a_1$ but with reversed orientation. Therefore, the geometric edge $a_1$ runs from the vertex identified with $v_3$ to the vertex identified with $v_2$.\n    *   Identification: The head of the original $a_1$ ($v_1$) is identified with the head of the mapped $a_1$ ($v_2$).\n    *   Identification: The tail of the original $a_1$ ($v_0$) is identified with the tail of the mapped $a_1$ ($v_3$).\n    *   Result: $v_1 \\sim v_2$ and $v_0 \\sim v_3$.\n3.  **Edge $b_1$:** Connects $v_1 \\to v_2$. It is identified with $b_1^{-1}$ (the 4th edge).\n4.  **Edge $b_1^{-1}$:** Runs from $v_3 \\to v_4$. Being the inverse, it is identified with $b_1$ reversed.\n    *   Identification: The start of $b_1$ ($v_1$) matches the end of $b_1^{-1}$ ($v_4$). Thus $v_1 \\sim v_4$.\n    *   Identification: The end of $b_1$ ($v_2$) matches the start of $b_1^{-1}$ ($v_3$). Thus $v_2 \\sim v_3$.\n\nCombining these equivalences for the first group of 4 edges:\n$$ v_0 \\sim v_3 \\sim v_2 \\sim v_1 \\sim v_4 $$\nThus, the start of the first sequence ($v_0$) is equivalent to the start of the next sequence ($v_4$). By induction, for any handle $i$, the vertices involved are all identified together, and the vertex at the end of the $i$-th group is identified with the vertex at the start of the $(i+1)$-th group.\n\nSince the boundary is a single connected cycle, **all** $4g$ vertices of the polygon are identified to a single point in the quotient manifold.\n$$ V = 1 $$\n\n**Step 5: Calculation**\nWe substitute the counts into the Euler characteristic formula:\n$$ \\chi(M) = V - E + F $$\n$$ \\chi(M) = 1 - 2g + 1 $$\n$$ \\chi(M) = 2 - 2g $$\n\n---\n\n### 3. Alternative Verification (Surgery / Handle Addition)\n\nWe can also prove this via induction on the number of handles, utilizing the property of the connected sum. A sphere with $g$ handles is homeomorphic to the connected sum of a sphere and $g$ tori, or simply the connected sum of $g$ tori (assuming $g \\ge 1$; for $g=0$ it is the sphere).\n\nLet $S^2$ be the sphere.\n1.  **Base Case ($g=0$):**\n    For a sphere, standard decomposition (e.g., tetrahedron) gives $V=4, E=6, F=4$.\n    $\\chi(S^2) = 4 - 6 + 4 = 2$.\n    The formula yields $2 - 2(0) = 2$. The base case holds.\n\n2.  **Inductive Step:**\n    Adding a \"handle\" is topologically equivalent to forming the connected sum with a torus $T^2$.\n    The operation is $M_{g+1} = M_g \\# T^2$.\n    The Euler characteristic for a connected sum is given by:\n    $$ \\chi(A \\# B) = \\chi(A) + \\chi(B) - 2 $$\n    We know $\\chi(T^2) = 0$ (since $T^2$ can be viewed as a square with opposite sides identified: $V=1, E=2, F=1 \\implies 1-2+1=0$).\n\n    Assume $\\chi(M_g) = 2 - 2g$. Then:\n    $$ \\chi(M_{g+1}) = \\chi(M_g) + \\chi(T^2) - 2 $$\n    $$ \\chi(M_{g+1}) = (2 - 2g) + 0 - 2 $$\n    $$ \\chi(M_{g+1}) = 2 - 2g - 2 $$\n    $$ \\chi(M_{g+1}) = 2 - 2(g + 1) $$\n\nThis confirms the result for all $g \\ge 0$.\n\n### Conclusion\n\nWe have constructed a cell decomposition for the manifold $M$, determined there is 1 face, $2g$ edges, and 1 vertex, and verified the result via the connected sum formula.\n\n**Final Result:**\nThe Euler characteristic of a 2-dimensional manifold homeomorphic to a sphere with $g$ handles is:\n$$ \\chi(M) = 2 - 2g $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $g(x) = x^3 - x - 1$. We are tasked with approximating the root of $g(x)$ in the interval $[1,2]$ using the bisection method. Perform two iterations of the bisection method starting with the initial interval $[1,2]$ to find the interval that contains the root after two iterations.",
    "run_id": "44",
    "outer_attempt": 2,
    "topic_slug": "numerical_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the problem of approximating the root of the function $g(x) = x^3 - x - 1$ in the interval $[1, 2]$ using the bisection method, we proceed step-by-step through two iterations.\n\n### Setup and Initial Verification\n\nThe function is given by:\n$$g(x) = x^3 - x - 1$$\n\nWe are looking for a root in the initial interval $[a_0, b_0] = [1, 2]$.\n\nFirst, we verify the existence of a root in this interval using the Intermediate Value Theorem. Since $g(x)$ is a polynomial, it is continuous everywhere. We evaluate the function at the endpoints:\n$$g(1) = (1)^3 - 1 - 1 = -1$$\n$$g(2) = (2)^3 - 2 - 1 = 8 - 3 = 5$$\n\nSince $g(1) < 0$ and $g(2) > 0$, the signs are opposite ($g(1) \\cdot g(2) < 0$). Therefore, there exists at least one root $r \\in (1, 2)$.\n\n### Iteration 1\n\n**1. Calculate the midpoint:**\nLet $c_1$ be the midpoint of the interval $[a_0, b_0] = [1, 2]$.\n$$c_1 = \\frac{a_0 + b_0}{2} = \\frac{1 + 2}{2} = 1.5$$\n\n**2. Evaluate the function at the midpoint:**\n$$g(c_1) = g(1.5) = (1.5)^3 - 1.5 - 1$$\nCalculating the powers:\n$$(1.5)^2 = 2.25$$\n$$(1.5)^3 = 2.25 \\times 1.5 = 3.375$$\nSubstituting back:\n$$g(1.5) = 3.375 - 1.5 - 1 = 3.375 - 2.5 = 0.875$$\n\n**3. Determine the new interval:**\nWe compare the sign of $g(c_1)$ with the signs at the endpoints $a_0$ and $b_0$:\n- $g(a_0) = g(1) = -1$ (Negative)\n- $g(c_1) = g(1.5) = 0.875$ (Positive)\n- $g(b_0) = g(2) = 5$ (Positive)\n\nThe sign change occurs between $a_0$ and $c_1$ (since negative to positive). Therefore, the root lies in the interval $[1, 1.5]$.\n\nWe set the new interval $[a_1, b_1] = [1, 1.5]$.\n\n### Iteration 2\n\n**1. Calculate the midpoint:**\nLet $c_2$ be the midpoint of the interval $[a_1, b_1] = [1, 1.5]$.\n$$c_2 = \\frac{a_1 + b_1}{2} = \\frac{1 + 1.5}{2} = \\frac{2.5}{2} = 1.25$$\n\n**2. Evaluate the function at the midpoint:**\n$$g(c_2) = g(1.25) = (1.25)^3 - 1.25 - 1$$\nCalculating the powers:\n$$(1.25)^2 = 1.5625$$\n$$(1.25)^3 = 1.5625 \\times 1.25 = 1.953125$$\nSubstituting back:\n$$g(1.25) = 1.953125 - 1.25 - 1$$\n$$g(1.25) = 1.953125 - 2.25 = -0.296875$$\n\n**3. Determine the new interval:**\nWe compare the sign of $g(c_2)$ with the signs at the endpoints $a_1$ and $b_1$:\n- $g(a_1) = g(1) = -1$ (Negative)\n- $g(c_2) = g(1.25) = -0.296875$ (Negative)\n- $g(b_1) = g(1.5) = 0.875$ (Positive)\n\nThe sign change occurs between $c_2$ and $b_1$ (since negative to positive). Therefore, the root lies in the interval $[1.25, 1.5]$.\n\nWe set the new interval $[a_2, b_2] = [1.25, 1.5]$.\n\n### Conclusion\n\nAfter performing two iterations of the bisection method on the function $g(x) = x^3 - x - 1$ starting with the interval $[1, 2]$, the resulting interval containing the root is:\n\n$$[1.25, 1.5]$$",
        "raw_answer": "To solve the problem of approximating the root of the function $g(x) = x^3 - x - 1$ in the interval $[1, 2]$ using the bisection method, we proceed step-by-step through two iterations.\n\n### Setup and Initial Verification\n\nThe function is given by:\n$$g(x) = x^3 - x - 1$$\n\nWe are looking for a root in the initial interval $[a_0, b_0] = [1, 2]$.\n\nFirst, we verify the existence of a root in this interval using the Intermediate Value Theorem. Since $g(x)$ is a polynomial, it is continuous everywhere. We evaluate the function at the endpoints:\n$$g(1) = (1)^3 - 1 - 1 = -1$$\n$$g(2) = (2)^3 - 2 - 1 = 8 - 3 = 5$$\n\nSince $g(1) < 0$ and $g(2) > 0$, the signs are opposite ($g(1) \\cdot g(2) < 0$). Therefore, there exists at least one root $r \\in (1, 2)$.\n\n### Iteration 1\n\n**1. Calculate the midpoint:**\nLet $c_1$ be the midpoint of the interval $[a_0, b_0] = [1, 2]$.\n$$c_1 = \\frac{a_0 + b_0}{2} = \\frac{1 + 2}{2} = 1.5$$\n\n**2. Evaluate the function at the midpoint:**\n$$g(c_1) = g(1.5) = (1.5)^3 - 1.5 - 1$$\nCalculating the powers:\n$$(1.5)^2 = 2.25$$\n$$(1.5)^3 = 2.25 \\times 1.5 = 3.375$$\nSubstituting back:\n$$g(1.5) = 3.375 - 1.5 - 1 = 3.375 - 2.5 = 0.875$$\n\n**3. Determine the new interval:**\nWe compare the sign of $g(c_1)$ with the signs at the endpoints $a_0$ and $b_0$:\n- $g(a_0) = g(1) = -1$ (Negative)\n- $g(c_1) = g(1.5) = 0.875$ (Positive)\n- $g(b_0) = g(2) = 5$ (Positive)\n\nThe sign change occurs between $a_0$ and $c_1$ (since negative to positive). Therefore, the root lies in the interval $[1, 1.5]$.\n\nWe set the new interval $[a_1, b_1] = [1, 1.5]$.\n\n### Iteration 2\n\n**1. Calculate the midpoint:**\nLet $c_2$ be the midpoint of the interval $[a_1, b_1] = [1, 1.5]$.\n$$c_2 = \\frac{a_1 + b_1}{2} = \\frac{1 + 1.5}{2} = \\frac{2.5}{2} = 1.25$$\n\n**2. Evaluate the function at the midpoint:**\n$$g(c_2) = g(1.25) = (1.25)^3 - 1.25 - 1$$\nCalculating the powers:\n$$(1.25)^2 = 1.5625$$\n$$(1.25)^3 = 1.5625 \\times 1.25 = 1.953125$$\nSubstituting back:\n$$g(1.25) = 1.953125 - 1.25 - 1$$\n$$g(1.25) = 1.953125 - 2.25 = -0.296875$$\n\n**3. Determine the new interval:**\nWe compare the sign of $g(c_2)$ with the signs at the endpoints $a_1$ and $b_1$:\n- $g(a_1) = g(1) = -1$ (Negative)\n- $g(c_2) = g(1.25) = -0.296875$ (Negative)\n- $g(b_1) = g(1.5) = 0.875$ (Positive)\n\nThe sign change occurs between $c_2$ and $b_1$ (since negative to positive). Therefore, the root lies in the interval $[1.25, 1.5]$.\n\nWe set the new interval $[a_2, b_2] = [1.25, 1.5]$.\n\n### Conclusion\n\nAfter performing two iterations of the bisection method on the function $g(x) = x^3 - x - 1$ starting with the interval $[1, 2]$, the resulting interval containing the root is:\n\n$$[1.25, 1.5]$$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $P(x)$ be the predicate \"$x$ is a prime number.\" Formalize the statement \"There are infinitely many prime numbers\" using the predicate $P(x)$, and determine whether it is true or false. If true, provide a proof; if false, provide a counterexample.",
    "run_id": "1",
    "outer_attempt": 3,
    "topic_slug": "mathematical_logic_and_foundations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To answer this question, we must first translate the English statement into a formal logical expression using the provided predicate, then determine its validity, and finally provide a rigorous mathematical proof.\n\n### 1. Formalization\n\nLet the domain of discourse be the set of positive integers, $\\mathbb{Z}^+ = \\{1, 2, 3, \\dots\\}$.\nLet $P(x)$ denote the predicate \"$x$ is a prime number.\"\n\nThe statement \"There are infinitely many prime numbers\" is logically equivalent to saying that for any integer, there exists a prime number strictly larger than it. In formal logic, this is expressed as:\n\n$$ \\forall x \\in \\mathbb{Z}^+, \\, \\exists y \\in \\mathbb{Z}^+ \\, (y > x \\land P(y)) $$\n\n### 2. Determination of Truth Value\n\nThe statement is **True**. This result is known as **Euclid's Theorem**.\n\n### 3. Proof\n\nWe provide a proof for the statement $\\forall x \\in \\mathbb{Z}^+, \\, \\exists y \\in \\mathbb{Z}^+ \\, (y > x \\land P(y))$.\n\n**Proof:**\n\nLet $x$ be an arbitrary positive integer. We construct an integer $N$ defined as:\n$$ N = x! + 1 $$\nwhere $x!$ (x factorial) is the product of all positive integers less than or equal to $x$.\n\n**Step 1: Existence of a prime divisor**\nSince $x \\ge 1$, we have $x! \\ge 1$, and thus $N = x! + 1 \\ge 2$.\nBy the **Fundamental Theorem of Arithmetic** (or the property that every integer greater than 1 has at least one prime factor), there exists a prime number $p$ such that $p$ divides $N$.\nSince $p$ is a prime number, the predicate $P(p)$ is true.\n\n**Step 2: Proving $p > x$**\nWe claim that this prime divisor $p$ must be strictly greater than $x$. We proceed by contradiction.\n\nAssume, for the sake of contradiction, that $p \\le x$.\nIf $p \\le x$, then $p$ is one of the factors in the product $x! = 1 \\times 2 \\times \\dots \\times p \\times \\dots \\times x$.\nTherefore, $p$ divides $x!$.\n\nWe now have two facts:\n1. $p$ divides $N$ (by definition of $p$).\n2. $p$ divides $x!$ (by assumption).\n\nIf a number divides two integers, it must divide their difference. Therefore, $p$ must divide:\n$$ N - x! = (x! + 1) - x! = 1 $$\n\nHowever, $p$ is a prime number, so $p \\ge 2$. There is no integer $p \\ge 2$ that divides $1$.\nThis is a contradiction.\n\n**Conclusion**\nThe assumption that $p \\le x$ is false. Therefore, it must be that $p > x$.\n\nWe have shown that for any arbitrary positive integer $x$, there exists a prime number $p$ (where we set $y=p$) such that $p > x$. Thus, the set of prime numbers is not finite.\n\n**Q.E.D.**",
        "raw_answer": "To answer this question, we must first translate the English statement into a formal logical expression using the provided predicate, then determine its validity, and finally provide a rigorous mathematical proof.\n\n### 1. Formalization\n\nLet the domain of discourse be the set of positive integers, $\\mathbb{Z}^+ = \\{1, 2, 3, \\dots\\}$.\nLet $P(x)$ denote the predicate \"$x$ is a prime number.\"\n\nThe statement \"There are infinitely many prime numbers\" is logically equivalent to saying that for any integer, there exists a prime number strictly larger than it. In formal logic, this is expressed as:\n\n$$ \\forall x \\in \\mathbb{Z}^+, \\, \\exists y \\in \\mathbb{Z}^+ \\, (y > x \\land P(y)) $$\n\n### 2. Determination of Truth Value\n\nThe statement is **True**. This result is known as **Euclid's Theorem**.\n\n### 3. Proof\n\nWe provide a proof for the statement $\\forall x \\in \\mathbb{Z}^+, \\, \\exists y \\in \\mathbb{Z}^+ \\, (y > x \\land P(y))$.\n\n**Proof:**\n\nLet $x$ be an arbitrary positive integer. We construct an integer $N$ defined as:\n$$ N = x! + 1 $$\nwhere $x!$ (x factorial) is the product of all positive integers less than or equal to $x$.\n\n**Step 1: Existence of a prime divisor**\nSince $x \\ge 1$, we have $x! \\ge 1$, and thus $N = x! + 1 \\ge 2$.\nBy the **Fundamental Theorem of Arithmetic** (or the property that every integer greater than 1 has at least one prime factor), there exists a prime number $p$ such that $p$ divides $N$.\nSince $p$ is a prime number, the predicate $P(p)$ is true.\n\n**Step 2: Proving $p > x$**\nWe claim that this prime divisor $p$ must be strictly greater than $x$. We proceed by contradiction.\n\nAssume, for the sake of contradiction, that $p \\le x$.\nIf $p \\le x$, then $p$ is one of the factors in the product $x! = 1 \\times 2 \\times \\dots \\times p \\times \\dots \\times x$.\nTherefore, $p$ divides $x!$.\n\nWe now have two facts:\n1. $p$ divides $N$ (by definition of $p$).\n2. $p$ divides $x!$ (by assumption).\n\nIf a number divides two integers, it must divide their difference. Therefore, $p$ must divide:\n$$ N - x! = (x! + 1) - x! = 1 $$\n\nHowever, $p$ is a prime number, so $p \\ge 2$. There is no integer $p \\ge 2$ that divides $1$.\nThis is a contradiction.\n\n**Conclusion**\nThe assumption that $p \\le x$ is false. Therefore, it must be that $p > x$.\n\nWe have shown that for any arbitrary positive integer $x$, there exists a prime number $p$ (where we set $y=p$) such that $p > x$. Thus, the set of prime numbers is not finite.\n\n**Q.E.D.**",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Determine whether the polynomial $p(x) = x^4 + 1$ is irreducible over the field $\\mathbb{Q}$ of rational numbers.",
    "run_id": "6",
    "outer_attempt": 4,
    "topic_slug": "field_theory_and_polynomials",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To determine whether the polynomial $p(x) = x^4 + 1$ is irreducible over the field of rational numbers $\\mathbb{Q}$, we will utilize **Eisenstein's Criterion** combined with a linear substitution (shift) of the variable.\n\n### 1. Definition of Irreducibility\nA polynomial $f(x) \\in \\mathbb{Q}[x]$ of degree $n \\geq 1$ is **irreducible** over $\\mathbb{Q}$ if it cannot be written as the product of two polynomials $g(x), h(x) \\in \\mathbb{Q}[x]$ with degrees strictly less than $n$.\n\nBy Gauss's Lemma, a monic polynomial with integer coefficients is irreducible over $\\mathbb{Q}$ if and only if it is irreducible over $\\mathbb{Z}$. Thus, we can treat $p(x)$ as an element of $\\mathbb{Z}[x]$.\n\n### 2. Strategy: Eisenstein's Criterion\n**Eisenstein's Criterion** states that for a polynomial $f(x) = a_n x^n + a_{n-1} x^{n-1} + \\dots + a_1 x + a_0$ with integer coefficients, if there exists a prime number $p$ such that:\n1. $p \\mid a_i$ for all $0 \\leq i < n$,\n2. $p \\nmid a_n$, and\n3. $p^2 \\nmid a_0$,\nthen $f(x)$ is irreducible over $\\mathbb{Q}$.\n\nApplying this directly to $p(x) = x^4 + 1$:\n- Coefficients are $a_4=1, a_3=0, a_2=0, a_1=0, a_0=1$.\n- There is no prime $p$ that divides $a_0 = 1$.\nThus, the criterion does not apply directly.\n\n### 3. Change of Variable (Shift)\nIrreducibility is preserved under linear translations of the variable. Let $x = y + 1$. We define a new polynomial $q(y)$ such that $q(y) = p(y+1)$. If $q(y)$ is irreducible over $\\mathbb{Q}$, then $p(x)$ implies $p(x)$ is irreducible over $\\mathbb{Q}$ because the map $x \\mapsto x+1$ is an isomorphism of the ring $\\mathbb{Q}[x]$.\n\nSubstitute $x = y+1$ into $p(x)$:\n$$\n\\begin{aligned}\nq(y) &= (y+1)^4 + 1 \\\\\n&= (y^4 + 4y^3 + 6y^2 + 4y + 1) + 1 \\\\\n&= y^4 + 4y^3 + 6y^2 + 4y + 2\n\\end{aligned}\n$$\n\nThe coefficients of $q(y)$ are:\n- $a_4 = 1$\n- $a_3 = 4$\n- $a_2 = 6$\n- $a_1 = 4$\n- $a_0 = 2$\n\n### 4. Applying Eisenstein's Criterion to $q(y)$\nWe test the prime $p = 2$:\n1. **Check divisibility of non-leading coefficients:**\n   - $a_3 = 4$: $2 \\mid 4$ (Yes)\n   - $a_2 = 6$: $2 \\mid 6$ (Yes)\n   - $a_1 = 4$: $2 \\mid 4$ (Yes)\n   - $a_0 = 2$: $2 \\mid 2$ (Yes)\n\n2. **Check non-divisibility of leading coefficient:**\n   - $a_4 = 1$: $2 \\nmid 1$ (Yes)\n\n3. **Check non-divisibility of constant term by $p^2$:**\n   - $a_0 = 2$: $2^2 = 4$, and $4 \\nmid 2$ (Yes)\n\nSince all conditions are satisfied for $p=2$, the polynomial $q(y)$ is irreducible over $\\mathbb{Q}$.\n\n### 5. Conclusion\nSince $q(y) = p(y+1)$ is irreducible over $\\mathbb{Q}$, the original polynomial $p(x)$ must also be irreducible over $\\mathbb{Q}$.\n\n**Answer:** The polynomial $p(x) = x^4 + 1$ is **irreducible** over $\\mathbb{Q}$.",
        "raw_answer": "To determine whether the polynomial $p(x) = x^4 + 1$ is irreducible over the field of rational numbers $\\mathbb{Q}$, we will utilize **Eisenstein's Criterion** combined with a linear substitution (shift) of the variable.\n\n### 1. Definition of Irreducibility\nA polynomial $f(x) \\in \\mathbb{Q}[x]$ of degree $n \\geq 1$ is **irreducible** over $\\mathbb{Q}$ if it cannot be written as the product of two polynomials $g(x), h(x) \\in \\mathbb{Q}[x]$ with degrees strictly less than $n$.\n\nBy Gauss's Lemma, a monic polynomial with integer coefficients is irreducible over $\\mathbb{Q}$ if and only if it is irreducible over $\\mathbb{Z}$. Thus, we can treat $p(x)$ as an element of $\\mathbb{Z}[x]$.\n\n### 2. Strategy: Eisenstein's Criterion\n**Eisenstein's Criterion** states that for a polynomial $f(x) = a_n x^n + a_{n-1} x^{n-1} + \\dots + a_1 x + a_0$ with integer coefficients, if there exists a prime number $p$ such that:\n1. $p \\mid a_i$ for all $0 \\leq i < n$,\n2. $p \\nmid a_n$, and\n3. $p^2 \\nmid a_0$,\nthen $f(x)$ is irreducible over $\\mathbb{Q}$.\n\nApplying this directly to $p(x) = x^4 + 1$:\n- Coefficients are $a_4=1, a_3=0, a_2=0, a_1=0, a_0=1$.\n- There is no prime $p$ that divides $a_0 = 1$.\nThus, the criterion does not apply directly.\n\n### 3. Change of Variable (Shift)\nIrreducibility is preserved under linear translations of the variable. Let $x = y + 1$. We define a new polynomial $q(y)$ such that $q(y) = p(y+1)$. If $q(y)$ is irreducible over $\\mathbb{Q}$, then $p(x)$ implies $p(x)$ is irreducible over $\\mathbb{Q}$ because the map $x \\mapsto x+1$ is an isomorphism of the ring $\\mathbb{Q}[x]$.\n\nSubstitute $x = y+1$ into $p(x)$:\n$$\n\\begin{aligned}\nq(y) &= (y+1)^4 + 1 \\\\\n&= (y^4 + 4y^3 + 6y^2 + 4y + 1) + 1 \\\\\n&= y^4 + 4y^3 + 6y^2 + 4y + 2\n\\end{aligned}\n$$\n\nThe coefficients of $q(y)$ are:\n- $a_4 = 1$\n- $a_3 = 4$\n- $a_2 = 6$\n- $a_1 = 4$\n- $a_0 = 2$\n\n### 4. Applying Eisenstein's Criterion to $q(y)$\nWe test the prime $p = 2$:\n1. **Check divisibility of non-leading coefficients:**\n   - $a_3 = 4$: $2 \\mid 4$ (Yes)\n   - $a_2 = 6$: $2 \\mid 6$ (Yes)\n   - $a_1 = 4$: $2 \\mid 4$ (Yes)\n   - $a_0 = 2$: $2 \\mid 2$ (Yes)\n\n2. **Check non-divisibility of leading coefficient:**\n   - $a_4 = 1$: $2 \\nmid 1$ (Yes)\n\n3. **Check non-divisibility of constant term by $p^2$:**\n   - $a_0 = 2$: $2^2 = 4$, and $4 \\nmid 2$ (Yes)\n\nSince all conditions are satisfied for $p=2$, the polynomial $q(y)$ is irreducible over $\\mathbb{Q}$.\n\n### 5. Conclusion\nSince $q(y) = p(y+1)$ is irreducible over $\\mathbb{Q}$, the original polynomial $p(x)$ must also be irreducible over $\\mathbb{Q}$.\n\n**Answer:** The polynomial $p(x) = x^4 + 1$ is **irreducible** over $\\mathbb{Q}$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $\\mathfrak{sl}(2, \\mathbb{R})$ be the Lie algebra of $2 \\times 2$ real matrices with trace zero, with the Lie bracket $[A, B] = AB - BA$. Show that the matrices $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and compute the structure constants with respect to this basis.",
    "run_id": "11",
    "outer_attempt": 4,
    "topic_slug": "nonassociative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "### Verification of the Basis\n\nFirst, we define the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$ explicitly. It is the vector space of $2 \\times 2$ matrices with real entries and trace equal to zero, equipped with the Lie bracket $[A, B] = AB - BA$.\n$$ \\mathfrak{sl}(2, \\mathbb{R}) = \\left\\{ M \\in M_2(\\mathbb{R}) \\mid \\text{tr}(M) = 0 \\right\\} $$\n\nThe given matrices are:\n$$ H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} $$\n\n**Step 1: Verify membership in $\\mathfrak{sl}(2, \\mathbb{R})$**\nWe calculate the trace (sum of diagonal elements) for each matrix:\n$$ \\text{tr}(H) = 1 + (-1) = 0 $$\n$$ \\text{tr}(X) = 0 + 0 = 0 $$\n$$ \\text{tr}(Y) = 0 + 0 = 0 $$\nSince the entries are real and the traces are zero, $H, X, Y \\in \\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Step 2: Verify Linear Independence**\nConsider a linear combination equal to the zero matrix:\n$$ c_1 H + c_2 X + c_3 Y = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nSubstituting the matrices:\n$$ c_1 \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + c_2 \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c_3 \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} c_1 & c_2 \\\\ c_3 & -c_1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nEquating the components gives the system:\n1. $c_1 = 0$\n2. $c_2 = 0$\n3. $c_3 = 0$\n4. $-c_1 = 0$\n\nThe only solution is the trivial solution $c_1 = c_2 = c_3 = 0$. Therefore, the set $\\{H, X, Y\\}$ is linearly independent.\n\n**Step 3: Verify they form a Basis**\nWe determine the dimension of $\\mathfrak{sl}(2, \\mathbb{R})$. Let $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\in \\mathfrak{sl}(2, \\mathbb{R})$. The condition $\\text{tr}(A) = 0$ implies $a + d = 0$, or $d = -a$. Thus, any element is of the form:\n$$ A = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} = a \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + b \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = aH + bX + cY $$\nThis shows that $\\{H, X, Y\\}$ spans $\\mathfrak{sl}(2, \\mathbb{R})$. Since the set is linearly independent and spans the space, it forms a basis for $\\mathfrak{sl}(2, \\mathbb{R})$. (Alternatively, since the dimension of the space is 3 and we have 3 linearly independent vectors, they must form a basis).\n\n---\n\n### Computation of Structure Constants\n\nWe compute the Lie brackets (commutators) $[A, B] = AB - BA$ for the basis elements.\n\n**1. Bracket $[H, X]$**\n$$ HX = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = X $$\n$$ XH = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix} = -X $$\n$$ [H, X] = X - (-X) = 2X $$\n\n**2. Bracket $[H, Y]$**\n$$ HY = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix} = -Y $$\n$$ YH = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = Y $$\n$$ [H, Y] = -Y - Y = -2Y $$\n\n**3. Bracket $[X, Y]$**\n$$ XY = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ YX = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\n$$ [X, Y] = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = H $$\n\n**Summary of Commutation Relations:**\n$$ [H, X] = 2X $$\n$$ [H, Y] = -2Y $$\n$$ [X, Y] = H $$\n\nThe structure constants $C_{ij}^k$ are the coefficients defined by the relation $[e_i, e_j] = \\sum_{k} C_{ij}^k e_k$, where $\\{e_1, e_2, e_3\\}$ is the ordered basis $\\{H, X, Y\\}$.\n\nThe non-zero structure constants are:\n*   From $[H, X] = 2X$:\n    $$ C_{12}^2 = 2, \\quad C_{21}^2 = -2 $$\n*   From $[H, Y] = -2Y$:\n    $$ C_{13}^3 = -2, \\quad C_{31}^3 = 2 $$\n*   From $[X, Y] = H$:\n    $$ C_{23}^1 = 1, \\quad C_{32}^1 = -1 $$\n\nAll other structure constants (e.g., $C_{12}^1, C_{12}^3$) are zero.",
        "raw_answer": "### Verification of the Basis\n\nFirst, we define the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$ explicitly. It is the vector space of $2 \\times 2$ matrices with real entries and trace equal to zero, equipped with the Lie bracket $[A, B] = AB - BA$.\n$$ \\mathfrak{sl}(2, \\mathbb{R}) = \\left\\{ M \\in M_2(\\mathbb{R}) \\mid \\text{tr}(M) = 0 \\right\\} $$\n\nThe given matrices are:\n$$ H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} $$\n\n**Step 1: Verify membership in $\\mathfrak{sl}(2, \\mathbb{R})$**\nWe calculate the trace (sum of diagonal elements) for each matrix:\n$$ \\text{tr}(H) = 1 + (-1) = 0 $$\n$$ \\text{tr}(X) = 0 + 0 = 0 $$\n$$ \\text{tr}(Y) = 0 + 0 = 0 $$\nSince the entries are real and the traces are zero, $H, X, Y \\in \\mathfrak{sl}(2, \\mathbb{R})$.\n\n**Step 2: Verify Linear Independence**\nConsider a linear combination equal to the zero matrix:\n$$ c_1 H + c_2 X + c_3 Y = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nSubstituting the matrices:\n$$ c_1 \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + c_2 \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c_3 \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} c_1 & c_2 \\\\ c_3 & -c_1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\nEquating the components gives the system:\n1. $c_1 = 0$\n2. $c_2 = 0$\n3. $c_3 = 0$\n4. $-c_1 = 0$\n\nThe only solution is the trivial solution $c_1 = c_2 = c_3 = 0$. Therefore, the set $\\{H, X, Y\\}$ is linearly independent.\n\n**Step 3: Verify they form a Basis**\nWe determine the dimension of $\\mathfrak{sl}(2, \\mathbb{R})$. Let $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\in \\mathfrak{sl}(2, \\mathbb{R})$. The condition $\\text{tr}(A) = 0$ implies $a + d = 0$, or $d = -a$. Thus, any element is of the form:\n$$ A = \\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} = a \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + b \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + c \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = aH + bX + cY $$\nThis shows that $\\{H, X, Y\\}$ spans $\\mathfrak{sl}(2, \\mathbb{R})$. Since the set is linearly independent and spans the space, it forms a basis for $\\mathfrak{sl}(2, \\mathbb{R})$. (Alternatively, since the dimension of the space is 3 and we have 3 linearly independent vectors, they must form a basis).\n\n---\n\n### Computation of Structure Constants\n\nWe compute the Lie brackets (commutators) $[A, B] = AB - BA$ for the basis elements.\n\n**1. Bracket $[H, X]$**\n$$ HX = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = X $$\n$$ XH = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix} = -X $$\n$$ [H, X] = X - (-X) = 2X $$\n\n**2. Bracket $[H, Y]$**\n$$ HY = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix} = -Y $$\n$$ YH = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = Y $$\n$$ [H, Y] = -Y - Y = -2Y $$\n\n**3. Bracket $[X, Y]$**\n$$ XY = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} $$\n$$ YX = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\n$$ [X, Y] = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = H $$\n\n**Summary of Commutation Relations:**\n$$ [H, X] = 2X $$\n$$ [H, Y] = -2Y $$\n$$ [X, Y] = H $$\n\nThe structure constants $C_{ij}^k$ are the coefficients defined by the relation $[e_i, e_j] = \\sum_{k} C_{ij}^k e_k$, where $\\{e_1, e_2, e_3\\}$ is the ordered basis $\\{H, X, Y\\}$.\n\nThe non-zero structure constants are:\n*   From $[H, X] = 2X$:\n    $$ C_{12}^2 = 2, \\quad C_{21}^2 = -2 $$\n*   From $[H, Y] = -2Y$:\n    $$ C_{13}^3 = -2, \\quad C_{31}^3 = 2 $$\n*   From $[X, Y] = H$:\n    $$ C_{23}^1 = 1, \\quad C_{32}^1 = -1 $$\n\nAll other structure constants (e.g., $C_{12}^1, C_{12}^3$) are zero.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "## Step 1: Understand the task and the given domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of special functions, along with a complete and verifiable solution. The given domain is special functions, and we need to create a problem that is simpler than the previously attempted questions but still challenging.\n\n## Step 2: Recall the properties and examples of special functions\nSpecial functions include the Gamma function, Bessel functions, elliptic functions, and others. The Gamma function, denoted by $\\Gamma(x)$, is defined as $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$ for $x > 0$. It has various properties and applications in mathematics and physics.\n\n## Step 3: Formulate a problem related to special functions\nTo create a problem, let's consider a basic property or application of special functions. One fundamental property is the Gamma function's relation to factorials for positive integers, given by $\\Gamma(n+1) = n!$. A simple and challenging problem could involve proving or verifying an identity or inequality related to the Gamma function.\n\n## Step 4: Generate a specific problem\nLet's consider the problem: \"Prove that $\\Gamma(x+1) = x\\Gamma(x)$ for $x > 0$, where $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.\"\n\n## Step 5: Provide a solution to the generated problem\nTo prove that $\\Gamma(x+1) = x\\Gamma(x)$, we start with the definition of $\\Gamma(x+1)$:\n$\\Gamma(x+1) = \\int_{0}^{\\infty} t^{x}e^{-t}dt$.\nUsing integration by parts with $u = t^x$ and $dv = e^{-t}dt$, we have $du = xt^{x-1}dt$ and $v = -e^{-t}$. Thus,\n$\\Gamma(x+1) = \\left[-t^xe^{-t}\\right]_{0}^{\\infty} + x\\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.\nThe first term vanishes at both limits because $e^{-t}$ decays faster than $t^x$ grows as $t \\to \\infty$ for $x > 0$, and at $t = 0$, $t^x = 0$ for $x > 0$. Thus,\n$\\Gamma(x+1) = x\\int_{0}^{\\infty} t^{x-1}e^{-t}dt = x\\Gamma(x)$.\n\n## Step 6: Format the problem and solution according to the required output format\n\nProve that $\\Gamma(x+1) = x\\Gamma(x)$ for $x > 0$, where $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.",
    "run_id": "21",
    "outer_attempt": 3,
    "topic_slug": "special_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove the functional equation $\\Gamma(x+1) = x\\Gamma(x)$ for $x > 0$, we begin with the integral definition of the Gamma function provided in the problem statement.\n\n### Definition\n\nThe Gamma function is defined for $x > 0$ by the improper integral:\n$$ \\Gamma(z) = \\int_{0}^{\\infty} t^{z-1}e^{-t} \\, dt $$\nSubstituting $z = x+1$, we obtain the expression for $\\Gamma(x+1)$:\n$$ \\Gamma(x+1) = \\int_{0}^{\\infty} t^{(x+1)-1}e^{-t} \\, dt = \\int_{0}^{\\infty} t^{x}e^{-t} \\, dt $$\n\n### Integration by Parts\n\nWe evaluate this integral using integration by parts. Let:\n$$ u = t^x \\quad \\text{and} \\quad dv = e^{-t} \\, dt $$\nThen, differentiating $u$ with respect to $t$ and integrating $dv$:\n$$ du = x t^{x-1} \\, dt \\quad \\text{and} \\quad v = -e^{-t} $$\n\nUsing the integration by parts formula $\\int_{a}^{b} u \\, dv = [uv]_{a}^{b} - \\int_{a}^{b} v \\, du$, we apply the limits from $0$ to $\\infty$:\n$$ \\Gamma(x+1) = \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} - \\int_{0}^{\\infty} \\left( -e^{-t} \\right) x t^{x-1} \\, dt $$\n$$ \\Gamma(x+1) = \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} + x \\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt $$\n\n### Analysis of the Boundary Terms\n\nWe must evaluate the boundary term $\\left[ -t^x e^{-t} \\right]_{0}^{\\infty}$. This involves taking the limits as $t \\to \\infty$ and as $t \\to 0^+$.\n\n**1. Upper Limit ($t \\to \\infty$):**\nWe evaluate $L_1 = \\lim_{t \\to \\infty} -t^x e^{-t} = -\\lim_{t \\to \\infty} \\frac{t^x}{e^t}$.\nSince the exponential function $e^t$ grows faster than any power function $t^x$ for any real $x$, this limit is zero.\n$$ \\lim_{t \\to \\infty} -t^x e^{-t} = 0 $$\n\n**2. Lower Limit ($t \\to 0^+$):**\nWe evaluate $L_2 = \\lim_{t \\to 0^+} -t^x e^{-t}$.\nSince we are given that $x > 0$, the term $t^x$ approaches $0$ as $t \\to 0^+$. The term $e^{-t}$ approaches $e^0 = 1$.\n$$ \\lim_{t \\to 0^+} -t^x e^{-t} = -(0 \\cdot 1) = 0 $$\n\nThus, the entire boundary term vanishes:\n$$ \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} = 0 - 0 = 0 $$\n\n### Final Calculation\n\nSubstituting the result of the boundary terms back into our expression for $\\Gamma(x+1)$:\n$$ \\Gamma(x+1) = 0 + x \\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt $$\n\nWe recognize the remaining integral as the definition of $\\Gamma(x)$:\n$$ \\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt = \\Gamma(x) $$\n\nTherefore:\n$$ \\Gamma(x+1) = x \\Gamma(x) $$\n\n### Conclusion\n\nWe have rigorously derived the recurrence relation for the Gamma function using integration by parts and the properties of the limits at the boundaries.\n\n**Final Answer:**\nFor all $x > 0$, $\\Gamma(x+1) = x\\Gamma(x)$.",
        "raw_answer": "To prove the functional equation $\\Gamma(x+1) = x\\Gamma(x)$ for $x > 0$, we begin with the integral definition of the Gamma function provided in the problem statement.\n\n### Definition\n\nThe Gamma function is defined for $x > 0$ by the improper integral:\n$$ \\Gamma(z) = \\int_{0}^{\\infty} t^{z-1}e^{-t} \\, dt $$\nSubstituting $z = x+1$, we obtain the expression for $\\Gamma(x+1)$:\n$$ \\Gamma(x+1) = \\int_{0}^{\\infty} t^{(x+1)-1}e^{-t} \\, dt = \\int_{0}^{\\infty} t^{x}e^{-t} \\, dt $$\n\n### Integration by Parts\n\nWe evaluate this integral using integration by parts. Let:\n$$ u = t^x \\quad \\text{and} \\quad dv = e^{-t} \\, dt $$\nThen, differentiating $u$ with respect to $t$ and integrating $dv$:\n$$ du = x t^{x-1} \\, dt \\quad \\text{and} \\quad v = -e^{-t} $$\n\nUsing the integration by parts formula $\\int_{a}^{b} u \\, dv = [uv]_{a}^{b} - \\int_{a}^{b} v \\, du$, we apply the limits from $0$ to $\\infty$:\n$$ \\Gamma(x+1) = \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} - \\int_{0}^{\\infty} \\left( -e^{-t} \\right) x t^{x-1} \\, dt $$\n$$ \\Gamma(x+1) = \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} + x \\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt $$\n\n### Analysis of the Boundary Terms\n\nWe must evaluate the boundary term $\\left[ -t^x e^{-t} \\right]_{0}^{\\infty}$. This involves taking the limits as $t \\to \\infty$ and as $t \\to 0^+$.\n\n**1. Upper Limit ($t \\to \\infty$):**\nWe evaluate $L_1 = \\lim_{t \\to \\infty} -t^x e^{-t} = -\\lim_{t \\to \\infty} \\frac{t^x}{e^t}$.\nSince the exponential function $e^t$ grows faster than any power function $t^x$ for any real $x$, this limit is zero.\n$$ \\lim_{t \\to \\infty} -t^x e^{-t} = 0 $$\n\n**2. Lower Limit ($t \\to 0^+$):**\nWe evaluate $L_2 = \\lim_{t \\to 0^+} -t^x e^{-t}$.\nSince we are given that $x > 0$, the term $t^x$ approaches $0$ as $t \\to 0^+$. The term $e^{-t}$ approaches $e^0 = 1$.\n$$ \\lim_{t \\to 0^+} -t^x e^{-t} = -(0 \\cdot 1) = 0 $$\n\nThus, the entire boundary term vanishes:\n$$ \\left[ -t^x e^{-t} \\right]_{0}^{\\infty} = 0 - 0 = 0 $$\n\n### Final Calculation\n\nSubstituting the result of the boundary terms back into our expression for $\\Gamma(x+1)$:\n$$ \\Gamma(x+1) = 0 + x \\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt $$\n\nWe recognize the remaining integral as the definition of $\\Gamma(x)$:\n$$ \\int_{0}^{\\infty} t^{x-1} e^{-t} \\, dt = \\Gamma(x) $$\n\nTherefore:\n$$ \\Gamma(x+1) = x \\Gamma(x) $$\n\n### Conclusion\n\nWe have rigorously derived the recurrence relation for the Gamma function using integration by parts and the properties of the limits at the boundaries.\n\n**Final Answer:**\nFor all $x > 0$, $\\Gamma(x+1) = x\\Gamma(x)$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $G$ be a finite abelian group and $\\mu$ be the counting measure on $G$. For $f \\in L^2(G, \\mu)$, define the Fourier transform $\\hat{f}: \\hat{G} \\to \\mathbb{C}$ by $\\hat{f}(\\chi) = \\sum_{x \\in G} f(x) \\overline{\\chi(x)}$, where $\\hat{G}$ is the dual group of $G$. Prove that the inverse Fourier transform of $\\hat{f}$ is given by $f(x) = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x)$ for all $x \\in G$.",
    "run_id": "29",
    "outer_attempt": 3,
    "topic_slug": "abstract_harmonic_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Proof of the Fourier Inversion Formula for Finite Abelian Groups**\n\nLet $G$ be a finite abelian group with order $|G|$. Let $\\hat{G}$ denote the dual group of $G$, which consists of all characters $\\chi: G \\to \\mathbb{C}^\\times$ (homomorphisms from $G$ to the multiplicative group of non-zero complex numbers). Since $G$ is finite, the image of any character lies in the unit circle, so $\\overline{\\chi(g)} = \\chi(g)^{-1} = \\chi(g^{-1})$ for all $g \\in G$.\n\nWe are given the definition of the Fourier transform $\\hat{f}: \\hat{G} \\to \\mathbb{C}$ for a function $f: G \\to \\mathbb{C}$:\n$$ \\hat{f}(\\chi) = \\sum_{y \\in G} f(y) \\overline{\\chi(y)} $$\n(Note: We use the dummy variable $y$ here to distinguish it from the variable $x$ in the inversion formula.)\n\nWe wish to prove that for all $x \\in G$:\n$$ f(x) = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x) $$\n\n### Step 1: Substitution and Rearrangement\n\nLet $S$ denote the right-hand side of the equation we wish to prove:\n$$ S = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x) $$\n\nSubstitute the definition of $\\hat{f}(\\chi)$ into $S$:\n$$ S = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\left( \\sum_{y \\in G} f(y) \\overline{\\chi(y)} \\right) \\chi(x) $$\n\nSince $G$ and $\\hat{G}$ are finite, all sums are finite. We can interchange the order of summation (Fubini's theorem for counting measure):\n$$ S = \\frac{1}{|G|} \\sum_{y \\in G} f(y) \\left( \\sum_{\\chi \\in \\hat{G}} \\chi(x) \\overline{\\chi(y)} \\right) $$\n\nUsing the homomorphism property of characters, $\\chi(x) \\overline{\\chi(y)} = \\chi(x) \\chi(y^{-1}) = \\chi(x y^{-1})$. Let $g = x y^{-1}$. The inner sum becomes:\n$$ \\sum_{\\chi \\in \\hat{G}} \\chi(x y^{-1}) $$\n\n### Step 2: Orthogonality Relations of Characters\n\nTo evaluate the inner sum, we utilize the orthogonality relations for characters of finite abelian groups.\n\n**Lemma (Second Orthogonality Relation):**\nFor any $g \\in G$,\n$$ \\sum_{\\chi \\in \\hat{G}} \\chi(g) = \\begin{cases} |G| & \\text{if } g = e_G \\\\ 0 & \\text{if } g \\neq e_G \\end{cases} $$\nwhere $e_G$ is the identity element of $G$.\n\n**Proof of Lemma:**\nIt is a standard result that for a finite abelian group, the dual group is isomorphic to the group itself, so $|\\hat{G}| = |G|$.\n\n**Case 1:** Let $g = e_G$.\nFor every character $\\chi \\in \\hat{G}$, $\\chi(e_G) = 1$.\nThus, the sum is $\\sum_{\\chi \\in \\hat{G}} 1 = |\\hat{G}| = |G|$.\n\n**Case 2:** Let $g \\neq e_G$.\nWe claim there exists a character $\\psi \\in \\hat{G}$ such that $\\psi(g) \\neq 1$.\n*Reasoning:* The characters of $G$ separate points. Since $g \\neq e_G$, there exists $\\psi$ such that $\\psi(g) \\neq \\psi(e_G) = 1$. (This follows from the structure theorem of finite abelian groups or Pontryagin duality).\n\nLet $T = \\sum_{\\chi \\in \\hat{G}} \\chi(g)$.\nMultiply $T$ by $\\psi(g)$:\n$$ \\psi(g) T = \\psi(g) \\sum_{\\chi \\in \\hat{G}} \\chi(g) = \\sum_{\\chi \\in \\hat{G}} (\\psi \\chi)(g) $$\nAs $\\chi$ runs over all elements of the group $\\hat{G}$, the product $\\psi \\chi$ also runs over all elements of $\\hat{G}$ (since multiplication by $\\psi$ is a bijection on the group $\\hat{G}$).\nTherefore, the sum remains the same:\n$$ \\sum_{\\chi \\in \\hat{G}} (\\psi \\chi)(g) = \\sum_{\\eta \\in \\hat{G}} \\eta(g) = T $$\nSo, $\\psi(g) T = T$, which implies $(\\psi(g) - 1) T = 0$.\nSince $\\psi(g) \\neq 1$, we must have $T = 0$.\n\nThis concludes the proof of the lemma.\n\n### Step 3: Evaluation of the Sum\n\nReturn to the expression for $S$:\n$$ S = \\frac{1}{|G|} \\sum_{y \\in G} f(y) \\left( \\sum_{\\chi \\in \\hat{G}} \\chi(x y^{-1}) \\right) $$\n\nUsing the Lemma, the inner sum is non-zero if and only if $x y^{-1} = e_G$, which implies $y = x$.\n- If $y \\neq x$, the inner sum is $0$.\n- If $y = x$, the inner sum is $|G|$.\n\nThus, the sum over $y$ collapses to the single term where $y = x$:\n$$ S = \\frac{1}{|G|} \\left( f(x) \\cdot |G| \\right) $$\n\nSimplifying the expression:\n$$ S = f(x) $$\n\n### Conclusion\n\nWe have shown that:\n$$ \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x) = f(x) $$\nThis completes the proof of the Fourier Inversion Formula.",
        "raw_answer": "**Proof of the Fourier Inversion Formula for Finite Abelian Groups**\n\nLet $G$ be a finite abelian group with order $|G|$. Let $\\hat{G}$ denote the dual group of $G$, which consists of all characters $\\chi: G \\to \\mathbb{C}^\\times$ (homomorphisms from $G$ to the multiplicative group of non-zero complex numbers). Since $G$ is finite, the image of any character lies in the unit circle, so $\\overline{\\chi(g)} = \\chi(g)^{-1} = \\chi(g^{-1})$ for all $g \\in G$.\n\nWe are given the definition of the Fourier transform $\\hat{f}: \\hat{G} \\to \\mathbb{C}$ for a function $f: G \\to \\mathbb{C}$:\n$$ \\hat{f}(\\chi) = \\sum_{y \\in G} f(y) \\overline{\\chi(y)} $$\n(Note: We use the dummy variable $y$ here to distinguish it from the variable $x$ in the inversion formula.)\n\nWe wish to prove that for all $x \\in G$:\n$$ f(x) = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x) $$\n\n### Step 1: Substitution and Rearrangement\n\nLet $S$ denote the right-hand side of the equation we wish to prove:\n$$ S = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x) $$\n\nSubstitute the definition of $\\hat{f}(\\chi)$ into $S$:\n$$ S = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\left( \\sum_{y \\in G} f(y) \\overline{\\chi(y)} \\right) \\chi(x) $$\n\nSince $G$ and $\\hat{G}$ are finite, all sums are finite. We can interchange the order of summation (Fubini's theorem for counting measure):\n$$ S = \\frac{1}{|G|} \\sum_{y \\in G} f(y) \\left( \\sum_{\\chi \\in \\hat{G}} \\chi(x) \\overline{\\chi(y)} \\right) $$\n\nUsing the homomorphism property of characters, $\\chi(x) \\overline{\\chi(y)} = \\chi(x) \\chi(y^{-1}) = \\chi(x y^{-1})$. Let $g = x y^{-1}$. The inner sum becomes:\n$$ \\sum_{\\chi \\in \\hat{G}} \\chi(x y^{-1}) $$\n\n### Step 2: Orthogonality Relations of Characters\n\nTo evaluate the inner sum, we utilize the orthogonality relations for characters of finite abelian groups.\n\n**Lemma (Second Orthogonality Relation):**\nFor any $g \\in G$,\n$$ \\sum_{\\chi \\in \\hat{G}} \\chi(g) = \\begin{cases} |G| & \\text{if } g = e_G \\\\ 0 & \\text{if } g \\neq e_G \\end{cases} $$\nwhere $e_G$ is the identity element of $G$.\n\n**Proof of Lemma:**\nIt is a standard result that for a finite abelian group, the dual group is isomorphic to the group itself, so $|\\hat{G}| = |G|$.\n\n**Case 1:** Let $g = e_G$.\nFor every character $\\chi \\in \\hat{G}$, $\\chi(e_G) = 1$.\nThus, the sum is $\\sum_{\\chi \\in \\hat{G}} 1 = |\\hat{G}| = |G|$.\n\n**Case 2:** Let $g \\neq e_G$.\nWe claim there exists a character $\\psi \\in \\hat{G}$ such that $\\psi(g) \\neq 1$.\n*Reasoning:* The characters of $G$ separate points. Since $g \\neq e_G$, there exists $\\psi$ such that $\\psi(g) \\neq \\psi(e_G) = 1$. (This follows from the structure theorem of finite abelian groups or Pontryagin duality).\n\nLet $T = \\sum_{\\chi \\in \\hat{G}} \\chi(g)$.\nMultiply $T$ by $\\psi(g)$:\n$$ \\psi(g) T = \\psi(g) \\sum_{\\chi \\in \\hat{G}} \\chi(g) = \\sum_{\\chi \\in \\hat{G}} (\\psi \\chi)(g) $$\nAs $\\chi$ runs over all elements of the group $\\hat{G}$, the product $\\psi \\chi$ also runs over all elements of $\\hat{G}$ (since multiplication by $\\psi$ is a bijection on the group $\\hat{G}$).\nTherefore, the sum remains the same:\n$$ \\sum_{\\chi \\in \\hat{G}} (\\psi \\chi)(g) = \\sum_{\\eta \\in \\hat{G}} \\eta(g) = T $$\nSo, $\\psi(g) T = T$, which implies $(\\psi(g) - 1) T = 0$.\nSince $\\psi(g) \\neq 1$, we must have $T = 0$.\n\nThis concludes the proof of the lemma.\n\n### Step 3: Evaluation of the Sum\n\nReturn to the expression for $S$:\n$$ S = \\frac{1}{|G|} \\sum_{y \\in G} f(y) \\left( \\sum_{\\chi \\in \\hat{G}} \\chi(x y^{-1}) \\right) $$\n\nUsing the Lemma, the inner sum is non-zero if and only if $x y^{-1} = e_G$, which implies $y = x$.\n- If $y \\neq x$, the inner sum is $0$.\n- If $y = x$, the inner sum is $|G|$.\n\nThus, the sum over $y$ collapses to the single term where $y = x$:\n$$ S = \\frac{1}{|G|} \\left( f(x) \\cdot |G| \\right) $$\n\nSimplifying the expression:\n$$ S = f(x) $$\n\n### Conclusion\n\nWe have shown that:\n$$ \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x) = f(x) $$\nThis completes the proof of the Fourier Inversion Formula.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles. Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.",
    "run_id": "40",
    "outer_attempt": 3,
    "topic_slug": "manifolds_and_cell_complexes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To prove that the Euler characteristic $\\chi(M)$ of a 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles is given by $\\chi(M) = 2 - 2g$, we will proceed by mathematical induction on the number of handles $g$.\n\n### 1. Definitions and Preliminaries\n\n**Euler Characteristic**\nThe Euler characteristic $\\chi(X)$ of a topological space $X$ (specifically a finite CW-complex or simplicial complex) is defined as the alternating sum of the number of cells in each dimension:\n$$ \\chi(X) = \\sum_{k=0}^n (-1)^k c_k $$\nwhere $c_k$ is the number of $k$-dimensional cells. For a 2-dimensional surface with a triangulation consisting of $V$ vertices, $E$ edges, and $F$ faces, this formula reduces to:\n$$ \\chi(X) = V - E + F $$\nThe Euler characteristic is a topological invariant; homeomorphic spaces have the same Euler characteristic.\n\n**Inclusion-Exclusion Principle**\nIf a space $X$ is the union of two closed subspaces $A$ and $B$ such that their intersection $A \\cap B$ is a subcomplex of both, then:\n$$ \\chi(A \\cup B) = \\chi(A) + \\chi(B) - \\chi(A \\cap B) $$\n\n### 2. Base Case: $g = 0$\n\nA sphere with 0 handles is simply the sphere $\\mathbb{S}^2$. To find $\\chi(\\mathbb{S}^2)$, we can use a simple triangulation, such as the boundary of a tetrahedron.\n\n- **Vertices ($V$):** 4\n- **Edges ($E$):** 6\n- **Faces ($F$):** 4\n\n$$ \\chi(\\mathbb{S}^2) = 4 - 6 + 4 = 2 $$\n\nSubstituting $g=0$ into the formula $2 - 2g$:\n$$ 2 - 2(0) = 2 $$\nThe base case holds.\n\n### 3. Inductive Step\n\nAssume that for a sphere with $k$ handles, denoted $M_k$, the Euler characteristic is $\\chi(M_k) = 2 - 2k$. We wish to show that for a sphere with $k+1$ handles, $M_{k+1}$, the Euler characteristic is $\\chi(M_{k+1}) = 2 - 2(k+1) = 2 - 2k - 2$.\n\n**Construction of $M_{k+1}$ from $M_k$**\nA \"handle\" is topologically a cylinder (homeomorphic to $\\mathbb{S}^1 \\times [0,1]$). Adding a handle to a surface involves the following surgery operation:\n1.  Select two disjoint closed disks $D_1$ and $D_2$ on the surface $M_k$.\n2.  Remove the interiors of these disks to form a surface with boundary, $M'_k = M_k \\setminus (\\text{int}(D_1) \\cup \\text{int}(D_2))$. The boundary $\\partial M'_k$ consists of two disjoint circles, $C_1$ and $C_2$.\n3.  Attach a cylinder $H \\cong \\mathbb{S}^1 \\times [0,1]$ by identifying its two boundary circles ($\\mathbb{S}^1 \\times \\{0\\}$ and $\\mathbb{S}^1 \\times \\{1\\}$) with $C_1$ and $C_2$.\n\nWe calculate the Euler characteristic change in two steps:\n\n**Step 1: Removing the Disks**\nLet $D$ be a closed disk. Since $D$ is contractible (homeomorphic to a point), $\\chi(D) = 1$. Its boundary $\\partial D$ is a circle $\\mathbb{S}^1$, and $\\chi(\\mathbb{S}^1) = 0$ (since it can be triangulated with $V=E$).\n\nUsing the decomposition $M_k = M'_k \\cup D_1 \\cup D_2$, where the intersections are the boundaries $\\partial D_1$ and $\\partial D_2$:\n$$ \\chi(M_k) = \\chi(M'_k) + \\chi(D_1 \\cup D_2) - \\chi(\\partial D_1 \\cup \\partial D_2) $$\nSince $D_1$ and $D_2$ are disjoint:\n$$ \\chi(M_k) = \\chi(M'_k) + (\\chi(D_1) + \\chi(D_2)) - (\\chi(\\mathbb{S}^1) + \\chi(\\mathbb{S}^1)) $$\nSubstituting the known values ($\\chi(D)=1, \\chi(\\mathbb{S}^1)=0$):\n$$ \\chi(M_k) = \\chi(M'_k) + 2 - 0 $$\n$$ \\chi(M'_k) = \\chi(M_k) - 2 $$\n\n**Step 2: Attaching the Handle**\nLet $H$ be the handle (cylinder). $H$ retracts onto a circle, so it is homotopy equivalent to $\\mathbb{S}^1$. Thus, $\\chi(H) = \\chi(\\mathbb{S}^1) = 0$.\nThe new manifold is $M_{k+1} = M'_k \\cup H$.\nThe intersection $M'_k \\cap H$ consists of the two boundary circles used for gluing.\n$$ \\chi(M'_k \\cap H) = \\chi(\\mathbb{S}^1 \\sqcup \\mathbb{S}^1) = 0 + 0 = 0 $$\n\nNow apply the inclusion-exclusion principle:\n$$ \\chi(M_{k+1}) = \\chi(M'_k) + \\chi(H) - \\chi(M'_k \\cap H) $$\n$$ \\chi(M_{k+1}) = (\\chi(M_k) - 2) + 0 - 0 $$\n$$ \\chi(M_{k+1}) = \\chi(M_k) - 2 $$\n\n**Conclusion of Inductive Step**\nBy the inductive hypothesis, $\\chi(M_k) = 2 - 2k$. Therefore:\n$$ \\chi(M_{k+1}) = (2 - 2k) - 2 = 2 - 2(k+1) $$\n\n### 4. Final Conclusion\n\nBy the principle of mathematical induction, for any non-negative integer $g$, the Euler characteristic of a 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles is:\n$$ \\chi(M) = 2 - 2g $$",
        "raw_answer": "To prove that the Euler characteristic $\\chi(M)$ of a 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles is given by $\\chi(M) = 2 - 2g$, we will proceed by mathematical induction on the number of handles $g$.\n\n### 1. Definitions and Preliminaries\n\n**Euler Characteristic**\nThe Euler characteristic $\\chi(X)$ of a topological space $X$ (specifically a finite CW-complex or simplicial complex) is defined as the alternating sum of the number of cells in each dimension:\n$$ \\chi(X) = \\sum_{k=0}^n (-1)^k c_k $$\nwhere $c_k$ is the number of $k$-dimensional cells. For a 2-dimensional surface with a triangulation consisting of $V$ vertices, $E$ edges, and $F$ faces, this formula reduces to:\n$$ \\chi(X) = V - E + F $$\nThe Euler characteristic is a topological invariant; homeomorphic spaces have the same Euler characteristic.\n\n**Inclusion-Exclusion Principle**\nIf a space $X$ is the union of two closed subspaces $A$ and $B$ such that their intersection $A \\cap B$ is a subcomplex of both, then:\n$$ \\chi(A \\cup B) = \\chi(A) + \\chi(B) - \\chi(A \\cap B) $$\n\n### 2. Base Case: $g = 0$\n\nA sphere with 0 handles is simply the sphere $\\mathbb{S}^2$. To find $\\chi(\\mathbb{S}^2)$, we can use a simple triangulation, such as the boundary of a tetrahedron.\n\n- **Vertices ($V$):** 4\n- **Edges ($E$):** 6\n- **Faces ($F$):** 4\n\n$$ \\chi(\\mathbb{S}^2) = 4 - 6 + 4 = 2 $$\n\nSubstituting $g=0$ into the formula $2 - 2g$:\n$$ 2 - 2(0) = 2 $$\nThe base case holds.\n\n### 3. Inductive Step\n\nAssume that for a sphere with $k$ handles, denoted $M_k$, the Euler characteristic is $\\chi(M_k) = 2 - 2k$. We wish to show that for a sphere with $k+1$ handles, $M_{k+1}$, the Euler characteristic is $\\chi(M_{k+1}) = 2 - 2(k+1) = 2 - 2k - 2$.\n\n**Construction of $M_{k+1}$ from $M_k$**\nA \"handle\" is topologically a cylinder (homeomorphic to $\\mathbb{S}^1 \\times [0,1]$). Adding a handle to a surface involves the following surgery operation:\n1.  Select two disjoint closed disks $D_1$ and $D_2$ on the surface $M_k$.\n2.  Remove the interiors of these disks to form a surface with boundary, $M'_k = M_k \\setminus (\\text{int}(D_1) \\cup \\text{int}(D_2))$. The boundary $\\partial M'_k$ consists of two disjoint circles, $C_1$ and $C_2$.\n3.  Attach a cylinder $H \\cong \\mathbb{S}^1 \\times [0,1]$ by identifying its two boundary circles ($\\mathbb{S}^1 \\times \\{0\\}$ and $\\mathbb{S}^1 \\times \\{1\\}$) with $C_1$ and $C_2$.\n\nWe calculate the Euler characteristic change in two steps:\n\n**Step 1: Removing the Disks**\nLet $D$ be a closed disk. Since $D$ is contractible (homeomorphic to a point), $\\chi(D) = 1$. Its boundary $\\partial D$ is a circle $\\mathbb{S}^1$, and $\\chi(\\mathbb{S}^1) = 0$ (since it can be triangulated with $V=E$).\n\nUsing the decomposition $M_k = M'_k \\cup D_1 \\cup D_2$, where the intersections are the boundaries $\\partial D_1$ and $\\partial D_2$:\n$$ \\chi(M_k) = \\chi(M'_k) + \\chi(D_1 \\cup D_2) - \\chi(\\partial D_1 \\cup \\partial D_2) $$\nSince $D_1$ and $D_2$ are disjoint:\n$$ \\chi(M_k) = \\chi(M'_k) + (\\chi(D_1) + \\chi(D_2)) - (\\chi(\\mathbb{S}^1) + \\chi(\\mathbb{S}^1)) $$\nSubstituting the known values ($\\chi(D)=1, \\chi(\\mathbb{S}^1)=0$):\n$$ \\chi(M_k) = \\chi(M'_k) + 2 - 0 $$\n$$ \\chi(M'_k) = \\chi(M_k) - 2 $$\n\n**Step 2: Attaching the Handle**\nLet $H$ be the handle (cylinder). $H$ retracts onto a circle, so it is homotopy equivalent to $\\mathbb{S}^1$. Thus, $\\chi(H) = \\chi(\\mathbb{S}^1) = 0$.\nThe new manifold is $M_{k+1} = M'_k \\cup H$.\nThe intersection $M'_k \\cap H$ consists of the two boundary circles used for gluing.\n$$ \\chi(M'_k \\cap H) = \\chi(\\mathbb{S}^1 \\sqcup \\mathbb{S}^1) = 0 + 0 = 0 $$\n\nNow apply the inclusion-exclusion principle:\n$$ \\chi(M_{k+1}) = \\chi(M'_k) + \\chi(H) - \\chi(M'_k \\cap H) $$\n$$ \\chi(M_{k+1}) = (\\chi(M_k) - 2) + 0 - 0 $$\n$$ \\chi(M_{k+1}) = \\chi(M_k) - 2 $$\n\n**Conclusion of Inductive Step**\nBy the inductive hypothesis, $\\chi(M_k) = 2 - 2k$. Therefore:\n$$ \\chi(M_{k+1}) = (2 - 2k) - 2 = 2 - 2(k+1) $$\n\n### 4. Final Conclusion\n\nBy the principle of mathematical induction, for any non-negative integer $g$, the Euler characteristic of a 2-dimensional manifold $M$ homeomorphic to a sphere with $g$ handles is:\n$$ \\chi(M) = 2 - 2g $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "google-gemini-3-pro-preview",
    "question": "Let $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.",
    "run_id": "19",
    "outer_attempt": 5,
    "topic_slug": "potential_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "To solve the Dirichlet problem $\\Delta u = 0$ in the unit disk $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ with the boundary condition $u(x) = \\log|x - (1,0)|$ on $\\partial D$, we proceed as follows.\n\n### 1. Analysis of the Candidate Solution\n\nLet $\\mathbf{e}_1 = (1,0)$. The boundary condition is given by the restriction of the function $v(x) = \\log|x - \\mathbf{e}_1|$ to the boundary $\\partial D$.\n\nWe consider the function defined on the entire domain $\\bar{D} \\setminus \\{\\mathbf{e}_1\\}$:\n$$ u(x) = \\log|x - \\mathbf{e}_1| $$\n\nWe verify if this function satisfies the Laplace equation in the interior $D$ and matches the boundary data.\n\n### 2. Verification of Harmonicity\n\nThe function $u(x) = \\log|x - \\mathbf{e}_1|$ is the fundamental solution to the Laplace equation in 2D, shifted to center at $\\mathbf{e}_1$. Specifically, for any $y \\in \\mathbb{R}^2$, the Laplacian of $\\phi(x) = \\log|x - y|$ is:\n$$ \\Delta \\phi = 2\\pi \\delta(x - y) $$\nwhere $\\delta$ is the Dirac delta distribution.\n\nIn our case, the singularity is at $y = \\mathbf{e}_1 = (1,0)$.\nSince $D = \\{x : |x| < 1\\}$, the point $(1,0)$ lies on the boundary $\\partial D$ and not in the interior $D$.\nTherefore, for all $x \\in D$, $x \\neq \\mathbf{e}_1$.\nConsequently:\n$$ \\Delta u(x) = 0 \\quad \\text{for all } x \\in D. $$\nThus, $u(x)$ is harmonic in $D$.\n\nAlternatively, using complex variables, let $z = x_1 + i x_2$. The function $f(z) = \\log(1 - z)$ is analytic in the unit disk $|z| < 1$ (the branch point is at $z=1$ and the branch cut can be taken along the real axis $x \\geq 1$, outside the disk). The real part of an analytic function is harmonic.\n$$ \\text{Re}(\\log(1 - z)) = \\log|1 - z| = \\log| (1-x_1) - i x_2 | = \\log\\sqrt{(1-x_1)^2 + x_2^2} = \\log|x - \\mathbf{e}_1|. $$\nThis confirms $u(x)$ is harmonic in $D$.\n\n### 3. Verification of Boundary Conditions\n\nThe problem requires $u(x) = \\log|x - \\mathbf{e}_1|$ for $x \\in \\partial D$.\nOur candidate solution is defined as $u(x) = \\log|x - \\mathbf{e}_1|$ for all $x \\in \\bar{D} \\setminus \\{\\mathbf{e}_1\\}$.\nTrivially, for any $x \\in \\partial D$ where $x \\neq (1,0)$, the function value matches the specified boundary condition.\nAt $x = (1,0)$, the boundary data has a logarithmic singularity ($-\\infty$). The solution $u(x)$ exhibits the exact same behavior as $x \\to (1,0)$ from within $D$.\n\n### 4. Uniqueness and Poisson Integral Formulation\n\nAlthough the boundary data $g(t) = \\log|e^{it} - 1|$ has a singularity at $t=0$, it is integrable ($g \\in L^1[-\\pi, \\pi]$). The unique harmonic function corresponding to such boundary data (via the Poisson integral formula) is given by the convolution of the Poisson kernel with the boundary data.\n\nThe Fourier series of the boundary data is well-known:\n$$ \\log|e^{it} - 1| = \\log\\left| 2\\sin(t/2) \\right| = -\\sum_{k=1}^{\\infty} \\frac{\\cos(kt)}{k} $$\nThe harmonic extension into the disk $x = (r\\cos\\theta, r\\sin\\theta)$ is obtained by scaling the $k$-th mode by $r^k$:\n$$ u(r, \\theta) = -\\sum_{k=1}^{\\infty} \\frac{r^k \\cos(k\\theta)}{k} $$\nRecognizing the Taylor series for $-\\log(1 - z)$:\n$$ -\\log(1 - z) = \\sum_{k=1}^{\\infty} \\frac{z^k}{k} \\quad (|z|<1) $$\nLet $z = r e^{i\\theta}$. Then:\n$$ \\text{Re}(-\\log(1 - z)) = \\text{Re}\\left( \\sum_{k=1}^{\\infty} \\frac{r^k (\\cos k\\theta + i \\sin k\\theta)}{k} \\right) = \\sum_{k=1}^{\\infty} \\frac{r^k \\cos(k\\theta)}{k} = -u(r, \\theta) $$\nThus:\n$$ u(r, \\theta) = -\\text{Re}(-\\log(1 - z)) = \\text{Re}(\\log(1 - z)) = \\log|1 - z| = \\log|x - (1,0)| $$\nThis confirms that the candidate function is indeed the solution generated by the standard Poisson integral method.\n\n### Conclusion\n\nThe solution is the harmonic extension of the boundary function into the interior.\n\n$$ u(x) = \\log|x - (1,0)| $$\n\nIn coordinate form, where $x = (x_1, x_2)$:\n$$ u(x_1, x_2) = \\frac{1}{2} \\ln\\left( (x_1 - 1)^2 + x_2^2 \\right) $$\n\nIn polar coordinates $(r, \\theta)$:\n$$ u(r, \\theta) = \\frac{1}{2} \\ln\\left( 1 - 2r\\cos\\theta + r^2 \\right) $$",
        "raw_answer": "To solve the Dirichlet problem $\\Delta u = 0$ in the unit disk $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ with the boundary condition $u(x) = \\log|x - (1,0)|$ on $\\partial D$, we proceed as follows.\n\n### 1. Analysis of the Candidate Solution\n\nLet $\\mathbf{e}_1 = (1,0)$. The boundary condition is given by the restriction of the function $v(x) = \\log|x - \\mathbf{e}_1|$ to the boundary $\\partial D$.\n\nWe consider the function defined on the entire domain $\\bar{D} \\setminus \\{\\mathbf{e}_1\\}$:\n$$ u(x) = \\log|x - \\mathbf{e}_1| $$\n\nWe verify if this function satisfies the Laplace equation in the interior $D$ and matches the boundary data.\n\n### 2. Verification of Harmonicity\n\nThe function $u(x) = \\log|x - \\mathbf{e}_1|$ is the fundamental solution to the Laplace equation in 2D, shifted to center at $\\mathbf{e}_1$. Specifically, for any $y \\in \\mathbb{R}^2$, the Laplacian of $\\phi(x) = \\log|x - y|$ is:\n$$ \\Delta \\phi = 2\\pi \\delta(x - y) $$\nwhere $\\delta$ is the Dirac delta distribution.\n\nIn our case, the singularity is at $y = \\mathbf{e}_1 = (1,0)$.\nSince $D = \\{x : |x| < 1\\}$, the point $(1,0)$ lies on the boundary $\\partial D$ and not in the interior $D$.\nTherefore, for all $x \\in D$, $x \\neq \\mathbf{e}_1$.\nConsequently:\n$$ \\Delta u(x) = 0 \\quad \\text{for all } x \\in D. $$\nThus, $u(x)$ is harmonic in $D$.\n\nAlternatively, using complex variables, let $z = x_1 + i x_2$. The function $f(z) = \\log(1 - z)$ is analytic in the unit disk $|z| < 1$ (the branch point is at $z=1$ and the branch cut can be taken along the real axis $x \\geq 1$, outside the disk). The real part of an analytic function is harmonic.\n$$ \\text{Re}(\\log(1 - z)) = \\log|1 - z| = \\log| (1-x_1) - i x_2 | = \\log\\sqrt{(1-x_1)^2 + x_2^2} = \\log|x - \\mathbf{e}_1|. $$\nThis confirms $u(x)$ is harmonic in $D$.\n\n### 3. Verification of Boundary Conditions\n\nThe problem requires $u(x) = \\log|x - \\mathbf{e}_1|$ for $x \\in \\partial D$.\nOur candidate solution is defined as $u(x) = \\log|x - \\mathbf{e}_1|$ for all $x \\in \\bar{D} \\setminus \\{\\mathbf{e}_1\\}$.\nTrivially, for any $x \\in \\partial D$ where $x \\neq (1,0)$, the function value matches the specified boundary condition.\nAt $x = (1,0)$, the boundary data has a logarithmic singularity ($-\\infty$). The solution $u(x)$ exhibits the exact same behavior as $x \\to (1,0)$ from within $D$.\n\n### 4. Uniqueness and Poisson Integral Formulation\n\nAlthough the boundary data $g(t) = \\log|e^{it} - 1|$ has a singularity at $t=0$, it is integrable ($g \\in L^1[-\\pi, \\pi]$). The unique harmonic function corresponding to such boundary data (via the Poisson integral formula) is given by the convolution of the Poisson kernel with the boundary data.\n\nThe Fourier series of the boundary data is well-known:\n$$ \\log|e^{it} - 1| = \\log\\left| 2\\sin(t/2) \\right| = -\\sum_{k=1}^{\\infty} \\frac{\\cos(kt)}{k} $$\nThe harmonic extension into the disk $x = (r\\cos\\theta, r\\sin\\theta)$ is obtained by scaling the $k$-th mode by $r^k$:\n$$ u(r, \\theta) = -\\sum_{k=1}^{\\infty} \\frac{r^k \\cos(k\\theta)}{k} $$\nRecognizing the Taylor series for $-\\log(1 - z)$:\n$$ -\\log(1 - z) = \\sum_{k=1}^{\\infty} \\frac{z^k}{k} \\quad (|z|<1) $$\nLet $z = r e^{i\\theta}$. Then:\n$$ \\text{Re}(-\\log(1 - z)) = \\text{Re}\\left( \\sum_{k=1}^{\\infty} \\frac{r^k (\\cos k\\theta + i \\sin k\\theta)}{k} \\right) = \\sum_{k=1}^{\\infty} \\frac{r^k \\cos(k\\theta)}{k} = -u(r, \\theta) $$\nThus:\n$$ u(r, \\theta) = -\\text{Re}(-\\log(1 - z)) = \\text{Re}(\\log(1 - z)) = \\log|1 - z| = \\log|x - (1,0)| $$\nThis confirms that the candidate function is indeed the solution generated by the standard Poisson integral method.\n\n### Conclusion\n\nThe solution is the harmonic extension of the boundary function into the interior.\n\n$$ u(x) = \\log|x - (1,0)| $$\n\nIn coordinate form, where $x = (x_1, x_2)$:\n$$ u(x_1, x_2) = \\frac{1}{2} \\ln\\left( (x_1 - 1)^2 + x_2^2 \\right) $$\n\nIn polar coordinates $(r, \\theta)$:\n$$ u(r, \\theta) = \\frac{1}{2} \\ln\\left( 1 - 2r\\cos\\theta + r^2 \\right) $$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  }
]