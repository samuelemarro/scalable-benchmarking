[
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $P(x)$ be the predicate \"$x$ is a prime number\" and $Q(x, y)$ be the predicate \"$y$ is the smallest prime greater than $x$.\" For all natural numbers $n$, consider the statement: \"For every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\" Formalize this statement using the given predicates $P(x)$ and $Q(x, y)$, and determine whether it is true or false. If true, provide a proof; if false, provide a counterexample.",
    "run_id": "1",
    "topic_slug": "mathematical_logic_and_foundations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We formalize the statement and then determine its truth value.\n\n### Formalization\n\nLet the domain be the set of natural numbers $\\mathbb{N} = \\{1,2,3,\\dots\\}$.  \nGiven predicates:  \n- $P(x)$: \u201c$x$ is a prime number.\u201d  \n- $Q(x,y)$: \u201c$y$ is the smallest prime greater than $x$.\u201d\n\nThe English statement  \n\n> \u201cFor every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\u201d\n\ncan be expressed using both predicates as follows.  \nObserve that the existence of a prime between $n$ and $2n$ is equivalent to the smallest prime greater than $n$ being less than $2n$. Hence we write\n\n$$\n\\forall n \\in \\mathbb{N}\\; \\exists p \\in \\mathbb{N}\\; \\bigl( P(p) \\land Q(n, p) \\land p < 2n \\bigr).\n$$\n\n(We include $P(p)$ explicitly to use both predicates, even though $Q(n,p)$ already implies $P(p)$.)\n\n### Truth Value\n\nThe statement is **false**.\n\n#### Counterexample\n\nTake $n = 1$.  \nWe need a prime $p$ such that $1 < p < 2$.  \nThe only integers strictly between $1$ and $2$ do not exist. In particular, the smallest integer greater than $1$ is $2$, but $2$ is **not** less than $2$. Since every prime is an integer $\\ge 2$, no prime can satisfy $1 < p < 2$.  \n\nMore formally, suppose there existed a $p$ with $P(p)$, $Q(1,p)$, and $p < 2$.  \n$Q(1,p)$ means $p$ is the smallest prime greater than $1$, which forces $p = 2$.  \nBut then $p < 2$ becomes $2 < 2$, a contradiction.  \nThus $\\exists p\\,(P(p) \\land Q(1,p) \\land p<2)$ is false, and consequently the universal statement is false.\n\n### Remark\n\nThe statement becomes true when restricted to $n \\ge 2$; this is the well\u2011known Bertrand\u2019s postulate (Chebyshev\u2019s theorem). However, as quantified over all natural numbers (including $n=1$), it is false.",
        "raw_answer": "We formalize the statement and then determine its truth value.\n\n### Formalization\n\nLet the domain be the set of natural numbers $\\mathbb{N} = \\{1,2,3,\\dots\\}$.  \nGiven predicates:  \n- $P(x)$: \u201c$x$ is a prime number.\u201d  \n- $Q(x,y)$: \u201c$y$ is the smallest prime greater than $x$.\u201d\n\nThe English statement  \n\n> \u201cFor every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\u201d\n\ncan be expressed using both predicates as follows.  \nObserve that the existence of a prime between $n$ and $2n$ is equivalent to the smallest prime greater than $n$ being less than $2n$. Hence we write\n\n\\[\n\\forall n \\in \\mathbb{N}\\; \\exists p \\in \\mathbb{N}\\; \\bigl( P(p) \\land Q(n, p) \\land p < 2n \\bigr).\n\\]\n\n(We include $P(p)$ explicitly to use both predicates, even though $Q(n,p)$ already implies $P(p)$.)\n\n### Truth Value\n\nThe statement is **false**.\n\n#### Counterexample\n\nTake $n = 1$.  \nWe need a prime $p$ such that $1 < p < 2$.  \nThe only integers strictly between $1$ and $2$ do not exist. In particular, the smallest integer greater than $1$ is $2$, but $2$ is **not** less than $2$. Since every prime is an integer $\\ge 2$, no prime can satisfy $1 < p < 2$.  \n\nMore formally, suppose there existed a $p$ with $P(p)$, $Q(1,p)$, and $p < 2$.  \n$Q(1,p)$ means $p$ is the smallest prime greater than $1$, which forces $p = 2$.  \nBut then $p < 2$ becomes $2 < 2$, a contradiction.  \nThus $\\exists p\\,(P(p) \\land Q(1,p) \\land p<2)$ is false, and consequently the universal statement is false.\n\n### Remark\n\nThe statement becomes true when restricted to $n \\ge 2$; this is the well\u2011known Bertrand\u2019s postulate (Chebyshev\u2019s theorem). However, as quantified over all natural numbers (including $n=1$), it is false.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Combinatorics, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the domain\nThe domain specified is Combinatorics, which involves the study of counting, arranging, and optimizing objects in various ways. It encompasses topics such as permutations, combinations, graph theory, and more.\n\n## Step 3: Generate a problem\nTo create a challenging problem, let's consider a topic within Combinatorics that is both interesting and requires substantial reasoning. A potential topic is graph theory, specifically focusing on graph coloring or connectivity.\n\n## Step 4: Formulate the problem\nLet's formulate a problem: \"Prove that in any simple graph with $n$ vertices, if the graph is connected and has no cycles (i.e., it's a tree), then it has exactly $n-1$ edges.\"\n\n## Step 5: Verify the problem against the quality rubric\n- **Well-Posedness and Completeness**: The problem is self-contained, defines the necessary terms (simple graph, connected, no cycles, tree), and asks for a proof.\n- **Clarity**: The terms used are standard in graph theory, and the task is clear.\n- **Non-Triviality**: The problem requires understanding of graph theory and a proof involving induction or another suitable method, making it non-trivial.\n- **Solvability and Verification**: The statement is a known fact in graph theory and can be proven using established methods.\n\n## Step 6: Provide the solution\nTo solve this, we can use induction on $n$. For $n=1$, a tree has 0 edges, and $1-1=0$, so the statement holds. For $n>1$, assume the statement is true for all trees with fewer than $n$ vertices. A tree with $n$ vertices has at least one leaf (a vertex of degree 1); removing this leaf and its edge gives a tree with $n-1$ vertices. By the induction hypothesis, this smaller tree has $(n-1)-1 = n-2$ edges. Adding back the removed edge gives $n-2 + 1 = n-1$ edges, proving the statement for $n$.\n\n## Step 7: Format the output\nLet's format the problem and solution according to the required structure.\n\n\nLet $G$ be a simple graph with $n$ vertices. Prove that if $G$ is a tree (i.e., it is connected and has no cycles), then it has exactly $n-1$ edges.",
    "run_id": "2",
    "topic_slug": "combinatorics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove the following theorem:\n\n**Theorem.** Let $G$ be a simple graph with $n$ vertices. If $G$ is a tree (i.e., connected and contains no cycles), then $G$ has exactly $n-1$ edges.\n\n*Proof.* We proceed by induction on $n$, the number of vertices.\n\n**Base case:** $n = 1$. A tree with one vertex has no edges. Indeed, any edge would require two distinct vertices. Hence the number of edges is $0 = 1 - 1$. The statement holds.\n\n**Inductive step:** Assume that every tree with fewer than $n$ vertices (for some $n \\ge 2$) has exactly one less edge than its number of vertices. Consider a tree $T$ with $n$ vertices.\n\nFirst, we claim that $T$ contains at least one leaf (a vertex of degree $1$). Since $T$ is connected and has at least two vertices, it contains a path of maximal length. Let $P = v_0 v_1 \\dots v_k$ be such a maximal path. The endpoints $v_0$ and $v_k$ cannot have degree $\\ge 2$ in $T$; otherwise, if (say) $v_0$ were adjacent to some vertex $w$ different from $v_1$, then either $w$ is not on $P$ (giving a longer path $w v_0 v_1 \\dots v_k$) or $w$ is on $P$ (creating a cycle). Both contradict maximality or acyclicity. Hence $\\deg(v_0) = 1$ and similarly $\\deg(v_k) = 1$. Thus $T$ has a leaf; pick one, call it $v$, and let $e$ be the unique edge incident with $v$, connecting $v$ to some vertex $u$.\n\nNow remove $v$ and the edge $e$ from $T$. Denote the resulting graph by $T' = T - v$. We show that $T'$ is still a tree.\n\n- **Acyclicity:** Removing a vertex cannot create a cycle, and $T$ itself has no cycles, so $T'$ is also acyclic.\n- **Connectedness:** Take any two vertices $x, y \\in V(T')$. In $T$ there is a unique simple path between $x$ and $y$. This path cannot contain the leaf $v$, because if it did, then $v$ would appear with degree $2$ on that path (one edge to enter, one to exit), contradicting $\\deg(v)=1$. Hence the path lies entirely in $T'$, so $x$ and $y$ are connected in $T'$. Thus $T'$ is connected.\n\nTherefore $T'$ is a tree with $n-1$ vertices. By the induction hypothesis, $T'$ has $(n-1)-1 = n-2$ edges.\n\nSince we removed exactly one edge $e$ from $T$ to obtain $T'$, the original tree $T$ has $(n-2) + 1 = n-1$ edges.\n\nThis completes the inductive step.\n\nBy the principle of mathematical induction, the theorem holds for all $n \\ge 1$. \u220e\n\n**Conclusion:** Every tree on $n$ vertices has exactly $n-1$ edges.",
        "raw_answer": "We prove the following theorem:\n\n**Theorem.** Let \\(G\\) be a simple graph with \\(n\\) vertices. If \\(G\\) is a tree (i.e., connected and contains no cycles), then \\(G\\) has exactly \\(n-1\\) edges.\n\n*Proof.* We proceed by induction on \\(n\\), the number of vertices.\n\n**Base case:** \\(n = 1\\). A tree with one vertex has no edges. Indeed, any edge would require two distinct vertices. Hence the number of edges is \\(0 = 1 - 1\\). The statement holds.\n\n**Inductive step:** Assume that every tree with fewer than \\(n\\) vertices (for some \\(n \\ge 2\\)) has exactly one less edge than its number of vertices. Consider a tree \\(T\\) with \\(n\\) vertices.\n\nFirst, we claim that \\(T\\) contains at least one leaf (a vertex of degree \\(1\\)). Since \\(T\\) is connected and has at least two vertices, it contains a path of maximal length. Let \\(P = v_0 v_1 \\dots v_k\\) be such a maximal path. The endpoints \\(v_0\\) and \\(v_k\\) cannot have degree \\(\\ge 2\\) in \\(T\\); otherwise, if (say) \\(v_0\\) were adjacent to some vertex \\(w\\) different from \\(v_1\\), then either \\(w\\) is not on \\(P\\) (giving a longer path \\(w v_0 v_1 \\dots v_k\\)) or \\(w\\) is on \\(P\\) (creating a cycle). Both contradict maximality or acyclicity. Hence \\(\\deg(v_0) = 1\\) and similarly \\(\\deg(v_k) = 1\\). Thus \\(T\\) has a leaf; pick one, call it \\(v\\), and let \\(e\\) be the unique edge incident with \\(v\\), connecting \\(v\\) to some vertex \\(u\\).\n\nNow remove \\(v\\) and the edge \\(e\\) from \\(T\\). Denote the resulting graph by \\(T' = T - v\\). We show that \\(T'\\) is still a tree.\n\n- **Acyclicity:** Removing a vertex cannot create a cycle, and \\(T\\) itself has no cycles, so \\(T'\\) is also acyclic.\n- **Connectedness:** Take any two vertices \\(x, y \\in V(T')\\). In \\(T\\) there is a unique simple path between \\(x\\) and \\(y\\). This path cannot contain the leaf \\(v\\), because if it did, then \\(v\\) would appear with degree \\(2\\) on that path (one edge to enter, one to exit), contradicting \\(\\deg(v)=1\\). Hence the path lies entirely in \\(T'\\), so \\(x\\) and \\(y\\) are connected in \\(T'\\). Thus \\(T'\\) is connected.\n\nTherefore \\(T'\\) is a tree with \\(n-1\\) vertices. By the induction hypothesis, \\(T'\\) has \\((n-1)-1 = n-2\\) edges.\n\nSince we removed exactly one edge \\(e\\) from \\(T\\) to obtain \\(T'\\), the original tree \\(T\\) has \\((n-2) + 1 = n-1\\) edges.\n\nThis completes the inductive step.\n\nBy the principle of mathematical induction, the theorem holds for all \\(n \\ge 1\\). \u220e\n\n**Conclusion:** Every tree on \\(n\\) vertices has exactly \\(n-1\\) edges.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the requirements for the problem.\nThe task is to generate a challenging but solvable mathematics problem in the domain of number theory, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within number theory.\nNumber theory encompasses various topics such as divisibility, prime numbers, congruences, and Diophantine equations. A challenging problem could involve proving a property related to prime numbers or solving a specific type of Diophantine equation.\n\n## Step 3: Formulate a problem that meets the criteria.\nLet's consider a problem involving the sum of divisors of a number and its relation to perfect numbers. A perfect number is a positive integer that is equal to the sum of its proper divisors, excluding the number itself.\n\n## Step 4: Specify the problem.\nConsider the following problem: \"Prove that if $n$ is an even perfect number, then $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.\"\n\n## Step 5: Provide the solution to the problem.\nTo solve this, we need to understand the definition of an even perfect number and its relation to Mersenne primes.\n\n## Step 6: Recall the definition and properties of even perfect numbers.\nAn even perfect number $n$ can be written as $n = 2^{k-1}(2^k - 1)$, where $2^k - 1$ is prime. This is known as the Euclid-Euler theorem.\n\n## Step 7: State the Euclid-Euler theorem.\nThe Euclid-Euler theorem states that every even perfect number is of the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime (i.e., $2^p - 1$ is prime).\n\n## Step 8: Provide the proof or reasoning for the given statement.\nThe proof involves two main parts: (1) showing that any number of the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is prime, is perfect, and (2) showing that every even perfect number is of this form.\n\n## Step 9: Outline the proof that $2^{p-1}(2^p - 1)$ is perfect when $2^p - 1$ is prime.\nLet $n = 2^{p-1}(2^p - 1)$. The sum of divisors of $n$, $\\sigma(n)$, is given by $\\sigma(n) = \\sigma(2^{p-1})\\sigma(2^p - 1)$. Since $2^p - 1$ is prime, $\\sigma(2^p - 1) = 2^p$. Also, $\\sigma(2^{p-1}) = 1 + 2 + 2^2 + \\cdots + 2^{p-1} = 2^p - 1$. Thus, $\\sigma(n) = (2^p - 1) \\cdot 2^p = 2 \\cdot 2^{p-1}(2^p - 1) = 2n$, proving $n$ is perfect.\n\n## Step 10: Outline the proof that every even perfect number is of the form $2^{p-1}(2^p - 1)$.\nLet $n$ be an even perfect number. Then $n = 2^k \\cdot m$, where $m$ is odd. Since $n$ is perfect, $\\sigma(n) = 2n$. Using the multiplicative property of $\\sigma$, we have $\\sigma(n) = \\sigma(2^k)\\sigma(m) = (2^{k+1} - 1)\\sigma(m)$. Thus, $(2^{k+1} - 1)\\sigma(m) = 2^{k+1}m$. This implies $2^{k+1} - 1$ divides $m$, so $m = (2^{k+1} - 1)d$ for some $d$. Substituting back gives $\\sigma(m) = 2^{k+1}d$. For $d = 1$, $m = 2^{k+1} - 1$ is prime, and $\\sigma(m) = m + 1 = 2^{k+1}$, which matches our requirement. For $d > 1$, it leads to a contradiction because $\\sigma(m) \\geq m + d > 2d$, unless $d = 1$ and $m$ is prime.\n\n## Step 11: Conclude the solution.\nThe given statement is a direct consequence of the Euclid-Euler theorem, which characterizes even perfect numbers.\n\nThe final answer is: \n\nProve that if $n$ is an even perfect number, then $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.",
    "run_id": "3",
    "topic_slug": "number_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Proof.** Let $n$ be an even perfect number. By definition, $\\sigma(n) = 2n$, where $\\sigma$ denotes the sum of all positive divisors.\n\nSince $n$ is even, we can write $n = 2^{p-1} m$ with an integer $p \\ge 2$ and $m$ odd. (Factor out the highest power of $2$; if the exponent of $2$ is $a$, set $p = a+1$.)\n\nThe function $\\sigma$ is multiplicative for coprime integers. Because $2^{p-1}$ and $m$ are coprime ($m$ is odd), we have\n$$\n\\sigma(n) = \\sigma(2^{p-1})\\,\\sigma(m).\n$$\nFor a prime power, $\\sigma(2^{p-1}) = 1 + 2 + 2^2 + \\cdots + 2^{p-1} = 2^{p} - 1$. Hence,\n$$\n\\sigma(n) = (2^{p} - 1)\\,\\sigma(m).\n$$\nUsing the perfectness of $n$,\n$$\n(2^{p} - 1)\\,\\sigma(m) = 2n = 2\\cdot 2^{p-1}m = 2^{p}m. \\tag{1}\n$$\n\nObserve that $\\gcd(2^{p} - 1, 2^{p}) = 1$ (any common divisor divides their difference $2^{p} - (2^{p}-1) = 1$). Therefore, from (1) we deduce that $2^{p} - 1$ divides $m$. Write\n$$\nm = (2^{p} - 1)\\,t \\tag{2}\n$$\nfor some positive integer $t$.\n\nSubstituting (2) into (1) gives\n$$\n(2^{p} - 1)\\,\\sigma(m) = 2^{p}(2^{p} - 1)\\,t \\quad\\Longrightarrow\\quad \\sigma(m) = 2^{p}t.\n$$\nUsing (2) again, $m = (2^{p} - 1)t$, so\n$$\n\\sigma(m) = 2^{p}t = (2^{p} - 1)t + t = m + t. \\tag{3}\n$$\n\nThus $\\sigma(m) = m + t$. Note that $t$ divides $m$ by (2), and $1$ also divides $m$. We now examine the possible values of $t$.\n\n* **Case $t = 1$.** Then (3) becomes $\\sigma(m) = m + 1$. For an integer $m > 1$, the equality $\\sigma(m) = m + 1$ holds if and only if $m$ is prime. (If $m$ is prime, its only divisors are $1$ and $m$, so $\\sigma(m) = 1 + m$. Conversely, if $m$ is composite, it has a divisor $d$ with $1 < d < m$, so $\\sigma(m) \\ge 1 + d + m \\ge 1 + 2 + m = m + 3 > m + 1$.) Moreover, from (2) we have $m = 2^{p} - 1$, so $2^{p} - 1$ is prime.\n\n* **Case $t > 1$.** Since $p \\ge 2$, we have $2^{p} - 1 \\ge 3$. Then $t < (2^{p} - 1)t = m$, so $t$ is a proper divisor of $m$ distinct from $1$ and $m$. Consequently, $1$, $t$, and $m$ are three distinct positive divisors of $m$, implying\n$$\n\\sigma(m) \\ge 1 + t + m > m + t,\n$$\nwhich contradicts (3). Hence this case cannot occur.\n\nTherefore $t = 1$ is forced, and we have shown that $m = 2^{p} - 1$ is prime. Substituting back into the expression for $n$ yields\n$$\nn = 2^{p-1}(2^{p} - 1),\n$$\nwhere $2^{p} - 1$ is a Mersenne prime. This completes the proof. \u220e",
        "raw_answer": "**Proof.** Let \\(n\\) be an even perfect number. By definition, \\(\\sigma(n) = 2n\\), where \\(\\sigma\\) denotes the sum of all positive divisors.\n\nSince \\(n\\) is even, we can write \\(n = 2^{p-1} m\\) with an integer \\(p \\ge 2\\) and \\(m\\) odd. (Factor out the highest power of \\(2\\); if the exponent of \\(2\\) is \\(a\\), set \\(p = a+1\\).)\n\nThe function \\(\\sigma\\) is multiplicative for coprime integers. Because \\(2^{p-1}\\) and \\(m\\) are coprime (\\(m\\) is odd), we have\n\\[\n\\sigma(n) = \\sigma(2^{p-1})\\,\\sigma(m).\n\\]\nFor a prime power, \\(\\sigma(2^{p-1}) = 1 + 2 + 2^2 + \\cdots + 2^{p-1} = 2^{p} - 1\\). Hence,\n\\[\n\\sigma(n) = (2^{p} - 1)\\,\\sigma(m).\n\\]\nUsing the perfectness of \\(n\\),\n\\[\n(2^{p} - 1)\\,\\sigma(m) = 2n = 2\\cdot 2^{p-1}m = 2^{p}m. \\tag{1}\n\\]\n\nObserve that \\(\\gcd(2^{p} - 1, 2^{p}) = 1\\) (any common divisor divides their difference \\(2^{p} - (2^{p}-1) = 1\\)). Therefore, from (1) we deduce that \\(2^{p} - 1\\) divides \\(m\\). Write\n\\[\nm = (2^{p} - 1)\\,t \\tag{2}\n\\]\nfor some positive integer \\(t\\).\n\nSubstituting (2) into (1) gives\n\\[\n(2^{p} - 1)\\,\\sigma(m) = 2^{p}(2^{p} - 1)\\,t \\quad\\Longrightarrow\\quad \\sigma(m) = 2^{p}t.\n\\]\nUsing (2) again, \\(m = (2^{p} - 1)t\\), so\n\\[\n\\sigma(m) = 2^{p}t = (2^{p} - 1)t + t = m + t. \\tag{3}\n\\]\n\nThus \\(\\sigma(m) = m + t\\). Note that \\(t\\) divides \\(m\\) by (2), and \\(1\\) also divides \\(m\\). We now examine the possible values of \\(t\\).\n\n* **Case \\(t = 1\\).** Then (3) becomes \\(\\sigma(m) = m + 1\\). For an integer \\(m > 1\\), the equality \\(\\sigma(m) = m + 1\\) holds if and only if \\(m\\) is prime. (If \\(m\\) is prime, its only divisors are \\(1\\) and \\(m\\), so \\(\\sigma(m) = 1 + m\\). Conversely, if \\(m\\) is composite, it has a divisor \\(d\\) with \\(1 < d < m\\), so \\(\\sigma(m) \\ge 1 + d + m \\ge 1 + 2 + m = m + 3 > m + 1\\).) Moreover, from (2) we have \\(m = 2^{p} - 1\\), so \\(2^{p} - 1\\) is prime.\n\n* **Case \\(t > 1\\).** Since \\(p \\ge 2\\), we have \\(2^{p} - 1 \\ge 3\\). Then \\(t < (2^{p} - 1)t = m\\), so \\(t\\) is a proper divisor of \\(m\\) distinct from \\(1\\) and \\(m\\). Consequently, \\(1\\), \\(t\\), and \\(m\\) are three distinct positive divisors of \\(m\\), implying\n\\[\n\\sigma(m) \\ge 1 + t + m > m + t,\n\\]\nwhich contradicts (3). Hence this case cannot occur.\n\nTherefore \\(t = 1\\) is forced, and we have shown that \\(m = 2^{p} - 1\\) is prime. Substituting back into the expression for \\(n\\) yields\n\\[\nn = 2^{p-1}(2^{p} - 1),\n\\]\nwhere \\(2^{p} - 1\\) is a Mersenne prime. This completes the proof. \u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of \"Order, lattices, ordered algebraic structures\" along with a complete and verifiable solution.\n\n## Step 2: Identify the key elements of the problem domain\nThe domain involves concepts related to order, lattices, and ordered algebraic structures. This includes partially ordered sets (posets), lattices, Boolean algebras, and other related structures.\n\n## Step 3: Formulate a problem that fits the domain\nTo create a problem, we need to consider what aspects of \"Order, lattices, ordered algebraic structures\" can be explored. A potential problem could involve proving a property about a specific type of lattice or ordered structure.\n\n## Step 4: Generate a specific problem\nLet's consider a problem involving a Boolean algebra, which is a type of lattice. A Boolean algebra is a distributive lattice with the additional property that every element has a complement.\n\n## Step 5: State the problem\n\"Let $B$ be a Boolean algebra. Prove that for any elements $a, b \\in B$, the following identity holds: $a \\vee (a \\wedge b) = a$.\"\n\n## Step 6: Provide a solution to the problem\nTo prove $a \\vee (a \\wedge b) = a$, we can use the properties of a Boolean algebra, specifically the absorption laws.\n\n## Step 7: Write out the solution in detail\nFirst, recall that a Boolean algebra is a distributive lattice with complementation. The absorption laws state that for any $a, b$ in the Boolean algebra, $a \\vee (a \\wedge b) = a$ and $a \\wedge (a \\vee b) = a$. We need to prove the first absorption law.\n\n## Step 8: Apply the properties of a lattice to prove the identity\nBy definition of a lattice, $a \\wedge b \\leq a$ because $a$ is an upper bound of $a$ and $a \\wedge b$, and $a \\wedge b$ is the greatest lower bound of $a$ and $b$. Thus, $a \\vee (a \\wedge b) = a$ because $a \\vee x = a$ whenever $x \\leq a$.\n\n## Step 9: Formalize the solution\nGiven $a, b \\in B$, since $a \\wedge b \\leq a$, we have $a \\vee (a \\wedge b) = a$ due to the property that $x \\leq y$ implies $y \\vee x = y$. Thus, $a \\vee (a \\wedge b) = a$.\n\n## Step 10: Present the problem and solution in the required format\n\nLet $B$ be a Boolean algebra. Prove that for any elements $a, b \\in B$, the following identity holds: $a \\vee (a \\wedge b) = a$.",
    "run_id": "4",
    "topic_slug": "order_lattices_and_ordered_algebraic_structures",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked to prove that in a Boolean algebra $B$, for any elements $a, b \\in B$, the identity $a \\vee (a \\wedge b) = a$ holds. This is one of the absorption laws of lattice theory; since a Boolean algebra is a (distributive) lattice, the proof follows directly from the order\u2011theoretic definition of meet and join.\n\n**Proof.**  \nA Boolean algebra is, in particular, a lattice. In a lattice, for any two elements $x, y$ we have a meet $x \\wedge y$ (greatest lower bound) and a join $x \\vee y$ (least upper bound) with respect to the partial order $\\leq$ of the lattice.\n\n1. By definition of the meet, $a \\wedge b$ is the greatest lower bound of $\\{a, b\\}$. Consequently, it is a lower bound, so  \n   $$\n   a \\wedge b \\leq a \\quad\\text{and}\\quad a \\wedge b \\leq b.\n   $$\n\n2. Consider the set $\\{a, a \\wedge b\\}$.  \n   - Since $a \\leq a$ trivially, and $a \\wedge b \\leq a$ by step\u202f1, the element $a$ is an **upper bound** of this set.\n\n3. The join $a \\vee (a \\wedge b)$ is, by definition, the **least upper bound** of $\\{a, a \\wedge b\\}$.  \n   - Because $a$ is an upper bound, the least upper bound must be less than or equal to every upper bound; in particular,  \n     $$\n     a \\vee (a \\wedge b) \\leq a.\n     $$\n   - On the other hand, $a$ is an element of the set, so any upper bound of the set must be at least $a$. Since $a \\vee (a \\wedge b)$ is an upper bound (it is the least upper bound, hence an upper bound), we have  \n     $$\n     a \\leq a \\vee (a \\wedge b).\n     $$\n\n4. Combining the two inequalities yields  \n   $$\n   a \\vee (a \\wedge b) = a.\n   $$\n\nThus the identity holds for all $a, b \\in B$. \u220e\n\n**Remark.** The proof uses only the lattice structure (the existence of meets and joins with their order\u2011theoretic properties). The additional Boolean algebra axioms (distributivity, existence of complements) are not needed for this particular identity; it is valid in every lattice.",
        "raw_answer": "We are asked to prove that in a Boolean algebra \\(B\\), for any elements \\(a, b \\in B\\), the identity \\(a \\vee (a \\wedge b) = a\\) holds. This is one of the absorption laws of lattice theory; since a Boolean algebra is a (distributive) lattice, the proof follows directly from the order\u2011theoretic definition of meet and join.\n\n**Proof.**  \nA Boolean algebra is, in particular, a lattice. In a lattice, for any two elements \\(x, y\\) we have a meet \\(x \\wedge y\\) (greatest lower bound) and a join \\(x \\vee y\\) (least upper bound) with respect to the partial order \\(\\leq\\) of the lattice.\n\n1. By definition of the meet, \\(a \\wedge b\\) is the greatest lower bound of \\(\\{a, b\\}\\). Consequently, it is a lower bound, so  \n   \\[\n   a \\wedge b \\leq a \\quad\\text{and}\\quad a \\wedge b \\leq b.\n   \\]\n\n2. Consider the set \\(\\{a, a \\wedge b\\}\\).  \n   - Since \\(a \\leq a\\) trivially, and \\(a \\wedge b \\leq a\\) by step\u202f1, the element \\(a\\) is an **upper bound** of this set.\n\n3. The join \\(a \\vee (a \\wedge b)\\) is, by definition, the **least upper bound** of \\(\\{a, a \\wedge b\\}\\).  \n   - Because \\(a\\) is an upper bound, the least upper bound must be less than or equal to every upper bound; in particular,  \n     \\[\n     a \\vee (a \\wedge b) \\leq a.\n     \\]\n   - On the other hand, \\(a\\) is an element of the set, so any upper bound of the set must be at least \\(a\\). Since \\(a \\vee (a \\wedge b)\\) is an upper bound (it is the least upper bound, hence an upper bound), we have  \n     \\[\n     a \\leq a \\vee (a \\wedge b).\n     \\]\n\n4. Combining the two inequalities yields  \n   \\[\n   a \\vee (a \\wedge b) = a.\n   \\]\n\nThus the identity holds for all \\(a, b \\in B\\). \u220e\n\n**Remark.** The proof uses only the lattice structure (the existence of meets and joins with their order\u2011theoretic properties). The additional Boolean algebra axioms (distributivity, existence of complements) are not needed for this particular identity; it is valid in every lattice.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of general algebraic systems, along with a complete and verifiable solution.\n\n## Step 2: Identify the domain\nThe domain is general algebraic systems, which includes topics like groups, rings, fields, and other algebraic structures.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving a specific algebraic structure. A challenging problem could involve proving a property about a certain type of algebraic system.\n\n## Step 4: Create a specific problem\nConsider the following problem: \"Let $G$ be a finite group and $H$ be a subgroup of $G$. Suppose that $|G| = 2|H|$. Prove that $H$ is a normal subgroup of $G$.\"\n\n## Step 5: Verify the problem meets the quality rubric\n- **Well-Posedness and Completeness**: The problem is fully specified with $G$ being a finite group and $H$ a subgroup of $G$, and the condition $|G| = 2|H|$ is given.\n- **Clarity**: The terms are standard in group theory, and the task is clear.\n- **Non-Triviality**: The problem requires understanding of group theory and the concept of normal subgroups, making it non-trivial.\n- **Solvability and Verification**: The problem is solvable using established methods in group theory.\n\n## Step 6: Provide the solution\nTo prove that $H$ is a normal subgroup of $G$, we need to show that for any $g \\in G$ and $h \\in H$, $g^{-1}hg \\in H$.\n\n## Step 7: Break down the solution\nFirst, note that since $|G| = 2|H|$, $H$ has index 2 in $G$. This implies there are exactly two cosets of $H$ in $G$: $H$ itself and $G \\setminus H$.\n\n## Step 8: Analyze cosets\nFor any $g \\in G$, if $g \\in H$, then $gH = H$ and $Hg = H$, so $gH = Hg$. If $g \\notin H$, then $gH = G \\setminus H$ because there are only two cosets and $gH$ cannot be $H$. Similarly, $Hg = G \\setminus H$, so again $gH = Hg$.\n\n## Step 9: Conclude normality\nSince $gH = Hg$ for all $g \\in G$, $H$ is normal in $G$.\n\n## Step 10: Write the problem and solution in the required format\n\nLet $G$ be a finite group and $H$ be a subgroup of $G$. Suppose that $|G| = 2|H|$. Prove that $H$ is a normal subgroup of $G$.",
    "run_id": "5",
    "topic_slug": "general_algebraic_systems",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution.**  \nSince $|G| = 2|H|$, Lagrange\u2019s theorem gives the index $[G:H] = |G|/|H| = 2$. Hence there are exactly two left cosets of $H$ in $G$ and exactly two right cosets.\n\nLet $g \\in G$. We consider two cases.\n\n*Case 1:* $g \\in H$.  \nThen $gH = H$ and $Hg = H$, so $gH = Hg$.\n\n*Case 2:* $g \\notin H$.  \nBecause there are only two left cosets, they must be $H$ and $gH$ (the coset $gH$ is distinct from $H$ since $g \\notin H$). These two left cosets partition $G$, so $gH = G \\setminus H$.  \nSimilarly, the two right cosets are $H$ and $Hg$, and they also partition $G$, giving $Hg = G \\setminus H$.  \nThus $gH = G \\setminus H = Hg$.\n\nIn both cases we have $gH = Hg$ for every $g \\in G$, which means $H$ is a normal subgroup of $G$. $\\square$",
        "raw_answer": "**Solution.**  \nSince $|G| = 2|H|$, Lagrange\u2019s theorem gives the index $[G:H] = |G|/|H| = 2$. Hence there are exactly two left cosets of $H$ in $G$ and exactly two right cosets.\n\nLet $g \\in G$. We consider two cases.\n\n*Case 1:* $g \\in H$.  \nThen $gH = H$ and $Hg = H$, so $gH = Hg$.\n\n*Case 2:* $g \\notin H$.  \nBecause there are only two left cosets, they must be $H$ and $gH$ (the coset $gH$ is distinct from $H$ since $g \\notin H$). These two left cosets partition $G$, so $gH = G \\setminus H$.  \nSimilarly, the two right cosets are $H$ and $Hg$, and they also partition $G$, giving $Hg = G \\setminus H$.  \nThus $gH = G \\setminus H = Hg$.\n\nIn both cases we have $gH = Hg$ for every $g \\in G$, which means $H$ is a normal subgroup of $G$. $\\square$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $F$ be a field and let $p(x) = x^3 + ax + b \\in F[x]$ be a cubic polynomial with distinct roots in some extension field of $F$. Suppose that the discriminant of $p(x)$ is a square in $F$. Prove that the Galois group of $p(x)$ over $F$ is isomorphic to $\\mathbb{Z}/3\\mathbb{Z}$ if and only if $p(x)$ is irreducible over $F$.",
    "run_id": "6",
    "topic_slug": "field_theory_and_polynomials",
    "ill_posed_claim": {
      "verdict": "fail",
      "ill_posed": true,
      "issues": [
        "The irreducibility proof is invalid: treating u and v as constants when equating coefficients of 1, s, t is incorrect because u and v themselves depend on s and t.",
        "The argument that the Galois group is S3 is insufficiently justified: the Artin\u2013Schreier condition is not verified, and the claim that it fails because s and t are independent transcendentals is handwavy."
      ],
      "improvements": "Provide a correct irreducibility proof: assume a root exists in F2[s,t] (by Gauss's lemma), then write A \u2208 F2[s,t] satisfying A^3 + sA = t. View A as a polynomial in t with coefficients in F2[s]; compare degrees to obtain a contradiction. For the Galois group, show that the quadratic x^2 + \u03b1x + (\u03b1^2+s) has no solution in F(\u03b1) by deriving a contradiction from the minimal polynomial of \u03b1, or cite known results about the generic cubic in characteristic 2. Alternatively, give a more rigorous treatment of the Artin\u2013Schreier condition using the trace map."
    },
    "status": "ill-posed",
    "attempts": [
      {
        "round": 1,
        "answer": "The question is ill\u2011posed because it omits the necessary restriction on the characteristic of the field $F$.  In characteristic $2$ the statement fails, as shown by the following counterexample.\n\nLet $F = \\mathbb{F}_2(s,t)$ be the field of rational functions in two independent variables over the field with two elements.  Consider  \n$$\np(x) = x^3 + s x + t \\in F[x].\n$$\n\n* **Distinct roots:** The discriminant of $p$ is $\\Delta = -4s^3 -27 t^2$.  In characteristic $2$ we have $4 = 0$ and $27 = 1$, and $-1 = 1$, so $\\Delta = t^2$.  Since $t$ is transcendental, $\\Delta \\neq 0$; hence $p$ has distinct roots.\n* **Discriminant a square:** $\\Delta = t^2 = (t)^2$ is a square in $F$.\n* **Irreducibility:** Suppose $p$ had a root $r = u/v \\in F$ with $u, v \\in \\mathbb{F}_2[s,t]$ coprime.  Substituting gives  \n  $$\n  u^3 + s u v^2 + t v^3 = 0.\n  $$  \n  Treating the left\u2011hand side as a polynomial in $s$ and $t$, the coefficients of $1$, $s$, and $t$ must each vanish.  Thus $u^3 = 0$, $u v^2 = 0$, $v^3 = 0$, forcing $u = v = 0$, a contradiction.  Therefore $p$ is irreducible over $F$.\n* **Galois group:** Let $\\alpha$ be a root of $p$.  The extension $F(\\alpha)/F$ has degree $3$.  The other roots satisfy the quadratic  \n  $$\n  x^2 + \\alpha x + (\\alpha^2 + s) = 0.\n  $$  \n  Over a field of characteristic $2$, this quadratic splits over $F(\\alpha)$ iff the Artin\u2013Schreier equation  \n  $$\n  y^2 + y = 1 + \\frac{s}{\\alpha^2}\n  $$  \n  has a solution in $F(\\alpha)$.  Because $s$ and $t$ are independent transcendentals, this condition does **not** hold; consequently the quadratic remains irreducible over $F(\\alpha)$.  Hence the splitting field of $p$ has degree $6$, and the Galois group, being a transitive subgroup of $S_3$ of order $6$, is $S_3$, not $\\mathbb{Z}/3\\mathbb{Z}$.\n\nThus we have an irreducible cubic over $F$ satisfying the hypothesis (discriminant a square) whose Galois group is not $\\mathbb{Z}/3\\mathbb{Z}$, contradicting the claimed equivalence.\n\nThe underlying reason is that the standard step \u201cdiscriminant a square $\\Rightarrow$ Galois group $\\subseteq A_3$\u201d requires that $-1 \\neq 1$ in the field, i.e., $\\operatorname{char} F \\neq 2$.  In characteristic $2$ the sign of every permutation is $1$, so the discriminant condition imposes no restriction on the Galois group.\n\nTherefore the question is ill\u2011posed due to a missing constraint: it should explicitly assume $\\operatorname{char} F \\neq 2$ (or restrict to fields of characteristic different from $2$).  Without this assumption the statement is false, as demonstrated above.",
        "raw_answer": "The question is ill\u2011posed because it omits the necessary restriction on the characteristic of the field \\(F\\).  In characteristic \\(2\\) the statement fails, as shown by the following counterexample.\n\nLet \\(F = \\mathbb{F}_2(s,t)\\) be the field of rational functions in two independent variables over the field with two elements.  Consider  \n\\[\np(x) = x^3 + s x + t \\in F[x].\n\\]\n\n* **Distinct roots:** The discriminant of \\(p\\) is \\(\\Delta = -4s^3 -27 t^2\\).  In characteristic \\(2\\) we have \\(4 = 0\\) and \\(27 = 1\\), and \\(-1 = 1\\), so \\(\\Delta = t^2\\).  Since \\(t\\) is transcendental, \\(\\Delta \\neq 0\\); hence \\(p\\) has distinct roots.\n* **Discriminant a square:** \\(\\Delta = t^2 = (t)^2\\) is a square in \\(F\\).\n* **Irreducibility:** Suppose \\(p\\) had a root \\(r = u/v \\in F\\) with \\(u, v \\in \\mathbb{F}_2[s,t]\\) coprime.  Substituting gives  \n  \\[\n  u^3 + s u v^2 + t v^3 = 0.\n  \\]  \n  Treating the left\u2011hand side as a polynomial in \\(s\\) and \\(t\\), the coefficients of \\(1\\), \\(s\\), and \\(t\\) must each vanish.  Thus \\(u^3 = 0\\), \\(u v^2 = 0\\), \\(v^3 = 0\\), forcing \\(u = v = 0\\), a contradiction.  Therefore \\(p\\) is irreducible over \\(F\\).\n* **Galois group:** Let \\(\\alpha\\) be a root of \\(p\\).  The extension \\(F(\\alpha)/F\\) has degree \\(3\\).  The other roots satisfy the quadratic  \n  \\[\n  x^2 + \\alpha x + (\\alpha^2 + s) = 0.\n  \\]  \n  Over a field of characteristic \\(2\\), this quadratic splits over \\(F(\\alpha)\\) iff the Artin\u2013Schreier equation  \n  \\[\n  y^2 + y = 1 + \\frac{s}{\\alpha^2}\n  \\]  \n  has a solution in \\(F(\\alpha)\\).  Because \\(s\\) and \\(t\\) are independent transcendentals, this condition does **not** hold; consequently the quadratic remains irreducible over \\(F(\\alpha)\\).  Hence the splitting field of \\(p\\) has degree \\(6\\), and the Galois group, being a transitive subgroup of \\(S_3\\) of order \\(6\\), is \\(S_3\\), not \\(\\mathbb{Z}/3\\mathbb{Z}\\).\n\nThus we have an irreducible cubic over \\(F\\) satisfying the hypothesis (discriminant a square) whose Galois group is not \\(\\mathbb{Z}/3\\mathbb{Z}\\), contradicting the claimed equivalence.\n\nThe underlying reason is that the standard step \u201cdiscriminant a square \\(\\Rightarrow\\) Galois group \\(\\subseteq A_3\\)\u201d requires that \\(-1 \\neq 1\\) in the field, i.e., \\(\\operatorname{char} F \\neq 2\\).  In characteristic \\(2\\) the sign of every permutation is \\(1\\), so the discriminant condition imposes no restriction on the Galois group.\n\nTherefore the question is ill\u2011posed due to a missing constraint: it should explicitly assume \\(\\operatorname{char} F \\neq 2\\) (or restrict to fields of characteristic different from \\(2\\)).  Without this assumption the statement is false, as demonstrated above.",
        "evaluation": {
          "verdict": "fail",
          "ill_posed": true,
          "issues": [
            "The irreducibility proof is invalid: treating u and v as constants when equating coefficients of 1, s, t is incorrect because u and v themselves depend on s and t.",
            "The argument that the Galois group is S3 is insufficiently justified: the Artin\u2013Schreier condition is not verified, and the claim that it fails because s and t are independent transcendentals is handwavy."
          ],
          "improvements": "Provide a correct irreducibility proof: assume a root exists in F2[s,t] (by Gauss's lemma), then write A \u2208 F2[s,t] satisfying A^3 + sA = t. View A as a polynomial in t with coefficients in F2[s]; compare degrees to obtain a contradiction. For the Galois group, show that the quadratic x^2 + \u03b1x + (\u03b1^2+s) has no solution in F(\u03b1) by deriving a contradiction from the minimal polynomial of \u03b1, or cite known results about the generic cubic in characteristic 2. Alternatively, give a more rigorous treatment of the Artin\u2013Schreier condition using the trace map."
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of commutative algebra, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic in commutative algebra\nCommutative algebra involves the study of commutative rings and their ideals, modules, and algebras. A challenging problem could involve understanding the properties of ideals, quotient rings, or the behavior of polynomials over certain rings.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the properties of ideals in a polynomial ring. Specifically, we can examine the ideal generated by a set of polynomials and ask questions about its properties, such as whether it is prime or maximal.\n\n## Step 4: Construct the problem\nConsider the polynomial ring $\\mathbb{Q}[x, y]$ and the ideal $I = (x^2 + y^2, xy)$. We can ask: Is the ideal $I$ prime? To make it more challenging and ensure it's well-posed, we can ask to determine whether $I$ is radical, i.e., whether it is equal to its radical $\\sqrt{I}$.\n\n## Step 5: Write down the problem statement\nLet $I = (x^2 + y^2, xy)$ be an ideal in $\\mathbb{Q}[x, y]$. Determine whether $I = \\sqrt{I}$, where $\\sqrt{I} = \\{f \\in \\mathbb{Q}[x, y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N}\\}$.\n\n## Step 6: Provide the solution\nTo determine if $I = \\sqrt{I}$, we first need to understand what $\\sqrt{I}$ is. An element $f \\in \\mathbb{Q}[x, y]$ is in $\\sqrt{I}$ if $f^n \\in I$ for some $n$. We need to check if there are elements in $\\sqrt{I}$ that are not in $I$.\n\n## Step 7: Analyze the ideal $I$\nTo check if $I = \\sqrt{I}$, let's first examine the quotient ring $\\mathbb{Q}[x, y]/I$. The ideal $I$ contains $x^2 + y^2$ and $xy$, which implies that $x^2 + y^2$ and $xy$ are zero in $\\mathbb{Q}[x, y]/I$. We can simplify this by observing that $x^2y + y^3 = 0$ and $x^2y = 0$ in $\\mathbb{Q}[x, y]/I$, implying $y^3 = 0$ in $\\mathbb{Q}[x, y]/I$. Similarly, $x^3 = 0$.\n\n## Step 8: Check if $I$ is radical\nSince $x^3 = 0$ and $y^3 = 0$ in $\\mathbb{Q}[x, y]/I$, it follows that $x, y \\in \\sqrt{I}$ because $x^3, y^3 \\in I$. We need to verify if $x$ and $y$ are in $I$. If not, then $I \\neq \\sqrt{I}$.\n\n## Step 9: Verify if $x$ and $y$ are in $I$\nTo check if $x \\in I$, we need to see if there exist $f, g \\in \\mathbb{Q}[x, y]$ such that $x = f(x^2 + y^2) + g(xy)$. This simplifies to checking if $x$ can be expressed as a combination of $x^2 + y^2$ and $xy$, which is not possible because any element in $I$ is of degree at least 2.\n\n## Step 10: Conclude on $I = \\sqrt{I}$\nSince $x, y \\in \\sqrt{I}$ but $x, y \\notin I$, it follows that $I \\neq \\sqrt{I}$. Thus, $I$ is not radical.\n\nThe final answer is: \n\nLet $I = (x^2 + y^2, xy)$ be an ideal in $\\mathbb{Q}[x, y]$. Determine whether $I = \\sqrt{I}$, where $\\sqrt{I} = \\{f \\in \\mathbb{Q}[x, y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N}\\}$.",
    "run_id": "7",
    "topic_slug": "commutative_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We need to determine whether the ideal $I = (x^2 + y^2, xy)$ in $\\mathbb{Q}[x, y]$ equals its radical $\\sqrt{I} = \\{ f \\in \\mathbb{Q}[x, y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N} \\}$.\n\n**Claim:** $I \\neq \\sqrt{I}$; the ideal is not radical.\n\n**Proof.**  \nWe show that $x \\in \\sqrt{I}$ but $x \\notin I$.\n\n---\n\n### 1. $x \\notin I$\n\nThe generators $f = x^2 + y^2$ and $g = xy$ are homogeneous polynomials of degree $2$. Hence $I$ is a homogeneous ideal. In a homogeneous ideal, every polynomial can be written as a sum of its homogeneous components, each of which also belongs to the ideal.\n\nSuppose, for contradiction, that $x \\in I$. Then its homogeneous component of degree $1$ (namely $x$ itself) would lie in $I$. However, any element of $I$ is of the form $A f + B g$ with $A, B \\in \\mathbb{Q}[x, y]$. Because $f$ and $g$ have degree $2$, the lowest possible total degree of a nonzero term in $A f + B g$ is at least $2$:  \n- If $A$ has a nonzero constant term $c$, then $c f$ contributes terms of degree $2$.  \n- If $A$ has no constant term, then every term in $A$ has degree $\\ge 1$, so $A f$ has degree $\\ge 3$. The same holds for $B g$.\n\nThus $I$ contains no nonzero polynomial of total degree $1$. Since $x$ is a nonzero polynomial of degree $1$, it cannot belong to $I$. Therefore $x \\notin I$.\n\n---\n\n### 2. $x \\in \\sqrt{I}$\n\nWe exhibit a positive integer $n$ such that $x^n \\in I$. Compute:\n\n$$\nx^3 = x \\cdot x^2 = x \\cdot (x^2 + y^2) - x y^2.\n$$\n\nNow:\n- $x (x^2 + y^2) \\in I$ because $x^2 + y^2 \\in I$ and $I$ is an ideal.\n- $x y^2 = (x y) \\cdot y$. Since $xy \\in I$, multiplying by $y$ gives $(xy) y = x y^2 \\in I$.\n\nHence $x^3 = x (x^2 + y^2) - (xy) y$ is a difference of two elements of $I$, so $x^3 \\in I$. By definition of the radical, $x \\in \\sqrt{I}$.\n\n(Similarly, one can show $y^3 \\in I$, so $y \\in \\sqrt{I}$ as well.)\n\n---\n\n### 3. Conclusion\n\nWe have found an element $x$ that belongs to $\\sqrt{I}$ but not to $I$. Consequently, $I \\subsetneq \\sqrt{I}$; in particular, $I$ is not equal to its radical.\n\nThus the answer to the question is: **No, $I \\neq \\sqrt{I}$.**",
        "raw_answer": "We need to determine whether the ideal \\(I = (x^2 + y^2, xy)\\) in \\(\\mathbb{Q}[x, y]\\) equals its radical \\(\\sqrt{I} = \\{ f \\in \\mathbb{Q}[x, y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N} \\}\\).\n\n**Claim:** \\(I \\neq \\sqrt{I}\\); the ideal is not radical.\n\n**Proof.**  \nWe show that \\(x \\in \\sqrt{I}\\) but \\(x \\notin I\\).\n\n---\n\n### 1. \\(x \\notin I\\)\n\nThe generators \\(f = x^2 + y^2\\) and \\(g = xy\\) are homogeneous polynomials of degree \\(2\\). Hence \\(I\\) is a homogeneous ideal. In a homogeneous ideal, every polynomial can be written as a sum of its homogeneous components, each of which also belongs to the ideal.\n\nSuppose, for contradiction, that \\(x \\in I\\). Then its homogeneous component of degree \\(1\\) (namely \\(x\\) itself) would lie in \\(I\\). However, any element of \\(I\\) is of the form \\(A f + B g\\) with \\(A, B \\in \\mathbb{Q}[x, y]\\). Because \\(f\\) and \\(g\\) have degree \\(2\\), the lowest possible total degree of a nonzero term in \\(A f + B g\\) is at least \\(2\\):  \n- If \\(A\\) has a nonzero constant term \\(c\\), then \\(c f\\) contributes terms of degree \\(2\\).  \n- If \\(A\\) has no constant term, then every term in \\(A\\) has degree \\(\\ge 1\\), so \\(A f\\) has degree \\(\\ge 3\\). The same holds for \\(B g\\).\n\nThus \\(I\\) contains no nonzero polynomial of total degree \\(1\\). Since \\(x\\) is a nonzero polynomial of degree \\(1\\), it cannot belong to \\(I\\). Therefore \\(x \\notin I\\).\n\n---\n\n### 2. \\(x \\in \\sqrt{I}\\)\n\nWe exhibit a positive integer \\(n\\) such that \\(x^n \\in I\\). Compute:\n\n\\[\nx^3 = x \\cdot x^2 = x \\cdot (x^2 + y^2) - x y^2.\n\\]\n\nNow:\n- \\(x (x^2 + y^2) \\in I\\) because \\(x^2 + y^2 \\in I\\) and \\(I\\) is an ideal.\n- \\(x y^2 = (x y) \\cdot y\\). Since \\(xy \\in I\\), multiplying by \\(y\\) gives \\((xy) y = x y^2 \\in I\\).\n\nHence \\(x^3 = x (x^2 + y^2) - (xy) y\\) is a difference of two elements of \\(I\\), so \\(x^3 \\in I\\). By definition of the radical, \\(x \\in \\sqrt{I}\\).\n\n(Similarly, one can show \\(y^3 \\in I\\), so \\(y \\in \\sqrt{I}\\) as well.)\n\n---\n\n### 3. Conclusion\n\nWe have found an element \\(x\\) that belongs to \\(\\sqrt{I}\\) but not to \\(I\\). Consequently, \\(I \\subsetneq \\sqrt{I}\\); in particular, \\(I\\) is not equal to its radical.\n\nThus the answer to the question is: **No, \\(I \\neq \\sqrt{I}\\).**",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of algebraic geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within algebraic geometry\nAlgebraic geometry is a broad field that involves the study of geometric objects, such as varieties and schemes, using tools from abstract algebra. A suitable topic could involve the study of curves, surfaces, or higher-dimensional varieties, and their properties.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the intersection of curves on a surface. A classic result in algebraic geometry is B\u00e9zout's theorem, which describes the intersection of two curves on a projective plane. We can formulate a problem related to this.\n\n## Step 4: State the problem\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.\n\n## Step 5: Provide the solution\nTo find the intersection points, we need to solve the system of equations given by $f(x,y,z) = 0$ and $g(x,y,z) = 0$. This means we have to solve $x^2 + y^2 - z^2 = 0$ and $xy - z^2 = 0$ simultaneously.\n\n## Step 6: Solve the system of equations\nFirst, from $xy - z^2 = 0$, we can express $z^2 = xy$. Substituting $z^2$ into the first equation gives $x^2 + y^2 - xy = 0$. This is a homogeneous equation in $x$ and $y$, which can be solved by considering it as a quadratic form.\n\n## Step 7: Analyze the quadratic form\nThe equation $x^2 - xy + y^2 = 0$ can be analyzed by finding its roots. This is equivalent to solving $x^2 - xy + y^2 = 0$ for $x$ in terms of $y$ (or vice versa), treating it as a quadratic equation.\n\n## Step 8: Solve for $x$ in terms of $y$\nUsing the quadratic formula, $x = \\frac{y \\pm \\sqrt{y^2 - 4y^2}}{2} = \\frac{y \\pm \\sqrt{-3y^2}}{2}$. For $y \\neq 0$, this simplifies to $x = \\frac{y(1 \\pm i\\sqrt{3})}{2}$. Thus, $x = y\\omega$ or $x = y\\omega^2$, where $\\omega$ is a primitive third root of unity.\n\n## Step 9: Determine the intersection points\nFor $x = y\\omega$ and $x = y\\omega^2$, substituting back into $xy = z^2$ gives $y^2\\omega = z^2$ and $y^2\\omega^2 = z^2$, respectively. This implies $z = \\pm y\\sqrt{\\omega}$ and $z = \\pm y\\sqrt{\\omega^2}$. However, we must consider the projective nature and the fact that we're working with homogeneous coordinates.\n\n## Step 10: Count the intersection points with multiplicity\nSince $\\omega$ and $\\omega^2$ are not real, and we're working over $\\mathbb{C}$, we need to consider the solutions in $\\mathbb{P}^2(\\mathbb{C})$. The solutions are given by the pairs $(x:y:z)$ satisfying both equations. We need to check if there are any solutions where $y = 0$, which would imply $x = 0$ and thus $z = 0$, but $(0,0,0)$ is not a valid point in $\\mathbb{P}^2$.\n\n## Step 11: Apply B\u00e9zout's theorem for a simpler solution\nB\u00e9zout's theorem states that two curves of degrees $d_1$ and $d_2$ intersect in $d_1d_2$ points, counted with multiplicity, if they have no common components. Here, $C_1$ and $C_2$ are both of degree 2, so they should intersect in $2 \\times 2 = 4$ points.\n\nThe final answer is: \n\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.",
    "run_id": "8",
    "topic_slug": "algebraic_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution.**\n\nWe work over the complex numbers $\\mathbb{C}$ (or any algebraically closed field) to apply B\u00e9zout's theorem and capture all intersection points. The curves are in the projective plane $\\mathbb{P}^2$.\n\n---\n\n### 1. Degrees and common components\n\n$C_1$ is defined by the homogeneous polynomial $f(x,y,z)=x^2+y^2-z^2$ of degree $2$.  \n$C_2$ is defined by $g(x,y,z)=xy-z^2$, also of degree $2$.  \n\nBoth polynomials are irreducible (they are non\u2011degenerate quadratic forms) and are not scalar multiples of each other. Hence $C_1$ and $C_2$ share no common component.\n\n---\n\n### 2. B\u00e9zout\u2019s theorem\n\nFor two projective plane curves with no common component, the total intersection number \u2013 the sum of intersection multiplicities at all points \u2013 equals the product of their degrees. Therefore\n\n$$\n\\sum_{P\\in C_1\\cap C_2} I(P, C_1\\cap C_2) = 2\\cdot 2 = 4.\n$$\n\n---\n\n### 3. Explicit intersection points\n\nWe solve the system\n\n$$\n\\begin{cases}\nx^2 + y^2 - z^2 = 0,\\$$2mm]\nxy - z^2 = 0.\n\\end{cases}\n$$\n\nFrom the second equation, $z^2 = xy$. Substituting into the first gives\n\n$$\nx^2 + y^2 - xy = 0 \\quad\\Longrightarrow\\quad x^2 - xy + y^2 = 0. \\tag{1}\n$$\n\nEquation (1) is homogeneous.  \n\n*If $y = 0$*, then (1) forces $x = 0$, and then $z^2 = 0$ from the second equation, yielding $(0,0,0)$ which is not a point in $\\mathbb{P}^2$. Hence $y \\neq 0$. Similarly, $x = 0$ would imply $y = 0$, so $x \\neq 0$ as well.  \n\nBecause $y \\neq 0$, we may scale the homogeneous coordinates so that $y = 1$. Then (1) becomes\n\n$$\nx^2 - x + 1 = 0.\n$$\n\nIts solutions are\n\n$$\nx = \\frac{1 \\pm i\\sqrt{3}}{2}.\n$$\n\nSet $\\zeta = \\frac{1 + i\\sqrt{3}}{2} = e^{i\\pi/3}$; then the other root is $\\zeta^{-1} = \\frac{1 - i\\sqrt{3}}{2} = e^{-i\\pi/3}$.\n\nFor each value of $x$ we have $z^2 = xy = x$ (since $y=1$). Thus $z$ is a square root of $x$. Because $x \\neq 0$, there are two distinct square roots for each $x$, differing by a sign. This yields four points in $\\mathbb{P}^2$ (with the representative $y=1$):\n\n$$\n\\begin{aligned}\nP_1 &= (\\zeta,\\; 1,\\; \\sqrt{\\zeta}), &\nP_2 &= (\\zeta,\\; 1,\\; -\\sqrt{\\zeta}), \\$$1mm]\nP_3 &= (\\zeta^{-1},\\; 1,\\; \\sqrt{\\zeta^{-1}}), &\nP_4 &= (\\zeta^{-1},\\; 1,\\; -\\sqrt{\\zeta^{-1}}),\n\\end{aligned}\n$$\n\nwhere $\\sqrt{\\zeta}$ denotes a fixed choice of square root; the opposite sign gives the other point.\n\nThese four points are distinct:\n- The ratios $x:y$ are $\\zeta$ for $P_1,P_2$ and $\\zeta^{-1}$ for $P_3,P_4$, and $\\zeta \\neq \\zeta^{-1}$ because $\\zeta \\neq \\pm 1$.\n- For a fixed ratio, the two points differ only in the sign of the $z$-coordinate. No non\u2011zero scalar $\\lambda$ can identify them because that would require $\\lambda = 1$ from the first two coordinates and then force $z = -z$, i.e., $z=0$, which is impossible since $z^2 = \\zeta \\neq 0$.\n\nHence $C_1 \\cap C_2$ consists of exactly four distinct points.\n\n---\n\n### 4. Intersection multiplicities\n\nBecause we have found four distinct intersection points and B\u00e9zout\u2019s theorem guarantees that the sum of multiplicities is $4$, each intersection multiplicity must be exactly $1$. (One may also verify transversality directly: both curves are smooth at these points, and their gradient vectors $\\nabla f = (2x,2y,-2z)$ and $\\nabla g = (y,x,-2z)$ are linearly independent at each point, so the intersection is transverse.)\n\n---\n\n### 5. Conclusion\n\nThe number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity, is\n\n$$\n\\boxed{4}.\n$$",
        "raw_answer": "**Solution.**\n\nWe work over the complex numbers \\(\\mathbb{C}\\) (or any algebraically closed field) to apply B\u00e9zout's theorem and capture all intersection points. The curves are in the projective plane \\(\\mathbb{P}^2\\).\n\n---\n\n### 1. Degrees and common components\n\n\\(C_1\\) is defined by the homogeneous polynomial \\(f(x,y,z)=x^2+y^2-z^2\\) of degree \\(2\\).  \n\\(C_2\\) is defined by \\(g(x,y,z)=xy-z^2\\), also of degree \\(2\\).  \n\nBoth polynomials are irreducible (they are non\u2011degenerate quadratic forms) and are not scalar multiples of each other. Hence \\(C_1\\) and \\(C_2\\) share no common component.\n\n---\n\n### 2. B\u00e9zout\u2019s theorem\n\nFor two projective plane curves with no common component, the total intersection number \u2013 the sum of intersection multiplicities at all points \u2013 equals the product of their degrees. Therefore\n\n\\[\n\\sum_{P\\in C_1\\cap C_2} I(P, C_1\\cap C_2) = 2\\cdot 2 = 4.\n\\]\n\n---\n\n### 3. Explicit intersection points\n\nWe solve the system\n\n\\[\n\\begin{cases}\nx^2 + y^2 - z^2 = 0,\\\\[2mm]\nxy - z^2 = 0.\n\\end{cases}\n\\]\n\nFrom the second equation, \\(z^2 = xy\\). Substituting into the first gives\n\n\\[\nx^2 + y^2 - xy = 0 \\quad\\Longrightarrow\\quad x^2 - xy + y^2 = 0. \\tag{1}\n\\]\n\nEquation (1) is homogeneous.  \n\n*If \\(y = 0\\)*, then (1) forces \\(x = 0\\), and then \\(z^2 = 0\\) from the second equation, yielding \\((0,0,0)\\) which is not a point in \\(\\mathbb{P}^2\\). Hence \\(y \\neq 0\\). Similarly, \\(x = 0\\) would imply \\(y = 0\\), so \\(x \\neq 0\\) as well.  \n\nBecause \\(y \\neq 0\\), we may scale the homogeneous coordinates so that \\(y = 1\\). Then (1) becomes\n\n\\[\nx^2 - x + 1 = 0.\n\\]\n\nIts solutions are\n\n\\[\nx = \\frac{1 \\pm i\\sqrt{3}}{2}.\n\\]\n\nSet \\(\\zeta = \\frac{1 + i\\sqrt{3}}{2} = e^{i\\pi/3}\\); then the other root is \\(\\zeta^{-1} = \\frac{1 - i\\sqrt{3}}{2} = e^{-i\\pi/3}\\).\n\nFor each value of \\(x\\) we have \\(z^2 = xy = x\\) (since \\(y=1\\)). Thus \\(z\\) is a square root of \\(x\\). Because \\(x \\neq 0\\), there are two distinct square roots for each \\(x\\), differing by a sign. This yields four points in \\(\\mathbb{P}^2\\) (with the representative \\(y=1\\)):\n\n\\[\n\\begin{aligned}\nP_1 &= (\\zeta,\\; 1,\\; \\sqrt{\\zeta}), &\nP_2 &= (\\zeta,\\; 1,\\; -\\sqrt{\\zeta}), \\\\[1mm]\nP_3 &= (\\zeta^{-1},\\; 1,\\; \\sqrt{\\zeta^{-1}}), &\nP_4 &= (\\zeta^{-1},\\; 1,\\; -\\sqrt{\\zeta^{-1}}),\n\\end{aligned}\n\\]\n\nwhere \\(\\sqrt{\\zeta}\\) denotes a fixed choice of square root; the opposite sign gives the other point.\n\nThese four points are distinct:\n- The ratios \\(x:y\\) are \\(\\zeta\\) for \\(P_1,P_2\\) and \\(\\zeta^{-1}\\) for \\(P_3,P_4\\), and \\(\\zeta \\neq \\zeta^{-1}\\) because \\(\\zeta \\neq \\pm 1\\).\n- For a fixed ratio, the two points differ only in the sign of the \\(z\\)-coordinate. No non\u2011zero scalar \\(\\lambda\\) can identify them because that would require \\(\\lambda = 1\\) from the first two coordinates and then force \\(z = -z\\), i.e., \\(z=0\\), which is impossible since \\(z^2 = \\zeta \\neq 0\\).\n\nHence \\(C_1 \\cap C_2\\) consists of exactly four distinct points.\n\n---\n\n### 4. Intersection multiplicities\n\nBecause we have found four distinct intersection points and B\u00e9zout\u2019s theorem guarantees that the sum of multiplicities is \\(4\\), each intersection multiplicity must be exactly \\(1\\). (One may also verify transversality directly: both curves are smooth at these points, and their gradient vectors \\(\\nabla f = (2x,2y,-2z)\\) and \\(\\nabla g = (y,x,-2z)\\) are linearly independent at each point, so the intersection is transverse.)\n\n---\n\n### 5. Conclusion\n\nThe number of intersection points of \\(C_1\\) and \\(C_2\\) in \\(\\mathbb{P}^2\\), counted with multiplicity, is\n\n\\[\n\\boxed{4}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Linear and multilinear algebra; matrix theory, along with a complete and verifiable solution.\n\n## Step 2: Identify the key elements of a well-posed problem\nThe problem must be fully self-contained, clear, non-trivial, solvable, and verifiable. It should involve sophisticated techniques from linear and multilinear algebra or matrix theory.\n\n## Step 3: Generate a problem that fits the criteria\nLet's consider a problem that involves matrix theory and requires a good understanding of linear algebra concepts. A potential problem could involve proving a property of matrices or finding a specific matrix that satisfies certain conditions.\n\n## Step 4: Formulate the problem\nConsider the following problem: \"Let $A$ be a $3 \\times 3$ real matrix such that $A^3 = I$, where $I$ is the $3 \\times 3$ identity matrix. Prove that $A$ is diagonalizable over $\\mathbb{C}$.\"\n\n## Step 5: Verify that the problem is well-posed and solvable\nThe problem is well-posed because it specifies the domain of $A$ (real $3 \\times 3$ matrices), gives a clear condition ($A^3 = I$), and asks for a specific proof (that $A$ is diagonalizable over $\\mathbb{C}$). It is solvable using established methods in linear algebra.\n\n## Step 6: Provide a complete solution to the problem\nTo solve this, we note that $A$ satisfies the polynomial $x^3 - 1 = 0$. This polynomial factors as $(x-1)(x^2 + x + 1) = 0$. The roots are $1$, $e^{2\\pi i/3}$, and $e^{4\\pi i/3}$. Since $A$ satisfies this polynomial, its eigenvalues must be among these roots. Because the minimal polynomial of $A$ divides $x^3 - 1$ and has distinct roots (since $x^3 - 1$ has distinct roots), $A$ is diagonalizable over $\\mathbb{C}$.\n\n## Step 7: Write the problem and solution in the required format\n\nLet $A$ be a $3 \\times 3$ real matrix such that $A^3 = I$, where $I$ is the $3 \\times 3$ identity matrix. Prove that $A$ is diagonalizable over $\\mathbb{C}$.",
    "run_id": "9",
    "topic_slug": "linear_and_multilinear_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove that any real $3\\times 3$ matrix $A$ satisfying $A^3 = I$ is diagonalizable over $\\mathbb{C}$.\n\n**Key criterion.** A matrix over an algebraically closed field (such as $\\mathbb{C}$) is diagonalizable if and only if its minimal polynomial splits into distinct linear factors (i.e., has no repeated roots).\n\n**Proof.**  \nRegard $A$ as a complex matrix. Since $A^3 = I$, we have $A^3 - I = 0$, so $A$ satisfies the polynomial  \n$$\np(x) = x^3 - 1 \\in \\mathbb{C}[x].\n$$\n\nLet $m(x) \\in \\mathbb{C}[x]$ be the minimal polynomial of $A$ (over $\\mathbb{C}$). By definition, $m(x)$ is the monic polynomial of least degree with $m(A)=0$. Because $p(A)=0$, the minimal polynomial must divide $p(x)$:  \n$$\nm(x) \\mid p(x).\n$$\n\nOver $\\mathbb{C}$, $p(x)$ factors as  \n$$\np(x) = (x-1)(x-\\omega)(x-\\omega^2),\n$$  \nwhere $\\omega = e^{2\\pi i/3} = -\\frac12 + i\\frac{\\sqrt3}{2}$ and $\\omega^2 = e^{4\\pi i/3} = -\\frac12 - i\\frac{\\sqrt3}{2}$. The three roots $1$, $\\omega$, $\\omega^2$ are distinct.\n\nSince $p(x)$ has no repeated roots, any divisor of $p(x)$ is a product of distinct linear factors. In particular, $m(x)$ is of the form  \n$$\nm(x) = (x-\\lambda_1)(x-\\lambda_2)\\cdots(x-\\lambda_k),\n$$  \nwhere each $\\lambda_i$ is one of $\\{1,\\omega,\\omega^2\\}$ and all $\\lambda_i$ are distinct. Hence $m(x)$ splits completely over $\\mathbb{C}$ and has no repeated roots.\n\nBy the diagonalizability criterion stated above, $A$ is diagonalizable over $\\mathbb{C}$.\n\n**Remark.** The argument does not depend on the size of the matrix; it holds for any square matrix (real or complex) satisfying $A^3 = I$.\n\nThus the proof is complete. \u220e",
        "raw_answer": "We prove that any real $3\\times 3$ matrix $A$ satisfying $A^3 = I$ is diagonalizable over $\\mathbb{C}$.\n\n**Key criterion.** A matrix over an algebraically closed field (such as $\\mathbb{C}$) is diagonalizable if and only if its minimal polynomial splits into distinct linear factors (i.e., has no repeated roots).\n\n**Proof.**  \nRegard $A$ as a complex matrix. Since $A^3 = I$, we have $A^3 - I = 0$, so $A$ satisfies the polynomial  \n\\[\np(x) = x^3 - 1 \\in \\mathbb{C}[x].\n\\]\n\nLet $m(x) \\in \\mathbb{C}[x]$ be the minimal polynomial of $A$ (over $\\mathbb{C}$). By definition, $m(x)$ is the monic polynomial of least degree with $m(A)=0$. Because $p(A)=0$, the minimal polynomial must divide $p(x)$:  \n\\[\nm(x) \\mid p(x).\n\\]\n\nOver $\\mathbb{C}$, $p(x)$ factors as  \n\\[\np(x) = (x-1)(x-\\omega)(x-\\omega^2),\n\\]  \nwhere $\\omega = e^{2\\pi i/3} = -\\frac12 + i\\frac{\\sqrt3}{2}$ and $\\omega^2 = e^{4\\pi i/3} = -\\frac12 - i\\frac{\\sqrt3}{2}$. The three roots $1$, $\\omega$, $\\omega^2$ are distinct.\n\nSince $p(x)$ has no repeated roots, any divisor of $p(x)$ is a product of distinct linear factors. In particular, $m(x)$ is of the form  \n\\[\nm(x) = (x-\\lambda_1)(x-\\lambda_2)\\cdots(x-\\lambda_k),\n\\]  \nwhere each $\\lambda_i$ is one of $\\{1,\\omega,\\omega^2\\}$ and all $\\lambda_i$ are distinct. Hence $m(x)$ splits completely over $\\mathbb{C}$ and has no repeated roots.\n\nBy the diagonalizability criterion stated above, $A$ is diagonalizable over $\\mathbb{C}$.\n\n**Remark.** The argument does not depend on the size of the matrix; it holds for any square matrix (real or complex) satisfying $A^3 = I$.\n\nThus the proof is complete. \u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of associative rings and algebras, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within associative rings and algebras\nAssociative rings and algebras involve the study of algebraic structures with associative multiplication. A suitable topic could involve properties of ideals, quotient rings, or specific types of algebras like matrix algebras.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving the properties of a specific type of associative algebra. For instance, we could explore the characteristics of a matrix algebra over a ring.\n\n## Step 4: Generate a specific problem\nConsider the ring $R = \\mathbb{Z}/4\\mathbb{Z}$ and the matrix algebra $M_2(R)$ of $2 \\times 2$ matrices with entries in $R$. Let's examine the properties of ideals in $M_2(R)$.\n\n## Step 5: Formulate the problem statement\n\"Let $R = \\mathbb{Z}/4\\mathbb{Z}$ and consider the matrix algebra $M_2(R)$. Prove that $M_2(R)$ is not a simple ring, i.e., it has a non-trivial ideal.\"\n\n## Step 6: Provide the solution\nTo solve this, we need to show that there exists a non-trivial ideal in $M_2(R)$. An ideal $I$ in $M_2(R)$ is a subset that is closed under addition and under multiplication by any element of $M_2(R)$ from either side.\n\n## Step 7: Identify a non-trivial ideal\nConsider the set $I$ of matrices in $M_2(R)$ where all entries are even (i.e., $0$ or $2$ mod $4$). This set is non-empty and not equal to $M_2(R)$ because it does not contain matrices with odd entries.\n\n## Step 8: Verify that $I$ is an ideal\nFor $I$ to be an ideal, it must be closed under addition and under multiplication by elements of $M_2(R)$. For any two matrices $A, B \\in I$, $A + B$ has even entries because the sum of even numbers is even, so $A + B \\in I$. For any $A \\in I$ and $C \\in M_2(R)$, the product $CA$ and $AC$ will have entries that are products and sums of products involving elements of $R$. Since $A$ has even entries, $CA$ and $AC$ will also have even entries because multiplying any element of $R$ by an even element results in an even element.\n\n## Step 9: Check if $I$ is non-trivial\n$I$ is non-trivial if it is not the zero ideal and not the entire ring $M_2(R)$. The zero matrix is in $I$, and there are non-zero matrices in $I$ (e.g., $\\begin{pmatrix} 2 & 0 \\\\ 0 & 0 \\end{pmatrix}$), so $I$ is not the zero ideal. $I$ is not $M_2(R)$ because, for example, $\\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\notin I$.\n\n## Step 10: Conclude the solution\nSince $I$ is a non-trivial ideal, $M_2(R)$ is not a simple ring.\n\nThe final answer is: \n\nLet $R = \\mathbb{Z}/4\\mathbb{Z}$ and consider the matrix algebra $M_2(R)$. Prove that $M_2(R)$ is not a simple ring, i.e., it has a non-trivial ideal.",
    "run_id": "10",
    "topic_slug": "associative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove that the matrix ring $M_2(\\mathbb{Z}/4\\mathbb{Z})$ is not simple by exhibiting a proper non\u2011zero two\u2011sided ideal.\n\nLet $R = \\mathbb{Z}/4\\mathbb{Z}$. The subset $J = 2R = \\{0,2\\}$ is an ideal of $R$: it is closed under addition ($0+0=0,\\;0+2=2,\\;2+2=0$) and for any $r \\in R$, $r\\cdot 2 \\in \\{0,2\\}$ because $2\\cdot0=0,\\;2\\cdot1=2,\\;2\\cdot2=0,\\;2\\cdot3=2$ modulo $4$.\n\nDefine  \n$$\nI = \\left\\{\n\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\in M_2(R) \\;\\Big|\\; a,b,c,d \\in J\n\\right\\}.\n$$\n\n**1. $I$ is an additive subgroup.**  \nIf $A,B \\in I$, each entry of $A+B$ is a sum of two elements of $J$, hence lies in $J$. The zero matrix belongs to $I$. For $A \\in I$, its additive inverse $-A$ has entries $-a$; since $-1 \\in R$ and $J$ is an ideal, $-a = (-1)\\cdot a \\in J$. Thus $-A \\in I$.\n\n**2. $I$ is a two\u2011sided ideal.**  \nTake any $A = (a_{ij}) \\in I$ (so $a_{ij} \\in J$) and any $X = (x_{ij}) \\in M_2(R)$.  \n\n- The $(i,j)$ entry of $XA$ is $\\sum_{k=1}^2 x_{ik} a_{kj}$. Because each $a_{kj} \\in J$ and $x_{ik} \\in R$, the product $x_{ik}a_{kj}$ belongs to $J$ (as $J$ is an ideal). A finite sum of elements of $J$ stays in $J$, so every entry of $XA$ lies in $J$. Hence $XA \\in I$.  \n- Similarly, the $(i,j)$ entry of $AX$ is $\\sum_{k=1}^2 a_{ik} x_{kj}$. Since $a_{ik} \\in J$ and $x_{kj} \\in R$, each term $a_{ik}x_{kj} \\in J$, and the sum is in $J$. Thus $AX \\in I$.\n\n**3. $I$ is non\u2011trivial.**  \nThe matrix $\\begin{pmatrix} 2 & 0 \\\\ 0 & 0 \\end{pmatrix}$ belongs to $I$ and is non\u2011zero, so $I \\neq \\{0\\}$. The identity matrix $\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$ does **not** belong to $I$ because its entries are $1 \\notin J$. Hence $I \\neq M_2(R)$.\n\nTherefore $I$ is a proper non\u2011zero two\u2011sided ideal of $M_2(R)$, and consequently $M_2(\\mathbb{Z}/4\\mathbb{Z})$ is not a simple ring. \u220e",
        "raw_answer": "We prove that the matrix ring \\(M_2(\\mathbb{Z}/4\\mathbb{Z})\\) is not simple by exhibiting a proper non\u2011zero two\u2011sided ideal.\n\nLet \\(R = \\mathbb{Z}/4\\mathbb{Z}\\). The subset \\(J = 2R = \\{0,2\\}\\) is an ideal of \\(R\\): it is closed under addition (\\(0+0=0,\\;0+2=2,\\;2+2=0\\)) and for any \\(r \\in R\\), \\(r\\cdot 2 \\in \\{0,2\\}\\) because \\(2\\cdot0=0,\\;2\\cdot1=2,\\;2\\cdot2=0,\\;2\\cdot3=2\\) modulo \\(4\\).\n\nDefine  \n\\[\nI = \\left\\{\n\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\in M_2(R) \\;\\Big|\\; a,b,c,d \\in J\n\\right\\}.\n\\]\n\n**1. \\(I\\) is an additive subgroup.**  \nIf \\(A,B \\in I\\), each entry of \\(A+B\\) is a sum of two elements of \\(J\\), hence lies in \\(J\\). The zero matrix belongs to \\(I\\). For \\(A \\in I\\), its additive inverse \\(-A\\) has entries \\(-a\\); since \\(-1 \\in R\\) and \\(J\\) is an ideal, \\(-a = (-1)\\cdot a \\in J\\). Thus \\(-A \\in I\\).\n\n**2. \\(I\\) is a two\u2011sided ideal.**  \nTake any \\(A = (a_{ij}) \\in I\\) (so \\(a_{ij} \\in J\\)) and any \\(X = (x_{ij}) \\in M_2(R)\\).  \n\n- The \\((i,j)\\) entry of \\(XA\\) is \\(\\sum_{k=1}^2 x_{ik} a_{kj}\\). Because each \\(a_{kj} \\in J\\) and \\(x_{ik} \\in R\\), the product \\(x_{ik}a_{kj}\\) belongs to \\(J\\) (as \\(J\\) is an ideal). A finite sum of elements of \\(J\\) stays in \\(J\\), so every entry of \\(XA\\) lies in \\(J\\). Hence \\(XA \\in I\\).  \n- Similarly, the \\((i,j)\\) entry of \\(AX\\) is \\(\\sum_{k=1}^2 a_{ik} x_{kj}\\). Since \\(a_{ik} \\in J\\) and \\(x_{kj} \\in R\\), each term \\(a_{ik}x_{kj} \\in J\\), and the sum is in \\(J\\). Thus \\(AX \\in I\\).\n\n**3. \\(I\\) is non\u2011trivial.**  \nThe matrix \\(\\begin{pmatrix} 2 & 0 \\\\ 0 & 0 \\end{pmatrix}\\) belongs to \\(I\\) and is non\u2011zero, so \\(I \\neq \\{0\\}\\). The identity matrix \\(\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\) does **not** belong to \\(I\\) because its entries are \\(1 \\notin J\\). Hence \\(I \\neq M_2(R)\\).\n\nTherefore \\(I\\) is a proper non\u2011zero two\u2011sided ideal of \\(M_2(R)\\), and consequently \\(M_2(\\mathbb{Z}/4\\mathbb{Z})\\) is not a simple ring. \u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of nonassociative rings and algebras, along with a complete and verifiable solution. Nonassociative rings and algebras are mathematical structures where the multiplication operation is not necessarily associative.\n\n## Step 2: Identify a specific area within nonassociative rings and algebras\nA key area within nonassociative rings and algebras is the study of Lie algebras, which are crucial in various branches of mathematics and physics, particularly in the study of symmetries and conservation laws.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving Lie algebras. A Lie algebra is a vector space $\\mathfrak{g}$ over a field $\\mathbb{F}$, together with a binary operation $[\\cdot, \\cdot]: \\mathfrak{g} \\times \\mathfrak{g} \\to \\mathfrak{g}$, called the Lie bracket, that satisfies bilinearity, skew-symmetry, and the Jacobi identity.\n\n## Step 4: Specify the problem\nConsider the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$, which consists of $2 \\times 2$ real matrices with trace zero. The Lie bracket is defined as $[A, B] = AB - BA$. Let $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$. Show that $H, X, Y$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and determine the structure constants with respect to this basis.\n\n## Step 5: Provide the problem statement in the required format\n\nLet $\\mathfrak{sl}(2, \\mathbb{R})$ be the Lie algebra of $2 \\times 2$ real matrices with trace zero, with the Lie bracket $[A, B] = AB - BA$. Show that the matrices $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and compute the structure constants with respect to this basis.",
    "run_id": "11",
    "topic_slug": "nonassociative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe work in the Lie algebra $\\mathfrak{sl}(2,\\mathbb{R}) = \\{ A \\in M_{2}(\\mathbb{R}) \\mid \\operatorname{tr}(A) = 0 \\}$ with the Lie bracket $[A,B] = AB - BA$.\n\n---\n\n### 1. Membership\n\nCompute traces:\n\n$$\n\\operatorname{tr}(H) = 1 + (-1) = 0,\\qquad\n\\operatorname{tr}(X) = 0 + 0 = 0,\\qquad\n\\operatorname{tr}(Y) = 0 + 0 = 0.\n$$\n\nThus $H, X, Y \\in \\mathfrak{sl}(2,\\mathbb{R})$.\n\n---\n\n### 2. Linear independence\n\nAssume $a H + b X + c Y = 0$ for some $a,b,c \\in \\mathbb{R}$. Then\n\n$$\na\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} + b\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} + c\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\n= \\begin{pmatrix}a & b \\\\ c & -a\\end{pmatrix}\n= \\begin{pmatrix}0&0\\\\0&0\\end{pmatrix},\n$$\n\nwhich forces $a = b = c = 0$. Hence $H, X, Y$ are linearly independent.\n\n---\n\n### 3. Spanning\n\nLet $A \\in \\mathfrak{sl}(2,\\mathbb{R})$ be arbitrary. Write $A = \\begin{pmatrix} p & q \\\\ r & s \\end{pmatrix}$ with $\\operatorname{tr}(A) = p + s = 0$, so $s = -p$. Then\n\n$$\nA = \\begin{pmatrix} p & q \\\\ r & -p \\end{pmatrix}\n= p\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} + q\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} + r\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\n= p H + q X + r Y.\n$$\n\nThus every element of $\\mathfrak{sl}(2,\\mathbb{R})$ is a linear combination of $H, X, Y$. Consequently, $\\{H, X, Y\\}$ is a basis.\n\n*(Alternatively, $\\dim \\mathfrak{sl}(2,\\mathbb{R}) = 3$ and three linearly independent vectors automatically form a basis.)*\n\n---\n\n### 4. Lie brackets\n\nCompute the commutators explicitly.\n\n- $[H, X] = HX - XH$\n\n$$\nHX = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = X,\n$$\n$$\nXH = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix}\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = \\begin{pmatrix}0&-1\\\\0&0\\end{pmatrix} = -X,\n$$\n$$\n\\Rightarrow [H,X] = X - (-X) = 2X.\n$$\n\n- $[H, Y] = HY - YH$\n\n$$\nHY = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = \\begin{pmatrix}0&0\\\\-1&0\\end{pmatrix} = -Y,\n$$\n$$\nYH = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = Y,\n$$\n$$\n\\Rightarrow [H,Y] = -Y - Y = -2Y.\n$$\n\n- $[X, Y] = XY - YX$\n\n$$\nXY = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix}\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = \\begin{pmatrix}1&0\\\\0&0\\end{pmatrix},\n$$\n$$\nYX = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = \\begin{pmatrix}0&0\\\\0&1\\end{pmatrix},\n$$\n$$\n\\Rightarrow [X,Y] = \\begin{pmatrix}1&0\\\\0&0\\end{pmatrix} - \\begin{pmatrix}0&0\\\\0&1\\end{pmatrix} = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = H.\n$$\n\nThe remaining brackets follow from skew\u2011symmetry:\n\n$$\n[X,H] = -[H,X] = -2X,\\qquad\n[Y,H] = -[H,Y] = 2Y,\\qquad\n[Y,X] = -[X,Y] = -H.\n$$\n\n---\n\n### 5. Structure constants\n\nOrder the basis as $e_1 = H$, $e_2 = X$, $e_3 = Y$. The structure constants $c_{ij}^k$ are defined by\n\n$$\n[e_i, e_j] = \\sum_{k=1}^{3} c_{ij}^k e_k.\n$$\n\nFrom the computed brackets we obtain the non\u2011zero constants:\n\n$$\n\\begin{aligned}\n[e_1, e_2] &= 2 e_2 \\quad &\\Rightarrow\\quad c_{12}^2 = 2,\\\\\n[e_1, e_3] &= -2 e_3 \\quad &\\Rightarrow\\quad c_{13}^3 = -2,\\\\\n[e_2, e_3] &= e_1 \\quad &\\Rightarrow\\quad c_{23}^1 = 1.\n\\end{aligned}\n$$\n\nBy antisymmetry $c_{ji}^k = -c_{ij}^k$ we also have\n\n$$\nc_{21}^2 = -2,\\qquad c_{31}^3 = 2,\\qquad c_{32}^1 = -1.\n$$\n\nAll other $c_{ij}^k$ are zero.\n\n---\n\n### Conclusion\n\nThe matrices $H, X, Y$ form a basis of $\\mathfrak{sl}(2,\\mathbb{R})$, and the structure constants relative to this basis are given by the non\u2011zero values $c_{12}^2 = 2$, $c_{13}^3 = -2$, $c_{23}^1 = 1$ (together with those obtained by antisymmetry).",
        "raw_answer": "**Solution**\n\nWe work in the Lie algebra \\(\\mathfrak{sl}(2,\\mathbb{R}) = \\{ A \\in M_{2}(\\mathbb{R}) \\mid \\operatorname{tr}(A) = 0 \\}\\) with the Lie bracket \\([A,B] = AB - BA\\).\n\n---\n\n### 1. Membership\n\nCompute traces:\n\n\\[\n\\operatorname{tr}(H) = 1 + (-1) = 0,\\qquad\n\\operatorname{tr}(X) = 0 + 0 = 0,\\qquad\n\\operatorname{tr}(Y) = 0 + 0 = 0.\n\\]\n\nThus \\(H, X, Y \\in \\mathfrak{sl}(2,\\mathbb{R})\\).\n\n---\n\n### 2. Linear independence\n\nAssume \\(a H + b X + c Y = 0\\) for some \\(a,b,c \\in \\mathbb{R}\\). Then\n\n\\[\na\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} + b\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} + c\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\n= \\begin{pmatrix}a & b \\\\ c & -a\\end{pmatrix}\n= \\begin{pmatrix}0&0\\\\0&0\\end{pmatrix},\n\\]\n\nwhich forces \\(a = b = c = 0\\). Hence \\(H, X, Y\\) are linearly independent.\n\n---\n\n### 3. Spanning\n\nLet \\(A \\in \\mathfrak{sl}(2,\\mathbb{R})\\) be arbitrary. Write \\(A = \\begin{pmatrix} p & q \\\\ r & s \\end{pmatrix}\\) with \\(\\operatorname{tr}(A) = p + s = 0\\), so \\(s = -p\\). Then\n\n\\[\nA = \\begin{pmatrix} p & q \\\\ r & -p \\end{pmatrix}\n= p\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} + q\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} + r\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\n= p H + q X + r Y.\n\\]\n\nThus every element of \\(\\mathfrak{sl}(2,\\mathbb{R})\\) is a linear combination of \\(H, X, Y\\). Consequently, \\(\\{H, X, Y\\}\\) is a basis.\n\n*(Alternatively, \\(\\dim \\mathfrak{sl}(2,\\mathbb{R}) = 3\\) and three linearly independent vectors automatically form a basis.)*\n\n---\n\n### 4. Lie brackets\n\nCompute the commutators explicitly.\n\n- \\([H, X] = HX - XH\\)\n\n\\[\nHX = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = X,\n\\]\n\\[\nXH = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix}\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = \\begin{pmatrix}0&-1\\\\0&0\\end{pmatrix} = -X,\n\\]\n\\[\n\\Rightarrow [H,X] = X - (-X) = 2X.\n\\]\n\n- \\([H, Y] = HY - YH\\)\n\n\\[\nHY = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = \\begin{pmatrix}0&0\\\\-1&0\\end{pmatrix} = -Y,\n\\]\n\\[\nYH = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = Y,\n\\]\n\\[\n\\Rightarrow [H,Y] = -Y - Y = -2Y.\n\\]\n\n- \\([X, Y] = XY - YX\\)\n\n\\[\nXY = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix}\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = \\begin{pmatrix}1&0\\\\0&0\\end{pmatrix},\n\\]\n\\[\nYX = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = \\begin{pmatrix}0&0\\\\0&1\\end{pmatrix},\n\\]\n\\[\n\\Rightarrow [X,Y] = \\begin{pmatrix}1&0\\\\0&0\\end{pmatrix} - \\begin{pmatrix}0&0\\\\0&1\\end{pmatrix} = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = H.\n\\]\n\nThe remaining brackets follow from skew\u2011symmetry:\n\n\\[\n[X,H] = -[H,X] = -2X,\\qquad\n[Y,H] = -[H,Y] = 2Y,\\qquad\n[Y,X] = -[X,Y] = -H.\n\\]\n\n---\n\n### 5. Structure constants\n\nOrder the basis as \\(e_1 = H\\), \\(e_2 = X\\), \\(e_3 = Y\\). The structure constants \\(c_{ij}^k\\) are defined by\n\n\\[\n[e_i, e_j] = \\sum_{k=1}^{3} c_{ij}^k e_k.\n\\]\n\nFrom the computed brackets we obtain the non\u2011zero constants:\n\n\\[\n\\begin{aligned}\n[e_1, e_2] &= 2 e_2 \\quad &\\Rightarrow\\quad c_{12}^2 = 2,\\\\\n[e_1, e_3] &= -2 e_3 \\quad &\\Rightarrow\\quad c_{13}^3 = -2,\\\\\n[e_2, e_3] &= e_1 \\quad &\\Rightarrow\\quad c_{23}^1 = 1.\n\\end{aligned}\n\\]\n\nBy antisymmetry \\(c_{ji}^k = -c_{ij}^k\\) we also have\n\n\\[\nc_{21}^2 = -2,\\qquad c_{31}^3 = 2,\\qquad c_{32}^1 = -1.\n\\]\n\nAll other \\(c_{ij}^k\\) are zero.\n\n---\n\n### Conclusion\n\nThe matrices \\(H, X, Y\\) form a basis of \\(\\mathfrak{sl}(2,\\mathbb{R})\\), and the structure constants relative to this basis are given by the non\u2011zero values \\(c_{12}^2 = 2\\), \\(c_{13}^3 = -2\\), \\(c_{23}^1 = 1\\) (together with those obtained by antisymmetry).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of category theory or homological algebra, along with a solution that is verifiable and follows the given guidelines.\n\n## Step 2: Identify the domain\nThe problem should be related to category theory or homological algebra.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we need to ensure it is well-posed, non-trivial, and solvable with the given constraints. Let's consider a problem that involves understanding and applying concepts from category theory.\n\n## Step 4: Generate the problem\nLet's formulate a problem that involves proving a property related to categories and functors.\n\n## Step 5: Write the problem\nProve that the functor $F: \\mathbf{Ab} \\to \\mathbf{Ab}$ defined by $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is exact.\n[/QUESTION]",
    "run_id": "12",
    "topic_slug": "category_theory_and_homological_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove that the functor $F\\colon\\mathbf{Ab}\\to\\mathbf{Ab}$ defined by $F(G)=G\\otimes_{\\mathbb{Z}}\\mathbb{Q}$ is exact.  The category $\\mathbf{Ab}$ is equivalent to $\\mathbb{Z}\\text{-}\\mathbf{Mod}$, so we work with $\\mathbb{Z}$-modules.\n\nThe key observation is that $\\mathbb{Q}$ is the localization of $\\mathbb{Z}$ at the multiplicative set $S=\\mathbb{Z}\\setminus\\{0\\}$.  For any $\\mathbb{Z}$-module $G$, let\n$$\nS^{-1}G = \\left\\{\\frac{g}{s}\\;\\Big|\\; g\\in G,\\; s\\in S\\right\\}\\big/{\\sim},\n$$\nwhere $\\frac{g}{s}\\sim\\frac{g'}{s'}$ iff there exists $t\\in S$ with $t(s'g-sg')=0$.  This is the usual localization of a module.\n\n**Lemma 1.**  There is a natural isomorphism of functors\n$$\n\\varphi_G\\colon G\\otimes_{\\mathbb{Z}}\\mathbb{Q} \\longrightarrow S^{-1}G,\\qquad\ng\\otimes\\frac{a}{s} \\;\\longmapsto\\; \\frac{a\\cdot g}{s}.\n$$\nIts inverse is $\\psi_G\\bigl(\\frac{g}{s}\\bigr)=g\\otimes\\frac{1}{s}$.\n\n*Proof (sketch).*  The map $(g,\\frac{a}{s})\\mapsto\\frac{a g}{s}$ is $\\mathbb{Z}$-bilinear, hence induces a homomorphism $\\varphi_G$.  One verifies that $\\psi_G$ is well\u2011defined and that $\\varphi_G\\circ\\psi_G=\\mathrm{id}$ and $\\psi_G\\circ\\varphi_G=\\mathrm{id}$.  Naturality in $G$ is clear.  \u220e\n\nThus $F$ is naturally isomorphic to the localization functor $L\\colon G\\mapsto S^{-1}G$.  Because a natural isomorphism preserves exactness, it suffices to show that $L$ is exact.\n\n**Lemma 2.**  The functor $L$ is exact: for every short exact sequence\n$$\n0 \\longrightarrow A \\xrightarrow{\\;i\\;} B \\xrightarrow{\\;p\\;} C \\longrightarrow 0\n$$\nthe induced sequence\n$$\n0 \\longrightarrow S^{-1}A \\xrightarrow{S^{-1}i} S^{-1}B \\xrightarrow{S^{-1}p} S^{-1}C \\longrightarrow 0\n$$\nis exact.\n\n*Proof.*  We check the three conditions.\n\n1. **Injectivity of $S^{-1}i$.**  \n   Suppose $\\frac{a}{s}\\in S^{-1}A$ satisfies $(S^{-1}i)\\bigl(\\frac{a}{s}\\bigr)=\\frac{i(a)}{s}=0$ in $S^{-1}B$.  By definition, there exists $t\\in S$ such that $t\\cdot i(a)=0$ in $B$.  Since $i$ is injective, $t\\cdot a=0$ in $A$.  Then\n   $$\n   \\frac{a}{s}=\\frac{t a}{t s}=0 \\quad\\text{in } S^{-1}A,\n   $$\n   so $S^{-1}i$ is injective.\n\n2. **Surjectivity of $S^{-1}p$.**  \n   For any $\\frac{c}{s}\\in S^{-1}C$, surjectivity of $p$ gives $b\\in B$ with $p(b)=c$.  Then\n   $$\n   (S^{-1}p)\\Bigl(\\frac{b}{s}\\Bigr)=\\frac{p(b)}{s}=\\frac{c}{s},\n   $$\n   hence $S^{-1}p$ is surjective.\n\n3. **Exactness at $S^{-1}B$.**  \n   - $\\operatorname{Im}(S^{-1}i)\\subseteq\\operatorname{Ker}(S^{-1}p)$: If $\\frac{a}{s}\\in S^{-1}A$, then\n     $$\n     (S^{-1}p\\circ S^{-1}i)\\Bigl(\\frac{a}{s}\\Bigr)=\\frac{p(i(a))}{s}=0,\n     $$\n     because $p\\circ i=0$.  \n   - $\\operatorname{Ker}(S^{-1}p)\\subseteq\\operatorname{Im}(S^{-1}i)$: Let $\\frac{b}{s}\\in S^{-1}B$ with $(S^{-1}p)\\bigl(\\frac{b}{s}\\bigr)=\\frac{p(b)}{s}=0$.  Then there exists $t\\in S$ such that $t\\cdot p(b)=0$ in $C$, i.e. $p(t b)=0$.  Hence $t b\\in\\operatorname{Ker}(p)=\\operatorname{Im}(i)$, so we can choose $a\\in A$ with $i(a)=t b$.  Now consider $\\frac{a}{t s}\\in S^{-1}A$.  We have\n     $$\n     (S^{-1}i)\\Bigl(\\frac{a}{t s}\\Bigr)=\\frac{i(a)}{t s}=\\frac{t b}{t s}=\\frac{b}{s},\n     $$\n     showing $\\frac{b}{s}\\in\\operatorname{Im}(S^{-1}i)$.\n\nThus the sequence is exact.  \u220e\n\nBecause $F\\cong L$ naturally and $L$ is exact, the functor $F$ is exact.  $\\blacksquare$",
        "raw_answer": "We prove that the functor \\(F\\colon\\mathbf{Ab}\\to\\mathbf{Ab}\\) defined by \\(F(G)=G\\otimes_{\\mathbb{Z}}\\mathbb{Q}\\) is exact.  The category \\(\\mathbf{Ab}\\) is equivalent to \\(\\mathbb{Z}\\text{-}\\mathbf{Mod}\\), so we work with \\(\\mathbb{Z}\\)-modules.\n\nThe key observation is that \\(\\mathbb{Q}\\) is the localization of \\(\\mathbb{Z}\\) at the multiplicative set \\(S=\\mathbb{Z}\\setminus\\{0\\}\\).  For any \\(\\mathbb{Z}\\)-module \\(G\\), let\n\\[\nS^{-1}G = \\left\\{\\frac{g}{s}\\;\\Big|\\; g\\in G,\\; s\\in S\\right\\}\\big/{\\sim},\n\\]\nwhere \\(\\frac{g}{s}\\sim\\frac{g'}{s'}\\) iff there exists \\(t\\in S\\) with \\(t(s'g-sg')=0\\).  This is the usual localization of a module.\n\n**Lemma 1.**  There is a natural isomorphism of functors\n\\[\n\\varphi_G\\colon G\\otimes_{\\mathbb{Z}}\\mathbb{Q} \\longrightarrow S^{-1}G,\\qquad\ng\\otimes\\frac{a}{s} \\;\\longmapsto\\; \\frac{a\\cdot g}{s}.\n\\]\nIts inverse is \\(\\psi_G\\bigl(\\frac{g}{s}\\bigr)=g\\otimes\\frac{1}{s}\\).\n\n*Proof (sketch).*  The map \\((g,\\frac{a}{s})\\mapsto\\frac{a g}{s}\\) is \\(\\mathbb{Z}\\)-bilinear, hence induces a homomorphism \\(\\varphi_G\\).  One verifies that \\(\\psi_G\\) is well\u2011defined and that \\(\\varphi_G\\circ\\psi_G=\\mathrm{id}\\) and \\(\\psi_G\\circ\\varphi_G=\\mathrm{id}\\).  Naturality in \\(G\\) is clear.  \u220e\n\nThus \\(F\\) is naturally isomorphic to the localization functor \\(L\\colon G\\mapsto S^{-1}G\\).  Because a natural isomorphism preserves exactness, it suffices to show that \\(L\\) is exact.\n\n**Lemma 2.**  The functor \\(L\\) is exact: for every short exact sequence\n\\[\n0 \\longrightarrow A \\xrightarrow{\\;i\\;} B \\xrightarrow{\\;p\\;} C \\longrightarrow 0\n\\]\nthe induced sequence\n\\[\n0 \\longrightarrow S^{-1}A \\xrightarrow{S^{-1}i} S^{-1}B \\xrightarrow{S^{-1}p} S^{-1}C \\longrightarrow 0\n\\]\nis exact.\n\n*Proof.*  We check the three conditions.\n\n1. **Injectivity of \\(S^{-1}i\\).**  \n   Suppose \\(\\frac{a}{s}\\in S^{-1}A\\) satisfies \\((S^{-1}i)\\bigl(\\frac{a}{s}\\bigr)=\\frac{i(a)}{s}=0\\) in \\(S^{-1}B\\).  By definition, there exists \\(t\\in S\\) such that \\(t\\cdot i(a)=0\\) in \\(B\\).  Since \\(i\\) is injective, \\(t\\cdot a=0\\) in \\(A\\).  Then\n   \\[\n   \\frac{a}{s}=\\frac{t a}{t s}=0 \\quad\\text{in } S^{-1}A,\n   \\]\n   so \\(S^{-1}i\\) is injective.\n\n2. **Surjectivity of \\(S^{-1}p\\).**  \n   For any \\(\\frac{c}{s}\\in S^{-1}C\\), surjectivity of \\(p\\) gives \\(b\\in B\\) with \\(p(b)=c\\).  Then\n   \\[\n   (S^{-1}p)\\Bigl(\\frac{b}{s}\\Bigr)=\\frac{p(b)}{s}=\\frac{c}{s},\n   \\]\n   hence \\(S^{-1}p\\) is surjective.\n\n3. **Exactness at \\(S^{-1}B\\).**  \n   - \\(\\operatorname{Im}(S^{-1}i)\\subseteq\\operatorname{Ker}(S^{-1}p)\\): If \\(\\frac{a}{s}\\in S^{-1}A\\), then\n     \\[\n     (S^{-1}p\\circ S^{-1}i)\\Bigl(\\frac{a}{s}\\Bigr)=\\frac{p(i(a))}{s}=0,\n     \\]\n     because \\(p\\circ i=0\\).  \n   - \\(\\operatorname{Ker}(S^{-1}p)\\subseteq\\operatorname{Im}(S^{-1}i)\\): Let \\(\\frac{b}{s}\\in S^{-1}B\\) with \\((S^{-1}p)\\bigl(\\frac{b}{s}\\bigr)=\\frac{p(b)}{s}=0\\).  Then there exists \\(t\\in S\\) such that \\(t\\cdot p(b)=0\\) in \\(C\\), i.e. \\(p(t b)=0\\).  Hence \\(t b\\in\\operatorname{Ker}(p)=\\operatorname{Im}(i)\\), so we can choose \\(a\\in A\\) with \\(i(a)=t b\\).  Now consider \\(\\frac{a}{t s}\\in S^{-1}A\\).  We have\n     \\[\n     (S^{-1}i)\\Bigl(\\frac{a}{t s}\\Bigr)=\\frac{i(a)}{t s}=\\frac{t b}{t s}=\\frac{b}{s},\n     \\]\n     showing \\(\\frac{b}{s}\\in\\operatorname{Im}(S^{-1}i)\\).\n\nThus the sequence is exact.  \u220e\n\nBecause \\(F\\cong L\\) naturally and \\(L\\) is exact, the functor \\(F\\) is exact.  \\(\\blacksquare\\)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of K-theory, along with a solution that is verifiable and follows the given format.\n\n## Step 2: Identify the topic and relevant concepts\nThe topic is K-theory, which is a branch of algebraic topology that studies the properties of vector bundles and their relations to the underlying space. K-theory is crucial in various areas of mathematics and physics.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to understand what kind of questions are typically asked in K-theory. A common type of problem involves calculating the K-theory groups of a specific space or understanding the properties of K-theory groups under certain operations.\n\n## Step 4: Generate a specific problem\nLet's generate a problem related to the K-theory of a particular space. Consider the space $S^2$, the 2-sphere. A relevant problem could be to compute $K^0(S^2)$ and $K^1(S^2)$, which are related to the complex vector bundles on $S^2$.\n\n## Step 5: Formulate the problem in the required format\nWe need to provide a problem in the format: \"Compute $K^0(X)$ and $K^1(X)$ for $X = S^2$,\" where $S^2$ is the 2-sphere.\n\n## Step 6: Provide the solution\nTo solve this, we recall that $K^0(X)$ and $K^1(X)$ are related to the Grothendieck groups of complex vector bundles on $X$. For $S^2$, we know that $K^0(S^2)$ is related to the isomorphism classes of complex vector bundles on $S^2$, and $K^1(S^2)$ is related to the stable homotopy group $\\pi_1(S^2)$.\n\n## Step 7: Write down the problem and its solution\n### Problem\nCompute $K^0(S^2)$ and $K^1(S^2)$.",
    "run_id": "13",
    "topic_slug": "k_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We compute the complex topological K\u2011theory groups $K^0(S^2)$ and $K^1(S^2)$ of the 2\u2011sphere.\n\n## 1. Definitions and preliminaries\n\nFor a compact Hausdorff space $X$,  \n\n* $K^0(X)$ is the Grothendieck group of complex vector bundles over $X$.  \n  If $X$ is connected, there is a split exact sequence  \n  $$\n  0 \\longrightarrow \\widetilde{K}^0(X) \\longrightarrow K^0(X) \\xrightarrow{\\;\\operatorname{rk}\\;} \\mathbb{Z} \\longrightarrow 0,\n  $$\n  where $\\widetilde{K}^0(X)$ is the reduced K\u2011theory (virtual bundles of rank zero).\n\n* $K^1(X) = \\widetilde{K}^0(\\Sigma X)$, where $\\Sigma X$ is the reduced suspension.  \n  Equivalently, $K^1(X) = [X, U]$ with $U = \\varinjlim U(n)$ the infinite unitary group.\n\n## 2. Computation of $K^0(S^2)$\n\nWe use the **clutching construction**.  \n\nCover $S^2$ by two contractible open sets, e.g.  \n$U = S^2\\setminus\\{\\text{south pole}\\}$ and $V = S^2\\setminus\\{\\text{north pole}\\}$.  \nThen $U \\cap V$ retracts onto the equator $S^1$.\n\nBecause $U$ and $V$ are contractible, any complex vector bundle $E$ over $S^2$ is trivial when restricted to $U$ and to $V$.  \nChoose trivialisations $\\phi_U : E|_U \\to U\\times\\mathbb{C}^n$ and $\\phi_V : E|_V \\to V\\times\\mathbb{C}^n$.  \nOn $U\\cap V$ the transition map  \n$$\ng = \\phi_U \\circ \\phi_V^{-1} : U\\cap V \\to GL_n(\\mathbb{C})\n$$  \nis continuous. Up to homotopy, $g$ is determined by its restriction to $S^1$.  \nChanging the trivialisations alters $g$ by a homotopy, so the isomorphism class of $E$ depends only on the homotopy class $[g] \\in [S^1, GL_n(\\mathbb{C})] = \\pi_1(GL_n(\\mathbb{C}))$.  \nThis gives a bijection  \n$$\n\\operatorname{Vect}_n(S^2) \\;\\cong\\; \\pi_1(GL_n(\\mathbb{C})).\n$$\n\nNow $GL_n(\\mathbb{C})$ deformation retracts onto $U(n)$.  \nThe determinant $\\det : U(n) \\to U(1)$ is a fibration with fibre $SU(n)$.  \nSince $SU(n)$ is simply connected for $n\\ge 2$ (and $SU(1)$ is trivial), the long exact homotopy sequence yields  \n$$\n\\pi_1(U(n)) \\cong \\pi_1(U(1)) \\cong \\mathbb{Z} \\qquad\\text{for all } n\\ge 1.\n$$  \nHence $\\pi_1(GL_n(\\mathbb{C})) \\cong \\mathbb{Z}$ as well.  \n\nUnder this correspondence, the integer associated to a bundle $E$ is its **first Chern class**  \n$$\nc_1(E) \\in H^2(S^2;\\mathbb{Z}) \\cong \\mathbb{Z}.\n$$  \nFor line bundles it is the usual degree; for higher rank bundles one takes $c_1(\\det E)$.  \nIn particular, the Hopf line bundle $H$ corresponds to $1 \\in \\mathbb{Z}$.\n\nThe monoid of vector bundles (under direct sum) therefore satisfies  \n$$\n[E] \\leftrightarrow (\\operatorname{rk}(E),\\, c_1(E)) \\in \\mathbb{N} \\times \\mathbb{Z},\n$$  \nand the Grothendieck group $K^0(S^2)$ inherits a homomorphism  \n$$\n\\Phi : K^0(S^2) \\longrightarrow \\mathbb{Z} \\oplus \\mathbb{Z},\\qquad\n\\Phi([E]-[F]) = \\bigl(\\operatorname{rk}(E)-\\operatorname{rk}(F),\\; c_1(E)-c_1(F)\\bigr).\n$$  \n$\\Phi$ is well\u2011defined because $c_1$ is additive on exact sequences.\n\n* **Surjectivity**:  \n  $\\Phi( [\\text{trivial line bundle }1] ) = (1,0)$ and  \n  $\\Phi( [H] - [1] ) = (0,1)$.\n\n* **Injectivity**:  \n  The reduced group $\\widetilde{K}^0(S^2)$ consists of virtual bundles of rank zero.  \n  The map $c_1 : \\widetilde{K}^0(S^2) \\to \\mathbb{Z}$ is an isomorphism (it sends the generator $[H]-[1]$ to $1$).  \n  Since $K^0(S^2) \\cong \\widetilde{K}^0(S^2) \\oplus \\mathbb{Z}$ via the rank map, $\\Phi$ is an isomorphism.\n\nThus  \n$$\n\\boxed{K^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}}.\n$$\n\n## 3. Computation of $K^1(S^2)$\n\nBy definition, $K^1(S^2) = \\widetilde{K}^0(\\Sigma S^2)$. The reduced suspension $\\Sigma S^2$ is homeomorphic to $S^3$.  \nWe therefore compute $\\widetilde{K}^0(S^3)$.\n\nAgain use a clutching construction: cover $S^3$ by two 3\u2011balls $U'$ and $V'$ whose intersection retracts onto $S^2$.  \nA vector bundle over $S^3$ is determined by a transition map  \n$$\nf : S^2 \\to GL_n(\\mathbb{C}),\n$$  \nwith isomorphism classes corresponding to homotopy classes $[f] \\in \\pi_2(GL_n(\\mathbb{C}))$.\n\nBecause $GL_n(\\mathbb{C}) \\simeq U(n)$, we examine $\\pi_2(U(n))$.  \nFrom the fibration $U(n-1) \\to U(n) \\to S^{2n-1}$ and the fact that  \n\n* $\\pi_2(S^{2n-1}) = 0$ for all $n\\ge 1$,  \n* $\\pi_2(U(1)) = \\pi_2(S^1) = 0$,  \n\nan induction shows $\\pi_2(U(n)) = 0$ for every $n$.  \nHence every vector bundle over $S^3$ is trivial.\n\nConsequently, the monoid of vector bundles on $S^3$ is $\\mathbb{N}$ (rank), its Grothendieck group is $\\mathbb{Z}$, and the rank map $K^0(S^3) \\to \\mathbb{Z}$ is an isomorphism.  \nTherefore the reduced K\u2011theory vanishes:  \n$$\n\\widetilde{K}^0(S^3) = 0.\n$$  \nThus  \n$$\n\\boxed{K^1(S^2) = 0}.\n$$\n\n## 4. Conclusion\n\nThe complex K\u2011theory groups of the 2\u2011sphere are  \n\n$$\nK^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}, \\qquad\nK^1(S^2) = 0.\n$$\n\nThis result is consistent with Bott periodicity, which gives $K^0(S^{2n}) \\cong \\mathbb{Z}\\oplus\\mathbb{Z}$ and $K^1(S^{2n}) = 0$ for $n\\ge 1$.",
        "raw_answer": "We compute the complex topological K\u2011theory groups \\(K^0(S^2)\\) and \\(K^1(S^2)\\) of the 2\u2011sphere.\n\n## 1. Definitions and preliminaries\n\nFor a compact Hausdorff space \\(X\\),  \n\n* \\(K^0(X)\\) is the Grothendieck group of complex vector bundles over \\(X\\).  \n  If \\(X\\) is connected, there is a split exact sequence  \n  \\[\n  0 \\longrightarrow \\widetilde{K}^0(X) \\longrightarrow K^0(X) \\xrightarrow{\\;\\operatorname{rk}\\;} \\mathbb{Z} \\longrightarrow 0,\n  \\]\n  where \\(\\widetilde{K}^0(X)\\) is the reduced K\u2011theory (virtual bundles of rank zero).\n\n* \\(K^1(X) = \\widetilde{K}^0(\\Sigma X)\\), where \\(\\Sigma X\\) is the reduced suspension.  \n  Equivalently, \\(K^1(X) = [X, U]\\) with \\(U = \\varinjlim U(n)\\) the infinite unitary group.\n\n## 2. Computation of \\(K^0(S^2)\\)\n\nWe use the **clutching construction**.  \n\nCover \\(S^2\\) by two contractible open sets, e.g.  \n\\(U = S^2\\setminus\\{\\text{south pole}\\}\\) and \\(V = S^2\\setminus\\{\\text{north pole}\\}\\).  \nThen \\(U \\cap V\\) retracts onto the equator \\(S^1\\).\n\nBecause \\(U\\) and \\(V\\) are contractible, any complex vector bundle \\(E\\) over \\(S^2\\) is trivial when restricted to \\(U\\) and to \\(V\\).  \nChoose trivialisations \\(\\phi_U : E|_U \\to U\\times\\mathbb{C}^n\\) and \\(\\phi_V : E|_V \\to V\\times\\mathbb{C}^n\\).  \nOn \\(U\\cap V\\) the transition map  \n\\[\ng = \\phi_U \\circ \\phi_V^{-1} : U\\cap V \\to GL_n(\\mathbb{C})\n\\]  \nis continuous. Up to homotopy, \\(g\\) is determined by its restriction to \\(S^1\\).  \nChanging the trivialisations alters \\(g\\) by a homotopy, so the isomorphism class of \\(E\\) depends only on the homotopy class \\([g] \\in [S^1, GL_n(\\mathbb{C})] = \\pi_1(GL_n(\\mathbb{C}))\\).  \nThis gives a bijection  \n\\[\n\\operatorname{Vect}_n(S^2) \\;\\cong\\; \\pi_1(GL_n(\\mathbb{C})).\n\\]\n\nNow \\(GL_n(\\mathbb{C})\\) deformation retracts onto \\(U(n)\\).  \nThe determinant \\(\\det : U(n) \\to U(1)\\) is a fibration with fibre \\(SU(n)\\).  \nSince \\(SU(n)\\) is simply connected for \\(n\\ge 2\\) (and \\(SU(1)\\) is trivial), the long exact homotopy sequence yields  \n\\[\n\\pi_1(U(n)) \\cong \\pi_1(U(1)) \\cong \\mathbb{Z} \\qquad\\text{for all } n\\ge 1.\n\\]  \nHence \\(\\pi_1(GL_n(\\mathbb{C})) \\cong \\mathbb{Z}\\) as well.  \n\nUnder this correspondence, the integer associated to a bundle \\(E\\) is its **first Chern class**  \n\\[\nc_1(E) \\in H^2(S^2;\\mathbb{Z}) \\cong \\mathbb{Z}.\n\\]  \nFor line bundles it is the usual degree; for higher rank bundles one takes \\(c_1(\\det E)\\).  \nIn particular, the Hopf line bundle \\(H\\) corresponds to \\(1 \\in \\mathbb{Z}\\).\n\nThe monoid of vector bundles (under direct sum) therefore satisfies  \n\\[\n[E] \\leftrightarrow (\\operatorname{rk}(E),\\, c_1(E)) \\in \\mathbb{N} \\times \\mathbb{Z},\n\\]  \nand the Grothendieck group \\(K^0(S^2)\\) inherits a homomorphism  \n\\[\n\\Phi : K^0(S^2) \\longrightarrow \\mathbb{Z} \\oplus \\mathbb{Z},\\qquad\n\\Phi([E]-[F]) = \\bigl(\\operatorname{rk}(E)-\\operatorname{rk}(F),\\; c_1(E)-c_1(F)\\bigr).\n\\]  \n\\(\\Phi\\) is well\u2011defined because \\(c_1\\) is additive on exact sequences.\n\n* **Surjectivity**:  \n  \\(\\Phi( [\\text{trivial line bundle }1] ) = (1,0)\\) and  \n  \\(\\Phi( [H] - [1] ) = (0,1)\\).\n\n* **Injectivity**:  \n  The reduced group \\(\\widetilde{K}^0(S^2)\\) consists of virtual bundles of rank zero.  \n  The map \\(c_1 : \\widetilde{K}^0(S^2) \\to \\mathbb{Z}\\) is an isomorphism (it sends the generator \\([H]-[1]\\) to \\(1\\)).  \n  Since \\(K^0(S^2) \\cong \\widetilde{K}^0(S^2) \\oplus \\mathbb{Z}\\) via the rank map, \\(\\Phi\\) is an isomorphism.\n\nThus  \n\\[\n\\boxed{K^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}}.\n\\]\n\n## 3. Computation of \\(K^1(S^2)\\)\n\nBy definition, \\(K^1(S^2) = \\widetilde{K}^0(\\Sigma S^2)\\). The reduced suspension \\(\\Sigma S^2\\) is homeomorphic to \\(S^3\\).  \nWe therefore compute \\(\\widetilde{K}^0(S^3)\\).\n\nAgain use a clutching construction: cover \\(S^3\\) by two 3\u2011balls \\(U'\\) and \\(V'\\) whose intersection retracts onto \\(S^2\\).  \nA vector bundle over \\(S^3\\) is determined by a transition map  \n\\[\nf : S^2 \\to GL_n(\\mathbb{C}),\n\\]  \nwith isomorphism classes corresponding to homotopy classes \\([f] \\in \\pi_2(GL_n(\\mathbb{C}))\\).\n\nBecause \\(GL_n(\\mathbb{C}) \\simeq U(n)\\), we examine \\(\\pi_2(U(n))\\).  \nFrom the fibration \\(U(n-1) \\to U(n) \\to S^{2n-1}\\) and the fact that  \n\n* \\(\\pi_2(S^{2n-1}) = 0\\) for all \\(n\\ge 1\\),  \n* \\(\\pi_2(U(1)) = \\pi_2(S^1) = 0\\),  \n\nan induction shows \\(\\pi_2(U(n)) = 0\\) for every \\(n\\).  \nHence every vector bundle over \\(S^3\\) is trivial.\n\nConsequently, the monoid of vector bundles on \\(S^3\\) is \\(\\mathbb{N}\\) (rank), its Grothendieck group is \\(\\mathbb{Z}\\), and the rank map \\(K^0(S^3) \\to \\mathbb{Z}\\) is an isomorphism.  \nTherefore the reduced K\u2011theory vanishes:  \n\\[\n\\widetilde{K}^0(S^3) = 0.\n\\]  \nThus  \n\\[\n\\boxed{K^1(S^2) = 0}.\n\\]\n\n## 4. Conclusion\n\nThe complex K\u2011theory groups of the 2\u2011sphere are  \n\n\\[\nK^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}, \\qquad\nK^1(S^2) = 0.\n\\]\n\nThis result is consistent with Bott periodicity, which gives \\(K^0(S^{2n}) \\cong \\mathbb{Z}\\oplus\\mathbb{Z}\\) and \\(K^1(S^{2n}) = 0\\) for \\(n\\ge 1\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Group theory and generalizations\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Group theory and generalizations\nGroup theory is a branch of abstract algebra that studies the symmetric aspects of objects and the transformations that preserve those symmetries. A suitable topic could involve properties of groups, such as subgroup structures, homomorphisms, or specific types of groups like cyclic or symmetric groups.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider a topic like the classification of groups or the study of group homomorphisms. A potential problem could involve determining the number of homomorphisms between two given groups or analyzing the structure of a specific group.\n\n## Step 4: Generate a specific problem\nLet's consider the problem of finding the number of homomorphisms from the cyclic group of order 12, $\\mathbb{Z}_{12}$, to the symmetric group $S_3$. This involves understanding the structure of both groups and applying knowledge about homomorphisms.\n\n## Step 5: State the problem formally\nThe problem can be stated as: \"Let $\\mathbb{Z}_{12}$ be the cyclic group of order 12 and $S_3$ be the symmetric group on 3 elements. Determine the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\"\n\n## Step 6: Provide the solution\nTo solve this, we need to understand that a homomorphism $f: \\mathbb{Z}_{12} \\to S_3$ is determined by $f(1)$, where $1$ is a generator of $\\mathbb{Z}_{12}$. The element $f(1)$ must have an order that divides 12. $S_3$ has elements of orders 1, 2, and 3. We need to count how many elements in $S_3$ have orders that divide 12.\n\n## Step 7: Analyze the elements of $S_3$\n$S_3 = \\{e, (12), (13), (23), (123), (132)\\}$. The identity $e$ has order 1, the transpositions $(12), (13), (23)$ have order 2, and the 3-cycles $(123), (132)$ have order 3. The orders of elements in $S_3$ that divide 12 are 1, 2, and 3.\n\n## Step 8: Count the possible images of $1 \\in \\mathbb{Z}_{12}$\nThere is 1 element of order 1, 3 elements of order 2, and 2 elements of order 3. So, $f(1)$ can be any of these 6 elements because their orders divide 12.\n\n## Step 9: Conclude the number of homomorphisms\nSince $f(1)$ can be any of the 6 elements (1 of order 1, 3 of order 2, and 2 of order 3), there are 6 possible homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\n\n## Step 10: Format the problem and solution according to the required output format\n\nLet $\\mathbb{Z}_{12}$ be the cyclic group of order 12 and $S_3$ be the symmetric group on 3 elements. Determine the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.",
    "run_id": "14",
    "topic_slug": "group_theory_and_generalizations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked: \"Let $\\mathbb{Z}_{12}$ be the cyclic group of order 12 and $S_3$ be the symmetric group on 3 elements. Determine the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\"\n\n**Solution.**  \nA homomorphism $\\varphi : \\mathbb{Z}_{12} \\to S_3$ is completely determined by the image of a generator of $\\mathbb{Z}_{12}$. The group $\\mathbb{Z}_{12}$ is cyclic; we take $1$ (mod $12$) as a generator. For any $g \\in S_3$, define $\\varphi(1)=g$. Then for any integer $k$, $\\varphi(k) = \\varphi(1)^k = g^k$. This gives a well\u2011defined homomorphism if and only if $\\varphi(12) = \\varphi(0) = e$ (the identity of $S_3$), i.e. $g^{12}=e$. Hence the necessary and sufficient condition is that the order of $g$ divides $12$.\n\nWe therefore need to count the elements of $S_3$ whose order divides $12$.  \nRecall the symmetric group $S_3$ consists of the following six elements:\n\n- The identity $e$, order $1$.\n- Three transpositions: $(12)$, $(13)$, $(23)$, each of order $2$.\n- Two $3$-cycles: $(123)$ and $(132)$, each of order $3$.\n\nAll these orders ($1$, $2$, $3$) divide $12$. Consequently every element of $S_3$ satisfies the condition.\n\nThus there are exactly $6$ choices for $\\varphi(1)$, and each choice yields a distinct homomorphism. Therefore the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$ is $\\boxed{6}$.\n\n**Verification.**  \nFor each $g \\in S_3$, the map $\\varphi(k)=g^k$ is indeed a homomorphism because $\\varphi(k+\\ell)=g^{k+\\ell}=g^k g^{\\ell}=\\varphi(k)\\varphi(\\ell)$ and the condition $g^{12}=e$ ensures that $\\varphi(k+12)=g^{k+12}=g^k=\\varphi(k)$, so $\\varphi$ respects the relation $k\\equiv \\ell \\pmod{12}$. The six homomorphisms are:\n\n- trivial homomorphism ($g=e$);\n- three homomorphisms with $g$ a transposition (e.g., $g=(12)$ gives $\\varphi(k) = (12)^k$, which is $e$ when $k$ even and $(12)$ when $k$ odd);\n- two homomorphisms with $g$ a $3$-cycle (e.g., $g=(123)$ gives $\\varphi(k) = (123)^k$, cycling with period $3$).\n\nNo other homomorphisms exist because any homomorphism must send $1$ to an element whose order divides $12$, and we have exhausted all such elements.",
        "raw_answer": "We are asked: \"Let $\\mathbb{Z}_{12}$ be the cyclic group of order 12 and $S_3$ be the symmetric group on 3 elements. Determine the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\"\n\n**Solution.**  \nA homomorphism $\\varphi : \\mathbb{Z}_{12} \\to S_3$ is completely determined by the image of a generator of $\\mathbb{Z}_{12}$. The group $\\mathbb{Z}_{12}$ is cyclic; we take $1$ (mod $12$) as a generator. For any $g \\in S_3$, define $\\varphi(1)=g$. Then for any integer $k$, $\\varphi(k) = \\varphi(1)^k = g^k$. This gives a well\u2011defined homomorphism if and only if $\\varphi(12) = \\varphi(0) = e$ (the identity of $S_3$), i.e. $g^{12}=e$. Hence the necessary and sufficient condition is that the order of $g$ divides $12$.\n\nWe therefore need to count the elements of $S_3$ whose order divides $12$.  \nRecall the symmetric group $S_3$ consists of the following six elements:\n\n- The identity $e$, order $1$.\n- Three transpositions: $(12)$, $(13)$, $(23)$, each of order $2$.\n- Two $3$-cycles: $(123)$ and $(132)$, each of order $3$.\n\nAll these orders ($1$, $2$, $3$) divide $12$. Consequently every element of $S_3$ satisfies the condition.\n\nThus there are exactly $6$ choices for $\\varphi(1)$, and each choice yields a distinct homomorphism. Therefore the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$ is $\\boxed{6}$.\n\n**Verification.**  \nFor each $g \\in S_3$, the map $\\varphi(k)=g^k$ is indeed a homomorphism because $\\varphi(k+\\ell)=g^{k+\\ell}=g^k g^{\\ell}=\\varphi(k)\\varphi(\\ell)$ and the condition $g^{12}=e$ ensures that $\\varphi(k+12)=g^{k+12}=g^k=\\varphi(k)$, so $\\varphi$ respects the relation $k\\equiv \\ell \\pmod{12}$. The six homomorphisms are:\n\n- trivial homomorphism ($g=e$);\n- three homomorphisms with $g$ a transposition (e.g., $g=(12)$ gives $\\varphi(k) = (12)^k$, which is $e$ when $k$ even and $(12)$ when $k$ odd);\n- two homomorphisms with $g$ a $3$-cycle (e.g., $g=(123)$ gives $\\varphi(k) = (123)^k$, cycling with period $3$).\n\nNo other homomorphisms exist because any homomorphism must send $1$ to an element whose order divides $12$, and we have exhausted all such elements.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $G$ be a connected Lie group with Lie algebra $\\mathfrak{g}$. Suppose that $\\mathfrak{g}$ is simple and that $G$ has a discrete subgroup $\\Gamma$ such that $G/\\Gamma$ is compact. Prove that $\\Gamma$ is contained in the center of $G$ if and only if the adjoint representation of $G$ on $\\mathfrak{g}$ descends to a representation of $G/\\Gamma$.",
    "run_id": "15",
    "topic_slug": "topological_groups_and_lie_groups",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove the equivalence using basic properties of the adjoint representation and the center of a connected Lie group.\n\n### Preliminaries\n\nLet $G$ be a connected Lie group with Lie algebra $\\mathfrak{g}$. The **adjoint representation**  \n$$\n\\operatorname{Ad}:G\\to \\operatorname{GL}(\\mathfrak{g}),\\qquad \\operatorname{Ad}(g) = d(C_g)_e,\n$$\nwhere $C_g(h)=ghg^{-1}$ is conjugation. For a connected Lie group one has\n$$\n\\ker(\\operatorname{Ad}) = Z(G),\n$$\nthe center of $G$. Indeed:\n- If $g\\in Z(G)$ then $C_g=\\operatorname{id}_G$, so $\\operatorname{Ad}(g)=\\operatorname{id}_{\\mathfrak{g}}$.\n- Conversely, if $\\operatorname{Ad}(g)=\\operatorname{id}$, then $C_g$ is the identity on a neighbourhood of $e$; because $G$ is connected, $C_g$ is the identity everywhere, hence $g$ commutes with every element of $G$, i.e., $g\\in Z(G)$.\n\n### Interpretation of \u201cdescends to a representation of $G/\\Gamma$\u201d\n\nThe statement \u201cthe adjoint representation descends to a representation of $G/\\Gamma$\u201d means that there exists a (smooth) Lie group homomorphism\n$$\n\\rho : G/\\Gamma \\to \\operatorname{GL}(\\mathfrak{g})\n$$\nsuch that $\\operatorname{Ad}= \\rho \\circ \\pi$, where $\\pi:G\\to G/\\Gamma$ is the canonical projection. For this to make sense, $G/\\Gamma$ must be a Lie group, which requires $\\Gamma$ to be a **normal** subgroup. (If $\\Gamma$ is not normal, $G/\\Gamma$ is only a homogeneous space and does not carry a natural group structure.) In the forward direction we will see that $\\Gamma\\subset Z(G)$ forces $\\Gamma$ to be normal, so $G/\\Gamma$ is indeed a Lie group. In the reverse direction the hypothesis itself already presumes the existence of such a $\\rho$, hence $G/\\Gamma$ is a group and $\\Gamma$ is automatically normal.\n\n### Proof of the equivalence\n\n#### 1. $\\Gamma\\subset Z(G)$ $\\Longrightarrow$ $\\operatorname{Ad}$ descends to a representation of $G/\\Gamma$.\n\nAssume $\\Gamma\\subset Z(G)$. Because the center consists of elements commuting with all of $G$, $\\Gamma$ is central and therefore normal. As $\\Gamma$ is discrete and closed, $G/\\Gamma$ is a Lie group.\n\nSince $\\Gamma\\subset Z(G)=\\ker(\\operatorname{Ad})$, we have $\\operatorname{Ad}(\\gamma)=\\operatorname{id}_{\\mathfrak{g}}$ for every $\\gamma\\in\\Gamma$. Define\n$$\n\\rho : G/\\Gamma \\to \\operatorname{GL}(\\mathfrak{g}),\\qquad \\rho(g\\Gamma) = \\operatorname{Ad}(g).\n$$\n- **Well\u2011defined:** If $g\\Gamma = h\\Gamma$, then $h = g\\gamma$ for some $\\gamma\\in\\Gamma$. Then\n  $$\n  \\operatorname{Ad}(h)=\\operatorname{Ad}(g\\gamma)=\\operatorname{Ad}(g)\\operatorname{Ad}(\\gamma)=\\operatorname{Ad}(g)\\cdot\\operatorname{id}=\\operatorname{Ad}(g),\n  $$\n  so $\\rho$ is independent of the coset representative.\n- **Homomorphism:** For any $g,h\\in G$,\n  $$\n  \\rho\\bigl((g\\Gamma)(h\\Gamma)\\bigr) = \\rho(gh\\Gamma) = \\operatorname{Ad}(gh)=\\operatorname{Ad}(g)\\operatorname{Ad}(h)=\\rho(g\\Gamma)\\,\\rho(h\\Gamma).\n  $$\n- **Smoothness:** $\\operatorname{Ad}$ is smooth and $\\pi$ is a local diffeomorphism, hence $\\rho$ is smooth.\n\nThus $\\rho$ is a Lie group representation of $G/\\Gamma$ on $\\mathfrak{g}$ and $\\operatorname{Ad}= \\rho\\circ\\pi$; i.e., the adjoint representation descends.\n\n#### 2. $\\operatorname{Ad}$ descends to a representation of $G/\\Gamma$ $\\Longrightarrow$ $\\Gamma\\subset Z(G)$.\n\nAssume there exists a homomorphism $\\rho:G/\\Gamma\\to\\operatorname{GL}(\\mathfrak{g})$ with $\\operatorname{Ad}= \\rho\\circ\\pi$. For any $\\gamma\\in\\Gamma$,\n$$\n\\pi(\\gamma)=\\gamma\\Gamma = e\\Gamma \\quad\\text{(the identity coset)},\n$$\nso\n$$\n\\operatorname{Ad}(\\gamma) = \\rho(\\pi(\\gamma)) = \\rho(e\\Gamma) = \\operatorname{id}_{\\mathfrak{g}}.\n$$\nHence $\\gamma\\in\\ker(\\operatorname{Ad}) = Z(G)$. Therefore $\\Gamma\\subset Z(G)$.\n\n### Conclusion\n\nThe two statements are equivalent:\n$$\n\\boxed{\\Gamma\\subset Z(G)\\;\\iff\\; \\operatorname{Ad}\\text{ descends to a representation of }G/\\Gamma.}\n$$\n\n### Remarks on the hypotheses\n\n- The connectedness of $G$ is essential for the identification $\\ker(\\operatorname{Ad})=Z(G)$.\n- The simplicity of $\\mathfrak{g}$ and the compactness of $G/\\Gamma$ are **not** used in the above argument; they are additional conditions that may be relevant for other parts of a larger context (for instance, they guarantee that $Z(G)$ is discrete and that $G/\\Gamma$ is a compact manifold).",
        "raw_answer": "We prove the equivalence using basic properties of the adjoint representation and the center of a connected Lie group.\n\n### Preliminaries\n\nLet \\(G\\) be a connected Lie group with Lie algebra \\(\\mathfrak{g}\\). The **adjoint representation**  \n\\[\n\\operatorname{Ad}:G\\to \\operatorname{GL}(\\mathfrak{g}),\\qquad \\operatorname{Ad}(g) = d(C_g)_e,\n\\]\nwhere \\(C_g(h)=ghg^{-1}\\) is conjugation. For a connected Lie group one has\n\\[\n\\ker(\\operatorname{Ad}) = Z(G),\n\\]\nthe center of \\(G\\). Indeed:\n- If \\(g\\in Z(G)\\) then \\(C_g=\\operatorname{id}_G\\), so \\(\\operatorname{Ad}(g)=\\operatorname{id}_{\\mathfrak{g}}\\).\n- Conversely, if \\(\\operatorname{Ad}(g)=\\operatorname{id}\\), then \\(C_g\\) is the identity on a neighbourhood of \\(e\\); because \\(G\\) is connected, \\(C_g\\) is the identity everywhere, hence \\(g\\) commutes with every element of \\(G\\), i.e., \\(g\\in Z(G)\\).\n\n### Interpretation of \u201cdescends to a representation of \\(G/\\Gamma\\)\u201d\n\nThe statement \u201cthe adjoint representation descends to a representation of \\(G/\\Gamma\\)\u201d means that there exists a (smooth) Lie group homomorphism\n\\[\n\\rho : G/\\Gamma \\to \\operatorname{GL}(\\mathfrak{g})\n\\]\nsuch that \\(\\operatorname{Ad}= \\rho \\circ \\pi\\), where \\(\\pi:G\\to G/\\Gamma\\) is the canonical projection. For this to make sense, \\(G/\\Gamma\\) must be a Lie group, which requires \\(\\Gamma\\) to be a **normal** subgroup. (If \\(\\Gamma\\) is not normal, \\(G/\\Gamma\\) is only a homogeneous space and does not carry a natural group structure.) In the forward direction we will see that \\(\\Gamma\\subset Z(G)\\) forces \\(\\Gamma\\) to be normal, so \\(G/\\Gamma\\) is indeed a Lie group. In the reverse direction the hypothesis itself already presumes the existence of such a \\(\\rho\\), hence \\(G/\\Gamma\\) is a group and \\(\\Gamma\\) is automatically normal.\n\n### Proof of the equivalence\n\n#### 1. \\(\\Gamma\\subset Z(G)\\) \\(\\Longrightarrow\\) \\(\\operatorname{Ad}\\) descends to a representation of \\(G/\\Gamma\\).\n\nAssume \\(\\Gamma\\subset Z(G)\\). Because the center consists of elements commuting with all of \\(G\\), \\(\\Gamma\\) is central and therefore normal. As \\(\\Gamma\\) is discrete and closed, \\(G/\\Gamma\\) is a Lie group.\n\nSince \\(\\Gamma\\subset Z(G)=\\ker(\\operatorname{Ad})\\), we have \\(\\operatorname{Ad}(\\gamma)=\\operatorname{id}_{\\mathfrak{g}}\\) for every \\(\\gamma\\in\\Gamma\\). Define\n\\[\n\\rho : G/\\Gamma \\to \\operatorname{GL}(\\mathfrak{g}),\\qquad \\rho(g\\Gamma) = \\operatorname{Ad}(g).\n\\]\n- **Well\u2011defined:** If \\(g\\Gamma = h\\Gamma\\), then \\(h = g\\gamma\\) for some \\(\\gamma\\in\\Gamma\\). Then\n  \\[\n  \\operatorname{Ad}(h)=\\operatorname{Ad}(g\\gamma)=\\operatorname{Ad}(g)\\operatorname{Ad}(\\gamma)=\\operatorname{Ad}(g)\\cdot\\operatorname{id}=\\operatorname{Ad}(g),\n  \\]\n  so \\(\\rho\\) is independent of the coset representative.\n- **Homomorphism:** For any \\(g,h\\in G\\),\n  \\[\n  \\rho\\bigl((g\\Gamma)(h\\Gamma)\\bigr) = \\rho(gh\\Gamma) = \\operatorname{Ad}(gh)=\\operatorname{Ad}(g)\\operatorname{Ad}(h)=\\rho(g\\Gamma)\\,\\rho(h\\Gamma).\n  \\]\n- **Smoothness:** \\(\\operatorname{Ad}\\) is smooth and \\(\\pi\\) is a local diffeomorphism, hence \\(\\rho\\) is smooth.\n\nThus \\(\\rho\\) is a Lie group representation of \\(G/\\Gamma\\) on \\(\\mathfrak{g}\\) and \\(\\operatorname{Ad}= \\rho\\circ\\pi\\); i.e., the adjoint representation descends.\n\n#### 2. \\(\\operatorname{Ad}\\) descends to a representation of \\(G/\\Gamma\\) \\(\\Longrightarrow\\) \\(\\Gamma\\subset Z(G)\\).\n\nAssume there exists a homomorphism \\(\\rho:G/\\Gamma\\to\\operatorname{GL}(\\mathfrak{g})\\) with \\(\\operatorname{Ad}= \\rho\\circ\\pi\\). For any \\(\\gamma\\in\\Gamma\\),\n\\[\n\\pi(\\gamma)=\\gamma\\Gamma = e\\Gamma \\quad\\text{(the identity coset)},\n\\]\nso\n\\[\n\\operatorname{Ad}(\\gamma) = \\rho(\\pi(\\gamma)) = \\rho(e\\Gamma) = \\operatorname{id}_{\\mathfrak{g}}.\n\\]\nHence \\(\\gamma\\in\\ker(\\operatorname{Ad}) = Z(G)\\). Therefore \\(\\Gamma\\subset Z(G)\\).\n\n### Conclusion\n\nThe two statements are equivalent:\n\\[\n\\boxed{\\Gamma\\subset Z(G)\\;\\iff\\; \\operatorname{Ad}\\text{ descends to a representation of }G/\\Gamma.}\n\\]\n\n### Remarks on the hypotheses\n\n- The connectedness of \\(G\\) is essential for the identification \\(\\ker(\\operatorname{Ad})=Z(G)\\).\n- The simplicity of \\(\\mathfrak{g}\\) and the compactness of \\(G/\\Gamma\\) are **not** used in the above argument; they are additional conditions that may be relevant for other parts of a larger context (for instance, they guarantee that \\(Z(G)\\) is discrete and that \\(G/\\Gamma\\) is a compact manifold).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the requirements for the problem.\nThe task is to generate a challenging but solvable mathematics problem in the domain of real functions, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Determine the specific area within real functions to focus on.\nGiven the broad domain of real functions, we can consider various aspects such as differentiation, integration, functional equations, or properties of specific types of functions (e.g., continuous, differentiable, integrable).\n\n## Step 3: Choose a specific topic within real functions that can be used to create a challenging problem.\nLet's consider the topic of functional equations, which involves finding a function that satisfies a given equation involving the function and its inputs.\n\n## Step 4: Generate a challenging problem in the chosen topic.\nConsider the functional equation $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for $x, y \\in \\mathbb{R}$, where $f: \\mathbb{R} \\to \\mathbb{R}$. The task is to find all $f$ that satisfy this equation.\n\n## Step 5: Ensure the problem is well-posed and meets the quality rubric.\nThe given functional equation is well-defined, and the task is clear. We need to verify that it's non-trivial and solvable.\n\n## Step 6: Provide a solution to the generated problem.\nTo solve $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$, let's first check if there are any obvious solutions. For $y = 0$, we get $f(x) = \\frac{f(x) + f(0)}{1 - f(x)f(0)}$. This simplifies to $f(x)(1 - f(x)f(0)) = f(x) + f(0)$, or $f(x) - f(x)^2f(0) = f(x) + f(0)$, leading to $-f(x)^2f(0) = f(0)$. If $f(0) \\neq 0$, this gives $f(x)^2 = -1$ for all $x$, which is impossible for real-valued $f$. Thus, $f(0) = 0$.\n\n## Step 7: Continue solving the functional equation.\nSetting $y = x$, we have $f(2x) = \\frac{2f(x)}{1 - f(x)^2}$. This is a useful relation but let's first explore the derivative of $f$ if it exists. Assuming $f$ is differentiable, differentiating both sides with respect to $y$ and then setting $y = 0$ gives $f'(x) = \\frac{f'(0)(1 + f(x)^2)}{(1 - f(x)f(0))^2} = f'(0)(1 + f(x)^2)$ because $f(0) = 0$. So, $f'(x) = f'(0)(1 + f(x)^2)$.\n\n## Step 8: Solve the differential equation obtained from the functional equation.\nThe differential equation $f'(x) = f'(0)(1 + f(x)^2)$ can be solved by separation of variables: $\\frac{df}{1 + f^2} = f'(0)dx$. Integrating both sides gives $\\arctan(f(x)) = f'(0)x + C$, where $C$ is a constant. Since $f(0) = 0$, we have $C = 0$. Thus, $f(x) = \\tan(f'(0)x)$.\n\n## Step 9: Verify that the solution satisfies the original functional equation.\nSubstituting $f(x) = \\tan(f'(0)x)$ into the original equation: $\\tan(f'(0)(x+y)) = \\frac{\\tan(f'(0)x) + \\tan(f'(0)y)}{1 - \\tan(f'(0)x)\\tan(f'(0)y)}$, which is a known trigonometric identity, thus verifying that $f(x) = \\tan(f'(0)x)$ is a solution.\n\n## Step 10: Check if there are any constraints on $f'(0)$.\nFor $f(x) = \\tan(f'(0)x)$ to be defined for all $x \\in \\mathbb{R}$, $f'(0)$ must be $0$, otherwise, $f(x)$ will have discontinuities. If $f'(0) = 0$, then $f(x) = 0$ for all $x$, which is indeed a solution.\n\n## Step 11: Formulate the final problem and solution.\nLet's formulate the problem: \"Find all $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for all $x, y \\in \\mathbb{R}$.\"\n\n\nFind all $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for all $x, y \\in \\mathbb{R}$.",
    "run_id": "16",
    "topic_slug": "real_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The question as stated is **ill\u2011posed**. It asks to find all functions $f:\\mathbb{R}\\to\\mathbb{R}$ satisfying  \n$$\nf(x+y)=\\frac{f(x)+f(y)}{1-f(x)f(y)}\\qquad\\forall x,y\\in\\mathbb{R},\n$$  \nbut does **not** impose any regularity conditions (such as continuity, measurability, boundedness on an interval, etc.). Without such conditions the solution set is enormous and cannot be described in a simple closed form; any attempt to \u201cfind all\u201d would require an unmanageable classification via the axiom of choice.\n\n### Why the question is ill\u2011posed\n\n1. **Trivial necessary conditions**  \n   From the equation one easily deduces $f(0)=0$ and $f(-x)=-f(x)$. However, these are far from sufficient.\n\n2. **Existence of exotic solutions**  \n   Let $A:\\mathbb{R}\\to\\mathbb{R}$ be any additive function (i.e. $A(x+y)=A(x)+A(y)$ for all $x,y$) whose image is contained in a $\\mathbb{Q}$-linear subspace that avoids the set  \n   $$\n   S=\\bigl\\{\\tfrac{\\pi}{2}+k\\pi\\mid k\\in\\mathbb{Z}\\bigr\\}.\n   $$  \n   (For example, take a Hamel basis of $\\mathbb{R}$ over $\\mathbb{Q}$, pick one basis element $e_0$, and define $A(x)$ as the coefficient of $e_0$ in the representation of $x$; then $A(x)\\in\\mathbb{Q}$ for all $x$, and $\\mathbb{Q}\\cap S=\\varnothing$.)  \n   Then the function  \n   $$\n   f(x)=\\tan(A(x))\n   $$  \n   is well defined on $\\mathbb{R}$ (because $A(x)\\notin S$) and satisfies the given functional equation. Indeed,  \n   $$\n   f(x+y)=\\tan(A(x+y))=\\tan(A(x)+A(y))=\\frac{\\tan(A(x))+\\tan(A(y))}{1-\\tan(A(x))\\tan(A(y))}=\\frac{f(x)+f(y)}{1-f(x)f(y)}.\n   $$  \n   Moreover, the denominator never vanishes because $A(x)+A(y)=A(x+y)\\notin S$.\n\n   Such additive functions exist in ZFC but are highly pathological (discontinuous, non\u2011measurable, unbounded on every interval). Consequently there are infinitely many non\u2011zero solutions, and they cannot be expressed by elementary formulas.\n\n3. **Lack of a simple classification**  \n   The most general description of all solutions is:  \n   *Let $\\varphi(x)=\\arctan(f(x))\\in(-\\pi/2,\\pi/2)$. Then the map $x\\mapsto\\varphi(x)+\\pi\\mathbb{Z}$ is a group homomorphism from $\\mathbb{R}$ into $\\mathbb{R}/\\pi\\mathbb{Z}$. Conversely, any such homomorphism (with the additional requirement that the chosen representatives avoid $S$) yields a solution.*  \n   This characterization relies on the axiom of choice and does not provide a concrete list of functions. Hence the problem is **underspecified** \u2013 it misses necessary constraints that would restrict the solutions to a tractable set.\n\n### How to make the question well\u2011posed\n\nAdd a natural regularity assumption, for example:\n\n* \u201cFind all **continuous** functions $f:\\mathbb{R}\\to\\mathbb{R}$ satisfying \u2026\u201d  \n* \u201cFind all **measurable** functions \u2026\u201d  \n* \u201cFind all functions **bounded on some interval** \u2026\u201d\n\nUnder any such condition the only solution is the trivial one $f(x)\\equiv 0$. (Sketch: continuity forces the additive function $A$ to be linear, $A(x)=cx$; then $f(x)=\\tan(cx)$ must be defined for all real $x$, which forces $c=0$.)\n\n---\n\n**Conclusion:** The original question is ill\u2011posed due to missing constraints. It cannot be answered in a meaningful elementary way without further assumptions on $f$.",
        "raw_answer": "The question as stated is **ill\u2011posed**. It asks to find all functions \\(f:\\mathbb{R}\\to\\mathbb{R}\\) satisfying  \n\\[\nf(x+y)=\\frac{f(x)+f(y)}{1-f(x)f(y)}\\qquad\\forall x,y\\in\\mathbb{R},\n\\]  \nbut does **not** impose any regularity conditions (such as continuity, measurability, boundedness on an interval, etc.). Without such conditions the solution set is enormous and cannot be described in a simple closed form; any attempt to \u201cfind all\u201d would require an unmanageable classification via the axiom of choice.\n\n### Why the question is ill\u2011posed\n\n1. **Trivial necessary conditions**  \n   From the equation one easily deduces \\(f(0)=0\\) and \\(f(-x)=-f(x)\\). However, these are far from sufficient.\n\n2. **Existence of exotic solutions**  \n   Let \\(A:\\mathbb{R}\\to\\mathbb{R}\\) be any additive function (i.e. \\(A(x+y)=A(x)+A(y)\\) for all \\(x,y\\)) whose image is contained in a \\(\\mathbb{Q}\\)-linear subspace that avoids the set  \n   \\[\n   S=\\bigl\\{\\tfrac{\\pi}{2}+k\\pi\\mid k\\in\\mathbb{Z}\\bigr\\}.\n   \\]  \n   (For example, take a Hamel basis of \\(\\mathbb{R}\\) over \\(\\mathbb{Q}\\), pick one basis element \\(e_0\\), and define \\(A(x)\\) as the coefficient of \\(e_0\\) in the representation of \\(x\\); then \\(A(x)\\in\\mathbb{Q}\\) for all \\(x\\), and \\(\\mathbb{Q}\\cap S=\\varnothing\\).)  \n   Then the function  \n   \\[\n   f(x)=\\tan(A(x))\n   \\]  \n   is well defined on \\(\\mathbb{R}\\) (because \\(A(x)\\notin S\\)) and satisfies the given functional equation. Indeed,  \n   \\[\n   f(x+y)=\\tan(A(x+y))=\\tan(A(x)+A(y))=\\frac{\\tan(A(x))+\\tan(A(y))}{1-\\tan(A(x))\\tan(A(y))}=\\frac{f(x)+f(y)}{1-f(x)f(y)}.\n   \\]  \n   Moreover, the denominator never vanishes because \\(A(x)+A(y)=A(x+y)\\notin S\\).\n\n   Such additive functions exist in ZFC but are highly pathological (discontinuous, non\u2011measurable, unbounded on every interval). Consequently there are infinitely many non\u2011zero solutions, and they cannot be expressed by elementary formulas.\n\n3. **Lack of a simple classification**  \n   The most general description of all solutions is:  \n   *Let \\(\\varphi(x)=\\arctan(f(x))\\in(-\\pi/2,\\pi/2)\\). Then the map \\(x\\mapsto\\varphi(x)+\\pi\\mathbb{Z}\\) is a group homomorphism from \\(\\mathbb{R}\\) into \\(\\mathbb{R}/\\pi\\mathbb{Z}\\). Conversely, any such homomorphism (with the additional requirement that the chosen representatives avoid \\(S\\)) yields a solution.*  \n   This characterization relies on the axiom of choice and does not provide a concrete list of functions. Hence the problem is **underspecified** \u2013 it misses necessary constraints that would restrict the solutions to a tractable set.\n\n### How to make the question well\u2011posed\n\nAdd a natural regularity assumption, for example:\n\n* \u201cFind all **continuous** functions \\(f:\\mathbb{R}\\to\\mathbb{R}\\) satisfying \u2026\u201d  \n* \u201cFind all **measurable** functions \u2026\u201d  \n* \u201cFind all functions **bounded on some interval** \u2026\u201d\n\nUnder any such condition the only solution is the trivial one \\(f(x)\\equiv 0\\). (Sketch: continuity forces the additive function \\(A\\) to be linear, \\(A(x)=cx\\); then \\(f(x)=\\tan(cx)\\) must be defined for all real \\(x\\), which forces \\(c=0\\).)\n\n---\n\n**Conclusion:** The original question is ill\u2011posed due to missing constraints. It cannot be answered in a meaningful elementary way without further assumptions on \\(f\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $f: [0,1] \\to \\mathbb{R}$ be a bounded measurable function. Prove that $\\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) dx = 0$.",
    "run_id": "17",
    "topic_slug": "measure_and_integration",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove that for any bounded measurable function $f:[0,1]\\to\\mathbb{R}$,\n\n$$\n\\lim_{n\\to\\infty}\\int_0^1 f(x)\\sin(nx)\\,dx = 0.\n$$\n\nThe argument proceeds in three steps: first we show the limit is zero for step functions (piecewise constant on intervals), then for continuous functions (by uniform approximation with step functions), and finally for the given $f$ (by $L^1$ approximation with continuous functions).\n\n---\n\n### Step 1. Step functions\n\nLet $\\varphi$ be a step function on $[0,1]$, i.e., there exist a partition $0 = a_0 < a_1 < \\dots < a_m = 1$ and constants $c_1,\\dots,c_m$ such that $\\varphi(x) = c_i$ for $x\\in (a_{i-1},a_i)$ (the endpoints have measure zero and do not affect the integral). Then\n\n$$\n\\int_0^1 \\varphi(x)\\sin(nx)\\,dx = \\sum_{i=1}^m c_i \\int_{a_{i-1}}^{a_i} \\sin(nx)\\,dx\n= \\sum_{i=1}^m c_i\\,\\frac{\\cos(na_{i-1})-\\cos(na_i)}{n}.\n$$\n\nHence\n\n$$\n\\left|\\int_0^1 \\varphi(x)\\sin(nx)\\,dx\\right|\n\\le \\sum_{i=1}^m |c_i|\\,\\frac{|\\cos(na_{i-1})-\\cos(na_i)|}{n}\n\\le \\frac{2}{n}\\sum_{i=1}^m |c_i|.\n$$\n\nSince $\\sum_{i=1}^m |c_i|$ is a constant independent of $n$, the right\u2011hand side tends to $0$ as $n\\to\\infty$. Therefore\n\n$$\n\\lim_{n\\to\\infty}\\int_0^1 \\varphi(x)\\sin(nx)\\,dx = 0.\n$$\n\n---\n\n### Step 2. Continuous functions\n\nLet $g\\in C([0,1])$. Because $g$ is uniformly continuous on the compact interval $[0,1]$, for any $\\varepsilon>0$ we can choose $\\delta>0$ such that $|x-y|<\\delta$ implies $|g(x)-g(y)|<\\varepsilon$. Partition $[0,1]$ into subintervals $I_i=[x_{i-1},x_i]$ of length less than $\\delta$ and define a step function $\\psi$ by\n\n$$\n\\psi(x)=g(x_{i-1})\\quad\\text{for } x\\in I_i.\n$$\n\nThen $\\sup_{x\\in[0,1]}|g(x)-\\psi(x)|<\\varepsilon$, and consequently\n\n$$\n\\int_0^1|g(x)-\\psi(x)|\\,dx \\le \\varepsilon.\n$$\n\nNow estimate the integral of $g$:\n\n$$\n\\left|\\int_0^1 g(x)\\sin(nx)\\,dx\\right|\n\\le \\left|\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\right| + \\int_0^1|g-\\psi|\\,dx\n< \\left|\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\right| + \\varepsilon.\n$$\n\nFrom Step 1, $\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\to 0$ as $n\\to\\infty$. Hence there exists $N$ such that for all $n>N$,\n\n$$\n\\left|\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\right| < \\varepsilon.\n$$\n\nFor those $n$ we obtain\n\n$$\n\\left|\\int_0^1 g(x)\\sin(nx)\\,dx\\right| < 2\\varepsilon.\n$$\n\nSince $\\varepsilon>0$ was arbitrary, we conclude\n\n$$\n\\lim_{n\\to\\infty}\\int_0^1 g(x)\\sin(nx)\\,dx = 0.\n$$\n\n---\n\n### Step 3. Approximation of $f$ by continuous functions\n\nBecause $f$ is bounded and measurable on $[0,1]$, it belongs to $L^1([0,1])$. It is a standard fact that continuous functions are dense in $L^1([0,1])$; one can for instance use Lusin\u2019s theorem together with Tietze\u2019s extension theorem. More concretely: let $M=\\sup_{x\\in[0,1]}|f(x)|$ (finite by boundedness). Given $\\varepsilon>0$, Lusin\u2019s theorem provides a closed set $F\\subseteq[0,1]$ such that $m([0,1]\\setminus F)<\\varepsilon/(2M)$ and $f|_F$ is continuous. By Tietze\u2019s extension theorem, there exists a continuous function $g:[0,1]\\to\\mathbb{R}$ with $g|_F=f|_F$ and $|g(x)|\\le M$ for all $x$. Then\n\n$$\n\\int_0^1|f(x)-g(x)|\\,dx = \\int_{[0,1]\\setminus F}|f(x)-g(x)|\\,dx\n\\le 2M\\cdot m([0,1]\\setminus F) < \\varepsilon.\n$$\n\nThus for any $\\varepsilon>0$ we can find a continuous function $g$ with $\\|f-g\\|_{L^1}<\\varepsilon$.\n\nNow fix $\\varepsilon>0$ and choose a continuous $g$ such that $\\int_0^1|f-g|<\\varepsilon/2$. By Step 2 there exists $N$ such that for all $n>N$,\n\n$$\n\\left|\\int_0^1 g(x)\\sin(nx)\\,dx\\right| < \\frac{\\varepsilon}{2}.\n$$\n\nThen for $n>N$,\n\n$$\n\\left|\\int_0^1 f(x)\\sin(nx)\\,dx\\right|\n\\le \\left|\\int_0^1 g(x)\\sin(nx)\\,dx\\right| + \\int_0^1|f(x)-g(x)|\\,dx\n< \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon.\n$$\n\nSince $\\varepsilon$ is arbitrary, this proves\n\n$$\n\\lim_{n\\to\\infty}\\int_0^1 f(x)\\sin(nx)\\,dx = 0.\n$$\n\n---\n\n**Remark.** The same argument works for any $f\\in L^1([0,1])$; the boundedness hypothesis is only used to guarantee that $f$ is integrable and to simplify the approximation by a continuous function (though density of continuous functions in $L^1$ holds without boundedness). The result is a special case of the Riemann\u2013Lebesgue lemma.",
        "raw_answer": "We prove that for any bounded measurable function \\(f:[0,1]\\to\\mathbb{R}\\),\n\n\\[\n\\lim_{n\\to\\infty}\\int_0^1 f(x)\\sin(nx)\\,dx = 0.\n\\]\n\nThe argument proceeds in three steps: first we show the limit is zero for step functions (piecewise constant on intervals), then for continuous functions (by uniform approximation with step functions), and finally for the given \\(f\\) (by \\(L^1\\) approximation with continuous functions).\n\n---\n\n### Step 1. Step functions\n\nLet \\(\\varphi\\) be a step function on \\([0,1]\\), i.e., there exist a partition \\(0 = a_0 < a_1 < \\dots < a_m = 1\\) and constants \\(c_1,\\dots,c_m\\) such that \\(\\varphi(x) = c_i\\) for \\(x\\in (a_{i-1},a_i)\\) (the endpoints have measure zero and do not affect the integral). Then\n\n\\[\n\\int_0^1 \\varphi(x)\\sin(nx)\\,dx = \\sum_{i=1}^m c_i \\int_{a_{i-1}}^{a_i} \\sin(nx)\\,dx\n= \\sum_{i=1}^m c_i\\,\\frac{\\cos(na_{i-1})-\\cos(na_i)}{n}.\n\\]\n\nHence\n\n\\[\n\\left|\\int_0^1 \\varphi(x)\\sin(nx)\\,dx\\right|\n\\le \\sum_{i=1}^m |c_i|\\,\\frac{|\\cos(na_{i-1})-\\cos(na_i)|}{n}\n\\le \\frac{2}{n}\\sum_{i=1}^m |c_i|.\n\\]\n\nSince \\(\\sum_{i=1}^m |c_i|\\) is a constant independent of \\(n\\), the right\u2011hand side tends to \\(0\\) as \\(n\\to\\infty\\). Therefore\n\n\\[\n\\lim_{n\\to\\infty}\\int_0^1 \\varphi(x)\\sin(nx)\\,dx = 0.\n\\]\n\n---\n\n### Step 2. Continuous functions\n\nLet \\(g\\in C([0,1])\\). Because \\(g\\) is uniformly continuous on the compact interval \\([0,1]\\), for any \\(\\varepsilon>0\\) we can choose \\(\\delta>0\\) such that \\(|x-y|<\\delta\\) implies \\(|g(x)-g(y)|<\\varepsilon\\). Partition \\([0,1]\\) into subintervals \\(I_i=[x_{i-1},x_i]\\) of length less than \\(\\delta\\) and define a step function \\(\\psi\\) by\n\n\\[\n\\psi(x)=g(x_{i-1})\\quad\\text{for } x\\in I_i.\n\\]\n\nThen \\(\\sup_{x\\in[0,1]}|g(x)-\\psi(x)|<\\varepsilon\\), and consequently\n\n\\[\n\\int_0^1|g(x)-\\psi(x)|\\,dx \\le \\varepsilon.\n\\]\n\nNow estimate the integral of \\(g\\):\n\n\\[\n\\left|\\int_0^1 g(x)\\sin(nx)\\,dx\\right|\n\\le \\left|\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\right| + \\int_0^1|g-\\psi|\\,dx\n< \\left|\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\right| + \\varepsilon.\n\\]\n\nFrom Step 1, \\(\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\to 0\\) as \\(n\\to\\infty\\). Hence there exists \\(N\\) such that for all \\(n>N\\),\n\n\\[\n\\left|\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\right| < \\varepsilon.\n\\]\n\nFor those \\(n\\) we obtain\n\n\\[\n\\left|\\int_0^1 g(x)\\sin(nx)\\,dx\\right| < 2\\varepsilon.\n\\]\n\nSince \\(\\varepsilon>0\\) was arbitrary, we conclude\n\n\\[\n\\lim_{n\\to\\infty}\\int_0^1 g(x)\\sin(nx)\\,dx = 0.\n\\]\n\n---\n\n### Step 3. Approximation of \\(f\\) by continuous functions\n\nBecause \\(f\\) is bounded and measurable on \\([0,1]\\), it belongs to \\(L^1([0,1])\\). It is a standard fact that continuous functions are dense in \\(L^1([0,1])\\); one can for instance use Lusin\u2019s theorem together with Tietze\u2019s extension theorem. More concretely: let \\(M=\\sup_{x\\in[0,1]}|f(x)|\\) (finite by boundedness). Given \\(\\varepsilon>0\\), Lusin\u2019s theorem provides a closed set \\(F\\subseteq[0,1]\\) such that \\(m([0,1]\\setminus F)<\\varepsilon/(2M)\\) and \\(f|_F\\) is continuous. By Tietze\u2019s extension theorem, there exists a continuous function \\(g:[0,1]\\to\\mathbb{R}\\) with \\(g|_F=f|_F\\) and \\(|g(x)|\\le M\\) for all \\(x\\). Then\n\n\\[\n\\int_0^1|f(x)-g(x)|\\,dx = \\int_{[0,1]\\setminus F}|f(x)-g(x)|\\,dx\n\\le 2M\\cdot m([0,1]\\setminus F) < \\varepsilon.\n\\]\n\nThus for any \\(\\varepsilon>0\\) we can find a continuous function \\(g\\) with \\(\\|f-g\\|_{L^1}<\\varepsilon\\).\n\nNow fix \\(\\varepsilon>0\\) and choose a continuous \\(g\\) such that \\(\\int_0^1|f-g|<\\varepsilon/2\\). By Step 2 there exists \\(N\\) such that for all \\(n>N\\),\n\n\\[\n\\left|\\int_0^1 g(x)\\sin(nx)\\,dx\\right| < \\frac{\\varepsilon}{2}.\n\\]\n\nThen for \\(n>N\\),\n\n\\[\n\\left|\\int_0^1 f(x)\\sin(nx)\\,dx\\right|\n\\le \\left|\\int_0^1 g(x)\\sin(nx)\\,dx\\right| + \\int_0^1|f(x)-g(x)|\\,dx\n< \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon.\n\\]\n\nSince \\(\\varepsilon\\) is arbitrary, this proves\n\n\\[\n\\lim_{n\\to\\infty}\\int_0^1 f(x)\\sin(nx)\\,dx = 0.\n\\]\n\n---\n\n**Remark.** The same argument works for any \\(f\\in L^1([0,1])\\); the boundedness hypothesis is only used to guarantee that \\(f\\) is integrable and to simplify the approximation by a continuous function (though density of continuous functions in \\(L^1\\) holds without boundedness). The result is a special case of the Riemann\u2013Lebesgue lemma.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of \"Functions of a complex variable\" along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the domain and requirements\nThe domain is \"Functions of a complex variable.\" This involves complex analysis, including topics like analytic functions, contour integration, and possibly properties of specific functions like the exponential or logarithmic function in the complex plane.\n\n## Step 3: Generate a problem\nTo create a challenging problem, we should consider a topic that requires a good understanding of complex analysis. One such topic is contour integration and the application of Cauchy's Integral Formula or the Residue Theorem.\n\n## Step 4: Formulate the problem\nLet's consider a problem that involves evaluating a contour integral using the Residue Theorem, which is a fundamental technique in complex analysis.\n\n## Step 5: Specify the problem\nThe problem could be: \"Evaluate the integral $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, where the contour $|z| = 2$ is traversed in the positive direction.\"\n\n## Step 6: Provide the solution\nTo solve $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, first identify the singularities of the integrand within the contour $|z| = 2$. The singularities occur at $z = \\pm i$, both of which are inside $|z| = 2$ since $|i| = |-i| = 1 < 2$.\n\n## Step 7: Apply the Residue Theorem\nThe Residue Theorem states that $\\oint_C f(z) dz = 2\\pi i \\sum \\text{Res}(f, z_j)$, where $z_j$ are the singularities enclosed by $C$. We need to calculate the residues at $z = i$ and $z = -i$.\n\n## Step 8: Calculate the residue at $z = i$\nThe residue of $\\frac{e^z}{z^2 + 1}$ at $z = i$ can be found using the formula for simple poles: $\\text{Res}(f, z_0) = \\lim_{z \\to z_0} (z - z_0)f(z)$. So, $\\text{Res}(f, i) = \\lim_{z \\to i} (z - i)\\frac{e^z}{(z - i)(z + i)} = \\lim_{z \\to i} \\frac{e^z}{z + i} = \\frac{e^i}{2i}$.\n\n## Step 9: Calculate the residue at $z = -i$\nSimilarly, $\\text{Res}(f, -i) = \\lim_{z \\to -i} (z + i)\\frac{e^z}{(z + i)(z - i)} = \\lim_{z \\to -i} \\frac{e^z}{z - i} = \\frac{e^{-i}}{-2i}$.\n\n## Step 10: Sum the residues and apply the Residue Theorem\n$\\sum \\text{Res} = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i} = \\sin(1)$, because $e^i - e^{-i} = 2i\\sin(1)$.\n\n## Step 11: Calculate the integral\n$\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz = 2\\pi i \\sin(1)$.\n\n## Step 12: Write the final answer in the required format\n\nEvaluate the integral $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, where the contour $|z| = 2$ is traversed in the positive direction.",
    "run_id": "18",
    "topic_slug": "functions_of_a_complex_variable",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe evaluate the contour integral\n\n$$\nI = \\oint_{|z|=2} \\frac{e^z}{z^2+1}\\,dz,\n$$\n\nwhere the circle $|z|=2$ is traversed in the positive (counter\u2011clockwise) direction.\n\n---\n\n### 1. Singularities of the integrand\n\nThe function $f(z) = \\dfrac{e^z}{z^2+1}$ is meromorphic on $\\mathbb{C}$. Its singularities occur at the zeros of the denominator:\n\n$$\nz^2+1 = 0 \\quad\\Longrightarrow\\quad z = i,\\; z = -i.\n$$\n\nBoth points are **simple poles** because the denominator has simple zeros at these points and the numerator $e^z$ (which is entire) is non\u2011zero there ($e^{\\pm i} \\neq 0$).\n\n---\n\n### 2. Location relative to the contour\n\nThe contour is the circle $|z| = 2$ centered at the origin with radius $2$. Since\n\n$$\n|i| = 1 < 2 \\qquad\\text{and}\\qquad |-i| = 1 < 2,\n$$\n\nboth singularities lie **inside** the contour.\n\n---\n\n### 3. Residues at the poles\n\nFor a simple pole at $z = z_0$, the residue is\n\n$$\n\\operatorname{Res}(f, z_0) = \\lim_{z\\to z_0} (z - z_0) f(z).\n$$\n\n- **At $z = i$:**\n\n$$\n\\operatorname{Res}(f, i) = \\lim_{z\\to i} (z-i)\\,\\frac{e^z}{(z-i)(z+i)} = \\lim_{z\\to i} \\frac{e^z}{z+i} = \\frac{e^i}{2i}.\n$$\n\n- **At $z = -i$:**\n\n$$\n\\operatorname{Res}(f, -i) = \\lim_{z\\to -i} (z+i)\\,\\frac{e^z}{(z+i)(z-i)} = \\lim_{z\\to -i} \\frac{e^z}{z-i} = \\frac{e^{-i}}{-2i} = -\\frac{e^{-i}}{2i}.\n$$\n\n---\n\n### 4. Sum of residues\n\n$$\n\\operatorname{Res}(f, i) + \\operatorname{Res}(f, -i) = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i}.\n$$\n\nRecall the identity $\\sin w = \\dfrac{e^{iw} - e^{-iw}}{2i}$. With $w = 1$ (since the exponent is $i\\cdot 1$), we have\n\n$$\n\\sin(1) = \\frac{e^{i} - e^{-i}}{2i}.\n$$\n\nHence the sum of residues equals $\\sin(1)$.\n\n---\n\n### 5. Application of the Residue Theorem\n\nThe Residue Theorem states that for a positively oriented simple closed contour $C$ and a function $f$ analytic on and inside $C$ except for a finite number of isolated singularities $z_k$ inside $C$,\n\n$$\n\\oint_C f(z)\\,dz = 2\\pi i \\sum_k \\operatorname{Res}(f, z_k).\n$$\n\nApplying it here gives\n\n$$\nI = 2\\pi i \\cdot \\bigl(\\operatorname{Res}(f, i) + \\operatorname{Res}(f, -i)\\bigr) = 2\\pi i \\cdot \\sin(1).\n$$\n\n---\n\n### 6. Final answer\n\n$$\n\\boxed{2\\pi i \\sin(1)}.\n$$",
        "raw_answer": "**Solution**\n\nWe evaluate the contour integral\n\n\\[\nI = \\oint_{|z|=2} \\frac{e^z}{z^2+1}\\,dz,\n\\]\n\nwhere the circle \\(|z|=2\\) is traversed in the positive (counter\u2011clockwise) direction.\n\n---\n\n### 1. Singularities of the integrand\n\nThe function \\(f(z) = \\dfrac{e^z}{z^2+1}\\) is meromorphic on \\(\\mathbb{C}\\). Its singularities occur at the zeros of the denominator:\n\n\\[\nz^2+1 = 0 \\quad\\Longrightarrow\\quad z = i,\\; z = -i.\n\\]\n\nBoth points are **simple poles** because the denominator has simple zeros at these points and the numerator \\(e^z\\) (which is entire) is non\u2011zero there (\\(e^{\\pm i} \\neq 0\\)).\n\n---\n\n### 2. Location relative to the contour\n\nThe contour is the circle \\(|z| = 2\\) centered at the origin with radius \\(2\\). Since\n\n\\[\n|i| = 1 < 2 \\qquad\\text{and}\\qquad |-i| = 1 < 2,\n\\]\n\nboth singularities lie **inside** the contour.\n\n---\n\n### 3. Residues at the poles\n\nFor a simple pole at \\(z = z_0\\), the residue is\n\n\\[\n\\operatorname{Res}(f, z_0) = \\lim_{z\\to z_0} (z - z_0) f(z).\n\\]\n\n- **At \\(z = i\\):**\n\n\\[\n\\operatorname{Res}(f, i) = \\lim_{z\\to i} (z-i)\\,\\frac{e^z}{(z-i)(z+i)} = \\lim_{z\\to i} \\frac{e^z}{z+i} = \\frac{e^i}{2i}.\n\\]\n\n- **At \\(z = -i\\):**\n\n\\[\n\\operatorname{Res}(f, -i) = \\lim_{z\\to -i} (z+i)\\,\\frac{e^z}{(z+i)(z-i)} = \\lim_{z\\to -i} \\frac{e^z}{z-i} = \\frac{e^{-i}}{-2i} = -\\frac{e^{-i}}{2i}.\n\\]\n\n---\n\n### 4. Sum of residues\n\n\\[\n\\operatorname{Res}(f, i) + \\operatorname{Res}(f, -i) = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i}.\n\\]\n\nRecall the identity \\(\\sin w = \\dfrac{e^{iw} - e^{-iw}}{2i}\\). With \\(w = 1\\) (since the exponent is \\(i\\cdot 1\\)), we have\n\n\\[\n\\sin(1) = \\frac{e^{i} - e^{-i}}{2i}.\n\\]\n\nHence the sum of residues equals \\(\\sin(1)\\).\n\n---\n\n### 5. Application of the Residue Theorem\n\nThe Residue Theorem states that for a positively oriented simple closed contour \\(C\\) and a function \\(f\\) analytic on and inside \\(C\\) except for a finite number of isolated singularities \\(z_k\\) inside \\(C\\),\n\n\\[\n\\oint_C f(z)\\,dz = 2\\pi i \\sum_k \\operatorname{Res}(f, z_k).\n\\]\n\nApplying it here gives\n\n\\[\nI = 2\\pi i \\cdot \\bigl(\\operatorname{Res}(f, i) + \\operatorname{Res}(f, -i)\\bigr) = 2\\pi i \\cdot \\sin(1).\n\\]\n\n---\n\n### 6. Final answer\n\n\\[\n\\boxed{2\\pi i \\sin(1)}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Potential theory, along with a complete and verifiable solution. Potential theory is a branch of mathematics that deals with the study of potentials and their properties, particularly in relation to partial differential equations, especially Laplace's equation.\n\n## Step 2: Identify key concepts in Potential theory\nPotential theory involves the study of harmonic functions, potentials (such as Newtonian or logarithmic potentials), and their applications. Key concepts include the Laplace equation ($\\Delta u = 0$), Poisson's equation ($\\Delta u = f$), and boundary value problems (Dirichlet and Neumann problems).\n\n## Step 3: Formulate a problem\nTo create a challenging problem, we need to involve some of the advanced concepts or techniques from Potential theory. Let's consider a problem involving the Dirichlet problem for the Laplace equation on a specific domain.\n\n## Step 4: Specify the problem\nLet's consider the following problem: \"Let $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.\"\n\n## Step 5: Provide the solution\nTo solve this problem, we can use the Poisson integral formula, which gives the solution to the Dirichlet problem on the unit disk. The Poisson integral formula is given by $u(x) = \\frac{1}{2\\pi} \\int_{\\partial D} \\frac{1 - |x|^2}{|x - y|^2} f(y) ds(y)$, where $f(y)$ is the boundary data.\n\n## Step 6: Apply the Poisson integral formula\nFor $x = (r\\cos\\theta, r\\sin\\theta)$ and $y = (\\cos\\phi, \\sin\\phi)$, we have $|x - y|^2 = r^2 - 2r\\cos(\\theta - \\phi) + 1$ and $ds(y) = d\\phi$. The boundary data is $f(y) = \\log|y - (1,0)| = \\log\\sqrt{2 - 2\\cos\\phi}$. So, $u(x) = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} \\frac{1 - r^2}{r^2 - 2r\\cos(\\theta - \\phi) + 1} \\log\\sqrt{2 - 2\\cos\\phi} d\\phi$.\n\n## Step 7: Simplify the integral\nThe integral can be simplified by recognizing that $\\log\\sqrt{2 - 2\\cos\\phi} = \\log|1 - e^{i\\phi}| = \\log|1 - e^{i\\phi}| = \\Re(\\log(1 - e^{i\\phi}))$. However, directly evaluating this integral is complex and typically involves recognizing it as a special case that can be related to the properties of harmonic functions and the Poisson kernel.\n\n## Step 8: Evaluate the solution using properties of harmonic functions\nFor $x \\in D$, the solution can be found by directly applying properties of harmonic functions and recognizing that the given boundary condition corresponds to a specific harmonic function. The function $u(x) = \\log|x - (1,0)|$ is harmonic in $D$ except at $x = (1,0)$, which is outside $D$ since $|1,0| = 1$ is on $\\partial D$. Thus, we directly check if $u(x)$ satisfies the given boundary condition and is harmonic.\n\n## Step 9: Check if the given boundary data directly provides the solution\nSince $\\log|x - (1,0)|$ is harmonic in $D$ and equals $\\log|y - (1,0)|$ on $\\partial D$, it is the solution to the Dirichlet problem.\n\nThe final answer is: \n\nLet $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.",
    "run_id": "19",
    "topic_slug": "potential_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The problem as originally stated is ill\u2011posed for two reasons:\n\n1. The boundary condition $u(x)=\\log|x-(1,0)|$ is not defined at the boundary point $(1,0)$ because $\\log 0$ is undefined.\n2. Even if we require the condition only on $\\partial D\\setminus\\{(1,0)\\}$, the solution is not unique. For any constant $c$, the function  \n   $$u_c(x)=\\log|x-(1,0)|+c\\,\\frac{1-|x|^2}{|x-(1,0)|^2}$$  \n   is harmonic in $D$ and equals $\\log|x-(1,0)|$ on $\\partial D\\setminus\\{(1,0)\\}$ (since $1-|x|^2=0$ there). Hence infinitely many solutions exist.\n\nTo obtain a well\u2011posed problem we must add a condition that selects a unique solution. A natural choice, motivated by the behavior of the boundary data, is to require that $u$ does not have a singularity worse than logarithmic at $(1,0)$; precisely, that $u(x)-\\log|x-(1,0)|$ remains bounded as $x\\to(1,0)$ within $D$. Under this condition the problem becomes well\u2011posed and the unique solution is  \n\n$$u(x)=\\log|x-(1,0)|.$$\n\n---\n\n### Verification\n\n**Harmonicity.** For $x\\neq(1,0)$, the function $\\log|x-(1,0)|$ is the real part of the analytic function $\\log(z-1)$ (with $z=x_1+ix_2$ and a branch cut avoiding the unit disk), hence it is harmonic on $\\mathbb{R}^2\\setminus\\{(1,0)\\}$. Since $(1,0)\\notin D$, it is harmonic in $D$.\n\n**Boundary condition.** For every $y\\in\\partial D\\setminus\\{(1,0)\\}$, $u(y)=\\log|y-(1,0)|$ by definition. Moreover, $u$ is continuous on $\\overline{D}\\setminus\\{(1,0)\\}$, so the boundary values are attained as limits.\n\n**Growth condition.** Trivially, $u(x)-\\log|x-(1,0)|=0$, which is bounded.\n\n**Uniqueness.** Suppose $w$ is another harmonic function in $D$ satisfying  \n- $\\displaystyle\\lim_{x\\to y}w(x)=\\log|y-(1,0)|$ for all $y\\in\\partial D\\setminus\\{(1,0)\\}$,  \n- $w(x)-\\log|x-(1,0)|$ bounded as $x\\to(1,0)$.  \n\nDefine $h(x)=w(x)-u(x)$. Then $h$ is harmonic in $D$, bounded (because the difference is bounded near $(1,0)$ and $h\\to0$ on the rest of the boundary), and has radial limit $0$ at almost every boundary point (indeed everywhere except at the single point $(1,0)$). A bounded harmonic function in the unit disk is uniquely determined by its non\u2011tangential limits almost everywhere (Fatou\u2019s theorem). Since those limits are $0$ a.e., the Poisson integral of $0$ forces $h\\equiv0$. Hence $w=u$.\n\nThus, under the stated extra condition, the solution is unique and given by  \n\n$$\\boxed{u(x)=\\log|x-(1,0)|}.$$\n\n---\n\n**Remark.** If one instead interprets the problem in the sense of the Poisson integral (i.e., $u$ is the Poisson integral of the boundary function $\\log|y-(1,0)|$, which is integrable on $\\partial D$), the same formula results because the Poisson integral of that boundary function equals $\\log|x-(1,0)|$ for $|x|<1$.",
        "raw_answer": "The problem as originally stated is ill\u2011posed for two reasons:\n\n1. The boundary condition $u(x)=\\log|x-(1,0)|$ is not defined at the boundary point $(1,0)$ because $\\log 0$ is undefined.\n2. Even if we require the condition only on $\\partial D\\setminus\\{(1,0)\\}$, the solution is not unique. For any constant $c$, the function  \n   $$u_c(x)=\\log|x-(1,0)|+c\\,\\frac{1-|x|^2}{|x-(1,0)|^2}$$  \n   is harmonic in $D$ and equals $\\log|x-(1,0)|$ on $\\partial D\\setminus\\{(1,0)\\}$ (since $1-|x|^2=0$ there). Hence infinitely many solutions exist.\n\nTo obtain a well\u2011posed problem we must add a condition that selects a unique solution. A natural choice, motivated by the behavior of the boundary data, is to require that $u$ does not have a singularity worse than logarithmic at $(1,0)$; precisely, that $u(x)-\\log|x-(1,0)|$ remains bounded as $x\\to(1,0)$ within $D$. Under this condition the problem becomes well\u2011posed and the unique solution is  \n\n$$u(x)=\\log|x-(1,0)|.$$\n\n---\n\n### Verification\n\n**Harmonicity.** For $x\\neq(1,0)$, the function $\\log|x-(1,0)|$ is the real part of the analytic function $\\log(z-1)$ (with $z=x_1+ix_2$ and a branch cut avoiding the unit disk), hence it is harmonic on $\\mathbb{R}^2\\setminus\\{(1,0)\\}$. Since $(1,0)\\notin D$, it is harmonic in $D$.\n\n**Boundary condition.** For every $y\\in\\partial D\\setminus\\{(1,0)\\}$, $u(y)=\\log|y-(1,0)|$ by definition. Moreover, $u$ is continuous on $\\overline{D}\\setminus\\{(1,0)\\}$, so the boundary values are attained as limits.\n\n**Growth condition.** Trivially, $u(x)-\\log|x-(1,0)|=0$, which is bounded.\n\n**Uniqueness.** Suppose $w$ is another harmonic function in $D$ satisfying  \n- $\\displaystyle\\lim_{x\\to y}w(x)=\\log|y-(1,0)|$ for all $y\\in\\partial D\\setminus\\{(1,0)\\}$,  \n- $w(x)-\\log|x-(1,0)|$ bounded as $x\\to(1,0)$.  \n\nDefine $h(x)=w(x)-u(x)$. Then $h$ is harmonic in $D$, bounded (because the difference is bounded near $(1,0)$ and $h\\to0$ on the rest of the boundary), and has radial limit $0$ at almost every boundary point (indeed everywhere except at the single point $(1,0)$). A bounded harmonic function in the unit disk is uniquely determined by its non\u2011tangential limits almost everywhere (Fatou\u2019s theorem). Since those limits are $0$ a.e., the Poisson integral of $0$ forces $h\\equiv0$. Hence $w=u$.\n\nThus, under the stated extra condition, the solution is unique and given by  \n\n$$\\boxed{u(x)=\\log|x-(1,0)|}.$$\n\n---\n\n**Remark.** If one instead interprets the problem in the sense of the Poisson integral (i.e., $u$ is the Poisson integral of the boundary function $\\log|y-(1,0)|$, which is integrable on $\\partial D$), the same formula results because the Poisson integral of that boundary function equals $\\log|x-(1,0)|$ for $|x|<1$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Several complex variables and analytic spaces\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify key concepts in the domain\nSeveral complex variables and analytic spaces involve the study of functions of multiple complex variables and the spaces on which these functions are defined. Key concepts include holomorphic functions, complex manifolds, analytic continuation, and various types of domains (e.g., domains of holomorphy, pseudoconvex domains).\n\n## Step 3: Formulate a problem\nTo create a problem, we need to focus on a specific aspect of several complex variables. Let's consider the concept of holomorphic functions on a domain in $\\mathbb{C}^n$. A potential problem could involve characterizing or analyzing the properties of such functions.\n\n## Step 4: Specify the problem\nLet's formulate a problem related to the extension of holomorphic functions. A well-known result in several complex variables is the Hartogs' extension theorem, which states that any holomorphic function defined on a domain in $\\mathbb{C}^n$ ($n > 1$) with a compact hole can be extended holomorphically to the whole domain. We can create a problem related to this concept.\n\n## Step 5: Create the problem statement\nConsider the domain $\\Omega = \\{z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1\\}$ and the subset $S = \\{z \\in \\Omega : |z_1| < \\frac{1}{2}\\}$. Let $f$ be a holomorphic function on $\\Omega \\setminus S$. Show that $f$ can be extended to a holomorphic function on $\\Omega$.\n\n## Step 6: Provide the solution\nTo solve this, we recognize that $\\Omega \\setminus S$ is not a compact hole in $\\Omega$, so we cannot directly apply Hartogs' theorem. However, we can analyze the problem by considering the properties of holomorphic functions in $\\mathbb{C}^2$ and the specific geometry of $\\Omega$ and $S$.\n\n## Step 7: Detail the solution\nFor $z = (z_1, z_2) \\in \\Omega \\setminus S$, $f(z)$ is holomorphic. We need to show that $f$ can be extended holomorphically to $\\Omega$. For any fixed $z_2$ with $|z_2| < 1$, $f(z_1, z_2)$ is holomorphic in $z_1$ for $\\frac{1}{2} \\leq |z_1| < 1$. By the principle of analytic continuation in one variable, if $f(z_1, z_2)$ is holomorphic for $|z_1| < 1$ except on a smaller disk, it can be extended. However, the direct application of Hartogs' theorem is not possible here due to the shape of $S$. Instead, we can use the fact that for each $z_2$, $f(\\cdot, z_2)$ can be extended to $|z_1| < 1$ because the singularity set is contained within $|z_1| \\leq \\frac{1}{2}$, and then apply Hartogs' theorem or a similar principle to conclude the extension is holomorphic in both variables.\n\n## Step 8: Write the problem and solution in the required format\n\nLet $\\Omega = \\{z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1\\}$ and $S = \\{z \\in \\Omega : |z_1| < \\frac{1}{2}\\}$. Suppose $f$ is a holomorphic function on $\\Omega \\setminus S$. Prove that $f$ can be extended to a holomorphic function on $\\Omega$.",
    "run_id": "20",
    "topic_slug": "several_complex_variables_and_analytic_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The question as stated is ill-posed.  \n\nIn several complex variables, a function is said to be holomorphic on a set only if that set is **open** (or at least each point has an open neighbourhood contained in the set where the function is complex\u2011differentiable).  Here  \n$$\n\\Omega = \\{z\\in\\mathbb{C}^2 : |z_1|<1,\\;|z_2|<1\\}\n$$  \nis open, but  \n$$\nS = \\{z\\in\\Omega : |z_1|<\\tfrac12\\}\n$$  \nis also open (as the pre\u2011image of $(-\\infty,\\tfrac12)$ under the continuous map $z\\mapsto|z_1|$).  Consequently, $\\Omega\\setminus S$ is the complement of an open set inside an open set and is **not open**.  For example, any point with $|z_1|=\\tfrac12$ lies in $\\Omega\\setminus S$, but every neighbourhood of such a point contains points with $|z_1|<\\tfrac12$, which belong to $S$ and not to $\\Omega\\setminus S$; hence $\\Omega\\setminus S$ has no interior at those points.  \n\nThe hypothesis \u201c$f$ is a holomorphic function on $\\Omega\\setminus S$\u201d is therefore not meaningful under the standard definition of holomorphicity.  One cannot speak of a function being holomorphic on a non\u2011open set without additional structure (e.g., requiring it to be holomorphic on the interior and perhaps continuous up to the boundary).  \n\nTo make the question well\u2011posed, one could either  \n- replace $S$ by a **closed** subset, e.g., $\\{z\\in\\Omega : |z_1|\\le \\tfrac12\\}$, so that $\\Omega\\setminus S$ becomes open, or  \n- explicitly require $f$ to be holomorphic on the interior of $\\Omega\\setminus S$ and continuous on $\\Omega\\setminus S$, and then ask for an extension to $\\Omega$.  \n\nAs it stands, the problem lacks a proper domain of holomorphy and cannot be answered without clarification.",
        "raw_answer": "The question as stated is ill-posed.  \n\nIn several complex variables, a function is said to be holomorphic on a set only if that set is **open** (or at least each point has an open neighbourhood contained in the set where the function is complex\u2011differentiable).  Here  \n\\[\n\\Omega = \\{z\\in\\mathbb{C}^2 : |z_1|<1,\\;|z_2|<1\\}\n\\]  \nis open, but  \n\\[\nS = \\{z\\in\\Omega : |z_1|<\\tfrac12\\}\n\\]  \nis also open (as the pre\u2011image of $(-\\infty,\\tfrac12)$ under the continuous map $z\\mapsto|z_1|$).  Consequently, $\\Omega\\setminus S$ is the complement of an open set inside an open set and is **not open**.  For example, any point with $|z_1|=\\tfrac12$ lies in $\\Omega\\setminus S$, but every neighbourhood of such a point contains points with $|z_1|<\\tfrac12$, which belong to $S$ and not to $\\Omega\\setminus S$; hence $\\Omega\\setminus S$ has no interior at those points.  \n\nThe hypothesis \u201c$f$ is a holomorphic function on $\\Omega\\setminus S$\u201d is therefore not meaningful under the standard definition of holomorphicity.  One cannot speak of a function being holomorphic on a non\u2011open set without additional structure (e.g., requiring it to be holomorphic on the interior and perhaps continuous up to the boundary).  \n\nTo make the question well\u2011posed, one could either  \n- replace $S$ by a **closed** subset, e.g., $\\{z\\in\\Omega : |z_1|\\le \\tfrac12\\}$, so that $\\Omega\\setminus S$ becomes open, or  \n- explicitly require $f$ to be holomorphic on the interior of $\\Omega\\setminus S$ and continuous on $\\Omega\\setminus S$, and then ask for an extension to $\\Omega$.  \n\nAs it stands, the problem lacks a proper domain of holomorphy and cannot be answered without clarification.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of special functions, along with a clear and detailed solution, following specific guidelines.\n[/QUESTION]",
    "run_id": "21",
    "topic_slug": "special_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem (Gamma and Beta functions)**  \n\n1. The Gamma function is defined for $\\operatorname{Re}(z) > 0$ by  \n   $$\n   \\Gamma(z) = \\int_0^\\infty t^{z-1} e^{-t} \\, dt.\n   $$\n   The Beta function is defined for $\\operatorname{Re}(a) > 0$, $\\operatorname{Re}(b) > 0$ by  \n   $$\n   B(a,b) = \\int_0^1 x^{a-1} (1-x)^{b-1} \\, dx.\n   $$\n\n   (a) Prove that  \n   $$\n   B(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}.\n   $$\n\n   (b) Show that for $0 < \\operatorname{Re}(z) < 1$,  \n   $$\n   B(z,1-z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt.\n   $$\n\n   (c) Evaluate the integral $\\displaystyle I(z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt$ for $0 < \\operatorname{Re}(z) < 1$ using a keyhole contour integration, and deduce Euler's reflection formula:  \n   $$\n   \\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)}.\n   $$\n\n   (d) Hence compute $\\Gamma\\bigl(\\tfrac{1}{2}\\bigr)$.\n\n---\n\n**Solution**\n\n**(a)**  \nWe start from the product of two Gamma functions:\n\n$$\n\\Gamma(a)\\Gamma(b) = \\int_0^\\infty \\int_0^\\infty x^{a-1} y^{b-1} e^{-(x+y)} \\, dx \\, dy, \\qquad \\operatorname{Re}(a)>0,\\; \\operatorname{Re}(b)>0.\n$$\n\nThe integrand is non\u2011negative and the integrals converge absolutely, so Fubini\u2019s theorem justifies the interchange of order.  \nIntroduce the change of variables  \n\n$$\nu = x + y, \\quad v = \\frac{x}{x+y} \\qquad \\Longleftrightarrow \\qquad x = uv,\\; y = u(1-v),\n$$\n\nwhich maps the domain $\\{(x,y): x>0,\\; y>0\\}$ bijectively onto $\\{(u,v): u>0,\\; 0<v<1\\}$.  \nThe Jacobian determinant is  \n\n$$\n\\frac{\\partial(x,y)}{\\partial(u,v)} = \\begin{vmatrix} v & u \\\\ 1-v & -u \\end{vmatrix} = -uv - u(1-v) = -u,\n$$\n\nhence $|J| = u$. Then  \n\n$$\n\\begin{aligned}\n\\Gamma(a)\\Gamma(b) &= \\int_0^\\infty \\int_0^1 (uv)^{a-1} \\bigl(u(1-v)\\bigr)^{b-1} e^{-u} \\; u \\, dv \\, du \\\\\n&= \\int_0^\\infty u^{a+b-1} e^{-u} \\, du \\int_0^1 v^{a-1} (1-v)^{b-1} \\, dv \\\\\n&= \\Gamma(a+b) \\, B(a,b).\n\\end{aligned}\n$$\n\nTherefore  \n\n$$\nB(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}.\n$$\n\n**(b)**  \nFor $0 < \\operatorname{Re}(z) < 1$ we have  \n\n$$\nB(z,1-z) = \\int_0^1 x^{z-1} (1-x)^{-z} \\, dx.\n$$\n\nPerform the substitution  \n\n$$\nx = \\frac{t}{1+t}, \\qquad t = \\frac{x}{1-x}, \\qquad dx = \\frac{dt}{(1+t)^2}.\n$$\n\nWhen $x \\to 0^+$, $t \\to 0$; when $x \\to 1^-$, $t \\to \\infty$. Also $1-x = \\frac{1}{1+t}$. Hence  \n\n$$\n\\begin{aligned}\nx^{z-1} (1-x)^{-z} \\, dx &= \\left(\\frac{t}{1+t}\\right)^{z-1} \\left(\\frac{1}{1+t}\\right)^{-z} \\frac{dt}{(1+t)^2} \\\\\n&= t^{z-1} (1+t)^{-(z-1)} (1+t)^{z} (1+t)^{-2} \\, dt \\\\\n&= \\frac{t^{z-1}}{1+t} \\, dt.\n\\end{aligned}\n$$\n\nThus  \n\n$$\nB(z,1-z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt.\n$$\n\nThe integral converges absolutely for $0 < \\operatorname{Re}(z) < 1$ because near $t=0$ the integrand behaves like $t^{\\operatorname{Re}(z)-1}$ (integrable when $\\operatorname{Re}(z)>0$) and as $t\\to\\infty$ it behaves like $t^{\\operatorname{Re}(z)-2}$ (integrable when $\\operatorname{Re}(z)<1$).\n\n**(c)**  \nLet  \n\n$$\nI(z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt, \\qquad 0 < \\operatorname{Re}(z) < 1.\n$$\n\nConsider the complex function  \n\n$$\nf(\\zeta) = \\frac{\\zeta^{z-1}}{1+\\zeta},\n$$\n\nwhere we define $\\zeta^{z-1} = e^{(z-1)\\log \\zeta}$ with the principal branch of the logarithm:  \n$\\log \\zeta = \\ln|\\zeta| + i\\arg\\zeta$, $0 < \\arg\\zeta < 2\\pi$. This makes $f$ analytic on $\\mathbb{C} \\setminus [0,\\infty)$ (branch cut along the positive real axis) and meromorphic with a simple pole at $\\zeta = -1$.\n\nWe integrate $f$ over a *keyhole contour* $\\gamma$ consisting of (see Figure 1):\n\n- $\\gamma_1$: a line segment just above the positive real axis from $r$ to $R$ (with $\\arg\\zeta = 0$),\n- $\\gamma_2$: a large circle of radius $R$ centred at the origin traversed counterclockwise,\n- $\\gamma_3$: a line segment just below the positive real axis from $R$ back to $r$ (with $\\arg\\zeta = 2\\pi$),\n- $\\gamma_4$: a small circle of radius $r$ around the origin traversed clockwise.\n\nWe choose $r < 1 < R$ so that the pole at $\\zeta = -1 = e^{i\\pi}$ lies inside the contour. The contour is positively oriented (counterclockwise overall). By the residue theorem,\n\n$$\n\\oint_\\gamma f(\\zeta) \\, d\\zeta = 2\\pi i \\; \\operatorname{Res}(f, -1).\n$$\n\n**Residue at $\\zeta = -1$:**  \n\n$$\n\\operatorname{Res}(f, -1) = \\lim_{\\zeta \\to -1} (\\zeta+1) f(\\zeta) = \\lim_{\\zeta \\to -1} \\zeta^{z-1} = (-1)^{z-1}.\n$$\n\nWith our branch, $\\arg(-1) = \\pi$, so $\\log(-1) = i\\pi$ and  \n\n$$\n(-1)^{z-1} = e^{(z-1)\\log(-1)} = e^{i\\pi(z-1)}.\n$$\n\n**Estimate on the large circle $\\gamma_2$:**  \nFor $|\\zeta| = R$,  \n\n$$\n|f(\\zeta)| = \\frac{|\\zeta^{z-1}|}{|1+\\zeta|} = \\frac{R^{\\operatorname{Re}(z)-1} e^{-\\operatorname{Im}(z)\\arg\\zeta}}{|1+Re^{i\\theta}|} \\le \\frac{R^{\\operatorname{Re}(z)-1}}{R-1} \\qquad (R>1).\n$$\n\nSince $\\operatorname{Re}(z) < 1$, $R^{\\operatorname{Re}(z)-2} \\to 0$ as $R \\to \\infty$. The length of $\\gamma_2$ is $2\\pi R$, hence  \n\n$$\n\\left|\\int_{\\gamma_2} f(\\zeta) \\, d\\zeta\\right| \\le \\frac{R^{\\operatorname{Re}(z)-1}}{R-1} \\cdot 2\\pi R \\sim 2\\pi R^{\\operatorname{Re}(z)} \\to 0 \\quad \\text{as } R\\to\\infty.\n$$\n\n**Estimate on the small circle $\\gamma_4$:**  \nFor $|\\zeta| = r$,  \n\n$$\n|f(\\zeta)| \\le \\frac{r^{\\operatorname{Re}(z)-1}}{1-r} \\qquad (r<1).\n$$\n\nBecause $\\operatorname{Re}(z) > 0$, $r^{\\operatorname{Re}(z)-1} \\to 0$ as $r \\to 0$. The length of $\\gamma_4$ is $2\\pi r$, so  \n\n$$\n\\left|\\int_{\\gamma_4} f(\\zeta) \\, d\\zeta\\right| \\le \\frac{r^{\\operatorname{Re}(z)-1}}{1-r} \\cdot 2\\pi r \\sim 2\\pi r^{\\operatorname{Re}(z)} \\to 0 \\quad \\text{as } r\\to 0.\n$$\n\nThus in the limits $R\\to\\infty$ and $r\\to 0$ the contributions from $\\gamma_2$ and $\\gamma_4$ vanish.\n\n**Integral on $\\gamma_1$:**  \nHere $\\arg\\zeta = 0$, $\\zeta = t$ (real), $t$ runs from $0$ to $\\infty$. Hence  \n\n$$\n\\int_{\\gamma_1} f(\\zeta) \\, d\\zeta = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = I(z).\n$$\n\n**Integral on $\\gamma_3$:**  \nOn the lower side of the cut we have $\\arg\\zeta = 2\\pi$, so $\\zeta = t e^{i2\\pi}$ with $t$ decreasing from $\\infty$ to $0$. Then  \n\n$$\n\\zeta^{z-1} = e^{(z-1)(\\ln t + i2\\pi)} = t^{z-1} e^{i2\\pi(z-1)},\n$$\n\nand $d\\zeta = e^{i2\\pi} dt = dt$. Therefore  \n\n$$\n\\int_{\\gamma_3} f(\\zeta) \\, d\\zeta = \\int_\\infty^0 \\frac{t^{z-1} e^{i2\\pi(z-1)}}{1+t} \\, dt = - e^{i2\\pi(z-1)} \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = - e^{i2\\pi(z-1)} I(z).\n$$\n\n**Summing the contributions:**  \nTaking the limits $R\\to\\infty$, $r\\to 0$, we obtain  \n\n$$\n\\oint_\\gamma f(\\zeta) \\, d\\zeta = I(z) - e^{i2\\pi(z-1)} I(z) = \\bigl(1 - e^{i2\\pi(z-1)}\\bigr) I(z).\n$$\n\nBy the residue theorem this equals $2\\pi i \\, e^{i\\pi(z-1)}$. Hence  \n\n$$\n\\bigl(1 - e^{i2\\pi(z-1)}\\bigr) I(z) = 2\\pi i \\, e^{i\\pi(z-1)}.\n$$\n\nNow simplify the left\u2011hand side:  \n\n$$\n1 - e^{i2\\pi(z-1)} = e^{i\\pi(z-1)}\\bigl(e^{-i\\pi(z-1)} - e^{i\\pi(z-1)}\\bigr) = e^{i\\pi(z-1)}\\bigl(-2i \\sin(\\pi(z-1))\\bigr).\n$$\n\nSince $\\sin(\\pi(z-1)) = -\\sin(\\pi z)$, we have  \n\n$$\n1 - e^{i2\\pi(z-1)} = e^{i\\pi(z-1)} \\cdot 2i \\sin(\\pi z).\n$$\n\nSubstituting,  \n\n$$\ne^{i\\pi(z-1)} \\cdot 2i \\sin(\\pi z) \\cdot I(z) = 2\\pi i \\, e^{i\\pi(z-1)}.\n$$\n\nCancelling the non\u2011zero factor $e^{i\\pi(z-1)}$ and $2i$ yields  \n\n$$\nI(z) = \\frac{\\pi}{\\sin(\\pi z)}.\n$$\n\nThus for $0 < \\operatorname{Re}(z) < 1$,  \n\n$$\n\\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = \\frac{\\pi}{\\sin(\\pi z)}.\n$$\n\nFrom part (b), $B(z,1-z) = I(z)$. From part (a) with $a=z$, $b=1-z$, and using $\\Gamma(1)=1$ (since $\\Gamma(1)=\\int_0^\\infty e^{-t}dt =1$), we obtain  \n\n$$\nB(z,1-z) = \\frac{\\Gamma(z)\\Gamma(1-z)}{\\Gamma(1)} = \\Gamma(z)\\Gamma(1-z).\n$$\n\nTherefore  \n\n$$\n\\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)} \\qquad (0 < \\operatorname{Re}(z) < 1).\n$$\n\nBy analytic continuation, the formula holds for all complex $z$ not an integer.\n\n**(d)**  \nSubstitute $z = \\frac{1}{2}$ into the reflection formula:\n\n$$\n\\Gamma\\!\\left(\\frac{1}{2}\\right) \\Gamma\\!\\left(1-\\frac{1}{2}\\right) = \\Gamma\\!\\left(\\frac{1}{2}\\right)^2 = \\frac{\\pi}{\\sin(\\pi/2)} = \\pi.\n$$\n\nBecause $\\Gamma(1/2) > 0$ (the integral definition shows it is positive), we conclude  \n\n$$\n\\Gamma\\!\\left(\\frac{1}{2}\\right) = \\sqrt{\\pi}.\n$$\n\nThis completes the solution.",
        "raw_answer": "**Problem (Gamma and Beta functions)**  \n\n1. The Gamma function is defined for \\(\\operatorname{Re}(z) > 0\\) by  \n   \\[\n   \\Gamma(z) = \\int_0^\\infty t^{z-1} e^{-t} \\, dt.\n   \\]\n   The Beta function is defined for \\(\\operatorname{Re}(a) > 0\\), \\(\\operatorname{Re}(b) > 0\\) by  \n   \\[\n   B(a,b) = \\int_0^1 x^{a-1} (1-x)^{b-1} \\, dx.\n   \\]\n\n   (a) Prove that  \n   \\[\n   B(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}.\n   \\]\n\n   (b) Show that for \\(0 < \\operatorname{Re}(z) < 1\\),  \n   \\[\n   B(z,1-z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt.\n   \\]\n\n   (c) Evaluate the integral \\(\\displaystyle I(z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt\\) for \\(0 < \\operatorname{Re}(z) < 1\\) using a keyhole contour integration, and deduce Euler's reflection formula:  \n   \\[\n   \\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)}.\n   \\]\n\n   (d) Hence compute \\(\\Gamma\\bigl(\\tfrac{1}{2}\\bigr)\\).\n\n---\n\n**Solution**\n\n**(a)**  \nWe start from the product of two Gamma functions:\n\n\\[\n\\Gamma(a)\\Gamma(b) = \\int_0^\\infty \\int_0^\\infty x^{a-1} y^{b-1} e^{-(x+y)} \\, dx \\, dy, \\qquad \\operatorname{Re}(a)>0,\\; \\operatorname{Re}(b)>0.\n\\]\n\nThe integrand is non\u2011negative and the integrals converge absolutely, so Fubini\u2019s theorem justifies the interchange of order.  \nIntroduce the change of variables  \n\n\\[\nu = x + y, \\quad v = \\frac{x}{x+y} \\qquad \\Longleftrightarrow \\qquad x = uv,\\; y = u(1-v),\n\\]\n\nwhich maps the domain \\(\\{(x,y): x>0,\\; y>0\\}\\) bijectively onto \\(\\{(u,v): u>0,\\; 0<v<1\\}\\).  \nThe Jacobian determinant is  \n\n\\[\n\\frac{\\partial(x,y)}{\\partial(u,v)} = \\begin{vmatrix} v & u \\\\ 1-v & -u \\end{vmatrix} = -uv - u(1-v) = -u,\n\\]\n\nhence \\(|J| = u\\). Then  \n\n\\[\n\\begin{aligned}\n\\Gamma(a)\\Gamma(b) &= \\int_0^\\infty \\int_0^1 (uv)^{a-1} \\bigl(u(1-v)\\bigr)^{b-1} e^{-u} \\; u \\, dv \\, du \\\\\n&= \\int_0^\\infty u^{a+b-1} e^{-u} \\, du \\int_0^1 v^{a-1} (1-v)^{b-1} \\, dv \\\\\n&= \\Gamma(a+b) \\, B(a,b).\n\\end{aligned}\n\\]\n\nTherefore  \n\n\\[\nB(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}.\n\\]\n\n**(b)**  \nFor \\(0 < \\operatorname{Re}(z) < 1\\) we have  \n\n\\[\nB(z,1-z) = \\int_0^1 x^{z-1} (1-x)^{-z} \\, dx.\n\\]\n\nPerform the substitution  \n\n\\[\nx = \\frac{t}{1+t}, \\qquad t = \\frac{x}{1-x}, \\qquad dx = \\frac{dt}{(1+t)^2}.\n\\]\n\nWhen \\(x \\to 0^+\\), \\(t \\to 0\\); when \\(x \\to 1^-\\), \\(t \\to \\infty\\). Also \\(1-x = \\frac{1}{1+t}\\). Hence  \n\n\\[\n\\begin{aligned}\nx^{z-1} (1-x)^{-z} \\, dx &= \\left(\\frac{t}{1+t}\\right)^{z-1} \\left(\\frac{1}{1+t}\\right)^{-z} \\frac{dt}{(1+t)^2} \\\\\n&= t^{z-1} (1+t)^{-(z-1)} (1+t)^{z} (1+t)^{-2} \\, dt \\\\\n&= \\frac{t^{z-1}}{1+t} \\, dt.\n\\end{aligned}\n\\]\n\nThus  \n\n\\[\nB(z,1-z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt.\n\\]\n\nThe integral converges absolutely for \\(0 < \\operatorname{Re}(z) < 1\\) because near \\(t=0\\) the integrand behaves like \\(t^{\\operatorname{Re}(z)-1}\\) (integrable when \\(\\operatorname{Re}(z)>0\\)) and as \\(t\\to\\infty\\) it behaves like \\(t^{\\operatorname{Re}(z)-2}\\) (integrable when \\(\\operatorname{Re}(z)<1\\)).\n\n**(c)**  \nLet  \n\n\\[\nI(z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt, \\qquad 0 < \\operatorname{Re}(z) < 1.\n\\]\n\nConsider the complex function  \n\n\\[\nf(\\zeta) = \\frac{\\zeta^{z-1}}{1+\\zeta},\n\\]\n\nwhere we define \\(\\zeta^{z-1} = e^{(z-1)\\log \\zeta}\\) with the principal branch of the logarithm:  \n\\(\\log \\zeta = \\ln|\\zeta| + i\\arg\\zeta\\), \\(0 < \\arg\\zeta < 2\\pi\\). This makes \\(f\\) analytic on \\(\\mathbb{C} \\setminus [0,\\infty)\\) (branch cut along the positive real axis) and meromorphic with a simple pole at \\(\\zeta = -1\\).\n\nWe integrate \\(f\\) over a *keyhole contour* \\(\\gamma\\) consisting of (see Figure 1):\n\n- \\(\\gamma_1\\): a line segment just above the positive real axis from \\(r\\) to \\(R\\) (with \\(\\arg\\zeta = 0\\)),\n- \\(\\gamma_2\\): a large circle of radius \\(R\\) centred at the origin traversed counterclockwise,\n- \\(\\gamma_3\\): a line segment just below the positive real axis from \\(R\\) back to \\(r\\) (with \\(\\arg\\zeta = 2\\pi\\)),\n- \\(\\gamma_4\\): a small circle of radius \\(r\\) around the origin traversed clockwise.\n\nWe choose \\(r < 1 < R\\) so that the pole at \\(\\zeta = -1 = e^{i\\pi}\\) lies inside the contour. The contour is positively oriented (counterclockwise overall). By the residue theorem,\n\n\\[\n\\oint_\\gamma f(\\zeta) \\, d\\zeta = 2\\pi i \\; \\operatorname{Res}(f, -1).\n\\]\n\n**Residue at \\(\\zeta = -1\\):**  \n\n\\[\n\\operatorname{Res}(f, -1) = \\lim_{\\zeta \\to -1} (\\zeta+1) f(\\zeta) = \\lim_{\\zeta \\to -1} \\zeta^{z-1} = (-1)^{z-1}.\n\\]\n\nWith our branch, \\(\\arg(-1) = \\pi\\), so \\(\\log(-1) = i\\pi\\) and  \n\n\\[\n(-1)^{z-1} = e^{(z-1)\\log(-1)} = e^{i\\pi(z-1)}.\n\\]\n\n**Estimate on the large circle \\(\\gamma_2\\):**  \nFor \\(|\\zeta| = R\\),  \n\n\\[\n|f(\\zeta)| = \\frac{|\\zeta^{z-1}|}{|1+\\zeta|} = \\frac{R^{\\operatorname{Re}(z)-1} e^{-\\operatorname{Im}(z)\\arg\\zeta}}{|1+Re^{i\\theta}|} \\le \\frac{R^{\\operatorname{Re}(z)-1}}{R-1} \\qquad (R>1).\n\\]\n\nSince \\(\\operatorname{Re}(z) < 1\\), \\(R^{\\operatorname{Re}(z)-2} \\to 0\\) as \\(R \\to \\infty\\). The length of \\(\\gamma_2\\) is \\(2\\pi R\\), hence  \n\n\\[\n\\left|\\int_{\\gamma_2} f(\\zeta) \\, d\\zeta\\right| \\le \\frac{R^{\\operatorname{Re}(z)-1}}{R-1} \\cdot 2\\pi R \\sim 2\\pi R^{\\operatorname{Re}(z)} \\to 0 \\quad \\text{as } R\\to\\infty.\n\\]\n\n**Estimate on the small circle \\(\\gamma_4\\):**  \nFor \\(|\\zeta| = r\\),  \n\n\\[\n|f(\\zeta)| \\le \\frac{r^{\\operatorname{Re}(z)-1}}{1-r} \\qquad (r<1).\n\\]\n\nBecause \\(\\operatorname{Re}(z) > 0\\), \\(r^{\\operatorname{Re}(z)-1} \\to 0\\) as \\(r \\to 0\\). The length of \\(\\gamma_4\\) is \\(2\\pi r\\), so  \n\n\\[\n\\left|\\int_{\\gamma_4} f(\\zeta) \\, d\\zeta\\right| \\le \\frac{r^{\\operatorname{Re}(z)-1}}{1-r} \\cdot 2\\pi r \\sim 2\\pi r^{\\operatorname{Re}(z)} \\to 0 \\quad \\text{as } r\\to 0.\n\\]\n\nThus in the limits \\(R\\to\\infty\\) and \\(r\\to 0\\) the contributions from \\(\\gamma_2\\) and \\(\\gamma_4\\) vanish.\n\n**Integral on \\(\\gamma_1\\):**  \nHere \\(\\arg\\zeta = 0\\), \\(\\zeta = t\\) (real), \\(t\\) runs from \\(0\\) to \\(\\infty\\). Hence  \n\n\\[\n\\int_{\\gamma_1} f(\\zeta) \\, d\\zeta = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = I(z).\n\\]\n\n**Integral on \\(\\gamma_3\\):**  \nOn the lower side of the cut we have \\(\\arg\\zeta = 2\\pi\\), so \\(\\zeta = t e^{i2\\pi}\\) with \\(t\\) decreasing from \\(\\infty\\) to \\(0\\). Then  \n\n\\[\n\\zeta^{z-1} = e^{(z-1)(\\ln t + i2\\pi)} = t^{z-1} e^{i2\\pi(z-1)},\n\\]\n\nand \\(d\\zeta = e^{i2\\pi} dt = dt\\). Therefore  \n\n\\[\n\\int_{\\gamma_3} f(\\zeta) \\, d\\zeta = \\int_\\infty^0 \\frac{t^{z-1} e^{i2\\pi(z-1)}}{1+t} \\, dt = - e^{i2\\pi(z-1)} \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = - e^{i2\\pi(z-1)} I(z).\n\\]\n\n**Summing the contributions:**  \nTaking the limits \\(R\\to\\infty\\), \\(r\\to 0\\), we obtain  \n\n\\[\n\\oint_\\gamma f(\\zeta) \\, d\\zeta = I(z) - e^{i2\\pi(z-1)} I(z) = \\bigl(1 - e^{i2\\pi(z-1)}\\bigr) I(z).\n\\]\n\nBy the residue theorem this equals \\(2\\pi i \\, e^{i\\pi(z-1)}\\). Hence  \n\n\\[\n\\bigl(1 - e^{i2\\pi(z-1)}\\bigr) I(z) = 2\\pi i \\, e^{i\\pi(z-1)}.\n\\]\n\nNow simplify the left\u2011hand side:  \n\n\\[\n1 - e^{i2\\pi(z-1)} = e^{i\\pi(z-1)}\\bigl(e^{-i\\pi(z-1)} - e^{i\\pi(z-1)}\\bigr) = e^{i\\pi(z-1)}\\bigl(-2i \\sin(\\pi(z-1))\\bigr).\n\\]\n\nSince \\(\\sin(\\pi(z-1)) = -\\sin(\\pi z)\\), we have  \n\n\\[\n1 - e^{i2\\pi(z-1)} = e^{i\\pi(z-1)} \\cdot 2i \\sin(\\pi z).\n\\]\n\nSubstituting,  \n\n\\[\ne^{i\\pi(z-1)} \\cdot 2i \\sin(\\pi z) \\cdot I(z) = 2\\pi i \\, e^{i\\pi(z-1)}.\n\\]\n\nCancelling the non\u2011zero factor \\(e^{i\\pi(z-1)}\\) and \\(2i\\) yields  \n\n\\[\nI(z) = \\frac{\\pi}{\\sin(\\pi z)}.\n\\]\n\nThus for \\(0 < \\operatorname{Re}(z) < 1\\),  \n\n\\[\n\\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = \\frac{\\pi}{\\sin(\\pi z)}.\n\\]\n\nFrom part (b), \\(B(z,1-z) = I(z)\\). From part (a) with \\(a=z\\), \\(b=1-z\\), and using \\(\\Gamma(1)=1\\) (since \\(\\Gamma(1)=\\int_0^\\infty e^{-t}dt =1\\)), we obtain  \n\n\\[\nB(z,1-z) = \\frac{\\Gamma(z)\\Gamma(1-z)}{\\Gamma(1)} = \\Gamma(z)\\Gamma(1-z).\n\\]\n\nTherefore  \n\n\\[\n\\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)} \\qquad (0 < \\operatorname{Re}(z) < 1).\n\\]\n\nBy analytic continuation, the formula holds for all complex \\(z\\) not an integer.\n\n**(d)**  \nSubstitute \\(z = \\frac{1}{2}\\) into the reflection formula:\n\n\\[\n\\Gamma\\!\\left(\\frac{1}{2}\\right) \\Gamma\\!\\left(1-\\frac{1}{2}\\right) = \\Gamma\\!\\left(\\frac{1}{2}\\right)^2 = \\frac{\\pi}{\\sin(\\pi/2)} = \\pi.\n\\]\n\nBecause \\(\\Gamma(1/2) > 0\\) (the integral definition shows it is positive), we conclude  \n\n\\[\n\\Gamma\\!\\left(\\frac{1}{2}\\right) = \\sqrt{\\pi}.\n\\]\n\nThis completes the solution.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of ordinary differential equations (ODEs), along with a complete and clear solution. The problem should be solvable, verifiable, and not require external resources or conjectures.\n\n## Step 2: Formulate the problem\nTo create a meaningful problem, we need to consider an ODE that is not trivial and involves some level of mathematical sophistication. Let's consider a second-order linear homogeneous differential equation with constant coefficients, which is a standard topic in ODEs.\n\n## Step 3: Propose a specific problem\nConsider the differential equation $y'' + 4y' + 4y = 0$. The task is to find the general solution to this equation.\n\n## Step 4: Verify the problem meets the criteria\n- **Non-trivial**: The equation is not straightforward to solve by inspection.\n- **Solvable**: The equation can be solved using standard methods for linear differential equations with constant coefficients.\n- **Verifiable**: The solution can be verified by substitution into the differential equation.",
    "run_id": "22",
    "topic_slug": "ordinary_differential_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "",
        "raw_answer": "",
        "evaluation": {
          "verdict": "fail",
          "ill_posed": false,
          "issues": [
            "The answer does not include the solution to the differential equation; it only states the problem.",
            "The answer is incomplete; it lacks the required complete and clear solution."
          ],
          "improvements": "Provide the general solution: y = (C1 + C2 x) e^{-2x}. Show the solving process: characteristic equation r^2+4r+4=0 => (r+2)^2=0 => r=-2 (double root). Then general solution y = (C1 + C2 x) e^{-2x}. Verify by substituting back into the ODE to confirm it satisfies the equation."
        }
      },
      {
        "round": 2,
        "answer": "**Problem:** Find the general solution of the ordinary differential equation  \n\\[\ny'' + 4y' + 4y = 0.\n\\]\n\n**Solution:**\n\n1. **Characteristic equation.**  \n   Assume a solution of the form \\(y = e^{rx}\\). Substituting into the ODE yields the characteristic equation  \n   \\[\n   r^2 + 4r + 4 = 0.\n   \\]\n\n2. **Solve the characteristic equation.**  \n   Factor:  \n   \\[\n   (r+2)^2 = 0,\n   \\]  \n   giving a repeated root \\(r = -2\\) (multiplicity 2).\n\n3. **General solution for a repeated root.**  \n   For a second\u2011order linear homogeneous ODE with constant coefficients and a repeated root \\(r\\), the general solution is  \n   \\[\n   y = (C_1 + C_2 x) e^{r x},\n   \\]  \n   where \\(C_1\\) and \\(C_2\\) are arbitrary constants.  \n   Hence,  \n   \\[\n   y(x) = (C_1 + C_2 x) e^{-2x}.\n   \\]\n\n4. **Verification by substitution.**  \n   Compute the first and second derivatives of the proposed solution.\n\n   Let \\(y = (C_1 + C_2 x) e^{-2x}\\).\n\n   - First derivative (product rule):  \n     \\[\n     \\begin{aligned}\n     y' &= C_2 e^{-2x} + (C_1 + C_2 x)(-2 e^{-2x}) \\\\\n        &= e^{-2x}\\bigl(C_2 - 2(C_1 + C_2 x)\\bigr) \\\\\n        &= e^{-2x}(-2C_1 + C_2 - 2C_2 x).\n     \\end{aligned}\n     \\]\n\n   - Second derivative:  \n     \\[\n     \\begin{aligned}\n     y'' &= \\frac{d}{dx}\\bigl[e^{-2x}(-2C_1 + C_2 - 2C_2 x)\\bigr] \\\\\n         &= (-2 e^{-2x})(-2C_1 + C_2 - 2C_2 x) + e^{-2x}(-2C_2) \\\\\n         &= e^{-2x}\\bigl[-2(-2C_1 + C_2 - 2C_2 x) - 2C_2\\bigr] \\\\\n         &= e^{-2x}\\bigl[4C_1 - 2C_2 + 4C_2 x - 2C_2\\bigr] \\\\\n         &= e^{-2x}(4C_1 - 4C_2 + 4C_2 x).\n     \\end{aligned}\n     \\]\n\n   Now substitute into the left\u2011hand side of the ODE:\n   \\[\n   \\begin{aligned}\n   y'' + 4y' + 4y \n   &= e^{-2x}\\Bigl[(4C_1 - 4C_2 + 4C_2 x) \\\\\n   &\\qquad + 4(-2C_1 + C_2 - 2C_2 x) \\\\\n   &\\qquad + 4(C_1 + C_2 x)\\Bigr] \\\\[0.5em]\n   &= e^{-2x}\\Bigl[4C_1 - 4C_2 + 4C_2 x \\\\\n   &\\qquad -8C_1 + 4C_2 - 8C_2 x \\\\\n   &\\qquad + 4C_1 + 4C_2 x\\Bigr] \\\\[0.5em]\n   &= e^{-2x}\\bigl[(4C_1 - 8C_1 + 4C_1) + (-4C_2 + 4C_2) + (4C_2 x - 8C_2 x + 4C_2 x)\\bigr] \\\\[0.5em]\n   &= e^{-2x}\\,(0 + 0 + 0) = 0.\n   \\end{aligned}\n   \\]\n   Thus the proposed function satisfies the differential equation identically for all \\(x \\in \\mathbb{R}\\).\n\n5. **Conclusion.**  \n   The general solution of \\(y'' + 4y' + 4y = 0\\) is  \n   \\[\n   \\boxed{y(x) = (C_1 + C_2 x) e^{-2x}},\n   \\]  \n   where \\(C_1, C_2\\) are arbitrary constants.",
        "raw_answer": "**Problem:** Find the general solution of the ordinary differential equation  \n\\[\ny'' + 4y' + 4y = 0.\n\\]\n\n**Solution:**\n\n1. **Characteristic equation.**  \n   Assume a solution of the form \\(y = e^{rx}\\). Substituting into the ODE yields the characteristic equation  \n   \\[\n   r^2 + 4r + 4 = 0.\n   \\]\n\n2. **Solve the characteristic equation.**  \n   Factor:  \n   \\[\n   (r+2)^2 = 0,\n   \\]  \n   giving a repeated root \\(r = -2\\) (multiplicity 2).\n\n3. **General solution for a repeated root.**  \n   For a second\u2011order linear homogeneous ODE with constant coefficients and a repeated root \\(r\\), the general solution is  \n   \\[\n   y = (C_1 + C_2 x) e^{r x},\n   \\]  \n   where \\(C_1\\) and \\(C_2\\) are arbitrary constants.  \n   Hence,  \n   \\[\n   y(x) = (C_1 + C_2 x) e^{-2x}.\n   \\]\n\n4. **Verification by substitution.**  \n   Compute the first and second derivatives of the proposed solution.\n\n   Let \\(y = (C_1 + C_2 x) e^{-2x}\\).\n\n   - First derivative (product rule):  \n     \\[\n     \\begin{aligned}\n     y' &= C_2 e^{-2x} + (C_1 + C_2 x)(-2 e^{-2x}) \\\\\n        &= e^{-2x}\\bigl(C_2 - 2(C_1 + C_2 x)\\bigr) \\\\\n        &= e^{-2x}(-2C_1 + C_2 - 2C_2 x).\n     \\end{aligned}\n     \\]\n\n   - Second derivative:  \n     \\[\n     \\begin{aligned}\n     y'' &= \\frac{d}{dx}\\bigl[e^{-2x}(-2C_1 + C_2 - 2C_2 x)\\bigr] \\\\\n         &= (-2 e^{-2x})(-2C_1 + C_2 - 2C_2 x) + e^{-2x}(-2C_2) \\\\\n         &= e^{-2x}\\bigl[-2(-2C_1 + C_2 - 2C_2 x) - 2C_2\\bigr] \\\\\n         &= e^{-2x}\\bigl[4C_1 - 2C_2 + 4C_2 x - 2C_2\\bigr] \\\\\n         &= e^{-2x}(4C_1 - 4C_2 + 4C_2 x).\n     \\end{aligned}\n     \\]\n\n   Now substitute into the left\u2011hand side of the ODE:\n   \\[\n   \\begin{aligned}\n   y'' + 4y' + 4y \n   &= e^{-2x}\\Bigl[(4C_1 - 4C_2 + 4C_2 x) \\\\\n   &\\qquad + 4(-2C_1 + C_2 - 2C_2 x) \\\\\n   &\\qquad + 4(C_1 + C_2 x)\\Bigr] \\\\[0.5em]\n   &= e^{-2x}\\Bigl[4C_1 - 4C_2 + 4C_2 x \\\\\n   &\\qquad -8C_1 + 4C_2 - 8C_2 x \\\\\n   &\\qquad + 4C_1 + 4C_2 x\\Bigr] \\\\[0.5em]\n   &= e^{-2x}\\bigl[(4C_1 - 8C_1 + 4C_1) + (-4C_2 + 4C_2) + (4C_2 x - 8C_2 x + 4C_2 x)\\bigr] \\\\[0.5em]\n   &= e^{-2x}\\,(0 + 0 + 0) = 0.\n   \\end{aligned}\n   \\]\n   Thus the proposed function satisfies the differential equation identically for all \\(x \\in \\mathbb{R}\\).\n\n5. **Conclusion.**  \n   The general solution of \\(y'' + 4y' + 4y = 0\\) is  \n   \\[\n   \\boxed{y(x) = (C_1 + C_2 x) e^{-2x}},\n   \\]  \n   where \\(C_1, C_2\\) are arbitrary constants.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Consider the one-dimensional heat equation given by $\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}$, where $\\alpha > 0$ is a constant, $x \\in [0, L]$, and $t \\geq 0$. The boundary conditions are $u(0, t) = u(L, t) = 0$ for all $t \\geq 0$, and the initial condition is $u(x, 0) = \\sin(\\frac{\\pi x}{L}) + 2\\sin(\\frac{3\\pi x}{L})$. Find the solution $u(x, t)$ for $x \\in [0, L]$ and $t \\geq 0$.",
    "run_id": "23",
    "topic_slug": "partial_differential_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The heat equation with given boundary and initial conditions is a standard Sturm\u2013Liouville problem. The solution is obtained by separation of variables.\n\n**Step 1: Separation of variables**  \nAssume a product solution $u(x,t)=X(x)T(t)$. Substituting into $\\frac{\\partial u}{\\partial t}=\\alpha\\frac{\\partial^2 u}{\\partial x^2}$ gives\n$$\nX(x)T'(t)=\\alpha X''(x)T(t) \\quad\\Longrightarrow\\quad \\frac{T'(t)}{\\alpha T(t)}=\\frac{X''(x)}{X(x)}=-\\lambda,\n$$\nwhere $\\lambda$ is a separation constant. This yields two ordinary differential equations:\n$$\nX''(x)+\\lambda X(x)=0,\\qquad T'(t)+\\alpha\\lambda T(t)=0.\n$$\n\n**Step 2: Spatial problem with boundary conditions**  \nThe boundary conditions $u(0,t)=u(L,t)=0$ imply $X(0)=0$ and $X(L)=0$. The eigenvalue problem\n$$\nX''+\\lambda X=0,\\quad X(0)=X(L)=0\n$$\nhas nontrivial solutions only for $\\lambda_n=\\left(\\frac{n\\pi}{L}\\right)^2$, $n=1,2,3,\\dots$, with corresponding eigenfunctions\n$$\nX_n(x)=\\sin\\left(\\frac{n\\pi x}{L}\\right).\n$$\n\n**Step 3: Temporal solution**  \nFor each $\\lambda_n$, the time equation becomes\n$$\nT_n'(t)+\\alpha\\left(\\frac{n\\pi}{L}\\right)^2 T_n(t)=0,\n$$\nwhose solution is\n$$\nT_n(t)=C_n\\exp\\left(-\\alpha\\left(\\frac{n\\pi}{L}\\right)^2 t\\right).\n$$\n\n**Step 4: General solution**  \nSuperposition gives\n$$\nu(x,t)=\\sum_{n=1}^{\\infty}B_n\\sin\\left(\\frac{n\\pi x}{L}\\right)\\exp\\left(-\\alpha\\left(\\frac{n\\pi}{L}\\right)^2 t\\right),\n$$\nwhere $B_n$ are constants to be determined from the initial condition.\n\n**Step 5: Initial condition**  \nAt $t=0$,\n$$\nu(x,0)=\\sum_{n=1}^{\\infty}B_n\\sin\\left(\\frac{n\\pi x}{L}\\right)=\\sin\\left(\\frac{\\pi x}{L}\\right)+2\\sin\\left(\\frac{3\\pi x}{L}\\right).\n$$\nThe functions $\\sin(n\\pi x/L)$ are orthogonal on $[0,L]$:\n$$\n\\int_0^L \\sin\\left(\\frac{n\\pi x}{L}\\right)\\sin\\left(\\frac{m\\pi x}{L}\\right)\\,dx=\\frac{L}{2}\\delta_{nm}.\n$$\nMultiplying both sides by $\\sin(m\\pi x/L)$ and integrating yields\n$$\nB_m=\\frac{2}{L}\\int_0^L\\left[\\sin\\left(\\frac{\\pi x}{L}\\right)+2\\sin\\left(\\frac{3\\pi x}{L}\\right)\\right]\\sin\\left(\\frac{m\\pi x}{L}\\right)\\,dx.\n$$\nBecause the initial condition is already a finite linear combination of the eigenfunctions, orthogonality immediately gives\n$$\nB_1=1,\\quad B_3=2,\\quad\\text{and } B_n=0\\ \\text{for } n\\neq1,3.\n$$\n\n**Step 6: Final solution**  \nSubstituting these coefficients back into the general solution, we obtain\n$$\n\\boxed{u(x,t)=\\sin\\left(\\frac{\\pi x}{L}\\right)\\exp\\left(-\\frac{\\alpha\\pi^2}{L^2}t\\right)+2\\sin\\left(\\frac{3\\pi x}{L}\\right)\\exp\\left(-\\frac{9\\alpha\\pi^2}{L^2}t\\right)}.\n$$\n\n**Verification:**  \n- The series reduces to a finite sum, so convergence is trivial.  \n- Each term satisfies the PDE and the homogeneous Dirichlet boundary conditions.  \n- At $t=0$ the sum reproduces the given initial condition.  \n- By the standard theory of the heat equation, this is the unique solution.",
        "raw_answer": "The heat equation with given boundary and initial conditions is a standard Sturm\u2013Liouville problem. The solution is obtained by separation of variables.\n\n**Step 1: Separation of variables**  \nAssume a product solution \\(u(x,t)=X(x)T(t)\\). Substituting into \\(\\frac{\\partial u}{\\partial t}=\\alpha\\frac{\\partial^2 u}{\\partial x^2}\\) gives\n\\[\nX(x)T'(t)=\\alpha X''(x)T(t) \\quad\\Longrightarrow\\quad \\frac{T'(t)}{\\alpha T(t)}=\\frac{X''(x)}{X(x)}=-\\lambda,\n\\]\nwhere \\(\\lambda\\) is a separation constant. This yields two ordinary differential equations:\n\\[\nX''(x)+\\lambda X(x)=0,\\qquad T'(t)+\\alpha\\lambda T(t)=0.\n\\]\n\n**Step 2: Spatial problem with boundary conditions**  \nThe boundary conditions \\(u(0,t)=u(L,t)=0\\) imply \\(X(0)=0\\) and \\(X(L)=0\\). The eigenvalue problem\n\\[\nX''+\\lambda X=0,\\quad X(0)=X(L)=0\n\\]\nhas nontrivial solutions only for \\(\\lambda_n=\\left(\\frac{n\\pi}{L}\\right)^2\\), \\(n=1,2,3,\\dots\\), with corresponding eigenfunctions\n\\[\nX_n(x)=\\sin\\left(\\frac{n\\pi x}{L}\\right).\n\\]\n\n**Step 3: Temporal solution**  \nFor each \\(\\lambda_n\\), the time equation becomes\n\\[\nT_n'(t)+\\alpha\\left(\\frac{n\\pi}{L}\\right)^2 T_n(t)=0,\n\\]\nwhose solution is\n\\[\nT_n(t)=C_n\\exp\\left(-\\alpha\\left(\\frac{n\\pi}{L}\\right)^2 t\\right).\n\\]\n\n**Step 4: General solution**  \nSuperposition gives\n\\[\nu(x,t)=\\sum_{n=1}^{\\infty}B_n\\sin\\left(\\frac{n\\pi x}{L}\\right)\\exp\\left(-\\alpha\\left(\\frac{n\\pi}{L}\\right)^2 t\\right),\n\\]\nwhere \\(B_n\\) are constants to be determined from the initial condition.\n\n**Step 5: Initial condition**  \nAt \\(t=0\\),\n\\[\nu(x,0)=\\sum_{n=1}^{\\infty}B_n\\sin\\left(\\frac{n\\pi x}{L}\\right)=\\sin\\left(\\frac{\\pi x}{L}\\right)+2\\sin\\left(\\frac{3\\pi x}{L}\\right).\n\\]\nThe functions \\(\\sin(n\\pi x/L)\\) are orthogonal on \\([0,L]\\):\n\\[\n\\int_0^L \\sin\\left(\\frac{n\\pi x}{L}\\right)\\sin\\left(\\frac{m\\pi x}{L}\\right)\\,dx=\\frac{L}{2}\\delta_{nm}.\n\\]\nMultiplying both sides by \\(\\sin(m\\pi x/L)\\) and integrating yields\n\\[\nB_m=\\frac{2}{L}\\int_0^L\\left[\\sin\\left(\\frac{\\pi x}{L}\\right)+2\\sin\\left(\\frac{3\\pi x}{L}\\right)\\right]\\sin\\left(\\frac{m\\pi x}{L}\\right)\\,dx.\n\\]\nBecause the initial condition is already a finite linear combination of the eigenfunctions, orthogonality immediately gives\n\\[\nB_1=1,\\quad B_3=2,\\quad\\text{and } B_n=0\\ \\text{for } n\\neq1,3.\n\\]\n\n**Step 6: Final solution**  \nSubstituting these coefficients back into the general solution, we obtain\n\\[\n\\boxed{u(x,t)=\\sin\\left(\\frac{\\pi x}{L}\\right)\\exp\\left(-\\frac{\\alpha\\pi^2}{L^2}t\\right)+2\\sin\\left(\\frac{3\\pi x}{L}\\right)\\exp\\left(-\\frac{9\\alpha\\pi^2}{L^2}t\\right)}.\n\\]\n\n**Verification:**  \n- The series reduces to a finite sum, so convergence is trivial.  \n- Each term satisfies the PDE and the homogeneous Dirichlet boundary conditions.  \n- At \\(t=0\\) the sum reproduces the given initial condition.  \n- By the standard theory of the heat equation, this is the unique solution.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of dynamical systems and ergodic theory, along with a complete and verifiable solution.\n\n## Step 2: Identify key concepts in dynamical systems and ergodic theory\nDynamical systems involve the study of the behavior of systems that change over time according to certain rules. Ergodic theory is a branch of mathematics that studies the behavior of dynamical systems over time, focusing on their statistical properties. Key concepts include ergodicity, measure-preserving transformations, and the ergodic theorem.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to incorporate concepts from dynamical systems and ergodic theory. A potential problem could involve analyzing the behavior of a specific dynamical system, such as determining if it is ergodic or calculating its invariant measures.\n\n## Step 4: Specify the problem\nLet's consider a simple yet challenging example: the rotation map on the unit circle. The unit circle can be represented as $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$, and a rotation map $T: \\mathbb{T} \\to \\mathbb{T}$ is defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$.\n\n## Step 5: Formulate the question\nWe can ask whether the rotation map $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$ when $\\alpha$ is irrational.\n\n## Step 6: Write the problem statement\n\"Let $T: \\mathbb{T} \\to \\mathbb{T}$ be defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$ is irrational. Prove that $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$.\"\n\n## Step 7: Provide the solution\nTo prove that $T$ is ergodic, we need to show that if $A \\subset \\mathbb{T}$ is $T$-invariant (i.e., $T(A) = A$) and measurable, then either $m(A) = 0$ or $m(A) = 1$, where $m$ denotes the Lebesgue measure.\n\n## Step 8: Detail the solution\nFirst, recall that $T$ is measure-preserving because $m(T^{-1}(A)) = m(A)$ for any measurable $A \\subset \\mathbb{T}$. For $T$ to be ergodic, we must show that $T$-invariant sets have measure 0 or 1.\n\n## Step 9: Use Fourier analysis to prove ergodicity\nConsider a $T$-invariant set $A$. The characteristic function $\\chi_A$ of $A$ is $T$-invariant, meaning $\\chi_A(T(x)) = \\chi_A(x)$. We can expand $\\chi_A$ in a Fourier series: $\\chi_A(x) = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi inx}$, where $c_n = \\int_{\\mathbb{T}} \\chi_A(x)e^{-2\\pi inx} dx$.\n\n## Step 10: Apply $T$-invariance to the Fourier series\nSince $\\chi_A(T(x)) = \\chi_A(x + \\alpha) = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi in(x + \\alpha)} = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi in\\alpha}e^{2\\pi inx}$, and this equals $\\chi_A(x)$, we have $c_n = c_n e^{2\\pi in\\alpha}$ for all $n$. For $\\alpha$ irrational, $e^{2\\pi in\\alpha} \\neq 1$ unless $n = 0$. Thus, $c_n = 0$ for $n \\neq 0$.\n\n## Step 11: Conclude ergodicity from the Fourier analysis\nThis implies $\\chi_A(x) = c_0 = \\int_{\\mathbb{T}} \\chi_A(x) dx = m(A)$, meaning $\\chi_A$ is constant. Hence, $A$ is either $\\mathbb{T}$ (if $m(A) = 1$) or $\\emptyset$ (if $m(A) = 0$), proving $T$ is ergodic.\n\n## Step 12: Format the question and answer according to the required structure\n\nLet $T: \\mathbb{T} \\to \\mathbb{T}$ be defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$ is irrational. Prove that $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$.",
    "run_id": "24",
    "topic_slug": "dynamical_systems_and_ergodic_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove that the irrational rotation $T(x)=x+\\alpha \\bmod 1$ on the circle $\\mathbb{T}=\\mathbb{R}/\\mathbb{Z}$ is ergodic with respect to Lebesgue measure $m$.\n\n---\n\n### 1. $T$ preserves Lebesgue measure\n\nFor any measurable $A\\subseteq\\mathbb{T}$,\n$$\nT^{-1}(A)=\\{x\\in\\mathbb{T}:x+\\alpha\\bmod1\\in A\\}.\n$$\nTranslation by $\\alpha$ (mod $1$) is a bijection of $\\mathbb{T}$ that leaves Lebesgue measure invariant because Lebesgue measure on $\\mathbb{R}$ is translation\u2011invariant. Hence $m(T^{-1}(A))=m(A)$, so $T$ is measure\u2011preserving.\n\n---\n\n### 2. Setup for ergodicity\n\nAssume $A$ is a measurable $T$\u2011invariant set, i.e.\n$$\nm\\big(T^{-1}(A)\\,\\triangle\\,A\\big)=0.\n$$\nThen the characteristic function $f=\\mathbf{1}_A$ satisfies\n$$\nf(Tx)=f(x)\\qquad\\text{for almost every }x\\in\\mathbb{T}.\n$$\n\n---\n\n### 3. Fourier expansion of $f$\n\nSince $f$ is bounded, $f\\in L^2(\\mathbb{T})$ and has a Fourier series (convergent in $L^2$)\n$$\nf(x)=\\sum_{n\\in\\mathbb{Z}}c_n e^{2\\pi i n x},\n$$\nwith coefficients\n$$\nc_n=\\int_{\\mathbb{T}} f(x)\\,e^{-2\\pi i n x}\\,dx=\\int_A e^{-2\\pi i n x}\\,dx.\n$$\n\n---\n\n### 4. Invariance forces constraints on the coefficients\n\nCompute the Fourier coefficients of $f\\circ T$:\n$$\n\\begin{aligned}\n\\int_{\\mathbb{T}} f(Tx)\\,e^{-2\\pi i n x}\\,dx\n&=\\int_{\\mathbb{T}} f(x+\\alpha)\\,e^{-2\\pi i n x}\\,dx\\\\\n&=\\int_{\\mathbb{T}} f(y)\\,e^{-2\\pi i n (y-\\alpha)}\\,dy \\qquad (y=x+\\alpha)\\\\\n&=e^{2\\pi i n\\alpha}\\int_{\\mathbb{T}} f(y)\\,e^{-2\\pi i n y}\\,dy\\\\\n&=e^{2\\pi i n\\alpha}\\,c_n.\n\\end{aligned}\n$$\nBecause $f(Tx)=f(x)$ a.e., the Fourier coefficients of $f\\circ T$ must equal those of $f$. Therefore, for every $n\\in\\mathbb{Z}$,\n$$\nc_n = e^{2\\pi i n\\alpha}\\,c_n.\n$$\n\n---\n\n### 5. Irrationality eliminates non\u2011zero coefficients\n\nIf $n\\neq0$, then $e^{2\\pi i n\\alpha}\\neq1$: indeed $e^{2\\pi i n\\alpha}=1$ would imply $n\\alpha\\in\\mathbb{Z}$, contradicting the irrationality of $\\alpha$. Hence for $n\\neq0$ we must have $c_n=0$.\n\n---\n\n### 6. $f$ is constant almost everywhere\n\nThus the Fourier series of $f$ collapses to\n$$\nf(x)=c_0\\quad\\text{a.e.}\n$$\nBut $c_0=\\int_{\\mathbb{T}} f = m(A)$. Consequently,\n$$\nf(x)=m(A)\\quad\\text{for almost every }x.\n$$\n\n---\n\n### 7. The constant must be $0$ or $1$\n\nSince $f$ takes only the values $0$ and $1$ (a.e.), the constant $m(A)$ can only be $0$ or $1$. Therefore $m(A)=0$ or $m(A)=1$.\n\n---\n\n### 8. Conclusion\n\nEvery $T$\u2011invariant measurable set has measure $0$ or $1$; by definition, $T$ is ergodic with respect to Lebesgue measure. $\\square$",
        "raw_answer": "We prove that the irrational rotation $T(x)=x+\\alpha \\bmod 1$ on the circle $\\mathbb{T}=\\mathbb{R}/\\mathbb{Z}$ is ergodic with respect to Lebesgue measure $m$.\n\n---\n\n### 1. $T$ preserves Lebesgue measure\n\nFor any measurable $A\\subseteq\\mathbb{T}$,\n\\[\nT^{-1}(A)=\\{x\\in\\mathbb{T}:x+\\alpha\\bmod1\\in A\\}.\n\\]\nTranslation by $\\alpha$ (mod $1$) is a bijection of $\\mathbb{T}$ that leaves Lebesgue measure invariant because Lebesgue measure on $\\mathbb{R}$ is translation\u2011invariant. Hence $m(T^{-1}(A))=m(A)$, so $T$ is measure\u2011preserving.\n\n---\n\n### 2. Setup for ergodicity\n\nAssume $A$ is a measurable $T$\u2011invariant set, i.e.\n\\[\nm\\big(T^{-1}(A)\\,\\triangle\\,A\\big)=0.\n\\]\nThen the characteristic function $f=\\mathbf{1}_A$ satisfies\n\\[\nf(Tx)=f(x)\\qquad\\text{for almost every }x\\in\\mathbb{T}.\n\\]\n\n---\n\n### 3. Fourier expansion of $f$\n\nSince $f$ is bounded, $f\\in L^2(\\mathbb{T})$ and has a Fourier series (convergent in $L^2$)\n\\[\nf(x)=\\sum_{n\\in\\mathbb{Z}}c_n e^{2\\pi i n x},\n\\]\nwith coefficients\n\\[\nc_n=\\int_{\\mathbb{T}} f(x)\\,e^{-2\\pi i n x}\\,dx=\\int_A e^{-2\\pi i n x}\\,dx.\n\\]\n\n---\n\n### 4. Invariance forces constraints on the coefficients\n\nCompute the Fourier coefficients of $f\\circ T$:\n\\[\n\\begin{aligned}\n\\int_{\\mathbb{T}} f(Tx)\\,e^{-2\\pi i n x}\\,dx\n&=\\int_{\\mathbb{T}} f(x+\\alpha)\\,e^{-2\\pi i n x}\\,dx\\\\\n&=\\int_{\\mathbb{T}} f(y)\\,e^{-2\\pi i n (y-\\alpha)}\\,dy \\qquad (y=x+\\alpha)\\\\\n&=e^{2\\pi i n\\alpha}\\int_{\\mathbb{T}} f(y)\\,e^{-2\\pi i n y}\\,dy\\\\\n&=e^{2\\pi i n\\alpha}\\,c_n.\n\\end{aligned}\n\\]\nBecause $f(Tx)=f(x)$ a.e., the Fourier coefficients of $f\\circ T$ must equal those of $f$. Therefore, for every $n\\in\\mathbb{Z}$,\n\\[\nc_n = e^{2\\pi i n\\alpha}\\,c_n.\n\\]\n\n---\n\n### 5. Irrationality eliminates non\u2011zero coefficients\n\nIf $n\\neq0$, then $e^{2\\pi i n\\alpha}\\neq1$: indeed $e^{2\\pi i n\\alpha}=1$ would imply $n\\alpha\\in\\mathbb{Z}$, contradicting the irrationality of $\\alpha$. Hence for $n\\neq0$ we must have $c_n=0$.\n\n---\n\n### 6. $f$ is constant almost everywhere\n\nThus the Fourier series of $f$ collapses to\n\\[\nf(x)=c_0\\quad\\text{a.e.}\n\\]\nBut $c_0=\\int_{\\mathbb{T}} f = m(A)$. Consequently,\n\\[\nf(x)=m(A)\\quad\\text{for almost every }x.\n\\]\n\n---\n\n### 7. The constant must be $0$ or $1$\n\nSince $f$ takes only the values $0$ and $1$ (a.e.), the constant $m(A)$ can only be $0$ or $1$. Therefore $m(A)=0$ or $m(A)=1$.\n\n---\n\n### 8. Conclusion\n\nEvery $T$\u2011invariant measurable set has measure $0$ or $1$; by definition, $T$ is ergodic with respect to Lebesgue measure. $\\square$",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of difference and functional equations, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the key elements of a good problem in the domain\nA good problem in the domain of difference and functional equations should involve a functional equation or a difference equation that requires substantive mathematical reasoning to solve. It should be fully specified, with clear notation and constraints.\n\n## Step 3: Generate a problem\nLet's generate a problem: \"Find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation $f(x + y) = f(x) + f(y) + xy$ for all $x, y \\in \\mathbb{R}$, and $f(1) = 1$.\"\n\n## Step 4: Verify that the generated problem meets the quality rubric\n- **Well-Posedness and Completeness**: The problem is fully self-contained, with the domain and codomain of $f$ specified, and the functional equation given.\n- **Clarity**: The notation is standard, and the task is clear.\n- **Non-Triviality**: The problem requires solving a functional equation, which is non-trivial.\n- **Solvability and Verification**: The problem is solvable using established methods for functional equations.\n\n## Step 5: Solve the generated problem\nTo solve $f(x + y) = f(x) + f(y) + xy$, let's first try substituting specific values for $x$ and $y$ to derive additional information.\n\n## Step 6: Substitute $x = y = 0$ into the equation\n$f(0 + 0) = f(0) + f(0) + 0 \\cdot 0$ simplifies to $f(0) = 2f(0)$, which implies $f(0) = 0$.\n\n## Step 7: Substitute $y = 1$ into the original equation\n$f(x + 1) = f(x) + f(1) + x = f(x) + x + 1$, since $f(1) = 1$. This gives a recursive formula to find $f(x)$ for integer values of $x$.\n\n## Step 8: Use the recursive formula to find $f(n)$ for any integer $n$\nStarting from $f(0) = 0$ and $f(1) = 1$, we can derive $f(2)$, $f(3)$, etc., to look for a pattern. $f(2) = f(1) + f(1) + 1 = 3$, $f(3) = f(2) + f(1) + 2 = 6$. It appears that $f(n) = \\frac{n(n+1)}{2}$ for positive integers $n$.\n\n## Step 9: Check if $f(x) = \\frac{x(x+1)}{2}$ satisfies the original functional equation\nSubstitute $f(x) = \\frac{x(x+1)}{2}$ into $f(x + y) = f(x) + f(y) + xy$:\n- LHS: $f(x + y) = \\frac{(x+y)(x+y+1)}{2} = \\frac{x^2 + 2xy + y^2 + x + y}{2}$\n- RHS: $f(x) + f(y) + xy = \\frac{x(x+1)}{2} + \\frac{y(y+1)}{2} + xy = \\frac{x^2 + x + y^2 + y + 2xy}{2}$\nBoth sides are equal, so $f(x) = \\frac{x(x+1)}{2}$ is a solution.\n\n## Step 10: Verify that the solution satisfies the initial condition\n$f(1) = \\frac{1(1+1)}{2} = 1$, which matches the given condition.\n\nThe final answer is: \n\nFind all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation $f(x + y) = f(x) + f(y) + xy$ for all $x, y \\in \\mathbb{R}$, and $f(1) = 1$.",
    "run_id": "25",
    "topic_slug": "difference_and_functional_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked to find all functions $f:\\mathbb{R}\\to\\mathbb{R}$ such that  \n$$f(x+y)=f(x)+f(y)+xy\\qquad\\text{for all }x,y\\in\\mathbb{R},$$  \nand $f(1)=1$.\n\n---\n\n### Step 1. Determine $f(0)$\n\nSet $x=y=0$:  \n$$f(0)=f(0)+f(0)+0\\quad\\Longrightarrow\\quad f(0)=0.$$\n\n---\n\n### Step 2. Transform to a Cauchy equation\n\nDefine $g(x)=f(x)-\\dfrac{x^2}{2}$. Then for any $x,y$,\n$$\n\\begin{aligned}\ng(x+y)&=f(x+y)-\\frac{(x+y)^2}{2}\\$$2mm]\n&=\\bigl[f(x)+f(y)+xy\\bigr]-\\frac{x^2+2xy+y^2}{2}\\$$2mm]\n&=f(x)+f(y)+xy-\\frac{x^2}{2}-xy-\\frac{y^2}{2}\\$$2mm]\n&=\\left(f(x)-\\frac{x^2}{2}\\right)+\\left(f(y)-\\frac{y^2}{2}\\right)\\$$2mm]\n&=g(x)+g(y).\n\\end{aligned}\n$$\nThus $g$ satisfies **Cauchy's functional equation**  \n$$g(x+y)=g(x)+g(y)\\qquad\\text{for all }x,y\\in\\mathbb{R},$$  \ni.e., $g$ is an *additive* function.\n\n---\n\n### Step 3. Use the condition $f(1)=1$\n\nFrom $f(1)=1$ we obtain  \n$$g(1)=f(1)-\\frac{1^2}{2}=1-\\frac12=\\frac12.$$\n\n---\n\n### Step 4. Characterise all solutions\n\nThe above steps show that any solution $f$ must be of the form  \n$$f(x)=\\frac{x^2}{2}+g(x),$$  \nwhere $g:\\mathbb{R}\\to\\mathbb{R}$ is additive and satisfies $g(1)=\\frac12$.\n\nConversely, if $g$ is any additive function with $g(1)=\\frac12$, then defining $f$ by $f(x)=\\frac{x^2}{2}+g(x)$ gives  \n$$\n\\begin{aligned}\nf(x+y)&=\\frac{(x+y)^2}{2}+g(x+y)\\\\\n&=\\frac{x^2+2xy+y^2}{2}+g(x)+g(y)\\\\\n&=\\left(\\frac{x^2}{2}+g(x)\\right)+\\left(\\frac{y^2}{2}+g(y)\\right)+xy\\\\\n&=f(x)+f(y)+xy,\n\\end{aligned}\n$$\nand $f(1)=\\frac12+g(1)=\\frac12+\\frac12=1$. Hence every such $g$ yields a valid $f$.\n\nTherefore **the general solution** is  \n$$\n\\boxed{f(x)=\\frac{x^2}{2}+A(x),\\quad\\text{where }A:\\mathbb{R}\\to\\mathbb{R}\\text{ is additive and }A(1)=\\frac12.}\n$$\n\n---\n\n### Remarks on additive functions\n\nAn additive function $A$ satisfies $A(x+y)=A(x)+A(y)$ for all real $x,y$. Such functions are exactly the $\\mathbb{Q}$-linear maps when $\\mathbb{R}$ is viewed as a vector space over $\\mathbb{Q}$. Without further regularity assumptions (continuity, measurability, boundedness on an interval, etc.) there exist many additive functions that are not of the form $A(x)=cx$; they can be constructed using a Hamel basis of $\\mathbb{R}$ over $\\mathbb{Q}$. The condition $A(1)=\\frac12$ fixes the value on all rational numbers: $A(q)=q\\cdot\\frac12$ for every $q\\in\\mathbb{Q}$, but on irrational numbers $A$ may be chosen arbitrarily subject only to additivity.\n\nIf one imposes any natural regularity condition (e.g., continuity, monotonicity, measurability, or local boundedness), then $A(x)=\\frac{x}{2}$ for all $x$, yielding the unique polynomial solution  \n$$f(x)=\\frac{x^2}{2}+\\frac{x}{2}=\\frac{x(x+1)}{2}.$$  \nIn the absence of such extra hypotheses, however, the description above gives **all** solutions.",
        "raw_answer": "We are asked to find all functions $f:\\mathbb{R}\\to\\mathbb{R}$ such that  \n$$f(x+y)=f(x)+f(y)+xy\\qquad\\text{for all }x,y\\in\\mathbb{R},$$  \nand $f(1)=1$.\n\n---\n\n### Step 1. Determine $f(0)$\n\nSet $x=y=0$:  \n$$f(0)=f(0)+f(0)+0\\quad\\Longrightarrow\\quad f(0)=0.$$\n\n---\n\n### Step 2. Transform to a Cauchy equation\n\nDefine $g(x)=f(x)-\\dfrac{x^2}{2}$. Then for any $x,y$,\n$$\n\\begin{aligned}\ng(x+y)&=f(x+y)-\\frac{(x+y)^2}{2}\\\\[2mm]\n&=\\bigl[f(x)+f(y)+xy\\bigr]-\\frac{x^2+2xy+y^2}{2}\\\\[2mm]\n&=f(x)+f(y)+xy-\\frac{x^2}{2}-xy-\\frac{y^2}{2}\\\\[2mm]\n&=\\left(f(x)-\\frac{x^2}{2}\\right)+\\left(f(y)-\\frac{y^2}{2}\\right)\\\\[2mm]\n&=g(x)+g(y).\n\\end{aligned}\n$$\nThus $g$ satisfies **Cauchy's functional equation**  \n$$g(x+y)=g(x)+g(y)\\qquad\\text{for all }x,y\\in\\mathbb{R},$$  \ni.e., $g$ is an *additive* function.\n\n---\n\n### Step 3. Use the condition $f(1)=1$\n\nFrom $f(1)=1$ we obtain  \n$$g(1)=f(1)-\\frac{1^2}{2}=1-\\frac12=\\frac12.$$\n\n---\n\n### Step 4. Characterise all solutions\n\nThe above steps show that any solution $f$ must be of the form  \n$$f(x)=\\frac{x^2}{2}+g(x),$$  \nwhere $g:\\mathbb{R}\\to\\mathbb{R}$ is additive and satisfies $g(1)=\\frac12$.\n\nConversely, if $g$ is any additive function with $g(1)=\\frac12$, then defining $f$ by $f(x)=\\frac{x^2}{2}+g(x)$ gives  \n$$\n\\begin{aligned}\nf(x+y)&=\\frac{(x+y)^2}{2}+g(x+y)\\\\\n&=\\frac{x^2+2xy+y^2}{2}+g(x)+g(y)\\\\\n&=\\left(\\frac{x^2}{2}+g(x)\\right)+\\left(\\frac{y^2}{2}+g(y)\\right)+xy\\\\\n&=f(x)+f(y)+xy,\n\\end{aligned}\n$$\nand $f(1)=\\frac12+g(1)=\\frac12+\\frac12=1$. Hence every such $g$ yields a valid $f$.\n\nTherefore **the general solution** is  \n$$\n\\boxed{f(x)=\\frac{x^2}{2}+A(x),\\quad\\text{where }A:\\mathbb{R}\\to\\mathbb{R}\\text{ is additive and }A(1)=\\frac12.}\n$$\n\n---\n\n### Remarks on additive functions\n\nAn additive function $A$ satisfies $A(x+y)=A(x)+A(y)$ for all real $x,y$. Such functions are exactly the $\\mathbb{Q}$-linear maps when $\\mathbb{R}$ is viewed as a vector space over $\\mathbb{Q}$. Without further regularity assumptions (continuity, measurability, boundedness on an interval, etc.) there exist many additive functions that are not of the form $A(x)=cx$; they can be constructed using a Hamel basis of $\\mathbb{R}$ over $\\mathbb{Q}$. The condition $A(1)=\\frac12$ fixes the value on all rational numbers: $A(q)=q\\cdot\\frac12$ for every $q\\in\\mathbb{Q}$, but on irrational numbers $A$ may be chosen arbitrarily subject only to additivity.\n\nIf one imposes any natural regularity condition (e.g., continuity, monotonicity, measurability, or local boundedness), then $A(x)=\\frac{x}{2}$ for all $x$, yielding the unique polynomial solution  \n$$f(x)=\\frac{x^2}{2}+\\frac{x}{2}=\\frac{x(x+1)}{2}.$$  \nIn the absence of such extra hypotheses, however, the description above gives **all** solutions.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$.",
    "run_id": "26",
    "topic_slug": "sequences_series_and_summability",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We evaluate the series\n\n$$\nS = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}.\n$$\n\n**Step 1. Convergence.**  \nSince $\\left|\\frac{(-1)^{n+1}}{n(n+1)}\\right| = \\frac{1}{n(n+1)} \\sim \\frac{1}{n^2}$ and $\\sum_{n=1}^{\\infty} \\frac{1}{n^2}$ converges, the series converges absolutely. Hence all rearrangements and term\u2011wise operations are justified.\n\n**Step 2. Partial fractions.**  \nFor every $n\\ge 1$,\n\n$$\n\\frac{1}{n(n+1)} = \\frac{1}{n} - \\frac{1}{n+1}.\n$$\n\nThus\n\n$$\n\\frac{(-1)^{n+1}}{n(n+1)} = (-1)^{n+1}\\left(\\frac{1}{n} - \\frac{1}{n+1}\\right).\n$$\n\n**Step 3. Partial sum.**  \nLet\n\n$$\nS_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n(n+1)}.\n$$\n\nThen\n\n$$\nS_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} - \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1}.\n$$\n\n**Step 4. Index shift in the second sum.**  \nSet $k = n+1$. When $n=1$, $k=2$; when $n=N$, $k=N+1$. Hence\n\n$$\n\\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1} = \\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k}.\n$$\n\n**Step 5. Express in terms of alternating harmonic partial sums.**  \nDefine\n\n$$\nH_M = \\sum_{m=1}^{M} \\frac{(-1)^{m+1}}{m}.\n$$\n\nThen the first sum is simply $H_N$. For the second sum we write\n\n$$\n\\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k} = \\left(\\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k}\\right) - \\frac{(-1)^1}{1}.\n$$\n\nSince $\\frac{(-1)^1}{1} = -1$, this becomes\n\n$$\n\\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k} = \\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k} + 1.\n$$\n\nBut $\\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k} = -H_{N+1}$ because $(-1)^{k} = -(-1)^{k+1}$. Therefore\n\n$$\n\\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1} = -H_{N+1} + 1.\n$$\n\n**Step 6. Combine.**  \nSubstituting into the expression for $S_N$,\n\n$$\nS_N = H_N - \\bigl(-H_{N+1} + 1\\bigr) = H_N + H_{N+1} - 1.\n$$\n\n**Step 7. Take the limit $N\\to\\infty$.**  \nThe alternating harmonic series converges to $\\ln 2$:\n\n$$\n\\lim_{M\\to\\infty} H_M = \\sum_{m=1}^{\\infty} \\frac{(-1)^{m+1}}{m} = \\ln 2.\n$$\n\nThus\n\n$$\n\\lim_{N\\to\\infty} H_N = \\ln 2, \\qquad \\lim_{N\\to\\infty} H_{N+1} = \\ln 2.\n$$\n\nConsequently,\n\n$$\nS = \\lim_{N\\to\\infty} S_N = \\ln 2 + \\ln 2 - 1 = 2\\ln 2 - 1.\n$$\n\n**Conclusion.**\n\n$$\n\\boxed{2\\ln 2 - 1}\n$$\n\n(Equivalently, $\\ln 4 - 1$.)",
        "raw_answer": "We evaluate the series\n\n\\[\nS = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}.\n\\]\n\n**Step 1. Convergence.**  \nSince \\(\\left|\\frac{(-1)^{n+1}}{n(n+1)}\\right| = \\frac{1}{n(n+1)} \\sim \\frac{1}{n^2}\\) and \\(\\sum_{n=1}^{\\infty} \\frac{1}{n^2}\\) converges, the series converges absolutely. Hence all rearrangements and term\u2011wise operations are justified.\n\n**Step 2. Partial fractions.**  \nFor every \\(n\\ge 1\\),\n\n\\[\n\\frac{1}{n(n+1)} = \\frac{1}{n} - \\frac{1}{n+1}.\n\\]\n\nThus\n\n\\[\n\\frac{(-1)^{n+1}}{n(n+1)} = (-1)^{n+1}\\left(\\frac{1}{n} - \\frac{1}{n+1}\\right).\n\\]\n\n**Step 3. Partial sum.**  \nLet\n\n\\[\nS_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n(n+1)}.\n\\]\n\nThen\n\n\\[\nS_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} - \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1}.\n\\]\n\n**Step 4. Index shift in the second sum.**  \nSet \\(k = n+1\\). When \\(n=1\\), \\(k=2\\); when \\(n=N\\), \\(k=N+1\\). Hence\n\n\\[\n\\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1} = \\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k}.\n\\]\n\n**Step 5. Express in terms of alternating harmonic partial sums.**  \nDefine\n\n\\[\nH_M = \\sum_{m=1}^{M} \\frac{(-1)^{m+1}}{m}.\n\\]\n\nThen the first sum is simply \\(H_N\\). For the second sum we write\n\n\\[\n\\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k} = \\left(\\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k}\\right) - \\frac{(-1)^1}{1}.\n\\]\n\nSince \\(\\frac{(-1)^1}{1} = -1\\), this becomes\n\n\\[\n\\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k} = \\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k} + 1.\n\\]\n\nBut \\(\\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k} = -H_{N+1}\\) because \\((-1)^{k} = -(-1)^{k+1}\\). Therefore\n\n\\[\n\\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1} = -H_{N+1} + 1.\n\\]\n\n**Step 6. Combine.**  \nSubstituting into the expression for \\(S_N\\),\n\n\\[\nS_N = H_N - \\bigl(-H_{N+1} + 1\\bigr) = H_N + H_{N+1} - 1.\n\\]\n\n**Step 7. Take the limit \\(N\\to\\infty\\).**  \nThe alternating harmonic series converges to \\(\\ln 2\\):\n\n\\[\n\\lim_{M\\to\\infty} H_M = \\sum_{m=1}^{\\infty} \\frac{(-1)^{m+1}}{m} = \\ln 2.\n\\]\n\nThus\n\n\\[\n\\lim_{N\\to\\infty} H_N = \\ln 2, \\qquad \\lim_{N\\to\\infty} H_{N+1} = \\ln 2.\n\\]\n\nConsequently,\n\n\\[\nS = \\lim_{N\\to\\infty} S_N = \\ln 2 + \\ln 2 - 1 = 2\\ln 2 - 1.\n\\]\n\n**Conclusion.**\n\n\\[\n\\boxed{2\\ln 2 - 1}\n\\]\n\n(Equivalently, \\(\\ln 4 - 1\\).)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the topic\nThe task is to generate a challenging mathematics problem along with a complete and verifiable solution in the domain of \"Approximations and expansions.\" The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within \"Approximations and expansions\"\nA suitable topic could involve Taylor series expansions, asymptotic approximations, or other related areas where mathematical functions are approximated.\n\n## Step 3: Formulate a challenging problem\nLet's consider a problem involving the approximation of a function using its Taylor series expansion. A classic example is approximating $e^x$ or $\\sin(x)$ around $x = 0$. However, to make it more challenging, we could involve a less straightforward function or require the derivation of an approximation under certain conditions.\n\n## Step 4: Create a specific problem\nConsider the function $f(x) = \\frac{1}{\\sqrt{1 + x}}$. We can ask to find the Taylor series expansion of $f(x)$ around $x = 0$ up to the third term and then use this expansion to approximate $f(0.1)$.\n\n## Step 5: Formulate the problem statement\nLet's refine the problem: \"Find the Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to and including the term involving $x^3$. Then, use this expansion to approximate $f(0.1)$ and compare it with the exact value.\"\n\n## Step 6: Write the problem in the required format\n\nFind the Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to and including the term involving $x^3$. Then, use this expansion to approximate $f(0.1)$ and compare it with the exact value.",
    "run_id": "27",
    "topic_slug": "approximations_and_expansions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe consider $f(x) = \\frac{1}{\\sqrt{1+x}} = (1+x)^{-1/2}$.  \nThe Maclaurin (Taylor about $0$) series for $(1+x)^\\alpha$ is given by the binomial series\n\n$$\n(1+x)^\\alpha = \\sum_{k=0}^\\infty \\binom{\\alpha}{k} x^k, \\qquad \n\\binom{\\alpha}{k} = \\frac{\\alpha(\\alpha-1)\\cdots(\\alpha-k+1)}{k!},\n$$\n\nvalid for $|x|<1$ when $\\alpha$ is not a non\u2011negative integer.  \nFor $\\alpha = -\\frac12$ we compute the coefficients up to $k=3$:\n\n$$\n\\begin{aligned}\nk=0&:\\quad \\binom{-\\frac12}{0} = 1,\\$$2mm]\nk=1&:\\quad \\binom{-\\frac12}{1} = -\\frac12,\\$$2mm]\nk=2&:\\quad \\binom{-\\frac12}{2} = \\frac{\\bigl(-\\frac12\\bigr)\\bigl(-\\frac32\\bigr)}{2!} = \\frac{3/4}{2} = \\frac38,\\$$2mm]\nk=3&:\\quad \\binom{-\\frac12}{3} = \\frac{\\bigl(-\\frac12\\bigr)\\bigl(-\\frac32\\bigr)\\bigl(-\\frac52\\bigr)}{3!} = \\frac{-15/8}{6} = -\\frac{15}{48} = -\\frac5{16}.\n\\end{aligned}\n$$\n\nThus the required expansion is\n\n$$\nf(x) = 1 - \\frac12 x + \\frac38 x^2 - \\frac5{16} x^3 + O(x^4).\n$$\n\nNow approximate $f(0.1)$ using the polynomial part:\n\n$$\nf(0.1) \\approx 1 - \\frac12(0.1) + \\frac38 (0.1)^2 - \\frac5{16} (0.1)^3.\n$$\n\nCompute each term precisely:\n\n$$\n\\begin{aligned}\n1 &= 1,\\\\\n-\\frac12 \\times 0.1 &= -0.05,\\\\\n\\frac38 \\times 0.01 &= \\frac{3}{800} = 0.00375,\\\\\n-\\frac5{16} \\times 0.001 &= -\\frac{5}{16000} = -\\frac{1}{3200} = -0.0003125.\n\\end{aligned}\n$$\n\nSumming step by step:\n\n$$\n1 - 0.05 = 0.95,\\quad 0.95 + 0.00375 = 0.95375,\\quad 0.95375 - 0.0003125 = 0.9534375.\n$$\n\nHence the approximation is $\\boxed{0.9534375}$.\n\nThe exact value is\n\n$$\nf(0.1) = \\frac{1}{\\sqrt{1.1}} = \\sqrt{\\frac{10}{11}} \\approx 0.953462589\\ldots\n$$\n\n($\\sqrt{1.1} \\approx 1.0488088482$, its reciprocal $\\approx 0.953462589$).  \n\nThe difference (approximation minus exact) is\n\n$$\n0.9534375 - 0.953462589 = -0.000025089,\n$$\n\nso the absolute error is about $2.51 \\times 10^{-5}$ and the relative error about $2.63 \\times 10^{-5}$.\n\nThe error is consistent with the first omitted term of the series. For $k=4$,\n\n$$\n\\binom{-\\frac12}{4} x^4 = \\frac{35}{128} x^4 \\approx 0.2734375 \\times 10^{-4} = 2.734 \\times 10^{-5},\n$$\n\nwhich is positive and of magnitude close to the observed error (the remainder after an alternating series with decreasing terms has the same sign as the first omitted term and is bounded by its absolute value).\n\nThe binomial series converges for $|x|<1$; here $x=0.1$ is well inside the interval of convergence, so the approximation is reliable.",
        "raw_answer": "**Solution**\n\nWe consider \\(f(x) = \\frac{1}{\\sqrt{1+x}} = (1+x)^{-1/2}\\).  \nThe Maclaurin (Taylor about \\(0\\)) series for \\((1+x)^\\alpha\\) is given by the binomial series\n\n\\[\n(1+x)^\\alpha = \\sum_{k=0}^\\infty \\binom{\\alpha}{k} x^k, \\qquad \n\\binom{\\alpha}{k} = \\frac{\\alpha(\\alpha-1)\\cdots(\\alpha-k+1)}{k!},\n\\]\n\nvalid for \\(|x|<1\\) when \\(\\alpha\\) is not a non\u2011negative integer.  \nFor \\(\\alpha = -\\frac12\\) we compute the coefficients up to \\(k=3\\):\n\n\\[\n\\begin{aligned}\nk=0&:\\quad \\binom{-\\frac12}{0} = 1,\\\\[2mm]\nk=1&:\\quad \\binom{-\\frac12}{1} = -\\frac12,\\\\[2mm]\nk=2&:\\quad \\binom{-\\frac12}{2} = \\frac{\\bigl(-\\frac12\\bigr)\\bigl(-\\frac32\\bigr)}{2!} = \\frac{3/4}{2} = \\frac38,\\\\[2mm]\nk=3&:\\quad \\binom{-\\frac12}{3} = \\frac{\\bigl(-\\frac12\\bigr)\\bigl(-\\frac32\\bigr)\\bigl(-\\frac52\\bigr)}{3!} = \\frac{-15/8}{6} = -\\frac{15}{48} = -\\frac5{16}.\n\\end{aligned}\n\\]\n\nThus the required expansion is\n\n\\[\nf(x) = 1 - \\frac12 x + \\frac38 x^2 - \\frac5{16} x^3 + O(x^4).\n\\]\n\nNow approximate \\(f(0.1)\\) using the polynomial part:\n\n\\[\nf(0.1) \\approx 1 - \\frac12(0.1) + \\frac38 (0.1)^2 - \\frac5{16} (0.1)^3.\n\\]\n\nCompute each term precisely:\n\n\\[\n\\begin{aligned}\n1 &= 1,\\\\\n-\\frac12 \\times 0.1 &= -0.05,\\\\\n\\frac38 \\times 0.01 &= \\frac{3}{800} = 0.00375,\\\\\n-\\frac5{16} \\times 0.001 &= -\\frac{5}{16000} = -\\frac{1}{3200} = -0.0003125.\n\\end{aligned}\n\\]\n\nSumming step by step:\n\n\\[\n1 - 0.05 = 0.95,\\quad 0.95 + 0.00375 = 0.95375,\\quad 0.95375 - 0.0003125 = 0.9534375.\n\\]\n\nHence the approximation is \\(\\boxed{0.9534375}\\).\n\nThe exact value is\n\n\\[\nf(0.1) = \\frac{1}{\\sqrt{1.1}} = \\sqrt{\\frac{10}{11}} \\approx 0.953462589\\ldots\n\\]\n\n(\\(\\sqrt{1.1} \\approx 1.0488088482\\), its reciprocal \\(\\approx 0.953462589\\)).  \n\nThe difference (approximation minus exact) is\n\n\\[\n0.9534375 - 0.953462589 = -0.000025089,\n\\]\n\nso the absolute error is about \\(2.51 \\times 10^{-5}\\) and the relative error about \\(2.63 \\times 10^{-5}\\).\n\nThe error is consistent with the first omitted term of the series. For \\(k=4\\),\n\n\\[\n\\binom{-\\frac12}{4} x^4 = \\frac{35}{128} x^4 \\approx 0.2734375 \\times 10^{-4} = 2.734 \\times 10^{-5},\n\\]\n\nwhich is positive and of magnitude close to the observed error (the remainder after an alternating series with decreasing terms has the same sign as the first omitted term and is bounded by its absolute value).\n\nThe binomial series converges for \\(|x|<1\\); here \\(x=0.1\\) is well inside the interval of convergence, so the approximation is reliable.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ and suppose that its Fourier transform $\\hat{f}$ is supported in the ball $B(0,1) = \\{ \\xi \\in \\mathbb{R}^n : |\\xi| \\leq 1 \\}$. Prove that $f$ is smooth, i.e., $f \\in C^\\infty(\\mathbb{R}^n)$, and that for any multi-index $\\alpha$, there exists a constant $C_\\alpha > 0$ such that $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$ for all $x \\in \\mathbb{R}^n$.",
    "run_id": "28",
    "topic_slug": "harmonic_analysis_on_euclidean_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The question is ill\u2011posed: the decay estimate $|\\partial^\\alpha f(x)|\\le C_\\alpha(1+|x|)^{-n-1}$ does **not** follow from the hypotheses $f\\in L^1(\\mathbb R^n)\\cap L^2(\\mathbb R^n)$ and $\\operatorname{supp}\\hat f\\subseteq B(0,1)$. A counterexample (for any $n\\ge1$) satisfying all assumptions but violating the bound can be constructed. The smoothness assertion $f\\in C^\\infty(\\mathbb R^n)$ is, however, correct.\n\n### 1. Why the question is ill\u2011posed\nThe problem asks to prove a statement that is false as written. The hypotheses are too weak to guarantee the claimed polynomial decay rate; the missing condition is additional regularity of $\\hat f$ (e.g., $\\hat f\\in C^{n}$ or $\\hat f\\in C^\\infty_c$). Without such regularity, the decay can be slower than $(1+|x|)^{-n-1}$, as demonstrated below.\n\n### 2. Counterexample (case $n=1$)\nLet $0<\\beta<1$ and define  \n$$\n\\hat f(\\xi) = (1-|\\xi|)^\\beta \\chi_{[-1,1]}(\\xi),\n$$  \nwhere $\\chi_{[-1,1]}$ is the characteristic function of $[-1,1]$. Clearly $\\hat f$ is continuous (because $\\beta>0$) and $\\operatorname{supp}\\hat f\\subseteq[-1,1]$. Moreover, $\\hat f\\in L^2(\\mathbb R)$ because it is bounded and compactly supported.\n\nThe inverse Fourier transform (using the convention $\\hat f(\\xi)=\\int f(x)e^{-2\\pi i x\\xi}\\,dx$) is  \n$$\nf(x)=\\int_{-1}^1 (1-|\\xi|)^\\beta e^{2\\pi i x\\xi}\\,d\\xi\n      =2\\int_0^1 (1-\\xi)^\\beta \\cos(2\\pi x\\xi)\\,d\\xi.\n$$\n\nWe verify that $f\\in L^1(\\mathbb R)\\cap L^2(\\mathbb R)$:\n- **$L^2$:** By Plancherel, $\\|f\\|_{L^2}=\\|\\hat f\\|_{L^2}<\\infty$.\n- **$L^1$:** For large $|x|$, standard asymptotic analysis (see below) gives  \n  $$\n  |f(x)| \\sim C_\\beta\\, |x|^{-\\beta-1}\\qquad (|x|\\to\\infty).\n  $$  \n  Since $\\beta+1>1$, the tail $\\int_{|x|>1}|f(x)|\\,dx$ converges; near $x=0$ the function is bounded. Hence $f\\in L^1$.\n\nThus $f$ satisfies all the hypotheses.\n\n#### Asymptotic decay of $f$\nWrite for $x>0$ (the case $x<0$ is symmetric)\n$$\nf(x)=2\\operatorname{Re}\\!\\left(e^{2\\pi i x}\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du\\right),\\qquad u=1-\\xi.\n$$\nThe integral $\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du$ has the well\u2011known asymptotic expansion (see, e.g., Erd\u00e9lyi, *Asymptotic Expansions*)\n$$\n\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du = \n\\Gamma(\\beta+1)(2\\pi i x)^{-\\beta-1} + O\\bigl(|x|^{-\\beta-2}\\bigr),\\qquad x\\to\\infty.\n$$\nConsequently,\n$$\n|f(x)| = \\frac{2\\Gamma(\\beta+1)}{(2\\pi)^{\\beta+1}}\\,|x|^{-\\beta-1} + O\\bigl(|x|^{-\\beta-2}\\bigr).\n$$\nIn particular, there exist constants $c,C>0$ such that for all sufficiently large $|x|$,\n$$\nc\\,|x|^{-\\beta-1} \\le |f(x)| \\le C\\,|x|^{-\\beta-1}.\n$$\n\n#### Failure of the claimed bound\nBecause $0<\\beta<1$, we have $\\beta+1<2$. Therefore\n$$\n\\lim_{|x|\\to\\infty} |f(x)|\\,(1+|x|)^{2} = \\infty.\n$$\nHence **no** constant $C_0$ can satisfy $|f(x)|\\le C_0(1+|x|)^{-2}$ for all $x$. This already contradicts the required inequality for the multi\u2011index $\\alpha=0$.\n\n**Remark.** The same construction works in $\\mathbb R^n$ by taking $\\hat f(\\xi)=(1-|\\xi|)^\\beta$ for $|\\xi|\\le1$ and $0$ otherwise, with $0<\\beta<n/2$. Then $f$ decays like $|x|^{-\\beta-1-n/2}$ (by the asymptotics of radial Fourier transforms), and the condition $\\beta+1+n/2 < n+1$ (i.e., $\\beta<n/2$) makes the decay slower than $(1+|x|)^{-n-1}$. The $L^1$ condition requires $\\beta+1+n/2 > n$, i.e., $\\beta>0$, so such $\\beta$ exist. Thus the counterexample is valid in any dimension.\n\n### 3. The smoothness part is true\nAlthough the decay estimate fails, the claim that $f$ is smooth is correct and can be proved as follows. Because $\\hat f$ is supported in the compact set $\\overline{B(0,1)}$ and belongs to $L^1(\\mathbb R^n)$ (it is in $L^2$ and compactly supported, hence in $L^1$), the inversion formula\n$$\nf(x)=\\int_{B(0,1)} \\hat f(\\xi)\\,e^{2\\pi i x\\cdot\\xi}\\,d\\xi\n$$\nholds for every $x$ and represents $f$ as a continuous function. For any multi\u2011index $\\alpha$, differentiation under the integral sign yields\n$$\n\\partial^\\alpha f(x)=\\int_{B(0,1)} \\hat f(\\xi)\\,(2\\pi i\\xi)^\\alpha e^{2\\pi i x\\cdot\\xi}\\,d\\xi.\n$$\nThe integrand is bounded by $|\\hat f(\\xi)|\\,(2\\pi)^\\alpha$ (since $|\\xi|\\le1$) and $\\hat f\\in L^1$; thus $\\partial^\\alpha f$ exists, is continuous, and the differentiation is justified. Hence $f\\in C^\\infty(\\mathbb R^n)$.\n\n### 4. Conclusion\nThe problem is ill\u2011posed because the stated decay estimate does **not** follow from the given assumptions. To make the statement true one would need additional regularity on $\\hat f$ (e.g., $\\hat f\\in C^{n}_c$ or $\\hat f\\in C^\\infty_c$), which would imply rapid decay of $f$. Alternatively, the conclusion could be weakened to, say, $|\\partial^\\alpha f(x)|\\le C_{\\alpha,N}(1+|x|)^{-N}$ for every $N$ (which would require $\\hat f\\in C^\\infty_c$).\n\n**Therefore the question cannot be answered as stated; it is ill\u2011posed due to a missing hypothesis.**",
        "raw_answer": "The question is ill\u2011posed: the decay estimate \\(|\\partial^\\alpha f(x)|\\le C_\\alpha(1+|x|)^{-n-1}\\) does **not** follow from the hypotheses \\(f\\in L^1(\\mathbb R^n)\\cap L^2(\\mathbb R^n)\\) and \\(\\operatorname{supp}\\hat f\\subseteq B(0,1)\\). A counterexample (for any \\(n\\ge1\\)) satisfying all assumptions but violating the bound can be constructed. The smoothness assertion \\(f\\in C^\\infty(\\mathbb R^n)\\) is, however, correct.\n\n### 1. Why the question is ill\u2011posed\nThe problem asks to prove a statement that is false as written. The hypotheses are too weak to guarantee the claimed polynomial decay rate; the missing condition is additional regularity of \\(\\hat f\\) (e.g., \\(\\hat f\\in C^{n}\\) or \\(\\hat f\\in C^\\infty_c\\)). Without such regularity, the decay can be slower than \\((1+|x|)^{-n-1}\\), as demonstrated below.\n\n### 2. Counterexample (case \\(n=1\\))\nLet \\(0<\\beta<1\\) and define  \n\\[\n\\hat f(\\xi) = (1-|\\xi|)^\\beta \\chi_{[-1,1]}(\\xi),\n\\]  \nwhere \\(\\chi_{[-1,1]}\\) is the characteristic function of \\([-1,1]\\). Clearly \\(\\hat f\\) is continuous (because \\(\\beta>0\\)) and \\(\\operatorname{supp}\\hat f\\subseteq[-1,1]\\). Moreover, \\(\\hat f\\in L^2(\\mathbb R)\\) because it is bounded and compactly supported.\n\nThe inverse Fourier transform (using the convention \\(\\hat f(\\xi)=\\int f(x)e^{-2\\pi i x\\xi}\\,dx\\)) is  \n\\[\nf(x)=\\int_{-1}^1 (1-|\\xi|)^\\beta e^{2\\pi i x\\xi}\\,d\\xi\n      =2\\int_0^1 (1-\\xi)^\\beta \\cos(2\\pi x\\xi)\\,d\\xi.\n\\]\n\nWe verify that \\(f\\in L^1(\\mathbb R)\\cap L^2(\\mathbb R)\\):\n- **\\(L^2\\):** By Plancherel, \\(\\|f\\|_{L^2}=\\|\\hat f\\|_{L^2}<\\infty\\).\n- **\\(L^1\\):** For large \\(|x|\\), standard asymptotic analysis (see below) gives  \n  \\[\n  |f(x)| \\sim C_\\beta\\, |x|^{-\\beta-1}\\qquad (|x|\\to\\infty).\n  \\]  \n  Since \\(\\beta+1>1\\), the tail \\(\\int_{|x|>1}|f(x)|\\,dx\\) converges; near \\(x=0\\) the function is bounded. Hence \\(f\\in L^1\\).\n\nThus \\(f\\) satisfies all the hypotheses.\n\n#### Asymptotic decay of \\(f\\)\nWrite for \\(x>0\\) (the case \\(x<0\\) is symmetric)\n\\[\nf(x)=2\\operatorname{Re}\\!\\left(e^{2\\pi i x}\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du\\right),\\qquad u=1-\\xi.\n\\]\nThe integral \\(\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du\\) has the well\u2011known asymptotic expansion (see, e.g., Erd\u00e9lyi, *Asymptotic Expansions*)\n\\[\n\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du = \n\\Gamma(\\beta+1)(2\\pi i x)^{-\\beta-1} + O\\bigl(|x|^{-\\beta-2}\\bigr),\\qquad x\\to\\infty.\n\\]\nConsequently,\n\\[\n|f(x)| = \\frac{2\\Gamma(\\beta+1)}{(2\\pi)^{\\beta+1}}\\,|x|^{-\\beta-1} + O\\bigl(|x|^{-\\beta-2}\\bigr).\n\\]\nIn particular, there exist constants \\(c,C>0\\) such that for all sufficiently large \\(|x|\\),\n\\[\nc\\,|x|^{-\\beta-1} \\le |f(x)| \\le C\\,|x|^{-\\beta-1}.\n\\]\n\n#### Failure of the claimed bound\nBecause \\(0<\\beta<1\\), we have \\(\\beta+1<2\\). Therefore\n\\[\n\\lim_{|x|\\to\\infty} |f(x)|\\,(1+|x|)^{2} = \\infty.\n\\]\nHence **no** constant \\(C_0\\) can satisfy \\(|f(x)|\\le C_0(1+|x|)^{-2}\\) for all \\(x\\). This already contradicts the required inequality for the multi\u2011index \\(\\alpha=0\\).\n\n**Remark.** The same construction works in \\(\\mathbb R^n\\) by taking \\(\\hat f(\\xi)=(1-|\\xi|)^\\beta\\) for \\(|\\xi|\\le1\\) and \\(0\\) otherwise, with \\(0<\\beta<n/2\\). Then \\(f\\) decays like \\(|x|^{-\\beta-1-n/2}\\) (by the asymptotics of radial Fourier transforms), and the condition \\(\\beta+1+n/2 < n+1\\) (i.e., \\(\\beta<n/2\\)) makes the decay slower than \\((1+|x|)^{-n-1}\\). The \\(L^1\\) condition requires \\(\\beta+1+n/2 > n\\), i.e., \\(\\beta>0\\), so such \\(\\beta\\) exist. Thus the counterexample is valid in any dimension.\n\n### 3. The smoothness part is true\nAlthough the decay estimate fails, the claim that \\(f\\) is smooth is correct and can be proved as follows. Because \\(\\hat f\\) is supported in the compact set \\(\\overline{B(0,1)}\\) and belongs to \\(L^1(\\mathbb R^n)\\) (it is in \\(L^2\\) and compactly supported, hence in \\(L^1\\)), the inversion formula\n\\[\nf(x)=\\int_{B(0,1)} \\hat f(\\xi)\\,e^{2\\pi i x\\cdot\\xi}\\,d\\xi\n\\]\nholds for every \\(x\\) and represents \\(f\\) as a continuous function. For any multi\u2011index \\(\\alpha\\), differentiation under the integral sign yields\n\\[\n\\partial^\\alpha f(x)=\\int_{B(0,1)} \\hat f(\\xi)\\,(2\\pi i\\xi)^\\alpha e^{2\\pi i x\\cdot\\xi}\\,d\\xi.\n\\]\nThe integrand is bounded by \\(|\\hat f(\\xi)|\\,(2\\pi)^\\alpha\\) (since \\(|\\xi|\\le1\\)) and \\(\\hat f\\in L^1\\); thus \\(\\partial^\\alpha f\\) exists, is continuous, and the differentiation is justified. Hence \\(f\\in C^\\infty(\\mathbb R^n)\\).\n\n### 4. Conclusion\nThe problem is ill\u2011posed because the stated decay estimate does **not** follow from the given assumptions. To make the statement true one would need additional regularity on \\(\\hat f\\) (e.g., \\(\\hat f\\in C^{n}_c\\) or \\(\\hat f\\in C^\\infty_c\\)), which would imply rapid decay of \\(f\\). Alternatively, the conclusion could be weakened to, say, \\(|\\partial^\\alpha f(x)|\\le C_{\\alpha,N}(1+|x|)^{-N}\\) for every \\(N\\) (which would require \\(\\hat f\\in C^\\infty_c\\)).\n\n**Therefore the question cannot be answered as stated; it is ill\u2011posed due to a missing hypothesis.**",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task requires generating a challenging mathematics problem in the domain of abstract harmonic analysis. The problem should be well-posed, solvable, and verifiable.\n[/QUESTION]",
    "run_id": "29",
    "topic_slug": "abstract_harmonic_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem.** Let $G$ be a locally compact abelian group with Haar measure $dx$. Denote by $\\widehat{G}$ its Pontryagin dual group, i.e., the group of continuous characters $\\chi : G \\to \\mathbb{T}$ (where $\\mathbb{T} = \\{z \\in \\mathbb{C} : |z| = 1\\}$) equipped with the compact\u2011open topology. For $f \\in L^1(G)$, define its Fourier transform $\\widehat{f} : \\widehat{G} \\to \\mathbb{C}$ by  \n$$\n\\widehat{f}(\\chi) = \\int_G f(x)\\,\\overline{\\chi(x)}\\,dx.\n$$  \nProve that the Fourier transform is injective: if $\\widehat{f} = 0$ (identically zero on $\\widehat{G}$), then $f = 0$ almost everywhere.\n\n*This problem is well\u2011posed (all terms are standard and the statement is unambiguous), solvable using techniques from abstract harmonic analysis (e.g., approximate identities, convolution, or the Gelfand transform), and its solution can be verified step\u2011by\u2011step.*",
        "raw_answer": "**Problem.** Let \\(G\\) be a locally compact abelian group with Haar measure \\(dx\\). Denote by \\(\\widehat{G}\\) its Pontryagin dual group, i.e., the group of continuous characters \\(\\chi : G \\to \\mathbb{T}\\) (where \\(\\mathbb{T} = \\{z \\in \\mathbb{C} : |z| = 1\\}\\)) equipped with the compact\u2011open topology. For \\(f \\in L^1(G)\\), define its Fourier transform \\(\\widehat{f} : \\widehat{G} \\to \\mathbb{C}\\) by  \n\\[\n\\widehat{f}(\\chi) = \\int_G f(x)\\,\\overline{\\chi(x)}\\,dx.\n\\]  \nProve that the Fourier transform is injective: if \\(\\widehat{f} = 0\\) (identically zero on \\(\\widehat{G}\\)), then \\(f = 0\\) almost everywhere.\n\n*This problem is well\u2011posed (all terms are standard and the statement is unambiguous), solvable using techniques from abstract harmonic analysis (e.g., approximate identities, convolution, or the Gelfand transform), and its solution can be verified step\u2011by\u2011step.*",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging mathematics problem in the domain of \"Integral transforms, operational calculus\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Choose a specific topic within the domain\nLet's focus on the Laplace transform, a key concept within integral transforms and operational calculus. The Laplace transform is defined as $\\mathcal{L}\\{f(t)\\} = \\int_{0}^{\\infty} e^{-st}f(t)dt = F(s)$, where $f(t)$ is a function defined for $t \\geq 0$.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider applying the Laplace transform to solve a differential equation, as this involves understanding both the transform and its inverse. A suitable problem could involve solving an initial value problem (IVP) using the Laplace transform.\n\n## Step 4: Specify the problem\nLet's consider the following IVP: $y'' + 4y = \\sin(2t)$, with initial conditions $y(0) = 0$ and $y'(0) = 0$. The task is to solve for $y(t)$ using the Laplace transform.\n\n## Step 5: Write the problem statement\n\nUse the Laplace transform to solve the initial value problem $y'' + 4y = \\sin(2t)$, where $y(0) = 0$ and $y'(0) = 0$.\n\n## Step 6: Provide the solution\nTo solve the given IVP using the Laplace transform, we first apply the Laplace transform to both sides of the differential equation.\n\n## Step 7: Apply the Laplace transform to the differential equation\n$\\mathcal{L}\\{y'' + 4y\\} = \\mathcal{L}\\{\\sin(2t)\\}$. Using linearity, we get $\\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\}$.\n\n## Step 8: Evaluate the Laplace transforms\n$\\mathcal{L}\\{y''\\} = s^2Y(s) - sy(0) - y'(0)$ and $\\mathcal{L}\\{y\\} = Y(s)$, where $Y(s) = \\mathcal{L}\\{y(t)\\}$. Given $y(0) = 0$ and $y'(0) = 0$, $\\mathcal{L}\\{y''\\} = s^2Y(s)$. $\\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4}$.\n\n## Step 9: Substitute the known values and simplify\n$s^2Y(s) + 4Y(s) = \\frac{2}{s^2 + 4}$. Thus, $Y(s)(s^2 + 4) = \\frac{2}{s^2 + 4}$, which simplifies to $Y(s) = \\frac{2}{(s^2 + 4)^2}$.\n\n## Step 10: Find the inverse Laplace transform of $Y(s)$\nTo find $y(t)$, we need $\\mathcal{L}^{-1}\\{Y(s)\\} = \\mathcal{L}^{-1}\\left\\{\\frac{2}{(s^2 + 4)^2}\\right\\}$. Recall that $\\mathcal{L}\\{\\sin(at)\\} = \\frac{a}{s^2 + a^2}$, and use the property that $\\mathcal{L}^{-1}\\{F(s)\\} = f(t)$ implies $\\mathcal{L}^{-1}\\left\\{\\frac{d}{ds}F(s)\\right\\} = -tf(t)$, or more directly, utilize the convolution or known transforms.\n\n## Step 11: Evaluate the inverse Laplace transform\nUsing the formula for $\\mathcal{L}^{-1}\\left\\{\\frac{2a^3}{(s^2 + a^2)^2}\\right\\} = \\sin(at) - at\\cos(at)$ with $a = 2$, we adjust for our case: $\\mathcal{L}^{-1}\\left\\{\\frac{2}{(s^2 + 4)^2}\\right\\} = \\frac{1}{4}\\mathcal{L}^{-1}\\left\\{\\frac{2 \\cdot 2^3}{(s^2 + 2^2)^2}\\right\\} = \\frac{1}{4}(\\sin(2t) - 2t\\cos(2t))$.\n\n## Step 12: Write the complete solution",
    "run_id": "30",
    "topic_slug": "integral_transforms_and_operational_calculus",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe are given the initial value problem\n\n$$\ny''(t) + 4y(t) = \\sin(2t), \\qquad y(0)=0,\\; y'(0)=0.\n$$\n\nWe solve it using the Laplace transform.\n\nLet $Y(s) = \\mathcal{L}\\{y(t)\\}(s)$. Taking the Laplace transform of both sides and using linearity:\n\n$$\n\\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\}.\n$$\n\nRecall the Laplace transform of a derivative:\n\n$$\n\\mathcal{L}\\{y'\\} = sY(s) - y(0), \\qquad \\mathcal{L}\\{y''\\} = s^2Y(s) - s y(0) - y'(0).\n$$\n\nWith the given initial conditions $y(0)=0$, $y'(0)=0$, we obtain\n\n$$\n\\mathcal{L}\\{y''\\} = s^2 Y(s), \\qquad \\mathcal{L}\\{y\\} = Y(s).\n$$\n\nAlso, $\\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2+4}$.\n\nSubstituting these into the equation yields\n\n$$\ns^2 Y(s) + 4 Y(s) = \\frac{2}{s^2+4}.\n$$\n\nFactor $Y(s)$:\n\n$$\n(s^2+4) Y(s) = \\frac{2}{s^2+4},\n$$\n\nso\n\n$$\nY(s) = \\frac{2}{(s^2+4)^2}.\n$$\n\nNow we need to find the inverse Laplace transform $y(t) = \\mathcal{L}^{-1}\\{Y(s)\\}$.\n\nWe compute the inverse using the convolution theorem. Observe that\n\n$$\n\\frac{2}{(s^2+4)^2} = \\frac{2}{s^2+4} \\cdot \\frac{1}{s^2+4}.\n$$\n\nWe know the inverse transforms:\n\n$$\n\\mathcal{L}^{-1}\\left\\{\\frac{2}{s^2+4}\\right\\} = \\sin(2t), \\qquad\n\\mathcal{L}^{-1}\\left\\{\\frac{1}{s^2+4}\\right\\} = \\frac{1}{2}\\sin(2t).\n$$\n\nBy the convolution theorem, $\\mathcal{L}^{-1}\\{F(s)G(s)\\} = (f * g)(t)$, where $(f*g)(t) = \\int_0^t f(\\tau)g(t-\\tau)\\,d\\tau$. Hence\n\n$$\ny(t) = \\sin(2t) * \\frac{1}{2}\\sin(2t) = \\frac{1}{2} \\int_0^t \\sin(2\\tau)\\,\\sin\\bigl(2(t-\\tau)\\bigr)\\,d\\tau.\n$$\n\nSimplify the product using the trigonometric identity $\\sin A \\sin B = \\frac{1}{2}\\bigl[\\cos(A-B) - \\cos(A+B)\\bigr]$. With $A = 2\\tau$ and $B = 2(t-\\tau) = 2t - 2\\tau$, we have\n\n$$\nA-B = 2\\tau - (2t-2\\tau) = 4\\tau - 2t, \\qquad A+B = 2\\tau + (2t-2\\tau) = 2t.\n$$\n\nThus\n\n$$\n\\sin(2\\tau)\\sin\\bigl(2(t-\\tau)\\bigr) = \\frac{1}{2}\\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr].\n$$\n\nSubstituting into the integral:\n\n$$\ny(t) = \\frac{1}{2} \\int_0^t \\frac{1}{2}\\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr]\\,d\\tau\n= \\frac{1}{4} \\int_0^t \\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr]\\,d\\tau.\n$$\n\nNow evaluate the two integrals separately.\n\n$$\n\\int_0^t \\cos(4\\tau-2t)\\,d\\tau = \\left[\\frac{1}{4}\\sin(4\\tau-2t)\\right]_{\\tau=0}^{\\tau=t}\n= \\frac{1}{4}\\bigl[\\sin(4t-2t) - \\sin(-2t)\\bigr]\n= \\frac{1}{4}\\bigl[\\sin(2t) + \\sin(2t)\\bigr] = \\frac{1}{2}\\sin(2t).\n$$\n\n$$\n\\int_0^t \\cos(2t)\\,d\\tau = \\cos(2t) \\int_0^t d\\tau = t\\cos(2t).\n$$\n\nTherefore,\n\n$$\ny(t) = \\frac{1}{4}\\left( \\frac{1}{2}\\sin(2t) - t\\cos(2t) \\right)\n= \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t).\n$$\n\nWe can also write this as\n\n$$\ny(t) = \\frac{1}{8}\\bigl(\\sin(2t) - 2t\\cos(2t)\\bigr).\n$$\n\nFinally, we verify that this solution satisfies the initial conditions and the differential equation.\n\n- $y(0) = \\frac{1}{8}(\\sin 0 - 0) = 0$.\n- Differentiate: $y'(t) = \\frac{1}{8}\\bigl(2\\cos(2t) - 2\\cos(2t) + 4t\\sin(2t)\\bigr) = \\frac{1}{2}t\\sin(2t)$, so $y'(0)=0$.\n- Second derivative: $y''(t) = \\frac{1}{2}\\sin(2t) + t\\cos(2t)$. Then\n\n$$\ny''(t) + 4y(t) = \\left(\\frac{1}{2}\\sin(2t) + t\\cos(2t)\\right) + 4\\left(\\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t)\\right)\n= \\frac{1}{2}\\sin(2t) + t\\cos(2t) + \\frac{1}{2}\\sin(2t) - t\\cos(2t) = \\sin(2t),\n$$\n\nwhich matches the right-hand side.\n\nHence the solution to the initial value problem is\n\n$$\n\\boxed{y(t) = \\frac{1}{8}\\bigl(\\sin(2t) - 2t\\cos(2t)\\bigr)}.\n$$",
        "raw_answer": "**Solution**\n\nWe are given the initial value problem\n\n\\[\ny''(t) + 4y(t) = \\sin(2t), \\qquad y(0)=0,\\; y'(0)=0.\n\\]\n\nWe solve it using the Laplace transform.\n\nLet \\(Y(s) = \\mathcal{L}\\{y(t)\\}(s)\\). Taking the Laplace transform of both sides and using linearity:\n\n\\[\n\\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\}.\n\\]\n\nRecall the Laplace transform of a derivative:\n\n\\[\n\\mathcal{L}\\{y'\\} = sY(s) - y(0), \\qquad \\mathcal{L}\\{y''\\} = s^2Y(s) - s y(0) - y'(0).\n\\]\n\nWith the given initial conditions \\(y(0)=0\\), \\(y'(0)=0\\), we obtain\n\n\\[\n\\mathcal{L}\\{y''\\} = s^2 Y(s), \\qquad \\mathcal{L}\\{y\\} = Y(s).\n\\]\n\nAlso, \\(\\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2+4}\\).\n\nSubstituting these into the equation yields\n\n\\[\ns^2 Y(s) + 4 Y(s) = \\frac{2}{s^2+4}.\n\\]\n\nFactor \\(Y(s)\\):\n\n\\[\n(s^2+4) Y(s) = \\frac{2}{s^2+4},\n\\]\n\nso\n\n\\[\nY(s) = \\frac{2}{(s^2+4)^2}.\n\\]\n\nNow we need to find the inverse Laplace transform \\(y(t) = \\mathcal{L}^{-1}\\{Y(s)\\}\\).\n\nWe compute the inverse using the convolution theorem. Observe that\n\n\\[\n\\frac{2}{(s^2+4)^2} = \\frac{2}{s^2+4} \\cdot \\frac{1}{s^2+4}.\n\\]\n\nWe know the inverse transforms:\n\n\\[\n\\mathcal{L}^{-1}\\left\\{\\frac{2}{s^2+4}\\right\\} = \\sin(2t), \\qquad\n\\mathcal{L}^{-1}\\left\\{\\frac{1}{s^2+4}\\right\\} = \\frac{1}{2}\\sin(2t).\n\\]\n\nBy the convolution theorem, \\(\\mathcal{L}^{-1}\\{F(s)G(s)\\} = (f * g)(t)\\), where \\((f*g)(t) = \\int_0^t f(\\tau)g(t-\\tau)\\,d\\tau\\). Hence\n\n\\[\ny(t) = \\sin(2t) * \\frac{1}{2}\\sin(2t) = \\frac{1}{2} \\int_0^t \\sin(2\\tau)\\,\\sin\\bigl(2(t-\\tau)\\bigr)\\,d\\tau.\n\\]\n\nSimplify the product using the trigonometric identity \\(\\sin A \\sin B = \\frac{1}{2}\\bigl[\\cos(A-B) - \\cos(A+B)\\bigr]\\). With \\(A = 2\\tau\\) and \\(B = 2(t-\\tau) = 2t - 2\\tau\\), we have\n\n\\[\nA-B = 2\\tau - (2t-2\\tau) = 4\\tau - 2t, \\qquad A+B = 2\\tau + (2t-2\\tau) = 2t.\n\\]\n\nThus\n\n\\[\n\\sin(2\\tau)\\sin\\bigl(2(t-\\tau)\\bigr) = \\frac{1}{2}\\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr].\n\\]\n\nSubstituting into the integral:\n\n\\[\ny(t) = \\frac{1}{2} \\int_0^t \\frac{1}{2}\\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr]\\,d\\tau\n= \\frac{1}{4} \\int_0^t \\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr]\\,d\\tau.\n\\]\n\nNow evaluate the two integrals separately.\n\n\\[\n\\int_0^t \\cos(4\\tau-2t)\\,d\\tau = \\left[\\frac{1}{4}\\sin(4\\tau-2t)\\right]_{\\tau=0}^{\\tau=t}\n= \\frac{1}{4}\\bigl[\\sin(4t-2t) - \\sin(-2t)\\bigr]\n= \\frac{1}{4}\\bigl[\\sin(2t) + \\sin(2t)\\bigr] = \\frac{1}{2}\\sin(2t).\n\\]\n\n\\[\n\\int_0^t \\cos(2t)\\,d\\tau = \\cos(2t) \\int_0^t d\\tau = t\\cos(2t).\n\\]\n\nTherefore,\n\n\\[\ny(t) = \\frac{1}{4}\\left( \\frac{1}{2}\\sin(2t) - t\\cos(2t) \\right)\n= \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t).\n\\]\n\nWe can also write this as\n\n\\[\ny(t) = \\frac{1}{8}\\bigl(\\sin(2t) - 2t\\cos(2t)\\bigr).\n\\]\n\nFinally, we verify that this solution satisfies the initial conditions and the differential equation.\n\n- \\(y(0) = \\frac{1}{8}(\\sin 0 - 0) = 0\\).\n- Differentiate: \\(y'(t) = \\frac{1}{8}\\bigl(2\\cos(2t) - 2\\cos(2t) + 4t\\sin(2t)\\bigr) = \\frac{1}{2}t\\sin(2t)\\), so \\(y'(0)=0\\).\n- Second derivative: \\(y''(t) = \\frac{1}{2}\\sin(2t) + t\\cos(2t)\\). Then\n\n\\[\ny''(t) + 4y(t) = \\left(\\frac{1}{2}\\sin(2t) + t\\cos(2t)\\right) + 4\\left(\\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t)\\right)\n= \\frac{1}{2}\\sin(2t) + t\\cos(2t) + \\frac{1}{2}\\sin(2t) - t\\cos(2t) = \\sin(2t),\n\\]\n\nwhich matches the right-hand side.\n\nHence the solution to the initial value problem is\n\n\\[\n\\boxed{y(t) = \\frac{1}{8}\\bigl(\\sin(2t) - 2t\\cos(2t)\\bigr)}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of integral equations, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the specific domain within integral equations\nIntegral equations involve equations where the unknown function appears under an integral sign. A common type is the Fredholm integral equation of the second kind, given by $f(x) = g(x) + \\lambda \\int_{a}^{b} K(x, t)f(t)dt$, where $f(x)$ is the unknown function, $g(x)$ and $K(x, t)$ are known functions, and $\\lambda$ is a parameter.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider a specific case of the Fredholm integral equation of the second kind with a given kernel $K(x, t)$ and a function $g(x)$, and ask to solve for $f(x)$.\n\n## Step 4: Specify the problem\nLet's consider the integral equation $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$. This is a Fredholm integral equation of the second kind. We need to find $f(x)$.\n\n## Step 5: Provide the solution\nTo solve $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$, let's first simplify the integral.\n$f(x) = x + x\\int_{0}^{1} tf(t)dt + x\\int_{0}^{1} f(t)dt + \\int_{0}^{1} tf(t)dt$.\nLet $A = \\int_{0}^{1} f(t)dt$ and $B = \\int_{0}^{1} tf(t)dt$. Then, $f(x) = x + xB + xA + B = x(1 + A + B) + B$.\n\n## Step 6: Calculate A and B using the definitions\nSubstitute $f(x)$ from Step 5 into the definitions of $A$ and $B$.\n$A = \\int_{0}^{1} [t(1 + A + B) + B]dt = \\left[\\frac{t^2}{2}(1 + A + B) + Bt\\right]_{0}^{1} = \\frac{1}{2}(1 + A + B) + B$.\n$B = \\int_{0}^{1} t[t(1 + A + B) + B]dt = \\left[\\frac{t^3}{3}(1 + A + B) + \\frac{Bt^2}{2}\\right]_{0}^{1} = \\frac{1}{3}(1 + A + B) + \\frac{B}{2}$.\n\n## Step 7: Solve for A and B\nFrom Step 6, we have:\n1. $A = \\frac{1}{2}(1 + A + B) + B$\n2. $B = \\frac{1}{3}(1 + A + B) + \\frac{B}{2}$.\n\nSimplifying these equations:\n1. $A = \\frac{1}{2} + \\frac{A}{2} + \\frac{B}{2} + B$ implies $\\frac{A}{2} = \\frac{1}{2} + \\frac{3B}{2}$, so $A = 1 + 3B$.\n2. $B = \\frac{1}{3} + \\frac{A}{3} + \\frac{B}{3} + \\frac{B}{2}$ implies $B - \\frac{B}{2} - \\frac{B}{3} = \\frac{1}{3} + \\frac{A}{3}$, so $\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3}$.\n\n## Step 8: Continue solving for A and B\nFrom equation 2 in Step 7: $\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3}$, we get $B = 2 + 2A$.\nSubstitute $A = 1 + 3B$ from Step 7 into $B = 2 + 2A$:\n$B = 2 + 2(1 + 3B)$, so $B = 2 + 2 + 6B$, which simplifies to $B = 4 + 6B$, hence $-5B = 4$, and $B = -\\frac{4}{5}$.\n\n## Step 9: Find A using B\nSubstitute $B = -\\frac{4}{5}$ into $A = 1 + 3B$:\n$A = 1 + 3(-\\frac{4}{5}) = 1 - \\frac{12}{5} = -\\frac{7}{5}$.\n\n## Step 10: Substitute A and B back into f(x)\n$f(x) = x(1 + A + B) + B = x(1 - \\frac{7}{5} - \\frac{4}{5}) - \\frac{4}{5}$.\n$f(x) = x(1 - \\frac{11}{5}) - \\frac{4}{5} = x(-\\frac{6}{5}) - \\frac{4}{5}$.\n$f(x) = -\\frac{6}{5}x - \\frac{4}{5}$.\n\nThe final answer is: \n\nSolve the integral equation $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$ for $f(x)$.",
    "run_id": "31",
    "topic_slug": "integral_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are to solve the Fredholm integral equation of the second kind\n\n$$\nf(x) = x + \\int_0^1 (xt + x + t) f(t) \\, dt,\n$$\n\nwhere $f$ is an unknown continuous function on $[0,1]$.  The kernel is separable (degenerate), so the solution can be reduced to solving a linear system for two constants.\n\n---\n\n### Step 1.  Introduce the necessary integrals\n\nDefine the two constants\n\n$$\nA = \\int_0^1 f(t) \\, dt, \\qquad B = \\int_0^1 t f(t) \\, dt.\n$$\n\nThese are numbers (provided the integrals exist).\n\n### Step 2.  Express $f(x)$ in terms of $A$ and $B$\n\nRewrite the integral:\n\n$$\n\\int_0^1 (xt + x + t) f(t) \\, dt\n= x \\int_0^1 t f(t) \\, dt + x \\int_0^1 f(t) \\, dt + \\int_0^1 t f(t) \\, dt\n= x B + x A + B.\n$$\n\nHence the integral equation becomes\n\n$$\nf(x) = x + x B + x A + B = x(1 + A + B) + B. \\tag{1}\n$$\n\n### Step 3.  Obtain equations for $A$ and $B$\n\nSubstitute the expression (1) into the definitions of $A$ and $B$.\n\n**Compute $A$:**\n\n$$\n\\begin{aligned}\nA &= \\int_0^1 f(t) \\, dt\n= \\int_0^1 \\bigl[ t(1 + A + B) + B \\bigr] \\, dt \\\\\n&= (1 + A + B) \\int_0^1 t \\, dt + B \\int_0^1 1 \\, dt \\\\\n&= (1 + A + B) \\cdot \\frac{1}{2} + B \\cdot 1 \\\\\n&= \\frac{1}{2}(1 + A + B) + B.\n\\end{aligned}\n$$\n\n**Compute $B$:**\n\n$$\n\\begin{aligned}\nB &= \\int_0^1 t f(t) \\, dt\n= \\int_0^1 t \\bigl[ t(1 + A + B) + B \\bigr] \\, dt \\\\\n&= (1 + A + B) \\int_0^1 t^2 \\, dt + B \\int_0^1 t \\, dt \\\\\n&= (1 + A + B) \\cdot \\frac{1}{3} + B \\cdot \\frac{1}{2} \\\\\n&= \\frac{1}{3}(1 + A + B) + \\frac{B}{2}.\n\\end{aligned}\n$$\n\nThus we have the system\n\n$$\n\\begin{cases}\nA = \\dfrac{1}{2}(1 + A + B) + B, \\$$6pt]\nB = \\dfrac{1}{3}(1 + A + B) + \\dfrac{B}{2}.\n\\end{cases} \\tag{2}\n$$\n\n### Step 4.  Simplify the equations\n\nSimplify the first equation:\n\n$$\nA = \\frac{1}{2} + \\frac{A}{2} + \\frac{B}{2} + B\n= \\frac{1}{2} + \\frac{A}{2} + \\frac{3B}{2}.\n$$\n\nBring the term $\\frac{A}{2}$ to the left:\n\n$$\nA - \\frac{A}{2} = \\frac{1}{2} + \\frac{3B}{2}\n\\quad\\Longrightarrow\\quad\n\\frac{A}{2} = \\frac{1}{2} + \\frac{3B}{2}.\n$$\n\nMultiplying by $2$ gives\n\n$$\nA = 1 + 3B. \\tag{3}\n$$\n\nNow simplify the second equation:\n\n$$\nB = \\frac{1}{3} + \\frac{A}{3} + \\frac{B}{3} + \\frac{B}{2}.\n$$\n\nCollect the $B$ terms on the left:\n\n$$\nB - \\frac{B}{3} - \\frac{B}{2} = \\frac{1}{3} + \\frac{A}{3}.\n$$\n\nThe left\u2011hand side is\n\n$$\nB\\left(1 - \\frac{1}{3} - \\frac{1}{2}\\right) = B\\left(\\frac{6}{6} - \\frac{2}{6} - \\frac{3}{6}\\right) = B \\cdot \\frac{1}{6} = \\frac{B}{6}.\n$$\n\nHence\n\n$$\n\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3} = \\frac{1 + A}{3}.\n$$\n\nMultiplying both sides by $6$ yields\n\n$$\nB = 2(1 + A) = 2 + 2A. \\tag{4}\n$$\n\n### Step 5.  Solve the linear system\n\nWe have from (3) and (4):\n\n$$\n\\begin{cases}\nA = 1 + 3B, \\\\\nB = 2 + 2A.\n\\end{cases}\n$$\n\nSubstitute $A$ from the first equation into the second:\n\n$$\nB = 2 + 2(1 + 3B) = 2 + 2 + 6B = 4 + 6B.\n$$\n\nThus\n\n$$\nB - 6B = 4 \\quad\\Longrightarrow\\quad -5B = 4 \\quad\\Longrightarrow\\quad B = -\\frac{4}{5}.\n$$\n\nInsert this into (3):\n\n$$\nA = 1 + 3\\left(-\\frac{4}{5}\\right) = 1 - \\frac{12}{5} = -\\frac{7}{5}.\n$$\n\n### Step 6.  Write the solution $f(x)$\n\nUsing (1) with the obtained values:\n\n$$\nf(x) = x(1 + A + B) + B = x\\left(1 - \\frac{7}{5} - \\frac{4}{5}\\right) - \\frac{4}{5}\n= x\\left(1 - \\frac{11}{5}\\right) - \\frac{4}{5}\n= x\\left(-\\frac{6}{5}\\right) - \\frac{4}{5}.\n$$\n\nTherefore\n\n$$\n\\boxed{f(x) = -\\frac{6}{5}\\,x - \\frac{4}{5}}.\n$$\n\n### Step 7.  Verification (optional but confirming correctness)\n\nCompute the integrals with this $f$:\n\n$$\nA = \\int_0^1 \\left(-\\frac{6}{5}t - \\frac{4}{5}\\right) dt\n= -\\frac{6}{5}\\cdot\\frac{1}{2} - \\frac{4}{5}\\cdot 1\n= -\\frac{3}{5} - \\frac{4}{5} = -\\frac{7}{5},\n$$\n\n$$\nB = \\int_0^1 t\\left(-\\frac{6}{5}t - \\frac{4}{5}\\right) dt\n= -\\frac{6}{5}\\int_0^1 t^2 dt - \\frac{4}{5}\\int_0^1 t dt\n= -\\frac{6}{5}\\cdot\\frac{1}{3} - \\frac{4}{5}\\cdot\\frac{1}{2}\n= -\\frac{2}{5} - \\frac{2}{5} = -\\frac{4}{5}.\n$$\n\nNow evaluate the right\u2011hand side of the original equation:\n\n$$\nx + xB + xA + B = x + x\\left(-\\frac{4}{5}\\right) + x\\left(-\\frac{7}{5}\\right) + \\left(-\\frac{4}{5}\\right)\n= x\\left(1 - \\frac{4}{5} - \\frac{7}{5}\\right) - \\frac{4}{5}\n= x\\left(-\\frac{6}{5}\\right) - \\frac{4}{5} = f(x).\n$$\n\nThus the function satisfies the integral equation identically.  Because the kernel is degenerate, the solution is unique; no other continuous solutions exist.\n\n---\n\n**Final answer:** $\\displaystyle f(x) = -\\frac{6}{5}x - \\frac{4}{5}$.",
        "raw_answer": "We are to solve the Fredholm integral equation of the second kind\n\n\\[\nf(x) = x + \\int_0^1 (xt + x + t) f(t) \\, dt,\n\\]\n\nwhere \\(f\\) is an unknown continuous function on \\([0,1]\\).  The kernel is separable (degenerate), so the solution can be reduced to solving a linear system for two constants.\n\n---\n\n### Step 1.  Introduce the necessary integrals\n\nDefine the two constants\n\n\\[\nA = \\int_0^1 f(t) \\, dt, \\qquad B = \\int_0^1 t f(t) \\, dt.\n\\]\n\nThese are numbers (provided the integrals exist).\n\n### Step 2.  Express \\(f(x)\\) in terms of \\(A\\) and \\(B\\)\n\nRewrite the integral:\n\n\\[\n\\int_0^1 (xt + x + t) f(t) \\, dt\n= x \\int_0^1 t f(t) \\, dt + x \\int_0^1 f(t) \\, dt + \\int_0^1 t f(t) \\, dt\n= x B + x A + B.\n\\]\n\nHence the integral equation becomes\n\n\\[\nf(x) = x + x B + x A + B = x(1 + A + B) + B. \\tag{1}\n\\]\n\n### Step 3.  Obtain equations for \\(A\\) and \\(B\\)\n\nSubstitute the expression (1) into the definitions of \\(A\\) and \\(B\\).\n\n**Compute \\(A\\):**\n\n\\[\n\\begin{aligned}\nA &= \\int_0^1 f(t) \\, dt\n= \\int_0^1 \\bigl[ t(1 + A + B) + B \\bigr] \\, dt \\\\\n&= (1 + A + B) \\int_0^1 t \\, dt + B \\int_0^1 1 \\, dt \\\\\n&= (1 + A + B) \\cdot \\frac{1}{2} + B \\cdot 1 \\\\\n&= \\frac{1}{2}(1 + A + B) + B.\n\\end{aligned}\n\\]\n\n**Compute \\(B\\):**\n\n\\[\n\\begin{aligned}\nB &= \\int_0^1 t f(t) \\, dt\n= \\int_0^1 t \\bigl[ t(1 + A + B) + B \\bigr] \\, dt \\\\\n&= (1 + A + B) \\int_0^1 t^2 \\, dt + B \\int_0^1 t \\, dt \\\\\n&= (1 + A + B) \\cdot \\frac{1}{3} + B \\cdot \\frac{1}{2} \\\\\n&= \\frac{1}{3}(1 + A + B) + \\frac{B}{2}.\n\\end{aligned}\n\\]\n\nThus we have the system\n\n\\[\n\\begin{cases}\nA = \\dfrac{1}{2}(1 + A + B) + B, \\\\[6pt]\nB = \\dfrac{1}{3}(1 + A + B) + \\dfrac{B}{2}.\n\\end{cases} \\tag{2}\n\\]\n\n### Step 4.  Simplify the equations\n\nSimplify the first equation:\n\n\\[\nA = \\frac{1}{2} + \\frac{A}{2} + \\frac{B}{2} + B\n= \\frac{1}{2} + \\frac{A}{2} + \\frac{3B}{2}.\n\\]\n\nBring the term \\(\\frac{A}{2}\\) to the left:\n\n\\[\nA - \\frac{A}{2} = \\frac{1}{2} + \\frac{3B}{2}\n\\quad\\Longrightarrow\\quad\n\\frac{A}{2} = \\frac{1}{2} + \\frac{3B}{2}.\n\\]\n\nMultiplying by \\(2\\) gives\n\n\\[\nA = 1 + 3B. \\tag{3}\n\\]\n\nNow simplify the second equation:\n\n\\[\nB = \\frac{1}{3} + \\frac{A}{3} + \\frac{B}{3} + \\frac{B}{2}.\n\\]\n\nCollect the \\(B\\) terms on the left:\n\n\\[\nB - \\frac{B}{3} - \\frac{B}{2} = \\frac{1}{3} + \\frac{A}{3}.\n\\]\n\nThe left\u2011hand side is\n\n\\[\nB\\left(1 - \\frac{1}{3} - \\frac{1}{2}\\right) = B\\left(\\frac{6}{6} - \\frac{2}{6} - \\frac{3}{6}\\right) = B \\cdot \\frac{1}{6} = \\frac{B}{6}.\n\\]\n\nHence\n\n\\[\n\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3} = \\frac{1 + A}{3}.\n\\]\n\nMultiplying both sides by \\(6\\) yields\n\n\\[\nB = 2(1 + A) = 2 + 2A. \\tag{4}\n\\]\n\n### Step 5.  Solve the linear system\n\nWe have from (3) and (4):\n\n\\[\n\\begin{cases}\nA = 1 + 3B, \\\\\nB = 2 + 2A.\n\\end{cases}\n\\]\n\nSubstitute \\(A\\) from the first equation into the second:\n\n\\[\nB = 2 + 2(1 + 3B) = 2 + 2 + 6B = 4 + 6B.\n\\]\n\nThus\n\n\\[\nB - 6B = 4 \\quad\\Longrightarrow\\quad -5B = 4 \\quad\\Longrightarrow\\quad B = -\\frac{4}{5}.\n\\]\n\nInsert this into (3):\n\n\\[\nA = 1 + 3\\left(-\\frac{4}{5}\\right) = 1 - \\frac{12}{5} = -\\frac{7}{5}.\n\\]\n\n### Step 6.  Write the solution \\(f(x)\\)\n\nUsing (1) with the obtained values:\n\n\\[\nf(x) = x(1 + A + B) + B = x\\left(1 - \\frac{7}{5} - \\frac{4}{5}\\right) - \\frac{4}{5}\n= x\\left(1 - \\frac{11}{5}\\right) - \\frac{4}{5}\n= x\\left(-\\frac{6}{5}\\right) - \\frac{4}{5}.\n\\]\n\nTherefore\n\n\\[\n\\boxed{f(x) = -\\frac{6}{5}\\,x - \\frac{4}{5}}.\n\\]\n\n### Step 7.  Verification (optional but confirming correctness)\n\nCompute the integrals with this \\(f\\):\n\n\\[\nA = \\int_0^1 \\left(-\\frac{6}{5}t - \\frac{4}{5}\\right) dt\n= -\\frac{6}{5}\\cdot\\frac{1}{2} - \\frac{4}{5}\\cdot 1\n= -\\frac{3}{5} - \\frac{4}{5} = -\\frac{7}{5},\n\\]\n\n\\[\nB = \\int_0^1 t\\left(-\\frac{6}{5}t - \\frac{4}{5}\\right) dt\n= -\\frac{6}{5}\\int_0^1 t^2 dt - \\frac{4}{5}\\int_0^1 t dt\n= -\\frac{6}{5}\\cdot\\frac{1}{3} - \\frac{4}{5}\\cdot\\frac{1}{2}\n= -\\frac{2}{5} - \\frac{2}{5} = -\\frac{4}{5}.\n\\]\n\nNow evaluate the right\u2011hand side of the original equation:\n\n\\[\nx + xB + xA + B = x + x\\left(-\\frac{4}{5}\\right) + x\\left(-\\frac{7}{5}\\right) + \\left(-\\frac{4}{5}\\right)\n= x\\left(1 - \\frac{4}{5} - \\frac{7}{5}\\right) - \\frac{4}{5}\n= x\\left(-\\frac{6}{5}\\right) - \\frac{4}{5} = f(x).\n\\]\n\nThus the function satisfies the integral equation identically.  Because the kernel is degenerate, the solution is unique; no other continuous solutions exist.\n\n---\n\n**Final answer:** \\(\\displaystyle f(x) = -\\frac{6}{5}x - \\frac{4}{5}\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $H$ be a Hilbert space and $T: H \\to H$ be a bounded linear operator. Suppose that $T$ is self-adjoint and satisfies the condition $\\|T\\| \\leq 1$. Prove that the operator $I - T^2$ is positive, where $I$ denotes the identity operator on $H$.",
    "run_id": "32",
    "topic_slug": "functional_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Proof.**  \nSince $T$ is self-adjoint, we have $T^* = T$.  \n\n1. **Self-adjointness of $I - T^2$:**  \n   $(T^2)^* = (T^*)^2 = T^2$, so $T^2$ is self-adjoint. Hence $(I - T^2)^* = I - T^2$, i.e., $I - T^2$ is self-adjoint.\n\n2. **Non\u2011negativity of the quadratic form:**  \n   For any $x \\in H$, the operator norm gives $\\|Tx\\| \\le \\|T\\| \\|x\\|$. Because $\\|T\\| \\le 1$, we obtain $\\|Tx\\| \\le \\|x\\|$.  \n   Using the self-adjointness of $T$, we compute  \n   $$\n   \\langle T^2 x, x \\rangle = \\langle T(Tx), x \\rangle = \\langle Tx, T^* x \\rangle = \\langle Tx, Tx \\rangle = \\|Tx\\|^2.\n   $$  \n   Therefore,  \n   $$\n   \\langle (I - T^2)x, x \\rangle = \\langle x, x \\rangle - \\langle T^2 x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2 \\ge 0.\n   $$\n\n3. **Conclusion:**  \n   $I - T^2$ is a self-adjoint operator whose quadratic form is nonnegative for every $x \\in H$. By definition, this means $I - T^2$ is a positive operator. \u220e",
        "raw_answer": "**Proof.**  \nSince $T$ is self-adjoint, we have $T^* = T$.  \n\n1. **Self-adjointness of $I - T^2$:**  \n   $(T^2)^* = (T^*)^2 = T^2$, so $T^2$ is self-adjoint. Hence $(I - T^2)^* = I - T^2$, i.e., $I - T^2$ is self-adjoint.\n\n2. **Non\u2011negativity of the quadratic form:**  \n   For any $x \\in H$, the operator norm gives $\\|Tx\\| \\le \\|T\\| \\|x\\|$. Because $\\|T\\| \\le 1$, we obtain $\\|Tx\\| \\le \\|x\\|$.  \n   Using the self-adjointness of $T$, we compute  \n   \\[\n   \\langle T^2 x, x \\rangle = \\langle T(Tx), x \\rangle = \\langle Tx, T^* x \\rangle = \\langle Tx, Tx \\rangle = \\|Tx\\|^2.\n   \\]  \n   Therefore,  \n   \\[\n   \\langle (I - T^2)x, x \\rangle = \\langle x, x \\rangle - \\langle T^2 x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2 \\ge 0.\n   \\]\n\n3. **Conclusion:**  \n   $I - T^2$ is a self-adjoint operator whose quadratic form is nonnegative for every $x \\in H$. By definition, this means $I - T^2$ is a positive operator. \u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $T: L^2[0,1] \\to L^2[0,1]$ be defined by $Tf(x) = \\int_{0}^{x} f(t) dt$. Prove that $T$ is compact and find its spectrum.",
    "run_id": "33",
    "topic_slug": "operator_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Answer:**\n\nWe prove that $T$ is compact and determine its spectrum.\n\n---\n\n### 1. Compactness of $T$\n\nDefine the kernel  \n$$\nK(x,t) = \\mathbf{1}_{[0,x]}(t) = \n\\begin{cases}\n1, & 0 \\le t \\le x \\le 1,\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$  \nFor any $f\\in L^2[0,1]$ we have  \n$$\n(Tf)(x) = \\int_0^x f(t)\\,dt = \\int_0^1 K(x,t)f(t)\\,dt.\n$$  \nThe kernel is square\u2011integrable because  \n$$\n\\|K\\|_{L^2([0,1]^2)}^2 = \\int_0^1\\int_0^1 |K(x,t)|^2\\,dt\\,dx = \\int_0^1\\int_0^x 1\\,dt\\,dx = \\int_0^1 x\\,dx = \\frac12 < \\infty.\n$$  \nThus $T$ is a Hilbert\u2013Schmidt integral operator. Every Hilbert\u2013Schmidt operator on $L^2$ is compact (it can be approximated in operator norm by finite\u2011rank operators, e.g., by truncating the kernel). Hence $T$ is compact.\n\n---\n\n### 2. Spectrum $\\sigma(T)$\n\nFirst, because $L^2[0,1]$ is infinite\u2011dimensional and $T$ is compact, $0$ must belong to the spectrum. Indeed, if $0$ were in the resolvent set, then $T$ would be invertible and the identity $I = T T^{-1}$ would be compact \u2013 impossible in an infinite\u2011dimensional space. Thus $0\\in\\sigma(T)$.\n\nNow let $\\lambda \\neq 0$. The **Fredholm alternative** for compact operators states that for $\\lambda \\neq 0$, either $\\lambda$ is an eigenvalue of $T$ or $T-\\lambda I$ is bijective with a bounded inverse. Therefore it suffices to show that $T$ has no nonzero eigenvalues.\n\n**Claim:** $T$ has no nonzero eigenvalues.\n\n*Proof.* Suppose $\\lambda \\neq 0$ and $f\\in L^2[0,1]$ satisfies $Tf = \\lambda f$, i.e.,  \n$$\n\\int_0^x f(t)\\,dt = \\lambda f(x) \\qquad \\text{for a.e. } x\\in[0,1]. \\tag{1}\n$$  \nThe left\u2011hand side is absolutely continuous (as an integral of an $L^1$ function), so the right\u2011hand side $\\lambda f$ is absolutely continuous. Since $\\lambda\\neq 0$, $f$ itself is absolutely continuous. Differentiating (1) with respect to $x$ (which holds almost everywhere by the Lebesgue differentiation theorem) gives  \n$$\nf(x) = \\lambda f'(x) \\qquad \\text{for a.e. } x\\in[0,1]. \\tag{2}\n$$  \nEvaluating (1) at $x=0$ yields $0 = \\lambda f(0)$, hence $f(0)=0$.\n\nThus $f$ satisfies the initial value problem  \n$$\nf'(x) = \\frac{1}{\\lambda} f(x) \\quad \\text{a.e.,} \\qquad f(0)=0.\n$$  \nMultiply by the integrating factor $e^{-x/\\lambda}$:  \n$$\n\\frac{d}{dx}\\bigl( f(x) e^{-x/\\lambda} \\bigr) = 0 \\quad \\text{a.e.},\n$$  \nso $f(x) e^{-x/\\lambda}$ is constant almost everywhere. The constant equals $f(0)e^{0}=0$; therefore $f(x)=0$ for almost every $x$. Hence no nonzero $\\lambda$ can be an eigenvalue of $T$. \u220e\n\nConsequently, for every $\\lambda \\neq 0$, $T-\\lambda I$ is bijective and has a bounded inverse, i.e., $\\lambda$ belongs to the resolvent set $\\rho(T)$. Together with $0\\in\\sigma(T)$ we obtain  \n$$\n\\boxed{\\sigma(T) = \\{0\\}}.\n$$\n\n**Remark.** The point spectrum is empty; in particular $0$ is not an eigenvalue because $Tf=0$ implies $f=0$ a.e.\n\n---\n\nThus $T$ is compact and its spectrum is $\\{0\\}$.",
        "raw_answer": "**Answer:**\n\nWe prove that \\(T\\) is compact and determine its spectrum.\n\n---\n\n### 1. Compactness of \\(T\\)\n\nDefine the kernel  \n\\[\nK(x,t) = \\mathbf{1}_{[0,x]}(t) = \n\\begin{cases}\n1, & 0 \\le t \\le x \\le 1,\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n\\]  \nFor any \\(f\\in L^2[0,1]\\) we have  \n\\[\n(Tf)(x) = \\int_0^x f(t)\\,dt = \\int_0^1 K(x,t)f(t)\\,dt.\n\\]  \nThe kernel is square\u2011integrable because  \n\\[\n\\|K\\|_{L^2([0,1]^2)}^2 = \\int_0^1\\int_0^1 |K(x,t)|^2\\,dt\\,dx = \\int_0^1\\int_0^x 1\\,dt\\,dx = \\int_0^1 x\\,dx = \\frac12 < \\infty.\n\\]  \nThus \\(T\\) is a Hilbert\u2013Schmidt integral operator. Every Hilbert\u2013Schmidt operator on \\(L^2\\) is compact (it can be approximated in operator norm by finite\u2011rank operators, e.g., by truncating the kernel). Hence \\(T\\) is compact.\n\n---\n\n### 2. Spectrum \\(\\sigma(T)\\)\n\nFirst, because \\(L^2[0,1]\\) is infinite\u2011dimensional and \\(T\\) is compact, \\(0\\) must belong to the spectrum. Indeed, if \\(0\\) were in the resolvent set, then \\(T\\) would be invertible and the identity \\(I = T T^{-1}\\) would be compact \u2013 impossible in an infinite\u2011dimensional space. Thus \\(0\\in\\sigma(T)\\).\n\nNow let \\(\\lambda \\neq 0\\). The **Fredholm alternative** for compact operators states that for \\(\\lambda \\neq 0\\), either \\(\\lambda\\) is an eigenvalue of \\(T\\) or \\(T-\\lambda I\\) is bijective with a bounded inverse. Therefore it suffices to show that \\(T\\) has no nonzero eigenvalues.\n\n**Claim:** \\(T\\) has no nonzero eigenvalues.\n\n*Proof.* Suppose \\(\\lambda \\neq 0\\) and \\(f\\in L^2[0,1]\\) satisfies \\(Tf = \\lambda f\\), i.e.,  \n\\[\n\\int_0^x f(t)\\,dt = \\lambda f(x) \\qquad \\text{for a.e. } x\\in[0,1]. \\tag{1}\n\\]  \nThe left\u2011hand side is absolutely continuous (as an integral of an \\(L^1\\) function), so the right\u2011hand side \\(\\lambda f\\) is absolutely continuous. Since \\(\\lambda\\neq 0\\), \\(f\\) itself is absolutely continuous. Differentiating (1) with respect to \\(x\\) (which holds almost everywhere by the Lebesgue differentiation theorem) gives  \n\\[\nf(x) = \\lambda f'(x) \\qquad \\text{for a.e. } x\\in[0,1]. \\tag{2}\n\\]  \nEvaluating (1) at \\(x=0\\) yields \\(0 = \\lambda f(0)\\), hence \\(f(0)=0\\).\n\nThus \\(f\\) satisfies the initial value problem  \n\\[\nf'(x) = \\frac{1}{\\lambda} f(x) \\quad \\text{a.e.,} \\qquad f(0)=0.\n\\]  \nMultiply by the integrating factor \\(e^{-x/\\lambda}\\):  \n\\[\n\\frac{d}{dx}\\bigl( f(x) e^{-x/\\lambda} \\bigr) = 0 \\quad \\text{a.e.},\n\\]  \nso \\(f(x) e^{-x/\\lambda}\\) is constant almost everywhere. The constant equals \\(f(0)e^{0}=0\\); therefore \\(f(x)=0\\) for almost every \\(x\\). Hence no nonzero \\(\\lambda\\) can be an eigenvalue of \\(T\\). \u220e\n\nConsequently, for every \\(\\lambda \\neq 0\\), \\(T-\\lambda I\\) is bijective and has a bounded inverse, i.e., \\(\\lambda\\) belongs to the resolvent set \\(\\rho(T)\\). Together with \\(0\\in\\sigma(T)\\) we obtain  \n\\[\n\\boxed{\\sigma(T) = \\{0\\}}.\n\\]\n\n**Remark.** The point spectrum is empty; in particular \\(0\\) is not an eigenvalue because \\(Tf=0\\) implies \\(f=0\\) a.e.\n\n---\n\nThus \\(T\\) is compact and its spectrum is \\(\\{0\\}\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of calculus of variations and optimal control, along with a complete solution. The problem should be solvable, verifiable, and adhere to the specified format.",
    "run_id": "34",
    "topic_slug": "calculus_of_variations_and_optimization",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem.**  \nA bead slides under the influence of gravity (constant acceleration $g$) along a frictionless wire from point $A(0,0)$ to point $B(x_1,y_1)$ with $y_1>0$. The bead starts from rest at $A$. Find the shape of the wire, i.e., the curve $y(x)$ for $0\\le x\\le x_1$ with $y(0)=0$ and $y(x_1)=y_1$, that minimizes the time of descent.\n\nShow that the time functional is  \n\n$$\nT[y]=\\int_{0}^{x_1}\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{2g\\,y}}\\;dx,\n$$\n\nand determine the minimizing curve explicitly.\n\n---\n\n**Solution.**  \n\n### 1. Derivation of the functional  \nLet the curve be described by $y=y(x)$, $y(0)=0$, $y(x_1)=y_1$. The speed of the bead at a height $y$ follows from conservation of energy:  \n\n$$\n\\frac{1}{2}mv^{2}=mgy\\quad\\Longrightarrow\\quad v=\\sqrt{2gy}.\n$$\n\nAn infinitesimal arc length along the curve is $ds=\\sqrt{1+(y')^{2}}\\,dx$. The time taken to traverse that element is $dt=ds/v$. Hence the total time is  \n\n$$\nT[y]=\\int_{0}^{x_1}\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{2gy}}\\;dx.\n$$\n\nWe ignore the constant factor $1/\\sqrt{2g}$ because it does not affect the minimizer. Thus we study the functional  \n\n$$\nJ[y]=\\int_{0}^{x_1}F(y,y')\\,dx,\\qquad F(y,y')=\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}.\n$$\n\n### 2. Calculus of variations setup  \nWe seek a twice differentiable function $y(x)>0$ for $x>0$ satisfying the fixed endpoints $y(0)=0$, $y(x_1)=y_1$ that minimizes $J$. The Euler\u2011Lagrange equation is  \n\n$$\n\\frac{\\partial F}{\\partial y}-\\frac{d}{dx}\\frac{\\partial F}{\\partial y'}=0.\n$$\n\nBecause $F$ does not depend explicitly on $x$, we may use the **Beltrami identity** (first integral of the Euler\u2011Lagrange equation):  \n\n$$\nF-y'\\frac{\\partial F}{\\partial y'}=C,\\qquad C\\text{ constant}.\n$$\n\nWe verify that this is legitimate: differentiating the left\u2011hand side with respect to $x$ and using the Euler\u2011Lagrange equation yields zero.\n\n### 3. Computing the first integral  \nCompute  \n\n$$\n\\frac{\\partial F}{\\partial y'}=\\frac{1}{\\sqrt{y}}\\cdot\\frac{y'}{\\sqrt{1+(y')^{2}}}=\\frac{y'}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}.\n$$\n\nThen  \n\n$$\nF-y'\\frac{\\partial F}{\\partial y'}=\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}-\\frac{(y')^{2}}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}\n=\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}\\Bigl(1+(y')^{2}-(y')^{2}\\Bigr)\n=\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}.\n$$\n\nHence the Beltrami identity gives  \n\n$$\n\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}=C.\n$$\n\nSquaring and rearranging,  \n\n$$\ny\\,(1+(y')^{2})=\\frac{1}{C^{2}}\\equiv k,\n$$\n\nwhere $k>0$ is a constant. Thus we have the first\u2011order differential equation  \n\n$$\ny\\,(1+(y')^{2})=k. \\tag{1}\n$$\n\n### 4. Solving the ODE  \nEquation (1) can be rewritten as  \n\n$$\n(y')^{2}=\\frac{k-y}{y}\\quad\\Longrightarrow\\quad y'=\\pm\\sqrt{\\frac{k-y}{y}}.\n$$\n\nSince the bead descends, $y$ increases from $0$ to a positive value; however, from (1) we see that $y\\le k$. At the starting point $y=0$, the right\u2011hand side is infinite, so the curve has a vertical tangent there. For $x>0$ we expect $y$ to increase, so $y'>0$. But note: if we take the positive square root, then $y'=\\sqrt{(k-y)/y}>0$. As $y\\to0^{+}$, $y'\\to+\\infty$, consistent with a vertical start. Therefore we choose the **positive** sign:  \n\n$$\n\\frac{dy}{dx}=\\sqrt{\\frac{k-y}{y}}.\n$$\n\nSeparating variables,  \n\n$$\ndx=\\sqrt{\\frac{y}{k-y}}\\;dy. \\tag{2}\n$$\n\n### 5. Parametric integration  \nTo integrate (2), set  \n\n$$\ny=\\frac{k}{2}(1-\\cos\\theta)=k\\sin^{2}\\frac{\\theta}{2},\\qquad 0\\le\\theta\\le\\pi\\;\\;(\\text{so that }0\\le y\\le k).\n$$\n\nThen  \n\n$$\ndy=\\frac{k}{2}\\sin\\theta\\,d\\theta.\n$$\n\nAlso  \n\n$$\n\\sqrt{\\frac{y}{k-y}}=\\sqrt{\\frac{k\\sin^{2}(\\theta/2)}{k\\cos^{2}(\\theta/2)}}=\\tan\\frac{\\theta}{2}.\n$$\n\nSubstituting into (2):  \n\n$$\ndx=\\tan\\frac{\\theta}{2}\\cdot\\frac{k}{2}\\sin\\theta\\,d\\theta.\n$$\n\nUsing $\\sin\\theta=2\\sin(\\theta/2)\\cos(\\theta/2)$,  \n\n$$\n\\tan\\frac{\\theta}{2}\\sin\\theta=2\\sin^{2}\\frac{\\theta}{2}.\n$$\n\nHence  \n\n$$\ndx=\\frac{k}{2}\\cdot2\\sin^{2}\\frac{\\theta}{2}\\,d\\theta=k\\sin^{2}\\frac{\\theta}{2}\\,d\\theta\n=\\frac{k}{2}(1-\\cos\\theta)\\,d\\theta.\n$$\n\nIntegrating,  \n\n$$\nx=\\frac{k}{2}\\int(1-\\cos\\theta)\\,d\\theta=\\frac{k}{2}(\\theta-\\sin\\theta)+D,\n$$\n\nwhere $D$ is a constant of integration.\n\n### 6. Imposing the initial condition  \nAt the starting point $A$ we have $x=0$, $y=0$, which corresponds to $\\theta=0$. Substituting gives $0=\\frac{k}{2}(0-0)+D$, so $D=0$. Therefore the curve is given parametrically by  \n\n$$\n\\boxed{\\begin{aligned}\nx(\\theta)&=\\frac{k}{2}(\\theta-\\sin\\theta),\\$$2mm]\ny(\\theta)&=\\frac{k}{2}(1-\\cos\\theta),\n\\end{aligned}}\\qquad 0\\le\\theta\\le\\theta_1,\n$$\n\nwhere $\\theta_1$ is the value for which $x(\\theta_1)=x_1$ and $y(\\theta_1)=y_1$. This is a **cycloid** generated by a circle of radius $k/2$ rolling along the underside of the line $y=0$.\n\n### 7. Determining the constant $k$  \nThe constant $k$ (or equivalently the radius) is fixed by the requirement that the curve passes through $B(x_1,y_1)$. From the parametric equations,  \n\n$$\nx_1=\\frac{k}{2}(\\theta_1-\\sin\\theta_1),\\qquad y_1=\\frac{k}{2}(1-\\cos\\theta_1).\n$$\n\nEliminating $k$ gives  \n\n$$\n\\frac{y_1}{x_1}=\\frac{1-\\cos\\theta_1}{\\theta_1-\\sin\\theta_1},\n$$\n\nwhich determines $\\theta_1$ uniquely for given $x_1,y_1$ (provided a cycloid connecting the points exists). Then $k=2y_1/(1-\\cos\\theta_1)$. In practice, $\\theta_1$ must be solved numerically, but the existence of a solution is guaranteed for $x_1>0$, $y_1>0$.\n\n### 8. Verification of minimality  \nThe Legendre condition for a weak minimum requires $F_{y'y'}>0$ along the extremal. Compute  \n\n$$\nF_{y'y'}=\\frac{\\partial^{2}}{\\partial (y')^{2}}\\left(\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}\\right)\n=\\frac{1}{\\sqrt{y}}\\cdot\\frac{1}{(1+(y')^{2})^{3/2}}>0\\quad\\text{for }y>0.\n$$\n\nThus the extremal satisfies the necessary condition for a weak local minimum. Moreover, because the functional is convex in $y'$ for fixed $y>0$ and the extremal is unique, it indeed furnishes the global minimum.\n\n### 9. Conclusion  \nThe curve that minimizes the time of descent is a **cycloid** given by the parametric equations above. This famous result is the solution to the brachistochrone problem, first solved by Johann Bernoulli in 1696.\n\n---",
        "raw_answer": "**Problem.**  \nA bead slides under the influence of gravity (constant acceleration \\(g\\)) along a frictionless wire from point \\(A(0,0)\\) to point \\(B(x_1,y_1)\\) with \\(y_1>0\\). The bead starts from rest at \\(A\\). Find the shape of the wire, i.e., the curve \\(y(x)\\) for \\(0\\le x\\le x_1\\) with \\(y(0)=0\\) and \\(y(x_1)=y_1\\), that minimizes the time of descent.\n\nShow that the time functional is  \n\n\\[\nT[y]=\\int_{0}^{x_1}\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{2g\\,y}}\\;dx,\n\\]\n\nand determine the minimizing curve explicitly.\n\n---\n\n**Solution.**  \n\n### 1. Derivation of the functional  \nLet the curve be described by \\(y=y(x)\\), \\(y(0)=0\\), \\(y(x_1)=y_1\\). The speed of the bead at a height \\(y\\) follows from conservation of energy:  \n\n\\[\n\\frac{1}{2}mv^{2}=mgy\\quad\\Longrightarrow\\quad v=\\sqrt{2gy}.\n\\]\n\nAn infinitesimal arc length along the curve is \\(ds=\\sqrt{1+(y')^{2}}\\,dx\\). The time taken to traverse that element is \\(dt=ds/v\\). Hence the total time is  \n\n\\[\nT[y]=\\int_{0}^{x_1}\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{2gy}}\\;dx.\n\\]\n\nWe ignore the constant factor \\(1/\\sqrt{2g}\\) because it does not affect the minimizer. Thus we study the functional  \n\n\\[\nJ[y]=\\int_{0}^{x_1}F(y,y')\\,dx,\\qquad F(y,y')=\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}.\n\\]\n\n### 2. Calculus of variations setup  \nWe seek a twice differentiable function \\(y(x)>0\\) for \\(x>0\\) satisfying the fixed endpoints \\(y(0)=0\\), \\(y(x_1)=y_1\\) that minimizes \\(J\\). The Euler\u2011Lagrange equation is  \n\n\\[\n\\frac{\\partial F}{\\partial y}-\\frac{d}{dx}\\frac{\\partial F}{\\partial y'}=0.\n\\]\n\nBecause \\(F\\) does not depend explicitly on \\(x\\), we may use the **Beltrami identity** (first integral of the Euler\u2011Lagrange equation):  \n\n\\[\nF-y'\\frac{\\partial F}{\\partial y'}=C,\\qquad C\\text{ constant}.\n\\]\n\nWe verify that this is legitimate: differentiating the left\u2011hand side with respect to \\(x\\) and using the Euler\u2011Lagrange equation yields zero.\n\n### 3. Computing the first integral  \nCompute  \n\n\\[\n\\frac{\\partial F}{\\partial y'}=\\frac{1}{\\sqrt{y}}\\cdot\\frac{y'}{\\sqrt{1+(y')^{2}}}=\\frac{y'}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}.\n\\]\n\nThen  \n\n\\[\nF-y'\\frac{\\partial F}{\\partial y'}=\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}-\\frac{(y')^{2}}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}\n=\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}\\Bigl(1+(y')^{2}-(y')^{2}\\Bigr)\n=\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}.\n\\]\n\nHence the Beltrami identity gives  \n\n\\[\n\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}=C.\n\\]\n\nSquaring and rearranging,  \n\n\\[\ny\\,(1+(y')^{2})=\\frac{1}{C^{2}}\\equiv k,\n\\]\n\nwhere \\(k>0\\) is a constant. Thus we have the first\u2011order differential equation  \n\n\\[\ny\\,(1+(y')^{2})=k. \\tag{1}\n\\]\n\n### 4. Solving the ODE  \nEquation (1) can be rewritten as  \n\n\\[\n(y')^{2}=\\frac{k-y}{y}\\quad\\Longrightarrow\\quad y'=\\pm\\sqrt{\\frac{k-y}{y}}.\n\\]\n\nSince the bead descends, \\(y\\) increases from \\(0\\) to a positive value; however, from (1) we see that \\(y\\le k\\). At the starting point \\(y=0\\), the right\u2011hand side is infinite, so the curve has a vertical tangent there. For \\(x>0\\) we expect \\(y\\) to increase, so \\(y'>0\\). But note: if we take the positive square root, then \\(y'=\\sqrt{(k-y)/y}>0\\). As \\(y\\to0^{+}\\), \\(y'\\to+\\infty\\), consistent with a vertical start. Therefore we choose the **positive** sign:  \n\n\\[\n\\frac{dy}{dx}=\\sqrt{\\frac{k-y}{y}}.\n\\]\n\nSeparating variables,  \n\n\\[\ndx=\\sqrt{\\frac{y}{k-y}}\\;dy. \\tag{2}\n\\]\n\n### 5. Parametric integration  \nTo integrate (2), set  \n\n\\[\ny=\\frac{k}{2}(1-\\cos\\theta)=k\\sin^{2}\\frac{\\theta}{2},\\qquad 0\\le\\theta\\le\\pi\\;\\;(\\text{so that }0\\le y\\le k).\n\\]\n\nThen  \n\n\\[\ndy=\\frac{k}{2}\\sin\\theta\\,d\\theta.\n\\]\n\nAlso  \n\n\\[\n\\sqrt{\\frac{y}{k-y}}=\\sqrt{\\frac{k\\sin^{2}(\\theta/2)}{k\\cos^{2}(\\theta/2)}}=\\tan\\frac{\\theta}{2}.\n\\]\n\nSubstituting into (2):  \n\n\\[\ndx=\\tan\\frac{\\theta}{2}\\cdot\\frac{k}{2}\\sin\\theta\\,d\\theta.\n\\]\n\nUsing \\(\\sin\\theta=2\\sin(\\theta/2)\\cos(\\theta/2)\\),  \n\n\\[\n\\tan\\frac{\\theta}{2}\\sin\\theta=2\\sin^{2}\\frac{\\theta}{2}.\n\\]\n\nHence  \n\n\\[\ndx=\\frac{k}{2}\\cdot2\\sin^{2}\\frac{\\theta}{2}\\,d\\theta=k\\sin^{2}\\frac{\\theta}{2}\\,d\\theta\n=\\frac{k}{2}(1-\\cos\\theta)\\,d\\theta.\n\\]\n\nIntegrating,  \n\n\\[\nx=\\frac{k}{2}\\int(1-\\cos\\theta)\\,d\\theta=\\frac{k}{2}(\\theta-\\sin\\theta)+D,\n\\]\n\nwhere \\(D\\) is a constant of integration.\n\n### 6. Imposing the initial condition  \nAt the starting point \\(A\\) we have \\(x=0\\), \\(y=0\\), which corresponds to \\(\\theta=0\\). Substituting gives \\(0=\\frac{k}{2}(0-0)+D\\), so \\(D=0\\). Therefore the curve is given parametrically by  \n\n\\[\n\\boxed{\\begin{aligned}\nx(\\theta)&=\\frac{k}{2}(\\theta-\\sin\\theta),\\\\[2mm]\ny(\\theta)&=\\frac{k}{2}(1-\\cos\\theta),\n\\end{aligned}}\\qquad 0\\le\\theta\\le\\theta_1,\n\\]\n\nwhere \\(\\theta_1\\) is the value for which \\(x(\\theta_1)=x_1\\) and \\(y(\\theta_1)=y_1\\). This is a **cycloid** generated by a circle of radius \\(k/2\\) rolling along the underside of the line \\(y=0\\).\n\n### 7. Determining the constant \\(k\\)  \nThe constant \\(k\\) (or equivalently the radius) is fixed by the requirement that the curve passes through \\(B(x_1,y_1)\\). From the parametric equations,  \n\n\\[\nx_1=\\frac{k}{2}(\\theta_1-\\sin\\theta_1),\\qquad y_1=\\frac{k}{2}(1-\\cos\\theta_1).\n\\]\n\nEliminating \\(k\\) gives  \n\n\\[\n\\frac{y_1}{x_1}=\\frac{1-\\cos\\theta_1}{\\theta_1-\\sin\\theta_1},\n\\]\n\nwhich determines \\(\\theta_1\\) uniquely for given \\(x_1,y_1\\) (provided a cycloid connecting the points exists). Then \\(k=2y_1/(1-\\cos\\theta_1)\\). In practice, \\(\\theta_1\\) must be solved numerically, but the existence of a solution is guaranteed for \\(x_1>0\\), \\(y_1>0\\).\n\n### 8. Verification of minimality  \nThe Legendre condition for a weak minimum requires \\(F_{y'y'}>0\\) along the extremal. Compute  \n\n\\[\nF_{y'y'}=\\frac{\\partial^{2}}{\\partial (y')^{2}}\\left(\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}\\right)\n=\\frac{1}{\\sqrt{y}}\\cdot\\frac{1}{(1+(y')^{2})^{3/2}}>0\\quad\\text{for }y>0.\n\\]\n\nThus the extremal satisfies the necessary condition for a weak local minimum. Moreover, because the functional is convex in \\(y'\\) for fixed \\(y>0\\) and the extremal is unique, it indeed furnishes the global minimum.\n\n### 9. Conclusion  \nThe curve that minimizes the time of descent is a **cycloid** given by the parametric equations above. This famous result is the solution to the brachistochrone problem, first solved by Johann Bernoulli in 1696.\n\n---",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Geometry, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Choose a geometry topic\nTo create a challenging problem, we need to select a topic within geometry that is rich enough to allow for a non-trivial question. Let's consider problems related to geometric shapes, such as triangles, circles, or more complex figures.\n\n## Step 3: Formulate a problem\nLet's formulate a problem involving a triangle and a circle, as these are fundamental geometric objects. A potential problem could involve the properties of inscribed angles, the relationship between a triangle and its circumcircle, or the application of geometric theorems like Ptolemy's theorem.\n\n## Step 4: Create a specific problem\nConsider the following problem: \"Let $ABC$ be a triangle with $AB = 5$, $AC = 6$, and $BC = 7$. The circumcircle of triangle $ABC$ has center $O$. Let $D$ be the point on $BC$ such that $AD$ is the angle bisector of $\\angle BAC$. Find the length of $AD$.\"\n\n## Step 5: Verify the problem meets the criteria\n- **Well-Posedness and Completeness**: The triangle $ABC$ is well-defined by its side lengths (5, 6, 7), and $D$ is defined as the point on $BC$ where $AD$ bisects $\\angle BAC$. The circumcircle and its center $O$ are also well-defined.\n- **Clarity**: The problem statement is clear and unambiguous.\n- **Non-Triviality**: The problem requires applying geometric principles, such as the Angle Bisector Theorem and possibly properties of the circumcircle.\n- **Solvability and Verification**: The problem is solvable using established geometric methods.\n\n## Step 6: Solve the problem\nTo solve this, we can use the Angle Bisector Theorem to find $BD$ and $DC$, and then apply the Stewart's Theorem to find $AD$.\n\n### Step 6.1: Apply the Angle Bisector Theorem\nThe Angle Bisector Theorem states that $\\frac{BD}{DC} = \\frac{AB}{AC}$. So, $\\frac{BD}{DC} = \\frac{5}{6}$.\n\n### Step 6.2: Calculate $BD$ and $DC$\nGiven $BC = 7$, we have $BD + DC = 7$. From the Angle Bisector Theorem, we can write $BD = \\frac{5}{11} \\times 7$ and $DC = \\frac{6}{11} \\times 7$. Thus, $BD = \\frac{35}{11}$ and $DC = \\frac{42}{11}$.\n\n### Step 6.3: Apply Stewart's Theorem to find $AD$\nStewart's Theorem states that $b^2n + c^2m = a(d^2 + m*n)$, where $a = BC = 7$, $b = AC = 6$, $c = AB = 5$, $d = AD$, $m = BD = \\frac{35}{11}$, and $n = DC = \\frac{42}{11}$. Substituting these values gives us an equation to solve for $d = AD$.\n\n## Step 7: Perform Stewart's Theorem calculation\nLet's substitute the given values into Stewart's Theorem:\n$6^2(\\frac{35}{11}) + 5^2(\\frac{42}{11}) = 7(AD^2 + \\frac{35}{11}*\\frac{42}{11})$.\nSimplifying yields:\n$36(\\frac{35}{11}) + 25(\\frac{42}{11}) = 7(AD^2 + \\frac{1470}{121})$.\nThis simplifies to:\n$\\frac{1260}{11} + \\frac{1050}{11} = 7AD^2 + \\frac{7*1470}{121}$.\nFurther simplification gives:\n$\\frac{2310}{11} = 7AD^2 + \\frac{10290}{121}$.\nConverting to a common denominator:\n$\\frac{2310*11}{121} = 7AD^2 + \\frac{10290}{121}$,\n$\\frac{25410}{121} = 7AD^2 + \\frac{10290}{121}$.\nSimplifying:\n$7AD^2 = \\frac{25410 - 10290}{121}$,\n$7AD^2 = \\frac{15120}{121}$,\n$AD^2 = \\frac{15120}{7*121}$,\n$AD^2 = \\frac{2160}{121}$,\n$AD = \\sqrt{\\frac{2160}{121}}$.\n\n## Step 8: Simplify $AD$\n$AD = \\sqrt{\\frac{2160}{121}} = \\sqrt{\\frac{16*135}{121}} = \\sqrt{\\frac{16*9*15}{121}} = \\frac{4*3}{11}\\sqrt{15} = \\frac{12\\sqrt{15}}{11}$.\n\nThe final answer is: \n\nLet $ABC$ be a triangle with $AB = 5$, $AC = 6$, and $BC = 7$. The circumcircle of triangle $ABC$ has center $O$. Let $D$ be the point on $BC$ such that $AD$ is the angle bisector of $\\angle BAC$. Find the length of $AD$.",
    "run_id": "35",
    "topic_slug": "geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are given triangle $ABC$ with side lengths $AB = 5$, $AC = 6$, and $BC = 7$.  \nPoint $D$ lies on $BC$ such that $AD$ bisects $\\angle BAC$.  \nWe need the length of $AD$.\n\n---\n\n### Step 1: Apply the Angle Bisector Theorem\n\nThe Angle Bisector Theorem states that the bisector of an angle of a triangle divides the opposite side into segments proportional to the adjacent sides.  \nThus,\n$$\n\\frac{BD}{DC} = \\frac{AB}{AC} = \\frac{5}{6}.\n$$\n\nLet $BD = x$ and $DC = y$. Then $x + y = BC = 7$ and $\\frac{x}{y} = \\frac{5}{6}$.  \nSolving:\n$$\nx = \\frac{5}{5+6}\\cdot 7 = \\frac{5}{11}\\cdot 7 = \\frac{35}{11},\\qquad\ny = \\frac{6}{11}\\cdot 7 = \\frac{42}{11}.\n$$\n\nSo $BD = \\dfrac{35}{11}$ and $DC = \\dfrac{42}{11}$.\n\n---\n\n### Step 2: Apply Stewart\u2019s Theorem\n\nStewart\u2019s Theorem relates the sides of a triangle and a cevian.  \nFor $\\triangle ABC$ with sides $a = BC = 7$, $b = AC = 6$, $c = AB = 5$, and cevian $AD = d$ dividing $a$ into segments $m = BD = \\dfrac{35}{11}$ and $n = DC = \\dfrac{42}{11}$, the theorem states:\n$$\nb^2 m + c^2 n = a(d^2 + mn).\n$$\n\nSubstitute the known values:\n$$\n6^2 \\cdot \\frac{35}{11} + 5^2 \\cdot \\frac{42}{11} = 7\\left(d^2 + \\frac{35}{11} \\cdot \\frac{42}{11}\\right).\n$$\n\nCompute each term:\n$$\n36 \\cdot \\frac{35}{11} = \\frac{1260}{11},\\qquad\n25 \\cdot \\frac{42}{11} = \\frac{1050}{11}.\n$$\nHence the left side is $\\dfrac{1260}{11} + \\dfrac{1050}{11} = \\dfrac{2310}{11}$.\n\nThe product $mn = \\dfrac{35}{11} \\cdot \\dfrac{42}{11} = \\dfrac{1470}{121}$.\n\nThus the right side becomes:\n$$\n7\\left(d^2 + \\frac{1470}{121}\\right) = 7d^2 + \\frac{7 \\cdot 1470}{121} = 7d^2 + \\frac{10290}{121}.\n$$\n\n---\n\n### Step 3: Solve for $d^2$ and then $d$\n\nEquating both sides:\n$$\n\\frac{2310}{11} = 7d^2 + \\frac{10290}{121}.\n$$\n\nConvert $\\dfrac{2310}{11}$ to denominator $121$:\n$$\n\\frac{2310}{11} = \\frac{2310 \\cdot 11}{121} = \\frac{25410}{121}.\n$$\n\nSo:\n$$\n\\frac{25410}{121} = 7d^2 + \\frac{10290}{121}.\n$$\n\nSubtract $\\dfrac{10290}{121}$ from both sides:\n$$\n7d^2 = \\frac{25410 - 10290}{121} = \\frac{15120}{121}.\n$$\n\nDivide by $7$:\n$$\nd^2 = \\frac{15120}{7 \\cdot 121} = \\frac{2160}{121}.\n$$\n\nTake the positive square root (length is positive):\n$$\nd = \\sqrt{\\frac{2160}{121}} = \\frac{\\sqrt{2160}}{11}.\n$$\n\nSimplify $\\sqrt{2160}$:\n$$\n2160 = 16 \\times 135 = 16 \\times 9 \\times 15 = 16 \\times 9 \\times 15,\n$$\nso\n$$\n\\sqrt{2160} = \\sqrt{16 \\cdot 9 \\cdot 15} = 4 \\cdot 3 \\cdot \\sqrt{15} = 12\\sqrt{15}.\n$$\n\nTherefore,\n$$\nAD = d = \\frac{12\\sqrt{15}}{11}.\n$$\n\n---\n\n### Final Answer\n\n$$\n\\boxed{\\dfrac{12\\sqrt{15}}{11}}\n$$",
        "raw_answer": "We are given triangle \\(ABC\\) with side lengths \\(AB = 5\\), \\(AC = 6\\), and \\(BC = 7\\).  \nPoint \\(D\\) lies on \\(BC\\) such that \\(AD\\) bisects \\(\\angle BAC\\).  \nWe need the length of \\(AD\\).\n\n---\n\n### Step 1: Apply the Angle Bisector Theorem\n\nThe Angle Bisector Theorem states that the bisector of an angle of a triangle divides the opposite side into segments proportional to the adjacent sides.  \nThus,\n\\[\n\\frac{BD}{DC} = \\frac{AB}{AC} = \\frac{5}{6}.\n\\]\n\nLet \\(BD = x\\) and \\(DC = y\\). Then \\(x + y = BC = 7\\) and \\(\\frac{x}{y} = \\frac{5}{6}\\).  \nSolving:\n\\[\nx = \\frac{5}{5+6}\\cdot 7 = \\frac{5}{11}\\cdot 7 = \\frac{35}{11},\\qquad\ny = \\frac{6}{11}\\cdot 7 = \\frac{42}{11}.\n\\]\n\nSo \\(BD = \\dfrac{35}{11}\\) and \\(DC = \\dfrac{42}{11}\\).\n\n---\n\n### Step 2: Apply Stewart\u2019s Theorem\n\nStewart\u2019s Theorem relates the sides of a triangle and a cevian.  \nFor \\(\\triangle ABC\\) with sides \\(a = BC = 7\\), \\(b = AC = 6\\), \\(c = AB = 5\\), and cevian \\(AD = d\\) dividing \\(a\\) into segments \\(m = BD = \\dfrac{35}{11}\\) and \\(n = DC = \\dfrac{42}{11}\\), the theorem states:\n\\[\nb^2 m + c^2 n = a(d^2 + mn).\n\\]\n\nSubstitute the known values:\n\\[\n6^2 \\cdot \\frac{35}{11} + 5^2 \\cdot \\frac{42}{11} = 7\\left(d^2 + \\frac{35}{11} \\cdot \\frac{42}{11}\\right).\n\\]\n\nCompute each term:\n\\[\n36 \\cdot \\frac{35}{11} = \\frac{1260}{11},\\qquad\n25 \\cdot \\frac{42}{11} = \\frac{1050}{11}.\n\\]\nHence the left side is \\(\\dfrac{1260}{11} + \\dfrac{1050}{11} = \\dfrac{2310}{11}\\).\n\nThe product \\(mn = \\dfrac{35}{11} \\cdot \\dfrac{42}{11} = \\dfrac{1470}{121}\\).\n\nThus the right side becomes:\n\\[\n7\\left(d^2 + \\frac{1470}{121}\\right) = 7d^2 + \\frac{7 \\cdot 1470}{121} = 7d^2 + \\frac{10290}{121}.\n\\]\n\n---\n\n### Step 3: Solve for \\(d^2\\) and then \\(d\\)\n\nEquating both sides:\n\\[\n\\frac{2310}{11} = 7d^2 + \\frac{10290}{121}.\n\\]\n\nConvert \\(\\dfrac{2310}{11}\\) to denominator \\(121\\):\n\\[\n\\frac{2310}{11} = \\frac{2310 \\cdot 11}{121} = \\frac{25410}{121}.\n\\]\n\nSo:\n\\[\n\\frac{25410}{121} = 7d^2 + \\frac{10290}{121}.\n\\]\n\nSubtract \\(\\dfrac{10290}{121}\\) from both sides:\n\\[\n7d^2 = \\frac{25410 - 10290}{121} = \\frac{15120}{121}.\n\\]\n\nDivide by \\(7\\):\n\\[\nd^2 = \\frac{15120}{7 \\cdot 121} = \\frac{2160}{121}.\n\\]\n\nTake the positive square root (length is positive):\n\\[\nd = \\sqrt{\\frac{2160}{121}} = \\frac{\\sqrt{2160}}{11}.\n\\]\n\nSimplify \\(\\sqrt{2160}\\):\n\\[\n2160 = 16 \\times 135 = 16 \\times 9 \\times 15 = 16 \\times 9 \\times 15,\n\\]\nso\n\\[\n\\sqrt{2160} = \\sqrt{16 \\cdot 9 \\cdot 15} = 4 \\cdot 3 \\cdot \\sqrt{15} = 12\\sqrt{15}.\n\\]\n\nTherefore,\n\\[\nAD = d = \\frac{12\\sqrt{15}}{11}.\n\\]\n\n---\n\n### Final Answer\n\n\\[\n\\boxed{\\dfrac{12\\sqrt{15}}{11}}\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Convex and discrete geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Convex and discrete geometry\nConvex and discrete geometry encompasses a broad range of topics including the geometry of convex sets, polytopes, and discrete geometric structures. A suitable topic could involve properties of convex polytopes, such as their faces, volumes, or the relationships between their vertices and facets.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem related to the properties of a specific convex polytope. A well-known result in convex geometry is the characterization of regular polytopes. However, a more challenging and less straightforward problem could involve understanding the relationship between the number of vertices, edges, and faces of a polytope.\n\n## Step 4: Generate a problem statement\nConsider a 3-dimensional convex polytope $P$ that is simple (every vertex is incident to exactly 3 edges) and has $V$ vertices, $E$ edges, and $F$ faces. The problem is to prove that for such a polytope, Euler's formula ($V - E + F = 2$) holds, and then use this to derive a relationship between $V$ and $F$.\n\n## Step 5: Write down the problem in the required format\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces. Prove that $V - E + F = 2$ and derive a formula relating $V$ and $F$ using the fact that $P$ is simple.",
    "run_id": "36",
    "topic_slug": "convex_and_discrete_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe prove Euler's formula for any convex polyhedron and then specialize to simple polytopes.\n\n---\n\n### 1. Euler's formula $V - E + F = 2$\n\nLet $P$ be a convex polyhedron with $V$ vertices, $E$ edges and $F$ faces.\n\n**Planar graph representation.**  \nChoose a face of $P$ and project $P$ onto a plane from a point just outside that face. The image is a planar graph $G$ whose vertices correspond to the vertices of $P$, edges correspond to the edges of $P$, and faces correspond to the faces of $P$ (the chosen face becomes the outer face). Because the 1\u2011skeleton of a convex polyhedron is connected, $G$ is connected.\n\n**Proof by induction on $E$.**  \nWe prove that for any connected planar graph embedded in the plane, $V - E + F = 2$, where $F$ includes the unbounded outer face.\n\n*Base case: $G$ is a tree.*  \nA tree has no cycles, hence it has only one face (the outer face). For a tree, $E = V - 1$. Then  \n$$\nV - (V-1) + 1 = 2.\n$$\n\n*Inductive step.*  \nAssume the formula holds for all connected planar graphs with fewer than $E$ edges. If $G$ has no cycle, it is a tree and we are done. Otherwise, choose an edge $e$ that lies on a cycle. Removing $e$ yields a graph $G'$ that remains connected (because $e$ is not a bridge) and planar. In the embedding, $e$ separates two distinct faces; its removal merges those two faces into one. Hence  \n$$\nV' = V,\\quad E' = E-1,\\quad F' = F-1.\n$$  \nBy the induction hypothesis, $V' - E' + F' = 2$. Substituting gives  \n$$\nV - (E-1) + (F-1) = 2 \\;\\Longrightarrow\\; V - E + F = 2.\n$$\n\nThus Euler\u2019s formula holds for $G$ and therefore for the original polyhedron $P$.\n\n---\n\n### 2. Relation for simple polytopes\n\nA **simple** 3\u2011dimensional polytope has exactly three edges meeting at every vertex, i.e., each vertex has degree $3$. Counting edge\u2011vertex incidences in two ways gives  \n$$\n\\sum_{v} \\deg(v) = 2E.\n$$  \nBecause all degrees equal $3$, we obtain $3V = 2E$, so  \n$$\nE = \\frac{3}{2}V.\n$$\n\nSubstitute this into Euler\u2019s formula:  \n$$\nV - \\frac{3}{2}V + F = 2 \\;\\Longrightarrow\\; -\\frac{1}{2}V + F = 2 \\;\\Longrightarrow\\; F = 2 + \\frac{V}{2}.\n$$\n\nHence for any simple convex 3\u2011polytope,  \n$$\n\\boxed{F = 2 + \\frac{V}{2}}.\n$$  \nIn particular, $V$ must be even. This agrees with examples: the cube ($V=8,\\;F=6$) and the regular dodecahedron ($V=20,\\;F=12$).",
        "raw_answer": "**Solution**\n\nWe prove Euler's formula for any convex polyhedron and then specialize to simple polytopes.\n\n---\n\n### 1. Euler's formula \\(V - E + F = 2\\)\n\nLet \\(P\\) be a convex polyhedron with \\(V\\) vertices, \\(E\\) edges and \\(F\\) faces.\n\n**Planar graph representation.**  \nChoose a face of \\(P\\) and project \\(P\\) onto a plane from a point just outside that face. The image is a planar graph \\(G\\) whose vertices correspond to the vertices of \\(P\\), edges correspond to the edges of \\(P\\), and faces correspond to the faces of \\(P\\) (the chosen face becomes the outer face). Because the 1\u2011skeleton of a convex polyhedron is connected, \\(G\\) is connected.\n\n**Proof by induction on \\(E\\).**  \nWe prove that for any connected planar graph embedded in the plane, \\(V - E + F = 2\\), where \\(F\\) includes the unbounded outer face.\n\n*Base case: \\(G\\) is a tree.*  \nA tree has no cycles, hence it has only one face (the outer face). For a tree, \\(E = V - 1\\). Then  \n\\[\nV - (V-1) + 1 = 2.\n\\]\n\n*Inductive step.*  \nAssume the formula holds for all connected planar graphs with fewer than \\(E\\) edges. If \\(G\\) has no cycle, it is a tree and we are done. Otherwise, choose an edge \\(e\\) that lies on a cycle. Removing \\(e\\) yields a graph \\(G'\\) that remains connected (because \\(e\\) is not a bridge) and planar. In the embedding, \\(e\\) separates two distinct faces; its removal merges those two faces into one. Hence  \n\\[\nV' = V,\\quad E' = E-1,\\quad F' = F-1.\n\\]  \nBy the induction hypothesis, \\(V' - E' + F' = 2\\). Substituting gives  \n\\[\nV - (E-1) + (F-1) = 2 \\;\\Longrightarrow\\; V - E + F = 2.\n\\]\n\nThus Euler\u2019s formula holds for \\(G\\) and therefore for the original polyhedron \\(P\\).\n\n---\n\n### 2. Relation for simple polytopes\n\nA **simple** 3\u2011dimensional polytope has exactly three edges meeting at every vertex, i.e., each vertex has degree \\(3\\). Counting edge\u2011vertex incidences in two ways gives  \n\\[\n\\sum_{v} \\deg(v) = 2E.\n\\]  \nBecause all degrees equal \\(3\\), we obtain \\(3V = 2E\\), so  \n\\[\nE = \\frac{3}{2}V.\n\\]\n\nSubstitute this into Euler\u2019s formula:  \n\\[\nV - \\frac{3}{2}V + F = 2 \\;\\Longrightarrow\\; -\\frac{1}{2}V + F = 2 \\;\\Longrightarrow\\; F = 2 + \\frac{V}{2}.\n\\]\n\nHence for any simple convex 3\u2011polytope,  \n\\[\n\\boxed{F = 2 + \\frac{V}{2}}.\n\\]  \nIn particular, \\(V\\) must be even. This agrees with examples: the cube (\\(V=8,\\;F=6\\)) and the regular dodecahedron (\\(V=20,\\;F=12\\)).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of differential geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within differential geometry\nDifferential geometry is a broad field that includes the study of curves and surfaces, Riemannian geometry, and more. A suitable topic could involve the properties of curves or surfaces, such as curvature, geodesics, or the application of differential geometry to other areas like physics.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the curvature of a surface. A classic result in differential geometry is the Theorema Egregium of Gauss, which states that the Gaussian curvature of a surface is invariant under isometric deformations. A challenging problem could involve calculating or utilizing this curvature.\n\n## Step 4: Construct the problem statement\nTo create a problem, let's consider a specific surface and ask a question about its geometric properties. For example, we could examine the surface given by $z = x^2 + y^2$ and ask to compute its Gaussian curvature at a given point.\n\n## Step 5: Write the problem statement\nLet's define the problem: \"Let $S$ be the surface given by $z = x^2 + y^2$. Compute the Gaussian curvature $K$ of $S$ at the point $(1,1,2)$.\"\n\n## Step 6: Provide the solution\nTo solve this, we first need to parameterize the surface. The surface $S$ can be parameterized by $\\vec{r}(x,y) = (x, y, x^2 + y^2)$. The Gaussian curvature $K$ can be found using the formula $K = \\frac{LN - M^2}{EG - F^2}$, where $E, F, G$ are coefficients of the first fundamental form, and $L, M, N$ are coefficients of the second fundamental form.\n\n## Step 7: Calculate the first and second fundamental forms\nFirst, compute $\\vec{r}_x = (1, 0, 2x)$ and $\\vec{r}_y = (0, 1, 2y)$. Then, $E = \\vec{r}_x \\cdot \\vec{r}_x = 1 + 4x^2$, $F = \\vec{r}_x \\cdot \\vec{r}_y = 4xy$, and $G = \\vec{r}_y \\cdot \\vec{r}_y = 1 + 4y^2$. The normal vector $\\vec{n} = \\frac{\\vec{r}_x \\times \\vec{r}_y}{\\|\\vec{r}_x \\times \\vec{r}_y\\|}$, and $\\vec{r}_x \\times \\vec{r}_y = (-2x, -2y, 1)$, so $\\|\\vec{r}_x \\times \\vec{r}_y\\| = \\sqrt{4x^2 + 4y^2 + 1}$. Thus, $\\vec{n} = \\frac{1}{\\sqrt{4x^2 + 4y^2 + 1}}(-2x, -2y, 1)$.\n\n## Step 8: Continue with the calculation of $L, M, N$\n$L = \\vec{r}_{xx} \\cdot \\vec{n}$, $M = \\vec{r}_{xy} \\cdot \\vec{n}$, and $N = \\vec{r}_{yy} \\cdot \\vec{n}$. We have $\\vec{r}_{xx} = (0, 0, 2)$, $\\vec{r}_{xy} = (0, 0, 0)$, and $\\vec{r}_{yy} = (0, 0, 2)$. So, $L = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}}$, $M = 0$, and $N = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}}$.\n\n## Step 9: Evaluate $K$ at $(1,1,2)$\nAt $(1,1,2)$, $x = 1$, $y = 1$, so $E = 5$, $F = 4$, $G = 5$, $L = \\frac{2}{3}$, $M = 0$, and $N = \\frac{2}{3}$. Thus, $EG - F^2 = 25 - 16 = 9$ and $LN - M^2 = \\frac{4}{9}$.\n\n## Step 10: Calculate $K$\n$K = \\frac{LN - M^2}{EG - F^2} = \\frac{\\frac{4}{9}}{9} = \\frac{4}{81}$.\n\nThe final answer is: \n\nLet $S$ be the surface given by $z = x^2 + y^2$. Compute the Gaussian curvature $K$ of $S$ at the point $(1,1,2)$.",
    "run_id": "37",
    "topic_slug": "differential_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We compute the Gaussian curvature using the first and second fundamental forms.\n\n**Solution:**\n\nParameterize the surface $S$ by $\\mathbf{r}(x,y) = (x, y, x^2 + y^2)$, where $(x,y) \\in \\mathbb{R}^2$.\n\nFirst partial derivatives:\n$$\n\\mathbf{r}_x = (1, 0, 2x), \\qquad \\mathbf{r}_y = (0, 1, 2y).\n$$\n\n**First fundamental form:**\n$$\nE = \\mathbf{r}_x \\cdot \\mathbf{r}_x = 1 + 4x^2,\\quad\nF = \\mathbf{r}_x \\cdot \\mathbf{r}_y = 4xy,\\quad\nG = \\mathbf{r}_y \\cdot \\mathbf{r}_y = 1 + 4y^2.\n$$\n\nAt the point $(1,1,2)$ (so $x=1$, $y=1$):\n$$\nE = 5,\\quad F = 4,\\quad G = 5,\\quad EG - F^2 = 25 - 16 = 9.\n$$\n\n**Unit normal vector:**\n$$\n\\mathbf{r}_x \\times \\mathbf{r}_y = \\begin{vmatrix}\n\\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\\n1 & 0 & 2x \\\\\n0 & 1 & 2y\n\\end{vmatrix} = (-2x, -2y, 1).\n$$\n$$\n\\|\\mathbf{r}_x \\times \\mathbf{r}_y\\| = \\sqrt{4x^2 + 4y^2 + 1}.\n$$\n$$\n\\mathbf{n} = \\frac{\\mathbf{r}_x \\times \\mathbf{r}_y}{\\|\\mathbf{r}_x \\times \\mathbf{r}_y\\|} = \\frac{(-2x, -2y, 1)}{\\sqrt{4x^2 + 4y^2 + 1}}.\n$$\n\nAt $(1,1)$: $\\|\\mathbf{r}_x \\times \\mathbf{r}_y\\| = \\sqrt{4+4+1}=3$, so $\\mathbf{n} = \\frac{(-2, -2, 1)}{3}$.\n\n**Second partial derivatives:**\n$$\n\\mathbf{r}_{xx} = (0,0,2),\\quad \\mathbf{r}_{xy} = (0,0,0),\\quad \\mathbf{r}_{yy} = (0,0,2).\n$$\n\n**Second fundamental form coefficients** (using the unit normal):\n$$\nL = \\mathbf{r}_{xx} \\cdot \\mathbf{n},\\quad M = \\mathbf{r}_{xy} \\cdot \\mathbf{n},\\quad N = \\mathbf{r}_{yy} \\cdot \\mathbf{n}.\n$$\n\nAt $(1,1)$:\n$$\nL = (0,0,2) \\cdot \\frac{(-2,-2,1)}{3} = \\frac{2}{3},\\quad\nM = 0,\\quad\nN = \\frac{2}{3}.\n$$\nThus,\n$$\nLN - M^2 = \\left(\\frac{2}{3}\\right)^2 = \\frac{4}{9}.\n$$\n\n**Gaussian curvature:**\n$$\nK = \\frac{LN - M^2}{EG - F^2} = \\frac{4/9}{9} = \\frac{4}{81}.\n$$\n\nTherefore, the Gaussian curvature of $S$ at the point $(1,1,2)$ is $\\boxed{\\dfrac{4}{81}}$.",
        "raw_answer": "We compute the Gaussian curvature using the first and second fundamental forms.\n\n**Solution:**\n\nParameterize the surface \\(S\\) by \\(\\mathbf{r}(x,y) = (x, y, x^2 + y^2)\\), where \\((x,y) \\in \\mathbb{R}^2\\).\n\nFirst partial derivatives:\n\\[\n\\mathbf{r}_x = (1, 0, 2x), \\qquad \\mathbf{r}_y = (0, 1, 2y).\n\\]\n\n**First fundamental form:**\n\\[\nE = \\mathbf{r}_x \\cdot \\mathbf{r}_x = 1 + 4x^2,\\quad\nF = \\mathbf{r}_x \\cdot \\mathbf{r}_y = 4xy,\\quad\nG = \\mathbf{r}_y \\cdot \\mathbf{r}_y = 1 + 4y^2.\n\\]\n\nAt the point \\((1,1,2)\\) (so \\(x=1\\), \\(y=1\\)):\n\\[\nE = 5,\\quad F = 4,\\quad G = 5,\\quad EG - F^2 = 25 - 16 = 9.\n\\]\n\n**Unit normal vector:**\n\\[\n\\mathbf{r}_x \\times \\mathbf{r}_y = \\begin{vmatrix}\n\\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\\n1 & 0 & 2x \\\\\n0 & 1 & 2y\n\\end{vmatrix} = (-2x, -2y, 1).\n\\]\n\\[\n\\|\\mathbf{r}_x \\times \\mathbf{r}_y\\| = \\sqrt{4x^2 + 4y^2 + 1}.\n\\]\n\\[\n\\mathbf{n} = \\frac{\\mathbf{r}_x \\times \\mathbf{r}_y}{\\|\\mathbf{r}_x \\times \\mathbf{r}_y\\|} = \\frac{(-2x, -2y, 1)}{\\sqrt{4x^2 + 4y^2 + 1}}.\n\\]\n\nAt \\((1,1)\\): \\(\\|\\mathbf{r}_x \\times \\mathbf{r}_y\\| = \\sqrt{4+4+1}=3\\), so \\(\\mathbf{n} = \\frac{(-2, -2, 1)}{3}\\).\n\n**Second partial derivatives:**\n\\[\n\\mathbf{r}_{xx} = (0,0,2),\\quad \\mathbf{r}_{xy} = (0,0,0),\\quad \\mathbf{r}_{yy} = (0,0,2).\n\\]\n\n**Second fundamental form coefficients** (using the unit normal):\n\\[\nL = \\mathbf{r}_{xx} \\cdot \\mathbf{n},\\quad M = \\mathbf{r}_{xy} \\cdot \\mathbf{n},\\quad N = \\mathbf{r}_{yy} \\cdot \\mathbf{n}.\n\\]\n\nAt \\((1,1)\\):\n\\[\nL = (0,0,2) \\cdot \\frac{(-2,-2,1)}{3} = \\frac{2}{3},\\quad\nM = 0,\\quad\nN = \\frac{2}{3}.\n\\]\nThus,\n\\[\nLN - M^2 = \\left(\\frac{2}{3}\\right)^2 = \\frac{4}{9}.\n\\]\n\n**Gaussian curvature:**\n\\[\nK = \\frac{LN - M^2}{EG - F^2} = \\frac{4/9}{9} = \\frac{4}{81}.\n\\]\n\nTherefore, the Gaussian curvature of \\(S\\) at the point \\((1,1,2)\\) is \\(\\boxed{\\dfrac{4}{81}}\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of general topology, along with a complete solution, following specific guidelines.\n[/QUESTION]",
    "run_id": "38",
    "topic_slug": "general_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem.**  \nDefine the *Sorgenfrey line* $\\mathbb{R}_\\ell$ as the topological space on $\\mathbb{R}$ whose basis consists of all half\u2011open intervals $[a,b)$ with $a<b$.  \nProve that $\\mathbb{R}_\\ell$ is a normal topological space, but the product space $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ (the *Sorgenfrey plane*) is not normal.\n\n---\n\n**Solution.**\n\n### 1. Normality of $\\mathbb{R}_\\ell$\n\nWe first establish that $\\mathbb{R}_\\ell$ is $T_1$, regular, and Lindel\u00f6f; then a general lemma shows that every regular Lindel\u00f6f space is normal.\n\n---\n\n**Lemma 1.** $\\mathbb{R}_\\ell$ is $T_1$.\n\n*Proof.* For any $x\\in\\mathbb{R}$, the complement $\\mathbb{R}\\setminus\\{x\\}=(-\\infty,x)\\cup[x,\\infty)$ is open: $(-\\infty,x)=\\bigcup_{n=1}^{\\infty}[x-n,x)$ and $[x,\\infty)=\\bigcup_{n=1}^{\\infty}[x,x+n)$ are unions of basic open sets. Hence $\\{x\\}$ is closed. \u220e\n\n---\n\n**Lemma 2.** $\\mathbb{R}_\\ell$ is regular.\n\n*Proof.* Let $x\\in\\mathbb{R}_\\ell$ and let $C\\subseteq\\mathbb{R}_\\ell$ be closed with $x\\notin C$. Then $U=\\mathbb{R}_\\ell\\setminus C$ is open and contains $x$, so there exists $\\varepsilon>0$ such that $[x,x+\\varepsilon)\\subseteq U$. The set $[x,x+\\varepsilon)$ is both open (by definition) and closed (its complement $(-\\infty,x)\\cup[x+\\varepsilon,\\infty)$ is a union of basic open sets). Set $V=\\mathbb{R}_\\ell\\setminus[x,x+\\varepsilon)$, which is open. Then $x\\in[x,x+\\varepsilon)$, $C\\subseteq V$, and $[x,x+\\varepsilon)\\cap V=\\varnothing$. Thus $\\mathbb{R}_\\ell$ is regular. \u220e\n\n---\n\n**Lemma 3.** $\\mathbb{R}_\\ell$ is Lindel\u00f6f.\n\n*Proof.* Let $\\mathcal{U}$ be an open cover of $\\mathbb{R}_\\ell$. For each $x\\in\\mathbb{R}$ choose $U_x\\in\\mathcal{U}$ and $\\varepsilon_x>0$ with $[x,x+\\varepsilon_x)\\subseteq U_x$. Consider the family of ordinary open intervals $\\mathcal{I}=\\{(x,x+\\varepsilon_x):x\\in\\mathbb{R}\\}$ in the usual topology on $\\mathbb{R}$. Let $V=\\bigcup_{x\\in\\mathbb{R}}(x,x+\\varepsilon_x)$ and $K=\\mathbb{R}\\setminus V$.\n\n*$K$ is countable.* For each $y\\in K$, the interval $(y,y+\\varepsilon_y)$ is non\u2011empty. If $y_1,y_2\\in K$ with $y_1<y_2$ and $(y_1,y_1+\\varepsilon_{y_1})\\cap(y_2,y_2+\\varepsilon_{y_2})\\neq\\varnothing$, pick $z$ in the intersection. Then $y_1<z<y_1+\\varepsilon_{y_1}$ and $y_2<z<y_2+\\varepsilon_{y_2}$, so $y_2\\in(y_1,y_1+\\varepsilon_{y_1})$, contradicting $y_2\\in K$ (since $y_2$ would then belong to some $(x,x+\\varepsilon_x)$). Hence the intervals $\\{(y,y+\\varepsilon_y):y\\in K\\}$ are pairwise disjoint. Each contains a rational number; choosing one rational per interval gives an injection $K\\hookrightarrow\\mathbb{Q}$, so $K$ is countable.\n\n*Cover $V$ by a countable subfamily.* $V$ is open in the usual topology, and $\\mathcal{I}$ is an open cover of $V$. The usual topology on $\\mathbb{R}$ is second countable, hence Lindel\u00f6f, so there exists a countable set $X\\subseteq\\mathbb{R}$ such that $V\\subseteq\\bigcup_{x\\in X}(x,x+\\varepsilon_x)$. Then the corresponding $U_x$ (for $x\\in X$) together with the $U_y$ for $y\\in K$ form a countable subcover of $\\mathcal{U}$. Indeed, every point of $V$ lies in some $(x,x+\\varepsilon_x)$ with $x\\in X$, hence also in $[x,x+\\varepsilon_x)\\subseteq U_x$; every point of $K$ is covered by its own $U_y$. Therefore $\\mathbb{R}_\\ell$ is Lindel\u00f6f. \u220e\n\n---\n\n**Lemma 4.** Every regular Lindel\u00f6f space is normal.\n\n*Proof.* Let $X$ be regular and Lindel\u00f6f, and let $A,B\\subseteq X$ be disjoint closed sets. For each $a\\in A$ choose an open neighbourhood $U_a$ of $a$ with $\\overline{U_a}\\cap B=\\varnothing$ (regularity gives disjoint neighbourhoods of $a$ and $B$; take the one containing $a$ and note that its closure stays away from $B$ because the neighbourhood of $B$ is open). Similarly, for each $b\\in B$ choose an open $V_b$ with $\\overline{V_b}\\cap A=\\varnothing$. The families $\\{U_a\\}_{a\\in A}$ and $\\{V_b\\}_{b\\in B}$ cover $A$ and $B$, respectively. Since closed subsets of a Lindel\u00f6f space are Lindel\u00f6f, $A$ and $B$ are Lindel\u00f6f, so we can extract countable subcovers $\\{U_n\\}_{n\\in\\mathbb{N}}$ of $A$ and $\\{V_n\\}_{n\\in\\mathbb{N}}$ of $B$, still satisfying $\\overline{U_n}\\cap B=\\varnothing$, $\\overline{V_n}\\cap A=\\varnothing$.\n\nDefine\n$$\nU_n' = U_n \\setminus \\bigcup_{i=1}^{n} \\overline{V_i},\\qquad\nV_n' = V_n \\setminus \\bigcup_{i=1}^{n} \\overline{U_i},\n$$\nand set $U=\\bigcup_n U_n'$, $V=\\bigcup_n V_n'$. Each $U_n'$, $V_n'$ is open (difference of an open set and a closed set). If $a\\in A$, let $n$ be the smallest index with $a\\in U_n$; then $a\\notin\\bigcup_{i=1}^{n}\\overline{V_i}$ (because $\\overline{V_i}\\cap A=\\varnothing$), so $a\\in U_n'\\subseteq U$. Hence $A\\subseteq U$. Similarly $B\\subseteq V$.\n\nSuppose $x\\in U\\cap V$. Then $x\\in U_n'$ for some $n$ and $x\\in V_m'$ for some $m$. Assume $n\\le m$ (the other case is symmetric). Then $x\\in U_n\\subseteq\\overline{U_n}$, but $V_m'$ is disjoint from $\\bigcup_{i=1}^{m}\\overline{U_i}$, which contains $\\overline{U_n}$ because $n\\le m$. Thus $x\\notin V_m'$, contradiction. Therefore $U\\cap V=\\varnothing$, and $X$ is normal. \u220e\n\nCombining Lemmas 1\u20134, $\\mathbb{R}_\\ell$ is normal (and $T_1$, hence $T_4$).\n\n---\n\n### 2. Non\u2011normality of $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$\n\nFirst, note that the product of $T_1$ spaces is $T_1$, so $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is $T_1$.\n\n---\n\n**Lemma 5.** $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is separable.\n\n*Proof.* $\\mathbb{Q}\\times\\mathbb{Q}$ is countable. Any basic open set in the product has the form $[a,b)\\times[c,d)$. Since $\\mathbb{Q}$ is dense in $\\mathbb{R}$ (in the usual topology, hence also in $\\mathbb{R}_\\ell$ because the Sorgenfrey topology is finer), there exist $q_1\\in(a,b)$ and $q_2\\in(c,d)$. Then $(q_1,q_2)\\in[a,b)\\times[c,d)$. Thus $\\mathbb{Q}\\times\\mathbb{Q}$ meets every nonempty basic open set, so it is dense. \u220e\n\n---\n\n**Lemma 6.** The set $L=\\{(x,-x):x\\in\\mathbb{R}\\}$ is an uncountable closed discrete subspace of $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$.\n\n*Proof.* The map $x\\mapsto(x,-x)$ is a bijection onto $\\mathbb{R}$, so $|L|=\\mathfrak{c}=2^{\\aleph_0}$.\n\n*Closed.* The Euclidean topology on $\\mathbb{R}^2$ is coarser than the Sorgenfrey plane topology: every Euclidean open set is open in $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ because a Euclidean ball around a point contains a product of half\u2011open intervals. Hence every Euclidean closed set is also closed in the finer topology. $L$ is closed in the Euclidean plane (it is the zero set of the continuous function $(x,y)\\mapsto x+y$), so $L$ is closed in $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$.\n\n*Discrete.* For $(x,-x)\\in L$, the basic open set $[x,x+1)\\times[-x,-x+1)$ intersects $L$ only in $\\{(x,-x)\\}$: if $(t,-t)\\in L$ also lies in this product, then $t\\in[x,x+1)$ and $-t\\in[-x,-x+1)$. The second condition gives $-x\\le -t<-x+1$, i.e., $x\\ge t>x-1$. Together with $t\\ge x$ we obtain $t=x$. Hence $\\{(x,-x)\\}$ is open in the subspace topology, so $L$ is discrete. \u220e\n\n---\n\n**Lemma 7 (Jones\u2019 Lemma).** Let $X$ be a normal topological space, $D\\subseteq X$ a dense subset, and $S\\subseteq X$ a closed discrete subspace. Then $2^{|S|}\\le 2^{|D|}$.\n\n*Proof.* For each $T\\subseteq S$, the sets $T$ and $S\\setminus T$ are disjoint and closed in $X$ (every subset of a closed discrete subspace is closed). By normality there exist disjoint open sets $U_T,V_T$ with $T\\subseteq U_T$, $S\\setminus T\\subseteq V_T$. Then $\\overline{U_T}\\subseteq X\\setminus V_T$, so $\\overline{U_T}\\cap(S\\setminus T)=\\varnothing$. Consequently $\\overline{U_T}\\cap S=T$.\n\nDefine $f:\\mathcal{P}(S)\\to\\mathcal{P}(D)$ by $f(T)=\\overline{U_T}\\cap D$. We show $f$ is injective. Suppose $T_1\\neq T_2$; without loss of generality, pick $s\\in T_1\\setminus T_2$. Then $s\\in\\overline{U_{T_1}}$ and $s\\in S\\setminus T_2\\subseteq V_{T_2}$. Because $\\overline{U_{T_2}}\\subseteq X\\setminus V_{T_2}$, we have $s\\notin\\overline{U_{T_2}}$. Thus $\\overline{U_{T_1}}\\neq\\overline{U_{T_2}}$. Since $D$ is dense, $\\overline{U_T}=\\overline{U_T\\cap D}$ for any $T$. If $f(T_1)=f(T_2)$, then $\\overline{U_{T_1}}\\cap D=\\overline{U_{T_2}}\\cap D$, and taking closures gives $\\overline{U_{T_1}}=\\overline{U_{T_2}}$, a contradiction. Hence $f$ is injective, yielding $|\\mathcal{P}(S)|\\le|\\mathcal{P}(D)|$, i.e., $2^{|S|}\\le 2^{|D|}$. \u220e\n\n---\n\n**Conclusion.** Assume, for contradiction, that $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is normal. Take $D=\\mathbb{Q}\\times\\mathbb{Q}$ (countable, $|D|=\\aleph_0$) and $S=L$ (with $|S|=\\mathfrak{c}$). By Jones\u2019 Lemma,\n$$\n2^{\\mathfrak{c}} \\le 2^{\\aleph_0} = \\mathfrak{c}.\n$$\nBut Cantor\u2019s theorem states $\\mathfrak{c}<2^{\\mathfrak{c}}$, a contradiction. Therefore $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ cannot be normal.\n\n---\n\nThus the Sorgenfrey line is normal, while the Sorgenfrey plane is not. \u220e",
        "raw_answer": "**Problem.**  \nDefine the *Sorgenfrey line* $\\mathbb{R}_\\ell$ as the topological space on $\\mathbb{R}$ whose basis consists of all half\u2011open intervals $[a,b)$ with $a<b$.  \nProve that $\\mathbb{R}_\\ell$ is a normal topological space, but the product space $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ (the *Sorgenfrey plane*) is not normal.\n\n---\n\n**Solution.**\n\n### 1. Normality of $\\mathbb{R}_\\ell$\n\nWe first establish that $\\mathbb{R}_\\ell$ is $T_1$, regular, and Lindel\u00f6f; then a general lemma shows that every regular Lindel\u00f6f space is normal.\n\n---\n\n**Lemma 1.** $\\mathbb{R}_\\ell$ is $T_1$.\n\n*Proof.* For any $x\\in\\mathbb{R}$, the complement $\\mathbb{R}\\setminus\\{x\\}=(-\\infty,x)\\cup[x,\\infty)$ is open: $(-\\infty,x)=\\bigcup_{n=1}^{\\infty}[x-n,x)$ and $[x,\\infty)=\\bigcup_{n=1}^{\\infty}[x,x+n)$ are unions of basic open sets. Hence $\\{x\\}$ is closed. \u220e\n\n---\n\n**Lemma 2.** $\\mathbb{R}_\\ell$ is regular.\n\n*Proof.* Let $x\\in\\mathbb{R}_\\ell$ and let $C\\subseteq\\mathbb{R}_\\ell$ be closed with $x\\notin C$. Then $U=\\mathbb{R}_\\ell\\setminus C$ is open and contains $x$, so there exists $\\varepsilon>0$ such that $[x,x+\\varepsilon)\\subseteq U$. The set $[x,x+\\varepsilon)$ is both open (by definition) and closed (its complement $(-\\infty,x)\\cup[x+\\varepsilon,\\infty)$ is a union of basic open sets). Set $V=\\mathbb{R}_\\ell\\setminus[x,x+\\varepsilon)$, which is open. Then $x\\in[x,x+\\varepsilon)$, $C\\subseteq V$, and $[x,x+\\varepsilon)\\cap V=\\varnothing$. Thus $\\mathbb{R}_\\ell$ is regular. \u220e\n\n---\n\n**Lemma 3.** $\\mathbb{R}_\\ell$ is Lindel\u00f6f.\n\n*Proof.* Let $\\mathcal{U}$ be an open cover of $\\mathbb{R}_\\ell$. For each $x\\in\\mathbb{R}$ choose $U_x\\in\\mathcal{U}$ and $\\varepsilon_x>0$ with $[x,x+\\varepsilon_x)\\subseteq U_x$. Consider the family of ordinary open intervals $\\mathcal{I}=\\{(x,x+\\varepsilon_x):x\\in\\mathbb{R}\\}$ in the usual topology on $\\mathbb{R}$. Let $V=\\bigcup_{x\\in\\mathbb{R}}(x,x+\\varepsilon_x)$ and $K=\\mathbb{R}\\setminus V$.\n\n*$K$ is countable.* For each $y\\in K$, the interval $(y,y+\\varepsilon_y)$ is non\u2011empty. If $y_1,y_2\\in K$ with $y_1<y_2$ and $(y_1,y_1+\\varepsilon_{y_1})\\cap(y_2,y_2+\\varepsilon_{y_2})\\neq\\varnothing$, pick $z$ in the intersection. Then $y_1<z<y_1+\\varepsilon_{y_1}$ and $y_2<z<y_2+\\varepsilon_{y_2}$, so $y_2\\in(y_1,y_1+\\varepsilon_{y_1})$, contradicting $y_2\\in K$ (since $y_2$ would then belong to some $(x,x+\\varepsilon_x)$). Hence the intervals $\\{(y,y+\\varepsilon_y):y\\in K\\}$ are pairwise disjoint. Each contains a rational number; choosing one rational per interval gives an injection $K\\hookrightarrow\\mathbb{Q}$, so $K$ is countable.\n\n*Cover $V$ by a countable subfamily.* $V$ is open in the usual topology, and $\\mathcal{I}$ is an open cover of $V$. The usual topology on $\\mathbb{R}$ is second countable, hence Lindel\u00f6f, so there exists a countable set $X\\subseteq\\mathbb{R}$ such that $V\\subseteq\\bigcup_{x\\in X}(x,x+\\varepsilon_x)$. Then the corresponding $U_x$ (for $x\\in X$) together with the $U_y$ for $y\\in K$ form a countable subcover of $\\mathcal{U}$. Indeed, every point of $V$ lies in some $(x,x+\\varepsilon_x)$ with $x\\in X$, hence also in $[x,x+\\varepsilon_x)\\subseteq U_x$; every point of $K$ is covered by its own $U_y$. Therefore $\\mathbb{R}_\\ell$ is Lindel\u00f6f. \u220e\n\n---\n\n**Lemma 4.** Every regular Lindel\u00f6f space is normal.\n\n*Proof.* Let $X$ be regular and Lindel\u00f6f, and let $A,B\\subseteq X$ be disjoint closed sets. For each $a\\in A$ choose an open neighbourhood $U_a$ of $a$ with $\\overline{U_a}\\cap B=\\varnothing$ (regularity gives disjoint neighbourhoods of $a$ and $B$; take the one containing $a$ and note that its closure stays away from $B$ because the neighbourhood of $B$ is open). Similarly, for each $b\\in B$ choose an open $V_b$ with $\\overline{V_b}\\cap A=\\varnothing$. The families $\\{U_a\\}_{a\\in A}$ and $\\{V_b\\}_{b\\in B}$ cover $A$ and $B$, respectively. Since closed subsets of a Lindel\u00f6f space are Lindel\u00f6f, $A$ and $B$ are Lindel\u00f6f, so we can extract countable subcovers $\\{U_n\\}_{n\\in\\mathbb{N}}$ of $A$ and $\\{V_n\\}_{n\\in\\mathbb{N}}$ of $B$, still satisfying $\\overline{U_n}\\cap B=\\varnothing$, $\\overline{V_n}\\cap A=\\varnothing$.\n\nDefine\n\\[\nU_n' = U_n \\setminus \\bigcup_{i=1}^{n} \\overline{V_i},\\qquad\nV_n' = V_n \\setminus \\bigcup_{i=1}^{n} \\overline{U_i},\n\\]\nand set $U=\\bigcup_n U_n'$, $V=\\bigcup_n V_n'$. Each $U_n'$, $V_n'$ is open (difference of an open set and a closed set). If $a\\in A$, let $n$ be the smallest index with $a\\in U_n$; then $a\\notin\\bigcup_{i=1}^{n}\\overline{V_i}$ (because $\\overline{V_i}\\cap A=\\varnothing$), so $a\\in U_n'\\subseteq U$. Hence $A\\subseteq U$. Similarly $B\\subseteq V$.\n\nSuppose $x\\in U\\cap V$. Then $x\\in U_n'$ for some $n$ and $x\\in V_m'$ for some $m$. Assume $n\\le m$ (the other case is symmetric). Then $x\\in U_n\\subseteq\\overline{U_n}$, but $V_m'$ is disjoint from $\\bigcup_{i=1}^{m}\\overline{U_i}$, which contains $\\overline{U_n}$ because $n\\le m$. Thus $x\\notin V_m'$, contradiction. Therefore $U\\cap V=\\varnothing$, and $X$ is normal. \u220e\n\nCombining Lemmas 1\u20134, $\\mathbb{R}_\\ell$ is normal (and $T_1$, hence $T_4$).\n\n---\n\n### 2. Non\u2011normality of $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$\n\nFirst, note that the product of $T_1$ spaces is $T_1$, so $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is $T_1$.\n\n---\n\n**Lemma 5.** $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is separable.\n\n*Proof.* $\\mathbb{Q}\\times\\mathbb{Q}$ is countable. Any basic open set in the product has the form $[a,b)\\times[c,d)$. Since $\\mathbb{Q}$ is dense in $\\mathbb{R}$ (in the usual topology, hence also in $\\mathbb{R}_\\ell$ because the Sorgenfrey topology is finer), there exist $q_1\\in(a,b)$ and $q_2\\in(c,d)$. Then $(q_1,q_2)\\in[a,b)\\times[c,d)$. Thus $\\mathbb{Q}\\times\\mathbb{Q}$ meets every nonempty basic open set, so it is dense. \u220e\n\n---\n\n**Lemma 6.** The set $L=\\{(x,-x):x\\in\\mathbb{R}\\}$ is an uncountable closed discrete subspace of $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$.\n\n*Proof.* The map $x\\mapsto(x,-x)$ is a bijection onto $\\mathbb{R}$, so $|L|=\\mathfrak{c}=2^{\\aleph_0}$.\n\n*Closed.* The Euclidean topology on $\\mathbb{R}^2$ is coarser than the Sorgenfrey plane topology: every Euclidean open set is open in $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ because a Euclidean ball around a point contains a product of half\u2011open intervals. Hence every Euclidean closed set is also closed in the finer topology. $L$ is closed in the Euclidean plane (it is the zero set of the continuous function $(x,y)\\mapsto x+y$), so $L$ is closed in $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$.\n\n*Discrete.* For $(x,-x)\\in L$, the basic open set $[x,x+1)\\times[-x,-x+1)$ intersects $L$ only in $\\{(x,-x)\\}$: if $(t,-t)\\in L$ also lies in this product, then $t\\in[x,x+1)$ and $-t\\in[-x,-x+1)$. The second condition gives $-x\\le -t<-x+1$, i.e., $x\\ge t>x-1$. Together with $t\\ge x$ we obtain $t=x$. Hence $\\{(x,-x)\\}$ is open in the subspace topology, so $L$ is discrete. \u220e\n\n---\n\n**Lemma 7 (Jones\u2019 Lemma).** Let $X$ be a normal topological space, $D\\subseteq X$ a dense subset, and $S\\subseteq X$ a closed discrete subspace. Then $2^{|S|}\\le 2^{|D|}$.\n\n*Proof.* For each $T\\subseteq S$, the sets $T$ and $S\\setminus T$ are disjoint and closed in $X$ (every subset of a closed discrete subspace is closed). By normality there exist disjoint open sets $U_T,V_T$ with $T\\subseteq U_T$, $S\\setminus T\\subseteq V_T$. Then $\\overline{U_T}\\subseteq X\\setminus V_T$, so $\\overline{U_T}\\cap(S\\setminus T)=\\varnothing$. Consequently $\\overline{U_T}\\cap S=T$.\n\nDefine $f:\\mathcal{P}(S)\\to\\mathcal{P}(D)$ by $f(T)=\\overline{U_T}\\cap D$. We show $f$ is injective. Suppose $T_1\\neq T_2$; without loss of generality, pick $s\\in T_1\\setminus T_2$. Then $s\\in\\overline{U_{T_1}}$ and $s\\in S\\setminus T_2\\subseteq V_{T_2}$. Because $\\overline{U_{T_2}}\\subseteq X\\setminus V_{T_2}$, we have $s\\notin\\overline{U_{T_2}}$. Thus $\\overline{U_{T_1}}\\neq\\overline{U_{T_2}}$. Since $D$ is dense, $\\overline{U_T}=\\overline{U_T\\cap D}$ for any $T$. If $f(T_1)=f(T_2)$, then $\\overline{U_{T_1}}\\cap D=\\overline{U_{T_2}}\\cap D$, and taking closures gives $\\overline{U_{T_1}}=\\overline{U_{T_2}}$, a contradiction. Hence $f$ is injective, yielding $|\\mathcal{P}(S)|\\le|\\mathcal{P}(D)|$, i.e., $2^{|S|}\\le 2^{|D|}$. \u220e\n\n---\n\n**Conclusion.** Assume, for contradiction, that $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is normal. Take $D=\\mathbb{Q}\\times\\mathbb{Q}$ (countable, $|D|=\\aleph_0$) and $S=L$ (with $|S|=\\mathfrak{c}$). By Jones\u2019 Lemma,\n\\[\n2^{\\mathfrak{c}} \\le 2^{\\aleph_0} = \\mathfrak{c}.\n\\]\nBut Cantor\u2019s theorem states $\\mathfrak{c}<2^{\\mathfrak{c}}$, a contradiction. Therefore $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ cannot be normal.\n\n---\n\nThus the Sorgenfrey line is normal, while the Sorgenfrey plane is not. \u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $X = S^1 \\vee S^1$ be the wedge sum of two circles, where the wedge point is $x_0$. Compute $\\pi_1(X, x_0)$.",
    "run_id": "39",
    "topic_slug": "algebraic_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We wish to compute the fundamental group of the wedge sum $X = S^1 \\vee S^1$ (the figure\u2011eight space) with basepoint $x_0$, the common point of the two circles.\n\nLet $C_1$ and $C_2$ be the two copies of $S^1$ in $X$, so that $C_1 \\cap C_2 = \\{x_0\\}$.\n\n**Construction of open sets.**  \nChoose distinct points $p_1 \\in C_1 \\setminus \\{x_0\\}$ and $p_2 \\in C_2 \\setminus \\{x_0\\}$. Define\n$$\nU = X \\setminus \\{p_2\\}, \\qquad V = X \\setminus \\{p_1\\}.\n$$\nSince points are closed in the Hausdorff space $X$, both $U$ and $V$ are open.  \n$U$ and $V$ are path\u2011connected: removing a point from a circle leaves an open interval, which is path\u2011connected, and the wedge point connects the two parts. Clearly $U \\cup V = X$ and $x_0 \\in U \\cap V$.\n\n**Deformation retractions.**  \n- $U = C_1 \\cup (C_2 \\setminus \\{p_2\\})$. The set $C_2 \\setminus \\{p_2\\}$ is homeomorphic to an open interval and therefore contractible. A strong deformation retraction of $U$ onto $C_1$ can be obtained by fixing every point of $C_1$ and sliding each point of $C_2 \\setminus \\{p_2\\}$ along the unique arc in $C_2 \\setminus \\{p_2\\}$ to $x_0$. (For instance, identify $C_2 \\setminus \\{p_2\\}$ with $(0,1)$ such that $x_0$ corresponds to $0$, and use the homotopy $(t,s) \\mapsto (1-s)t$.) Hence $\\pi_1(U, x_0) \\cong \\pi_1(C_1, x_0) \\cong \\mathbb{Z}$.  \n- Similarly, $V$ deformation retracts onto $C_2$, giving $\\pi_1(V, x_0) \\cong \\mathbb{Z}$.\n\n**The intersection.**  \n$$\nU \\cap V = X \\setminus \\{p_1, p_2\\} = (C_1 \\setminus \\{p_1\\}) \\cup (C_2 \\setminus \\{p_2\\}).\n$$\nEach $C_i \\setminus \\{p_i\\}$ is an open interval, hence contractible. Their union is two intervals glued together at the single point $x_0$; this space is a tree and therefore contractible as well (one can deformation retract each interval to $x_0$ simultaneously). Consequently, $U \\cap V$ is simply connected: $\\pi_1(U \\cap V, x_0) = 1$.\n\n**Application of the Seifert\u2013van Kampen theorem.**  \nThe open sets $U$, $V$ and their intersection are path\u2011connected and contain the basepoint $x_0$. The theorem then gives\n$$\n\\pi_1(X, x_0) \\cong \\pi_1(U, x_0) *_{\\pi_1(U \\cap V, x_0)} \\pi_1(V, x_0).\n$$\nBecause $\\pi_1(U \\cap V, x_0)$ is trivial, the amalgamated free product reduces to the ordinary free product:\n$$\n\\pi_1(X, x_0) \\cong \\pi_1(U, x_0) * \\pi_1(V, x_0) \\cong \\mathbb{Z} * \\mathbb{Z}.\n$$\n\nThe free product $\\mathbb{Z} * \\mathbb{Z}$ is the free group $F_2$ on two generators. Explicitly, if $a$ denotes the homotopy class of a loop that traverses $C_1$ once, and $b$ the class of a loop that traverses $C_2$ once, then every element of $\\pi_1(X, x_0)$ can be uniquely expressed as a reduced word in the letters $a, b, a^{-1}, b^{-1}$.\n\nThus,\n$$\n\\boxed{\\pi_1(X, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} \\cong F_2}.\n$$",
        "raw_answer": "We wish to compute the fundamental group of the wedge sum \\(X = S^1 \\vee S^1\\) (the figure\u2011eight space) with basepoint \\(x_0\\), the common point of the two circles.\n\nLet \\(C_1\\) and \\(C_2\\) be the two copies of \\(S^1\\) in \\(X\\), so that \\(C_1 \\cap C_2 = \\{x_0\\}\\).\n\n**Construction of open sets.**  \nChoose distinct points \\(p_1 \\in C_1 \\setminus \\{x_0\\}\\) and \\(p_2 \\in C_2 \\setminus \\{x_0\\}\\). Define\n\\[\nU = X \\setminus \\{p_2\\}, \\qquad V = X \\setminus \\{p_1\\}.\n\\]\nSince points are closed in the Hausdorff space \\(X\\), both \\(U\\) and \\(V\\) are open.  \n\\(U\\) and \\(V\\) are path\u2011connected: removing a point from a circle leaves an open interval, which is path\u2011connected, and the wedge point connects the two parts. Clearly \\(U \\cup V = X\\) and \\(x_0 \\in U \\cap V\\).\n\n**Deformation retractions.**  \n- \\(U = C_1 \\cup (C_2 \\setminus \\{p_2\\})\\). The set \\(C_2 \\setminus \\{p_2\\}\\) is homeomorphic to an open interval and therefore contractible. A strong deformation retraction of \\(U\\) onto \\(C_1\\) can be obtained by fixing every point of \\(C_1\\) and sliding each point of \\(C_2 \\setminus \\{p_2\\}\\) along the unique arc in \\(C_2 \\setminus \\{p_2\\}\\) to \\(x_0\\). (For instance, identify \\(C_2 \\setminus \\{p_2\\}\\) with \\((0,1)\\) such that \\(x_0\\) corresponds to \\(0\\), and use the homotopy \\((t,s) \\mapsto (1-s)t\\).) Hence \\(\\pi_1(U, x_0) \\cong \\pi_1(C_1, x_0) \\cong \\mathbb{Z}\\).  \n- Similarly, \\(V\\) deformation retracts onto \\(C_2\\), giving \\(\\pi_1(V, x_0) \\cong \\mathbb{Z}\\).\n\n**The intersection.**  \n\\[\nU \\cap V = X \\setminus \\{p_1, p_2\\} = (C_1 \\setminus \\{p_1\\}) \\cup (C_2 \\setminus \\{p_2\\}).\n\\]\nEach \\(C_i \\setminus \\{p_i\\}\\) is an open interval, hence contractible. Their union is two intervals glued together at the single point \\(x_0\\); this space is a tree and therefore contractible as well (one can deformation retract each interval to \\(x_0\\) simultaneously). Consequently, \\(U \\cap V\\) is simply connected: \\(\\pi_1(U \\cap V, x_0) = 1\\).\n\n**Application of the Seifert\u2013van Kampen theorem.**  \nThe open sets \\(U\\), \\(V\\) and their intersection are path\u2011connected and contain the basepoint \\(x_0\\). The theorem then gives\n\\[\n\\pi_1(X, x_0) \\cong \\pi_1(U, x_0) *_{\\pi_1(U \\cap V, x_0)} \\pi_1(V, x_0).\n\\]\nBecause \\(\\pi_1(U \\cap V, x_0)\\) is trivial, the amalgamated free product reduces to the ordinary free product:\n\\[\n\\pi_1(X, x_0) \\cong \\pi_1(U, x_0) * \\pi_1(V, x_0) \\cong \\mathbb{Z} * \\mathbb{Z}.\n\\]\n\nThe free product \\(\\mathbb{Z} * \\mathbb{Z}\\) is the free group \\(F_2\\) on two generators. Explicitly, if \\(a\\) denotes the homotopy class of a loop that traverses \\(C_1\\) once, and \\(b\\) the class of a loop that traverses \\(C_2\\) once, then every element of \\(\\pi_1(X, x_0)\\) can be uniquely expressed as a reduced word in the letters \\(a, b, a^{-1}, b^{-1}\\).\n\nThus,\n\\[\n\\boxed{\\pi_1(X, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} \\cong F_2}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Manifolds and cell complexes\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within the domain\nA suitable topic within \"Manifolds and cell complexes\" could involve the properties or constructions related to manifolds or cell complexes, such as their topology, geometry, or algebraic invariants.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the Euler characteristic of a manifold, which is a fundamental concept in algebraic topology that relates to both manifolds and cell complexes. The Euler characteristic is a topological invariant that can be computed using a cell decomposition of a manifold.\n\n## Step 4: Construct the problem statement\nConsider a 2-dimensional manifold $M$ that is homeomorphic to a sphere with $g$ handles (i.e., a surface of genus $g$). The task is to prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.\n\n## Step 5: Provide the problem statement in the required format\n\nLet $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles. Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.",
    "run_id": "40",
    "topic_slug": "manifolds_and_cell_complexes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove that the Euler characteristic of a closed orientable surface of genus $g$ (a sphere with $g$ handles) is $2-2g$. The Euler characteristic $\\chi(M)$ of a compact surface $M$ is defined as $\\chi(M)=V-E+F$ for any finite cell decomposition (or triangulation) of $M$ into $V$ vertices, $E$ edges, and $F$ faces. It is a topological invariant: homeomorphic surfaces have the same Euler characteristic.\n\nWe construct an explicit cell decomposition for the surface $\\Sigma_g$ of genus $g$ (including $g=0$) and compute its Euler characteristic.\n\n---\n\n### 1. The case $g=0$\n\nThe sphere $S^2$ is homeomorphic to a sphere with $0$ handles. A simple CW\u2011structure consists of one $0$-cell (a point) and one $2$-cell attached via the constant map (collapsing the boundary of the disk to the $0$-cell). This yields $V=1$, $E=0$, $F=1$, hence $\\chi(S^2)=1-0+1=2$, which agrees with $2-2\\cdot0=2$.\n\n---\n\n### 2. The case $g\\ge 1$\n\nConsider a $4g$-sided polygon $P$ (a topological disk). Label its sides consecutively as\n$$\na_1,\\; b_1,\\; a_1^{-1},\\; b_1^{-1},\\; a_2,\\; b_2,\\; a_2^{-1},\\; b_2^{-1},\\;\\dots,\\; a_g,\\; b_g,\\; a_g^{-1},\\; b_g^{-1},\n$$\nwhere the notation indicates that sides with the same letter are to be identified, but with opposite orientations. More precisely, for each $i=1,\\dots,g$, side $a_i$ is identified with side $a_i^{-1}$ by a homeomorphism that reverses the direction (so that the head of $a_i$ is glued to the tail of $a_i^{-1}$, etc.), and similarly for $b_i$ and $b_i^{-1}$. The identifications are performed in the standard pattern that yields an orientable surface.\n\nAfter all identifications, we obtain a quotient space $\\Sigma_g$. It is a classical fact (easily verified) that $\\Sigma_g$ is a compact, connected, orientable surface of genus $g$. Let us briefly check the local Euclidean structure:\n\n* **Interior points of $P$:** a small open disk inside $P$ remains unchanged and is a neighbourhood homeomorphic to $\\mathbb{R}^2$.\n* **Points on the interior of a side:** a small half\u2011disk on each side of the side in $P$ is glued to a half\u2011disk from the paired side; together they form a full open disk.\n* **The unique vertex:** all $4g$ vertices of $P$ are identified to a single point. Take a small neighbourhood of each vertex in $P$ consisting of a small sector of the polygon. Under the identification, these sectors are arranged cyclically around the point; because the gluing pattern follows the cyclic order $a_1b_1a_1^{-1}b_1^{-1}\\cdots a_gb_ga_g^{-1}b_g^{-1}$, the sectors combine to form a single open disk (the total angle sums to $2\\pi$ after a suitable smoothing, which is always possible topologically).\n\nThus $\\Sigma_g$ is indeed a topological $2$-manifold without boundary.\n\n---\n\n### 3. Cell count\n\nWe view the quotient $\\Sigma_g$ as a CW complex:\n\n* The **$2$-cell** is the interior of the polygon $P$ (or $P$ itself).\n* The **$1$-cells** are the images of the sides after identification. Each pair $(a_i, a_i^{-1})$ gives one $1$-cell; similarly each pair $(b_i, b_i^{-1})$ gives one $1$-cell. Hence there are $2g$ distinct $1$-cells.\n* The **$0$-cells** are the images of the vertices. All $4g$ vertices of $P$ are identified to a single point, so there is exactly one $0$-cell.\n\nTherefore,\n$$\nV = 1,\\qquad E = 2g,\\qquad F = 1.\n$$\n\n---\n\n### 4. Euler characteristic\n\nUsing the definition $\\chi = V - E + F$ we obtain\n$$\n\\chi(\\Sigma_g) = 1 - 2g + 1 = 2 - 2g.\n$$\n\n---\n\n### 5. General case\n\nLet $M$ be any $2$-dimensional manifold homeomorphic to a sphere with $g$ handles. Then $M$ is homeomorphic to $\\Sigma_g$. Since the Euler characteristic is a topological invariant,\n$$\n\\chi(M) = \\chi(\\Sigma_g) = 2 - 2g.\n$$\n\n---\n\n### 6. Conclusion\n\nWe have shown that for every integer $g\\ge 0$, the Euler characteristic of a closed orientable surface of genus $g$ is $2-2g$. In particular, for a sphere with $g$ handles, $\\chi(M)=2-2g$. $\\square$",
        "raw_answer": "We prove that the Euler characteristic of a closed orientable surface of genus \\(g\\) (a sphere with \\(g\\) handles) is \\(2-2g\\). The Euler characteristic \\(\\chi(M)\\) of a compact surface \\(M\\) is defined as \\(\\chi(M)=V-E+F\\) for any finite cell decomposition (or triangulation) of \\(M\\) into \\(V\\) vertices, \\(E\\) edges, and \\(F\\) faces. It is a topological invariant: homeomorphic surfaces have the same Euler characteristic.\n\nWe construct an explicit cell decomposition for the surface \\(\\Sigma_g\\) of genus \\(g\\) (including \\(g=0\\)) and compute its Euler characteristic.\n\n---\n\n### 1. The case \\(g=0\\)\n\nThe sphere \\(S^2\\) is homeomorphic to a sphere with \\(0\\) handles. A simple CW\u2011structure consists of one \\(0\\)-cell (a point) and one \\(2\\)-cell attached via the constant map (collapsing the boundary of the disk to the \\(0\\)-cell). This yields \\(V=1\\), \\(E=0\\), \\(F=1\\), hence \\(\\chi(S^2)=1-0+1=2\\), which agrees with \\(2-2\\cdot0=2\\).\n\n---\n\n### 2. The case \\(g\\ge 1\\)\n\nConsider a \\(4g\\)-sided polygon \\(P\\) (a topological disk). Label its sides consecutively as\n\\[\na_1,\\; b_1,\\; a_1^{-1},\\; b_1^{-1},\\; a_2,\\; b_2,\\; a_2^{-1},\\; b_2^{-1},\\;\\dots,\\; a_g,\\; b_g,\\; a_g^{-1},\\; b_g^{-1},\n\\]\nwhere the notation indicates that sides with the same letter are to be identified, but with opposite orientations. More precisely, for each \\(i=1,\\dots,g\\), side \\(a_i\\) is identified with side \\(a_i^{-1}\\) by a homeomorphism that reverses the direction (so that the head of \\(a_i\\) is glued to the tail of \\(a_i^{-1}\\), etc.), and similarly for \\(b_i\\) and \\(b_i^{-1}\\). The identifications are performed in the standard pattern that yields an orientable surface.\n\nAfter all identifications, we obtain a quotient space \\(\\Sigma_g\\). It is a classical fact (easily verified) that \\(\\Sigma_g\\) is a compact, connected, orientable surface of genus \\(g\\). Let us briefly check the local Euclidean structure:\n\n* **Interior points of \\(P\\):** a small open disk inside \\(P\\) remains unchanged and is a neighbourhood homeomorphic to \\(\\mathbb{R}^2\\).\n* **Points on the interior of a side:** a small half\u2011disk on each side of the side in \\(P\\) is glued to a half\u2011disk from the paired side; together they form a full open disk.\n* **The unique vertex:** all \\(4g\\) vertices of \\(P\\) are identified to a single point. Take a small neighbourhood of each vertex in \\(P\\) consisting of a small sector of the polygon. Under the identification, these sectors are arranged cyclically around the point; because the gluing pattern follows the cyclic order \\(a_1b_1a_1^{-1}b_1^{-1}\\cdots a_gb_ga_g^{-1}b_g^{-1}\\), the sectors combine to form a single open disk (the total angle sums to \\(2\\pi\\) after a suitable smoothing, which is always possible topologically).\n\nThus \\(\\Sigma_g\\) is indeed a topological \\(2\\)-manifold without boundary.\n\n---\n\n### 3. Cell count\n\nWe view the quotient \\(\\Sigma_g\\) as a CW complex:\n\n* The **\\(2\\)-cell** is the interior of the polygon \\(P\\) (or \\(P\\) itself).\n* The **\\(1\\)-cells** are the images of the sides after identification. Each pair \\((a_i, a_i^{-1})\\) gives one \\(1\\)-cell; similarly each pair \\((b_i, b_i^{-1})\\) gives one \\(1\\)-cell. Hence there are \\(2g\\) distinct \\(1\\)-cells.\n* The **\\(0\\)-cells** are the images of the vertices. All \\(4g\\) vertices of \\(P\\) are identified to a single point, so there is exactly one \\(0\\)-cell.\n\nTherefore,\n\\[\nV = 1,\\qquad E = 2g,\\qquad F = 1.\n\\]\n\n---\n\n### 4. Euler characteristic\n\nUsing the definition \\(\\chi = V - E + F\\) we obtain\n\\[\n\\chi(\\Sigma_g) = 1 - 2g + 1 = 2 - 2g.\n\\]\n\n---\n\n### 5. General case\n\nLet \\(M\\) be any \\(2\\)-dimensional manifold homeomorphic to a sphere with \\(g\\) handles. Then \\(M\\) is homeomorphic to \\(\\Sigma_g\\). Since the Euler characteristic is a topological invariant,\n\\[\n\\chi(M) = \\chi(\\Sigma_g) = 2 - 2g.\n\\]\n\n---\n\n### 6. Conclusion\n\nWe have shown that for every integer \\(g\\ge 0\\), the Euler characteristic of a closed orientable surface of genus \\(g\\) is \\(2-2g\\). In particular, for a sphere with \\(g\\) handles, \\(\\chi(M)=2-2g\\). \\(\\square\\)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Global analysis, analysis on manifolds\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify key concepts in the domain\nGlobal analysis and analysis on manifolds involve the study of geometric and topological properties of manifolds using analytical techniques. Key concepts include differential forms, integration on manifolds, Stokes' theorem, and the study of differential equations on manifolds.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to identify a specific concept or technique within global analysis or analysis on manifolds that can be used to formulate a challenging yet solvable question. One such concept is the application of Stokes' theorem, which relates the integral of a differential form over a manifold to the integral of its exterior derivative over the boundary of the manifold.\n\n## Step 4: Construct the problem\nLet's consider a specific manifold and a differential form. A common example is the unit sphere $S^2$ in $\\mathbb{R}^3$. We can formulate a problem involving the integration of a differential form over $S^2$ and applying Stokes' theorem.\n\n## Step 5: Specify the problem\nLet $\\omega = y \\, dx \\wedge dz$ be a 2-form on $\\mathbb{R}^3$. Consider the unit sphere $S^2 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 = 1 \\}$ oriented with the outward unit normal. Evaluate $\\int_{S^2} \\omega$.\n\n## Step 6: Provide the solution\nTo solve this, we can directly integrate $\\omega$ over $S^2$ or apply Stokes' theorem. Stokes' theorem states that $\\int_M d\\omega = \\int_{\\partial M} \\omega$, where $M$ is a manifold with boundary $\\partial M$. Here, we can consider $M = B^3 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 \\leq 1 \\}$, so $\\partial M = S^2$.\n\n## Step 7: Calculate $d\\omega$\n$d\\omega = d(y \\, dx \\wedge dz) = dy \\wedge dx \\wedge dz = -dx \\wedge dy \\wedge dz$ because $d(y) = dy$, $d(dx) = 0$, and $d(dz) = 0$. So, $d\\omega = -dx \\wedge dy \\wedge dz$.\n\n## Step 8: Apply Stokes' theorem\n$\\int_{S^2} \\omega = \\int_{B^3} d\\omega = \\int_{B^3} -dx \\wedge dy \\wedge dz = -\\int_{B^3} dV$, where $dV = dx \\wedge dy \\wedge dz$ is the volume form on $\\mathbb{R}^3$. Thus, $\\int_{S^2} \\omega = -\\text{Vol}(B^3)$.\n\n## Step 9: Calculate the volume of $B^3$\nThe volume of the unit ball $B^3$ is given by $\\frac{4}{3}\\pi(1)^3 = \\frac{4}{3}\\pi$.\n\n## Step 10: Conclude the solution\n$\\int_{S^2} \\omega = -\\frac{4}{3}\\pi$.\n\nThe final answer is: \n\nLet $\\omega = y \\, dx \\wedge dz$ be a 2-form on $\\mathbb{R}^3$. Consider the unit sphere $S^2 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 = 1 \\}$ oriented with the outward unit normal. Evaluate $\\int_{S^2} \\omega$.",
    "run_id": "41",
    "topic_slug": "global_analysis_on_manifolds",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe evaluate $\\displaystyle \\int_{S^2} \\omega$ where $\\omega = y\\,dx\\wedge dz$ and $S^2 = \\{(x,y,z)\\in\\mathbb{R}^3 : x^2+y^2+z^2=1\\}$ is oriented by the outward unit normal.\n\nLet $M = \\{(x,y,z)\\in\\mathbb{R}^3 : x^2+y^2+z^2 \\le 1\\}$ be the closed unit ball. Equip $M$ with the standard orientation of $\\mathbb{R}^3$ (i.e., the volume form $dx\\wedge dy\\wedge dz$ is positive). Then $\\partial M = S^2$ inherits the induced orientation, which coincides with the orientation given by the outward unit normal. By Stokes' theorem,\n\n$$\n\\int_{S^2} \\omega = \\int_{M} d\\omega.\n$$\n\nCompute the exterior derivative of $\\omega$:\n\n$$\nd\\omega = d(y\\,dx\\wedge dz) = dy\\wedge dx\\wedge dz = -dx\\wedge dy\\wedge dz,\n$$\n\nsince $dy\\wedge dx = -dx\\wedge dy$. Therefore,\n\n$$\n\\int_{M} d\\omega = \\int_{M} (-dx\\wedge dy\\wedge dz) = -\\int_{M} dV,\n$$\n\nwhere $dV = dx\\wedge dy\\wedge dz$ is the standard volume element. The integral $\\int_{M} dV$ is the volume of the unit ball, which is $\\frac{4}{3}\\pi$. Hence,\n\n$$\n\\int_{S^2} \\omega = -\\frac{4}{3}\\pi.\n$$\n\nThus, the value of the integral is $\\boxed{-\\dfrac{4}{3}\\pi}$.",
        "raw_answer": "**Solution**\n\nWe evaluate \\(\\displaystyle \\int_{S^2} \\omega\\) where \\(\\omega = y\\,dx\\wedge dz\\) and \\(S^2 = \\{(x,y,z)\\in\\mathbb{R}^3 : x^2+y^2+z^2=1\\}\\) is oriented by the outward unit normal.\n\nLet \\(M = \\{(x,y,z)\\in\\mathbb{R}^3 : x^2+y^2+z^2 \\le 1\\}\\) be the closed unit ball. Equip \\(M\\) with the standard orientation of \\(\\mathbb{R}^3\\) (i.e., the volume form \\(dx\\wedge dy\\wedge dz\\) is positive). Then \\(\\partial M = S^2\\) inherits the induced orientation, which coincides with the orientation given by the outward unit normal. By Stokes' theorem,\n\n\\[\n\\int_{S^2} \\omega = \\int_{M} d\\omega.\n\\]\n\nCompute the exterior derivative of \\(\\omega\\):\n\n\\[\nd\\omega = d(y\\,dx\\wedge dz) = dy\\wedge dx\\wedge dz = -dx\\wedge dy\\wedge dz,\n\\]\n\nsince \\(dy\\wedge dx = -dx\\wedge dy\\). Therefore,\n\n\\[\n\\int_{M} d\\omega = \\int_{M} (-dx\\wedge dy\\wedge dz) = -\\int_{M} dV,\n\\]\n\nwhere \\(dV = dx\\wedge dy\\wedge dz\\) is the standard volume element. The integral \\(\\int_{M} dV\\) is the volume of the unit ball, which is \\(\\frac{4}{3}\\pi\\). Hence,\n\n\\[\n\\int_{S^2} \\omega = -\\frac{4}{3}\\pi.\n\\]\n\nThus, the value of the integral is \\(\\boxed{-\\dfrac{4}{3}\\pi}\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $X$ and $Y$ be independent random variables with $X \\sim \\text{Exp}(\\lambda)$ and $Y \\sim \\text{Exp}(\\mu)$, where $\\lambda > 0$ and $\\mu > 0$ are the rate parameters. Define $Z = \\min(X, Y)$. Derive the probability density function (pdf) of $Z$ and compute $\\mathbb{E}[Z]$.",
    "run_id": "42",
    "topic_slug": "probability_theory_and_stochastic_processes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nLet $X \\sim \\text{Exp}(\\lambda)$ and $Y \\sim \\text{Exp}(\\mu)$ be independent, with rate parameters $\\lambda > 0$ and $\\mu > 0$.  \nFor $x \\ge 0$, the probability density function (pdf) and cumulative distribution function (cdf) of $X$ are  \n\n$$\nf_X(x) = \\lambda e^{-\\lambda x}, \\qquad F_X(x) = 1 - e^{-\\lambda x}.\n$$\n\nAnalogously, for $Y$:  \n\n$$\nf_Y(y) = \\mu e^{-\\mu y}, \\qquad F_Y(y) = 1 - e^{-\\mu y}, \\quad y \\ge 0.\n$$\n\nDefine $Z = \\min(X, Y)$. For any $z \\ge 0$, the survival function of $Z$ is  \n\n$$\nP(Z > z) = P(X > z,\\; Y > z) = P(X > z)\\,P(Y > z) \\quad (\\text{by independence}).\n$$\n\nSince $P(X > z) = e^{-\\lambda z}$ and $P(Y > z) = e^{-\\mu z}$, we obtain  \n\n$$\nP(Z > z) = e^{-\\lambda z} e^{-\\mu z} = e^{-(\\lambda+\\mu)z}.\n$$\n\nTherefore, the cdf of $Z$ for $z \\ge 0$ is  \n\n$$\nF_Z(z) = P(Z \\le z) = 1 - P(Z > z) = 1 - e^{-(\\lambda+\\mu)z},\n$$\n\nand $F_Z(z) = 0$ for $z < 0$.\n\nDifferentiating with respect to $z$ (for $z > 0$) gives the pdf:\n\n$$\nf_Z(z) = \\frac{d}{dz}F_Z(z) = (\\lambda+\\mu) e^{-(\\lambda+\\mu)z}, \\quad z > 0.\n$$\n\nWe may extend the definition to $z = 0$ by continuity, and note that $f_Z(z) = 0$ for $z < 0$.  \nThus $Z$ follows an exponential distribution with rate parameter $\\lambda+\\mu$.\n\nThe expected value of $Z$ is  \n\n$$\n\\mathbb{E}[Z] = \\int_{0}^{\\infty} z\\, f_Z(z)\\, dz = (\\lambda+\\mu) \\int_{0}^{\\infty} z\\, e^{-(\\lambda+\\mu)z}\\, dz.\n$$\n\nUsing the standard integral $\\int_{0}^{\\infty} z e^{-a z}\\, dz = \\frac{1}{a^2}$ for $a > 0$ (which follows from integration by parts or the Gamma function), with $a = \\lambda+\\mu$, we obtain  \n\n$$\n\\mathbb{E}[Z] = (\\lambda+\\mu) \\cdot \\frac{1}{(\\lambda+\\mu)^2} = \\frac{1}{\\lambda+\\mu}.\n$$\n\nAlternatively, since $Z \\sim \\text{Exp}(\\lambda+\\mu)$, its mean is indeed $1/(\\lambda+\\mu)$.\n\n**Final answer:**  \n\n$$\n\\boxed{f_Z(z) = (\\lambda+\\mu) e^{-(\\lambda+\\mu)z},\\; z \\ge 0;\\qquad \\mathbb{E}[Z] = \\frac{1}{\\lambda+\\mu}}.\n$$",
        "raw_answer": "**Solution**\n\nLet \\(X \\sim \\text{Exp}(\\lambda)\\) and \\(Y \\sim \\text{Exp}(\\mu)\\) be independent, with rate parameters \\(\\lambda > 0\\) and \\(\\mu > 0\\).  \nFor \\(x \\ge 0\\), the probability density function (pdf) and cumulative distribution function (cdf) of \\(X\\) are  \n\n\\[\nf_X(x) = \\lambda e^{-\\lambda x}, \\qquad F_X(x) = 1 - e^{-\\lambda x}.\n\\]\n\nAnalogously, for \\(Y\\):  \n\n\\[\nf_Y(y) = \\mu e^{-\\mu y}, \\qquad F_Y(y) = 1 - e^{-\\mu y}, \\quad y \\ge 0.\n\\]\n\nDefine \\(Z = \\min(X, Y)\\). For any \\(z \\ge 0\\), the survival function of \\(Z\\) is  \n\n\\[\nP(Z > z) = P(X > z,\\; Y > z) = P(X > z)\\,P(Y > z) \\quad (\\text{by independence}).\n\\]\n\nSince \\(P(X > z) = e^{-\\lambda z}\\) and \\(P(Y > z) = e^{-\\mu z}\\), we obtain  \n\n\\[\nP(Z > z) = e^{-\\lambda z} e^{-\\mu z} = e^{-(\\lambda+\\mu)z}.\n\\]\n\nTherefore, the cdf of \\(Z\\) for \\(z \\ge 0\\) is  \n\n\\[\nF_Z(z) = P(Z \\le z) = 1 - P(Z > z) = 1 - e^{-(\\lambda+\\mu)z},\n\\]\n\nand \\(F_Z(z) = 0\\) for \\(z < 0\\).\n\nDifferentiating with respect to \\(z\\) (for \\(z > 0\\)) gives the pdf:\n\n\\[\nf_Z(z) = \\frac{d}{dz}F_Z(z) = (\\lambda+\\mu) e^{-(\\lambda+\\mu)z}, \\quad z > 0.\n\\]\n\nWe may extend the definition to \\(z = 0\\) by continuity, and note that \\(f_Z(z) = 0\\) for \\(z < 0\\).  \nThus \\(Z\\) follows an exponential distribution with rate parameter \\(\\lambda+\\mu\\).\n\nThe expected value of \\(Z\\) is  \n\n\\[\n\\mathbb{E}[Z] = \\int_{0}^{\\infty} z\\, f_Z(z)\\, dz = (\\lambda+\\mu) \\int_{0}^{\\infty} z\\, e^{-(\\lambda+\\mu)z}\\, dz.\n\\]\n\nUsing the standard integral \\(\\int_{0}^{\\infty} z e^{-a z}\\, dz = \\frac{1}{a^2}\\) for \\(a > 0\\) (which follows from integration by parts or the Gamma function), with \\(a = \\lambda+\\mu\\), we obtain  \n\n\\[\n\\mathbb{E}[Z] = (\\lambda+\\mu) \\cdot \\frac{1}{(\\lambda+\\mu)^2} = \\frac{1}{\\lambda+\\mu}.\n\\]\n\nAlternatively, since \\(Z \\sim \\text{Exp}(\\lambda+\\mu)\\), its mean is indeed \\(1/(\\lambda+\\mu)\\).\n\n**Final answer:**  \n\n\\[\n\\boxed{f_Z(z) = (\\lambda+\\mu) e^{-(\\lambda+\\mu)z},\\; z \\ge 0;\\qquad \\mathbb{E}[Z] = \\frac{1}{\\lambda+\\mu}}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $X$ and $Y$ be independent random variables with $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ and $Y \\sim \\mathcal{N}(0, 1)$, where $\\mu \\in \\mathbb{R}$ and $\\sigma > 0$ are unknown parameters. Suppose we have a sample of $n$ independent observations from $X$ and $m$ independent observations from $Y$, denoted as $x_1, x_2, \\ldots, x_n$ and $y_1, y_2, \\ldots, y_m$, respectively. Derive the likelihood ratio test statistic for testing $H_0: \\mu = 0, \\sigma = 1$ against $H_1: \\mu \\neq 0 \\text{ or } \\sigma \\neq 1$.",
    "run_id": "43",
    "topic_slug": "statistics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The likelihood ratio test statistic is derived as follows.\n\n### 1. Joint likelihood\n\nGiven independent samples $x_1,\\dots,x_n$ from $\\mathcal{N}(\\mu,\\sigma^2)$ and $y_1,\\dots,y_m$ from $\\mathcal{N}(0,1)$, the joint likelihood for parameters $\\mu\\in\\mathbb{R},\\;\\sigma>0$ is\n\n$$\nL(\\mu,\\sigma) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}} \\;\\cdot\\; \\prod_{j=1}^m \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{y_j^2}{2}}.\n$$\n\n### 2. Likelihood under $H_0$\n\nUnder the null hypothesis $H_0:\\mu=0,\\;\\sigma=1$, both samples come from $\\mathcal{N}(0,1)$. Hence\n\n$$\nL_0 = (2\\pi)^{-\\frac{n+m}{2}} \\exp\\!\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2 - \\frac{1}{2}\\sum_{j=1}^m y_j^2\\right).\n$$\n\n### 3. Maximum likelihood under $H_1$\n\nUnder the alternative $H_1:\\mu\\neq0$ or $\\sigma\\neq1$, only the $X$ component depends on the unknown parameters. The $Y$ component is fixed as $\\mathcal{N}(0,1)$ and will cancel later. The log\u2011likelihood for the $X$ sample (ignoring constants) is\n\n$$\n\\ell(\\mu,\\sigma) = -n\\ln\\sigma - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (x_i-\\mu)^2.\n$$\n\nTaking derivatives and solving gives the MLEs:\n\n$$\n\\hat\\mu = \\bar x = \\frac{1}{n}\\sum_{i=1}^n x_i,\\qquad\n\\hat\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar x)^2.\n$$\n\nPlugging these into the likelihood yields the maximized value\n\n$$\nL_1^{\\max} = (2\\pi\\hat\\sigma^2)^{-n/2} e^{-n/2} \\;\\cdot\\; (2\\pi)^{-m/2} \\exp\\!\\left(-\\frac{1}{2}\\sum_{j=1}^m y_j^2\\right).\n$$\n\n### 4. Likelihood ratio\n\n$$\n\\lambda = \\frac{L_0}{L_1^{\\max}} = \\frac{ (2\\pi)^{-\\frac{n+m}{2}} \\exp\\!\\left(-\\frac{1}{2}\\sum x_i^2 - \\frac{1}{2}\\sum y_j^2\\right) }\n{ (2\\pi\\hat\\sigma^2)^{-n/2} e^{-n/2} \\; (2\\pi)^{-m/2} \\exp\\!\\left(-\\frac{1}{2}\\sum y_j^2\\right) }.\n$$\n\nThe factors involving the $Y$ sample and the constant $(2\\pi)^{-m/2}$ cancel, leaving\n\n$$\n\\lambda = ( \\hat\\sigma^2 )^{n/2} \\exp\\!\\left( -\\frac{1}{2}\\sum_{i=1}^n x_i^2 + \\frac{n}{2} \\right).\n$$\n\nUsing the identity $\\sum_{i=1}^n x_i^2 = n\\hat\\sigma^2 + n\\bar x^2$, we obtain\n\n$$\n\\lambda = ( \\hat\\sigma^2 )^{n/2} \\exp\\!\\left( \\frac{n}{2}\\bigl(1 - \\hat\\sigma^2 - \\bar x^2\\bigr) \\right).\n$$\n\n### 5. Test statistic\n\nThe likelihood ratio test rejects $H_0$ for small values of $\\lambda$, equivalently for large values of $-2\\ln\\lambda$. Computing:\n\n$$\n-2\\ln\\lambda = -2\\Bigl[ \\frac{n}{2}\\ln\\hat\\sigma^2 + \\frac{n}{2}\\bigl(1 - \\hat\\sigma^2 - \\bar x^2\\bigr) \\Bigr]\n= n\\bigl( \\hat\\sigma^2 + \\bar x^2 - 1 - \\ln\\hat\\sigma^2 \\bigr).\n$$\n\nAn alternative equivalent form is\n\n$$\n-2\\ln\\lambda = \\sum_{i=1}^n x_i^2 - n - 2n\\ln\\hat\\sigma.\n$$\n\n### 6. Conclusion\n\nThus the likelihood ratio test statistic is\n\n$$\n\\boxed{\\Lambda = n\\left( \\hat\\sigma^2 + \\bar x^2 - 1 - \\ln\\hat\\sigma^2 \\right)},\n$$\n\nwhere $\\bar x = \\frac{1}{n}\\sum_{i=1}^n x_i$ and $\\hat\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar x)^2$. Under $H_0$, as $n\\to\\infty$, $\\Lambda$ converges in distribution to a $\\chi^2_2$ random variable (Wilks\u2019 theorem). The test rejects $H_0$ at approximate level $\\alpha$ when $\\Lambda > \\chi^2_{2,1-\\alpha}$.\n\n**Remark:** The sample from $Y$ does not appear in the statistic because its distribution is the same under both hypotheses and cancels out.",
        "raw_answer": "The likelihood ratio test statistic is derived as follows.\n\n### 1. Joint likelihood\n\nGiven independent samples \\(x_1,\\dots,x_n\\) from \\(\\mathcal{N}(\\mu,\\sigma^2)\\) and \\(y_1,\\dots,y_m\\) from \\(\\mathcal{N}(0,1)\\), the joint likelihood for parameters \\(\\mu\\in\\mathbb{R},\\;\\sigma>0\\) is\n\n\\[\nL(\\mu,\\sigma) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}} \\;\\cdot\\; \\prod_{j=1}^m \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{y_j^2}{2}}.\n\\]\n\n### 2. Likelihood under \\(H_0\\)\n\nUnder the null hypothesis \\(H_0:\\mu=0,\\;\\sigma=1\\), both samples come from \\(\\mathcal{N}(0,1)\\). Hence\n\n\\[\nL_0 = (2\\pi)^{-\\frac{n+m}{2}} \\exp\\!\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2 - \\frac{1}{2}\\sum_{j=1}^m y_j^2\\right).\n\\]\n\n### 3. Maximum likelihood under \\(H_1\\)\n\nUnder the alternative \\(H_1:\\mu\\neq0\\) or \\(\\sigma\\neq1\\), only the \\(X\\) component depends on the unknown parameters. The \\(Y\\) component is fixed as \\(\\mathcal{N}(0,1)\\) and will cancel later. The log\u2011likelihood for the \\(X\\) sample (ignoring constants) is\n\n\\[\n\\ell(\\mu,\\sigma) = -n\\ln\\sigma - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (x_i-\\mu)^2.\n\\]\n\nTaking derivatives and solving gives the MLEs:\n\n\\[\n\\hat\\mu = \\bar x = \\frac{1}{n}\\sum_{i=1}^n x_i,\\qquad\n\\hat\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar x)^2.\n\\]\n\nPlugging these into the likelihood yields the maximized value\n\n\\[\nL_1^{\\max} = (2\\pi\\hat\\sigma^2)^{-n/2} e^{-n/2} \\;\\cdot\\; (2\\pi)^{-m/2} \\exp\\!\\left(-\\frac{1}{2}\\sum_{j=1}^m y_j^2\\right).\n\\]\n\n### 4. Likelihood ratio\n\n\\[\n\\lambda = \\frac{L_0}{L_1^{\\max}} = \\frac{ (2\\pi)^{-\\frac{n+m}{2}} \\exp\\!\\left(-\\frac{1}{2}\\sum x_i^2 - \\frac{1}{2}\\sum y_j^2\\right) }\n{ (2\\pi\\hat\\sigma^2)^{-n/2} e^{-n/2} \\; (2\\pi)^{-m/2} \\exp\\!\\left(-\\frac{1}{2}\\sum y_j^2\\right) }.\n\\]\n\nThe factors involving the \\(Y\\) sample and the constant \\((2\\pi)^{-m/2}\\) cancel, leaving\n\n\\[\n\\lambda = ( \\hat\\sigma^2 )^{n/2} \\exp\\!\\left( -\\frac{1}{2}\\sum_{i=1}^n x_i^2 + \\frac{n}{2} \\right).\n\\]\n\nUsing the identity \\(\\sum_{i=1}^n x_i^2 = n\\hat\\sigma^2 + n\\bar x^2\\), we obtain\n\n\\[\n\\lambda = ( \\hat\\sigma^2 )^{n/2} \\exp\\!\\left( \\frac{n}{2}\\bigl(1 - \\hat\\sigma^2 - \\bar x^2\\bigr) \\right).\n\\]\n\n### 5. Test statistic\n\nThe likelihood ratio test rejects \\(H_0\\) for small values of \\(\\lambda\\), equivalently for large values of \\(-2\\ln\\lambda\\). Computing:\n\n\\[\n-2\\ln\\lambda = -2\\Bigl[ \\frac{n}{2}\\ln\\hat\\sigma^2 + \\frac{n}{2}\\bigl(1 - \\hat\\sigma^2 - \\bar x^2\\bigr) \\Bigr]\n= n\\bigl( \\hat\\sigma^2 + \\bar x^2 - 1 - \\ln\\hat\\sigma^2 \\bigr).\n\\]\n\nAn alternative equivalent form is\n\n\\[\n-2\\ln\\lambda = \\sum_{i=1}^n x_i^2 - n - 2n\\ln\\hat\\sigma.\n\\]\n\n### 6. Conclusion\n\nThus the likelihood ratio test statistic is\n\n\\[\n\\boxed{\\Lambda = n\\left( \\hat\\sigma^2 + \\bar x^2 - 1 - \\ln\\hat\\sigma^2 \\right)},\n\\]\n\nwhere \\(\\bar x = \\frac{1}{n}\\sum_{i=1}^n x_i\\) and \\(\\hat\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar x)^2\\). Under \\(H_0\\), as \\(n\\to\\infty\\), \\(\\Lambda\\) converges in distribution to a \\(\\chi^2_2\\) random variable (Wilks\u2019 theorem). The test rejects \\(H_0\\) at approximate level \\(\\alpha\\) when \\(\\Lambda > \\chi^2_{2,1-\\alpha}\\).\n\n**Remark:** The sample from \\(Y\\) does not appear in the statistic because its distribution is the same under both hypotheses and cancels out.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Consider the function $f(x) = e^x - 2x - 1$. We want to approximate the root of $f(x)$ in the interval $[0,1]$ using the Newton-Raphson method. Starting with $x_0 = 1$, perform two iterations of the Newton-Raphson method to find $x_2$. Provide the exact value of $x_2$.",
    "run_id": "44",
    "topic_slug": "numerical_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe are given $f(x) = e^x - 2x - 1$ and its derivative $f'(x) = e^x - 2$.  \nThe Newton\u2013Raphson iteration formula is  \n\n$$\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}.\n$$\n\nWe start with $x_0 = 1$.\n\n---\n\n**First iteration ($x_1$):**\n\n$$\nf(1) = e^1 - 2\\cdot 1 - 1 = e - 3, \\qquad f'(1) = e - 2.\n$$\n\n$$\nx_1 = 1 - \\frac{e-3}{e-2} = \\frac{(e-2) - (e-3)}{e-2} = \\frac{1}{e-2}.\n$$\n\nThus  \n\n$$\nx_1 = \\frac{1}{e-2}.\n$$\n\n(Note that $e-2 > 0$, so the division is valid.)\n\n---\n\n**Second iteration ($x_2$):**\n\nLet $a = x_1 = \\dfrac{1}{e-2}$. Then  \n\n$$\nf(a) = e^{a} - 2a - 1, \\qquad f'(a) = e^{a} - 2.\n$$\n\n$$\nx_2 = a - \\frac{f(a)}{f'(a)} = a - \\frac{e^{a} - 2a - 1}{e^{a} - 2}.\n$$\n\nSimplify the expression:\n\n$$\nx_2 = \\frac{a(e^{a} - 2) - (e^{a} - 2a - 1)}{e^{a} - 2}\n   = \\frac{a e^{a} - 2a - e^{a} + 2a + 1}{e^{a} - 2}\n   = \\frac{e^{a}(a - 1) + 1}{e^{a} - 2}.\n$$\n\nNow substitute back $a = \\dfrac{1}{e-2}$:\n\n$$\nx_2 = \\frac{ e^{\\frac{1}{e-2}} \\left( \\frac{1}{e-2} - 1 \\right) + 1 }{ e^{\\frac{1}{e-2}} - 2 }.\n$$\n\nThe term in parentheses can be rewritten as  \n\n$$\n\\frac{1}{e-2} - 1 = \\frac{1 - (e-2)}{e-2} = \\frac{3 - e}{e-2},\n$$\n\ngiving an alternative exact form:\n\n$$\nx_2 = \\frac{ e^{\\frac{1}{e-2}} \\cdot \\frac{3-e}{e-2} + 1 }{ e^{\\frac{1}{e-2}} - 2 }.\n$$\n\nAll these expressions are equivalent and represent the **exact value** of $x_2$ after two Newton\u2013Raphson iterations.\n\n(We note that $e^{a} - 2 \\neq 0$ because $a \\approx 1.392 > \\ln 2$, so the iteration is well\u2011defined.)\n\n---\n\n**Final answer:**\n\n$$\n\\boxed{ x_2 = \\frac{ e^{\\frac{1}{e-2}} \\left( \\frac{1}{e-2} - 1 \\right) + 1 }{ e^{\\frac{1}{e-2}} - 2 } }\n$$",
        "raw_answer": "**Solution**\n\nWe are given \\(f(x) = e^x - 2x - 1\\) and its derivative \\(f'(x) = e^x - 2\\).  \nThe Newton\u2013Raphson iteration formula is  \n\n\\[\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}.\n\\]\n\nWe start with \\(x_0 = 1\\).\n\n---\n\n**First iteration (\\(x_1\\)):**\n\n\\[\nf(1) = e^1 - 2\\cdot 1 - 1 = e - 3, \\qquad f'(1) = e - 2.\n\\]\n\n\\[\nx_1 = 1 - \\frac{e-3}{e-2} = \\frac{(e-2) - (e-3)}{e-2} = \\frac{1}{e-2}.\n\\]\n\nThus  \n\n\\[\nx_1 = \\frac{1}{e-2}.\n\\]\n\n(Note that \\(e-2 > 0\\), so the division is valid.)\n\n---\n\n**Second iteration (\\(x_2\\)):**\n\nLet \\(a = x_1 = \\dfrac{1}{e-2}\\). Then  \n\n\\[\nf(a) = e^{a} - 2a - 1, \\qquad f'(a) = e^{a} - 2.\n\\]\n\n\\[\nx_2 = a - \\frac{f(a)}{f'(a)} = a - \\frac{e^{a} - 2a - 1}{e^{a} - 2}.\n\\]\n\nSimplify the expression:\n\n\\[\nx_2 = \\frac{a(e^{a} - 2) - (e^{a} - 2a - 1)}{e^{a} - 2}\n   = \\frac{a e^{a} - 2a - e^{a} + 2a + 1}{e^{a} - 2}\n   = \\frac{e^{a}(a - 1) + 1}{e^{a} - 2}.\n\\]\n\nNow substitute back \\(a = \\dfrac{1}{e-2}\\):\n\n\\[\nx_2 = \\frac{ e^{\\frac{1}{e-2}} \\left( \\frac{1}{e-2} - 1 \\right) + 1 }{ e^{\\frac{1}{e-2}} - 2 }.\n\\]\n\nThe term in parentheses can be rewritten as  \n\n\\[\n\\frac{1}{e-2} - 1 = \\frac{1 - (e-2)}{e-2} = \\frac{3 - e}{e-2},\n\\]\n\ngiving an alternative exact form:\n\n\\[\nx_2 = \\frac{ e^{\\frac{1}{e-2}} \\cdot \\frac{3-e}{e-2} + 1 }{ e^{\\frac{1}{e-2}} - 2 }.\n\\]\n\nAll these expressions are equivalent and represent the **exact value** of \\(x_2\\) after two Newton\u2013Raphson iterations.\n\n(We note that \\(e^{a} - 2 \\neq 0\\) because \\(a \\approx 1.392 > \\ln 2\\), so the iteration is well\u2011defined.)\n\n---\n\n**Final answer:**\n\n\\[\n\\boxed{ x_2 = \\frac{ e^{\\frac{1}{e-2}} \\left( \\frac{1}{e-2} - 1 \\right) + 1 }{ e^{\\frac{1}{e-2}} - 2 } }\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ],
    "outer_attempt": 1
  }
]