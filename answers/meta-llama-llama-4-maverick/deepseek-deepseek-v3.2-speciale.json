[
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $P(x)$ be the predicate \"$x$ is a prime number\" and $Q(x, y)$ be the predicate \"$y$ is the smallest prime greater than $x$.\" For all natural numbers $n$, consider the statement: \"For every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\" Formalize this statement using the given predicates $P(x)$ and $Q(x, y)$, and determine whether it is true or false. If true, provide a proof; if false, provide a counterexample.",
    "run_id": "1",
    "outer_attempt": 1,
    "topic_slug": "mathematical_logic_and_foundations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We formalize the statement and then determine its truth value.\n\n### Formalization\n\nLet the domain be the set of natural numbers $\\mathbb{N} = \\{1,2,3,\\dots\\}$.  \nGiven predicates:  \n- $P(x)$: \u201c$x$ is a prime number.\u201d  \n- $Q(x,y)$: \u201c$y$ is the smallest prime greater than $x$.\u201d\n\nThe English statement  \n\n> \u201cFor every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\u201d\n\ncan be expressed using both predicates as follows.  \nObserve that the existence of a prime between $n$ and $2n$ is equivalent to the smallest prime greater than $n$ being less than $2n$. Hence we write\n\n$$\n\\forall n \\in \\mathbb{N}\\; \\exists p \\in \\mathbb{N}\\; \\bigl( P(p) \\land Q(n, p) \\land p < 2n \\bigr).\n$$\n\n(We include $P(p)$ explicitly to use both predicates, even though $Q(n,p)$ already implies $P(p)$.)\n\n### Truth Value\n\nThe statement is **false**.\n\n#### Counterexample\n\nTake $n = 1$.  \nWe need a prime $p$ such that $1 < p < 2$.  \nThe only integers strictly between $1$ and $2$ do not exist. In particular, the smallest integer greater than $1$ is $2$, but $2$ is **not** less than $2$. Since every prime is an integer $\\ge 2$, no prime can satisfy $1 < p < 2$.  \n\nMore formally, suppose there existed a $p$ with $P(p)$, $Q(1,p)$, and $p < 2$.  \n$Q(1,p)$ means $p$ is the smallest prime greater than $1$, which forces $p = 2$.  \nBut then $p < 2$ becomes $2 < 2$, a contradiction.  \nThus $\\exists p\\,(P(p) \\land Q(1,p) \\land p<2)$ is false, and consequently the universal statement is false.\n\n### Remark\n\nThe statement becomes true when restricted to $n \\ge 2$; this is the well\u2011known Bertrand\u2019s postulate (Chebyshev\u2019s theorem). However, as quantified over all natural numbers (including $n=1$), it is false.",
        "raw_answer": "We formalize the statement and then determine its truth value.\n\n### Formalization\n\nLet the domain be the set of natural numbers $\\mathbb{N} = \\{1,2,3,\\dots\\}$.  \nGiven predicates:  \n- $P(x)$: \u201c$x$ is a prime number.\u201d  \n- $Q(x,y)$: \u201c$y$ is the smallest prime greater than $x$.\u201d\n\nThe English statement  \n\n> \u201cFor every natural number $n$, there exists a prime $p$ such that $n < p < 2n$.\u201d\n\ncan be expressed using both predicates as follows.  \nObserve that the existence of a prime between $n$ and $2n$ is equivalent to the smallest prime greater than $n$ being less than $2n$. Hence we write\n\n\\[\n\\forall n \\in \\mathbb{N}\\; \\exists p \\in \\mathbb{N}\\; \\bigl( P(p) \\land Q(n, p) \\land p < 2n \\bigr).\n\\]\n\n(We include $P(p)$ explicitly to use both predicates, even though $Q(n,p)$ already implies $P(p)$.)\n\n### Truth Value\n\nThe statement is **false**.\n\n#### Counterexample\n\nTake $n = 1$.  \nWe need a prime $p$ such that $1 < p < 2$.  \nThe only integers strictly between $1$ and $2$ do not exist. In particular, the smallest integer greater than $1$ is $2$, but $2$ is **not** less than $2$. Since every prime is an integer $\\ge 2$, no prime can satisfy $1 < p < 2$.  \n\nMore formally, suppose there existed a $p$ with $P(p)$, $Q(1,p)$, and $p < 2$.  \n$Q(1,p)$ means $p$ is the smallest prime greater than $1$, which forces $p = 2$.  \nBut then $p < 2$ becomes $2 < 2$, a contradiction.  \nThus $\\exists p\\,(P(p) \\land Q(1,p) \\land p<2)$ is false, and consequently the universal statement is false.\n\n### Remark\n\nThe statement becomes true when restricted to $n \\ge 2$; this is the well\u2011known Bertrand\u2019s postulate (Chebyshev\u2019s theorem). However, as quantified over all natural numbers (including $n=1$), it is false.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Combinatorics, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the domain\nThe domain specified is Combinatorics, which involves the study of counting, arranging, and optimizing objects in various ways. It encompasses topics such as permutations, combinations, graph theory, and more.\n\n## Step 3: Generate a problem\nTo create a challenging problem, let's consider a topic within Combinatorics that is both interesting and requires substantial reasoning. A potential topic is graph theory, specifically focusing on graph coloring or connectivity.\n\n## Step 4: Formulate the problem\nLet's formulate a problem: \"Prove that in any simple graph with $n$ vertices, if the graph is connected and has no cycles (i.e., it's a tree), then it has exactly $n-1$ edges.\"\n\n## Step 5: Verify the problem against the quality rubric\n- **Well-Posedness and Completeness**: The problem is self-contained, defines the necessary terms (simple graph, connected, no cycles, tree), and asks for a proof.\n- **Clarity**: The terms used are standard in graph theory, and the task is clear.\n- **Non-Triviality**: The problem requires understanding of graph theory and a proof involving induction or another suitable method, making it non-trivial.\n- **Solvability and Verification**: The statement is a known fact in graph theory and can be proven using established methods.\n\n## Step 6: Provide the solution\nTo solve this, we can use induction on $n$. For $n=1$, a tree has 0 edges, and $1-1=0$, so the statement holds. For $n>1$, assume the statement is true for all trees with fewer than $n$ vertices. A tree with $n$ vertices has at least one leaf (a vertex of degree 1); removing this leaf and its edge gives a tree with $n-1$ vertices. By the induction hypothesis, this smaller tree has $(n-1)-1 = n-2$ edges. Adding back the removed edge gives $n-2 + 1 = n-1$ edges, proving the statement for $n$.\n\n## Step 7: Format the output\nLet's format the problem and solution according to the required structure.\n\n\nLet $G$ be a simple graph with $n$ vertices. Prove that if $G$ is a tree (i.e., it is connected and has no cycles), then it has exactly $n-1$ edges.",
    "run_id": "2",
    "outer_attempt": 1,
    "topic_slug": "combinatorics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove the following theorem:\n\n**Theorem.** Let $G$ be a simple graph with $n$ vertices. If $G$ is a tree (i.e., connected and contains no cycles), then $G$ has exactly $n-1$ edges.\n\n*Proof.* We proceed by induction on $n$, the number of vertices.\n\n**Base case:** $n = 1$. A tree with one vertex has no edges. Indeed, any edge would require two distinct vertices. Hence the number of edges is $0 = 1 - 1$. The statement holds.\n\n**Inductive step:** Assume that every tree with fewer than $n$ vertices (for some $n \\ge 2$) has exactly one less edge than its number of vertices. Consider a tree $T$ with $n$ vertices.\n\nFirst, we claim that $T$ contains at least one leaf (a vertex of degree $1$). Since $T$ is connected and has at least two vertices, it contains a path of maximal length. Let $P = v_0 v_1 \\dots v_k$ be such a maximal path. The endpoints $v_0$ and $v_k$ cannot have degree $\\ge 2$ in $T$; otherwise, if (say) $v_0$ were adjacent to some vertex $w$ different from $v_1$, then either $w$ is not on $P$ (giving a longer path $w v_0 v_1 \\dots v_k$) or $w$ is on $P$ (creating a cycle). Both contradict maximality or acyclicity. Hence $\\deg(v_0) = 1$ and similarly $\\deg(v_k) = 1$. Thus $T$ has a leaf; pick one, call it $v$, and let $e$ be the unique edge incident with $v$, connecting $v$ to some vertex $u$.\n\nNow remove $v$ and the edge $e$ from $T$. Denote the resulting graph by $T' = T - v$. We show that $T'$ is still a tree.\n\n- **Acyclicity:** Removing a vertex cannot create a cycle, and $T$ itself has no cycles, so $T'$ is also acyclic.\n- **Connectedness:** Take any two vertices $x, y \\in V(T')$. In $T$ there is a unique simple path between $x$ and $y$. This path cannot contain the leaf $v$, because if it did, then $v$ would appear with degree $2$ on that path (one edge to enter, one to exit), contradicting $\\deg(v)=1$. Hence the path lies entirely in $T'$, so $x$ and $y$ are connected in $T'$. Thus $T'$ is connected.\n\nTherefore $T'$ is a tree with $n-1$ vertices. By the induction hypothesis, $T'$ has $(n-1)-1 = n-2$ edges.\n\nSince we removed exactly one edge $e$ from $T$ to obtain $T'$, the original tree $T$ has $(n-2) + 1 = n-1$ edges.\n\nThis completes the inductive step.\n\nBy the principle of mathematical induction, the theorem holds for all $n \\ge 1$. \u220e\n\n**Conclusion:** Every tree on $n$ vertices has exactly $n-1$ edges.",
        "raw_answer": "We prove the following theorem:\n\n**Theorem.** Let \\(G\\) be a simple graph with \\(n\\) vertices. If \\(G\\) is a tree (i.e., connected and contains no cycles), then \\(G\\) has exactly \\(n-1\\) edges.\n\n*Proof.* We proceed by induction on \\(n\\), the number of vertices.\n\n**Base case:** \\(n = 1\\). A tree with one vertex has no edges. Indeed, any edge would require two distinct vertices. Hence the number of edges is \\(0 = 1 - 1\\). The statement holds.\n\n**Inductive step:** Assume that every tree with fewer than \\(n\\) vertices (for some \\(n \\ge 2\\)) has exactly one less edge than its number of vertices. Consider a tree \\(T\\) with \\(n\\) vertices.\n\nFirst, we claim that \\(T\\) contains at least one leaf (a vertex of degree \\(1\\)). Since \\(T\\) is connected and has at least two vertices, it contains a path of maximal length. Let \\(P = v_0 v_1 \\dots v_k\\) be such a maximal path. The endpoints \\(v_0\\) and \\(v_k\\) cannot have degree \\(\\ge 2\\) in \\(T\\); otherwise, if (say) \\(v_0\\) were adjacent to some vertex \\(w\\) different from \\(v_1\\), then either \\(w\\) is not on \\(P\\) (giving a longer path \\(w v_0 v_1 \\dots v_k\\)) or \\(w\\) is on \\(P\\) (creating a cycle). Both contradict maximality or acyclicity. Hence \\(\\deg(v_0) = 1\\) and similarly \\(\\deg(v_k) = 1\\). Thus \\(T\\) has a leaf; pick one, call it \\(v\\), and let \\(e\\) be the unique edge incident with \\(v\\), connecting \\(v\\) to some vertex \\(u\\).\n\nNow remove \\(v\\) and the edge \\(e\\) from \\(T\\). Denote the resulting graph by \\(T' = T - v\\). We show that \\(T'\\) is still a tree.\n\n- **Acyclicity:** Removing a vertex cannot create a cycle, and \\(T\\) itself has no cycles, so \\(T'\\) is also acyclic.\n- **Connectedness:** Take any two vertices \\(x, y \\in V(T')\\). In \\(T\\) there is a unique simple path between \\(x\\) and \\(y\\). This path cannot contain the leaf \\(v\\), because if it did, then \\(v\\) would appear with degree \\(2\\) on that path (one edge to enter, one to exit), contradicting \\(\\deg(v)=1\\). Hence the path lies entirely in \\(T'\\), so \\(x\\) and \\(y\\) are connected in \\(T'\\). Thus \\(T'\\) is connected.\n\nTherefore \\(T'\\) is a tree with \\(n-1\\) vertices. By the induction hypothesis, \\(T'\\) has \\((n-1)-1 = n-2\\) edges.\n\nSince we removed exactly one edge \\(e\\) from \\(T\\) to obtain \\(T'\\), the original tree \\(T\\) has \\((n-2) + 1 = n-1\\) edges.\n\nThis completes the inductive step.\n\nBy the principle of mathematical induction, the theorem holds for all \\(n \\ge 1\\). \u220e\n\n**Conclusion:** Every tree on \\(n\\) vertices has exactly \\(n-1\\) edges.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the requirements for the problem.\nThe task is to generate a challenging but solvable mathematics problem in the domain of number theory, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within number theory.\nNumber theory encompasses various topics such as divisibility, prime numbers, congruences, and Diophantine equations. A challenging problem could involve proving a property related to prime numbers or solving a specific type of Diophantine equation.\n\n## Step 3: Formulate a problem that meets the criteria.\nLet's consider a problem involving the sum of divisors of a number and its relation to perfect numbers. A perfect number is a positive integer that is equal to the sum of its proper divisors, excluding the number itself.\n\n## Step 4: Specify the problem.\nConsider the following problem: \"Prove that if $n$ is an even perfect number, then $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.\"\n\n## Step 5: Provide the solution to the problem.\nTo solve this, we need to understand the definition of an even perfect number and its relation to Mersenne primes.\n\n## Step 6: Recall the definition and properties of even perfect numbers.\nAn even perfect number $n$ can be written as $n = 2^{k-1}(2^k - 1)$, where $2^k - 1$ is prime. This is known as the Euclid-Euler theorem.\n\n## Step 7: State the Euclid-Euler theorem.\nThe Euclid-Euler theorem states that every even perfect number is of the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime (i.e., $2^p - 1$ is prime).\n\n## Step 8: Provide the proof or reasoning for the given statement.\nThe proof involves two main parts: (1) showing that any number of the form $2^{p-1}(2^p - 1)$, where $2^p - 1$ is prime, is perfect, and (2) showing that every even perfect number is of this form.\n\n## Step 9: Outline the proof that $2^{p-1}(2^p - 1)$ is perfect when $2^p - 1$ is prime.\nLet $n = 2^{p-1}(2^p - 1)$. The sum of divisors of $n$, $\\sigma(n)$, is given by $\\sigma(n) = \\sigma(2^{p-1})\\sigma(2^p - 1)$. Since $2^p - 1$ is prime, $\\sigma(2^p - 1) = 2^p$. Also, $\\sigma(2^{p-1}) = 1 + 2 + 2^2 + \\cdots + 2^{p-1} = 2^p - 1$. Thus, $\\sigma(n) = (2^p - 1) \\cdot 2^p = 2 \\cdot 2^{p-1}(2^p - 1) = 2n$, proving $n$ is perfect.\n\n## Step 10: Outline the proof that every even perfect number is of the form $2^{p-1}(2^p - 1)$.\nLet $n$ be an even perfect number. Then $n = 2^k \\cdot m$, where $m$ is odd. Since $n$ is perfect, $\\sigma(n) = 2n$. Using the multiplicative property of $\\sigma$, we have $\\sigma(n) = \\sigma(2^k)\\sigma(m) = (2^{k+1} - 1)\\sigma(m)$. Thus, $(2^{k+1} - 1)\\sigma(m) = 2^{k+1}m$. This implies $2^{k+1} - 1$ divides $m$, so $m = (2^{k+1} - 1)d$ for some $d$. Substituting back gives $\\sigma(m) = 2^{k+1}d$. For $d = 1$, $m = 2^{k+1} - 1$ is prime, and $\\sigma(m) = m + 1 = 2^{k+1}$, which matches our requirement. For $d > 1$, it leads to a contradiction because $\\sigma(m) \\geq m + d > 2d$, unless $d = 1$ and $m$ is prime.\n\n## Step 11: Conclude the solution.\nThe given statement is a direct consequence of the Euclid-Euler theorem, which characterizes even perfect numbers.\n\nThe final answer is: \n\nProve that if $n$ is an even perfect number, then $n = 2^{p-1}(2^p - 1)$, where $2^p - 1$ is a Mersenne prime.",
    "run_id": "3",
    "outer_attempt": 1,
    "topic_slug": "number_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Proof.** Let $n$ be an even perfect number. By definition, $\\sigma(n) = 2n$, where $\\sigma$ denotes the sum of all positive divisors.\n\nSince $n$ is even, we can write $n = 2^{p-1} m$ with an integer $p \\ge 2$ and $m$ odd. (Factor out the highest power of $2$; if the exponent of $2$ is $a$, set $p = a+1$.)\n\nThe function $\\sigma$ is multiplicative for coprime integers. Because $2^{p-1}$ and $m$ are coprime ($m$ is odd), we have\n$$\n\\sigma(n) = \\sigma(2^{p-1})\\,\\sigma(m).\n$$\nFor a prime power, $\\sigma(2^{p-1}) = 1 + 2 + 2^2 + \\cdots + 2^{p-1} = 2^{p} - 1$. Hence,\n$$\n\\sigma(n) = (2^{p} - 1)\\,\\sigma(m).\n$$\nUsing the perfectness of $n$,\n$$\n(2^{p} - 1)\\,\\sigma(m) = 2n = 2\\cdot 2^{p-1}m = 2^{p}m. \\tag{1}\n$$\n\nObserve that $\\gcd(2^{p} - 1, 2^{p}) = 1$ (any common divisor divides their difference $2^{p} - (2^{p}-1) = 1$). Therefore, from (1) we deduce that $2^{p} - 1$ divides $m$. Write\n$$\nm = (2^{p} - 1)\\,t \\tag{2}\n$$\nfor some positive integer $t$.\n\nSubstituting (2) into (1) gives\n$$\n(2^{p} - 1)\\,\\sigma(m) = 2^{p}(2^{p} - 1)\\,t \\quad\\Longrightarrow\\quad \\sigma(m) = 2^{p}t.\n$$\nUsing (2) again, $m = (2^{p} - 1)t$, so\n$$\n\\sigma(m) = 2^{p}t = (2^{p} - 1)t + t = m + t. \\tag{3}\n$$\n\nThus $\\sigma(m) = m + t$. Note that $t$ divides $m$ by (2), and $1$ also divides $m$. We now examine the possible values of $t$.\n\n* **Case $t = 1$.** Then (3) becomes $\\sigma(m) = m + 1$. For an integer $m > 1$, the equality $\\sigma(m) = m + 1$ holds if and only if $m$ is prime. (If $m$ is prime, its only divisors are $1$ and $m$, so $\\sigma(m) = 1 + m$. Conversely, if $m$ is composite, it has a divisor $d$ with $1 < d < m$, so $\\sigma(m) \\ge 1 + d + m \\ge 1 + 2 + m = m + 3 > m + 1$.) Moreover, from (2) we have $m = 2^{p} - 1$, so $2^{p} - 1$ is prime.\n\n* **Case $t > 1$.** Since $p \\ge 2$, we have $2^{p} - 1 \\ge 3$. Then $t < (2^{p} - 1)t = m$, so $t$ is a proper divisor of $m$ distinct from $1$ and $m$. Consequently, $1$, $t$, and $m$ are three distinct positive divisors of $m$, implying\n$$\n\\sigma(m) \\ge 1 + t + m > m + t,\n$$\nwhich contradicts (3). Hence this case cannot occur.\n\nTherefore $t = 1$ is forced, and we have shown that $m = 2^{p} - 1$ is prime. Substituting back into the expression for $n$ yields\n$$\nn = 2^{p-1}(2^{p} - 1),\n$$\nwhere $2^{p} - 1$ is a Mersenne prime. This completes the proof. \u220e",
        "raw_answer": "**Proof.** Let \\(n\\) be an even perfect number. By definition, \\(\\sigma(n) = 2n\\), where \\(\\sigma\\) denotes the sum of all positive divisors.\n\nSince \\(n\\) is even, we can write \\(n = 2^{p-1} m\\) with an integer \\(p \\ge 2\\) and \\(m\\) odd. (Factor out the highest power of \\(2\\); if the exponent of \\(2\\) is \\(a\\), set \\(p = a+1\\).)\n\nThe function \\(\\sigma\\) is multiplicative for coprime integers. Because \\(2^{p-1}\\) and \\(m\\) are coprime (\\(m\\) is odd), we have\n\\[\n\\sigma(n) = \\sigma(2^{p-1})\\,\\sigma(m).\n\\]\nFor a prime power, \\(\\sigma(2^{p-1}) = 1 + 2 + 2^2 + \\cdots + 2^{p-1} = 2^{p} - 1\\). Hence,\n\\[\n\\sigma(n) = (2^{p} - 1)\\,\\sigma(m).\n\\]\nUsing the perfectness of \\(n\\),\n\\[\n(2^{p} - 1)\\,\\sigma(m) = 2n = 2\\cdot 2^{p-1}m = 2^{p}m. \\tag{1}\n\\]\n\nObserve that \\(\\gcd(2^{p} - 1, 2^{p}) = 1\\) (any common divisor divides their difference \\(2^{p} - (2^{p}-1) = 1\\)). Therefore, from (1) we deduce that \\(2^{p} - 1\\) divides \\(m\\). Write\n\\[\nm = (2^{p} - 1)\\,t \\tag{2}\n\\]\nfor some positive integer \\(t\\).\n\nSubstituting (2) into (1) gives\n\\[\n(2^{p} - 1)\\,\\sigma(m) = 2^{p}(2^{p} - 1)\\,t \\quad\\Longrightarrow\\quad \\sigma(m) = 2^{p}t.\n\\]\nUsing (2) again, \\(m = (2^{p} - 1)t\\), so\n\\[\n\\sigma(m) = 2^{p}t = (2^{p} - 1)t + t = m + t. \\tag{3}\n\\]\n\nThus \\(\\sigma(m) = m + t\\). Note that \\(t\\) divides \\(m\\) by (2), and \\(1\\) also divides \\(m\\). We now examine the possible values of \\(t\\).\n\n* **Case \\(t = 1\\).** Then (3) becomes \\(\\sigma(m) = m + 1\\). For an integer \\(m > 1\\), the equality \\(\\sigma(m) = m + 1\\) holds if and only if \\(m\\) is prime. (If \\(m\\) is prime, its only divisors are \\(1\\) and \\(m\\), so \\(\\sigma(m) = 1 + m\\). Conversely, if \\(m\\) is composite, it has a divisor \\(d\\) with \\(1 < d < m\\), so \\(\\sigma(m) \\ge 1 + d + m \\ge 1 + 2 + m = m + 3 > m + 1\\).) Moreover, from (2) we have \\(m = 2^{p} - 1\\), so \\(2^{p} - 1\\) is prime.\n\n* **Case \\(t > 1\\).** Since \\(p \\ge 2\\), we have \\(2^{p} - 1 \\ge 3\\). Then \\(t < (2^{p} - 1)t = m\\), so \\(t\\) is a proper divisor of \\(m\\) distinct from \\(1\\) and \\(m\\). Consequently, \\(1\\), \\(t\\), and \\(m\\) are three distinct positive divisors of \\(m\\), implying\n\\[\n\\sigma(m) \\ge 1 + t + m > m + t,\n\\]\nwhich contradicts (3). Hence this case cannot occur.\n\nTherefore \\(t = 1\\) is forced, and we have shown that \\(m = 2^{p} - 1\\) is prime. Substituting back into the expression for \\(n\\) yields\n\\[\nn = 2^{p-1}(2^{p} - 1),\n\\]\nwhere \\(2^{p} - 1\\) is a Mersenne prime. This completes the proof. \u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of \"Order, lattices, ordered algebraic structures\" along with a complete and verifiable solution.\n\n## Step 2: Identify the key elements of the problem domain\nThe domain involves concepts related to order, lattices, and ordered algebraic structures. This includes partially ordered sets (posets), lattices, Boolean algebras, and other related structures.\n\n## Step 3: Formulate a problem that fits the domain\nTo create a problem, we need to consider what aspects of \"Order, lattices, ordered algebraic structures\" can be explored. A potential problem could involve proving a property about a specific type of lattice or ordered structure.\n\n## Step 4: Generate a specific problem\nLet's consider a problem involving a Boolean algebra, which is a type of lattice. A Boolean algebra is a distributive lattice with the additional property that every element has a complement.\n\n## Step 5: State the problem\n\"Let $B$ be a Boolean algebra. Prove that for any elements $a, b \\in B$, the following identity holds: $a \\vee (a \\wedge b) = a$.\"\n\n## Step 6: Provide a solution to the problem\nTo prove $a \\vee (a \\wedge b) = a$, we can use the properties of a Boolean algebra, specifically the absorption laws.\n\n## Step 7: Write out the solution in detail\nFirst, recall that a Boolean algebra is a distributive lattice with complementation. The absorption laws state that for any $a, b$ in the Boolean algebra, $a \\vee (a \\wedge b) = a$ and $a \\wedge (a \\vee b) = a$. We need to prove the first absorption law.\n\n## Step 8: Apply the properties of a lattice to prove the identity\nBy definition of a lattice, $a \\wedge b \\leq a$ because $a$ is an upper bound of $a$ and $a \\wedge b$, and $a \\wedge b$ is the greatest lower bound of $a$ and $b$. Thus, $a \\vee (a \\wedge b) = a$ because $a \\vee x = a$ whenever $x \\leq a$.\n\n## Step 9: Formalize the solution\nGiven $a, b \\in B$, since $a \\wedge b \\leq a$, we have $a \\vee (a \\wedge b) = a$ due to the property that $x \\leq y$ implies $y \\vee x = y$. Thus, $a \\vee (a \\wedge b) = a$.\n\n## Step 10: Present the problem and solution in the required format\n\nLet $B$ be a Boolean algebra. Prove that for any elements $a, b \\in B$, the following identity holds: $a \\vee (a \\wedge b) = a$.",
    "run_id": "4",
    "outer_attempt": 1,
    "topic_slug": "order_lattices_and_ordered_algebraic_structures",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove the absorption law in a Boolean algebra using the order-theoretic definition of a lattice. Recall that a Boolean algebra is a distributive lattice with complements; in particular, it is a lattice. In any lattice, the meet $a \\wedge b$ is defined as the greatest lower bound of $\\{a,b\\}$, and the join $a \\vee b$ as the least upper bound. The partial order is given by $x \\le y$ iff $x \\vee y = y$ (equivalently $x \\wedge y = x$).\n\n**Proof.** Let $a, b \\in B$. By definition of meet as greatest lower bound, we have\n$$\na \\wedge b \\le a \\quad \\text{and} \\quad a \\wedge b \\le b.\n$$\nConsider the set $S = \\{a, a \\wedge b\\}$. We show that $a$ is the least upper bound of $S$.\n\n- **Upper bound:** Trivially $a \\le a$, and from above $a \\wedge b \\le a$. Hence $a$ is an upper bound of $S$.\n- **Least:** Let $u$ be any upper bound of $S$, i.e., $a \\le u$ and $a \\wedge b \\le u$. In particular, $a \\le u$. Thus $a$ is less than or equal to every upper bound of $S$.\n\nTherefore $a = \\sup S = a \\vee (a \\wedge b)$. \u220e\n\nThis completes the proof. The dual absorption law $a \\wedge (a \\vee b) = a$ follows by a symmetric argument.",
        "raw_answer": "We prove the absorption law in a Boolean algebra using the order-theoretic definition of a lattice. Recall that a Boolean algebra is a distributive lattice with complements; in particular, it is a lattice. In any lattice, the meet $a \\wedge b$ is defined as the greatest lower bound of $\\{a,b\\}$, and the join $a \\vee b$ as the least upper bound. The partial order is given by $x \\le y$ iff $x \\vee y = y$ (equivalently $x \\wedge y = x$).\n\n**Proof.** Let $a, b \\in B$. By definition of meet as greatest lower bound, we have\n\\[\na \\wedge b \\le a \\quad \\text{and} \\quad a \\wedge b \\le b.\n\\]\nConsider the set $S = \\{a, a \\wedge b\\}$. We show that $a$ is the least upper bound of $S$.\n\n- **Upper bound:** Trivially $a \\le a$, and from above $a \\wedge b \\le a$. Hence $a$ is an upper bound of $S$.\n- **Least:** Let $u$ be any upper bound of $S$, i.e., $a \\le u$ and $a \\wedge b \\le u$. In particular, $a \\le u$. Thus $a$ is less than or equal to every upper bound of $S$.\n\nTherefore $a = \\sup S = a \\vee (a \\wedge b)$. \u220e\n\nThis completes the proof. The dual absorption law $a \\wedge (a \\vee b) = a$ follows by a symmetric argument.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of general algebraic systems, along with a complete and verifiable solution.\n\n## Step 2: Identify the domain\nThe domain is general algebraic systems, which includes topics like groups, rings, fields, and other algebraic structures.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving a specific algebraic structure. A challenging problem could involve proving a property about a certain type of algebraic system.\n\n## Step 4: Create a specific problem\nConsider the following problem: \"Let $G$ be a finite group and $H$ be a subgroup of $G$. Suppose that $|G| = 2|H|$. Prove that $H$ is a normal subgroup of $G$.\"\n\n## Step 5: Verify the problem meets the quality rubric\n- **Well-Posedness and Completeness**: The problem is fully specified with $G$ being a finite group and $H$ a subgroup of $G$, and the condition $|G| = 2|H|$ is given.\n- **Clarity**: The terms are standard in group theory, and the task is clear.\n- **Non-Triviality**: The problem requires understanding of group theory and the concept of normal subgroups, making it non-trivial.\n- **Solvability and Verification**: The problem is solvable using established methods in group theory.\n\n## Step 6: Provide the solution\nTo prove that $H$ is a normal subgroup of $G$, we need to show that for any $g \\in G$ and $h \\in H$, $g^{-1}hg \\in H$.\n\n## Step 7: Break down the solution\nFirst, note that since $|G| = 2|H|$, $H$ has index 2 in $G$. This implies there are exactly two cosets of $H$ in $G$: $H$ itself and $G \\setminus H$.\n\n## Step 8: Analyze cosets\nFor any $g \\in G$, if $g \\in H$, then $gH = H$ and $Hg = H$, so $gH = Hg$. If $g \\notin H$, then $gH = G \\setminus H$ because there are only two cosets and $gH$ cannot be $H$. Similarly, $Hg = G \\setminus H$, so again $gH = Hg$.\n\n## Step 9: Conclude normality\nSince $gH = Hg$ for all $g \\in G$, $H$ is normal in $G$.\n\n## Step 10: Write the problem and solution in the required format\n\nLet $G$ be a finite group and $H$ be a subgroup of $G$. Suppose that $|G| = 2|H|$. Prove that $H$ is a normal subgroup of $G$.",
    "run_id": "5",
    "outer_attempt": 1,
    "topic_slug": "general_algebraic_systems",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked to prove that if $G$ is a finite group and $H$ is a subgroup with $|G| = 2|H|$, then $H$ is normal in $G$. The condition $|G| = 2|H|$ means the index $[G:H] = |G|/|H| = 2$, so $H$ has exactly two left cosets and two right cosets in $G$. The proof uses the standard fact that cosets partition the group.\n\n**Proof.**  \nSince $|G| = 2|H|$, we have $[G:H] = \\frac{|G|}{|H|} = 2$. Hence there are exactly two left cosets of $H$ in $G$ and exactly two right cosets.\n\nThe left cosets form a partition of $G$. One left coset is $H = eH$ (where $e$ is the identity). The other left coset must be the complement $G \\setminus H$, because it is disjoint from $H$ and together they cover $G$. Similarly, the right cosets also partition $G$; one is $H = He$, and the other is $G \\setminus H$.\n\nNow take an arbitrary $g \\in G$. We consider two cases.\n\n*Case 1:* $g \\in H$. Then $gH = H$ and $Hg = H$, so $gH = Hg$.\n\n*Case 2:* $g \\notin H$. Since $g \\notin H$, the left coset $gH$ is not equal to $H$. Because there are only two left cosets, $gH$ must be the other one, namely $G \\setminus H$. Likewise, $Hg$ is a right coset distinct from $H$ (because $g \\notin H$ implies $Hg \\neq H$), so $Hg$ must be the other right coset, which is also $G \\setminus H$. Therefore $gH = G \\setminus H = Hg$.\n\nIn both cases we obtain $gH = Hg$. Since $g$ was arbitrary, this equality holds for every $g \\in G$, which means $H$ is a normal subgroup of $G$. $\\square$\n\nThus we have shown that any subgroup of index $2$ in a finite group is normal. (The argument actually works for any group, finite or infinite, as long as the index is $2$.)",
        "raw_answer": "We are asked to prove that if $G$ is a finite group and $H$ is a subgroup with $|G| = 2|H|$, then $H$ is normal in $G$. The condition $|G| = 2|H|$ means the index $[G:H] = |G|/|H| = 2$, so $H$ has exactly two left cosets and two right cosets in $G$. The proof uses the standard fact that cosets partition the group.\n\n**Proof.**  \nSince $|G| = 2|H|$, we have $[G:H] = \\frac{|G|}{|H|} = 2$. Hence there are exactly two left cosets of $H$ in $G$ and exactly two right cosets.\n\nThe left cosets form a partition of $G$. One left coset is $H = eH$ (where $e$ is the identity). The other left coset must be the complement $G \\setminus H$, because it is disjoint from $H$ and together they cover $G$. Similarly, the right cosets also partition $G$; one is $H = He$, and the other is $G \\setminus H$.\n\nNow take an arbitrary $g \\in G$. We consider two cases.\n\n*Case 1:* $g \\in H$. Then $gH = H$ and $Hg = H$, so $gH = Hg$.\n\n*Case 2:* $g \\notin H$. Since $g \\notin H$, the left coset $gH$ is not equal to $H$. Because there are only two left cosets, $gH$ must be the other one, namely $G \\setminus H$. Likewise, $Hg$ is a right coset distinct from $H$ (because $g \\notin H$ implies $Hg \\neq H$), so $Hg$ must be the other right coset, which is also $G \\setminus H$. Therefore $gH = G \\setminus H = Hg$.\n\nIn both cases we obtain $gH = Hg$. Since $g$ was arbitrary, this equality holds for every $g \\in G$, which means $H$ is a normal subgroup of $G$. $\\square$\n\nThus we have shown that any subgroup of index $2$ in a finite group is normal. (The argument actually works for any group, finite or infinite, as long as the index is $2$.)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $F$ be a field and let $p(x) = x^3 + ax + b \\in F[x]$ be a cubic polynomial with distinct roots in some extension field of $F$. Suppose that the discriminant of $p(x)$ is a square in $F$. Prove that the Galois group of $p(x)$ over $F$ is isomorphic to $\\mathbb{Z}/3\\mathbb{Z}$ if and only if $p(x)$ is irreducible over $F$.",
    "run_id": "6",
    "outer_attempt": 1,
    "topic_slug": "field_theory_and_polynomials",
    "ill_posed_claim": {
      "verdict": "fail",
      "ill_posed": true,
      "issues": [
        "The irreducibility proof is invalid: treating u and v as constants when equating coefficients of 1, s, t is incorrect because u and v themselves depend on s and t.",
        "The argument that the Galois group is S3 is insufficiently justified: the Artin\u2013Schreier condition is not verified, and the claim that it fails because s and t are independent transcendentals is handwavy."
      ],
      "improvements": "Provide a correct irreducibility proof: assume a root exists in F2[s,t] (by Gauss's lemma), then write A \u2208 F2[s,t] satisfying A^3 + sA = t. View A as a polynomial in t with coefficients in F2[s]; compare degrees to obtain a contradiction. For the Galois group, show that the quadratic x^2 + \u03b1x + (\u03b1^2+s) has no solution in F(\u03b1) by deriving a contradiction from the minimal polynomial of \u03b1, or cite known results about the generic cubic in characteristic 2. Alternatively, give a more rigorous treatment of the Artin\u2013Schreier condition using the trace map."
    },
    "status": "ill-posed",
    "attempts": [
      {
        "round": 1,
        "answer": "The question is ill\u2011posed because it omits the necessary restriction on the characteristic of the field $F$.  In characteristic $2$ the statement fails, as shown by the following counterexample.\n\nLet $F = \\mathbb{F}_2(s,t)$ be the field of rational functions in two independent variables over the field with two elements.  Consider  \n$$\np(x) = x^3 + s x + t \\in F[x].\n$$\n\n* **Distinct roots:** The discriminant of $p$ is $\\Delta = -4s^3 -27 t^2$.  In characteristic $2$ we have $4 = 0$ and $27 = 1$, and $-1 = 1$, so $\\Delta = t^2$.  Since $t$ is transcendental, $\\Delta \\neq 0$; hence $p$ has distinct roots.\n* **Discriminant a square:** $\\Delta = t^2 = (t)^2$ is a square in $F$.\n* **Irreducibility:** Suppose $p$ had a root $r = u/v \\in F$ with $u, v \\in \\mathbb{F}_2[s,t]$ coprime.  Substituting gives  \n  $$\n  u^3 + s u v^2 + t v^3 = 0.\n  $$  \n  Treating the left\u2011hand side as a polynomial in $s$ and $t$, the coefficients of $1$, $s$, and $t$ must each vanish.  Thus $u^3 = 0$, $u v^2 = 0$, $v^3 = 0$, forcing $u = v = 0$, a contradiction.  Therefore $p$ is irreducible over $F$.\n* **Galois group:** Let $\\alpha$ be a root of $p$.  The extension $F(\\alpha)/F$ has degree $3$.  The other roots satisfy the quadratic  \n  $$\n  x^2 + \\alpha x + (\\alpha^2 + s) = 0.\n  $$  \n  Over a field of characteristic $2$, this quadratic splits over $F(\\alpha)$ iff the Artin\u2013Schreier equation  \n  $$\n  y^2 + y = 1 + \\frac{s}{\\alpha^2}\n  $$  \n  has a solution in $F(\\alpha)$.  Because $s$ and $t$ are independent transcendentals, this condition does **not** hold; consequently the quadratic remains irreducible over $F(\\alpha)$.  Hence the splitting field of $p$ has degree $6$, and the Galois group, being a transitive subgroup of $S_3$ of order $6$, is $S_3$, not $\\mathbb{Z}/3\\mathbb{Z}$.\n\nThus we have an irreducible cubic over $F$ satisfying the hypothesis (discriminant a square) whose Galois group is not $\\mathbb{Z}/3\\mathbb{Z}$, contradicting the claimed equivalence.\n\nThe underlying reason is that the standard step \u201cdiscriminant a square $\\Rightarrow$ Galois group $\\subseteq A_3$\u201d requires that $-1 \\neq 1$ in the field, i.e., $\\operatorname{char} F \\neq 2$.  In characteristic $2$ the sign of every permutation is $1$, so the discriminant condition imposes no restriction on the Galois group.\n\nTherefore the question is ill\u2011posed due to a missing constraint: it should explicitly assume $\\operatorname{char} F \\neq 2$ (or restrict to fields of characteristic different from $2$).  Without this assumption the statement is false, as demonstrated above.",
        "raw_answer": "The question is ill\u2011posed because it omits the necessary restriction on the characteristic of the field \\(F\\).  In characteristic \\(2\\) the statement fails, as shown by the following counterexample.\n\nLet \\(F = \\mathbb{F}_2(s,t)\\) be the field of rational functions in two independent variables over the field with two elements.  Consider  \n\\[\np(x) = x^3 + s x + t \\in F[x].\n\\]\n\n* **Distinct roots:** The discriminant of \\(p\\) is \\(\\Delta = -4s^3 -27 t^2\\).  In characteristic \\(2\\) we have \\(4 = 0\\) and \\(27 = 1\\), and \\(-1 = 1\\), so \\(\\Delta = t^2\\).  Since \\(t\\) is transcendental, \\(\\Delta \\neq 0\\); hence \\(p\\) has distinct roots.\n* **Discriminant a square:** \\(\\Delta = t^2 = (t)^2\\) is a square in \\(F\\).\n* **Irreducibility:** Suppose \\(p\\) had a root \\(r = u/v \\in F\\) with \\(u, v \\in \\mathbb{F}_2[s,t]\\) coprime.  Substituting gives  \n  \\[\n  u^3 + s u v^2 + t v^3 = 0.\n  \\]  \n  Treating the left\u2011hand side as a polynomial in \\(s\\) and \\(t\\), the coefficients of \\(1\\), \\(s\\), and \\(t\\) must each vanish.  Thus \\(u^3 = 0\\), \\(u v^2 = 0\\), \\(v^3 = 0\\), forcing \\(u = v = 0\\), a contradiction.  Therefore \\(p\\) is irreducible over \\(F\\).\n* **Galois group:** Let \\(\\alpha\\) be a root of \\(p\\).  The extension \\(F(\\alpha)/F\\) has degree \\(3\\).  The other roots satisfy the quadratic  \n  \\[\n  x^2 + \\alpha x + (\\alpha^2 + s) = 0.\n  \\]  \n  Over a field of characteristic \\(2\\), this quadratic splits over \\(F(\\alpha)\\) iff the Artin\u2013Schreier equation  \n  \\[\n  y^2 + y = 1 + \\frac{s}{\\alpha^2}\n  \\]  \n  has a solution in \\(F(\\alpha)\\).  Because \\(s\\) and \\(t\\) are independent transcendentals, this condition does **not** hold; consequently the quadratic remains irreducible over \\(F(\\alpha)\\).  Hence the splitting field of \\(p\\) has degree \\(6\\), and the Galois group, being a transitive subgroup of \\(S_3\\) of order \\(6\\), is \\(S_3\\), not \\(\\mathbb{Z}/3\\mathbb{Z}\\).\n\nThus we have an irreducible cubic over \\(F\\) satisfying the hypothesis (discriminant a square) whose Galois group is not \\(\\mathbb{Z}/3\\mathbb{Z}\\), contradicting the claimed equivalence.\n\nThe underlying reason is that the standard step \u201cdiscriminant a square \\(\\Rightarrow\\) Galois group \\(\\subseteq A_3\\)\u201d requires that \\(-1 \\neq 1\\) in the field, i.e., \\(\\operatorname{char} F \\neq 2\\).  In characteristic \\(2\\) the sign of every permutation is \\(1\\), so the discriminant condition imposes no restriction on the Galois group.\n\nTherefore the question is ill\u2011posed due to a missing constraint: it should explicitly assume \\(\\operatorname{char} F \\neq 2\\) (or restrict to fields of characteristic different from \\(2\\)).  Without this assumption the statement is false, as demonstrated above.",
        "evaluation": {
          "verdict": "fail",
          "ill_posed": true,
          "issues": [
            "The irreducibility proof is invalid: treating u and v as constants when equating coefficients of 1, s, t is incorrect because u and v themselves depend on s and t.",
            "The argument that the Galois group is S3 is insufficiently justified: the Artin\u2013Schreier condition is not verified, and the claim that it fails because s and t are independent transcendentals is handwavy."
          ],
          "improvements": "Provide a correct irreducibility proof: assume a root exists in F2[s,t] (by Gauss's lemma), then write A \u2208 F2[s,t] satisfying A^3 + sA = t. View A as a polynomial in t with coefficients in F2[s]; compare degrees to obtain a contradiction. For the Galois group, show that the quadratic x^2 + \u03b1x + (\u03b1^2+s) has no solution in F(\u03b1) by deriving a contradiction from the minimal polynomial of \u03b1, or cite known results about the generic cubic in characteristic 2. Alternatively, give a more rigorous treatment of the Artin\u2013Schreier condition using the trace map."
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of commutative algebra, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic in commutative algebra\nCommutative algebra involves the study of commutative rings and their ideals, modules, and algebras. A challenging problem could involve understanding the properties of ideals, quotient rings, or the behavior of polynomials over certain rings.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the properties of ideals in a polynomial ring. Specifically, we can examine the ideal generated by a set of polynomials and ask questions about its properties, such as whether it is prime or maximal.\n\n## Step 4: Construct the problem\nConsider the polynomial ring $\\mathbb{Q}[x, y]$ and the ideal $I = (x^2 + y^2, xy)$. We can ask: Is the ideal $I$ prime? To make it more challenging and ensure it's well-posed, we can ask to determine whether $I$ is radical, i.e., whether it is equal to its radical $\\sqrt{I}$.\n\n## Step 5: Write down the problem statement\nLet $I = (x^2 + y^2, xy)$ be an ideal in $\\mathbb{Q}[x, y]$. Determine whether $I = \\sqrt{I}$, where $\\sqrt{I} = \\{f \\in \\mathbb{Q}[x, y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N}\\}$.\n\n## Step 6: Provide the solution\nTo determine if $I = \\sqrt{I}$, we first need to understand what $\\sqrt{I}$ is. An element $f \\in \\mathbb{Q}[x, y]$ is in $\\sqrt{I}$ if $f^n \\in I$ for some $n$. We need to check if there are elements in $\\sqrt{I}$ that are not in $I$.\n\n## Step 7: Analyze the ideal $I$\nTo check if $I = \\sqrt{I}$, let's first examine the quotient ring $\\mathbb{Q}[x, y]/I$. The ideal $I$ contains $x^2 + y^2$ and $xy$, which implies that $x^2 + y^2$ and $xy$ are zero in $\\mathbb{Q}[x, y]/I$. We can simplify this by observing that $x^2y + y^3 = 0$ and $x^2y = 0$ in $\\mathbb{Q}[x, y]/I$, implying $y^3 = 0$ in $\\mathbb{Q}[x, y]/I$. Similarly, $x^3 = 0$.\n\n## Step 8: Check if $I$ is radical\nSince $x^3 = 0$ and $y^3 = 0$ in $\\mathbb{Q}[x, y]/I$, it follows that $x, y \\in \\sqrt{I}$ because $x^3, y^3 \\in I$. We need to verify if $x$ and $y$ are in $I$. If not, then $I \\neq \\sqrt{I}$.\n\n## Step 9: Verify if $x$ and $y$ are in $I$\nTo check if $x \\in I$, we need to see if there exist $f, g \\in \\mathbb{Q}[x, y]$ such that $x = f(x^2 + y^2) + g(xy)$. This simplifies to checking if $x$ can be expressed as a combination of $x^2 + y^2$ and $xy$, which is not possible because any element in $I$ is of degree at least 2.\n\n## Step 10: Conclude on $I = \\sqrt{I}$\nSince $x, y \\in \\sqrt{I}$ but $x, y \\notin I$, it follows that $I \\neq \\sqrt{I}$. Thus, $I$ is not radical.\n\nThe final answer is: \n\nLet $I = (x^2 + y^2, xy)$ be an ideal in $\\mathbb{Q}[x, y]$. Determine whether $I = \\sqrt{I}$, where $\\sqrt{I} = \\{f \\in \\mathbb{Q}[x, y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N}\\}$.",
    "run_id": "7",
    "outer_attempt": 1,
    "topic_slug": "commutative_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution:**\n\nLet $I = (x^2 + y^2,\\; xy)$ be an ideal in the polynomial ring $\\mathbb{Q}[x,y]$. We claim that $I \\neq \\sqrt{I}$, where $\\sqrt{I} = \\{ f \\in \\mathbb{Q}[x,y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N} \\}$.\n\n---\n\n### 1. $x$ and $y$ belong to $\\sqrt{I}$\n\nFirst, we show that $x \\in \\sqrt{I}$. Compute\n$$\nx^3 = x \\cdot x^2 = x(x^2 + y^2) - x y^2.\n$$\nSince $x^2 + y^2 \\in I$, the product $x(x^2 + y^2)$ lies in $I$ (because $I$ is an ideal).  \nMoreover, $xy \\in I$, so multiplying by $y$ gives $(xy)y = x y^2 \\in I$.  \nThus both summands on the right\u2011hand side are elements of $I$, and therefore $x^3 \\in I$. By definition of the radical, $x \\in \\sqrt{I}$.\n\nA completely analogous computation yields $y \\in \\sqrt{I}$:\n$$\ny^3 = y \\cdot y^2 = y(x^2 + y^2) - y x^2,\n$$\nwith $y x^2 = (xy)x \\in I$, so $y^3 \\in I$ and hence $y \\in \\sqrt{I}$.\n\n---\n\n### 2. $x$ is **not** an element of $I$\n\nThe ideal $I$ is *homogeneous*: it is generated by the homogeneous polynomials $x^2 + y^2$ and $xy$, both of degree $2$.  \nWe prove that no nonzero homogeneous polynomial of degree $1$ can belong to $I$.  \n\nSuppose, for contradiction, that $x \\in I$. Then there exist polynomials $A, B \\in \\mathbb{Q}[x,y]$ such that\n$$\nx = A\\,(x^2 + y^2) + B\\,(xy). \\tag{1}\n$$\n\nWrite $A$ and $B$ as sums of their homogeneous components:\n$$\nA = \\sum_{i \\ge 0} A_i, \\qquad B = \\sum_{j \\ge 0} B_j,\n$$\nwhere $A_i$ (resp. $B_j$) is homogeneous of degree $i$ (resp. $j$), and only finitely many are nonzero.  \nThen\n$$\nA\\,(x^2 + y^2) = \\sum_i A_i (x^2 + y^2), \\qquad B\\,(xy) = \\sum_j B_j (xy).\n$$\nEach term $A_i (x^2 + y^2)$ is homogeneous of degree $i+2$, and each term $B_j (xy)$ is homogeneous of degree $j+2$.  \nConsequently, the right\u2011hand side of (1) is a sum of homogeneous polynomials all of degree **at least** $2$ (since $i, j \\ge 0$).  \nThe left\u2011hand side, $x$, is homogeneous of degree $1$.  \nFor the equality to hold, all terms on the right must cancel to yield a polynomial of degree $1$, but cancellation can only affect terms of the same degree; it cannot produce a term of degree lower than the smallest degree present. Because every term on the right has degree $\\ge 2$, the sum must either be zero or have degree $\\ge 2$. It cannot equal the nonzero degree\u2011$1$ polynomial $x$. This contradiction shows that $x \\notin I$.\n\n(One may also argue more succinctly: in a homogeneous ideal generated in degree $2$, the smallest possible degree of a nonzero homogeneous element is $2$. Since $x$ is homogeneous of degree $1$ and nonzero, it cannot lie in $I$.)\n\n---\n\n### 3. Conclusion\n\nWe have shown that $x \\in \\sqrt{I}$ but $x \\notin I$. Therefore $I$ is **not** equal to its radical:\n$$\n\\boxed{I \\neq \\sqrt{I}}.\n$$",
        "raw_answer": "**Solution:**\n\nLet $I = (x^2 + y^2,\\; xy)$ be an ideal in the polynomial ring $\\mathbb{Q}[x,y]$. We claim that $I \\neq \\sqrt{I}$, where $\\sqrt{I} = \\{ f \\in \\mathbb{Q}[x,y] \\mid f^n \\in I \\text{ for some } n \\in \\mathbb{N} \\}$.\n\n---\n\n### 1. $x$ and $y$ belong to $\\sqrt{I}$\n\nFirst, we show that $x \\in \\sqrt{I}$. Compute\n\\[\nx^3 = x \\cdot x^2 = x(x^2 + y^2) - x y^2.\n\\]\nSince $x^2 + y^2 \\in I$, the product $x(x^2 + y^2)$ lies in $I$ (because $I$ is an ideal).  \nMoreover, $xy \\in I$, so multiplying by $y$ gives $(xy)y = x y^2 \\in I$.  \nThus both summands on the right\u2011hand side are elements of $I$, and therefore $x^3 \\in I$. By definition of the radical, $x \\in \\sqrt{I}$.\n\nA completely analogous computation yields $y \\in \\sqrt{I}$:\n\\[\ny^3 = y \\cdot y^2 = y(x^2 + y^2) - y x^2,\n\\]\nwith $y x^2 = (xy)x \\in I$, so $y^3 \\in I$ and hence $y \\in \\sqrt{I}$.\n\n---\n\n### 2. $x$ is **not** an element of $I$\n\nThe ideal $I$ is *homogeneous*: it is generated by the homogeneous polynomials $x^2 + y^2$ and $xy$, both of degree $2$.  \nWe prove that no nonzero homogeneous polynomial of degree $1$ can belong to $I$.  \n\nSuppose, for contradiction, that $x \\in I$. Then there exist polynomials $A, B \\in \\mathbb{Q}[x,y]$ such that\n\\[\nx = A\\,(x^2 + y^2) + B\\,(xy). \\tag{1}\n\\]\n\nWrite $A$ and $B$ as sums of their homogeneous components:\n\\[\nA = \\sum_{i \\ge 0} A_i, \\qquad B = \\sum_{j \\ge 0} B_j,\n\\]\nwhere $A_i$ (resp. $B_j$) is homogeneous of degree $i$ (resp. $j$), and only finitely many are nonzero.  \nThen\n\\[\nA\\,(x^2 + y^2) = \\sum_i A_i (x^2 + y^2), \\qquad B\\,(xy) = \\sum_j B_j (xy).\n\\]\nEach term $A_i (x^2 + y^2)$ is homogeneous of degree $i+2$, and each term $B_j (xy)$ is homogeneous of degree $j+2$.  \nConsequently, the right\u2011hand side of (1) is a sum of homogeneous polynomials all of degree **at least** $2$ (since $i, j \\ge 0$).  \nThe left\u2011hand side, $x$, is homogeneous of degree $1$.  \nFor the equality to hold, all terms on the right must cancel to yield a polynomial of degree $1$, but cancellation can only affect terms of the same degree; it cannot produce a term of degree lower than the smallest degree present. Because every term on the right has degree $\\ge 2$, the sum must either be zero or have degree $\\ge 2$. It cannot equal the nonzero degree\u2011$1$ polynomial $x$. This contradiction shows that $x \\notin I$.\n\n(One may also argue more succinctly: in a homogeneous ideal generated in degree $2$, the smallest possible degree of a nonzero homogeneous element is $2$. Since $x$ is homogeneous of degree $1$ and nonzero, it cannot lie in $I$.)\n\n---\n\n### 3. Conclusion\n\nWe have shown that $x \\in \\sqrt{I}$ but $x \\notin I$. Therefore $I$ is **not** equal to its radical:\n\\[\n\\boxed{I \\neq \\sqrt{I}}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of algebraic geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within algebraic geometry\nAlgebraic geometry is a broad field that involves the study of geometric objects, such as varieties and schemes, using tools from abstract algebra. A suitable topic could involve the study of curves, surfaces, or higher-dimensional varieties, and their properties.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the intersection of curves on a surface. A classic result in algebraic geometry is B\u00e9zout's theorem, which describes the intersection of two curves on a projective plane. We can formulate a problem related to this.\n\n## Step 4: State the problem\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.\n\n## Step 5: Provide the solution\nTo find the intersection points, we need to solve the system of equations given by $f(x,y,z) = 0$ and $g(x,y,z) = 0$. This means we have to solve $x^2 + y^2 - z^2 = 0$ and $xy - z^2 = 0$ simultaneously.\n\n## Step 6: Solve the system of equations\nFirst, from $xy - z^2 = 0$, we can express $z^2 = xy$. Substituting $z^2$ into the first equation gives $x^2 + y^2 - xy = 0$. This is a homogeneous equation in $x$ and $y$, which can be solved by considering it as a quadratic form.\n\n## Step 7: Analyze the quadratic form\nThe equation $x^2 - xy + y^2 = 0$ can be analyzed by finding its roots. This is equivalent to solving $x^2 - xy + y^2 = 0$ for $x$ in terms of $y$ (or vice versa), treating it as a quadratic equation.\n\n## Step 8: Solve for $x$ in terms of $y$\nUsing the quadratic formula, $x = \\frac{y \\pm \\sqrt{y^2 - 4y^2}}{2} = \\frac{y \\pm \\sqrt{-3y^2}}{2}$. For $y \\neq 0$, this simplifies to $x = \\frac{y(1 \\pm i\\sqrt{3})}{2}$. Thus, $x = y\\omega$ or $x = y\\omega^2$, where $\\omega$ is a primitive third root of unity.\n\n## Step 9: Determine the intersection points\nFor $x = y\\omega$ and $x = y\\omega^2$, substituting back into $xy = z^2$ gives $y^2\\omega = z^2$ and $y^2\\omega^2 = z^2$, respectively. This implies $z = \\pm y\\sqrt{\\omega}$ and $z = \\pm y\\sqrt{\\omega^2}$. However, we must consider the projective nature and the fact that we're working with homogeneous coordinates.\n\n## Step 10: Count the intersection points with multiplicity\nSince $\\omega$ and $\\omega^2$ are not real, and we're working over $\\mathbb{C}$, we need to consider the solutions in $\\mathbb{P}^2(\\mathbb{C})$. The solutions are given by the pairs $(x:y:z)$ satisfying both equations. We need to check if there are any solutions where $y = 0$, which would imply $x = 0$ and thus $z = 0$, but $(0,0,0)$ is not a valid point in $\\mathbb{P}^2$.\n\n## Step 11: Apply B\u00e9zout's theorem for a simpler solution\nB\u00e9zout's theorem states that two curves of degrees $d_1$ and $d_2$ intersect in $d_1d_2$ points, counted with multiplicity, if they have no common components. Here, $C_1$ and $C_2$ are both of degree 2, so they should intersect in $2 \\times 2 = 4$ points.\n\nThe final answer is: \n\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.",
    "run_id": "8",
    "outer_attempt": 1,
    "topic_slug": "algebraic_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution.**\n\nWe work over the complex numbers $\\mathbb{C}$ (or any algebraically closed field) to apply B\u00e9zout's theorem and capture all intersection points. The curves are in the projective plane $\\mathbb{P}^2$.\n\n---\n\n### 1. Degrees and common components\n\n$C_1$ is defined by the homogeneous polynomial $f(x,y,z)=x^2+y^2-z^2$ of degree $2$.  \n$C_2$ is defined by $g(x,y,z)=xy-z^2$, also of degree $2$.  \n\nBoth polynomials are irreducible (they are non\u2011degenerate quadratic forms) and are not scalar multiples of each other. Hence $C_1$ and $C_2$ share no common component.\n\n---\n\n### 2. B\u00e9zout\u2019s theorem\n\nFor two projective plane curves with no common component, the total intersection number \u2013 the sum of intersection multiplicities at all points \u2013 equals the product of their degrees. Therefore\n\n$$\n\\sum_{P\\in C_1\\cap C_2} I(P, C_1\\cap C_2) = 2\\cdot 2 = 4.\n$$\n\n---\n\n### 3. Explicit intersection points\n\nWe solve the system\n\n$$\n\\begin{cases}\nx^2 + y^2 - z^2 = 0,\\$$2mm]\nxy - z^2 = 0.\n\\end{cases}\n$$\n\nFrom the second equation, $z^2 = xy$. Substituting into the first gives\n\n$$\nx^2 + y^2 - xy = 0 \\quad\\Longrightarrow\\quad x^2 - xy + y^2 = 0. \\tag{1}\n$$\n\nEquation (1) is homogeneous.  \n\n*If $y = 0$*, then (1) forces $x = 0$, and then $z^2 = 0$ from the second equation, yielding $(0,0,0)$ which is not a point in $\\mathbb{P}^2$. Hence $y \\neq 0$. Similarly, $x = 0$ would imply $y = 0$, so $x \\neq 0$ as well.  \n\nBecause $y \\neq 0$, we may scale the homogeneous coordinates so that $y = 1$. Then (1) becomes\n\n$$\nx^2 - x + 1 = 0.\n$$\n\nIts solutions are\n\n$$\nx = \\frac{1 \\pm i\\sqrt{3}}{2}.\n$$\n\nSet $\\zeta = \\frac{1 + i\\sqrt{3}}{2} = e^{i\\pi/3}$; then the other root is $\\zeta^{-1} = \\frac{1 - i\\sqrt{3}}{2} = e^{-i\\pi/3}$.\n\nFor each value of $x$ we have $z^2 = xy = x$ (since $y=1$). Thus $z$ is a square root of $x$. Because $x \\neq 0$, there are two distinct square roots for each $x$, differing by a sign. This yields four points in $\\mathbb{P}^2$ (with the representative $y=1$):\n\n$$\n\\begin{aligned}\nP_1 &= (\\zeta,\\; 1,\\; \\sqrt{\\zeta}), &\nP_2 &= (\\zeta,\\; 1,\\; -\\sqrt{\\zeta}), \\$$1mm]\nP_3 &= (\\zeta^{-1},\\; 1,\\; \\sqrt{\\zeta^{-1}}), &\nP_4 &= (\\zeta^{-1},\\; 1,\\; -\\sqrt{\\zeta^{-1}}),\n\\end{aligned}\n$$\n\nwhere $\\sqrt{\\zeta}$ denotes a fixed choice of square root; the opposite sign gives the other point.\n\nThese four points are distinct:\n- The ratios $x:y$ are $\\zeta$ for $P_1,P_2$ and $\\zeta^{-1}$ for $P_3,P_4$, and $\\zeta \\neq \\zeta^{-1}$ because $\\zeta \\neq \\pm 1$.\n- For a fixed ratio, the two points differ only in the sign of the $z$-coordinate. No non\u2011zero scalar $\\lambda$ can identify them because that would require $\\lambda = 1$ from the first two coordinates and then force $z = -z$, i.e., $z=0$, which is impossible since $z^2 = \\zeta \\neq 0$.\n\nHence $C_1 \\cap C_2$ consists of exactly four distinct points.\n\n---\n\n### 4. Intersection multiplicities\n\nBecause we have found four distinct intersection points and B\u00e9zout\u2019s theorem guarantees that the sum of multiplicities is $4$, each intersection multiplicity must be exactly $1$. (One may also verify transversality directly: both curves are smooth at these points, and their gradient vectors $\\nabla f = (2x,2y,-2z)$ and $\\nabla g = (y,x,-2z)$ are linearly independent at each point, so the intersection is transverse.)\n\n---\n\n### 5. Conclusion\n\nThe number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity, is\n\n$$\n\\boxed{4}.\n$$",
        "raw_answer": "**Solution.**\n\nWe work over the complex numbers \\(\\mathbb{C}\\) (or any algebraically closed field) to apply B\u00e9zout's theorem and capture all intersection points. The curves are in the projective plane \\(\\mathbb{P}^2\\).\n\n---\n\n### 1. Degrees and common components\n\n\\(C_1\\) is defined by the homogeneous polynomial \\(f(x,y,z)=x^2+y^2-z^2\\) of degree \\(2\\).  \n\\(C_2\\) is defined by \\(g(x,y,z)=xy-z^2\\), also of degree \\(2\\).  \n\nBoth polynomials are irreducible (they are non\u2011degenerate quadratic forms) and are not scalar multiples of each other. Hence \\(C_1\\) and \\(C_2\\) share no common component.\n\n---\n\n### 2. B\u00e9zout\u2019s theorem\n\nFor two projective plane curves with no common component, the total intersection number \u2013 the sum of intersection multiplicities at all points \u2013 equals the product of their degrees. Therefore\n\n\\[\n\\sum_{P\\in C_1\\cap C_2} I(P, C_1\\cap C_2) = 2\\cdot 2 = 4.\n\\]\n\n---\n\n### 3. Explicit intersection points\n\nWe solve the system\n\n\\[\n\\begin{cases}\nx^2 + y^2 - z^2 = 0,\\\\[2mm]\nxy - z^2 = 0.\n\\end{cases}\n\\]\n\nFrom the second equation, \\(z^2 = xy\\). Substituting into the first gives\n\n\\[\nx^2 + y^2 - xy = 0 \\quad\\Longrightarrow\\quad x^2 - xy + y^2 = 0. \\tag{1}\n\\]\n\nEquation (1) is homogeneous.  \n\n*If \\(y = 0\\)*, then (1) forces \\(x = 0\\), and then \\(z^2 = 0\\) from the second equation, yielding \\((0,0,0)\\) which is not a point in \\(\\mathbb{P}^2\\). Hence \\(y \\neq 0\\). Similarly, \\(x = 0\\) would imply \\(y = 0\\), so \\(x \\neq 0\\) as well.  \n\nBecause \\(y \\neq 0\\), we may scale the homogeneous coordinates so that \\(y = 1\\). Then (1) becomes\n\n\\[\nx^2 - x + 1 = 0.\n\\]\n\nIts solutions are\n\n\\[\nx = \\frac{1 \\pm i\\sqrt{3}}{2}.\n\\]\n\nSet \\(\\zeta = \\frac{1 + i\\sqrt{3}}{2} = e^{i\\pi/3}\\); then the other root is \\(\\zeta^{-1} = \\frac{1 - i\\sqrt{3}}{2} = e^{-i\\pi/3}\\).\n\nFor each value of \\(x\\) we have \\(z^2 = xy = x\\) (since \\(y=1\\)). Thus \\(z\\) is a square root of \\(x\\). Because \\(x \\neq 0\\), there are two distinct square roots for each \\(x\\), differing by a sign. This yields four points in \\(\\mathbb{P}^2\\) (with the representative \\(y=1\\)):\n\n\\[\n\\begin{aligned}\nP_1 &= (\\zeta,\\; 1,\\; \\sqrt{\\zeta}), &\nP_2 &= (\\zeta,\\; 1,\\; -\\sqrt{\\zeta}), \\\\[1mm]\nP_3 &= (\\zeta^{-1},\\; 1,\\; \\sqrt{\\zeta^{-1}}), &\nP_4 &= (\\zeta^{-1},\\; 1,\\; -\\sqrt{\\zeta^{-1}}),\n\\end{aligned}\n\\]\n\nwhere \\(\\sqrt{\\zeta}\\) denotes a fixed choice of square root; the opposite sign gives the other point.\n\nThese four points are distinct:\n- The ratios \\(x:y\\) are \\(\\zeta\\) for \\(P_1,P_2\\) and \\(\\zeta^{-1}\\) for \\(P_3,P_4\\), and \\(\\zeta \\neq \\zeta^{-1}\\) because \\(\\zeta \\neq \\pm 1\\).\n- For a fixed ratio, the two points differ only in the sign of the \\(z\\)-coordinate. No non\u2011zero scalar \\(\\lambda\\) can identify them because that would require \\(\\lambda = 1\\) from the first two coordinates and then force \\(z = -z\\), i.e., \\(z=0\\), which is impossible since \\(z^2 = \\zeta \\neq 0\\).\n\nHence \\(C_1 \\cap C_2\\) consists of exactly four distinct points.\n\n---\n\n### 4. Intersection multiplicities\n\nBecause we have found four distinct intersection points and B\u00e9zout\u2019s theorem guarantees that the sum of multiplicities is \\(4\\), each intersection multiplicity must be exactly \\(1\\). (One may also verify transversality directly: both curves are smooth at these points, and their gradient vectors \\(\\nabla f = (2x,2y,-2z)\\) and \\(\\nabla g = (y,x,-2z)\\) are linearly independent at each point, so the intersection is transverse.)\n\n---\n\n### 5. Conclusion\n\nThe number of intersection points of \\(C_1\\) and \\(C_2\\) in \\(\\mathbb{P}^2\\), counted with multiplicity, is\n\n\\[\n\\boxed{4}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Linear and multilinear algebra; matrix theory, along with a complete and verifiable solution.\n\n## Step 2: Identify the key elements of a well-posed problem\nThe problem must be fully self-contained, clear, non-trivial, solvable, and verifiable. It should involve sophisticated techniques from linear and multilinear algebra or matrix theory.\n\n## Step 3: Generate a problem that fits the criteria\nLet's consider a problem that involves matrix theory and requires a good understanding of linear algebra concepts. A potential problem could involve proving a property of matrices or finding a specific matrix that satisfies certain conditions.\n\n## Step 4: Formulate the problem\nConsider the following problem: \"Let $A$ be a $3 \\times 3$ real matrix such that $A^3 = I$, where $I$ is the $3 \\times 3$ identity matrix. Prove that $A$ is diagonalizable over $\\mathbb{C}$.\"\n\n## Step 5: Verify that the problem is well-posed and solvable\nThe problem is well-posed because it specifies the domain of $A$ (real $3 \\times 3$ matrices), gives a clear condition ($A^3 = I$), and asks for a specific proof (that $A$ is diagonalizable over $\\mathbb{C}$). It is solvable using established methods in linear algebra.\n\n## Step 6: Provide a complete solution to the problem\nTo solve this, we note that $A$ satisfies the polynomial $x^3 - 1 = 0$. This polynomial factors as $(x-1)(x^2 + x + 1) = 0$. The roots are $1$, $e^{2\\pi i/3}$, and $e^{4\\pi i/3}$. Since $A$ satisfies this polynomial, its eigenvalues must be among these roots. Because the minimal polynomial of $A$ divides $x^3 - 1$ and has distinct roots (since $x^3 - 1$ has distinct roots), $A$ is diagonalizable over $\\mathbb{C}$.\n\n## Step 7: Write the problem and solution in the required format\n\nLet $A$ be a $3 \\times 3$ real matrix such that $A^3 = I$, where $I$ is the $3 \\times 3$ identity matrix. Prove that $A$ is diagonalizable over $\\mathbb{C}$.",
    "run_id": "9",
    "outer_attempt": 1,
    "topic_slug": "linear_and_multilinear_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are given a $3 \\times 3$ real matrix $A$ with $A^3 = I$. We must prove that $A$ is diagonalizable over $\\mathbb{C}$.\n\n**Proof.**  \nSince $A^3 = I$, the matrix $A$ satisfies the polynomial $p(t) = t^3 - 1$. Hence the minimal polynomial $m_A(t)$ of $A$ divides $p(t)$.\n\nOver $\\mathbb{C}$, $p(t)$ factors as  \n$$\np(t) = (t-1)(t-\\omega)(t-\\omega^2),\n$$  \nwhere $\\omega = e^{2\\pi i/3}$ is a primitive cube root of unity and $\\omega^2 = e^{4\\pi i/3}$. The three numbers $1$, $\\omega$, $\\omega^2$ are distinct (indeed, $\\omega \\neq 1$ and $\\omega^2 \\neq \\omega$ because $\\omega$ is not real). Therefore $p(t)$ has **distinct** linear factors.\n\nAny divisor of $p(t)$ is a product of a subset of these distinct linear factors; consequently, any such divisor also splits into distinct linear factors over $\\mathbb{C}$. In particular, the minimal polynomial $m_A(t)$ is of the form  \n$$\nm_A(t) = (t-\\lambda_1)\\cdots(t-\\lambda_k)\n$$  \nwith $\\lambda_i$ belonging to $\\{1,\\omega,\\omega^2\\}$ and all $\\lambda_i$ distinct.\n\nThe field $\\mathbb{C}$ is algebraically closed, so the characteristic polynomial of $A$ splits over $\\mathbb{C}$. A well\u2011known criterion states that a matrix over an algebraically closed field is diagonalizable if and only if its minimal polynomial has no repeated roots (i.e., is a product of distinct linear factors). Because $m_A(t)$ has distinct linear factors, $A$ is diagonalizable over $\\mathbb{C}$.\n\nThus we have shown that any $3 \\times 3$ real matrix satisfying $A^3 = I$ is diagonalizable over $\\mathbb{C}$. \u220e",
        "raw_answer": "We are given a $3 \\times 3$ real matrix $A$ with $A^3 = I$. We must prove that $A$ is diagonalizable over $\\mathbb{C}$.\n\n**Proof.**  \nSince $A^3 = I$, the matrix $A$ satisfies the polynomial $p(t) = t^3 - 1$. Hence the minimal polynomial $m_A(t)$ of $A$ divides $p(t)$.\n\nOver $\\mathbb{C}$, $p(t)$ factors as  \n\\[\np(t) = (t-1)(t-\\omega)(t-\\omega^2),\n\\]  \nwhere $\\omega = e^{2\\pi i/3}$ is a primitive cube root of unity and $\\omega^2 = e^{4\\pi i/3}$. The three numbers $1$, $\\omega$, $\\omega^2$ are distinct (indeed, $\\omega \\neq 1$ and $\\omega^2 \\neq \\omega$ because $\\omega$ is not real). Therefore $p(t)$ has **distinct** linear factors.\n\nAny divisor of $p(t)$ is a product of a subset of these distinct linear factors; consequently, any such divisor also splits into distinct linear factors over $\\mathbb{C}$. In particular, the minimal polynomial $m_A(t)$ is of the form  \n\\[\nm_A(t) = (t-\\lambda_1)\\cdots(t-\\lambda_k)\n\\]  \nwith $\\lambda_i$ belonging to $\\{1,\\omega,\\omega^2\\}$ and all $\\lambda_i$ distinct.\n\nThe field $\\mathbb{C}$ is algebraically closed, so the characteristic polynomial of $A$ splits over $\\mathbb{C}$. A well\u2011known criterion states that a matrix over an algebraically closed field is diagonalizable if and only if its minimal polynomial has no repeated roots (i.e., is a product of distinct linear factors). Because $m_A(t)$ has distinct linear factors, $A$ is diagonalizable over $\\mathbb{C}$.\n\nThus we have shown that any $3 \\times 3$ real matrix satisfying $A^3 = I$ is diagonalizable over $\\mathbb{C}$. \u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of associative rings and algebras, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within associative rings and algebras\nAssociative rings and algebras involve the study of algebraic structures with associative multiplication. A suitable topic could involve properties of ideals, quotient rings, or specific types of algebras like matrix algebras.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving the properties of a specific type of associative algebra. For instance, we could explore the characteristics of a matrix algebra over a ring.\n\n## Step 4: Generate a specific problem\nConsider the ring $R = \\mathbb{Z}/4\\mathbb{Z}$ and the matrix algebra $M_2(R)$ of $2 \\times 2$ matrices with entries in $R$. Let's examine the properties of ideals in $M_2(R)$.\n\n## Step 5: Formulate the problem statement\n\"Let $R = \\mathbb{Z}/4\\mathbb{Z}$ and consider the matrix algebra $M_2(R)$. Prove that $M_2(R)$ is not a simple ring, i.e., it has a non-trivial ideal.\"\n\n## Step 6: Provide the solution\nTo solve this, we need to show that there exists a non-trivial ideal in $M_2(R)$. An ideal $I$ in $M_2(R)$ is a subset that is closed under addition and under multiplication by any element of $M_2(R)$ from either side.\n\n## Step 7: Identify a non-trivial ideal\nConsider the set $I$ of matrices in $M_2(R)$ where all entries are even (i.e., $0$ or $2$ mod $4$). This set is non-empty and not equal to $M_2(R)$ because it does not contain matrices with odd entries.\n\n## Step 8: Verify that $I$ is an ideal\nFor $I$ to be an ideal, it must be closed under addition and under multiplication by elements of $M_2(R)$. For any two matrices $A, B \\in I$, $A + B$ has even entries because the sum of even numbers is even, so $A + B \\in I$. For any $A \\in I$ and $C \\in M_2(R)$, the product $CA$ and $AC$ will have entries that are products and sums of products involving elements of $R$. Since $A$ has even entries, $CA$ and $AC$ will also have even entries because multiplying any element of $R$ by an even element results in an even element.\n\n## Step 9: Check if $I$ is non-trivial\n$I$ is non-trivial if it is not the zero ideal and not the entire ring $M_2(R)$. The zero matrix is in $I$, and there are non-zero matrices in $I$ (e.g., $\\begin{pmatrix} 2 & 0 \\\\ 0 & 0 \\end{pmatrix}$), so $I$ is not the zero ideal. $I$ is not $M_2(R)$ because, for example, $\\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\notin I$.\n\n## Step 10: Conclude the solution\nSince $I$ is a non-trivial ideal, $M_2(R)$ is not a simple ring.\n\nThe final answer is: \n\nLet $R = \\mathbb{Z}/4\\mathbb{Z}$ and consider the matrix algebra $M_2(R)$. Prove that $M_2(R)$ is not a simple ring, i.e., it has a non-trivial ideal.",
    "run_id": "10",
    "outer_attempt": 1,
    "topic_slug": "associative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked to prove that the matrix ring $M_2(R)$ with $R = \\mathbb{Z}/4\\mathbb{Z}$ is not simple, i.e., it possesses a nontrivial two\u2011sided ideal.\n\n---\n\n**Proof.**  \nLet $R = \\mathbb{Z}/4\\mathbb{Z}$. Denote by $J$ the subset $\\{0,2\\} \\subseteq R$.  \n$J$ is an ideal of $R$:  \n- It is an additive subgroup because $0+0=0$, $0+2=2$, and $2+2=0$ (mod\u202f4).  \n- For any $r \\in R$ we have $r \\cdot 2 \\in \\{0,2\\}$ (since $2\\cdot0=0$, $2\\cdot1=2$, $2\\cdot2=0$, $2\\cdot3=2$ modulo\u202f4). Hence $rJ \\subseteq J$ and, because $R$ is commutative, also $Jr \\subseteq J$.  \n\nThus $J$ is a proper nonzero ideal of $R$ ($J \\neq 0$ and $J \\neq R$ because $1 \\notin J$).\n\nNow define  \n$$\nI = \\bigl\\{ A \\in M_2(R) \\;\\big|\\; \\text{every entry of } A \\text{ belongs to } J \\bigr\\}.\n$$  \nWe show that $I$ is a nontrivial two\u2011sided ideal of $M_2(R)$.\n\n1. **$I$ is an additive subgroup.**  \n   - The zero matrix has all entries $0 \\in J$, so $0 \\in I$.  \n   - If $A, B \\in I$, then for each entry $a_{ij}, b_{ij} \\in J$ we have $a_{ij}+b_{ij} \\in J$ because $J$ is closed under addition. Hence $A+B \\in I$.  \n   - If $A \\in I$, then $-A$ has entries $-a_{ij}$. Since $J$ is an additive subgroup, $-a_{ij} \\in J$, so $-A \\in I$.\n\n2. **$I$ is closed under left multiplication by any element of $M_2(R)$.**  \n   Let $X = (x_{ij}) \\in M_2(R)$ and $A = (a_{ij}) \\in I$. The $(i,j)$-entry of the product $XA$ is $\\sum_{k=1}^{2} x_{ik} a_{kj}$. For each $k$, $a_{kj} \\in J$ and because $J$ is an ideal, $x_{ik} a_{kj} \\in J$. A finite sum of elements of $J$ remains in $J$ (as $J$ is an additive subgroup). Therefore every entry of $XA$ lies in $J$, i.e., $XA \\in I$.\n\n3. **$I$ is closed under right multiplication by any element of $M_2(R)$.**  \n   The argument is symmetric: for $A \\in I$ and $X \\in M_2(R)$, the $(i,j)$-entry of $AX$ is $\\sum_{k=1}^{2} a_{ik} x_{kj}$. Since $a_{ik} \\in J$ and $J$ is an ideal, $a_{ik} x_{kj} \\in J$; the sum stays in $J$. Hence $AX \\in I$.\n\nThus $I$ is a two\u2011sided ideal of $M_2(R)$.\n\n4. **$I$ is nontrivial.**  \n   - $I$ is not the zero ideal: the matrix $\\begin{pmatrix} 2 & 0 \\\\ 0 & 0 \\end{pmatrix}$ is nonzero and belongs to $I$.  \n   - $I$ is not the whole ring: the identity matrix $I_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$ does **not** belong to $I$ because its diagonal entries are $1 \\notin J$.\n\nSince $M_2(R)$ contains a proper nonzero two\u2011sided ideal, it is not a simple ring. \u220e\n\n---\n\n**Remark.** The construction works generally: if $R$ has a proper nonzero ideal $J$, then the set of $n \\times n$ matrices with entries in $J$ is a proper nonzero ideal of $M_n(R)$. Hence $M_n(R)$ is simple only when $R$ itself is simple (i.e., has no nontrivial ideals). For $R = \\mathbb{Z}/4\\mathbb{Z}$ and $n=2$ we obtain the desired conclusion.",
        "raw_answer": "We are asked to prove that the matrix ring \\(M_2(R)\\) with \\(R = \\mathbb{Z}/4\\mathbb{Z}\\) is not simple, i.e., it possesses a nontrivial two\u2011sided ideal.\n\n---\n\n**Proof.**  \nLet \\(R = \\mathbb{Z}/4\\mathbb{Z}\\). Denote by \\(J\\) the subset \\(\\{0,2\\} \\subseteq R\\).  \n\\(J\\) is an ideal of \\(R\\):  \n- It is an additive subgroup because \\(0+0=0\\), \\(0+2=2\\), and \\(2+2=0\\) (mod\u202f4).  \n- For any \\(r \\in R\\) we have \\(r \\cdot 2 \\in \\{0,2\\}\\) (since \\(2\\cdot0=0\\), \\(2\\cdot1=2\\), \\(2\\cdot2=0\\), \\(2\\cdot3=2\\) modulo\u202f4). Hence \\(rJ \\subseteq J\\) and, because \\(R\\) is commutative, also \\(Jr \\subseteq J\\).  \n\nThus \\(J\\) is a proper nonzero ideal of \\(R\\) (\\(J \\neq 0\\) and \\(J \\neq R\\) because \\(1 \\notin J\\)).\n\nNow define  \n\\[\nI = \\bigl\\{ A \\in M_2(R) \\;\\big|\\; \\text{every entry of } A \\text{ belongs to } J \\bigr\\}.\n\\]  \nWe show that \\(I\\) is a nontrivial two\u2011sided ideal of \\(M_2(R)\\).\n\n1. **\\(I\\) is an additive subgroup.**  \n   - The zero matrix has all entries \\(0 \\in J\\), so \\(0 \\in I\\).  \n   - If \\(A, B \\in I\\), then for each entry \\(a_{ij}, b_{ij} \\in J\\) we have \\(a_{ij}+b_{ij} \\in J\\) because \\(J\\) is closed under addition. Hence \\(A+B \\in I\\).  \n   - If \\(A \\in I\\), then \\(-A\\) has entries \\(-a_{ij}\\). Since \\(J\\) is an additive subgroup, \\(-a_{ij} \\in J\\), so \\(-A \\in I\\).\n\n2. **\\(I\\) is closed under left multiplication by any element of \\(M_2(R)\\).**  \n   Let \\(X = (x_{ij}) \\in M_2(R)\\) and \\(A = (a_{ij}) \\in I\\). The \\((i,j)\\)-entry of the product \\(XA\\) is \\(\\sum_{k=1}^{2} x_{ik} a_{kj}\\). For each \\(k\\), \\(a_{kj} \\in J\\) and because \\(J\\) is an ideal, \\(x_{ik} a_{kj} \\in J\\). A finite sum of elements of \\(J\\) remains in \\(J\\) (as \\(J\\) is an additive subgroup). Therefore every entry of \\(XA\\) lies in \\(J\\), i.e., \\(XA \\in I\\).\n\n3. **\\(I\\) is closed under right multiplication by any element of \\(M_2(R)\\).**  \n   The argument is symmetric: for \\(A \\in I\\) and \\(X \\in M_2(R)\\), the \\((i,j)\\)-entry of \\(AX\\) is \\(\\sum_{k=1}^{2} a_{ik} x_{kj}\\). Since \\(a_{ik} \\in J\\) and \\(J\\) is an ideal, \\(a_{ik} x_{kj} \\in J\\); the sum stays in \\(J\\). Hence \\(AX \\in I\\).\n\nThus \\(I\\) is a two\u2011sided ideal of \\(M_2(R)\\).\n\n4. **\\(I\\) is nontrivial.**  \n   - \\(I\\) is not the zero ideal: the matrix \\(\\begin{pmatrix} 2 & 0 \\\\ 0 & 0 \\end{pmatrix}\\) is nonzero and belongs to \\(I\\).  \n   - \\(I\\) is not the whole ring: the identity matrix \\(I_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\) does **not** belong to \\(I\\) because its diagonal entries are \\(1 \\notin J\\).\n\nSince \\(M_2(R)\\) contains a proper nonzero two\u2011sided ideal, it is not a simple ring. \u220e\n\n---\n\n**Remark.** The construction works generally: if \\(R\\) has a proper nonzero ideal \\(J\\), then the set of \\(n \\times n\\) matrices with entries in \\(J\\) is a proper nonzero ideal of \\(M_n(R)\\). Hence \\(M_n(R)\\) is simple only when \\(R\\) itself is simple (i.e., has no nontrivial ideals). For \\(R = \\mathbb{Z}/4\\mathbb{Z}\\) and \\(n=2\\) we obtain the desired conclusion.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of nonassociative rings and algebras, along with a complete and verifiable solution. Nonassociative rings and algebras are mathematical structures where the multiplication operation is not necessarily associative.\n\n## Step 2: Identify a specific area within nonassociative rings and algebras\nA key area within nonassociative rings and algebras is the study of Lie algebras, which are crucial in various branches of mathematics and physics, particularly in the study of symmetries and conservation laws.\n\n## Step 3: Formulate a problem\nLet's consider a problem involving Lie algebras. A Lie algebra is a vector space $\\mathfrak{g}$ over a field $\\mathbb{F}$, together with a binary operation $[\\cdot, \\cdot]: \\mathfrak{g} \\times \\mathfrak{g} \\to \\mathfrak{g}$, called the Lie bracket, that satisfies bilinearity, skew-symmetry, and the Jacobi identity.\n\n## Step 4: Specify the problem\nConsider the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$, which consists of $2 \\times 2$ real matrices with trace zero. The Lie bracket is defined as $[A, B] = AB - BA$. Let $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$. Show that $H, X, Y$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and determine the structure constants with respect to this basis.\n\n## Step 5: Provide the problem statement in the required format\n\nLet $\\mathfrak{sl}(2, \\mathbb{R})$ be the Lie algebra of $2 \\times 2$ real matrices with trace zero, with the Lie bracket $[A, B] = AB - BA$. Show that the matrices $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and compute the structure constants with respect to this basis.",
    "run_id": "11",
    "outer_attempt": 1,
    "topic_slug": "nonassociative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe work in the Lie algebra $\\mathfrak{sl}(2,\\mathbb{R}) = \\{ A \\in M_{2}(\\mathbb{R}) \\mid \\operatorname{tr}(A) = 0 \\}$ with the Lie bracket $[A,B] = AB - BA$.\n\n---\n\n### 1. Membership\n\nCompute traces:\n\n$$\n\\operatorname{tr}(H) = 1 + (-1) = 0,\\qquad\n\\operatorname{tr}(X) = 0 + 0 = 0,\\qquad\n\\operatorname{tr}(Y) = 0 + 0 = 0.\n$$\n\nThus $H, X, Y \\in \\mathfrak{sl}(2,\\mathbb{R})$.\n\n---\n\n### 2. Linear independence\n\nAssume $a H + b X + c Y = 0$ for some $a,b,c \\in \\mathbb{R}$. Then\n\n$$\na\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} + b\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} + c\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\n= \\begin{pmatrix}a & b \\\\ c & -a\\end{pmatrix}\n= \\begin{pmatrix}0&0\\\\0&0\\end{pmatrix},\n$$\n\nwhich forces $a = b = c = 0$. Hence $H, X, Y$ are linearly independent.\n\n---\n\n### 3. Spanning\n\nLet $A \\in \\mathfrak{sl}(2,\\mathbb{R})$ be arbitrary. Write $A = \\begin{pmatrix} p & q \\\\ r & s \\end{pmatrix}$ with $\\operatorname{tr}(A) = p + s = 0$, so $s = -p$. Then\n\n$$\nA = \\begin{pmatrix} p & q \\\\ r & -p \\end{pmatrix}\n= p\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} + q\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} + r\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\n= p H + q X + r Y.\n$$\n\nThus every element of $\\mathfrak{sl}(2,\\mathbb{R})$ is a linear combination of $H, X, Y$. Consequently, $\\{H, X, Y\\}$ is a basis.\n\n*(Alternatively, $\\dim \\mathfrak{sl}(2,\\mathbb{R}) = 3$ and three linearly independent vectors automatically form a basis.)*\n\n---\n\n### 4. Lie brackets\n\nCompute the commutators explicitly.\n\n- $[H, X] = HX - XH$\n\n$$\nHX = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = X,\n$$\n$$\nXH = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix}\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = \\begin{pmatrix}0&-1\\\\0&0\\end{pmatrix} = -X,\n$$\n$$\n\\Rightarrow [H,X] = X - (-X) = 2X.\n$$\n\n- $[H, Y] = HY - YH$\n\n$$\nHY = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = \\begin{pmatrix}0&0\\\\-1&0\\end{pmatrix} = -Y,\n$$\n$$\nYH = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = Y,\n$$\n$$\n\\Rightarrow [H,Y] = -Y - Y = -2Y.\n$$\n\n- $[X, Y] = XY - YX$\n\n$$\nXY = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix}\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = \\begin{pmatrix}1&0\\\\0&0\\end{pmatrix},\n$$\n$$\nYX = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = \\begin{pmatrix}0&0\\\\0&1\\end{pmatrix},\n$$\n$$\n\\Rightarrow [X,Y] = \\begin{pmatrix}1&0\\\\0&0\\end{pmatrix} - \\begin{pmatrix}0&0\\\\0&1\\end{pmatrix} = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = H.\n$$\n\nThe remaining brackets follow from skew\u2011symmetry:\n\n$$\n[X,H] = -[H,X] = -2X,\\qquad\n[Y,H] = -[H,Y] = 2Y,\\qquad\n[Y,X] = -[X,Y] = -H.\n$$\n\n---\n\n### 5. Structure constants\n\nOrder the basis as $e_1 = H$, $e_2 = X$, $e_3 = Y$. The structure constants $c_{ij}^k$ are defined by\n\n$$\n[e_i, e_j] = \\sum_{k=1}^{3} c_{ij}^k e_k.\n$$\n\nFrom the computed brackets we obtain the non\u2011zero constants:\n\n$$\n\\begin{aligned}\n[e_1, e_2] &= 2 e_2 \\quad &\\Rightarrow\\quad c_{12}^2 = 2,\\\\\n[e_1, e_3] &= -2 e_3 \\quad &\\Rightarrow\\quad c_{13}^3 = -2,\\\\\n[e_2, e_3] &= e_1 \\quad &\\Rightarrow\\quad c_{23}^1 = 1.\n\\end{aligned}\n$$\n\nBy antisymmetry $c_{ji}^k = -c_{ij}^k$ we also have\n\n$$\nc_{21}^2 = -2,\\qquad c_{31}^3 = 2,\\qquad c_{32}^1 = -1.\n$$\n\nAll other $c_{ij}^k$ are zero.\n\n---\n\n### Conclusion\n\nThe matrices $H, X, Y$ form a basis of $\\mathfrak{sl}(2,\\mathbb{R})$, and the structure constants relative to this basis are given by the non\u2011zero values $c_{12}^2 = 2$, $c_{13}^3 = -2$, $c_{23}^1 = 1$ (together with those obtained by antisymmetry).",
        "raw_answer": "**Solution**\n\nWe work in the Lie algebra \\(\\mathfrak{sl}(2,\\mathbb{R}) = \\{ A \\in M_{2}(\\mathbb{R}) \\mid \\operatorname{tr}(A) = 0 \\}\\) with the Lie bracket \\([A,B] = AB - BA\\).\n\n---\n\n### 1. Membership\n\nCompute traces:\n\n\\[\n\\operatorname{tr}(H) = 1 + (-1) = 0,\\qquad\n\\operatorname{tr}(X) = 0 + 0 = 0,\\qquad\n\\operatorname{tr}(Y) = 0 + 0 = 0.\n\\]\n\nThus \\(H, X, Y \\in \\mathfrak{sl}(2,\\mathbb{R})\\).\n\n---\n\n### 2. Linear independence\n\nAssume \\(a H + b X + c Y = 0\\) for some \\(a,b,c \\in \\mathbb{R}\\). Then\n\n\\[\na\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} + b\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} + c\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\n= \\begin{pmatrix}a & b \\\\ c & -a\\end{pmatrix}\n= \\begin{pmatrix}0&0\\\\0&0\\end{pmatrix},\n\\]\n\nwhich forces \\(a = b = c = 0\\). Hence \\(H, X, Y\\) are linearly independent.\n\n---\n\n### 3. Spanning\n\nLet \\(A \\in \\mathfrak{sl}(2,\\mathbb{R})\\) be arbitrary. Write \\(A = \\begin{pmatrix} p & q \\\\ r & s \\end{pmatrix}\\) with \\(\\operatorname{tr}(A) = p + s = 0\\), so \\(s = -p\\). Then\n\n\\[\nA = \\begin{pmatrix} p & q \\\\ r & -p \\end{pmatrix}\n= p\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} + q\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} + r\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\n= p H + q X + r Y.\n\\]\n\nThus every element of \\(\\mathfrak{sl}(2,\\mathbb{R})\\) is a linear combination of \\(H, X, Y\\). Consequently, \\(\\{H, X, Y\\}\\) is a basis.\n\n*(Alternatively, \\(\\dim \\mathfrak{sl}(2,\\mathbb{R}) = 3\\) and three linearly independent vectors automatically form a basis.)*\n\n---\n\n### 4. Lie brackets\n\nCompute the commutators explicitly.\n\n- \\([H, X] = HX - XH\\)\n\n\\[\nHX = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = X,\n\\]\n\\[\nXH = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix}\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = \\begin{pmatrix}0&-1\\\\0&0\\end{pmatrix} = -X,\n\\]\n\\[\n\\Rightarrow [H,X] = X - (-X) = 2X.\n\\]\n\n- \\([H, Y] = HY - YH\\)\n\n\\[\nHY = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = \\begin{pmatrix}0&0\\\\-1&0\\end{pmatrix} = -Y,\n\\]\n\\[\nYH = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = Y,\n\\]\n\\[\n\\Rightarrow [H,Y] = -Y - Y = -2Y.\n\\]\n\n- \\([X, Y] = XY - YX\\)\n\n\\[\nXY = \\begin{pmatrix}0&1\\\\0&0\\end{pmatrix}\\begin{pmatrix}0&0\\\\1&0\\end{pmatrix} = \\begin{pmatrix}1&0\\\\0&0\\end{pmatrix},\n\\]\n\\[\nYX = \\begin{pmatrix}0&0\\\\1&0\\end{pmatrix}\\begin{pmatrix}0&1\\\\0&0\\end{pmatrix} = \\begin{pmatrix}0&0\\\\0&1\\end{pmatrix},\n\\]\n\\[\n\\Rightarrow [X,Y] = \\begin{pmatrix}1&0\\\\0&0\\end{pmatrix} - \\begin{pmatrix}0&0\\\\0&1\\end{pmatrix} = \\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix} = H.\n\\]\n\nThe remaining brackets follow from skew\u2011symmetry:\n\n\\[\n[X,H] = -[H,X] = -2X,\\qquad\n[Y,H] = -[H,Y] = 2Y,\\qquad\n[Y,X] = -[X,Y] = -H.\n\\]\n\n---\n\n### 5. Structure constants\n\nOrder the basis as \\(e_1 = H\\), \\(e_2 = X\\), \\(e_3 = Y\\). The structure constants \\(c_{ij}^k\\) are defined by\n\n\\[\n[e_i, e_j] = \\sum_{k=1}^{3} c_{ij}^k e_k.\n\\]\n\nFrom the computed brackets we obtain the non\u2011zero constants:\n\n\\[\n\\begin{aligned}\n[e_1, e_2] &= 2 e_2 \\quad &\\Rightarrow\\quad c_{12}^2 = 2,\\\\\n[e_1, e_3] &= -2 e_3 \\quad &\\Rightarrow\\quad c_{13}^3 = -2,\\\\\n[e_2, e_3] &= e_1 \\quad &\\Rightarrow\\quad c_{23}^1 = 1.\n\\end{aligned}\n\\]\n\nBy antisymmetry \\(c_{ji}^k = -c_{ij}^k\\) we also have\n\n\\[\nc_{21}^2 = -2,\\qquad c_{31}^3 = 2,\\qquad c_{32}^1 = -1.\n\\]\n\nAll other \\(c_{ij}^k\\) are zero.\n\n---\n\n### Conclusion\n\nThe matrices \\(H, X, Y\\) form a basis of \\(\\mathfrak{sl}(2,\\mathbb{R})\\), and the structure constants relative to this basis are given by the non\u2011zero values \\(c_{12}^2 = 2\\), \\(c_{13}^3 = -2\\), \\(c_{23}^1 = 1\\) (together with those obtained by antisymmetry).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of category theory or homological algebra, along with a solution that is verifiable and follows the given guidelines.\n\n## Step 2: Identify the domain\nThe problem should be related to category theory or homological algebra.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we need to ensure it is well-posed, non-trivial, and solvable with the given constraints. Let's consider a problem that involves understanding and applying concepts from category theory.\n\n## Step 4: Generate the problem\nLet's formulate a problem that involves proving a property related to categories and functors.\n\n## Step 5: Write the problem\nProve that the functor $F: \\mathbf{Ab} \\to \\mathbf{Ab}$ defined by $F(G) = G \\otimes_{\\mathbb{Z}} \\mathbb{Q}$ is exact.\n[/QUESTION]",
    "run_id": "12",
    "outer_attempt": 1,
    "topic_slug": "category_theory_and_homological_algebra",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove that the functor $F\\colon\\mathbf{Ab}\\to\\mathbf{Ab}$ defined by $F(G)=G\\otimes_{\\mathbb{Z}}\\mathbb{Q}$ is exact.  The category $\\mathbf{Ab}$ is equivalent to $\\mathbb{Z}\\text{-}\\mathbf{Mod}$, so we work with $\\mathbb{Z}$-modules.\n\nThe key observation is that $\\mathbb{Q}$ is the localization of $\\mathbb{Z}$ at the multiplicative set $S=\\mathbb{Z}\\setminus\\{0\\}$.  For any $\\mathbb{Z}$-module $G$, let\n$$\nS^{-1}G = \\left\\{\\frac{g}{s}\\;\\Big|\\; g\\in G,\\; s\\in S\\right\\}\\big/{\\sim},\n$$\nwhere $\\frac{g}{s}\\sim\\frac{g'}{s'}$ iff there exists $t\\in S$ with $t(s'g-sg')=0$.  This is the usual localization of a module.\n\n**Lemma 1.**  There is a natural isomorphism of functors\n$$\n\\varphi_G\\colon G\\otimes_{\\mathbb{Z}}\\mathbb{Q} \\longrightarrow S^{-1}G,\\qquad\ng\\otimes\\frac{a}{s} \\;\\longmapsto\\; \\frac{a\\cdot g}{s}.\n$$\nIts inverse is $\\psi_G\\bigl(\\frac{g}{s}\\bigr)=g\\otimes\\frac{1}{s}$.\n\n*Proof (sketch).*  The map $(g,\\frac{a}{s})\\mapsto\\frac{a g}{s}$ is $\\mathbb{Z}$-bilinear, hence induces a homomorphism $\\varphi_G$.  One verifies that $\\psi_G$ is well\u2011defined and that $\\varphi_G\\circ\\psi_G=\\mathrm{id}$ and $\\psi_G\\circ\\varphi_G=\\mathrm{id}$.  Naturality in $G$ is clear.  \u220e\n\nThus $F$ is naturally isomorphic to the localization functor $L\\colon G\\mapsto S^{-1}G$.  Because a natural isomorphism preserves exactness, it suffices to show that $L$ is exact.\n\n**Lemma 2.**  The functor $L$ is exact: for every short exact sequence\n$$\n0 \\longrightarrow A \\xrightarrow{\\;i\\;} B \\xrightarrow{\\;p\\;} C \\longrightarrow 0\n$$\nthe induced sequence\n$$\n0 \\longrightarrow S^{-1}A \\xrightarrow{S^{-1}i} S^{-1}B \\xrightarrow{S^{-1}p} S^{-1}C \\longrightarrow 0\n$$\nis exact.\n\n*Proof.*  We check the three conditions.\n\n1. **Injectivity of $S^{-1}i$.**  \n   Suppose $\\frac{a}{s}\\in S^{-1}A$ satisfies $(S^{-1}i)\\bigl(\\frac{a}{s}\\bigr)=\\frac{i(a)}{s}=0$ in $S^{-1}B$.  By definition, there exists $t\\in S$ such that $t\\cdot i(a)=0$ in $B$.  Since $i$ is injective, $t\\cdot a=0$ in $A$.  Then\n   $$\n   \\frac{a}{s}=\\frac{t a}{t s}=0 \\quad\\text{in } S^{-1}A,\n   $$\n   so $S^{-1}i$ is injective.\n\n2. **Surjectivity of $S^{-1}p$.**  \n   For any $\\frac{c}{s}\\in S^{-1}C$, surjectivity of $p$ gives $b\\in B$ with $p(b)=c$.  Then\n   $$\n   (S^{-1}p)\\Bigl(\\frac{b}{s}\\Bigr)=\\frac{p(b)}{s}=\\frac{c}{s},\n   $$\n   hence $S^{-1}p$ is surjective.\n\n3. **Exactness at $S^{-1}B$.**  \n   - $\\operatorname{Im}(S^{-1}i)\\subseteq\\operatorname{Ker}(S^{-1}p)$: If $\\frac{a}{s}\\in S^{-1}A$, then\n     $$\n     (S^{-1}p\\circ S^{-1}i)\\Bigl(\\frac{a}{s}\\Bigr)=\\frac{p(i(a))}{s}=0,\n     $$\n     because $p\\circ i=0$.  \n   - $\\operatorname{Ker}(S^{-1}p)\\subseteq\\operatorname{Im}(S^{-1}i)$: Let $\\frac{b}{s}\\in S^{-1}B$ with $(S^{-1}p)\\bigl(\\frac{b}{s}\\bigr)=\\frac{p(b)}{s}=0$.  Then there exists $t\\in S$ such that $t\\cdot p(b)=0$ in $C$, i.e. $p(t b)=0$.  Hence $t b\\in\\operatorname{Ker}(p)=\\operatorname{Im}(i)$, so we can choose $a\\in A$ with $i(a)=t b$.  Now consider $\\frac{a}{t s}\\in S^{-1}A$.  We have\n     $$\n     (S^{-1}i)\\Bigl(\\frac{a}{t s}\\Bigr)=\\frac{i(a)}{t s}=\\frac{t b}{t s}=\\frac{b}{s},\n     $$\n     showing $\\frac{b}{s}\\in\\operatorname{Im}(S^{-1}i)$.\n\nThus the sequence is exact.  \u220e\n\nBecause $F\\cong L$ naturally and $L$ is exact, the functor $F$ is exact.  $\\blacksquare$",
        "raw_answer": "We prove that the functor \\(F\\colon\\mathbf{Ab}\\to\\mathbf{Ab}\\) defined by \\(F(G)=G\\otimes_{\\mathbb{Z}}\\mathbb{Q}\\) is exact.  The category \\(\\mathbf{Ab}\\) is equivalent to \\(\\mathbb{Z}\\text{-}\\mathbf{Mod}\\), so we work with \\(\\mathbb{Z}\\)-modules.\n\nThe key observation is that \\(\\mathbb{Q}\\) is the localization of \\(\\mathbb{Z}\\) at the multiplicative set \\(S=\\mathbb{Z}\\setminus\\{0\\}\\).  For any \\(\\mathbb{Z}\\)-module \\(G\\), let\n\\[\nS^{-1}G = \\left\\{\\frac{g}{s}\\;\\Big|\\; g\\in G,\\; s\\in S\\right\\}\\big/{\\sim},\n\\]\nwhere \\(\\frac{g}{s}\\sim\\frac{g'}{s'}\\) iff there exists \\(t\\in S\\) with \\(t(s'g-sg')=0\\).  This is the usual localization of a module.\n\n**Lemma 1.**  There is a natural isomorphism of functors\n\\[\n\\varphi_G\\colon G\\otimes_{\\mathbb{Z}}\\mathbb{Q} \\longrightarrow S^{-1}G,\\qquad\ng\\otimes\\frac{a}{s} \\;\\longmapsto\\; \\frac{a\\cdot g}{s}.\n\\]\nIts inverse is \\(\\psi_G\\bigl(\\frac{g}{s}\\bigr)=g\\otimes\\frac{1}{s}\\).\n\n*Proof (sketch).*  The map \\((g,\\frac{a}{s})\\mapsto\\frac{a g}{s}\\) is \\(\\mathbb{Z}\\)-bilinear, hence induces a homomorphism \\(\\varphi_G\\).  One verifies that \\(\\psi_G\\) is well\u2011defined and that \\(\\varphi_G\\circ\\psi_G=\\mathrm{id}\\) and \\(\\psi_G\\circ\\varphi_G=\\mathrm{id}\\).  Naturality in \\(G\\) is clear.  \u220e\n\nThus \\(F\\) is naturally isomorphic to the localization functor \\(L\\colon G\\mapsto S^{-1}G\\).  Because a natural isomorphism preserves exactness, it suffices to show that \\(L\\) is exact.\n\n**Lemma 2.**  The functor \\(L\\) is exact: for every short exact sequence\n\\[\n0 \\longrightarrow A \\xrightarrow{\\;i\\;} B \\xrightarrow{\\;p\\;} C \\longrightarrow 0\n\\]\nthe induced sequence\n\\[\n0 \\longrightarrow S^{-1}A \\xrightarrow{S^{-1}i} S^{-1}B \\xrightarrow{S^{-1}p} S^{-1}C \\longrightarrow 0\n\\]\nis exact.\n\n*Proof.*  We check the three conditions.\n\n1. **Injectivity of \\(S^{-1}i\\).**  \n   Suppose \\(\\frac{a}{s}\\in S^{-1}A\\) satisfies \\((S^{-1}i)\\bigl(\\frac{a}{s}\\bigr)=\\frac{i(a)}{s}=0\\) in \\(S^{-1}B\\).  By definition, there exists \\(t\\in S\\) such that \\(t\\cdot i(a)=0\\) in \\(B\\).  Since \\(i\\) is injective, \\(t\\cdot a=0\\) in \\(A\\).  Then\n   \\[\n   \\frac{a}{s}=\\frac{t a}{t s}=0 \\quad\\text{in } S^{-1}A,\n   \\]\n   so \\(S^{-1}i\\) is injective.\n\n2. **Surjectivity of \\(S^{-1}p\\).**  \n   For any \\(\\frac{c}{s}\\in S^{-1}C\\), surjectivity of \\(p\\) gives \\(b\\in B\\) with \\(p(b)=c\\).  Then\n   \\[\n   (S^{-1}p)\\Bigl(\\frac{b}{s}\\Bigr)=\\frac{p(b)}{s}=\\frac{c}{s},\n   \\]\n   hence \\(S^{-1}p\\) is surjective.\n\n3. **Exactness at \\(S^{-1}B\\).**  \n   - \\(\\operatorname{Im}(S^{-1}i)\\subseteq\\operatorname{Ker}(S^{-1}p)\\): If \\(\\frac{a}{s}\\in S^{-1}A\\), then\n     \\[\n     (S^{-1}p\\circ S^{-1}i)\\Bigl(\\frac{a}{s}\\Bigr)=\\frac{p(i(a))}{s}=0,\n     \\]\n     because \\(p\\circ i=0\\).  \n   - \\(\\operatorname{Ker}(S^{-1}p)\\subseteq\\operatorname{Im}(S^{-1}i)\\): Let \\(\\frac{b}{s}\\in S^{-1}B\\) with \\((S^{-1}p)\\bigl(\\frac{b}{s}\\bigr)=\\frac{p(b)}{s}=0\\).  Then there exists \\(t\\in S\\) such that \\(t\\cdot p(b)=0\\) in \\(C\\), i.e. \\(p(t b)=0\\).  Hence \\(t b\\in\\operatorname{Ker}(p)=\\operatorname{Im}(i)\\), so we can choose \\(a\\in A\\) with \\(i(a)=t b\\).  Now consider \\(\\frac{a}{t s}\\in S^{-1}A\\).  We have\n     \\[\n     (S^{-1}i)\\Bigl(\\frac{a}{t s}\\Bigr)=\\frac{i(a)}{t s}=\\frac{t b}{t s}=\\frac{b}{s},\n     \\]\n     showing \\(\\frac{b}{s}\\in\\operatorname{Im}(S^{-1}i)\\).\n\nThus the sequence is exact.  \u220e\n\nBecause \\(F\\cong L\\) naturally and \\(L\\) is exact, the functor \\(F\\) is exact.  \\(\\blacksquare\\)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of K-theory, along with a solution that is verifiable and follows the given format.\n\n## Step 2: Identify the topic and relevant concepts\nThe topic is K-theory, which is a branch of algebraic topology that studies the properties of vector bundles and their relations to the underlying space. K-theory is crucial in various areas of mathematics and physics.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to understand what kind of questions are typically asked in K-theory. A common type of problem involves calculating the K-theory groups of a specific space or understanding the properties of K-theory groups under certain operations.\n\n## Step 4: Generate a specific problem\nLet's generate a problem related to the K-theory of a particular space. Consider the space $S^2$, the 2-sphere. A relevant problem could be to compute $K^0(S^2)$ and $K^1(S^2)$, which are related to the complex vector bundles on $S^2$.\n\n## Step 5: Formulate the problem in the required format\nWe need to provide a problem in the format: \"Compute $K^0(X)$ and $K^1(X)$ for $X = S^2$,\" where $S^2$ is the 2-sphere.\n\n## Step 6: Provide the solution\nTo solve this, we recall that $K^0(X)$ and $K^1(X)$ are related to the Grothendieck groups of complex vector bundles on $X$. For $S^2$, we know that $K^0(S^2)$ is related to the isomorphism classes of complex vector bundles on $S^2$, and $K^1(S^2)$ is related to the stable homotopy group $\\pi_1(S^2)$.\n\n## Step 7: Write down the problem and its solution\n### Problem\nCompute $K^0(S^2)$ and $K^1(S^2)$.",
    "run_id": "13",
    "outer_attempt": 1,
    "topic_slug": "k_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We compute the complex topological K\u2011theory groups $K^0(S^2)$ and $K^1(S^2)$ of the 2\u2011sphere.\n\n## 1. Definitions and preliminaries\n\nFor a compact Hausdorff space $X$,  \n\n* $K^0(X)$ is the Grothendieck group of complex vector bundles over $X$.  \n  If $X$ is connected, there is a split exact sequence  \n  $$\n  0 \\longrightarrow \\widetilde{K}^0(X) \\longrightarrow K^0(X) \\xrightarrow{\\;\\operatorname{rk}\\;} \\mathbb{Z} \\longrightarrow 0,\n  $$\n  where $\\widetilde{K}^0(X)$ is the reduced K\u2011theory (virtual bundles of rank zero).\n\n* $K^1(X) = \\widetilde{K}^0(\\Sigma X)$, where $\\Sigma X$ is the reduced suspension.  \n  Equivalently, $K^1(X) = [X, U]$ with $U = \\varinjlim U(n)$ the infinite unitary group.\n\n## 2. Computation of $K^0(S^2)$\n\nWe use the **clutching construction**.  \n\nCover $S^2$ by two contractible open sets, e.g.  \n$U = S^2\\setminus\\{\\text{south pole}\\}$ and $V = S^2\\setminus\\{\\text{north pole}\\}$.  \nThen $U \\cap V$ retracts onto the equator $S^1$.\n\nBecause $U$ and $V$ are contractible, any complex vector bundle $E$ over $S^2$ is trivial when restricted to $U$ and to $V$.  \nChoose trivialisations $\\phi_U : E|_U \\to U\\times\\mathbb{C}^n$ and $\\phi_V : E|_V \\to V\\times\\mathbb{C}^n$.  \nOn $U\\cap V$ the transition map  \n$$\ng = \\phi_U \\circ \\phi_V^{-1} : U\\cap V \\to GL_n(\\mathbb{C})\n$$  \nis continuous. Up to homotopy, $g$ is determined by its restriction to $S^1$.  \nChanging the trivialisations alters $g$ by a homotopy, so the isomorphism class of $E$ depends only on the homotopy class $[g] \\in [S^1, GL_n(\\mathbb{C})] = \\pi_1(GL_n(\\mathbb{C}))$.  \nThis gives a bijection  \n$$\n\\operatorname{Vect}_n(S^2) \\;\\cong\\; \\pi_1(GL_n(\\mathbb{C})).\n$$\n\nNow $GL_n(\\mathbb{C})$ deformation retracts onto $U(n)$.  \nThe determinant $\\det : U(n) \\to U(1)$ is a fibration with fibre $SU(n)$.  \nSince $SU(n)$ is simply connected for $n\\ge 2$ (and $SU(1)$ is trivial), the long exact homotopy sequence yields  \n$$\n\\pi_1(U(n)) \\cong \\pi_1(U(1)) \\cong \\mathbb{Z} \\qquad\\text{for all } n\\ge 1.\n$$  \nHence $\\pi_1(GL_n(\\mathbb{C})) \\cong \\mathbb{Z}$ as well.  \n\nUnder this correspondence, the integer associated to a bundle $E$ is its **first Chern class**  \n$$\nc_1(E) \\in H^2(S^2;\\mathbb{Z}) \\cong \\mathbb{Z}.\n$$  \nFor line bundles it is the usual degree; for higher rank bundles one takes $c_1(\\det E)$.  \nIn particular, the Hopf line bundle $H$ corresponds to $1 \\in \\mathbb{Z}$.\n\nThe monoid of vector bundles (under direct sum) therefore satisfies  \n$$\n[E] \\leftrightarrow (\\operatorname{rk}(E),\\, c_1(E)) \\in \\mathbb{N} \\times \\mathbb{Z},\n$$  \nand the Grothendieck group $K^0(S^2)$ inherits a homomorphism  \n$$\n\\Phi : K^0(S^2) \\longrightarrow \\mathbb{Z} \\oplus \\mathbb{Z},\\qquad\n\\Phi([E]-[F]) = \\bigl(\\operatorname{rk}(E)-\\operatorname{rk}(F),\\; c_1(E)-c_1(F)\\bigr).\n$$  \n$\\Phi$ is well\u2011defined because $c_1$ is additive on exact sequences.\n\n* **Surjectivity**:  \n  $\\Phi( [\\text{trivial line bundle }1] ) = (1,0)$ and  \n  $\\Phi( [H] - [1] ) = (0,1)$.\n\n* **Injectivity**:  \n  The reduced group $\\widetilde{K}^0(S^2)$ consists of virtual bundles of rank zero.  \n  The map $c_1 : \\widetilde{K}^0(S^2) \\to \\mathbb{Z}$ is an isomorphism (it sends the generator $[H]-[1]$ to $1$).  \n  Since $K^0(S^2) \\cong \\widetilde{K}^0(S^2) \\oplus \\mathbb{Z}$ via the rank map, $\\Phi$ is an isomorphism.\n\nThus  \n$$\n\\boxed{K^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}}.\n$$\n\n## 3. Computation of $K^1(S^2)$\n\nBy definition, $K^1(S^2) = \\widetilde{K}^0(\\Sigma S^2)$. The reduced suspension $\\Sigma S^2$ is homeomorphic to $S^3$.  \nWe therefore compute $\\widetilde{K}^0(S^3)$.\n\nAgain use a clutching construction: cover $S^3$ by two 3\u2011balls $U'$ and $V'$ whose intersection retracts onto $S^2$.  \nA vector bundle over $S^3$ is determined by a transition map  \n$$\nf : S^2 \\to GL_n(\\mathbb{C}),\n$$  \nwith isomorphism classes corresponding to homotopy classes $[f] \\in \\pi_2(GL_n(\\mathbb{C}))$.\n\nBecause $GL_n(\\mathbb{C}) \\simeq U(n)$, we examine $\\pi_2(U(n))$.  \nFrom the fibration $U(n-1) \\to U(n) \\to S^{2n-1}$ and the fact that  \n\n* $\\pi_2(S^{2n-1}) = 0$ for all $n\\ge 1$,  \n* $\\pi_2(U(1)) = \\pi_2(S^1) = 0$,  \n\nan induction shows $\\pi_2(U(n)) = 0$ for every $n$.  \nHence every vector bundle over $S^3$ is trivial.\n\nConsequently, the monoid of vector bundles on $S^3$ is $\\mathbb{N}$ (rank), its Grothendieck group is $\\mathbb{Z}$, and the rank map $K^0(S^3) \\to \\mathbb{Z}$ is an isomorphism.  \nTherefore the reduced K\u2011theory vanishes:  \n$$\n\\widetilde{K}^0(S^3) = 0.\n$$  \nThus  \n$$\n\\boxed{K^1(S^2) = 0}.\n$$\n\n## 4. Conclusion\n\nThe complex K\u2011theory groups of the 2\u2011sphere are  \n\n$$\nK^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}, \\qquad\nK^1(S^2) = 0.\n$$\n\nThis result is consistent with Bott periodicity, which gives $K^0(S^{2n}) \\cong \\mathbb{Z}\\oplus\\mathbb{Z}$ and $K^1(S^{2n}) = 0$ for $n\\ge 1$.",
        "raw_answer": "We compute the complex topological K\u2011theory groups \\(K^0(S^2)\\) and \\(K^1(S^2)\\) of the 2\u2011sphere.\n\n## 1. Definitions and preliminaries\n\nFor a compact Hausdorff space \\(X\\),  \n\n* \\(K^0(X)\\) is the Grothendieck group of complex vector bundles over \\(X\\).  \n  If \\(X\\) is connected, there is a split exact sequence  \n  \\[\n  0 \\longrightarrow \\widetilde{K}^0(X) \\longrightarrow K^0(X) \\xrightarrow{\\;\\operatorname{rk}\\;} \\mathbb{Z} \\longrightarrow 0,\n  \\]\n  where \\(\\widetilde{K}^0(X)\\) is the reduced K\u2011theory (virtual bundles of rank zero).\n\n* \\(K^1(X) = \\widetilde{K}^0(\\Sigma X)\\), where \\(\\Sigma X\\) is the reduced suspension.  \n  Equivalently, \\(K^1(X) = [X, U]\\) with \\(U = \\varinjlim U(n)\\) the infinite unitary group.\n\n## 2. Computation of \\(K^0(S^2)\\)\n\nWe use the **clutching construction**.  \n\nCover \\(S^2\\) by two contractible open sets, e.g.  \n\\(U = S^2\\setminus\\{\\text{south pole}\\}\\) and \\(V = S^2\\setminus\\{\\text{north pole}\\}\\).  \nThen \\(U \\cap V\\) retracts onto the equator \\(S^1\\).\n\nBecause \\(U\\) and \\(V\\) are contractible, any complex vector bundle \\(E\\) over \\(S^2\\) is trivial when restricted to \\(U\\) and to \\(V\\).  \nChoose trivialisations \\(\\phi_U : E|_U \\to U\\times\\mathbb{C}^n\\) and \\(\\phi_V : E|_V \\to V\\times\\mathbb{C}^n\\).  \nOn \\(U\\cap V\\) the transition map  \n\\[\ng = \\phi_U \\circ \\phi_V^{-1} : U\\cap V \\to GL_n(\\mathbb{C})\n\\]  \nis continuous. Up to homotopy, \\(g\\) is determined by its restriction to \\(S^1\\).  \nChanging the trivialisations alters \\(g\\) by a homotopy, so the isomorphism class of \\(E\\) depends only on the homotopy class \\([g] \\in [S^1, GL_n(\\mathbb{C})] = \\pi_1(GL_n(\\mathbb{C}))\\).  \nThis gives a bijection  \n\\[\n\\operatorname{Vect}_n(S^2) \\;\\cong\\; \\pi_1(GL_n(\\mathbb{C})).\n\\]\n\nNow \\(GL_n(\\mathbb{C})\\) deformation retracts onto \\(U(n)\\).  \nThe determinant \\(\\det : U(n) \\to U(1)\\) is a fibration with fibre \\(SU(n)\\).  \nSince \\(SU(n)\\) is simply connected for \\(n\\ge 2\\) (and \\(SU(1)\\) is trivial), the long exact homotopy sequence yields  \n\\[\n\\pi_1(U(n)) \\cong \\pi_1(U(1)) \\cong \\mathbb{Z} \\qquad\\text{for all } n\\ge 1.\n\\]  \nHence \\(\\pi_1(GL_n(\\mathbb{C})) \\cong \\mathbb{Z}\\) as well.  \n\nUnder this correspondence, the integer associated to a bundle \\(E\\) is its **first Chern class**  \n\\[\nc_1(E) \\in H^2(S^2;\\mathbb{Z}) \\cong \\mathbb{Z}.\n\\]  \nFor line bundles it is the usual degree; for higher rank bundles one takes \\(c_1(\\det E)\\).  \nIn particular, the Hopf line bundle \\(H\\) corresponds to \\(1 \\in \\mathbb{Z}\\).\n\nThe monoid of vector bundles (under direct sum) therefore satisfies  \n\\[\n[E] \\leftrightarrow (\\operatorname{rk}(E),\\, c_1(E)) \\in \\mathbb{N} \\times \\mathbb{Z},\n\\]  \nand the Grothendieck group \\(K^0(S^2)\\) inherits a homomorphism  \n\\[\n\\Phi : K^0(S^2) \\longrightarrow \\mathbb{Z} \\oplus \\mathbb{Z},\\qquad\n\\Phi([E]-[F]) = \\bigl(\\operatorname{rk}(E)-\\operatorname{rk}(F),\\; c_1(E)-c_1(F)\\bigr).\n\\]  \n\\(\\Phi\\) is well\u2011defined because \\(c_1\\) is additive on exact sequences.\n\n* **Surjectivity**:  \n  \\(\\Phi( [\\text{trivial line bundle }1] ) = (1,0)\\) and  \n  \\(\\Phi( [H] - [1] ) = (0,1)\\).\n\n* **Injectivity**:  \n  The reduced group \\(\\widetilde{K}^0(S^2)\\) consists of virtual bundles of rank zero.  \n  The map \\(c_1 : \\widetilde{K}^0(S^2) \\to \\mathbb{Z}\\) is an isomorphism (it sends the generator \\([H]-[1]\\) to \\(1\\)).  \n  Since \\(K^0(S^2) \\cong \\widetilde{K}^0(S^2) \\oplus \\mathbb{Z}\\) via the rank map, \\(\\Phi\\) is an isomorphism.\n\nThus  \n\\[\n\\boxed{K^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}}.\n\\]\n\n## 3. Computation of \\(K^1(S^2)\\)\n\nBy definition, \\(K^1(S^2) = \\widetilde{K}^0(\\Sigma S^2)\\). The reduced suspension \\(\\Sigma S^2\\) is homeomorphic to \\(S^3\\).  \nWe therefore compute \\(\\widetilde{K}^0(S^3)\\).\n\nAgain use a clutching construction: cover \\(S^3\\) by two 3\u2011balls \\(U'\\) and \\(V'\\) whose intersection retracts onto \\(S^2\\).  \nA vector bundle over \\(S^3\\) is determined by a transition map  \n\\[\nf : S^2 \\to GL_n(\\mathbb{C}),\n\\]  \nwith isomorphism classes corresponding to homotopy classes \\([f] \\in \\pi_2(GL_n(\\mathbb{C}))\\).\n\nBecause \\(GL_n(\\mathbb{C}) \\simeq U(n)\\), we examine \\(\\pi_2(U(n))\\).  \nFrom the fibration \\(U(n-1) \\to U(n) \\to S^{2n-1}\\) and the fact that  \n\n* \\(\\pi_2(S^{2n-1}) = 0\\) for all \\(n\\ge 1\\),  \n* \\(\\pi_2(U(1)) = \\pi_2(S^1) = 0\\),  \n\nan induction shows \\(\\pi_2(U(n)) = 0\\) for every \\(n\\).  \nHence every vector bundle over \\(S^3\\) is trivial.\n\nConsequently, the monoid of vector bundles on \\(S^3\\) is \\(\\mathbb{N}\\) (rank), its Grothendieck group is \\(\\mathbb{Z}\\), and the rank map \\(K^0(S^3) \\to \\mathbb{Z}\\) is an isomorphism.  \nTherefore the reduced K\u2011theory vanishes:  \n\\[\n\\widetilde{K}^0(S^3) = 0.\n\\]  \nThus  \n\\[\n\\boxed{K^1(S^2) = 0}.\n\\]\n\n## 4. Conclusion\n\nThe complex K\u2011theory groups of the 2\u2011sphere are  \n\n\\[\nK^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z}, \\qquad\nK^1(S^2) = 0.\n\\]\n\nThis result is consistent with Bott periodicity, which gives \\(K^0(S^{2n}) \\cong \\mathbb{Z}\\oplus\\mathbb{Z}\\) and \\(K^1(S^{2n}) = 0\\) for \\(n\\ge 1\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Group theory and generalizations\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Group theory and generalizations\nGroup theory is a branch of abstract algebra that studies the symmetric aspects of objects and the transformations that preserve those symmetries. A suitable topic could involve properties of groups, such as subgroup structures, homomorphisms, or specific types of groups like cyclic or symmetric groups.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider a topic like the classification of groups or the study of group homomorphisms. A potential problem could involve determining the number of homomorphisms between two given groups or analyzing the structure of a specific group.\n\n## Step 4: Generate a specific problem\nLet's consider the problem of finding the number of homomorphisms from the cyclic group of order 12, $\\mathbb{Z}_{12}$, to the symmetric group $S_3$. This involves understanding the structure of both groups and applying knowledge about homomorphisms.\n\n## Step 5: State the problem formally\nThe problem can be stated as: \"Let $\\mathbb{Z}_{12}$ be the cyclic group of order 12 and $S_3$ be the symmetric group on 3 elements. Determine the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\"\n\n## Step 6: Provide the solution\nTo solve this, we need to understand that a homomorphism $f: \\mathbb{Z}_{12} \\to S_3$ is determined by $f(1)$, where $1$ is a generator of $\\mathbb{Z}_{12}$. The element $f(1)$ must have an order that divides 12. $S_3$ has elements of orders 1, 2, and 3. We need to count how many elements in $S_3$ have orders that divide 12.\n\n## Step 7: Analyze the elements of $S_3$\n$S_3 = \\{e, (12), (13), (23), (123), (132)\\}$. The identity $e$ has order 1, the transpositions $(12), (13), (23)$ have order 2, and the 3-cycles $(123), (132)$ have order 3. The orders of elements in $S_3$ that divide 12 are 1, 2, and 3.\n\n## Step 8: Count the possible images of $1 \\in \\mathbb{Z}_{12}$\nThere is 1 element of order 1, 3 elements of order 2, and 2 elements of order 3. So, $f(1)$ can be any of these 6 elements because their orders divide 12.\n\n## Step 9: Conclude the number of homomorphisms\nSince $f(1)$ can be any of the 6 elements (1 of order 1, 3 of order 2, and 2 of order 3), there are 6 possible homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\n\n## Step 10: Format the problem and solution according to the required output format\n\nLet $\\mathbb{Z}_{12}$ be the cyclic group of order 12 and $S_3$ be the symmetric group on 3 elements. Determine the number of homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.",
    "run_id": "14",
    "outer_attempt": 1,
    "topic_slug": "group_theory_and_generalizations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution.**  \n\nLet $\\mathbb{Z}_{12} = \\langle a \\mid a^{12}=e \\rangle$ be the cyclic group of order 12, and let $S_3$ be the symmetric group on three elements.  \nA homomorphism $\\varphi : \\mathbb{Z}_{12} \\to S_3$ is completely determined by the image of the generator $a$.  \nWrite $\\varphi(a) = g \\in S_3$. Because $\\varphi(a^{12}) = \\varphi(e) = e$ and also $\\varphi(a^{12}) = g^{12}$, we must have $g^{12} = e$.  \nConversely, if $g \\in S_3$ satisfies $g^{12}=e$, then the map defined by $\\varphi(a^k) = g^k$ for all integers $k$ is a well\u2011defined homomorphism: if $a^k = a^\\ell$ then $k \\equiv \\ell \\pmod{12}$, so $g^k = g^\\ell$ because $g^{12}=e$ ensures that the powers of $g$ depend only on the exponent modulo the order of $g$ (which divides 12).  \n\nThus the number of homomorphisms equals the number of elements of $S_3$ whose order divides 12.\n\nThe group $S_3$ consists of the following six elements:\n\n- Identity $e$ (order 1)\n- Transpositions: $(12),\\, (13),\\, (23)$ (order 2)\n- 3\u2011cycles: $(123),\\, (132)$ (order 3)\n\nAll orders 1, 2, and 3 divide 12. Therefore every element of $S_3$ satisfies the condition $g^{12}=e$.  \n\nHence there are exactly six homomorphisms from $\\mathbb{Z}_{12}$ to $S_3$.\n\n$$\n\\boxed{6}\n$$",
        "raw_answer": "**Solution.**  \n\nLet \\(\\mathbb{Z}_{12} = \\langle a \\mid a^{12}=e \\rangle\\) be the cyclic group of order 12, and let \\(S_3\\) be the symmetric group on three elements.  \nA homomorphism \\(\\varphi : \\mathbb{Z}_{12} \\to S_3\\) is completely determined by the image of the generator \\(a\\).  \nWrite \\(\\varphi(a) = g \\in S_3\\). Because \\(\\varphi(a^{12}) = \\varphi(e) = e\\) and also \\(\\varphi(a^{12}) = g^{12}\\), we must have \\(g^{12} = e\\).  \nConversely, if \\(g \\in S_3\\) satisfies \\(g^{12}=e\\), then the map defined by \\(\\varphi(a^k) = g^k\\) for all integers \\(k\\) is a well\u2011defined homomorphism: if \\(a^k = a^\\ell\\) then \\(k \\equiv \\ell \\pmod{12}\\), so \\(g^k = g^\\ell\\) because \\(g^{12}=e\\) ensures that the powers of \\(g\\) depend only on the exponent modulo the order of \\(g\\) (which divides 12).  \n\nThus the number of homomorphisms equals the number of elements of \\(S_3\\) whose order divides 12.\n\nThe group \\(S_3\\) consists of the following six elements:\n\n- Identity \\(e\\) (order 1)\n- Transpositions: \\((12),\\, (13),\\, (23)\\) (order 2)\n- 3\u2011cycles: \\((123),\\, (132)\\) (order 3)\n\nAll orders 1, 2, and 3 divide 12. Therefore every element of \\(S_3\\) satisfies the condition \\(g^{12}=e\\).  \n\nHence there are exactly six homomorphisms from \\(\\mathbb{Z}_{12}\\) to \\(S_3\\).\n\n\\[\n\\boxed{6}\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $G$ be a connected Lie group with Lie algebra $\\mathfrak{g}$. Suppose that $\\mathfrak{g}$ is simple and that $G$ has a discrete subgroup $\\Gamma$ such that $G/\\Gamma$ is compact. Prove that $\\Gamma$ is contained in the center of $G$ if and only if the adjoint representation of $G$ on $\\mathfrak{g}$ descends to a representation of $G/\\Gamma$.",
    "run_id": "15",
    "outer_attempt": 1,
    "topic_slug": "topological_groups_and_lie_groups",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove the equivalence using basic properties of the adjoint representation and the center of a connected Lie group. The hypotheses that $\\mathfrak{g}$ is simple and $G/\\Gamma$ is compact are not needed for the argument; they may be present for contextual reasons.\n\n### Notation and preliminaries\n- $G$ is a connected Lie group with Lie algebra $\\mathfrak{g}$.\n- $\\operatorname{Ad}:G\\to \\operatorname{GL}(\\mathfrak{g})$ denotes the adjoint representation: $\\operatorname{Ad}(g) = d(C_g)_e$, where $C_g(h)=ghg^{-1}$.\n- $\\Gamma\\le G$ is a discrete subgroup such that $G/\\Gamma$ is compact. Moreover, the statement \u201cthe adjoint representation descends to a representation of $G/\\Gamma$\u201d means that there exists a group homomorphism $\\rho:G/\\Gamma\\to\\operatorname{GL}(\\mathfrak{g})$ satisfying $\\rho\\circ\\pi = \\operatorname{Ad}$, where $\\pi:G\\to G/\\Gamma$ is the canonical projection. This implicitly requires $G/\\Gamma$ to be a group, i.e., $\\Gamma$ must be normal. (As will be seen, the condition itself forces $\\Gamma$ to be central, hence normal, so no extra assumption is needed.)\n\n### Lemma: $\\ker\\operatorname{Ad} = Z(G)$ for connected $G$\n*Proof.*  \nIf $g\\in Z(G)$, then $C_g=\\mathrm{id}_G$, so $\\operatorname{Ad}(g)=d(C_g)_e = \\mathrm{id}_{\\mathfrak{g}}$.  \nConversely, suppose $\\operatorname{Ad}(g)=\\mathrm{id}$. Then for every $X\\in\\mathfrak{g}$ and $t\\in\\mathbb{R}$,\n$$\ng\\exp(tX)g^{-1} = \\exp(t\\operatorname{Ad}(g)X) = \\exp(tX).\n$$\nThus $g$ commutes with all elements of the form $\\exp(X)$. Since $G$ is connected, the set $\\{\\exp(X):X\\in\\mathfrak{g}\\}$ generates $G$, so $g$ commutes with every element of $G$, i.e., $g\\in Z(G)$. \u220e\n\n### Proof of the equivalence\n\n#### ($\\Rightarrow$) Assume $\\Gamma\\subseteq Z(G)$.\nBecause $\\Gamma\\subseteq Z(G)=\\ker\\operatorname{Ad}$, we have $\\operatorname{Ad}(\\gamma)=\\mathrm{id}$ for all $\\gamma\\in\\Gamma$. Define a map\n$$\n\\rho:G/\\Gamma\\to\\operatorname{GL}(\\mathfrak{g}),\\qquad \\rho(g\\Gamma) = \\operatorname{Ad}(g).\n$$\n- **Well\u2011defined:** If $g_1\\Gamma = g_2\\Gamma$, then $g_2^{-1}g_1\\in\\Gamma\\subseteq\\ker\\operatorname{Ad}$, so $\\operatorname{Ad}(g_2^{-1}g_1)=\\mathrm{id}$, hence $\\operatorname{Ad}(g_1)=\\operatorname{Ad}(g_2)\\operatorname{Ad}(g_2^{-1}g_1)=\\operatorname{Ad}(g_2)$.\n- **Homomorphism:** Since $\\Gamma$ is central, it is normal, so $G/\\Gamma$ is a group. For any $g,h\\in G$,\n$$\n\\rho\\big((g\\Gamma)(h\\Gamma)\\big) = \\rho(gh\\Gamma) = \\operatorname{Ad}(gh) = \\operatorname{Ad}(g)\\operatorname{Ad}(h) = \\rho(g\\Gamma)\\,\\rho(h\\Gamma).\n$$\n- **Lifts $\\operatorname{Ad}$:** $\\rho(\\pi(g)) = \\rho(g\\Gamma) = \\operatorname{Ad}(g)$.\nThus $\\operatorname{Ad}$ descends to a representation $\\rho$ of $G/\\Gamma$.\n\n#### ($\\Leftarrow$) Assume $\\operatorname{Ad}$ descends to a representation of $G/\\Gamma$.\nBy definition there exists a homomorphism $\\rho:G/\\Gamma\\to\\operatorname{GL}(\\mathfrak{g})$ with $\\rho\\circ\\pi = \\operatorname{Ad}$. For any $\\gamma\\in\\Gamma$,\n$$\n\\pi(\\gamma) = \\gamma\\Gamma = e\\Gamma = \\pi(e),\n$$\nso\n$$\n\\operatorname{Ad}(\\gamma) = \\rho(\\pi(\\gamma)) = \\rho(\\pi(e)) = \\rho(e_{G/\\Gamma}) = \\mathrm{id}_{\\mathfrak{g}}.\n$$\nHence $\\gamma\\in\\ker\\operatorname{Ad} = Z(G)$. Therefore $\\Gamma\\subseteq Z(G)$.\n\n### Conclusion\nWe have shown both implications, using only the connectedness of $G$ (for the lemma) and the fact that $G/\\Gamma$ is a group (which is inherent in the notion of a representation of $G/\\Gamma$). The simplicity of $\\mathfrak{g}$ and compactness of $G/\\Gamma$ are not required for this logical equivalence. \u220e",
        "raw_answer": "We prove the equivalence using basic properties of the adjoint representation and the center of a connected Lie group. The hypotheses that $\\mathfrak{g}$ is simple and $G/\\Gamma$ is compact are not needed for the argument; they may be present for contextual reasons.\n\n### Notation and preliminaries\n- $G$ is a connected Lie group with Lie algebra $\\mathfrak{g}$.\n- $\\operatorname{Ad}:G\\to \\operatorname{GL}(\\mathfrak{g})$ denotes the adjoint representation: $\\operatorname{Ad}(g) = d(C_g)_e$, where $C_g(h)=ghg^{-1}$.\n- $\\Gamma\\le G$ is a discrete subgroup such that $G/\\Gamma$ is compact. Moreover, the statement \u201cthe adjoint representation descends to a representation of $G/\\Gamma$\u201d means that there exists a group homomorphism $\\rho:G/\\Gamma\\to\\operatorname{GL}(\\mathfrak{g})$ satisfying $\\rho\\circ\\pi = \\operatorname{Ad}$, where $\\pi:G\\to G/\\Gamma$ is the canonical projection. This implicitly requires $G/\\Gamma$ to be a group, i.e., $\\Gamma$ must be normal. (As will be seen, the condition itself forces $\\Gamma$ to be central, hence normal, so no extra assumption is needed.)\n\n### Lemma: $\\ker\\operatorname{Ad} = Z(G)$ for connected $G$\n*Proof.*  \nIf $g\\in Z(G)$, then $C_g=\\mathrm{id}_G$, so $\\operatorname{Ad}(g)=d(C_g)_e = \\mathrm{id}_{\\mathfrak{g}}$.  \nConversely, suppose $\\operatorname{Ad}(g)=\\mathrm{id}$. Then for every $X\\in\\mathfrak{g}$ and $t\\in\\mathbb{R}$,\n\\[\ng\\exp(tX)g^{-1} = \\exp(t\\operatorname{Ad}(g)X) = \\exp(tX).\n\\]\nThus $g$ commutes with all elements of the form $\\exp(X)$. Since $G$ is connected, the set $\\{\\exp(X):X\\in\\mathfrak{g}\\}$ generates $G$, so $g$ commutes with every element of $G$, i.e., $g\\in Z(G)$. \u220e\n\n### Proof of the equivalence\n\n#### ($\\Rightarrow$) Assume $\\Gamma\\subseteq Z(G)$.\nBecause $\\Gamma\\subseteq Z(G)=\\ker\\operatorname{Ad}$, we have $\\operatorname{Ad}(\\gamma)=\\mathrm{id}$ for all $\\gamma\\in\\Gamma$. Define a map\n\\[\n\\rho:G/\\Gamma\\to\\operatorname{GL}(\\mathfrak{g}),\\qquad \\rho(g\\Gamma) = \\operatorname{Ad}(g).\n\\]\n- **Well\u2011defined:** If $g_1\\Gamma = g_2\\Gamma$, then $g_2^{-1}g_1\\in\\Gamma\\subseteq\\ker\\operatorname{Ad}$, so $\\operatorname{Ad}(g_2^{-1}g_1)=\\mathrm{id}$, hence $\\operatorname{Ad}(g_1)=\\operatorname{Ad}(g_2)\\operatorname{Ad}(g_2^{-1}g_1)=\\operatorname{Ad}(g_2)$.\n- **Homomorphism:** Since $\\Gamma$ is central, it is normal, so $G/\\Gamma$ is a group. For any $g,h\\in G$,\n\\[\n\\rho\\big((g\\Gamma)(h\\Gamma)\\big) = \\rho(gh\\Gamma) = \\operatorname{Ad}(gh) = \\operatorname{Ad}(g)\\operatorname{Ad}(h) = \\rho(g\\Gamma)\\,\\rho(h\\Gamma).\n\\]\n- **Lifts $\\operatorname{Ad}$:** $\\rho(\\pi(g)) = \\rho(g\\Gamma) = \\operatorname{Ad}(g)$.\nThus $\\operatorname{Ad}$ descends to a representation $\\rho$ of $G/\\Gamma$.\n\n#### ($\\Leftarrow$) Assume $\\operatorname{Ad}$ descends to a representation of $G/\\Gamma$.\nBy definition there exists a homomorphism $\\rho:G/\\Gamma\\to\\operatorname{GL}(\\mathfrak{g})$ with $\\rho\\circ\\pi = \\operatorname{Ad}$. For any $\\gamma\\in\\Gamma$,\n\\[\n\\pi(\\gamma) = \\gamma\\Gamma = e\\Gamma = \\pi(e),\n\\]\nso\n\\[\n\\operatorname{Ad}(\\gamma) = \\rho(\\pi(\\gamma)) = \\rho(\\pi(e)) = \\rho(e_{G/\\Gamma}) = \\mathrm{id}_{\\mathfrak{g}}.\n\\]\nHence $\\gamma\\in\\ker\\operatorname{Ad} = Z(G)$. Therefore $\\Gamma\\subseteq Z(G)$.\n\n### Conclusion\nWe have shown both implications, using only the connectedness of $G$ (for the lemma) and the fact that $G/\\Gamma$ is a group (which is inherent in the notion of a representation of $G/\\Gamma$). The simplicity of $\\mathfrak{g}$ and compactness of $G/\\Gamma$ are not required for this logical equivalence. \u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the requirements for the problem.\nThe task is to generate a challenging but solvable mathematics problem in the domain of real functions, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Determine the specific area within real functions to focus on.\nGiven the broad domain of real functions, we can consider various aspects such as differentiation, integration, functional equations, or properties of specific types of functions (e.g., continuous, differentiable, integrable).\n\n## Step 3: Choose a specific topic within real functions that can be used to create a challenging problem.\nLet's consider the topic of functional equations, which involves finding a function that satisfies a given equation involving the function and its inputs.\n\n## Step 4: Generate a challenging problem in the chosen topic.\nConsider the functional equation $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for $x, y \\in \\mathbb{R}$, where $f: \\mathbb{R} \\to \\mathbb{R}$. The task is to find all $f$ that satisfy this equation.\n\n## Step 5: Ensure the problem is well-posed and meets the quality rubric.\nThe given functional equation is well-defined, and the task is clear. We need to verify that it's non-trivial and solvable.\n\n## Step 6: Provide a solution to the generated problem.\nTo solve $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$, let's first check if there are any obvious solutions. For $y = 0$, we get $f(x) = \\frac{f(x) + f(0)}{1 - f(x)f(0)}$. This simplifies to $f(x)(1 - f(x)f(0)) = f(x) + f(0)$, or $f(x) - f(x)^2f(0) = f(x) + f(0)$, leading to $-f(x)^2f(0) = f(0)$. If $f(0) \\neq 0$, this gives $f(x)^2 = -1$ for all $x$, which is impossible for real-valued $f$. Thus, $f(0) = 0$.\n\n## Step 7: Continue solving the functional equation.\nSetting $y = x$, we have $f(2x) = \\frac{2f(x)}{1 - f(x)^2}$. This is a useful relation but let's first explore the derivative of $f$ if it exists. Assuming $f$ is differentiable, differentiating both sides with respect to $y$ and then setting $y = 0$ gives $f'(x) = \\frac{f'(0)(1 + f(x)^2)}{(1 - f(x)f(0))^2} = f'(0)(1 + f(x)^2)$ because $f(0) = 0$. So, $f'(x) = f'(0)(1 + f(x)^2)$.\n\n## Step 8: Solve the differential equation obtained from the functional equation.\nThe differential equation $f'(x) = f'(0)(1 + f(x)^2)$ can be solved by separation of variables: $\\frac{df}{1 + f^2} = f'(0)dx$. Integrating both sides gives $\\arctan(f(x)) = f'(0)x + C$, where $C$ is a constant. Since $f(0) = 0$, we have $C = 0$. Thus, $f(x) = \\tan(f'(0)x)$.\n\n## Step 9: Verify that the solution satisfies the original functional equation.\nSubstituting $f(x) = \\tan(f'(0)x)$ into the original equation: $\\tan(f'(0)(x+y)) = \\frac{\\tan(f'(0)x) + \\tan(f'(0)y)}{1 - \\tan(f'(0)x)\\tan(f'(0)y)}$, which is a known trigonometric identity, thus verifying that $f(x) = \\tan(f'(0)x)$ is a solution.\n\n## Step 10: Check if there are any constraints on $f'(0)$.\nFor $f(x) = \\tan(f'(0)x)$ to be defined for all $x \\in \\mathbb{R}$, $f'(0)$ must be $0$, otherwise, $f(x)$ will have discontinuities. If $f'(0) = 0$, then $f(x) = 0$ for all $x$, which is indeed a solution.\n\n## Step 11: Formulate the final problem and solution.\nLet's formulate the problem: \"Find all $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for all $x, y \\in \\mathbb{R}$.\"\n\n\nFind all $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy $f(x + y) = \\frac{f(x) + f(y)}{1 - f(x)f(y)}$ for all $x, y \\in \\mathbb{R}$.",
    "run_id": "16",
    "outer_attempt": 1,
    "topic_slug": "real_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The question as stated is **ill\u2011posed**. It asks to find all functions $f:\\mathbb{R}\\to\\mathbb{R}$ satisfying  \n$$\nf(x+y)=\\frac{f(x)+f(y)}{1-f(x)f(y)}\\qquad\\forall x,y\\in\\mathbb{R},\n$$  \nbut does **not** impose any regularity conditions (such as continuity, measurability, boundedness on an interval, etc.). Without such conditions the solution set is enormous and cannot be described in a simple closed form; any attempt to \u201cfind all\u201d would require an unmanageable classification via the axiom of choice.\n\n### Why the question is ill\u2011posed\n\n1. **Trivial necessary conditions**  \n   From the equation one easily deduces $f(0)=0$ and $f(-x)=-f(x)$. However, these are far from sufficient.\n\n2. **Existence of exotic solutions**  \n   Let $A:\\mathbb{R}\\to\\mathbb{R}$ be any additive function (i.e. $A(x+y)=A(x)+A(y)$ for all $x,y$) whose image is contained in a $\\mathbb{Q}$-linear subspace that avoids the set  \n   $$\n   S=\\bigl\\{\\tfrac{\\pi}{2}+k\\pi\\mid k\\in\\mathbb{Z}\\bigr\\}.\n   $$  \n   (For example, take a Hamel basis of $\\mathbb{R}$ over $\\mathbb{Q}$, pick one basis element $e_0$, and define $A(x)$ as the coefficient of $e_0$ in the representation of $x$; then $A(x)\\in\\mathbb{Q}$ for all $x$, and $\\mathbb{Q}\\cap S=\\varnothing$.)  \n   Then the function  \n   $$\n   f(x)=\\tan(A(x))\n   $$  \n   is well defined on $\\mathbb{R}$ (because $A(x)\\notin S$) and satisfies the given functional equation. Indeed,  \n   $$\n   f(x+y)=\\tan(A(x+y))=\\tan(A(x)+A(y))=\\frac{\\tan(A(x))+\\tan(A(y))}{1-\\tan(A(x))\\tan(A(y))}=\\frac{f(x)+f(y)}{1-f(x)f(y)}.\n   $$  \n   Moreover, the denominator never vanishes because $A(x)+A(y)=A(x+y)\\notin S$.\n\n   Such additive functions exist in ZFC but are highly pathological (discontinuous, non\u2011measurable, unbounded on every interval). Consequently there are infinitely many non\u2011zero solutions, and they cannot be expressed by elementary formulas.\n\n3. **Lack of a simple classification**  \n   The most general description of all solutions is:  \n   *Let $\\varphi(x)=\\arctan(f(x))\\in(-\\pi/2,\\pi/2)$. Then the map $x\\mapsto\\varphi(x)+\\pi\\mathbb{Z}$ is a group homomorphism from $\\mathbb{R}$ into $\\mathbb{R}/\\pi\\mathbb{Z}$. Conversely, any such homomorphism (with the additional requirement that the chosen representatives avoid $S$) yields a solution.*  \n   This characterization relies on the axiom of choice and does not provide a concrete list of functions. Hence the problem is **underspecified** \u2013 it misses necessary constraints that would restrict the solutions to a tractable set.\n\n### How to make the question well\u2011posed\n\nAdd a natural regularity assumption, for example:\n\n* \u201cFind all **continuous** functions $f:\\mathbb{R}\\to\\mathbb{R}$ satisfying \u2026\u201d  \n* \u201cFind all **measurable** functions \u2026\u201d  \n* \u201cFind all functions **bounded on some interval** \u2026\u201d\n\nUnder any such condition the only solution is the trivial one $f(x)\\equiv 0$. (Sketch: continuity forces the additive function $A$ to be linear, $A(x)=cx$; then $f(x)=\\tan(cx)$ must be defined for all real $x$, which forces $c=0$.)\n\n---\n\n**Conclusion:** The original question is ill\u2011posed due to missing constraints. It cannot be answered in a meaningful elementary way without further assumptions on $f$.",
        "raw_answer": "The question as stated is **ill\u2011posed**. It asks to find all functions \\(f:\\mathbb{R}\\to\\mathbb{R}\\) satisfying  \n\\[\nf(x+y)=\\frac{f(x)+f(y)}{1-f(x)f(y)}\\qquad\\forall x,y\\in\\mathbb{R},\n\\]  \nbut does **not** impose any regularity conditions (such as continuity, measurability, boundedness on an interval, etc.). Without such conditions the solution set is enormous and cannot be described in a simple closed form; any attempt to \u201cfind all\u201d would require an unmanageable classification via the axiom of choice.\n\n### Why the question is ill\u2011posed\n\n1. **Trivial necessary conditions**  \n   From the equation one easily deduces \\(f(0)=0\\) and \\(f(-x)=-f(x)\\). However, these are far from sufficient.\n\n2. **Existence of exotic solutions**  \n   Let \\(A:\\mathbb{R}\\to\\mathbb{R}\\) be any additive function (i.e. \\(A(x+y)=A(x)+A(y)\\) for all \\(x,y\\)) whose image is contained in a \\(\\mathbb{Q}\\)-linear subspace that avoids the set  \n   \\[\n   S=\\bigl\\{\\tfrac{\\pi}{2}+k\\pi\\mid k\\in\\mathbb{Z}\\bigr\\}.\n   \\]  \n   (For example, take a Hamel basis of \\(\\mathbb{R}\\) over \\(\\mathbb{Q}\\), pick one basis element \\(e_0\\), and define \\(A(x)\\) as the coefficient of \\(e_0\\) in the representation of \\(x\\); then \\(A(x)\\in\\mathbb{Q}\\) for all \\(x\\), and \\(\\mathbb{Q}\\cap S=\\varnothing\\).)  \n   Then the function  \n   \\[\n   f(x)=\\tan(A(x))\n   \\]  \n   is well defined on \\(\\mathbb{R}\\) (because \\(A(x)\\notin S\\)) and satisfies the given functional equation. Indeed,  \n   \\[\n   f(x+y)=\\tan(A(x+y))=\\tan(A(x)+A(y))=\\frac{\\tan(A(x))+\\tan(A(y))}{1-\\tan(A(x))\\tan(A(y))}=\\frac{f(x)+f(y)}{1-f(x)f(y)}.\n   \\]  \n   Moreover, the denominator never vanishes because \\(A(x)+A(y)=A(x+y)\\notin S\\).\n\n   Such additive functions exist in ZFC but are highly pathological (discontinuous, non\u2011measurable, unbounded on every interval). Consequently there are infinitely many non\u2011zero solutions, and they cannot be expressed by elementary formulas.\n\n3. **Lack of a simple classification**  \n   The most general description of all solutions is:  \n   *Let \\(\\varphi(x)=\\arctan(f(x))\\in(-\\pi/2,\\pi/2)\\). Then the map \\(x\\mapsto\\varphi(x)+\\pi\\mathbb{Z}\\) is a group homomorphism from \\(\\mathbb{R}\\) into \\(\\mathbb{R}/\\pi\\mathbb{Z}\\). Conversely, any such homomorphism (with the additional requirement that the chosen representatives avoid \\(S\\)) yields a solution.*  \n   This characterization relies on the axiom of choice and does not provide a concrete list of functions. Hence the problem is **underspecified** \u2013 it misses necessary constraints that would restrict the solutions to a tractable set.\n\n### How to make the question well\u2011posed\n\nAdd a natural regularity assumption, for example:\n\n* \u201cFind all **continuous** functions \\(f:\\mathbb{R}\\to\\mathbb{R}\\) satisfying \u2026\u201d  \n* \u201cFind all **measurable** functions \u2026\u201d  \n* \u201cFind all functions **bounded on some interval** \u2026\u201d\n\nUnder any such condition the only solution is the trivial one \\(f(x)\\equiv 0\\). (Sketch: continuity forces the additive function \\(A\\) to be linear, \\(A(x)=cx\\); then \\(f(x)=\\tan(cx)\\) must be defined for all real \\(x\\), which forces \\(c=0\\).)\n\n---\n\n**Conclusion:** The original question is ill\u2011posed due to missing constraints. It cannot be answered in a meaningful elementary way without further assumptions on \\(f\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $f: [0,1] \\to \\mathbb{R}$ be a bounded measurable function. Prove that $\\lim_{n \\to \\infty} \\int_{0}^{1} f(x) \\sin(nx) dx = 0$.",
    "run_id": "17",
    "outer_attempt": 1,
    "topic_slug": "measure_and_integration",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove the statement in several steps, using only basic properties of the Lebesgue integral and measure theory.\n\n---\n\n### Step 1. Integral over a single interval\n\nFor any interval $[a,b]\\subseteq[0,1]$ we have\n\n$$\n\\int_a^b \\sin(nx)\\,dx = \\frac{\\cos(na)-\\cos(nb)}{n} \\;\\longrightarrow\\; 0 \\quad\\text{as } n\\to\\infty.\n$$\n\n---\n\n### Step 2. Finite unions of intervals\n\nIf $U = \\bigcup_{i=1}^k I_i$ is a finite union of disjoint intervals, then by linearity\n\n$$\n\\int_U \\sin(nx)\\,dx = \\sum_{i=1}^k \\int_{I_i} \\sin(nx)\\,dx \\;\\longrightarrow\\; 0.\n$$\n\n---\n\n### Step 3. Extension to an arbitrary measurable set\n\nLet $E\\subseteq[0,1]$ be Lebesgue measurable. We show that $\\int_E \\sin(nx)\\,dx\\to 0$.\n\nGiven $\\varepsilon>0$, by the regularity of Lebesgue measure (or because finite unions of intervals are dense in the measure algebra) there exists a finite union of intervals $U\\subseteq[0,1]$ such that\n\n$$\nm(E\\triangle U) < \\varepsilon,\n$$\n\nwhere $E\\triangle U = (E\\setminus U)\\cup(U\\setminus E)$ denotes the symmetric difference. Then\n\n$$\n\\biggl|\\int_E \\sin(nx)\\,dx - \\int_U \\sin(nx)\\,dx\\biggr|\n\\le \\int_{E\\triangle U} |\\sin(nx)|\\,dx\n\\le m(E\\triangle U) < \\varepsilon.\n$$\n\nBy Step\u202f2, $\\int_U \\sin(nx)\\,dx\\to0$. Hence there exists $N$ such that for all $n\\ge N$,\n\n$$\n\\biggl|\\int_U \\sin(nx)\\,dx\\biggr| < \\varepsilon.\n$$\n\nConsequently, for $n\\ge N$,\n\n$$\n\\biggl|\\int_E \\sin(nx)\\,dx\\biggr|\n\\le \\biggl|\\int_U \\sin(nx)\\,dx\\biggr| + \\varepsilon < 2\\varepsilon.\n$$\n\nSince $\\varepsilon$ was arbitrary, $\\int_E \\sin(nx)\\,dx\\to0$.\n\n---\n\n### Step 4. Simple functions\n\nLet $\\psi = \\sum_{i=1}^m c_i\\,\\chi_{E_i}$ be a simple function, where the sets $E_i\\subseteq[0,1]$ are measurable and pairwise disjoint. Then\n\n$$\n\\int_0^1 \\psi(x)\\sin(nx)\\,dx\n= \\sum_{i=1}^m c_i \\int_{E_i} \\sin(nx)\\,dx \\;\\longrightarrow\\; 0,\n$$\n\nbecause each term tends to $0$ by Step\u202f3 and the sum is finite.\n\n---\n\n### Step 5. Uniform approximation of $f$ by a simple function\n\nSince $f$ is bounded, set $M = \\sup_{x\\in[0,1]}|f(x)|$. Fix $\\varepsilon>0$. Partition the interval $[-M,M]$ into subintervals of length $\\varepsilon$, say $J_1,\\dots,J_k$. Define\n\n$$\n\\psi(x) = \\inf J_i \\quad\\text{whenever } f(x)\\in J_i\n$$\n\n(if $f(x)$ lies exactly on a boundary, assign it to either adjacent interval \u2013 the bound below still holds). Because $f$ is measurable, each set $f^{-1}(J_i)$ is measurable, so $\\psi$ is a simple function. Moreover, for every $x$,\n\n$$\n|f(x)-\\psi(x)|\\le \\varepsilon,\n$$\n\nhence\n\n$$\n\\int_0^1 |f(x)-\\psi(x)|\\,dx \\le \\varepsilon.\n$$\n\n---\n\n### Step 6. Conclusion\n\nWrite\n\n$$\n\\biggl|\\int_0^1 f(x)\\sin(nx)\\,dx\\biggr|\n\\le \\biggl|\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\biggr|\n+ \\int_0^1 |f(x)-\\psi(x)||\\sin(nx)|\\,dx.\n$$\n\nThe second term is bounded by $\\int_0^1 |f(x)-\\psi(x)|\\,dx \\le \\varepsilon$ because $|\\sin(nx)|\\le 1$. By Step\u202f4, the first term tends to $0$ as $n\\to\\infty$. Therefore there exists $N$ such that for all $n\\ge N$,\n\n$$\n\\biggl|\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\biggr| < \\varepsilon.\n$$\n\nThus for $n\\ge N$,\n\n$$\n\\biggl|\\int_0^1 f(x)\\sin(nx)\\,dx\\biggr| < 2\\varepsilon.\n$$\n\nSince $\\varepsilon>0$ was arbitrary, we obtain\n\n$$\n\\lim_{n\\to\\infty} \\int_0^1 f(x)\\sin(nx)\\,dx = 0.\n$$\n\n\u220e",
        "raw_answer": "We prove the statement in several steps, using only basic properties of the Lebesgue integral and measure theory.\n\n---\n\n### Step 1. Integral over a single interval\n\nFor any interval \\([a,b]\\subseteq[0,1]\\) we have\n\n\\[\n\\int_a^b \\sin(nx)\\,dx = \\frac{\\cos(na)-\\cos(nb)}{n} \\;\\longrightarrow\\; 0 \\quad\\text{as } n\\to\\infty.\n\\]\n\n---\n\n### Step 2. Finite unions of intervals\n\nIf \\(U = \\bigcup_{i=1}^k I_i\\) is a finite union of disjoint intervals, then by linearity\n\n\\[\n\\int_U \\sin(nx)\\,dx = \\sum_{i=1}^k \\int_{I_i} \\sin(nx)\\,dx \\;\\longrightarrow\\; 0.\n\\]\n\n---\n\n### Step 3. Extension to an arbitrary measurable set\n\nLet \\(E\\subseteq[0,1]\\) be Lebesgue measurable. We show that \\(\\int_E \\sin(nx)\\,dx\\to 0\\).\n\nGiven \\(\\varepsilon>0\\), by the regularity of Lebesgue measure (or because finite unions of intervals are dense in the measure algebra) there exists a finite union of intervals \\(U\\subseteq[0,1]\\) such that\n\n\\[\nm(E\\triangle U) < \\varepsilon,\n\\]\n\nwhere \\(E\\triangle U = (E\\setminus U)\\cup(U\\setminus E)\\) denotes the symmetric difference. Then\n\n\\[\n\\biggl|\\int_E \\sin(nx)\\,dx - \\int_U \\sin(nx)\\,dx\\biggr|\n\\le \\int_{E\\triangle U} |\\sin(nx)|\\,dx\n\\le m(E\\triangle U) < \\varepsilon.\n\\]\n\nBy Step\u202f2, \\(\\int_U \\sin(nx)\\,dx\\to0\\). Hence there exists \\(N\\) such that for all \\(n\\ge N\\),\n\n\\[\n\\biggl|\\int_U \\sin(nx)\\,dx\\biggr| < \\varepsilon.\n\\]\n\nConsequently, for \\(n\\ge N\\),\n\n\\[\n\\biggl|\\int_E \\sin(nx)\\,dx\\biggr|\n\\le \\biggl|\\int_U \\sin(nx)\\,dx\\biggr| + \\varepsilon < 2\\varepsilon.\n\\]\n\nSince \\(\\varepsilon\\) was arbitrary, \\(\\int_E \\sin(nx)\\,dx\\to0\\).\n\n---\n\n### Step 4. Simple functions\n\nLet \\(\\psi = \\sum_{i=1}^m c_i\\,\\chi_{E_i}\\) be a simple function, where the sets \\(E_i\\subseteq[0,1]\\) are measurable and pairwise disjoint. Then\n\n\\[\n\\int_0^1 \\psi(x)\\sin(nx)\\,dx\n= \\sum_{i=1}^m c_i \\int_{E_i} \\sin(nx)\\,dx \\;\\longrightarrow\\; 0,\n\\]\n\nbecause each term tends to \\(0\\) by Step\u202f3 and the sum is finite.\n\n---\n\n### Step 5. Uniform approximation of \\(f\\) by a simple function\n\nSince \\(f\\) is bounded, set \\(M = \\sup_{x\\in[0,1]}|f(x)|\\). Fix \\(\\varepsilon>0\\). Partition the interval \\([-M,M]\\) into subintervals of length \\(\\varepsilon\\), say \\(J_1,\\dots,J_k\\). Define\n\n\\[\n\\psi(x) = \\inf J_i \\quad\\text{whenever } f(x)\\in J_i\n\\]\n\n(if \\(f(x)\\) lies exactly on a boundary, assign it to either adjacent interval \u2013 the bound below still holds). Because \\(f\\) is measurable, each set \\(f^{-1}(J_i)\\) is measurable, so \\(\\psi\\) is a simple function. Moreover, for every \\(x\\),\n\n\\[\n|f(x)-\\psi(x)|\\le \\varepsilon,\n\\]\n\nhence\n\n\\[\n\\int_0^1 |f(x)-\\psi(x)|\\,dx \\le \\varepsilon.\n\\]\n\n---\n\n### Step 6. Conclusion\n\nWrite\n\n\\[\n\\biggl|\\int_0^1 f(x)\\sin(nx)\\,dx\\biggr|\n\\le \\biggl|\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\biggr|\n+ \\int_0^1 |f(x)-\\psi(x)||\\sin(nx)|\\,dx.\n\\]\n\nThe second term is bounded by \\(\\int_0^1 |f(x)-\\psi(x)|\\,dx \\le \\varepsilon\\) because \\(|\\sin(nx)|\\le 1\\). By Step\u202f4, the first term tends to \\(0\\) as \\(n\\to\\infty\\). Therefore there exists \\(N\\) such that for all \\(n\\ge N\\),\n\n\\[\n\\biggl|\\int_0^1 \\psi(x)\\sin(nx)\\,dx\\biggr| < \\varepsilon.\n\\]\n\nThus for \\(n\\ge N\\),\n\n\\[\n\\biggl|\\int_0^1 f(x)\\sin(nx)\\,dx\\biggr| < 2\\varepsilon.\n\\]\n\nSince \\(\\varepsilon>0\\) was arbitrary, we obtain\n\n\\[\n\\lim_{n\\to\\infty} \\int_0^1 f(x)\\sin(nx)\\,dx = 0.\n\\]\n\n\u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematics problem in the domain of \"Functions of a complex variable\" along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the domain and requirements\nThe domain is \"Functions of a complex variable.\" This involves complex analysis, including topics like analytic functions, contour integration, and possibly properties of specific functions like the exponential or logarithmic function in the complex plane.\n\n## Step 3: Generate a problem\nTo create a challenging problem, we should consider a topic that requires a good understanding of complex analysis. One such topic is contour integration and the application of Cauchy's Integral Formula or the Residue Theorem.\n\n## Step 4: Formulate the problem\nLet's consider a problem that involves evaluating a contour integral using the Residue Theorem, which is a fundamental technique in complex analysis.\n\n## Step 5: Specify the problem\nThe problem could be: \"Evaluate the integral $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, where the contour $|z| = 2$ is traversed in the positive direction.\"\n\n## Step 6: Provide the solution\nTo solve $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, first identify the singularities of the integrand within the contour $|z| = 2$. The singularities occur at $z = \\pm i$, both of which are inside $|z| = 2$ since $|i| = |-i| = 1 < 2$.\n\n## Step 7: Apply the Residue Theorem\nThe Residue Theorem states that $\\oint_C f(z) dz = 2\\pi i \\sum \\text{Res}(f, z_j)$, where $z_j$ are the singularities enclosed by $C$. We need to calculate the residues at $z = i$ and $z = -i$.\n\n## Step 8: Calculate the residue at $z = i$\nThe residue of $\\frac{e^z}{z^2 + 1}$ at $z = i$ can be found using the formula for simple poles: $\\text{Res}(f, z_0) = \\lim_{z \\to z_0} (z - z_0)f(z)$. So, $\\text{Res}(f, i) = \\lim_{z \\to i} (z - i)\\frac{e^z}{(z - i)(z + i)} = \\lim_{z \\to i} \\frac{e^z}{z + i} = \\frac{e^i}{2i}$.\n\n## Step 9: Calculate the residue at $z = -i$\nSimilarly, $\\text{Res}(f, -i) = \\lim_{z \\to -i} (z + i)\\frac{e^z}{(z + i)(z - i)} = \\lim_{z \\to -i} \\frac{e^z}{z - i} = \\frac{e^{-i}}{-2i}$.\n\n## Step 10: Sum the residues and apply the Residue Theorem\n$\\sum \\text{Res} = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i} = \\sin(1)$, because $e^i - e^{-i} = 2i\\sin(1)$.\n\n## Step 11: Calculate the integral\n$\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz = 2\\pi i \\sin(1)$.\n\n## Step 12: Write the final answer in the required format\n\nEvaluate the integral $\\oint_{|z|=2} \\frac{e^z}{z^2 + 1} dz$, where the contour $|z| = 2$ is traversed in the positive direction.",
    "run_id": "18",
    "outer_attempt": 1,
    "topic_slug": "functions_of_a_complex_variable",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution:**\n\nWe evaluate the contour integral\n$$\nI = \\oint_{|z|=2} \\frac{e^z}{z^2+1}\\,dz,\n$$\nwhere the contour is the circle centered at the origin with radius $2$, traversed counterclockwise (positive direction).\n\nThe integrand $f(z) = \\frac{e^z}{z^2+1}$ is meromorphic on $\\mathbb{C}$. Its singularities occur at the zeros of the denominator:\n$$\nz^2+1 = 0 \\quad\\Longrightarrow\\quad z = i,\\; -i.\n$$\nBecause the denominator has simple zeros and the numerator $e^z$ is nonzero at these points, both singularities are **simple poles**.\n\nCheck whether these poles lie inside the contour $|z|=2$:\n$$\n|i| = 1 < 2,\\qquad |-i| = 1 < 2,\n$$\nso both are enclosed. The contour does not pass through any singularity, hence the integral is well\u2011defined and we may apply the Residue Theorem.\n\n**Residue Theorem.** If $C$ is a positively oriented simple closed contour and $f$ is analytic inside and on $C$ except for finitely many isolated singularities $z_k$ inside $C$, then\n$$\n\\oint_C f(z)\\,dz = 2\\pi i \\sum_k \\operatorname{Res}(f,z_k).\n$$\n\nWe compute the residues at $z=i$ and $z=-i$.\n\n**Residue at $z=i$.** Since the pole is simple,\n$$\n\\operatorname{Res}(f,i) = \\lim_{z\\to i} (z-i)f(z) = \\lim_{z\\to i} (z-i)\\frac{e^z}{(z-i)(z+i)} = \\lim_{z\\to i} \\frac{e^z}{z+i} = \\frac{e^i}{2i}.\n$$\n\n**Residue at $z=-i$.** Similarly,\n$$\n\\operatorname{Res}(f,-i) = \\lim_{z\\to -i} (z+i)f(z) = \\lim_{z\\to -i} (z+i)\\frac{e^z}{(z+i)(z-i)} = \\lim_{z\\to -i} \\frac{e^z}{z-i} = \\frac{e^{-i}}{-2i} = -\\frac{e^{-i}}{2i}.\n$$\n\n(Alternatively, using the formula $\\operatorname{Res}(g/h) = g(z_0)/h'(z_0)$ for a simple pole, with $h(z)=z^2+1$ and $h'(z)=2z$, gives the same results.)\n\nSumming the residues:\n$$\n\\operatorname{Res}(f,i) + \\operatorname{Res}(f,-i) = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i}.\n$$\n\nRecall Euler\u2019s formula: $\\sin\\theta = \\dfrac{e^{i\\theta} - e^{-i\\theta}}{2i}$. With $\\theta = 1$,\n$$\n\\frac{e^i - e^{-i}}{2i} = \\sin(1).\n$$\n\nTherefore, by the Residue Theorem,\n$$\nI = 2\\pi i \\cdot \\sin(1) = 2\\pi i \\sin(1).\n$$\n\n$$\n\\boxed{2\\pi i \\sin(1)}.\n$$",
        "raw_answer": "**Solution:**\n\nWe evaluate the contour integral\n\\[\nI = \\oint_{|z|=2} \\frac{e^z}{z^2+1}\\,dz,\n\\]\nwhere the contour is the circle centered at the origin with radius \\(2\\), traversed counterclockwise (positive direction).\n\nThe integrand \\(f(z) = \\frac{e^z}{z^2+1}\\) is meromorphic on \\(\\mathbb{C}\\). Its singularities occur at the zeros of the denominator:\n\\[\nz^2+1 = 0 \\quad\\Longrightarrow\\quad z = i,\\; -i.\n\\]\nBecause the denominator has simple zeros and the numerator \\(e^z\\) is nonzero at these points, both singularities are **simple poles**.\n\nCheck whether these poles lie inside the contour \\(|z|=2\\):\n\\[\n|i| = 1 < 2,\\qquad |-i| = 1 < 2,\n\\]\nso both are enclosed. The contour does not pass through any singularity, hence the integral is well\u2011defined and we may apply the Residue Theorem.\n\n**Residue Theorem.** If \\(C\\) is a positively oriented simple closed contour and \\(f\\) is analytic inside and on \\(C\\) except for finitely many isolated singularities \\(z_k\\) inside \\(C\\), then\n\\[\n\\oint_C f(z)\\,dz = 2\\pi i \\sum_k \\operatorname{Res}(f,z_k).\n\\]\n\nWe compute the residues at \\(z=i\\) and \\(z=-i\\).\n\n**Residue at \\(z=i\\).** Since the pole is simple,\n\\[\n\\operatorname{Res}(f,i) = \\lim_{z\\to i} (z-i)f(z) = \\lim_{z\\to i} (z-i)\\frac{e^z}{(z-i)(z+i)} = \\lim_{z\\to i} \\frac{e^z}{z+i} = \\frac{e^i}{2i}.\n\\]\n\n**Residue at \\(z=-i\\).** Similarly,\n\\[\n\\operatorname{Res}(f,-i) = \\lim_{z\\to -i} (z+i)f(z) = \\lim_{z\\to -i} (z+i)\\frac{e^z}{(z+i)(z-i)} = \\lim_{z\\to -i} \\frac{e^z}{z-i} = \\frac{e^{-i}}{-2i} = -\\frac{e^{-i}}{2i}.\n\\]\n\n(Alternatively, using the formula \\(\\operatorname{Res}(g/h) = g(z_0)/h'(z_0)\\) for a simple pole, with \\(h(z)=z^2+1\\) and \\(h'(z)=2z\\), gives the same results.)\n\nSumming the residues:\n\\[\n\\operatorname{Res}(f,i) + \\operatorname{Res}(f,-i) = \\frac{e^i}{2i} - \\frac{e^{-i}}{2i} = \\frac{e^i - e^{-i}}{2i}.\n\\]\n\nRecall Euler\u2019s formula: \\(\\sin\\theta = \\dfrac{e^{i\\theta} - e^{-i\\theta}}{2i}\\). With \\(\\theta = 1\\),\n\\[\n\\frac{e^i - e^{-i}}{2i} = \\sin(1).\n\\]\n\nTherefore, by the Residue Theorem,\n\\[\nI = 2\\pi i \\cdot \\sin(1) = 2\\pi i \\sin(1).\n\\]\n\n\\[\n\\boxed{2\\pi i \\sin(1)}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Potential theory, along with a complete and verifiable solution. Potential theory is a branch of mathematics that deals with the study of potentials and their properties, particularly in relation to partial differential equations, especially Laplace's equation.\n\n## Step 2: Identify key concepts in Potential theory\nPotential theory involves the study of harmonic functions, potentials (such as Newtonian or logarithmic potentials), and their applications. Key concepts include the Laplace equation ($\\Delta u = 0$), Poisson's equation ($\\Delta u = f$), and boundary value problems (Dirichlet and Neumann problems).\n\n## Step 3: Formulate a problem\nTo create a challenging problem, we need to involve some of the advanced concepts or techniques from Potential theory. Let's consider a problem involving the Dirichlet problem for the Laplace equation on a specific domain.\n\n## Step 4: Specify the problem\nLet's consider the following problem: \"Let $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.\"\n\n## Step 5: Provide the solution\nTo solve this problem, we can use the Poisson integral formula, which gives the solution to the Dirichlet problem on the unit disk. The Poisson integral formula is given by $u(x) = \\frac{1}{2\\pi} \\int_{\\partial D} \\frac{1 - |x|^2}{|x - y|^2} f(y) ds(y)$, where $f(y)$ is the boundary data.\n\n## Step 6: Apply the Poisson integral formula\nFor $x = (r\\cos\\theta, r\\sin\\theta)$ and $y = (\\cos\\phi, \\sin\\phi)$, we have $|x - y|^2 = r^2 - 2r\\cos(\\theta - \\phi) + 1$ and $ds(y) = d\\phi$. The boundary data is $f(y) = \\log|y - (1,0)| = \\log\\sqrt{2 - 2\\cos\\phi}$. So, $u(x) = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} \\frac{1 - r^2}{r^2 - 2r\\cos(\\theta - \\phi) + 1} \\log\\sqrt{2 - 2\\cos\\phi} d\\phi$.\n\n## Step 7: Simplify the integral\nThe integral can be simplified by recognizing that $\\log\\sqrt{2 - 2\\cos\\phi} = \\log|1 - e^{i\\phi}| = \\log|1 - e^{i\\phi}| = \\Re(\\log(1 - e^{i\\phi}))$. However, directly evaluating this integral is complex and typically involves recognizing it as a special case that can be related to the properties of harmonic functions and the Poisson kernel.\n\n## Step 8: Evaluate the solution using properties of harmonic functions\nFor $x \\in D$, the solution can be found by directly applying properties of harmonic functions and recognizing that the given boundary condition corresponds to a specific harmonic function. The function $u(x) = \\log|x - (1,0)|$ is harmonic in $D$ except at $x = (1,0)$, which is outside $D$ since $|1,0| = 1$ is on $\\partial D$. Thus, we directly check if $u(x)$ satisfies the given boundary condition and is harmonic.\n\n## Step 9: Check if the given boundary data directly provides the solution\nSince $\\log|x - (1,0)|$ is harmonic in $D$ and equals $\\log|y - (1,0)|$ on $\\partial D$, it is the solution to the Dirichlet problem.\n\nThe final answer is: \n\nLet $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.",
    "run_id": "19",
    "outer_attempt": 1,
    "topic_slug": "potential_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The problem as originally stated is ill\u2011posed for two reasons:\n\n1. The boundary condition $u(x)=\\log|x-(1,0)|$ is not defined at the boundary point $(1,0)$ because $\\log 0$ is undefined.\n2. Even if we require the condition only on $\\partial D\\setminus\\{(1,0)\\}$, the solution is not unique. For any constant $c$, the function  \n   $$u_c(x)=\\log|x-(1,0)|+c\\,\\frac{1-|x|^2}{|x-(1,0)|^2}$$  \n   is harmonic in $D$ and equals $\\log|x-(1,0)|$ on $\\partial D\\setminus\\{(1,0)\\}$ (since $1-|x|^2=0$ there). Hence infinitely many solutions exist.\n\nTo obtain a well\u2011posed problem we must add a condition that selects a unique solution. A natural choice, motivated by the behavior of the boundary data, is to require that $u$ does not have a singularity worse than logarithmic at $(1,0)$; precisely, that $u(x)-\\log|x-(1,0)|$ remains bounded as $x\\to(1,0)$ within $D$. Under this condition the problem becomes well\u2011posed and the unique solution is  \n\n$$u(x)=\\log|x-(1,0)|.$$\n\n---\n\n### Verification\n\n**Harmonicity.** For $x\\neq(1,0)$, the function $\\log|x-(1,0)|$ is the real part of the analytic function $\\log(z-1)$ (with $z=x_1+ix_2$ and a branch cut avoiding the unit disk), hence it is harmonic on $\\mathbb{R}^2\\setminus\\{(1,0)\\}$. Since $(1,0)\\notin D$, it is harmonic in $D$.\n\n**Boundary condition.** For every $y\\in\\partial D\\setminus\\{(1,0)\\}$, $u(y)=\\log|y-(1,0)|$ by definition. Moreover, $u$ is continuous on $\\overline{D}\\setminus\\{(1,0)\\}$, so the boundary values are attained as limits.\n\n**Growth condition.** Trivially, $u(x)-\\log|x-(1,0)|=0$, which is bounded.\n\n**Uniqueness.** Suppose $w$ is another harmonic function in $D$ satisfying  \n- $\\displaystyle\\lim_{x\\to y}w(x)=\\log|y-(1,0)|$ for all $y\\in\\partial D\\setminus\\{(1,0)\\}$,  \n- $w(x)-\\log|x-(1,0)|$ bounded as $x\\to(1,0)$.  \n\nDefine $h(x)=w(x)-u(x)$. Then $h$ is harmonic in $D$, bounded (because the difference is bounded near $(1,0)$ and $h\\to0$ on the rest of the boundary), and has radial limit $0$ at almost every boundary point (indeed everywhere except at the single point $(1,0)$). A bounded harmonic function in the unit disk is uniquely determined by its non\u2011tangential limits almost everywhere (Fatou\u2019s theorem). Since those limits are $0$ a.e., the Poisson integral of $0$ forces $h\\equiv0$. Hence $w=u$.\n\nThus, under the stated extra condition, the solution is unique and given by  \n\n$$\\boxed{u(x)=\\log|x-(1,0)|}.$$\n\n---\n\n**Remark.** If one instead interprets the problem in the sense of the Poisson integral (i.e., $u$ is the Poisson integral of the boundary function $\\log|y-(1,0)|$, which is integrable on $\\partial D$), the same formula results because the Poisson integral of that boundary function equals $\\log|x-(1,0)|$ for $|x|<1$.",
        "raw_answer": "The problem as originally stated is ill\u2011posed for two reasons:\n\n1. The boundary condition $u(x)=\\log|x-(1,0)|$ is not defined at the boundary point $(1,0)$ because $\\log 0$ is undefined.\n2. Even if we require the condition only on $\\partial D\\setminus\\{(1,0)\\}$, the solution is not unique. For any constant $c$, the function  \n   $$u_c(x)=\\log|x-(1,0)|+c\\,\\frac{1-|x|^2}{|x-(1,0)|^2}$$  \n   is harmonic in $D$ and equals $\\log|x-(1,0)|$ on $\\partial D\\setminus\\{(1,0)\\}$ (since $1-|x|^2=0$ there). Hence infinitely many solutions exist.\n\nTo obtain a well\u2011posed problem we must add a condition that selects a unique solution. A natural choice, motivated by the behavior of the boundary data, is to require that $u$ does not have a singularity worse than logarithmic at $(1,0)$; precisely, that $u(x)-\\log|x-(1,0)|$ remains bounded as $x\\to(1,0)$ within $D$. Under this condition the problem becomes well\u2011posed and the unique solution is  \n\n$$u(x)=\\log|x-(1,0)|.$$\n\n---\n\n### Verification\n\n**Harmonicity.** For $x\\neq(1,0)$, the function $\\log|x-(1,0)|$ is the real part of the analytic function $\\log(z-1)$ (with $z=x_1+ix_2$ and a branch cut avoiding the unit disk), hence it is harmonic on $\\mathbb{R}^2\\setminus\\{(1,0)\\}$. Since $(1,0)\\notin D$, it is harmonic in $D$.\n\n**Boundary condition.** For every $y\\in\\partial D\\setminus\\{(1,0)\\}$, $u(y)=\\log|y-(1,0)|$ by definition. Moreover, $u$ is continuous on $\\overline{D}\\setminus\\{(1,0)\\}$, so the boundary values are attained as limits.\n\n**Growth condition.** Trivially, $u(x)-\\log|x-(1,0)|=0$, which is bounded.\n\n**Uniqueness.** Suppose $w$ is another harmonic function in $D$ satisfying  \n- $\\displaystyle\\lim_{x\\to y}w(x)=\\log|y-(1,0)|$ for all $y\\in\\partial D\\setminus\\{(1,0)\\}$,  \n- $w(x)-\\log|x-(1,0)|$ bounded as $x\\to(1,0)$.  \n\nDefine $h(x)=w(x)-u(x)$. Then $h$ is harmonic in $D$, bounded (because the difference is bounded near $(1,0)$ and $h\\to0$ on the rest of the boundary), and has radial limit $0$ at almost every boundary point (indeed everywhere except at the single point $(1,0)$). A bounded harmonic function in the unit disk is uniquely determined by its non\u2011tangential limits almost everywhere (Fatou\u2019s theorem). Since those limits are $0$ a.e., the Poisson integral of $0$ forces $h\\equiv0$. Hence $w=u$.\n\nThus, under the stated extra condition, the solution is unique and given by  \n\n$$\\boxed{u(x)=\\log|x-(1,0)|}.$$\n\n---\n\n**Remark.** If one instead interprets the problem in the sense of the Poisson integral (i.e., $u$ is the Poisson integral of the boundary function $\\log|y-(1,0)|$, which is integrable on $\\partial D$), the same formula results because the Poisson integral of that boundary function equals $\\log|x-(1,0)|$ for $|x|<1$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Several complex variables and analytic spaces\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify key concepts in the domain\nSeveral complex variables and analytic spaces involve the study of functions of multiple complex variables and the spaces on which these functions are defined. Key concepts include holomorphic functions, complex manifolds, analytic continuation, and various types of domains (e.g., domains of holomorphy, pseudoconvex domains).\n\n## Step 3: Formulate a problem\nTo create a problem, we need to focus on a specific aspect of several complex variables. Let's consider the concept of holomorphic functions on a domain in $\\mathbb{C}^n$. A potential problem could involve characterizing or analyzing the properties of such functions.\n\n## Step 4: Specify the problem\nLet's formulate a problem related to the extension of holomorphic functions. A well-known result in several complex variables is the Hartogs' extension theorem, which states that any holomorphic function defined on a domain in $\\mathbb{C}^n$ ($n > 1$) with a compact hole can be extended holomorphically to the whole domain. We can create a problem related to this concept.\n\n## Step 5: Create the problem statement\nConsider the domain $\\Omega = \\{z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1\\}$ and the subset $S = \\{z \\in \\Omega : |z_1| < \\frac{1}{2}\\}$. Let $f$ be a holomorphic function on $\\Omega \\setminus S$. Show that $f$ can be extended to a holomorphic function on $\\Omega$.\n\n## Step 6: Provide the solution\nTo solve this, we recognize that $\\Omega \\setminus S$ is not a compact hole in $\\Omega$, so we cannot directly apply Hartogs' theorem. However, we can analyze the problem by considering the properties of holomorphic functions in $\\mathbb{C}^2$ and the specific geometry of $\\Omega$ and $S$.\n\n## Step 7: Detail the solution\nFor $z = (z_1, z_2) \\in \\Omega \\setminus S$, $f(z)$ is holomorphic. We need to show that $f$ can be extended holomorphically to $\\Omega$. For any fixed $z_2$ with $|z_2| < 1$, $f(z_1, z_2)$ is holomorphic in $z_1$ for $\\frac{1}{2} \\leq |z_1| < 1$. By the principle of analytic continuation in one variable, if $f(z_1, z_2)$ is holomorphic for $|z_1| < 1$ except on a smaller disk, it can be extended. However, the direct application of Hartogs' theorem is not possible here due to the shape of $S$. Instead, we can use the fact that for each $z_2$, $f(\\cdot, z_2)$ can be extended to $|z_1| < 1$ because the singularity set is contained within $|z_1| \\leq \\frac{1}{2}$, and then apply Hartogs' theorem or a similar principle to conclude the extension is holomorphic in both variables.\n\n## Step 8: Write the problem and solution in the required format\n\nLet $\\Omega = \\{z \\in \\mathbb{C}^2 : |z_1| < 1, |z_2| < 1\\}$ and $S = \\{z \\in \\Omega : |z_1| < \\frac{1}{2}\\}$. Suppose $f$ is a holomorphic function on $\\Omega \\setminus S$. Prove that $f$ can be extended to a holomorphic function on $\\Omega$.",
    "run_id": "20",
    "outer_attempt": 1,
    "topic_slug": "several_complex_variables_and_analytic_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The question as stated is ill-posed.  \n\nIn several complex variables, a function is said to be holomorphic on a set only if that set is **open** (or at least each point has an open neighbourhood contained in the set where the function is complex\u2011differentiable).  Here  \n$$\n\\Omega = \\{z\\in\\mathbb{C}^2 : |z_1|<1,\\;|z_2|<1\\}\n$$  \nis open, but  \n$$\nS = \\{z\\in\\Omega : |z_1|<\\tfrac12\\}\n$$  \nis also open (as the pre\u2011image of $(-\\infty,\\tfrac12)$ under the continuous map $z\\mapsto|z_1|$).  Consequently, $\\Omega\\setminus S$ is the complement of an open set inside an open set and is **not open**.  For example, any point with $|z_1|=\\tfrac12$ lies in $\\Omega\\setminus S$, but every neighbourhood of such a point contains points with $|z_1|<\\tfrac12$, which belong to $S$ and not to $\\Omega\\setminus S$; hence $\\Omega\\setminus S$ has no interior at those points.  \n\nThe hypothesis \u201c$f$ is a holomorphic function on $\\Omega\\setminus S$\u201d is therefore not meaningful under the standard definition of holomorphicity.  One cannot speak of a function being holomorphic on a non\u2011open set without additional structure (e.g., requiring it to be holomorphic on the interior and perhaps continuous up to the boundary).  \n\nTo make the question well\u2011posed, one could either  \n- replace $S$ by a **closed** subset, e.g., $\\{z\\in\\Omega : |z_1|\\le \\tfrac12\\}$, so that $\\Omega\\setminus S$ becomes open, or  \n- explicitly require $f$ to be holomorphic on the interior of $\\Omega\\setminus S$ and continuous on $\\Omega\\setminus S$, and then ask for an extension to $\\Omega$.  \n\nAs it stands, the problem lacks a proper domain of holomorphy and cannot be answered without clarification.",
        "raw_answer": "The question as stated is ill-posed.  \n\nIn several complex variables, a function is said to be holomorphic on a set only if that set is **open** (or at least each point has an open neighbourhood contained in the set where the function is complex\u2011differentiable).  Here  \n\\[\n\\Omega = \\{z\\in\\mathbb{C}^2 : |z_1|<1,\\;|z_2|<1\\}\n\\]  \nis open, but  \n\\[\nS = \\{z\\in\\Omega : |z_1|<\\tfrac12\\}\n\\]  \nis also open (as the pre\u2011image of $(-\\infty,\\tfrac12)$ under the continuous map $z\\mapsto|z_1|$).  Consequently, $\\Omega\\setminus S$ is the complement of an open set inside an open set and is **not open**.  For example, any point with $|z_1|=\\tfrac12$ lies in $\\Omega\\setminus S$, but every neighbourhood of such a point contains points with $|z_1|<\\tfrac12$, which belong to $S$ and not to $\\Omega\\setminus S$; hence $\\Omega\\setminus S$ has no interior at those points.  \n\nThe hypothesis \u201c$f$ is a holomorphic function on $\\Omega\\setminus S$\u201d is therefore not meaningful under the standard definition of holomorphicity.  One cannot speak of a function being holomorphic on a non\u2011open set without additional structure (e.g., requiring it to be holomorphic on the interior and perhaps continuous up to the boundary).  \n\nTo make the question well\u2011posed, one could either  \n- replace $S$ by a **closed** subset, e.g., $\\{z\\in\\Omega : |z_1|\\le \\tfrac12\\}$, so that $\\Omega\\setminus S$ becomes open, or  \n- explicitly require $f$ to be holomorphic on the interior of $\\Omega\\setminus S$ and continuous on $\\Omega\\setminus S$, and then ask for an extension to $\\Omega$.  \n\nAs it stands, the problem lacks a proper domain of holomorphy and cannot be answered without clarification.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of special functions, along with a clear and detailed solution, following specific guidelines.\n[/QUESTION]",
    "run_id": "21",
    "outer_attempt": 1,
    "topic_slug": "special_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem (Gamma and Beta functions)**  \n\n1. The Gamma function is defined for $\\operatorname{Re}(z) > 0$ by  \n   $$\n   \\Gamma(z) = \\int_0^\\infty t^{z-1} e^{-t} \\, dt.\n   $$\n   The Beta function is defined for $\\operatorname{Re}(a) > 0$, $\\operatorname{Re}(b) > 0$ by  \n   $$\n   B(a,b) = \\int_0^1 x^{a-1} (1-x)^{b-1} \\, dx.\n   $$\n\n   (a) Prove that  \n   $$\n   B(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}.\n   $$\n\n   (b) Show that for $0 < \\operatorname{Re}(z) < 1$,  \n   $$\n   B(z,1-z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt.\n   $$\n\n   (c) Evaluate the integral $\\displaystyle I(z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt$ for $0 < \\operatorname{Re}(z) < 1$ using a keyhole contour integration, and deduce Euler's reflection formula:  \n   $$\n   \\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)}.\n   $$\n\n   (d) Hence compute $\\Gamma\\bigl(\\tfrac{1}{2}\\bigr)$.\n\n---\n\n**Solution**\n\n**(a)**  \nWe start from the product of two Gamma functions:\n\n$$\n\\Gamma(a)\\Gamma(b) = \\int_0^\\infty \\int_0^\\infty x^{a-1} y^{b-1} e^{-(x+y)} \\, dx \\, dy, \\qquad \\operatorname{Re}(a)>0,\\; \\operatorname{Re}(b)>0.\n$$\n\nThe integrand is non\u2011negative and the integrals converge absolutely, so Fubini\u2019s theorem justifies the interchange of order.  \nIntroduce the change of variables  \n\n$$\nu = x + y, \\quad v = \\frac{x}{x+y} \\qquad \\Longleftrightarrow \\qquad x = uv,\\; y = u(1-v),\n$$\n\nwhich maps the domain $\\{(x,y): x>0,\\; y>0\\}$ bijectively onto $\\{(u,v): u>0,\\; 0<v<1\\}$.  \nThe Jacobian determinant is  \n\n$$\n\\frac{\\partial(x,y)}{\\partial(u,v)} = \\begin{vmatrix} v & u \\\\ 1-v & -u \\end{vmatrix} = -uv - u(1-v) = -u,\n$$\n\nhence $|J| = u$. Then  \n\n$$\n\\begin{aligned}\n\\Gamma(a)\\Gamma(b) &= \\int_0^\\infty \\int_0^1 (uv)^{a-1} \\bigl(u(1-v)\\bigr)^{b-1} e^{-u} \\; u \\, dv \\, du \\\\\n&= \\int_0^\\infty u^{a+b-1} e^{-u} \\, du \\int_0^1 v^{a-1} (1-v)^{b-1} \\, dv \\\\\n&= \\Gamma(a+b) \\, B(a,b).\n\\end{aligned}\n$$\n\nTherefore  \n\n$$\nB(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}.\n$$\n\n**(b)**  \nFor $0 < \\operatorname{Re}(z) < 1$ we have  \n\n$$\nB(z,1-z) = \\int_0^1 x^{z-1} (1-x)^{-z} \\, dx.\n$$\n\nPerform the substitution  \n\n$$\nx = \\frac{t}{1+t}, \\qquad t = \\frac{x}{1-x}, \\qquad dx = \\frac{dt}{(1+t)^2}.\n$$\n\nWhen $x \\to 0^+$, $t \\to 0$; when $x \\to 1^-$, $t \\to \\infty$. Also $1-x = \\frac{1}{1+t}$. Hence  \n\n$$\n\\begin{aligned}\nx^{z-1} (1-x)^{-z} \\, dx &= \\left(\\frac{t}{1+t}\\right)^{z-1} \\left(\\frac{1}{1+t}\\right)^{-z} \\frac{dt}{(1+t)^2} \\\\\n&= t^{z-1} (1+t)^{-(z-1)} (1+t)^{z} (1+t)^{-2} \\, dt \\\\\n&= \\frac{t^{z-1}}{1+t} \\, dt.\n\\end{aligned}\n$$\n\nThus  \n\n$$\nB(z,1-z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt.\n$$\n\nThe integral converges absolutely for $0 < \\operatorname{Re}(z) < 1$ because near $t=0$ the integrand behaves like $t^{\\operatorname{Re}(z)-1}$ (integrable when $\\operatorname{Re}(z)>0$) and as $t\\to\\infty$ it behaves like $t^{\\operatorname{Re}(z)-2}$ (integrable when $\\operatorname{Re}(z)<1$).\n\n**(c)**  \nLet  \n\n$$\nI(z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt, \\qquad 0 < \\operatorname{Re}(z) < 1.\n$$\n\nConsider the complex function  \n\n$$\nf(\\zeta) = \\frac{\\zeta^{z-1}}{1+\\zeta},\n$$\n\nwhere we define $\\zeta^{z-1} = e^{(z-1)\\log \\zeta}$ with the principal branch of the logarithm:  \n$\\log \\zeta = \\ln|\\zeta| + i\\arg\\zeta$, $0 < \\arg\\zeta < 2\\pi$. This makes $f$ analytic on $\\mathbb{C} \\setminus [0,\\infty)$ (branch cut along the positive real axis) and meromorphic with a simple pole at $\\zeta = -1$.\n\nWe integrate $f$ over a *keyhole contour* $\\gamma$ consisting of (see Figure 1):\n\n- $\\gamma_1$: a line segment just above the positive real axis from $r$ to $R$ (with $\\arg\\zeta = 0$),\n- $\\gamma_2$: a large circle of radius $R$ centred at the origin traversed counterclockwise,\n- $\\gamma_3$: a line segment just below the positive real axis from $R$ back to $r$ (with $\\arg\\zeta = 2\\pi$),\n- $\\gamma_4$: a small circle of radius $r$ around the origin traversed clockwise.\n\nWe choose $r < 1 < R$ so that the pole at $\\zeta = -1 = e^{i\\pi}$ lies inside the contour. The contour is positively oriented (counterclockwise overall). By the residue theorem,\n\n$$\n\\oint_\\gamma f(\\zeta) \\, d\\zeta = 2\\pi i \\; \\operatorname{Res}(f, -1).\n$$\n\n**Residue at $\\zeta = -1$:**  \n\n$$\n\\operatorname{Res}(f, -1) = \\lim_{\\zeta \\to -1} (\\zeta+1) f(\\zeta) = \\lim_{\\zeta \\to -1} \\zeta^{z-1} = (-1)^{z-1}.\n$$\n\nWith our branch, $\\arg(-1) = \\pi$, so $\\log(-1) = i\\pi$ and  \n\n$$\n(-1)^{z-1} = e^{(z-1)\\log(-1)} = e^{i\\pi(z-1)}.\n$$\n\n**Estimate on the large circle $\\gamma_2$:**  \nFor $|\\zeta| = R$,  \n\n$$\n|f(\\zeta)| = \\frac{|\\zeta^{z-1}|}{|1+\\zeta|} = \\frac{R^{\\operatorname{Re}(z)-1} e^{-\\operatorname{Im}(z)\\arg\\zeta}}{|1+Re^{i\\theta}|} \\le \\frac{R^{\\operatorname{Re}(z)-1}}{R-1} \\qquad (R>1).\n$$\n\nSince $\\operatorname{Re}(z) < 1$, $R^{\\operatorname{Re}(z)-2} \\to 0$ as $R \\to \\infty$. The length of $\\gamma_2$ is $2\\pi R$, hence  \n\n$$\n\\left|\\int_{\\gamma_2} f(\\zeta) \\, d\\zeta\\right| \\le \\frac{R^{\\operatorname{Re}(z)-1}}{R-1} \\cdot 2\\pi R \\sim 2\\pi R^{\\operatorname{Re}(z)} \\to 0 \\quad \\text{as } R\\to\\infty.\n$$\n\n**Estimate on the small circle $\\gamma_4$:**  \nFor $|\\zeta| = r$,  \n\n$$\n|f(\\zeta)| \\le \\frac{r^{\\operatorname{Re}(z)-1}}{1-r} \\qquad (r<1).\n$$\n\nBecause $\\operatorname{Re}(z) > 0$, $r^{\\operatorname{Re}(z)-1} \\to 0$ as $r \\to 0$. The length of $\\gamma_4$ is $2\\pi r$, so  \n\n$$\n\\left|\\int_{\\gamma_4} f(\\zeta) \\, d\\zeta\\right| \\le \\frac{r^{\\operatorname{Re}(z)-1}}{1-r} \\cdot 2\\pi r \\sim 2\\pi r^{\\operatorname{Re}(z)} \\to 0 \\quad \\text{as } r\\to 0.\n$$\n\nThus in the limits $R\\to\\infty$ and $r\\to 0$ the contributions from $\\gamma_2$ and $\\gamma_4$ vanish.\n\n**Integral on $\\gamma_1$:**  \nHere $\\arg\\zeta = 0$, $\\zeta = t$ (real), $t$ runs from $0$ to $\\infty$. Hence  \n\n$$\n\\int_{\\gamma_1} f(\\zeta) \\, d\\zeta = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = I(z).\n$$\n\n**Integral on $\\gamma_3$:**  \nOn the lower side of the cut we have $\\arg\\zeta = 2\\pi$, so $\\zeta = t e^{i2\\pi}$ with $t$ decreasing from $\\infty$ to $0$. Then  \n\n$$\n\\zeta^{z-1} = e^{(z-1)(\\ln t + i2\\pi)} = t^{z-1} e^{i2\\pi(z-1)},\n$$\n\nand $d\\zeta = e^{i2\\pi} dt = dt$. Therefore  \n\n$$\n\\int_{\\gamma_3} f(\\zeta) \\, d\\zeta = \\int_\\infty^0 \\frac{t^{z-1} e^{i2\\pi(z-1)}}{1+t} \\, dt = - e^{i2\\pi(z-1)} \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = - e^{i2\\pi(z-1)} I(z).\n$$\n\n**Summing the contributions:**  \nTaking the limits $R\\to\\infty$, $r\\to 0$, we obtain  \n\n$$\n\\oint_\\gamma f(\\zeta) \\, d\\zeta = I(z) - e^{i2\\pi(z-1)} I(z) = \\bigl(1 - e^{i2\\pi(z-1)}\\bigr) I(z).\n$$\n\nBy the residue theorem this equals $2\\pi i \\, e^{i\\pi(z-1)}$. Hence  \n\n$$\n\\bigl(1 - e^{i2\\pi(z-1)}\\bigr) I(z) = 2\\pi i \\, e^{i\\pi(z-1)}.\n$$\n\nNow simplify the left\u2011hand side:  \n\n$$\n1 - e^{i2\\pi(z-1)} = e^{i\\pi(z-1)}\\bigl(e^{-i\\pi(z-1)} - e^{i\\pi(z-1)}\\bigr) = e^{i\\pi(z-1)}\\bigl(-2i \\sin(\\pi(z-1))\\bigr).\n$$\n\nSince $\\sin(\\pi(z-1)) = -\\sin(\\pi z)$, we have  \n\n$$\n1 - e^{i2\\pi(z-1)} = e^{i\\pi(z-1)} \\cdot 2i \\sin(\\pi z).\n$$\n\nSubstituting,  \n\n$$\ne^{i\\pi(z-1)} \\cdot 2i \\sin(\\pi z) \\cdot I(z) = 2\\pi i \\, e^{i\\pi(z-1)}.\n$$\n\nCancelling the non\u2011zero factor $e^{i\\pi(z-1)}$ and $2i$ yields  \n\n$$\nI(z) = \\frac{\\pi}{\\sin(\\pi z)}.\n$$\n\nThus for $0 < \\operatorname{Re}(z) < 1$,  \n\n$$\n\\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = \\frac{\\pi}{\\sin(\\pi z)}.\n$$\n\nFrom part (b), $B(z,1-z) = I(z)$. From part (a) with $a=z$, $b=1-z$, and using $\\Gamma(1)=1$ (since $\\Gamma(1)=\\int_0^\\infty e^{-t}dt =1$), we obtain  \n\n$$\nB(z,1-z) = \\frac{\\Gamma(z)\\Gamma(1-z)}{\\Gamma(1)} = \\Gamma(z)\\Gamma(1-z).\n$$\n\nTherefore  \n\n$$\n\\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)} \\qquad (0 < \\operatorname{Re}(z) < 1).\n$$\n\nBy analytic continuation, the formula holds for all complex $z$ not an integer.\n\n**(d)**  \nSubstitute $z = \\frac{1}{2}$ into the reflection formula:\n\n$$\n\\Gamma\\!\\left(\\frac{1}{2}\\right) \\Gamma\\!\\left(1-\\frac{1}{2}\\right) = \\Gamma\\!\\left(\\frac{1}{2}\\right)^2 = \\frac{\\pi}{\\sin(\\pi/2)} = \\pi.\n$$\n\nBecause $\\Gamma(1/2) > 0$ (the integral definition shows it is positive), we conclude  \n\n$$\n\\Gamma\\!\\left(\\frac{1}{2}\\right) = \\sqrt{\\pi}.\n$$\n\nThis completes the solution.",
        "raw_answer": "**Problem (Gamma and Beta functions)**  \n\n1. The Gamma function is defined for \\(\\operatorname{Re}(z) > 0\\) by  \n   \\[\n   \\Gamma(z) = \\int_0^\\infty t^{z-1} e^{-t} \\, dt.\n   \\]\n   The Beta function is defined for \\(\\operatorname{Re}(a) > 0\\), \\(\\operatorname{Re}(b) > 0\\) by  \n   \\[\n   B(a,b) = \\int_0^1 x^{a-1} (1-x)^{b-1} \\, dx.\n   \\]\n\n   (a) Prove that  \n   \\[\n   B(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}.\n   \\]\n\n   (b) Show that for \\(0 < \\operatorname{Re}(z) < 1\\),  \n   \\[\n   B(z,1-z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt.\n   \\]\n\n   (c) Evaluate the integral \\(\\displaystyle I(z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt\\) for \\(0 < \\operatorname{Re}(z) < 1\\) using a keyhole contour integration, and deduce Euler's reflection formula:  \n   \\[\n   \\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)}.\n   \\]\n\n   (d) Hence compute \\(\\Gamma\\bigl(\\tfrac{1}{2}\\bigr)\\).\n\n---\n\n**Solution**\n\n**(a)**  \nWe start from the product of two Gamma functions:\n\n\\[\n\\Gamma(a)\\Gamma(b) = \\int_0^\\infty \\int_0^\\infty x^{a-1} y^{b-1} e^{-(x+y)} \\, dx \\, dy, \\qquad \\operatorname{Re}(a)>0,\\; \\operatorname{Re}(b)>0.\n\\]\n\nThe integrand is non\u2011negative and the integrals converge absolutely, so Fubini\u2019s theorem justifies the interchange of order.  \nIntroduce the change of variables  \n\n\\[\nu = x + y, \\quad v = \\frac{x}{x+y} \\qquad \\Longleftrightarrow \\qquad x = uv,\\; y = u(1-v),\n\\]\n\nwhich maps the domain \\(\\{(x,y): x>0,\\; y>0\\}\\) bijectively onto \\(\\{(u,v): u>0,\\; 0<v<1\\}\\).  \nThe Jacobian determinant is  \n\n\\[\n\\frac{\\partial(x,y)}{\\partial(u,v)} = \\begin{vmatrix} v & u \\\\ 1-v & -u \\end{vmatrix} = -uv - u(1-v) = -u,\n\\]\n\nhence \\(|J| = u\\). Then  \n\n\\[\n\\begin{aligned}\n\\Gamma(a)\\Gamma(b) &= \\int_0^\\infty \\int_0^1 (uv)^{a-1} \\bigl(u(1-v)\\bigr)^{b-1} e^{-u} \\; u \\, dv \\, du \\\\\n&= \\int_0^\\infty u^{a+b-1} e^{-u} \\, du \\int_0^1 v^{a-1} (1-v)^{b-1} \\, dv \\\\\n&= \\Gamma(a+b) \\, B(a,b).\n\\end{aligned}\n\\]\n\nTherefore  \n\n\\[\nB(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}.\n\\]\n\n**(b)**  \nFor \\(0 < \\operatorname{Re}(z) < 1\\) we have  \n\n\\[\nB(z,1-z) = \\int_0^1 x^{z-1} (1-x)^{-z} \\, dx.\n\\]\n\nPerform the substitution  \n\n\\[\nx = \\frac{t}{1+t}, \\qquad t = \\frac{x}{1-x}, \\qquad dx = \\frac{dt}{(1+t)^2}.\n\\]\n\nWhen \\(x \\to 0^+\\), \\(t \\to 0\\); when \\(x \\to 1^-\\), \\(t \\to \\infty\\). Also \\(1-x = \\frac{1}{1+t}\\). Hence  \n\n\\[\n\\begin{aligned}\nx^{z-1} (1-x)^{-z} \\, dx &= \\left(\\frac{t}{1+t}\\right)^{z-1} \\left(\\frac{1}{1+t}\\right)^{-z} \\frac{dt}{(1+t)^2} \\\\\n&= t^{z-1} (1+t)^{-(z-1)} (1+t)^{z} (1+t)^{-2} \\, dt \\\\\n&= \\frac{t^{z-1}}{1+t} \\, dt.\n\\end{aligned}\n\\]\n\nThus  \n\n\\[\nB(z,1-z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt.\n\\]\n\nThe integral converges absolutely for \\(0 < \\operatorname{Re}(z) < 1\\) because near \\(t=0\\) the integrand behaves like \\(t^{\\operatorname{Re}(z)-1}\\) (integrable when \\(\\operatorname{Re}(z)>0\\)) and as \\(t\\to\\infty\\) it behaves like \\(t^{\\operatorname{Re}(z)-2}\\) (integrable when \\(\\operatorname{Re}(z)<1\\)).\n\n**(c)**  \nLet  \n\n\\[\nI(z) = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt, \\qquad 0 < \\operatorname{Re}(z) < 1.\n\\]\n\nConsider the complex function  \n\n\\[\nf(\\zeta) = \\frac{\\zeta^{z-1}}{1+\\zeta},\n\\]\n\nwhere we define \\(\\zeta^{z-1} = e^{(z-1)\\log \\zeta}\\) with the principal branch of the logarithm:  \n\\(\\log \\zeta = \\ln|\\zeta| + i\\arg\\zeta\\), \\(0 < \\arg\\zeta < 2\\pi\\). This makes \\(f\\) analytic on \\(\\mathbb{C} \\setminus [0,\\infty)\\) (branch cut along the positive real axis) and meromorphic with a simple pole at \\(\\zeta = -1\\).\n\nWe integrate \\(f\\) over a *keyhole contour* \\(\\gamma\\) consisting of (see Figure 1):\n\n- \\(\\gamma_1\\): a line segment just above the positive real axis from \\(r\\) to \\(R\\) (with \\(\\arg\\zeta = 0\\)),\n- \\(\\gamma_2\\): a large circle of radius \\(R\\) centred at the origin traversed counterclockwise,\n- \\(\\gamma_3\\): a line segment just below the positive real axis from \\(R\\) back to \\(r\\) (with \\(\\arg\\zeta = 2\\pi\\)),\n- \\(\\gamma_4\\): a small circle of radius \\(r\\) around the origin traversed clockwise.\n\nWe choose \\(r < 1 < R\\) so that the pole at \\(\\zeta = -1 = e^{i\\pi}\\) lies inside the contour. The contour is positively oriented (counterclockwise overall). By the residue theorem,\n\n\\[\n\\oint_\\gamma f(\\zeta) \\, d\\zeta = 2\\pi i \\; \\operatorname{Res}(f, -1).\n\\]\n\n**Residue at \\(\\zeta = -1\\):**  \n\n\\[\n\\operatorname{Res}(f, -1) = \\lim_{\\zeta \\to -1} (\\zeta+1) f(\\zeta) = \\lim_{\\zeta \\to -1} \\zeta^{z-1} = (-1)^{z-1}.\n\\]\n\nWith our branch, \\(\\arg(-1) = \\pi\\), so \\(\\log(-1) = i\\pi\\) and  \n\n\\[\n(-1)^{z-1} = e^{(z-1)\\log(-1)} = e^{i\\pi(z-1)}.\n\\]\n\n**Estimate on the large circle \\(\\gamma_2\\):**  \nFor \\(|\\zeta| = R\\),  \n\n\\[\n|f(\\zeta)| = \\frac{|\\zeta^{z-1}|}{|1+\\zeta|} = \\frac{R^{\\operatorname{Re}(z)-1} e^{-\\operatorname{Im}(z)\\arg\\zeta}}{|1+Re^{i\\theta}|} \\le \\frac{R^{\\operatorname{Re}(z)-1}}{R-1} \\qquad (R>1).\n\\]\n\nSince \\(\\operatorname{Re}(z) < 1\\), \\(R^{\\operatorname{Re}(z)-2} \\to 0\\) as \\(R \\to \\infty\\). The length of \\(\\gamma_2\\) is \\(2\\pi R\\), hence  \n\n\\[\n\\left|\\int_{\\gamma_2} f(\\zeta) \\, d\\zeta\\right| \\le \\frac{R^{\\operatorname{Re}(z)-1}}{R-1} \\cdot 2\\pi R \\sim 2\\pi R^{\\operatorname{Re}(z)} \\to 0 \\quad \\text{as } R\\to\\infty.\n\\]\n\n**Estimate on the small circle \\(\\gamma_4\\):**  \nFor \\(|\\zeta| = r\\),  \n\n\\[\n|f(\\zeta)| \\le \\frac{r^{\\operatorname{Re}(z)-1}}{1-r} \\qquad (r<1).\n\\]\n\nBecause \\(\\operatorname{Re}(z) > 0\\), \\(r^{\\operatorname{Re}(z)-1} \\to 0\\) as \\(r \\to 0\\). The length of \\(\\gamma_4\\) is \\(2\\pi r\\), so  \n\n\\[\n\\left|\\int_{\\gamma_4} f(\\zeta) \\, d\\zeta\\right| \\le \\frac{r^{\\operatorname{Re}(z)-1}}{1-r} \\cdot 2\\pi r \\sim 2\\pi r^{\\operatorname{Re}(z)} \\to 0 \\quad \\text{as } r\\to 0.\n\\]\n\nThus in the limits \\(R\\to\\infty\\) and \\(r\\to 0\\) the contributions from \\(\\gamma_2\\) and \\(\\gamma_4\\) vanish.\n\n**Integral on \\(\\gamma_1\\):**  \nHere \\(\\arg\\zeta = 0\\), \\(\\zeta = t\\) (real), \\(t\\) runs from \\(0\\) to \\(\\infty\\). Hence  \n\n\\[\n\\int_{\\gamma_1} f(\\zeta) \\, d\\zeta = \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = I(z).\n\\]\n\n**Integral on \\(\\gamma_3\\):**  \nOn the lower side of the cut we have \\(\\arg\\zeta = 2\\pi\\), so \\(\\zeta = t e^{i2\\pi}\\) with \\(t\\) decreasing from \\(\\infty\\) to \\(0\\). Then  \n\n\\[\n\\zeta^{z-1} = e^{(z-1)(\\ln t + i2\\pi)} = t^{z-1} e^{i2\\pi(z-1)},\n\\]\n\nand \\(d\\zeta = e^{i2\\pi} dt = dt\\). Therefore  \n\n\\[\n\\int_{\\gamma_3} f(\\zeta) \\, d\\zeta = \\int_\\infty^0 \\frac{t^{z-1} e^{i2\\pi(z-1)}}{1+t} \\, dt = - e^{i2\\pi(z-1)} \\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = - e^{i2\\pi(z-1)} I(z).\n\\]\n\n**Summing the contributions:**  \nTaking the limits \\(R\\to\\infty\\), \\(r\\to 0\\), we obtain  \n\n\\[\n\\oint_\\gamma f(\\zeta) \\, d\\zeta = I(z) - e^{i2\\pi(z-1)} I(z) = \\bigl(1 - e^{i2\\pi(z-1)}\\bigr) I(z).\n\\]\n\nBy the residue theorem this equals \\(2\\pi i \\, e^{i\\pi(z-1)}\\). Hence  \n\n\\[\n\\bigl(1 - e^{i2\\pi(z-1)}\\bigr) I(z) = 2\\pi i \\, e^{i\\pi(z-1)}.\n\\]\n\nNow simplify the left\u2011hand side:  \n\n\\[\n1 - e^{i2\\pi(z-1)} = e^{i\\pi(z-1)}\\bigl(e^{-i\\pi(z-1)} - e^{i\\pi(z-1)}\\bigr) = e^{i\\pi(z-1)}\\bigl(-2i \\sin(\\pi(z-1))\\bigr).\n\\]\n\nSince \\(\\sin(\\pi(z-1)) = -\\sin(\\pi z)\\), we have  \n\n\\[\n1 - e^{i2\\pi(z-1)} = e^{i\\pi(z-1)} \\cdot 2i \\sin(\\pi z).\n\\]\n\nSubstituting,  \n\n\\[\ne^{i\\pi(z-1)} \\cdot 2i \\sin(\\pi z) \\cdot I(z) = 2\\pi i \\, e^{i\\pi(z-1)}.\n\\]\n\nCancelling the non\u2011zero factor \\(e^{i\\pi(z-1)}\\) and \\(2i\\) yields  \n\n\\[\nI(z) = \\frac{\\pi}{\\sin(\\pi z)}.\n\\]\n\nThus for \\(0 < \\operatorname{Re}(z) < 1\\),  \n\n\\[\n\\int_0^\\infty \\frac{t^{z-1}}{1+t} \\, dt = \\frac{\\pi}{\\sin(\\pi z)}.\n\\]\n\nFrom part (b), \\(B(z,1-z) = I(z)\\). From part (a) with \\(a=z\\), \\(b=1-z\\), and using \\(\\Gamma(1)=1\\) (since \\(\\Gamma(1)=\\int_0^\\infty e^{-t}dt =1\\)), we obtain  \n\n\\[\nB(z,1-z) = \\frac{\\Gamma(z)\\Gamma(1-z)}{\\Gamma(1)} = \\Gamma(z)\\Gamma(1-z).\n\\]\n\nTherefore  \n\n\\[\n\\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)} \\qquad (0 < \\operatorname{Re}(z) < 1).\n\\]\n\nBy analytic continuation, the formula holds for all complex \\(z\\) not an integer.\n\n**(d)**  \nSubstitute \\(z = \\frac{1}{2}\\) into the reflection formula:\n\n\\[\n\\Gamma\\!\\left(\\frac{1}{2}\\right) \\Gamma\\!\\left(1-\\frac{1}{2}\\right) = \\Gamma\\!\\left(\\frac{1}{2}\\right)^2 = \\frac{\\pi}{\\sin(\\pi/2)} = \\pi.\n\\]\n\nBecause \\(\\Gamma(1/2) > 0\\) (the integral definition shows it is positive), we conclude  \n\n\\[\n\\Gamma\\!\\left(\\frac{1}{2}\\right) = \\sqrt{\\pi}.\n\\]\n\nThis completes the solution.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of ordinary differential equations (ODEs), along with a complete and clear solution. The problem should be solvable, verifiable, and not require external resources or conjectures.\n\n## Step 2: Formulate the problem\nTo create a meaningful problem, we need to consider an ODE that is not trivial and involves some level of mathematical sophistication. Let's consider a second-order linear homogeneous differential equation with constant coefficients, which is a standard topic in ODEs.\n\n## Step 3: Propose a specific problem\nConsider the differential equation $y'' + 4y' + 4y = 0$. The task is to find the general solution to this equation.\n\n## Step 4: Verify the problem meets the criteria\n- **Non-trivial**: The equation is not straightforward to solve by inspection.\n- **Solvable**: The equation can be solved using standard methods for linear differential equations with constant coefficients.\n- **Verifiable**: The solution can be verified by substitution into the differential equation.",
    "run_id": "22",
    "outer_attempt": 1,
    "topic_slug": "ordinary_differential_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The differential equation is\n\n$$\ny'' + 4y' + 4y = 0.\n$$\n\nWe seek its general solution.\n\n### Solution\n\n**Step 1: Characteristic equation.**  \nFor a linear homogeneous ordinary differential equation with constant coefficients, we assume a solution of the form $y = e^{rx}$. Substituting into the ODE gives\n\n$$\nr^2 e^{rx} + 4r e^{rx} + 4 e^{rx} = 0 \\quad\\Longrightarrow\\quad e^{rx}(r^2 + 4r + 4) = 0.\n$$\n\nSince $e^{rx} \\neq 0$ for all real $x$, we obtain the characteristic equation\n\n$$\nr^2 + 4r + 4 = 0.\n$$\n\n**Step 2: Solve the characteristic equation.**  \nFactor the quadratic:\n\n$$\nr^2 + 4r + 4 = (r+2)^2 = 0.\n$$\n\nThus, we have a repeated real root $r = -2$ with multiplicity 2.\n\n**Step 3: General solution for repeated roots.**  \nWhen the characteristic equation has a repeated root $r = \\alpha$ of multiplicity 2, the general solution of the ODE is\n\n$$\ny(x) = (C_1 + C_2 x) e^{\\alpha x},\n$$\n\nwhere $C_1$ and $C_2$ are arbitrary constants. With $\\alpha = -2$, we obtain\n\n$$\n\\boxed{y(x) = (C_1 + C_2 x) e^{-2x}}.\n$$\n\n**Step 4: Verification (optional but instructive).**  \nCompute the first and second derivatives of the proposed solution:\n\n$$\n\\begin{aligned}\ny(x) &= (C_1 + C_2 x) e^{-2x},\\$$4pt]\ny'(x) &= C_2 e^{-2x} - 2(C_1 + C_2 x) e^{-2x} = (C_2 - 2C_1 - 2C_2 x) e^{-2x},\\$$4pt]\ny''(x) &= -2C_2 e^{-2x} - 2(C_2 - 2C_1 - 2C_2 x) e^{-2x} \\$$4pt]\n&= \\bigl[-2C_2 - 2C_2 + 4C_1 + 4C_2 x\\bigr] e^{-2x} \\$$4pt]\n&= (4C_1 - 4C_2 + 4C_2 x) e^{-2x}.\n\\end{aligned}\n$$\n\nNow substitute into the left-hand side of the ODE:\n\n$$\n\\begin{aligned}\ny'' + 4y' + 4y &= e^{-2x}\\Bigl[(4C_1 - 4C_2 + 4C_2 x) + 4(C_2 - 2C_1 - 2C_2 x) + 4(C_1 + C_2 x)\\Bigr] \\$$4pt]\n&= e^{-2x}\\Bigl[4C_1 - 4C_2 + 4C_2 x + 4C_2 - 8C_1 - 8C_2 x + 4C_1 + 4C_2 x\\Bigr] \\$$4pt]\n&= e^{-2x}\\Bigl[(4C_1 - 8C_1 + 4C_1) + (-4C_2 + 4C_2) + (4C_2 x - 8C_2 x + 4C_2 x)\\Bigr] \\$$4pt]\n&= e^{-2x}\\Bigl[0 + 0 + 0\\Bigr] = 0.\n\\end{aligned}\n$$\n\nThus, the proposed solution satisfies the differential equation identically for any constants $C_1, C_2$. Moreover, by the existence and uniqueness theorem for linear ODEs, this two-parameter family constitutes the complete set of solutions (valid for all $x \\in \\mathbb{R}$).\n\n### Conclusion\n\nThe general solution of $y'' + 4y' + 4y = 0$ is\n\n$$\n\\boxed{y(x) = (C_1 + C_2 x) e^{-2x}},\n$$\n\nwhere $C_1$ and $C_2$ are arbitrary constants.",
        "raw_answer": "The differential equation is\n\n\\[\ny'' + 4y' + 4y = 0.\n\\]\n\nWe seek its general solution.\n\n### Solution\n\n**Step 1: Characteristic equation.**  \nFor a linear homogeneous ordinary differential equation with constant coefficients, we assume a solution of the form \\(y = e^{rx}\\). Substituting into the ODE gives\n\n\\[\nr^2 e^{rx} + 4r e^{rx} + 4 e^{rx} = 0 \\quad\\Longrightarrow\\quad e^{rx}(r^2 + 4r + 4) = 0.\n\\]\n\nSince \\(e^{rx} \\neq 0\\) for all real \\(x\\), we obtain the characteristic equation\n\n\\[\nr^2 + 4r + 4 = 0.\n\\]\n\n**Step 2: Solve the characteristic equation.**  \nFactor the quadratic:\n\n\\[\nr^2 + 4r + 4 = (r+2)^2 = 0.\n\\]\n\nThus, we have a repeated real root \\(r = -2\\) with multiplicity 2.\n\n**Step 3: General solution for repeated roots.**  \nWhen the characteristic equation has a repeated root \\(r = \\alpha\\) of multiplicity 2, the general solution of the ODE is\n\n\\[\ny(x) = (C_1 + C_2 x) e^{\\alpha x},\n\\]\n\nwhere \\(C_1\\) and \\(C_2\\) are arbitrary constants. With \\(\\alpha = -2\\), we obtain\n\n\\[\n\\boxed{y(x) = (C_1 + C_2 x) e^{-2x}}.\n\\]\n\n**Step 4: Verification (optional but instructive).**  \nCompute the first and second derivatives of the proposed solution:\n\n\\[\n\\begin{aligned}\ny(x) &= (C_1 + C_2 x) e^{-2x},\\\\[4pt]\ny'(x) &= C_2 e^{-2x} - 2(C_1 + C_2 x) e^{-2x} = (C_2 - 2C_1 - 2C_2 x) e^{-2x},\\\\[4pt]\ny''(x) &= -2C_2 e^{-2x} - 2(C_2 - 2C_1 - 2C_2 x) e^{-2x} \\\\[4pt]\n&= \\bigl[-2C_2 - 2C_2 + 4C_1 + 4C_2 x\\bigr] e^{-2x} \\\\[4pt]\n&= (4C_1 - 4C_2 + 4C_2 x) e^{-2x}.\n\\end{aligned}\n\\]\n\nNow substitute into the left-hand side of the ODE:\n\n\\[\n\\begin{aligned}\ny'' + 4y' + 4y &= e^{-2x}\\Bigl[(4C_1 - 4C_2 + 4C_2 x) + 4(C_2 - 2C_1 - 2C_2 x) + 4(C_1 + C_2 x)\\Bigr] \\\\[4pt]\n&= e^{-2x}\\Bigl[4C_1 - 4C_2 + 4C_2 x + 4C_2 - 8C_1 - 8C_2 x + 4C_1 + 4C_2 x\\Bigr] \\\\[4pt]\n&= e^{-2x}\\Bigl[(4C_1 - 8C_1 + 4C_1) + (-4C_2 + 4C_2) + (4C_2 x - 8C_2 x + 4C_2 x)\\Bigr] \\\\[4pt]\n&= e^{-2x}\\Bigl[0 + 0 + 0\\Bigr] = 0.\n\\end{aligned}\n\\]\n\nThus, the proposed solution satisfies the differential equation identically for any constants \\(C_1, C_2\\). Moreover, by the existence and uniqueness theorem for linear ODEs, this two-parameter family constitutes the complete set of solutions (valid for all \\(x \\in \\mathbb{R}\\)).\n\n### Conclusion\n\nThe general solution of \\(y'' + 4y' + 4y = 0\\) is\n\n\\[\n\\boxed{y(x) = (C_1 + C_2 x) e^{-2x}},\n\\]\n\nwhere \\(C_1\\) and \\(C_2\\) are arbitrary constants.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Consider the one-dimensional heat equation given by $\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}$, where $\\alpha > 0$ is a constant, $x \\in [0, L]$, and $t \\geq 0$. The boundary conditions are $u(0, t) = u(L, t) = 0$ for all $t \\geq 0$, and the initial condition is $u(x, 0) = \\sin(\\frac{\\pi x}{L}) + 2\\sin(\\frac{3\\pi x}{L})$. Find the solution $u(x, t)$ for $x \\in [0, L]$ and $t \\geq 0$.",
    "run_id": "23",
    "outer_attempt": 1,
    "topic_slug": "partial_differential_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The solution to the heat equation with the given boundary and initial conditions is\n\n$$\nu(x,t) = \\sin\\!\\left(\\frac{\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{\\pi}{L}\\right)^2 t} + 2 \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{3\\pi}{L}\\right)^2 t},\n$$\n\nor equivalently\n\n$$\nu(x,t) = \\sin\\!\\left(\\frac{\\pi x}{L}\\right) e^{-\\alpha \\pi^2 t / L^2} + 2 \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) e^{-9\\alpha \\pi^2 t / L^2}.\n$$\n\n---\n\n### Step\u2011by\u2011step derivation\n\n1. **Separation of variables**  \n   Assume a product solution $u(x,t)=X(x)T(t)$. Substituting into $\\partial_t u = \\alpha \\partial_x^2 u$ gives  \n   $$\n   X T' = \\alpha X'' T \\quad\\Longrightarrow\\quad \\frac{T'}{\\alpha T} = \\frac{X''}{X} = -\\lambda,\n   $$  \n   where $\\lambda$ is a separation constant.\n\n2. **Spatial problem**  \n   $X'' + \\lambda X = 0$ with boundary conditions $X(0)=X(L)=0$.  \n   The nontrivial solutions are  \n   $$\n   \\lambda_n = \\left(\\frac{n\\pi}{L}\\right)^2,\\qquad X_n(x) = \\sin\\!\\left(\\frac{n\\pi x}{L}\\right),\\quad n=1,2,3,\\dots\n   $$\n\n3. **Temporal problem**  \n   For each $n$, $T_n' = -\\alpha \\lambda_n T_n$, so  \n   $$\n   T_n(t) = C_n e^{-\\alpha \\lambda_n t} = C_n e^{-\\alpha (n\\pi/L)^2 t}.\n   $$\n\n4. **Superposition**  \n   The general solution satisfying the boundary conditions is  \n   $$\n   u(x,t) = \\sum_{n=1}^{\\infty} B_n \\sin\\!\\left(\\frac{n\\pi x}{L}\\right) e^{-\\alpha (n\\pi/L)^2 t},\n   $$  \n   where $B_n$ are constants to be determined from the initial condition.\n\n5. **Initial condition**  \n   At $t=0$,  \n   $$\n   u(x,0) = \\sum_{n=1}^{\\infty} B_n \\sin\\!\\left(\\frac{n\\pi x}{L}\\right) = \\sin\\!\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\!\\left(\\frac{3\\pi x}{L}\\right).\n   $$\n\n6. **Determining the coefficients**  \n   The functions $\\sin(n\\pi x/L)$ are orthogonal on $[0,L]$:  \n   $$\n   \\int_0^L \\sin\\!\\left(\\frac{n\\pi x}{L}\\right) \\sin\\!\\left(\\frac{m\\pi x}{L}\\right) dx = \\frac{L}{2}\\,\\delta_{nm}.\n   $$  \n   Multiplying the initial condition by $\\sin(m\\pi x/L)$ and integrating yields  \n   $$\n   B_m = \\frac{2}{L} \\int_0^L u(x,0) \\sin\\!\\left(\\frac{m\\pi x}{L}\\right) dx.\n   $$\n\n   - For $m=1$:  \n     $$\n     B_1 = \\frac{2}{L} \\int_0^L \\left[\\sin\\!\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\!\\left(\\frac{3\\pi x}{L}\\right)\\right] \\sin\\!\\left(\\frac{\\pi x}{L}\\right) dx\n          = \\frac{2}{L}\\left( \\int_0^L \\sin^2\\!\\left(\\frac{\\pi x}{L}\\right) dx + 2 \\int_0^L \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) \\sin\\!\\left(\\frac{\\pi x}{L}\\right) dx \\right).\n     $$  \n     The second integral vanishes by orthogonality; the first equals $L/2$. Hence $B_1 = \\frac{2}{L}\\cdot\\frac{L}{2}=1$.\n\n   - For $m=3$:  \n     $$\n     B_3 = \\frac{2}{L} \\int_0^L \\left[\\sin\\!\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\!\\left(\\frac{3\\pi x}{L}\\right)\\right] \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) dx\n          = \\frac{2}{L}\\left( \\int_0^L \\sin\\!\\left(\\frac{\\pi x}{L}\\right) \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) dx + 2 \\int_0^L \\sin^2\\!\\left(\\frac{3\\pi x}{L}\\right) dx \\right).\n     $$  \n     The first integral is zero; the second equals $2\\cdot(L/2)=L$. Thus $B_3 = \\frac{2}{L}\\cdot L = 2$.\n\n   - For all other $m$, the integrals vanish, so $B_m = 0$.\n\n7. **Final expression**  \n   Substituting the nonzero coefficients back into the series gives  \n   $$\n   u(x,t) = 1\\cdot \\sin\\!\\left(\\frac{\\pi x}{L}\\right) e^{-\\alpha (\\pi/L)^2 t} + 2\\cdot \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) e^{-\\alpha (3\\pi/L)^2 t}.\n   $$\n\n---\n\n### Verification\n\n- **PDE:** Direct substitution shows that each term satisfies $\\partial_t = \\alpha \\partial_x^2$ because each is of the separated form.\n- **Boundary conditions:** $\\sin(0)=0$ and $\\sin(n\\pi)=0$ ensure $u(0,t)=u(L,t)=0$.\n- **Initial condition:** At $t=0$ the exponentials become $1$, recovering the given initial profile.\n- **Uniqueness:** The solution is unique due to the well\u2011posedness of the linear heat equation with Dirichlet boundary conditions.\n\nThus the obtained $u(x,t)$ is the required solution.",
        "raw_answer": "The solution to the heat equation with the given boundary and initial conditions is\n\n\\[\nu(x,t) = \\sin\\!\\left(\\frac{\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{\\pi}{L}\\right)^2 t} + 2 \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) e^{-\\alpha \\left(\\frac{3\\pi}{L}\\right)^2 t},\n\\]\n\nor equivalently\n\n\\[\nu(x,t) = \\sin\\!\\left(\\frac{\\pi x}{L}\\right) e^{-\\alpha \\pi^2 t / L^2} + 2 \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) e^{-9\\alpha \\pi^2 t / L^2}.\n\\]\n\n---\n\n### Step\u2011by\u2011step derivation\n\n1. **Separation of variables**  \n   Assume a product solution \\(u(x,t)=X(x)T(t)\\). Substituting into \\(\\partial_t u = \\alpha \\partial_x^2 u\\) gives  \n   \\[\n   X T' = \\alpha X'' T \\quad\\Longrightarrow\\quad \\frac{T'}{\\alpha T} = \\frac{X''}{X} = -\\lambda,\n   \\]  \n   where \\(\\lambda\\) is a separation constant.\n\n2. **Spatial problem**  \n   \\(X'' + \\lambda X = 0\\) with boundary conditions \\(X(0)=X(L)=0\\).  \n   The nontrivial solutions are  \n   \\[\n   \\lambda_n = \\left(\\frac{n\\pi}{L}\\right)^2,\\qquad X_n(x) = \\sin\\!\\left(\\frac{n\\pi x}{L}\\right),\\quad n=1,2,3,\\dots\n   \\]\n\n3. **Temporal problem**  \n   For each \\(n\\), \\(T_n' = -\\alpha \\lambda_n T_n\\), so  \n   \\[\n   T_n(t) = C_n e^{-\\alpha \\lambda_n t} = C_n e^{-\\alpha (n\\pi/L)^2 t}.\n   \\]\n\n4. **Superposition**  \n   The general solution satisfying the boundary conditions is  \n   \\[\n   u(x,t) = \\sum_{n=1}^{\\infty} B_n \\sin\\!\\left(\\frac{n\\pi x}{L}\\right) e^{-\\alpha (n\\pi/L)^2 t},\n   \\]  \n   where \\(B_n\\) are constants to be determined from the initial condition.\n\n5. **Initial condition**  \n   At \\(t=0\\),  \n   \\[\n   u(x,0) = \\sum_{n=1}^{\\infty} B_n \\sin\\!\\left(\\frac{n\\pi x}{L}\\right) = \\sin\\!\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\!\\left(\\frac{3\\pi x}{L}\\right).\n   \\]\n\n6. **Determining the coefficients**  \n   The functions \\(\\sin(n\\pi x/L)\\) are orthogonal on \\([0,L]\\):  \n   \\[\n   \\int_0^L \\sin\\!\\left(\\frac{n\\pi x}{L}\\right) \\sin\\!\\left(\\frac{m\\pi x}{L}\\right) dx = \\frac{L}{2}\\,\\delta_{nm}.\n   \\]  \n   Multiplying the initial condition by \\(\\sin(m\\pi x/L)\\) and integrating yields  \n   \\[\n   B_m = \\frac{2}{L} \\int_0^L u(x,0) \\sin\\!\\left(\\frac{m\\pi x}{L}\\right) dx.\n   \\]\n\n   - For \\(m=1\\):  \n     \\[\n     B_1 = \\frac{2}{L} \\int_0^L \\left[\\sin\\!\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\!\\left(\\frac{3\\pi x}{L}\\right)\\right] \\sin\\!\\left(\\frac{\\pi x}{L}\\right) dx\n          = \\frac{2}{L}\\left( \\int_0^L \\sin^2\\!\\left(\\frac{\\pi x}{L}\\right) dx + 2 \\int_0^L \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) \\sin\\!\\left(\\frac{\\pi x}{L}\\right) dx \\right).\n     \\]  \n     The second integral vanishes by orthogonality; the first equals \\(L/2\\). Hence \\(B_1 = \\frac{2}{L}\\cdot\\frac{L}{2}=1\\).\n\n   - For \\(m=3\\):  \n     \\[\n     B_3 = \\frac{2}{L} \\int_0^L \\left[\\sin\\!\\left(\\frac{\\pi x}{L}\\right) + 2\\sin\\!\\left(\\frac{3\\pi x}{L}\\right)\\right] \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) dx\n          = \\frac{2}{L}\\left( \\int_0^L \\sin\\!\\left(\\frac{\\pi x}{L}\\right) \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) dx + 2 \\int_0^L \\sin^2\\!\\left(\\frac{3\\pi x}{L}\\right) dx \\right).\n     \\]  \n     The first integral is zero; the second equals \\(2\\cdot(L/2)=L\\). Thus \\(B_3 = \\frac{2}{L}\\cdot L = 2\\).\n\n   - For all other \\(m\\), the integrals vanish, so \\(B_m = 0\\).\n\n7. **Final expression**  \n   Substituting the nonzero coefficients back into the series gives  \n   \\[\n   u(x,t) = 1\\cdot \\sin\\!\\left(\\frac{\\pi x}{L}\\right) e^{-\\alpha (\\pi/L)^2 t} + 2\\cdot \\sin\\!\\left(\\frac{3\\pi x}{L}\\right) e^{-\\alpha (3\\pi/L)^2 t}.\n   \\]\n\n---\n\n### Verification\n\n- **PDE:** Direct substitution shows that each term satisfies \\(\\partial_t = \\alpha \\partial_x^2\\) because each is of the separated form.\n- **Boundary conditions:** \\(\\sin(0)=0\\) and \\(\\sin(n\\pi)=0\\) ensure \\(u(0,t)=u(L,t)=0\\).\n- **Initial condition:** At \\(t=0\\) the exponentials become \\(1\\), recovering the given initial profile.\n- **Uniqueness:** The solution is unique due to the well\u2011posedness of the linear heat equation with Dirichlet boundary conditions.\n\nThus the obtained \\(u(x,t)\\) is the required solution.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of dynamical systems and ergodic theory, along with a complete and verifiable solution.\n\n## Step 2: Identify key concepts in dynamical systems and ergodic theory\nDynamical systems involve the study of the behavior of systems that change over time according to certain rules. Ergodic theory is a branch of mathematics that studies the behavior of dynamical systems over time, focusing on their statistical properties. Key concepts include ergodicity, measure-preserving transformations, and the ergodic theorem.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to incorporate concepts from dynamical systems and ergodic theory. A potential problem could involve analyzing the behavior of a specific dynamical system, such as determining if it is ergodic or calculating its invariant measures.\n\n## Step 4: Specify the problem\nLet's consider a simple yet challenging example: the rotation map on the unit circle. The unit circle can be represented as $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$, and a rotation map $T: \\mathbb{T} \\to \\mathbb{T}$ is defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$.\n\n## Step 5: Formulate the question\nWe can ask whether the rotation map $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$ when $\\alpha$ is irrational.\n\n## Step 6: Write the problem statement\n\"Let $T: \\mathbb{T} \\to \\mathbb{T}$ be defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$ is irrational. Prove that $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$.\"\n\n## Step 7: Provide the solution\nTo prove that $T$ is ergodic, we need to show that if $A \\subset \\mathbb{T}$ is $T$-invariant (i.e., $T(A) = A$) and measurable, then either $m(A) = 0$ or $m(A) = 1$, where $m$ denotes the Lebesgue measure.\n\n## Step 8: Detail the solution\nFirst, recall that $T$ is measure-preserving because $m(T^{-1}(A)) = m(A)$ for any measurable $A \\subset \\mathbb{T}$. For $T$ to be ergodic, we must show that $T$-invariant sets have measure 0 or 1.\n\n## Step 9: Use Fourier analysis to prove ergodicity\nConsider a $T$-invariant set $A$. The characteristic function $\\chi_A$ of $A$ is $T$-invariant, meaning $\\chi_A(T(x)) = \\chi_A(x)$. We can expand $\\chi_A$ in a Fourier series: $\\chi_A(x) = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi inx}$, where $c_n = \\int_{\\mathbb{T}} \\chi_A(x)e^{-2\\pi inx} dx$.\n\n## Step 10: Apply $T$-invariance to the Fourier series\nSince $\\chi_A(T(x)) = \\chi_A(x + \\alpha) = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi in(x + \\alpha)} = \\sum_{n=-\\infty}^{\\infty} c_n e^{2\\pi in\\alpha}e^{2\\pi inx}$, and this equals $\\chi_A(x)$, we have $c_n = c_n e^{2\\pi in\\alpha}$ for all $n$. For $\\alpha$ irrational, $e^{2\\pi in\\alpha} \\neq 1$ unless $n = 0$. Thus, $c_n = 0$ for $n \\neq 0$.\n\n## Step 11: Conclude ergodicity from the Fourier analysis\nThis implies $\\chi_A(x) = c_0 = \\int_{\\mathbb{T}} \\chi_A(x) dx = m(A)$, meaning $\\chi_A$ is constant. Hence, $A$ is either $\\mathbb{T}$ (if $m(A) = 1$) or $\\emptyset$ (if $m(A) = 0$), proving $T$ is ergodic.\n\n## Step 12: Format the question and answer according to the required structure\n\nLet $T: \\mathbb{T} \\to \\mathbb{T}$ be defined by $T(x) = x + \\alpha \\mod 1$, where $\\alpha \\in \\mathbb{R}$ is irrational. Prove that $T$ is ergodic with respect to the Lebesgue measure on $\\mathbb{T}$.",
    "run_id": "24",
    "outer_attempt": 1,
    "topic_slug": "dynamical_systems_and_ergodic_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Answer:**\n\nWe prove that the rotation map $T : \\mathbb{T} \\to \\mathbb{T}$ defined by $T(x) = x + \\alpha \\pmod 1$ is ergodic with respect to the Lebesgue (probability) measure $\\mu$ on the circle $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$ when $\\alpha$ is irrational.\n\n---\n\n### 1. Preliminaries\n\n- The measure space is $(\\mathbb{T}, \\mathcal{B}, \\mu)$ where $\\mathcal{B}$ are the Borel sets and $\\mu$ is Lebesgue measure normalized so that $\\mu(\\mathbb{T}) = 1$.\n- $T$ is **measure\u2011preserving**: for any $A \\in \\mathcal{B}$,\n  $$\n  \\mu(T^{-1}A) = \\mu(A).\n  $$\n  Indeed, $T^{-1}A = \\{ x : x+\\alpha \\bmod 1 \\in A \\} = A - \\alpha \\pmod 1$, and $\\mu$ is translation\u2011invariant.\n- A measure\u2011preserving transformation is **ergodic** if every measurable set $A$ with $T^{-1}A = A$ (mod $\\mu$), i.e., $\\mu(T^{-1}A \\triangle A) = 0$, satisfies $\\mu(A) = 0$ or $\\mu(A) = 1$.\n\n---\n\n### 2. Proof of Ergodicity\n\nLet $A \\in \\mathcal{B}$ be an invariant set: $\\mu(T^{-1}A \\triangle A) = 0$.  \nDefine the characteristic function $f = \\mathbf{1}_A$. Then $f \\in L^2(\\mu)$ and, because the symmetric difference has measure zero,\n$$\nf(Tx) = f(x) \\quad \\text{for } \\mu\\text{-almost every } x.\n$$\n\nFor each integer $n$, consider the Fourier coefficient\n$$\nc_n = \\int_{\\mathbb{T}} f(x) \\, e^{-2\\pi i n x} \\, d\\mu(x).\n$$\n\nWe compute the same coefficient for the function $f \\circ T$ in two different ways.\n\n**First computation (change of variable):**  \nUsing the substitution $y = Tx = x + \\alpha \\pmod 1$ (which is a bijection preserving $\\mu$),\n$$\n\\begin{aligned}\n\\int_{\\mathbb{T}} f(Tx) \\, e^{-2\\pi i n x} \\, d\\mu(x)\n&= \\int_{\\mathbb{T}} f(y) \\, e^{-2\\pi i n (y - \\alpha)} \\, d\\mu(y) \\\\\n&= e^{2\\pi i n \\alpha} \\int_{\\mathbb{T}} f(y) \\, e^{-2\\pi i n y} \\, d\\mu(y) \\\\\n&= e^{2\\pi i n \\alpha} \\, c_n.\n\\end{aligned}\n$$\n\n**Second computation (invariance):**  \nSince $f(Tx) = f(x)$ almost everywhere, the integral also equals\n$$\n\\int_{\\mathbb{T}} f(x) \\, e^{-2\\pi i n x} \\, d\\mu(x) = c_n.\n$$\n\nEquating the two expressions gives, for every $n \\in \\mathbb{Z}$,\n$$\nc_n = e^{2\\pi i n \\alpha} \\, c_n \\quad \\Longrightarrow \\quad c_n \\bigl(1 - e^{2\\pi i n \\alpha}\\bigr) = 0.\n$$\n\nIf $n \\neq 0$, the factor $1 - e^{2\\pi i n \\alpha}$ is non\u2011zero because $\\alpha$ irrational implies $n\\alpha \\notin \\mathbb{Z}$, hence $e^{2\\pi i n \\alpha} \\neq 1$. Therefore,\n$$\nc_n = 0 \\qquad (n \\neq 0).\n$$\n\nFor $n = 0$ we have\n$$\nc_0 = \\int_{\\mathbb{T}} f(x) \\, d\\mu(x) = \\mu(A).\n$$\n\nNow, the family $\\{ e^{2\\pi i n x} \\}_{n \\in \\mathbb{Z}}$ is an orthonormal basis of $L^2(\\mathbb{T},\\mu)$. The fact that all Fourier coefficients of $f$ vanish except $c_0$ means that $f$ equals the constant function $c_0$ in $L^2$, i.e.,\n$$\nf(x) = c_0 = \\mu(A) \\quad \\text{for } \\mu\\text{-almost every } x.\n$$\n\nBut $f = \\mathbf{1}_A$ takes only the values $0$ and $1$ almost everywhere. Consequently, the constant $\\mu(A)$ must be either $0$ or $1$. Hence,\n$$\n\\mu(A) = 0 \\quad \\text{or} \\quad \\mu(A) = 1.\n$$\n\nSince this holds for every $T$-invariant measurable set $A$, the transformation $T$ is ergodic. \u220e\n\n---\n\n### 3. Remarks\n\n- The proof relies crucially on the irrationality of $\\alpha$; if $\\alpha$ were rational, $e^{2\\pi i n \\alpha}=1$ for some non\u2011zero $n$ and the argument would fail, reflecting the fact that rational rotations are not ergodic.\n- The same reasoning shows that the only measurable functions invariant under an irrational rotation are constants almost everywhere (a stronger statement equivalent to ergodicity).",
        "raw_answer": "**Answer:**\n\nWe prove that the rotation map \\(T : \\mathbb{T} \\to \\mathbb{T}\\) defined by \\(T(x) = x + \\alpha \\pmod 1\\) is ergodic with respect to the Lebesgue (probability) measure \\(\\mu\\) on the circle \\(\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}\\) when \\(\\alpha\\) is irrational.\n\n---\n\n### 1. Preliminaries\n\n- The measure space is \\((\\mathbb{T}, \\mathcal{B}, \\mu)\\) where \\(\\mathcal{B}\\) are the Borel sets and \\(\\mu\\) is Lebesgue measure normalized so that \\(\\mu(\\mathbb{T}) = 1\\).\n- \\(T\\) is **measure\u2011preserving**: for any \\(A \\in \\mathcal{B}\\),\n  \\[\n  \\mu(T^{-1}A) = \\mu(A).\n  \\]\n  Indeed, \\(T^{-1}A = \\{ x : x+\\alpha \\bmod 1 \\in A \\} = A - \\alpha \\pmod 1\\), and \\(\\mu\\) is translation\u2011invariant.\n- A measure\u2011preserving transformation is **ergodic** if every measurable set \\(A\\) with \\(T^{-1}A = A\\) (mod \\(\\mu\\)), i.e., \\(\\mu(T^{-1}A \\triangle A) = 0\\), satisfies \\(\\mu(A) = 0\\) or \\(\\mu(A) = 1\\).\n\n---\n\n### 2. Proof of Ergodicity\n\nLet \\(A \\in \\mathcal{B}\\) be an invariant set: \\(\\mu(T^{-1}A \\triangle A) = 0\\).  \nDefine the characteristic function \\(f = \\mathbf{1}_A\\). Then \\(f \\in L^2(\\mu)\\) and, because the symmetric difference has measure zero,\n\\[\nf(Tx) = f(x) \\quad \\text{for } \\mu\\text{-almost every } x.\n\\]\n\nFor each integer \\(n\\), consider the Fourier coefficient\n\\[\nc_n = \\int_{\\mathbb{T}} f(x) \\, e^{-2\\pi i n x} \\, d\\mu(x).\n\\]\n\nWe compute the same coefficient for the function \\(f \\circ T\\) in two different ways.\n\n**First computation (change of variable):**  \nUsing the substitution \\(y = Tx = x + \\alpha \\pmod 1\\) (which is a bijection preserving \\(\\mu\\)),\n\\[\n\\begin{aligned}\n\\int_{\\mathbb{T}} f(Tx) \\, e^{-2\\pi i n x} \\, d\\mu(x)\n&= \\int_{\\mathbb{T}} f(y) \\, e^{-2\\pi i n (y - \\alpha)} \\, d\\mu(y) \\\\\n&= e^{2\\pi i n \\alpha} \\int_{\\mathbb{T}} f(y) \\, e^{-2\\pi i n y} \\, d\\mu(y) \\\\\n&= e^{2\\pi i n \\alpha} \\, c_n.\n\\end{aligned}\n\\]\n\n**Second computation (invariance):**  \nSince \\(f(Tx) = f(x)\\) almost everywhere, the integral also equals\n\\[\n\\int_{\\mathbb{T}} f(x) \\, e^{-2\\pi i n x} \\, d\\mu(x) = c_n.\n\\]\n\nEquating the two expressions gives, for every \\(n \\in \\mathbb{Z}\\),\n\\[\nc_n = e^{2\\pi i n \\alpha} \\, c_n \\quad \\Longrightarrow \\quad c_n \\bigl(1 - e^{2\\pi i n \\alpha}\\bigr) = 0.\n\\]\n\nIf \\(n \\neq 0\\), the factor \\(1 - e^{2\\pi i n \\alpha}\\) is non\u2011zero because \\(\\alpha\\) irrational implies \\(n\\alpha \\notin \\mathbb{Z}\\), hence \\(e^{2\\pi i n \\alpha} \\neq 1\\). Therefore,\n\\[\nc_n = 0 \\qquad (n \\neq 0).\n\\]\n\nFor \\(n = 0\\) we have\n\\[\nc_0 = \\int_{\\mathbb{T}} f(x) \\, d\\mu(x) = \\mu(A).\n\\]\n\nNow, the family \\(\\{ e^{2\\pi i n x} \\}_{n \\in \\mathbb{Z}}\\) is an orthonormal basis of \\(L^2(\\mathbb{T},\\mu)\\). The fact that all Fourier coefficients of \\(f\\) vanish except \\(c_0\\) means that \\(f\\) equals the constant function \\(c_0\\) in \\(L^2\\), i.e.,\n\\[\nf(x) = c_0 = \\mu(A) \\quad \\text{for } \\mu\\text{-almost every } x.\n\\]\n\nBut \\(f = \\mathbf{1}_A\\) takes only the values \\(0\\) and \\(1\\) almost everywhere. Consequently, the constant \\(\\mu(A)\\) must be either \\(0\\) or \\(1\\). Hence,\n\\[\n\\mu(A) = 0 \\quad \\text{or} \\quad \\mu(A) = 1.\n\\]\n\nSince this holds for every \\(T\\)-invariant measurable set \\(A\\), the transformation \\(T\\) is ergodic. \u220e\n\n---\n\n### 3. Remarks\n\n- The proof relies crucially on the irrationality of \\(\\alpha\\); if \\(\\alpha\\) were rational, \\(e^{2\\pi i n \\alpha}=1\\) for some non\u2011zero \\(n\\) and the argument would fail, reflecting the fact that rational rotations are not ergodic.\n- The same reasoning shows that the only measurable functions invariant under an irrational rotation are constants almost everywhere (a stronger statement equivalent to ergodicity).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of difference and functional equations, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the key elements of a good problem in the domain\nA good problem in the domain of difference and functional equations should involve a functional equation or a difference equation that requires substantive mathematical reasoning to solve. It should be fully specified, with clear notation and constraints.\n\n## Step 3: Generate a problem\nLet's generate a problem: \"Find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation $f(x + y) = f(x) + f(y) + xy$ for all $x, y \\in \\mathbb{R}$, and $f(1) = 1$.\"\n\n## Step 4: Verify that the generated problem meets the quality rubric\n- **Well-Posedness and Completeness**: The problem is fully self-contained, with the domain and codomain of $f$ specified, and the functional equation given.\n- **Clarity**: The notation is standard, and the task is clear.\n- **Non-Triviality**: The problem requires solving a functional equation, which is non-trivial.\n- **Solvability and Verification**: The problem is solvable using established methods for functional equations.\n\n## Step 5: Solve the generated problem\nTo solve $f(x + y) = f(x) + f(y) + xy$, let's first try substituting specific values for $x$ and $y$ to derive additional information.\n\n## Step 6: Substitute $x = y = 0$ into the equation\n$f(0 + 0) = f(0) + f(0) + 0 \\cdot 0$ simplifies to $f(0) = 2f(0)$, which implies $f(0) = 0$.\n\n## Step 7: Substitute $y = 1$ into the original equation\n$f(x + 1) = f(x) + f(1) + x = f(x) + x + 1$, since $f(1) = 1$. This gives a recursive formula to find $f(x)$ for integer values of $x$.\n\n## Step 8: Use the recursive formula to find $f(n)$ for any integer $n$\nStarting from $f(0) = 0$ and $f(1) = 1$, we can derive $f(2)$, $f(3)$, etc., to look for a pattern. $f(2) = f(1) + f(1) + 1 = 3$, $f(3) = f(2) + f(1) + 2 = 6$. It appears that $f(n) = \\frac{n(n+1)}{2}$ for positive integers $n$.\n\n## Step 9: Check if $f(x) = \\frac{x(x+1)}{2}$ satisfies the original functional equation\nSubstitute $f(x) = \\frac{x(x+1)}{2}$ into $f(x + y) = f(x) + f(y) + xy$:\n- LHS: $f(x + y) = \\frac{(x+y)(x+y+1)}{2} = \\frac{x^2 + 2xy + y^2 + x + y}{2}$\n- RHS: $f(x) + f(y) + xy = \\frac{x(x+1)}{2} + \\frac{y(y+1)}{2} + xy = \\frac{x^2 + x + y^2 + y + 2xy}{2}$\nBoth sides are equal, so $f(x) = \\frac{x(x+1)}{2}$ is a solution.\n\n## Step 10: Verify that the solution satisfies the initial condition\n$f(1) = \\frac{1(1+1)}{2} = 1$, which matches the given condition.\n\nThe final answer is: \n\nFind all functions $f: \\mathbb{R} \\to \\mathbb{R}$ that satisfy the functional equation $f(x + y) = f(x) + f(y) + xy$ for all $x, y \\in \\mathbb{R}$, and $f(1) = 1$.",
    "run_id": "25",
    "outer_attempt": 1,
    "topic_slug": "difference_and_functional_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked to find all functions $f:\\mathbb{R}\\to\\mathbb{R}$ such that  \n$$f(x+y)=f(x)+f(y)+xy\\qquad\\text{for all }x,y\\in\\mathbb{R},$$  \nand $f(1)=1$.\n\n---\n\n### Step 1. Determine $f(0)$\n\nSet $x=y=0$:  \n$$f(0)=f(0)+f(0)+0\\quad\\Longrightarrow\\quad f(0)=0.$$\n\n---\n\n### Step 2. Transform to a Cauchy equation\n\nDefine $g(x)=f(x)-\\dfrac{x^2}{2}$. Then for any $x,y$,\n$$\n\\begin{aligned}\ng(x+y)&=f(x+y)-\\frac{(x+y)^2}{2}\\$$2mm]\n&=\\bigl[f(x)+f(y)+xy\\bigr]-\\frac{x^2+2xy+y^2}{2}\\$$2mm]\n&=f(x)+f(y)+xy-\\frac{x^2}{2}-xy-\\frac{y^2}{2}\\$$2mm]\n&=\\left(f(x)-\\frac{x^2}{2}\\right)+\\left(f(y)-\\frac{y^2}{2}\\right)\\$$2mm]\n&=g(x)+g(y).\n\\end{aligned}\n$$\nThus $g$ satisfies **Cauchy's functional equation**  \n$$g(x+y)=g(x)+g(y)\\qquad\\text{for all }x,y\\in\\mathbb{R},$$  \ni.e., $g$ is an *additive* function.\n\n---\n\n### Step 3. Use the condition $f(1)=1$\n\nFrom $f(1)=1$ we obtain  \n$$g(1)=f(1)-\\frac{1^2}{2}=1-\\frac12=\\frac12.$$\n\n---\n\n### Step 4. Characterise all solutions\n\nThe above steps show that any solution $f$ must be of the form  \n$$f(x)=\\frac{x^2}{2}+g(x),$$  \nwhere $g:\\mathbb{R}\\to\\mathbb{R}$ is additive and satisfies $g(1)=\\frac12$.\n\nConversely, if $g$ is any additive function with $g(1)=\\frac12$, then defining $f$ by $f(x)=\\frac{x^2}{2}+g(x)$ gives  \n$$\n\\begin{aligned}\nf(x+y)&=\\frac{(x+y)^2}{2}+g(x+y)\\\\\n&=\\frac{x^2+2xy+y^2}{2}+g(x)+g(y)\\\\\n&=\\left(\\frac{x^2}{2}+g(x)\\right)+\\left(\\frac{y^2}{2}+g(y)\\right)+xy\\\\\n&=f(x)+f(y)+xy,\n\\end{aligned}\n$$\nand $f(1)=\\frac12+g(1)=\\frac12+\\frac12=1$. Hence every such $g$ yields a valid $f$.\n\nTherefore **the general solution** is  \n$$\n\\boxed{f(x)=\\frac{x^2}{2}+A(x),\\quad\\text{where }A:\\mathbb{R}\\to\\mathbb{R}\\text{ is additive and }A(1)=\\frac12.}\n$$\n\n---\n\n### Remarks on additive functions\n\nAn additive function $A$ satisfies $A(x+y)=A(x)+A(y)$ for all real $x,y$. Such functions are exactly the $\\mathbb{Q}$-linear maps when $\\mathbb{R}$ is viewed as a vector space over $\\mathbb{Q}$. Without further regularity assumptions (continuity, measurability, boundedness on an interval, etc.) there exist many additive functions that are not of the form $A(x)=cx$; they can be constructed using a Hamel basis of $\\mathbb{R}$ over $\\mathbb{Q}$. The condition $A(1)=\\frac12$ fixes the value on all rational numbers: $A(q)=q\\cdot\\frac12$ for every $q\\in\\mathbb{Q}$, but on irrational numbers $A$ may be chosen arbitrarily subject only to additivity.\n\nIf one imposes any natural regularity condition (e.g., continuity, monotonicity, measurability, or local boundedness), then $A(x)=\\frac{x}{2}$ for all $x$, yielding the unique polynomial solution  \n$$f(x)=\\frac{x^2}{2}+\\frac{x}{2}=\\frac{x(x+1)}{2}.$$  \nIn the absence of such extra hypotheses, however, the description above gives **all** solutions.",
        "raw_answer": "We are asked to find all functions $f:\\mathbb{R}\\to\\mathbb{R}$ such that  \n$$f(x+y)=f(x)+f(y)+xy\\qquad\\text{for all }x,y\\in\\mathbb{R},$$  \nand $f(1)=1$.\n\n---\n\n### Step 1. Determine $f(0)$\n\nSet $x=y=0$:  \n$$f(0)=f(0)+f(0)+0\\quad\\Longrightarrow\\quad f(0)=0.$$\n\n---\n\n### Step 2. Transform to a Cauchy equation\n\nDefine $g(x)=f(x)-\\dfrac{x^2}{2}$. Then for any $x,y$,\n$$\n\\begin{aligned}\ng(x+y)&=f(x+y)-\\frac{(x+y)^2}{2}\\\\[2mm]\n&=\\bigl[f(x)+f(y)+xy\\bigr]-\\frac{x^2+2xy+y^2}{2}\\\\[2mm]\n&=f(x)+f(y)+xy-\\frac{x^2}{2}-xy-\\frac{y^2}{2}\\\\[2mm]\n&=\\left(f(x)-\\frac{x^2}{2}\\right)+\\left(f(y)-\\frac{y^2}{2}\\right)\\\\[2mm]\n&=g(x)+g(y).\n\\end{aligned}\n$$\nThus $g$ satisfies **Cauchy's functional equation**  \n$$g(x+y)=g(x)+g(y)\\qquad\\text{for all }x,y\\in\\mathbb{R},$$  \ni.e., $g$ is an *additive* function.\n\n---\n\n### Step 3. Use the condition $f(1)=1$\n\nFrom $f(1)=1$ we obtain  \n$$g(1)=f(1)-\\frac{1^2}{2}=1-\\frac12=\\frac12.$$\n\n---\n\n### Step 4. Characterise all solutions\n\nThe above steps show that any solution $f$ must be of the form  \n$$f(x)=\\frac{x^2}{2}+g(x),$$  \nwhere $g:\\mathbb{R}\\to\\mathbb{R}$ is additive and satisfies $g(1)=\\frac12$.\n\nConversely, if $g$ is any additive function with $g(1)=\\frac12$, then defining $f$ by $f(x)=\\frac{x^2}{2}+g(x)$ gives  \n$$\n\\begin{aligned}\nf(x+y)&=\\frac{(x+y)^2}{2}+g(x+y)\\\\\n&=\\frac{x^2+2xy+y^2}{2}+g(x)+g(y)\\\\\n&=\\left(\\frac{x^2}{2}+g(x)\\right)+\\left(\\frac{y^2}{2}+g(y)\\right)+xy\\\\\n&=f(x)+f(y)+xy,\n\\end{aligned}\n$$\nand $f(1)=\\frac12+g(1)=\\frac12+\\frac12=1$. Hence every such $g$ yields a valid $f$.\n\nTherefore **the general solution** is  \n$$\n\\boxed{f(x)=\\frac{x^2}{2}+A(x),\\quad\\text{where }A:\\mathbb{R}\\to\\mathbb{R}\\text{ is additive and }A(1)=\\frac12.}\n$$\n\n---\n\n### Remarks on additive functions\n\nAn additive function $A$ satisfies $A(x+y)=A(x)+A(y)$ for all real $x,y$. Such functions are exactly the $\\mathbb{Q}$-linear maps when $\\mathbb{R}$ is viewed as a vector space over $\\mathbb{Q}$. Without further regularity assumptions (continuity, measurability, boundedness on an interval, etc.) there exist many additive functions that are not of the form $A(x)=cx$; they can be constructed using a Hamel basis of $\\mathbb{R}$ over $\\mathbb{Q}$. The condition $A(1)=\\frac12$ fixes the value on all rational numbers: $A(q)=q\\cdot\\frac12$ for every $q\\in\\mathbb{Q}$, but on irrational numbers $A$ may be chosen arbitrarily subject only to additivity.\n\nIf one imposes any natural regularity condition (e.g., continuity, monotonicity, measurability, or local boundedness), then $A(x)=\\frac{x}{2}$ for all $x$, yielding the unique polynomial solution  \n$$f(x)=\\frac{x^2}{2}+\\frac{x}{2}=\\frac{x(x+1)}{2}.$$  \nIn the absence of such extra hypotheses, however, the description above gives **all** solutions.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$.",
    "run_id": "26",
    "outer_attempt": 1,
    "topic_slug": "sequences_series_and_summability",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We evaluate the series\n\n$$\nS = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}.\n$$\n\n**Step 1. Convergence.**  \nSince $\\left|\\frac{(-1)^{n+1}}{n(n+1)}\\right| = \\frac{1}{n(n+1)} \\sim \\frac{1}{n^2}$ and $\\sum_{n=1}^{\\infty} \\frac{1}{n^2}$ converges, the series converges absolutely. Hence all rearrangements and term\u2011wise operations are justified.\n\n**Step 2. Partial fractions.**  \nFor every $n\\ge 1$,\n\n$$\n\\frac{1}{n(n+1)} = \\frac{1}{n} - \\frac{1}{n+1}.\n$$\n\nThus\n\n$$\n\\frac{(-1)^{n+1}}{n(n+1)} = (-1)^{n+1}\\left(\\frac{1}{n} - \\frac{1}{n+1}\\right).\n$$\n\n**Step 3. Partial sum.**  \nLet\n\n$$\nS_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n(n+1)}.\n$$\n\nThen\n\n$$\nS_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} - \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1}.\n$$\n\n**Step 4. Index shift in the second sum.**  \nSet $k = n+1$. When $n=1$, $k=2$; when $n=N$, $k=N+1$. Hence\n\n$$\n\\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1} = \\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k}.\n$$\n\n**Step 5. Express in terms of alternating harmonic partial sums.**  \nDefine\n\n$$\nH_M = \\sum_{m=1}^{M} \\frac{(-1)^{m+1}}{m}.\n$$\n\nThen the first sum is simply $H_N$. For the second sum we write\n\n$$\n\\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k} = \\left(\\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k}\\right) - \\frac{(-1)^1}{1}.\n$$\n\nSince $\\frac{(-1)^1}{1} = -1$, this becomes\n\n$$\n\\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k} = \\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k} + 1.\n$$\n\nBut $\\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k} = -H_{N+1}$ because $(-1)^{k} = -(-1)^{k+1}$. Therefore\n\n$$\n\\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1} = -H_{N+1} + 1.\n$$\n\n**Step 6. Combine.**  \nSubstituting into the expression for $S_N$,\n\n$$\nS_N = H_N - \\bigl(-H_{N+1} + 1\\bigr) = H_N + H_{N+1} - 1.\n$$\n\n**Step 7. Take the limit $N\\to\\infty$.**  \nThe alternating harmonic series converges to $\\ln 2$:\n\n$$\n\\lim_{M\\to\\infty} H_M = \\sum_{m=1}^{\\infty} \\frac{(-1)^{m+1}}{m} = \\ln 2.\n$$\n\nThus\n\n$$\n\\lim_{N\\to\\infty} H_N = \\ln 2, \\qquad \\lim_{N\\to\\infty} H_{N+1} = \\ln 2.\n$$\n\nConsequently,\n\n$$\nS = \\lim_{N\\to\\infty} S_N = \\ln 2 + \\ln 2 - 1 = 2\\ln 2 - 1.\n$$\n\n**Conclusion.**\n\n$$\n\\boxed{2\\ln 2 - 1}\n$$\n\n(Equivalently, $\\ln 4 - 1$.)",
        "raw_answer": "We evaluate the series\n\n\\[\nS = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}.\n\\]\n\n**Step 1. Convergence.**  \nSince \\(\\left|\\frac{(-1)^{n+1}}{n(n+1)}\\right| = \\frac{1}{n(n+1)} \\sim \\frac{1}{n^2}\\) and \\(\\sum_{n=1}^{\\infty} \\frac{1}{n^2}\\) converges, the series converges absolutely. Hence all rearrangements and term\u2011wise operations are justified.\n\n**Step 2. Partial fractions.**  \nFor every \\(n\\ge 1\\),\n\n\\[\n\\frac{1}{n(n+1)} = \\frac{1}{n} - \\frac{1}{n+1}.\n\\]\n\nThus\n\n\\[\n\\frac{(-1)^{n+1}}{n(n+1)} = (-1)^{n+1}\\left(\\frac{1}{n} - \\frac{1}{n+1}\\right).\n\\]\n\n**Step 3. Partial sum.**  \nLet\n\n\\[\nS_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n(n+1)}.\n\\]\n\nThen\n\n\\[\nS_N = \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n} - \\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1}.\n\\]\n\n**Step 4. Index shift in the second sum.**  \nSet \\(k = n+1\\). When \\(n=1\\), \\(k=2\\); when \\(n=N\\), \\(k=N+1\\). Hence\n\n\\[\n\\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1} = \\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k}.\n\\]\n\n**Step 5. Express in terms of alternating harmonic partial sums.**  \nDefine\n\n\\[\nH_M = \\sum_{m=1}^{M} \\frac{(-1)^{m+1}}{m}.\n\\]\n\nThen the first sum is simply \\(H_N\\). For the second sum we write\n\n\\[\n\\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k} = \\left(\\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k}\\right) - \\frac{(-1)^1}{1}.\n\\]\n\nSince \\(\\frac{(-1)^1}{1} = -1\\), this becomes\n\n\\[\n\\sum_{k=2}^{N+1} \\frac{(-1)^{k}}{k} = \\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k} + 1.\n\\]\n\nBut \\(\\sum_{k=1}^{N+1} \\frac{(-1)^{k}}{k} = -H_{N+1}\\) because \\((-1)^{k} = -(-1)^{k+1}\\). Therefore\n\n\\[\n\\sum_{n=1}^{N} \\frac{(-1)^{n+1}}{n+1} = -H_{N+1} + 1.\n\\]\n\n**Step 6. Combine.**  \nSubstituting into the expression for \\(S_N\\),\n\n\\[\nS_N = H_N - \\bigl(-H_{N+1} + 1\\bigr) = H_N + H_{N+1} - 1.\n\\]\n\n**Step 7. Take the limit \\(N\\to\\infty\\).**  \nThe alternating harmonic series converges to \\(\\ln 2\\):\n\n\\[\n\\lim_{M\\to\\infty} H_M = \\sum_{m=1}^{\\infty} \\frac{(-1)^{m+1}}{m} = \\ln 2.\n\\]\n\nThus\n\n\\[\n\\lim_{N\\to\\infty} H_N = \\ln 2, \\qquad \\lim_{N\\to\\infty} H_{N+1} = \\ln 2.\n\\]\n\nConsequently,\n\n\\[\nS = \\lim_{N\\to\\infty} S_N = \\ln 2 + \\ln 2 - 1 = 2\\ln 2 - 1.\n\\]\n\n**Conclusion.**\n\n\\[\n\\boxed{2\\ln 2 - 1}\n\\]\n\n(Equivalently, \\(\\ln 4 - 1\\).)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the topic\nThe task is to generate a challenging mathematics problem along with a complete and verifiable solution in the domain of \"Approximations and expansions.\" The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within \"Approximations and expansions\"\nA suitable topic could involve Taylor series expansions, asymptotic approximations, or other related areas where mathematical functions are approximated.\n\n## Step 3: Formulate a challenging problem\nLet's consider a problem involving the approximation of a function using its Taylor series expansion. A classic example is approximating $e^x$ or $\\sin(x)$ around $x = 0$. However, to make it more challenging, we could involve a less straightforward function or require the derivation of an approximation under certain conditions.\n\n## Step 4: Create a specific problem\nConsider the function $f(x) = \\frac{1}{\\sqrt{1 + x}}$. We can ask to find the Taylor series expansion of $f(x)$ around $x = 0$ up to the third term and then use this expansion to approximate $f(0.1)$.\n\n## Step 5: Formulate the problem statement\nLet's refine the problem: \"Find the Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to and including the term involving $x^3$. Then, use this expansion to approximate $f(0.1)$ and compare it with the exact value.\"\n\n## Step 6: Write the problem in the required format\n\nFind the Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ around $x = 0$ up to and including the term involving $x^3$. Then, use this expansion to approximate $f(0.1)$ and compare it with the exact value.",
    "run_id": "27",
    "outer_attempt": 1,
    "topic_slug": "approximations_and_expansions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The Taylor series expansion of $f(x) = \\frac{1}{\\sqrt{1 + x}}$ about $x = 0$ up to the $x^3$ term is\n\n$$\nf(x) = 1 - \\frac{1}{2}x + \\frac{3}{8}x^2 - \\frac{5}{16}x^3 + O(x^4).\n$$\n\nUsing this expansion to approximate $f(0.1)$ gives\n\n$$\nf(0.1) \\approx 1 - \\frac{1}{2}(0.1) + \\frac{3}{8}(0.1)^2 - \\frac{5}{16}(0.1)^3 = 1 - 0.05 + 0.00375 - 0.0003125 = 0.9534375.\n$$\n\nThe exact value is\n\n$$\nf(0.1) = \\frac{1}{\\sqrt{1.1}} \\approx 0.953462589.\n$$\n\nThe difference between the approximation and the exact value is approximately $0.000025089$, and the relative error is about $2.63 \\times 10^{-5}$ (or $0.00263\\%$). The cubic Taylor polynomial thus provides an accurate approximation for this small argument.",
        "raw_answer": "The Taylor series expansion of \\(f(x) = \\frac{1}{\\sqrt{1 + x}}\\) about \\(x = 0\\) up to the \\(x^3\\) term is\n\n\\[\nf(x) = 1 - \\frac{1}{2}x + \\frac{3}{8}x^2 - \\frac{5}{16}x^3 + O(x^4).\n\\]\n\nUsing this expansion to approximate \\(f(0.1)\\) gives\n\n\\[\nf(0.1) \\approx 1 - \\frac{1}{2}(0.1) + \\frac{3}{8}(0.1)^2 - \\frac{5}{16}(0.1)^3 = 1 - 0.05 + 0.00375 - 0.0003125 = 0.9534375.\n\\]\n\nThe exact value is\n\n\\[\nf(0.1) = \\frac{1}{\\sqrt{1.1}} \\approx 0.953462589.\n\\]\n\nThe difference between the approximation and the exact value is approximately \\(0.000025089\\), and the relative error is about \\(2.63 \\times 10^{-5}\\) (or \\(0.00263\\%\\)). The cubic Taylor polynomial thus provides an accurate approximation for this small argument.",
        "evaluation": {
          "verdict": "fail",
          "ill_posed": false,
          "issues": [
            "The answer does not show the derivation of the Taylor series coefficients; it simply states the result without justification."
          ],
          "improvements": "Provide a step-by-step derivation, e.g., using the binomial series expansion or computing derivatives, to show how the coefficients are obtained. This makes the solution complete and verifiable."
        }
      },
      {
        "round": 2,
        "answer": "**Solution**\n\nWe find the Taylor series expansion of \\(f(x) = \\frac{1}{\\sqrt{1+x}} = (1+x)^{-1/2}\\) about \\(x=0\\) up to the \\(x^3\\) term. The binomial series expansion for \\(|x|<1\\) is\n\n\\[\n(1+x)^{\\alpha} = \\sum_{k=0}^{\\infty} \\binom{\\alpha}{k} x^{k},\n\\qquad \\binom{\\alpha}{k} = \\frac{\\alpha(\\alpha-1)\\cdots(\\alpha-k+1)}{k!}.\n\\]\n\nHere \\(\\alpha = -\\frac12\\). Computing the coefficients for \\(k=0,1,2,3\\):\n\n- \\(k=0\\): \\(\\binom{-\\frac12}{0} = 1\\).\n\n- \\(k=1\\): \\(\\binom{-\\frac12}{1} = -\\frac12\\).\n\n- \\(k=2\\): \\(\\binom{-\\frac12}{2} = \\dfrac{(-\\frac12)(-\\frac32)}{2!} = \\dfrac{3/4}{2} = \\frac38\\).\n\n- \\(k=3\\): \\(\\binom{-\\frac12}{3} = \\dfrac{(-\\frac12)(-\\frac32)(-\\frac52)}{3!} = \\dfrac{(-\\frac12)(-\\frac32)(-\\frac52)}{6} = \\dfrac{-\\frac{15}{8}}{6} = -\\frac{15}{48} = -\\frac{5}{16}\\).\n\nThus the required Taylor polynomial is\n\n\\[\nf(x) = 1 - \\frac12 x + \\frac38 x^2 - \\frac{5}{16} x^3 + O(x^4).\n\\]\n\nNow use this polynomial to approximate \\(f(0.1)\\):\n\n\\[\n\\begin{aligned}\nf(0.1) &\\approx 1 - \\frac12(0.1) + \\frac38(0.1)^2 - \\frac{5}{16}(0.1)^3 \\\\[4pt]\n&= 1 - 0.05 + \\frac38 \\cdot 0.01 - \\frac{5}{16} \\cdot 0.001 \\\\[4pt]\n&= 1 - 0.05 + 0.00375 - 0.0003125 \\\\[4pt]\n&= 0.9534375.\n\\end{aligned}\n\\]\n\nThe exact value is\n\n\\[\nf(0.1) = \\frac{1}{\\sqrt{1.1}} \\approx 0.953462589.\n\\]\n\nThe absolute error is\n\n\\[\n0.953462589 - 0.9534375 = 0.000025089,\n\\]\n\nand the relative error is\n\n\\[\n\\frac{0.000025089}{0.953462589} \\approx 2.63 \\times 10^{-5} = 0.00263\\%.\n\\]\n\nHence the cubic Taylor polynomial provides an accurate approximation for \\(x=0.1\\). (The series converges for \\(|x|<1\\), so the approximation is valid.)",
        "raw_answer": "**Solution**\n\nWe find the Taylor series expansion of \\(f(x) = \\frac{1}{\\sqrt{1+x}} = (1+x)^{-1/2}\\) about \\(x=0\\) up to the \\(x^3\\) term. The binomial series expansion for \\(|x|<1\\) is\n\n\\[\n(1+x)^{\\alpha} = \\sum_{k=0}^{\\infty} \\binom{\\alpha}{k} x^{k},\n\\qquad \\binom{\\alpha}{k} = \\frac{\\alpha(\\alpha-1)\\cdots(\\alpha-k+1)}{k!}.\n\\]\n\nHere \\(\\alpha = -\\frac12\\). Computing the coefficients for \\(k=0,1,2,3\\):\n\n- \\(k=0\\): \\(\\binom{-\\frac12}{0} = 1\\).\n\n- \\(k=1\\): \\(\\binom{-\\frac12}{1} = -\\frac12\\).\n\n- \\(k=2\\): \\(\\binom{-\\frac12}{2} = \\dfrac{(-\\frac12)(-\\frac32)}{2!} = \\dfrac{3/4}{2} = \\frac38\\).\n\n- \\(k=3\\): \\(\\binom{-\\frac12}{3} = \\dfrac{(-\\frac12)(-\\frac32)(-\\frac52)}{3!} = \\dfrac{(-\\frac12)(-\\frac32)(-\\frac52)}{6} = \\dfrac{-\\frac{15}{8}}{6} = -\\frac{15}{48} = -\\frac{5}{16}\\).\n\nThus the required Taylor polynomial is\n\n\\[\nf(x) = 1 - \\frac12 x + \\frac38 x^2 - \\frac{5}{16} x^3 + O(x^4).\n\\]\n\nNow use this polynomial to approximate \\(f(0.1)\\):\n\n\\[\n\\begin{aligned}\nf(0.1) &\\approx 1 - \\frac12(0.1) + \\frac38(0.1)^2 - \\frac{5}{16}(0.1)^3 \\\\[4pt]\n&= 1 - 0.05 + \\frac38 \\cdot 0.01 - \\frac{5}{16} \\cdot 0.001 \\\\[4pt]\n&= 1 - 0.05 + 0.00375 - 0.0003125 \\\\[4pt]\n&= 0.9534375.\n\\end{aligned}\n\\]\n\nThe exact value is\n\n\\[\nf(0.1) = \\frac{1}{\\sqrt{1.1}} \\approx 0.953462589.\n\\]\n\nThe absolute error is\n\n\\[\n0.953462589 - 0.9534375 = 0.000025089,\n\\]\n\nand the relative error is\n\n\\[\n\\frac{0.000025089}{0.953462589} \\approx 2.63 \\times 10^{-5} = 0.00263\\%.\n\\]\n\nHence the cubic Taylor polynomial provides an accurate approximation for \\(x=0.1\\). (The series converges for \\(|x|<1\\), so the approximation is valid.)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ and suppose that its Fourier transform $\\hat{f}$ is supported in the ball $B(0,1) = \\{ \\xi \\in \\mathbb{R}^n : |\\xi| \\leq 1 \\}$. Prove that $f$ is smooth, i.e., $f \\in C^\\infty(\\mathbb{R}^n)$, and that for any multi-index $\\alpha$, there exists a constant $C_\\alpha > 0$ such that $|\\partial^\\alpha f(x)| \\leq C_\\alpha (1 + |x|)^{-n-1}$ for all $x \\in \\mathbb{R}^n$.",
    "run_id": "28",
    "outer_attempt": 1,
    "topic_slug": "harmonic_analysis_on_euclidean_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The question is ill\u2011posed: the decay estimate $|\\partial^\\alpha f(x)|\\le C_\\alpha(1+|x|)^{-n-1}$ does **not** follow from the hypotheses $f\\in L^1(\\mathbb R^n)\\cap L^2(\\mathbb R^n)$ and $\\operatorname{supp}\\hat f\\subseteq B(0,1)$. A counterexample (for any $n\\ge1$) satisfying all assumptions but violating the bound can be constructed. The smoothness assertion $f\\in C^\\infty(\\mathbb R^n)$ is, however, correct.\n\n### 1. Why the question is ill\u2011posed\nThe problem asks to prove a statement that is false as written. The hypotheses are too weak to guarantee the claimed polynomial decay rate; the missing condition is additional regularity of $\\hat f$ (e.g., $\\hat f\\in C^{n}$ or $\\hat f\\in C^\\infty_c$). Without such regularity, the decay can be slower than $(1+|x|)^{-n-1}$, as demonstrated below.\n\n### 2. Counterexample (case $n=1$)\nLet $0<\\beta<1$ and define  \n$$\n\\hat f(\\xi) = (1-|\\xi|)^\\beta \\chi_{[-1,1]}(\\xi),\n$$  \nwhere $\\chi_{[-1,1]}$ is the characteristic function of $[-1,1]$. Clearly $\\hat f$ is continuous (because $\\beta>0$) and $\\operatorname{supp}\\hat f\\subseteq[-1,1]$. Moreover, $\\hat f\\in L^2(\\mathbb R)$ because it is bounded and compactly supported.\n\nThe inverse Fourier transform (using the convention $\\hat f(\\xi)=\\int f(x)e^{-2\\pi i x\\xi}\\,dx$) is  \n$$\nf(x)=\\int_{-1}^1 (1-|\\xi|)^\\beta e^{2\\pi i x\\xi}\\,d\\xi\n      =2\\int_0^1 (1-\\xi)^\\beta \\cos(2\\pi x\\xi)\\,d\\xi.\n$$\n\nWe verify that $f\\in L^1(\\mathbb R)\\cap L^2(\\mathbb R)$:\n- **$L^2$:** By Plancherel, $\\|f\\|_{L^2}=\\|\\hat f\\|_{L^2}<\\infty$.\n- **$L^1$:** For large $|x|$, standard asymptotic analysis (see below) gives  \n  $$\n  |f(x)| \\sim C_\\beta\\, |x|^{-\\beta-1}\\qquad (|x|\\to\\infty).\n  $$  \n  Since $\\beta+1>1$, the tail $\\int_{|x|>1}|f(x)|\\,dx$ converges; near $x=0$ the function is bounded. Hence $f\\in L^1$.\n\nThus $f$ satisfies all the hypotheses.\n\n#### Asymptotic decay of $f$\nWrite for $x>0$ (the case $x<0$ is symmetric)\n$$\nf(x)=2\\operatorname{Re}\\!\\left(e^{2\\pi i x}\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du\\right),\\qquad u=1-\\xi.\n$$\nThe integral $\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du$ has the well\u2011known asymptotic expansion (see, e.g., Erd\u00e9lyi, *Asymptotic Expansions*)\n$$\n\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du = \n\\Gamma(\\beta+1)(2\\pi i x)^{-\\beta-1} + O\\bigl(|x|^{-\\beta-2}\\bigr),\\qquad x\\to\\infty.\n$$\nConsequently,\n$$\n|f(x)| = \\frac{2\\Gamma(\\beta+1)}{(2\\pi)^{\\beta+1}}\\,|x|^{-\\beta-1} + O\\bigl(|x|^{-\\beta-2}\\bigr).\n$$\nIn particular, there exist constants $c,C>0$ such that for all sufficiently large $|x|$,\n$$\nc\\,|x|^{-\\beta-1} \\le |f(x)| \\le C\\,|x|^{-\\beta-1}.\n$$\n\n#### Failure of the claimed bound\nBecause $0<\\beta<1$, we have $\\beta+1<2$. Therefore\n$$\n\\lim_{|x|\\to\\infty} |f(x)|\\,(1+|x|)^{2} = \\infty.\n$$\nHence **no** constant $C_0$ can satisfy $|f(x)|\\le C_0(1+|x|)^{-2}$ for all $x$. This already contradicts the required inequality for the multi\u2011index $\\alpha=0$.\n\n**Remark.** The same construction works in $\\mathbb R^n$ by taking $\\hat f(\\xi)=(1-|\\xi|)^\\beta$ for $|\\xi|\\le1$ and $0$ otherwise, with $0<\\beta<n/2$. Then $f$ decays like $|x|^{-\\beta-1-n/2}$ (by the asymptotics of radial Fourier transforms), and the condition $\\beta+1+n/2 < n+1$ (i.e., $\\beta<n/2$) makes the decay slower than $(1+|x|)^{-n-1}$. The $L^1$ condition requires $\\beta+1+n/2 > n$, i.e., $\\beta>0$, so such $\\beta$ exist. Thus the counterexample is valid in any dimension.\n\n### 3. The smoothness part is true\nAlthough the decay estimate fails, the claim that $f$ is smooth is correct and can be proved as follows. Because $\\hat f$ is supported in the compact set $\\overline{B(0,1)}$ and belongs to $L^1(\\mathbb R^n)$ (it is in $L^2$ and compactly supported, hence in $L^1$), the inversion formula\n$$\nf(x)=\\int_{B(0,1)} \\hat f(\\xi)\\,e^{2\\pi i x\\cdot\\xi}\\,d\\xi\n$$\nholds for every $x$ and represents $f$ as a continuous function. For any multi\u2011index $\\alpha$, differentiation under the integral sign yields\n$$\n\\partial^\\alpha f(x)=\\int_{B(0,1)} \\hat f(\\xi)\\,(2\\pi i\\xi)^\\alpha e^{2\\pi i x\\cdot\\xi}\\,d\\xi.\n$$\nThe integrand is bounded by $|\\hat f(\\xi)|\\,(2\\pi)^\\alpha$ (since $|\\xi|\\le1$) and $\\hat f\\in L^1$; thus $\\partial^\\alpha f$ exists, is continuous, and the differentiation is justified. Hence $f\\in C^\\infty(\\mathbb R^n)$.\n\n### 4. Conclusion\nThe problem is ill\u2011posed because the stated decay estimate does **not** follow from the given assumptions. To make the statement true one would need additional regularity on $\\hat f$ (e.g., $\\hat f\\in C^{n}_c$ or $\\hat f\\in C^\\infty_c$), which would imply rapid decay of $f$. Alternatively, the conclusion could be weakened to, say, $|\\partial^\\alpha f(x)|\\le C_{\\alpha,N}(1+|x|)^{-N}$ for every $N$ (which would require $\\hat f\\in C^\\infty_c$).\n\n**Therefore the question cannot be answered as stated; it is ill\u2011posed due to a missing hypothesis.**",
        "raw_answer": "The question is ill\u2011posed: the decay estimate \\(|\\partial^\\alpha f(x)|\\le C_\\alpha(1+|x|)^{-n-1}\\) does **not** follow from the hypotheses \\(f\\in L^1(\\mathbb R^n)\\cap L^2(\\mathbb R^n)\\) and \\(\\operatorname{supp}\\hat f\\subseteq B(0,1)\\). A counterexample (for any \\(n\\ge1\\)) satisfying all assumptions but violating the bound can be constructed. The smoothness assertion \\(f\\in C^\\infty(\\mathbb R^n)\\) is, however, correct.\n\n### 1. Why the question is ill\u2011posed\nThe problem asks to prove a statement that is false as written. The hypotheses are too weak to guarantee the claimed polynomial decay rate; the missing condition is additional regularity of \\(\\hat f\\) (e.g., \\(\\hat f\\in C^{n}\\) or \\(\\hat f\\in C^\\infty_c\\)). Without such regularity, the decay can be slower than \\((1+|x|)^{-n-1}\\), as demonstrated below.\n\n### 2. Counterexample (case \\(n=1\\))\nLet \\(0<\\beta<1\\) and define  \n\\[\n\\hat f(\\xi) = (1-|\\xi|)^\\beta \\chi_{[-1,1]}(\\xi),\n\\]  \nwhere \\(\\chi_{[-1,1]}\\) is the characteristic function of \\([-1,1]\\). Clearly \\(\\hat f\\) is continuous (because \\(\\beta>0\\)) and \\(\\operatorname{supp}\\hat f\\subseteq[-1,1]\\). Moreover, \\(\\hat f\\in L^2(\\mathbb R)\\) because it is bounded and compactly supported.\n\nThe inverse Fourier transform (using the convention \\(\\hat f(\\xi)=\\int f(x)e^{-2\\pi i x\\xi}\\,dx\\)) is  \n\\[\nf(x)=\\int_{-1}^1 (1-|\\xi|)^\\beta e^{2\\pi i x\\xi}\\,d\\xi\n      =2\\int_0^1 (1-\\xi)^\\beta \\cos(2\\pi x\\xi)\\,d\\xi.\n\\]\n\nWe verify that \\(f\\in L^1(\\mathbb R)\\cap L^2(\\mathbb R)\\):\n- **\\(L^2\\):** By Plancherel, \\(\\|f\\|_{L^2}=\\|\\hat f\\|_{L^2}<\\infty\\).\n- **\\(L^1\\):** For large \\(|x|\\), standard asymptotic analysis (see below) gives  \n  \\[\n  |f(x)| \\sim C_\\beta\\, |x|^{-\\beta-1}\\qquad (|x|\\to\\infty).\n  \\]  \n  Since \\(\\beta+1>1\\), the tail \\(\\int_{|x|>1}|f(x)|\\,dx\\) converges; near \\(x=0\\) the function is bounded. Hence \\(f\\in L^1\\).\n\nThus \\(f\\) satisfies all the hypotheses.\n\n#### Asymptotic decay of \\(f\\)\nWrite for \\(x>0\\) (the case \\(x<0\\) is symmetric)\n\\[\nf(x)=2\\operatorname{Re}\\!\\left(e^{2\\pi i x}\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du\\right),\\qquad u=1-\\xi.\n\\]\nThe integral \\(\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du\\) has the well\u2011known asymptotic expansion (see, e.g., Erd\u00e9lyi, *Asymptotic Expansions*)\n\\[\n\\int_0^1 u^\\beta e^{-2\\pi i x u}\\,du = \n\\Gamma(\\beta+1)(2\\pi i x)^{-\\beta-1} + O\\bigl(|x|^{-\\beta-2}\\bigr),\\qquad x\\to\\infty.\n\\]\nConsequently,\n\\[\n|f(x)| = \\frac{2\\Gamma(\\beta+1)}{(2\\pi)^{\\beta+1}}\\,|x|^{-\\beta-1} + O\\bigl(|x|^{-\\beta-2}\\bigr).\n\\]\nIn particular, there exist constants \\(c,C>0\\) such that for all sufficiently large \\(|x|\\),\n\\[\nc\\,|x|^{-\\beta-1} \\le |f(x)| \\le C\\,|x|^{-\\beta-1}.\n\\]\n\n#### Failure of the claimed bound\nBecause \\(0<\\beta<1\\), we have \\(\\beta+1<2\\). Therefore\n\\[\n\\lim_{|x|\\to\\infty} |f(x)|\\,(1+|x|)^{2} = \\infty.\n\\]\nHence **no** constant \\(C_0\\) can satisfy \\(|f(x)|\\le C_0(1+|x|)^{-2}\\) for all \\(x\\). This already contradicts the required inequality for the multi\u2011index \\(\\alpha=0\\).\n\n**Remark.** The same construction works in \\(\\mathbb R^n\\) by taking \\(\\hat f(\\xi)=(1-|\\xi|)^\\beta\\) for \\(|\\xi|\\le1\\) and \\(0\\) otherwise, with \\(0<\\beta<n/2\\). Then \\(f\\) decays like \\(|x|^{-\\beta-1-n/2}\\) (by the asymptotics of radial Fourier transforms), and the condition \\(\\beta+1+n/2 < n+1\\) (i.e., \\(\\beta<n/2\\)) makes the decay slower than \\((1+|x|)^{-n-1}\\). The \\(L^1\\) condition requires \\(\\beta+1+n/2 > n\\), i.e., \\(\\beta>0\\), so such \\(\\beta\\) exist. Thus the counterexample is valid in any dimension.\n\n### 3. The smoothness part is true\nAlthough the decay estimate fails, the claim that \\(f\\) is smooth is correct and can be proved as follows. Because \\(\\hat f\\) is supported in the compact set \\(\\overline{B(0,1)}\\) and belongs to \\(L^1(\\mathbb R^n)\\) (it is in \\(L^2\\) and compactly supported, hence in \\(L^1\\)), the inversion formula\n\\[\nf(x)=\\int_{B(0,1)} \\hat f(\\xi)\\,e^{2\\pi i x\\cdot\\xi}\\,d\\xi\n\\]\nholds for every \\(x\\) and represents \\(f\\) as a continuous function. For any multi\u2011index \\(\\alpha\\), differentiation under the integral sign yields\n\\[\n\\partial^\\alpha f(x)=\\int_{B(0,1)} \\hat f(\\xi)\\,(2\\pi i\\xi)^\\alpha e^{2\\pi i x\\cdot\\xi}\\,d\\xi.\n\\]\nThe integrand is bounded by \\(|\\hat f(\\xi)|\\,(2\\pi)^\\alpha\\) (since \\(|\\xi|\\le1\\)) and \\(\\hat f\\in L^1\\); thus \\(\\partial^\\alpha f\\) exists, is continuous, and the differentiation is justified. Hence \\(f\\in C^\\infty(\\mathbb R^n)\\).\n\n### 4. Conclusion\nThe problem is ill\u2011posed because the stated decay estimate does **not** follow from the given assumptions. To make the statement true one would need additional regularity on \\(\\hat f\\) (e.g., \\(\\hat f\\in C^{n}_c\\) or \\(\\hat f\\in C^\\infty_c\\)), which would imply rapid decay of \\(f\\). Alternatively, the conclusion could be weakened to, say, \\(|\\partial^\\alpha f(x)|\\le C_{\\alpha,N}(1+|x|)^{-N}\\) for every \\(N\\) (which would require \\(\\hat f\\in C^\\infty_c\\)).\n\n**Therefore the question cannot be answered as stated; it is ill\u2011posed due to a missing hypothesis.**",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task requires generating a challenging mathematics problem in the domain of abstract harmonic analysis. The problem should be well-posed, solvable, and verifiable.\n[/QUESTION]",
    "run_id": "29",
    "outer_attempt": 1,
    "topic_slug": "abstract_harmonic_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem.** Let $G$ be a locally compact abelian group with Haar measure $dx$. Denote by $\\widehat{G}$ its Pontryagin dual group, i.e., the group of continuous characters $\\chi : G \\to \\mathbb{T}$ (where $\\mathbb{T} = \\{z \\in \\mathbb{C} : |z| = 1\\}$) equipped with the compact\u2011open topology. For $f \\in L^1(G)$, define its Fourier transform $\\widehat{f} : \\widehat{G} \\to \\mathbb{C}$ by  \n$$\n\\widehat{f}(\\chi) = \\int_G f(x)\\,\\overline{\\chi(x)}\\,dx.\n$$  \nProve that the Fourier transform is injective: if $\\widehat{f} = 0$ (identically zero on $\\widehat{G}$), then $f = 0$ almost everywhere.\n\n*This problem is well\u2011posed (all terms are standard and the statement is unambiguous), solvable using techniques from abstract harmonic analysis (e.g., approximate identities, convolution, or the Gelfand transform), and its solution can be verified step\u2011by\u2011step.*",
        "raw_answer": "**Problem.** Let \\(G\\) be a locally compact abelian group with Haar measure \\(dx\\). Denote by \\(\\widehat{G}\\) its Pontryagin dual group, i.e., the group of continuous characters \\(\\chi : G \\to \\mathbb{T}\\) (where \\(\\mathbb{T} = \\{z \\in \\mathbb{C} : |z| = 1\\}\\)) equipped with the compact\u2011open topology. For \\(f \\in L^1(G)\\), define its Fourier transform \\(\\widehat{f} : \\widehat{G} \\to \\mathbb{C}\\) by  \n\\[\n\\widehat{f}(\\chi) = \\int_G f(x)\\,\\overline{\\chi(x)}\\,dx.\n\\]  \nProve that the Fourier transform is injective: if \\(\\widehat{f} = 0\\) (identically zero on \\(\\widehat{G}\\)), then \\(f = 0\\) almost everywhere.\n\n*This problem is well\u2011posed (all terms are standard and the statement is unambiguous), solvable using techniques from abstract harmonic analysis (e.g., approximate identities, convolution, or the Gelfand transform), and its solution can be verified step\u2011by\u2011step.*",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging mathematics problem in the domain of \"Integral transforms, operational calculus\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Choose a specific topic within the domain\nLet's focus on the Laplace transform, a key concept within integral transforms and operational calculus. The Laplace transform is defined as $\\mathcal{L}\\{f(t)\\} = \\int_{0}^{\\infty} e^{-st}f(t)dt = F(s)$, where $f(t)$ is a function defined for $t \\geq 0$.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider applying the Laplace transform to solve a differential equation, as this involves understanding both the transform and its inverse. A suitable problem could involve solving an initial value problem (IVP) using the Laplace transform.\n\n## Step 4: Specify the problem\nLet's consider the following IVP: $y'' + 4y = \\sin(2t)$, with initial conditions $y(0) = 0$ and $y'(0) = 0$. The task is to solve for $y(t)$ using the Laplace transform.\n\n## Step 5: Write the problem statement\n\nUse the Laplace transform to solve the initial value problem $y'' + 4y = \\sin(2t)$, where $y(0) = 0$ and $y'(0) = 0$.\n\n## Step 6: Provide the solution\nTo solve the given IVP using the Laplace transform, we first apply the Laplace transform to both sides of the differential equation.\n\n## Step 7: Apply the Laplace transform to the differential equation\n$\\mathcal{L}\\{y'' + 4y\\} = \\mathcal{L}\\{\\sin(2t)\\}$. Using linearity, we get $\\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\}$.\n\n## Step 8: Evaluate the Laplace transforms\n$\\mathcal{L}\\{y''\\} = s^2Y(s) - sy(0) - y'(0)$ and $\\mathcal{L}\\{y\\} = Y(s)$, where $Y(s) = \\mathcal{L}\\{y(t)\\}$. Given $y(0) = 0$ and $y'(0) = 0$, $\\mathcal{L}\\{y''\\} = s^2Y(s)$. $\\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2 + 4}$.\n\n## Step 9: Substitute the known values and simplify\n$s^2Y(s) + 4Y(s) = \\frac{2}{s^2 + 4}$. Thus, $Y(s)(s^2 + 4) = \\frac{2}{s^2 + 4}$, which simplifies to $Y(s) = \\frac{2}{(s^2 + 4)^2}$.\n\n## Step 10: Find the inverse Laplace transform of $Y(s)$\nTo find $y(t)$, we need $\\mathcal{L}^{-1}\\{Y(s)\\} = \\mathcal{L}^{-1}\\left\\{\\frac{2}{(s^2 + 4)^2}\\right\\}$. Recall that $\\mathcal{L}\\{\\sin(at)\\} = \\frac{a}{s^2 + a^2}$, and use the property that $\\mathcal{L}^{-1}\\{F(s)\\} = f(t)$ implies $\\mathcal{L}^{-1}\\left\\{\\frac{d}{ds}F(s)\\right\\} = -tf(t)$, or more directly, utilize the convolution or known transforms.\n\n## Step 11: Evaluate the inverse Laplace transform\nUsing the formula for $\\mathcal{L}^{-1}\\left\\{\\frac{2a^3}{(s^2 + a^2)^2}\\right\\} = \\sin(at) - at\\cos(at)$ with $a = 2$, we adjust for our case: $\\mathcal{L}^{-1}\\left\\{\\frac{2}{(s^2 + 4)^2}\\right\\} = \\frac{1}{4}\\mathcal{L}^{-1}\\left\\{\\frac{2 \\cdot 2^3}{(s^2 + 2^2)^2}\\right\\} = \\frac{1}{4}(\\sin(2t) - 2t\\cos(2t))$.\n\n## Step 12: Write the complete solution",
    "run_id": "30",
    "outer_attempt": 1,
    "topic_slug": "integral_transforms_and_operational_calculus",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe are given the initial value problem\n\n$$\ny''(t) + 4y(t) = \\sin(2t), \\qquad y(0)=0,\\; y'(0)=0.\n$$\n\nWe solve it using the Laplace transform.\n\nLet $Y(s) = \\mathcal{L}\\{y(t)\\}(s)$. Taking the Laplace transform of both sides and using linearity:\n\n$$\n\\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\}.\n$$\n\nRecall the Laplace transform of a derivative:\n\n$$\n\\mathcal{L}\\{y'\\} = sY(s) - y(0), \\qquad \\mathcal{L}\\{y''\\} = s^2Y(s) - s y(0) - y'(0).\n$$\n\nWith the given initial conditions $y(0)=0$, $y'(0)=0$, we obtain\n\n$$\n\\mathcal{L}\\{y''\\} = s^2 Y(s), \\qquad \\mathcal{L}\\{y\\} = Y(s).\n$$\n\nAlso, $\\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2+4}$.\n\nSubstituting these into the equation yields\n\n$$\ns^2 Y(s) + 4 Y(s) = \\frac{2}{s^2+4}.\n$$\n\nFactor $Y(s)$:\n\n$$\n(s^2+4) Y(s) = \\frac{2}{s^2+4},\n$$\n\nso\n\n$$\nY(s) = \\frac{2}{(s^2+4)^2}.\n$$\n\nNow we need to find the inverse Laplace transform $y(t) = \\mathcal{L}^{-1}\\{Y(s)\\}$.\n\nWe compute the inverse using the convolution theorem. Observe that\n\n$$\n\\frac{2}{(s^2+4)^2} = \\frac{2}{s^2+4} \\cdot \\frac{1}{s^2+4}.\n$$\n\nWe know the inverse transforms:\n\n$$\n\\mathcal{L}^{-1}\\left\\{\\frac{2}{s^2+4}\\right\\} = \\sin(2t), \\qquad\n\\mathcal{L}^{-1}\\left\\{\\frac{1}{s^2+4}\\right\\} = \\frac{1}{2}\\sin(2t).\n$$\n\nBy the convolution theorem, $\\mathcal{L}^{-1}\\{F(s)G(s)\\} = (f * g)(t)$, where $(f*g)(t) = \\int_0^t f(\\tau)g(t-\\tau)\\,d\\tau$. Hence\n\n$$\ny(t) = \\sin(2t) * \\frac{1}{2}\\sin(2t) = \\frac{1}{2} \\int_0^t \\sin(2\\tau)\\,\\sin\\bigl(2(t-\\tau)\\bigr)\\,d\\tau.\n$$\n\nSimplify the product using the trigonometric identity $\\sin A \\sin B = \\frac{1}{2}\\bigl[\\cos(A-B) - \\cos(A+B)\\bigr]$. With $A = 2\\tau$ and $B = 2(t-\\tau) = 2t - 2\\tau$, we have\n\n$$\nA-B = 2\\tau - (2t-2\\tau) = 4\\tau - 2t, \\qquad A+B = 2\\tau + (2t-2\\tau) = 2t.\n$$\n\nThus\n\n$$\n\\sin(2\\tau)\\sin\\bigl(2(t-\\tau)\\bigr) = \\frac{1}{2}\\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr].\n$$\n\nSubstituting into the integral:\n\n$$\ny(t) = \\frac{1}{2} \\int_0^t \\frac{1}{2}\\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr]\\,d\\tau\n= \\frac{1}{4} \\int_0^t \\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr]\\,d\\tau.\n$$\n\nNow evaluate the two integrals separately.\n\n$$\n\\int_0^t \\cos(4\\tau-2t)\\,d\\tau = \\left[\\frac{1}{4}\\sin(4\\tau-2t)\\right]_{\\tau=0}^{\\tau=t}\n= \\frac{1}{4}\\bigl[\\sin(4t-2t) - \\sin(-2t)\\bigr]\n= \\frac{1}{4}\\bigl[\\sin(2t) + \\sin(2t)\\bigr] = \\frac{1}{2}\\sin(2t).\n$$\n\n$$\n\\int_0^t \\cos(2t)\\,d\\tau = \\cos(2t) \\int_0^t d\\tau = t\\cos(2t).\n$$\n\nTherefore,\n\n$$\ny(t) = \\frac{1}{4}\\left( \\frac{1}{2}\\sin(2t) - t\\cos(2t) \\right)\n= \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t).\n$$\n\nWe can also write this as\n\n$$\ny(t) = \\frac{1}{8}\\bigl(\\sin(2t) - 2t\\cos(2t)\\bigr).\n$$\n\nFinally, we verify that this solution satisfies the initial conditions and the differential equation.\n\n- $y(0) = \\frac{1}{8}(\\sin 0 - 0) = 0$.\n- Differentiate: $y'(t) = \\frac{1}{8}\\bigl(2\\cos(2t) - 2\\cos(2t) + 4t\\sin(2t)\\bigr) = \\frac{1}{2}t\\sin(2t)$, so $y'(0)=0$.\n- Second derivative: $y''(t) = \\frac{1}{2}\\sin(2t) + t\\cos(2t)$. Then\n\n$$\ny''(t) + 4y(t) = \\left(\\frac{1}{2}\\sin(2t) + t\\cos(2t)\\right) + 4\\left(\\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t)\\right)\n= \\frac{1}{2}\\sin(2t) + t\\cos(2t) + \\frac{1}{2}\\sin(2t) - t\\cos(2t) = \\sin(2t),\n$$\n\nwhich matches the right-hand side.\n\nHence the solution to the initial value problem is\n\n$$\n\\boxed{y(t) = \\frac{1}{8}\\bigl(\\sin(2t) - 2t\\cos(2t)\\bigr)}.\n$$",
        "raw_answer": "**Solution**\n\nWe are given the initial value problem\n\n\\[\ny''(t) + 4y(t) = \\sin(2t), \\qquad y(0)=0,\\; y'(0)=0.\n\\]\n\nWe solve it using the Laplace transform.\n\nLet \\(Y(s) = \\mathcal{L}\\{y(t)\\}(s)\\). Taking the Laplace transform of both sides and using linearity:\n\n\\[\n\\mathcal{L}\\{y''\\} + 4\\mathcal{L}\\{y\\} = \\mathcal{L}\\{\\sin(2t)\\}.\n\\]\n\nRecall the Laplace transform of a derivative:\n\n\\[\n\\mathcal{L}\\{y'\\} = sY(s) - y(0), \\qquad \\mathcal{L}\\{y''\\} = s^2Y(s) - s y(0) - y'(0).\n\\]\n\nWith the given initial conditions \\(y(0)=0\\), \\(y'(0)=0\\), we obtain\n\n\\[\n\\mathcal{L}\\{y''\\} = s^2 Y(s), \\qquad \\mathcal{L}\\{y\\} = Y(s).\n\\]\n\nAlso, \\(\\mathcal{L}\\{\\sin(2t)\\} = \\frac{2}{s^2+4}\\).\n\nSubstituting these into the equation yields\n\n\\[\ns^2 Y(s) + 4 Y(s) = \\frac{2}{s^2+4}.\n\\]\n\nFactor \\(Y(s)\\):\n\n\\[\n(s^2+4) Y(s) = \\frac{2}{s^2+4},\n\\]\n\nso\n\n\\[\nY(s) = \\frac{2}{(s^2+4)^2}.\n\\]\n\nNow we need to find the inverse Laplace transform \\(y(t) = \\mathcal{L}^{-1}\\{Y(s)\\}\\).\n\nWe compute the inverse using the convolution theorem. Observe that\n\n\\[\n\\frac{2}{(s^2+4)^2} = \\frac{2}{s^2+4} \\cdot \\frac{1}{s^2+4}.\n\\]\n\nWe know the inverse transforms:\n\n\\[\n\\mathcal{L}^{-1}\\left\\{\\frac{2}{s^2+4}\\right\\} = \\sin(2t), \\qquad\n\\mathcal{L}^{-1}\\left\\{\\frac{1}{s^2+4}\\right\\} = \\frac{1}{2}\\sin(2t).\n\\]\n\nBy the convolution theorem, \\(\\mathcal{L}^{-1}\\{F(s)G(s)\\} = (f * g)(t)\\), where \\((f*g)(t) = \\int_0^t f(\\tau)g(t-\\tau)\\,d\\tau\\). Hence\n\n\\[\ny(t) = \\sin(2t) * \\frac{1}{2}\\sin(2t) = \\frac{1}{2} \\int_0^t \\sin(2\\tau)\\,\\sin\\bigl(2(t-\\tau)\\bigr)\\,d\\tau.\n\\]\n\nSimplify the product using the trigonometric identity \\(\\sin A \\sin B = \\frac{1}{2}\\bigl[\\cos(A-B) - \\cos(A+B)\\bigr]\\). With \\(A = 2\\tau\\) and \\(B = 2(t-\\tau) = 2t - 2\\tau\\), we have\n\n\\[\nA-B = 2\\tau - (2t-2\\tau) = 4\\tau - 2t, \\qquad A+B = 2\\tau + (2t-2\\tau) = 2t.\n\\]\n\nThus\n\n\\[\n\\sin(2\\tau)\\sin\\bigl(2(t-\\tau)\\bigr) = \\frac{1}{2}\\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr].\n\\]\n\nSubstituting into the integral:\n\n\\[\ny(t) = \\frac{1}{2} \\int_0^t \\frac{1}{2}\\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr]\\,d\\tau\n= \\frac{1}{4} \\int_0^t \\bigl[\\cos(4\\tau-2t) - \\cos(2t)\\bigr]\\,d\\tau.\n\\]\n\nNow evaluate the two integrals separately.\n\n\\[\n\\int_0^t \\cos(4\\tau-2t)\\,d\\tau = \\left[\\frac{1}{4}\\sin(4\\tau-2t)\\right]_{\\tau=0}^{\\tau=t}\n= \\frac{1}{4}\\bigl[\\sin(4t-2t) - \\sin(-2t)\\bigr]\n= \\frac{1}{4}\\bigl[\\sin(2t) + \\sin(2t)\\bigr] = \\frac{1}{2}\\sin(2t).\n\\]\n\n\\[\n\\int_0^t \\cos(2t)\\,d\\tau = \\cos(2t) \\int_0^t d\\tau = t\\cos(2t).\n\\]\n\nTherefore,\n\n\\[\ny(t) = \\frac{1}{4}\\left( \\frac{1}{2}\\sin(2t) - t\\cos(2t) \\right)\n= \\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t).\n\\]\n\nWe can also write this as\n\n\\[\ny(t) = \\frac{1}{8}\\bigl(\\sin(2t) - 2t\\cos(2t)\\bigr).\n\\]\n\nFinally, we verify that this solution satisfies the initial conditions and the differential equation.\n\n- \\(y(0) = \\frac{1}{8}(\\sin 0 - 0) = 0\\).\n- Differentiate: \\(y'(t) = \\frac{1}{8}\\bigl(2\\cos(2t) - 2\\cos(2t) + 4t\\sin(2t)\\bigr) = \\frac{1}{2}t\\sin(2t)\\), so \\(y'(0)=0\\).\n- Second derivative: \\(y''(t) = \\frac{1}{2}\\sin(2t) + t\\cos(2t)\\). Then\n\n\\[\ny''(t) + 4y(t) = \\left(\\frac{1}{2}\\sin(2t) + t\\cos(2t)\\right) + 4\\left(\\frac{1}{8}\\sin(2t) - \\frac{1}{4}t\\cos(2t)\\right)\n= \\frac{1}{2}\\sin(2t) + t\\cos(2t) + \\frac{1}{2}\\sin(2t) - t\\cos(2t) = \\sin(2t),\n\\]\n\nwhich matches the right-hand side.\n\nHence the solution to the initial value problem is\n\n\\[\n\\boxed{y(t) = \\frac{1}{8}\\bigl(\\sin(2t) - 2t\\cos(2t)\\bigr)}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of integral equations, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify the specific domain within integral equations\nIntegral equations involve equations where the unknown function appears under an integral sign. A common type is the Fredholm integral equation of the second kind, given by $f(x) = g(x) + \\lambda \\int_{a}^{b} K(x, t)f(t)dt$, where $f(x)$ is the unknown function, $g(x)$ and $K(x, t)$ are known functions, and $\\lambda$ is a parameter.\n\n## Step 3: Formulate a challenging problem\nTo create a challenging problem, we can consider a specific case of the Fredholm integral equation of the second kind with a given kernel $K(x, t)$ and a function $g(x)$, and ask to solve for $f(x)$.\n\n## Step 4: Specify the problem\nLet's consider the integral equation $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$. This is a Fredholm integral equation of the second kind. We need to find $f(x)$.\n\n## Step 5: Provide the solution\nTo solve $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$, let's first simplify the integral.\n$f(x) = x + x\\int_{0}^{1} tf(t)dt + x\\int_{0}^{1} f(t)dt + \\int_{0}^{1} tf(t)dt$.\nLet $A = \\int_{0}^{1} f(t)dt$ and $B = \\int_{0}^{1} tf(t)dt$. Then, $f(x) = x + xB + xA + B = x(1 + A + B) + B$.\n\n## Step 6: Calculate A and B using the definitions\nSubstitute $f(x)$ from Step 5 into the definitions of $A$ and $B$.\n$A = \\int_{0}^{1} [t(1 + A + B) + B]dt = \\left[\\frac{t^2}{2}(1 + A + B) + Bt\\right]_{0}^{1} = \\frac{1}{2}(1 + A + B) + B$.\n$B = \\int_{0}^{1} t[t(1 + A + B) + B]dt = \\left[\\frac{t^3}{3}(1 + A + B) + \\frac{Bt^2}{2}\\right]_{0}^{1} = \\frac{1}{3}(1 + A + B) + \\frac{B}{2}$.\n\n## Step 7: Solve for A and B\nFrom Step 6, we have:\n1. $A = \\frac{1}{2}(1 + A + B) + B$\n2. $B = \\frac{1}{3}(1 + A + B) + \\frac{B}{2}$.\n\nSimplifying these equations:\n1. $A = \\frac{1}{2} + \\frac{A}{2} + \\frac{B}{2} + B$ implies $\\frac{A}{2} = \\frac{1}{2} + \\frac{3B}{2}$, so $A = 1 + 3B$.\n2. $B = \\frac{1}{3} + \\frac{A}{3} + \\frac{B}{3} + \\frac{B}{2}$ implies $B - \\frac{B}{2} - \\frac{B}{3} = \\frac{1}{3} + \\frac{A}{3}$, so $\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3}$.\n\n## Step 8: Continue solving for A and B\nFrom equation 2 in Step 7: $\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3}$, we get $B = 2 + 2A$.\nSubstitute $A = 1 + 3B$ from Step 7 into $B = 2 + 2A$:\n$B = 2 + 2(1 + 3B)$, so $B = 2 + 2 + 6B$, which simplifies to $B = 4 + 6B$, hence $-5B = 4$, and $B = -\\frac{4}{5}$.\n\n## Step 9: Find A using B\nSubstitute $B = -\\frac{4}{5}$ into $A = 1 + 3B$:\n$A = 1 + 3(-\\frac{4}{5}) = 1 - \\frac{12}{5} = -\\frac{7}{5}$.\n\n## Step 10: Substitute A and B back into f(x)\n$f(x) = x(1 + A + B) + B = x(1 - \\frac{7}{5} - \\frac{4}{5}) - \\frac{4}{5}$.\n$f(x) = x(1 - \\frac{11}{5}) - \\frac{4}{5} = x(-\\frac{6}{5}) - \\frac{4}{5}$.\n$f(x) = -\\frac{6}{5}x - \\frac{4}{5}$.\n\nThe final answer is: \n\nSolve the integral equation $f(x) = x + \\int_{0}^{1} (xt + x + t)f(t)dt$ for $f(x)$.",
    "run_id": "31",
    "outer_attempt": 1,
    "topic_slug": "integral_equations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are to solve the Fredholm integral equation of the second kind\n\n$$\nf(x) = x + \\int_0^1 (x t + x + t) f(t) \\, dt.\n$$\n\nThe kernel $K(x,t)=x t + x + t$ is separable (degenerate), so the solution can be reduced to solving a linear system for the constants that appear after integration.\n\n**Step 1. Introduce the necessary integrals.**  \nLet  \n\n$$\nA = \\int_0^1 f(t)\\, dt, \\qquad B = \\int_0^1 t f(t)\\, dt.\n$$\n\nThese are numbers (constants) that we will determine.\n\n**Step 2. Express $f(x)$ in terms of $A$ and $B$.**  \nRewrite the integral:\n\n$$\n\\int_0^1 (x t + x + t) f(t)\\, dt = x \\int_0^1 t f(t)\\, dt + x \\int_0^1 f(t)\\, dt + \\int_0^1 t f(t)\\, dt = x B + x A + B.\n$$\n\nHence the equation becomes\n\n$$\nf(x) = x + x B + x A + B = x(1 + A + B) + B. \\tag{1}\n$$\n\n**Step 3. Derive equations for $A$ and $B$.**  \nSubstitute the expression (1) into the definitions of $A$ and $B$.\n\n- For $A$:\n\n$$\n\\begin{aligned}\nA &= \\int_0^1 f(t)\\, dt = \\int_0^1 \\bigl[ t(1+A+B) + B \\bigr]\\, dt \\\\\n  &= (1+A+B) \\int_0^1 t\\, dt + B \\int_0^1 1\\, dt \\\\\n  &= (1+A+B)\\cdot\\frac{1}{2} + B\\cdot 1 \\\\\n  &= \\frac{1}{2}(1+A+B) + B.\n\\end{aligned}\n$$\n\n- For $B$:\n\n$$\n\\begin{aligned}\nB &= \\int_0^1 t f(t)\\, dt = \\int_0^1 t\\bigl[ t(1+A+B) + B \\bigr]\\, dt \\\\\n  &= (1+A+B) \\int_0^1 t^2\\, dt + B \\int_0^1 t\\, dt \\\\\n  &= (1+A+B)\\cdot\\frac{1}{3} + B\\cdot\\frac{1}{2} \\\\\n  &= \\frac{1}{3}(1+A+B) + \\frac{B}{2}.\n\\end{aligned}\n$$\n\n**Step 4. Simplify the equations.**  \n\nFrom the expression for $A$:\n\n$$\nA = \\frac{1}{2} + \\frac{A}{2} + \\frac{B}{2} + B.\n$$\n\nBring the terms with $A$ to the left:\n\n$$\nA - \\frac{A}{2} = \\frac{1}{2} + \\frac{B}{2} + B \\quad\\Longrightarrow\\quad \\frac{A}{2} = \\frac{1}{2} + \\frac{3B}{2}.\n$$\n\nMultiplying by $2$ gives\n\n$$\nA = 1 + 3B. \\tag{2}\n$$\n\nFrom the expression for $B$:\n\n$$\nB = \\frac{1}{3} + \\frac{A}{3} + \\frac{B}{3} + \\frac{B}{2}.\n$$\n\nCollect the $B$ terms:\n\n$$\nB - \\frac{B}{3} - \\frac{B}{2} = \\frac{1}{3} + \\frac{A}{3}.\n$$\n\nThe left side is $B\\left(1 - \\frac{1}{3} - \\frac{1}{2}\\right) = B\\left(\\frac{6}{6} - \\frac{2}{6} - \\frac{3}{6}\\right) = B\\cdot\\frac{1}{6} = \\frac{B}{6}$. Thus\n\n$$\n\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3}.\n$$\n\nMultiply by $6$:\n\n$$\nB = 2 + 2A. \\tag{3}\n$$\n\n**Step 5. Solve the linear system (2)\u2013(3).**  \n\nSubstitute $A = 1 + 3B$ from (2) into (3):\n\n$$\nB = 2 + 2(1 + 3B) = 2 + 2 + 6B = 4 + 6B.\n$$\n\nHence\n\n$$\nB - 6B = 4 \\quad\\Longrightarrow\\quad -5B = 4 \\quad\\Longrightarrow\\quad B = -\\frac{4}{5}.\n$$\n\nNow from (2),\n\n$$\nA = 1 + 3\\left(-\\frac{4}{5}\\right) = 1 - \\frac{12}{5} = -\\frac{7}{5}.\n$$\n\n**Step 6. Write the solution $f(x)$.**  \n\nInsert $A$ and $B$ into (1):\n\n$$\n\\begin{aligned}\nf(x) &= x(1 + A + B) + B \\\\\n     &= x\\left(1 - \\frac{7}{5} - \\frac{4}{5}\\right) - \\frac{4}{5} \\\\\n     &= x\\left(1 - \\frac{11}{5}\\right) - \\frac{4}{5} \\\\\n     &= x\\left(-\\frac{6}{5}\\right) - \\frac{4}{5} \\\\\n     &= -\\frac{6}{5}x - \\frac{4}{5}.\n\\end{aligned}\n$$\n\nThus\n\n$$\n\\boxed{f(x) = -\\frac{6}{5}x - \\frac{4}{5}}.\n$$\n\n**Step 7. Verification (optional but reassuring).**  \n\nCompute the right\u2011hand side of the original equation with this $f$ and check that it equals $f(x)$.\n\nFirst, compute the constants again from the candidate function:\n\n$$\nA = \\int_0^1 \\left(-\\frac{6}{5}t - \\frac{4}{5}\\right) dt = -\\frac{6}{5}\\cdot\\frac{1}{2} - \\frac{4}{5}\\cdot 1 = -\\frac{3}{5} - \\frac{4}{5} = -\\frac{7}{5},\n$$\n$$\nB = \\int_0^1 t\\left(-\\frac{6}{5}t - \\frac{4}{5}\\right) dt = -\\frac{6}{5}\\int_0^1 t^2 dt - \\frac{4}{5}\\int_0^1 t dt = -\\frac{6}{5}\\cdot\\frac{1}{3} - \\frac{4}{5}\\cdot\\frac{1}{2} = -\\frac{2}{5} - \\frac{2}{5} = -\\frac{4}{5}.\n$$\n\nThen\n\n$$\nx + x B + x A + B = x + x\\left(-\\frac{4}{5}\\right) + x\\left(-\\frac{7}{5}\\right) + \\left(-\\frac{4}{5}\\right) = x\\left(1 - \\frac{4}{5} - \\frac{7}{5}\\right) - \\frac{4}{5} = x\\left(1 - \\frac{11}{5}\\right) - \\frac{4}{5} = -\\frac{6}{5}x - \\frac{4}{5},\n$$\n\nwhich matches $f(x)$. Hence the solution is correct.\n\nThe integral equation is linear and the kernel is separable; the derived constants satisfy a non\u2011singular linear system, so the solution is unique. Therefore the function found is the unique solution.",
        "raw_answer": "We are to solve the Fredholm integral equation of the second kind\n\n\\[\nf(x) = x + \\int_0^1 (x t + x + t) f(t) \\, dt.\n\\]\n\nThe kernel \\(K(x,t)=x t + x + t\\) is separable (degenerate), so the solution can be reduced to solving a linear system for the constants that appear after integration.\n\n**Step 1. Introduce the necessary integrals.**  \nLet  \n\n\\[\nA = \\int_0^1 f(t)\\, dt, \\qquad B = \\int_0^1 t f(t)\\, dt.\n\\]\n\nThese are numbers (constants) that we will determine.\n\n**Step 2. Express \\(f(x)\\) in terms of \\(A\\) and \\(B\\).**  \nRewrite the integral:\n\n\\[\n\\int_0^1 (x t + x + t) f(t)\\, dt = x \\int_0^1 t f(t)\\, dt + x \\int_0^1 f(t)\\, dt + \\int_0^1 t f(t)\\, dt = x B + x A + B.\n\\]\n\nHence the equation becomes\n\n\\[\nf(x) = x + x B + x A + B = x(1 + A + B) + B. \\tag{1}\n\\]\n\n**Step 3. Derive equations for \\(A\\) and \\(B\\).**  \nSubstitute the expression (1) into the definitions of \\(A\\) and \\(B\\).\n\n- For \\(A\\):\n\n\\[\n\\begin{aligned}\nA &= \\int_0^1 f(t)\\, dt = \\int_0^1 \\bigl[ t(1+A+B) + B \\bigr]\\, dt \\\\\n  &= (1+A+B) \\int_0^1 t\\, dt + B \\int_0^1 1\\, dt \\\\\n  &= (1+A+B)\\cdot\\frac{1}{2} + B\\cdot 1 \\\\\n  &= \\frac{1}{2}(1+A+B) + B.\n\\end{aligned}\n\\]\n\n- For \\(B\\):\n\n\\[\n\\begin{aligned}\nB &= \\int_0^1 t f(t)\\, dt = \\int_0^1 t\\bigl[ t(1+A+B) + B \\bigr]\\, dt \\\\\n  &= (1+A+B) \\int_0^1 t^2\\, dt + B \\int_0^1 t\\, dt \\\\\n  &= (1+A+B)\\cdot\\frac{1}{3} + B\\cdot\\frac{1}{2} \\\\\n  &= \\frac{1}{3}(1+A+B) + \\frac{B}{2}.\n\\end{aligned}\n\\]\n\n**Step 4. Simplify the equations.**  \n\nFrom the expression for \\(A\\):\n\n\\[\nA = \\frac{1}{2} + \\frac{A}{2} + \\frac{B}{2} + B.\n\\]\n\nBring the terms with \\(A\\) to the left:\n\n\\[\nA - \\frac{A}{2} = \\frac{1}{2} + \\frac{B}{2} + B \\quad\\Longrightarrow\\quad \\frac{A}{2} = \\frac{1}{2} + \\frac{3B}{2}.\n\\]\n\nMultiplying by \\(2\\) gives\n\n\\[\nA = 1 + 3B. \\tag{2}\n\\]\n\nFrom the expression for \\(B\\):\n\n\\[\nB = \\frac{1}{3} + \\frac{A}{3} + \\frac{B}{3} + \\frac{B}{2}.\n\\]\n\nCollect the \\(B\\) terms:\n\n\\[\nB - \\frac{B}{3} - \\frac{B}{2} = \\frac{1}{3} + \\frac{A}{3}.\n\\]\n\nThe left side is \\(B\\left(1 - \\frac{1}{3} - \\frac{1}{2}\\right) = B\\left(\\frac{6}{6} - \\frac{2}{6} - \\frac{3}{6}\\right) = B\\cdot\\frac{1}{6} = \\frac{B}{6}\\). Thus\n\n\\[\n\\frac{B}{6} = \\frac{1}{3} + \\frac{A}{3}.\n\\]\n\nMultiply by \\(6\\):\n\n\\[\nB = 2 + 2A. \\tag{3}\n\\]\n\n**Step 5. Solve the linear system (2)\u2013(3).**  \n\nSubstitute \\(A = 1 + 3B\\) from (2) into (3):\n\n\\[\nB = 2 + 2(1 + 3B) = 2 + 2 + 6B = 4 + 6B.\n\\]\n\nHence\n\n\\[\nB - 6B = 4 \\quad\\Longrightarrow\\quad -5B = 4 \\quad\\Longrightarrow\\quad B = -\\frac{4}{5}.\n\\]\n\nNow from (2),\n\n\\[\nA = 1 + 3\\left(-\\frac{4}{5}\\right) = 1 - \\frac{12}{5} = -\\frac{7}{5}.\n\\]\n\n**Step 6. Write the solution \\(f(x)\\).**  \n\nInsert \\(A\\) and \\(B\\) into (1):\n\n\\[\n\\begin{aligned}\nf(x) &= x(1 + A + B) + B \\\\\n     &= x\\left(1 - \\frac{7}{5} - \\frac{4}{5}\\right) - \\frac{4}{5} \\\\\n     &= x\\left(1 - \\frac{11}{5}\\right) - \\frac{4}{5} \\\\\n     &= x\\left(-\\frac{6}{5}\\right) - \\frac{4}{5} \\\\\n     &= -\\frac{6}{5}x - \\frac{4}{5}.\n\\end{aligned}\n\\]\n\nThus\n\n\\[\n\\boxed{f(x) = -\\frac{6}{5}x - \\frac{4}{5}}.\n\\]\n\n**Step 7. Verification (optional but reassuring).**  \n\nCompute the right\u2011hand side of the original equation with this \\(f\\) and check that it equals \\(f(x)\\).\n\nFirst, compute the constants again from the candidate function:\n\n\\[\nA = \\int_0^1 \\left(-\\frac{6}{5}t - \\frac{4}{5}\\right) dt = -\\frac{6}{5}\\cdot\\frac{1}{2} - \\frac{4}{5}\\cdot 1 = -\\frac{3}{5} - \\frac{4}{5} = -\\frac{7}{5},\n\\]\n\\[\nB = \\int_0^1 t\\left(-\\frac{6}{5}t - \\frac{4}{5}\\right) dt = -\\frac{6}{5}\\int_0^1 t^2 dt - \\frac{4}{5}\\int_0^1 t dt = -\\frac{6}{5}\\cdot\\frac{1}{3} - \\frac{4}{5}\\cdot\\frac{1}{2} = -\\frac{2}{5} - \\frac{2}{5} = -\\frac{4}{5}.\n\\]\n\nThen\n\n\\[\nx + x B + x A + B = x + x\\left(-\\frac{4}{5}\\right) + x\\left(-\\frac{7}{5}\\right) + \\left(-\\frac{4}{5}\\right) = x\\left(1 - \\frac{4}{5} - \\frac{7}{5}\\right) - \\frac{4}{5} = x\\left(1 - \\frac{11}{5}\\right) - \\frac{4}{5} = -\\frac{6}{5}x - \\frac{4}{5},\n\\]\n\nwhich matches \\(f(x)\\). Hence the solution is correct.\n\nThe integral equation is linear and the kernel is separable; the derived constants satisfy a non\u2011singular linear system, so the solution is unique. Therefore the function found is the unique solution.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $H$ be a Hilbert space and $T: H \\to H$ be a bounded linear operator. Suppose that $T$ is self-adjoint and satisfies the condition $\\|T\\| \\leq 1$. Prove that the operator $I - T^2$ is positive, where $I$ denotes the identity operator on $H$.",
    "run_id": "32",
    "outer_attempt": 1,
    "topic_slug": "functional_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are given a Hilbert space $H$ (real or complex) and a bounded linear operator $T: H \\to H$ that is self\u2011adjoint ($T^* = T$) and satisfies $\\|T\\| \\le 1$. We must prove that $I - T^2$ is a positive operator. Recall that an operator $A$ on $H$ is called **positive** if it is self\u2011adjoint and $\\langle A x, x \\rangle \\ge 0$ for every $x \\in H$.\n\n---\n\n### Proof\n\n1. **Self\u2011adjointness of $I - T^2$.**  \n   Since $T$ is self\u2011adjoint, $T^* = T$. The identity $I$ is obviously self\u2011adjoint. For the square we have $(T^2)^* = (T^*)^2 = T^2$, so $T^2$ is also self\u2011adjoint. Hence $I - T^2$ is self\u2011adjoint as a difference of two self\u2011adjoint operators:\n   $$\n   (I - T^2)^* = I^* - (T^2)^* = I - T^2.\n   $$\n\n2. **Quadratic form of $I - T^2$.**  \n   For any $x \\in H$ we compute\n   $$\n   \\langle (I - T^2)x, x \\rangle = \\langle x, x \\rangle - \\langle T^2 x, x \\rangle.\n   $$\n   Because $T$ is self\u2011adjoint,\n   $$\n   \\langle T^2 x, x \\rangle = \\langle T(Tx), x \\rangle = \\langle Tx, T^* x \\rangle = \\langle Tx, T x \\rangle = \\|Tx\\|^2.\n   $$\n   Therefore\n   $$\n   \\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2.\n   $$\n\n3. **Using the norm bound $\\|T\\| \\le 1$.**  \n   The operator norm is defined as $\\|T\\| = \\sup_{x \\ne 0} \\frac{\\|Tx\\|}{\\|x\\|}$. The condition $\\|T\\| \\le 1$ implies that for every $x \\in H$,\n   $$\n   \\|Tx\\| \\le \\|T\\| \\|x\\| \\le \\|x\\|.\n   $$\n   Consequently, $\\|Tx\\|^2 \\le \\|x\\|^2$, and so\n   $$\n   \\|x\\|^2 - \\|Tx\\|^2 \\ge 0.\n   $$\n\n4. **Conclusion.**  \n   From steps 2 and 3 we obtain\n   $$\n   \\langle (I - T^2)x, x \\rangle \\ge 0 \\qquad \\text{for all } x \\in H.\n   $$\n   Together with the self\u2011adjointness established in step 1, this proves that $I - T^2$ is a positive operator.\n\n\u220e\n\n---\n\n### Remark\n\nThe argument is elementary and does not require the spectral theorem; it relies only on the definitions of self\u2011adjointness, operator norm, and the fact that $\\|Tx\\| \\le \\|T\\|\\|x\\|$. The self\u2011adjointness of $T$ is essential to rewrite $\\langle T^2 x, x \\rangle$ as $\\|Tx\\|^2$.",
        "raw_answer": "We are given a Hilbert space $H$ (real or complex) and a bounded linear operator $T: H \\to H$ that is self\u2011adjoint ($T^* = T$) and satisfies $\\|T\\| \\le 1$. We must prove that $I - T^2$ is a positive operator. Recall that an operator $A$ on $H$ is called **positive** if it is self\u2011adjoint and $\\langle A x, x \\rangle \\ge 0$ for every $x \\in H$.\n\n---\n\n### Proof\n\n1. **Self\u2011adjointness of $I - T^2$.**  \n   Since $T$ is self\u2011adjoint, $T^* = T$. The identity $I$ is obviously self\u2011adjoint. For the square we have $(T^2)^* = (T^*)^2 = T^2$, so $T^2$ is also self\u2011adjoint. Hence $I - T^2$ is self\u2011adjoint as a difference of two self\u2011adjoint operators:\n   \\[\n   (I - T^2)^* = I^* - (T^2)^* = I - T^2.\n   \\]\n\n2. **Quadratic form of $I - T^2$.**  \n   For any $x \\in H$ we compute\n   \\[\n   \\langle (I - T^2)x, x \\rangle = \\langle x, x \\rangle - \\langle T^2 x, x \\rangle.\n   \\]\n   Because $T$ is self\u2011adjoint,\n   \\[\n   \\langle T^2 x, x \\rangle = \\langle T(Tx), x \\rangle = \\langle Tx, T^* x \\rangle = \\langle Tx, T x \\rangle = \\|Tx\\|^2.\n   \\]\n   Therefore\n   \\[\n   \\langle (I - T^2)x, x \\rangle = \\|x\\|^2 - \\|Tx\\|^2.\n   \\]\n\n3. **Using the norm bound $\\|T\\| \\le 1$.**  \n   The operator norm is defined as $\\|T\\| = \\sup_{x \\ne 0} \\frac{\\|Tx\\|}{\\|x\\|}$. The condition $\\|T\\| \\le 1$ implies that for every $x \\in H$,\n   \\[\n   \\|Tx\\| \\le \\|T\\| \\|x\\| \\le \\|x\\|.\n   \\]\n   Consequently, $\\|Tx\\|^2 \\le \\|x\\|^2$, and so\n   \\[\n   \\|x\\|^2 - \\|Tx\\|^2 \\ge 0.\n   \\]\n\n4. **Conclusion.**  \n   From steps 2 and 3 we obtain\n   \\[\n   \\langle (I - T^2)x, x \\rangle \\ge 0 \\qquad \\text{for all } x \\in H.\n   \\]\n   Together with the self\u2011adjointness established in step 1, this proves that $I - T^2$ is a positive operator.\n\n\u220e\n\n---\n\n### Remark\n\nThe argument is elementary and does not require the spectral theorem; it relies only on the definitions of self\u2011adjointness, operator norm, and the fact that $\\|Tx\\| \\le \\|T\\|\\|x\\|$. The self\u2011adjointness of $T$ is essential to rewrite $\\langle T^2 x, x \\rangle$ as $\\|Tx\\|^2$.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $T: L^2[0,1] \\to L^2[0,1]$ be defined by $Tf(x) = \\int_{0}^{x} f(t) dt$. Prove that $T$ is compact and find its spectrum.",
    "run_id": "33",
    "outer_attempt": 1,
    "topic_slug": "operator_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Answer:**\n\nWe prove that $T$ is compact and determine its spectrum.\n\n---\n\n### 1. Compactness of $T$\n\nDefine the kernel  \n$$\nK(x,t) = \\mathbf{1}_{[0,x]}(t) = \n\\begin{cases}\n1, & 0 \\le t \\le x \\le 1,\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$  \nFor any $f\\in L^2[0,1]$ we have  \n$$\n(Tf)(x) = \\int_0^x f(t)\\,dt = \\int_0^1 K(x,t)f(t)\\,dt.\n$$  \nThe kernel is square\u2011integrable because  \n$$\n\\|K\\|_{L^2([0,1]^2)}^2 = \\int_0^1\\int_0^1 |K(x,t)|^2\\,dt\\,dx = \\int_0^1\\int_0^x 1\\,dt\\,dx = \\int_0^1 x\\,dx = \\frac12 < \\infty.\n$$  \nThus $T$ is a Hilbert\u2013Schmidt integral operator. Every Hilbert\u2013Schmidt operator on $L^2$ is compact (it can be approximated in operator norm by finite\u2011rank operators, e.g., by truncating the kernel). Hence $T$ is compact.\n\n---\n\n### 2. Spectrum $\\sigma(T)$\n\nFirst, because $L^2[0,1]$ is infinite\u2011dimensional and $T$ is compact, $0$ must belong to the spectrum. Indeed, if $0$ were in the resolvent set, then $T$ would be invertible and the identity $I = T T^{-1}$ would be compact \u2013 impossible in an infinite\u2011dimensional space. Thus $0\\in\\sigma(T)$.\n\nNow let $\\lambda \\neq 0$. The **Fredholm alternative** for compact operators states that for $\\lambda \\neq 0$, either $\\lambda$ is an eigenvalue of $T$ or $T-\\lambda I$ is bijective with a bounded inverse. Therefore it suffices to show that $T$ has no nonzero eigenvalues.\n\n**Claim:** $T$ has no nonzero eigenvalues.\n\n*Proof.* Suppose $\\lambda \\neq 0$ and $f\\in L^2[0,1]$ satisfies $Tf = \\lambda f$, i.e.,  \n$$\n\\int_0^x f(t)\\,dt = \\lambda f(x) \\qquad \\text{for a.e. } x\\in[0,1]. \\tag{1}\n$$  \nThe left\u2011hand side is absolutely continuous (as an integral of an $L^1$ function), so the right\u2011hand side $\\lambda f$ is absolutely continuous. Since $\\lambda\\neq 0$, $f$ itself is absolutely continuous. Differentiating (1) with respect to $x$ (which holds almost everywhere by the Lebesgue differentiation theorem) gives  \n$$\nf(x) = \\lambda f'(x) \\qquad \\text{for a.e. } x\\in[0,1]. \\tag{2}\n$$  \nEvaluating (1) at $x=0$ yields $0 = \\lambda f(0)$, hence $f(0)=0$.\n\nThus $f$ satisfies the initial value problem  \n$$\nf'(x) = \\frac{1}{\\lambda} f(x) \\quad \\text{a.e.,} \\qquad f(0)=0.\n$$  \nMultiply by the integrating factor $e^{-x/\\lambda}$:  \n$$\n\\frac{d}{dx}\\bigl( f(x) e^{-x/\\lambda} \\bigr) = 0 \\quad \\text{a.e.},\n$$  \nso $f(x) e^{-x/\\lambda}$ is constant almost everywhere. The constant equals $f(0)e^{0}=0$; therefore $f(x)=0$ for almost every $x$. Hence no nonzero $\\lambda$ can be an eigenvalue of $T$. \u220e\n\nConsequently, for every $\\lambda \\neq 0$, $T-\\lambda I$ is bijective and has a bounded inverse, i.e., $\\lambda$ belongs to the resolvent set $\\rho(T)$. Together with $0\\in\\sigma(T)$ we obtain  \n$$\n\\boxed{\\sigma(T) = \\{0\\}}.\n$$\n\n**Remark.** The point spectrum is empty; in particular $0$ is not an eigenvalue because $Tf=0$ implies $f=0$ a.e.\n\n---\n\nThus $T$ is compact and its spectrum is $\\{0\\}$.",
        "raw_answer": "**Answer:**\n\nWe prove that \\(T\\) is compact and determine its spectrum.\n\n---\n\n### 1. Compactness of \\(T\\)\n\nDefine the kernel  \n\\[\nK(x,t) = \\mathbf{1}_{[0,x]}(t) = \n\\begin{cases}\n1, & 0 \\le t \\le x \\le 1,\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n\\]  \nFor any \\(f\\in L^2[0,1]\\) we have  \n\\[\n(Tf)(x) = \\int_0^x f(t)\\,dt = \\int_0^1 K(x,t)f(t)\\,dt.\n\\]  \nThe kernel is square\u2011integrable because  \n\\[\n\\|K\\|_{L^2([0,1]^2)}^2 = \\int_0^1\\int_0^1 |K(x,t)|^2\\,dt\\,dx = \\int_0^1\\int_0^x 1\\,dt\\,dx = \\int_0^1 x\\,dx = \\frac12 < \\infty.\n\\]  \nThus \\(T\\) is a Hilbert\u2013Schmidt integral operator. Every Hilbert\u2013Schmidt operator on \\(L^2\\) is compact (it can be approximated in operator norm by finite\u2011rank operators, e.g., by truncating the kernel). Hence \\(T\\) is compact.\n\n---\n\n### 2. Spectrum \\(\\sigma(T)\\)\n\nFirst, because \\(L^2[0,1]\\) is infinite\u2011dimensional and \\(T\\) is compact, \\(0\\) must belong to the spectrum. Indeed, if \\(0\\) were in the resolvent set, then \\(T\\) would be invertible and the identity \\(I = T T^{-1}\\) would be compact \u2013 impossible in an infinite\u2011dimensional space. Thus \\(0\\in\\sigma(T)\\).\n\nNow let \\(\\lambda \\neq 0\\). The **Fredholm alternative** for compact operators states that for \\(\\lambda \\neq 0\\), either \\(\\lambda\\) is an eigenvalue of \\(T\\) or \\(T-\\lambda I\\) is bijective with a bounded inverse. Therefore it suffices to show that \\(T\\) has no nonzero eigenvalues.\n\n**Claim:** \\(T\\) has no nonzero eigenvalues.\n\n*Proof.* Suppose \\(\\lambda \\neq 0\\) and \\(f\\in L^2[0,1]\\) satisfies \\(Tf = \\lambda f\\), i.e.,  \n\\[\n\\int_0^x f(t)\\,dt = \\lambda f(x) \\qquad \\text{for a.e. } x\\in[0,1]. \\tag{1}\n\\]  \nThe left\u2011hand side is absolutely continuous (as an integral of an \\(L^1\\) function), so the right\u2011hand side \\(\\lambda f\\) is absolutely continuous. Since \\(\\lambda\\neq 0\\), \\(f\\) itself is absolutely continuous. Differentiating (1) with respect to \\(x\\) (which holds almost everywhere by the Lebesgue differentiation theorem) gives  \n\\[\nf(x) = \\lambda f'(x) \\qquad \\text{for a.e. } x\\in[0,1]. \\tag{2}\n\\]  \nEvaluating (1) at \\(x=0\\) yields \\(0 = \\lambda f(0)\\), hence \\(f(0)=0\\).\n\nThus \\(f\\) satisfies the initial value problem  \n\\[\nf'(x) = \\frac{1}{\\lambda} f(x) \\quad \\text{a.e.,} \\qquad f(0)=0.\n\\]  \nMultiply by the integrating factor \\(e^{-x/\\lambda}\\):  \n\\[\n\\frac{d}{dx}\\bigl( f(x) e^{-x/\\lambda} \\bigr) = 0 \\quad \\text{a.e.},\n\\]  \nso \\(f(x) e^{-x/\\lambda}\\) is constant almost everywhere. The constant equals \\(f(0)e^{0}=0\\); therefore \\(f(x)=0\\) for almost every \\(x\\). Hence no nonzero \\(\\lambda\\) can be an eigenvalue of \\(T\\). \u220e\n\nConsequently, for every \\(\\lambda \\neq 0\\), \\(T-\\lambda I\\) is bijective and has a bounded inverse, i.e., \\(\\lambda\\) belongs to the resolvent set \\(\\rho(T)\\). Together with \\(0\\in\\sigma(T)\\) we obtain  \n\\[\n\\boxed{\\sigma(T) = \\{0\\}}.\n\\]\n\n**Remark.** The point spectrum is empty; in particular \\(0\\) is not an eigenvalue because \\(Tf=0\\) implies \\(f=0\\) a.e.\n\n---\n\nThus \\(T\\) is compact and its spectrum is \\(\\{0\\}\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of calculus of variations and optimal control, along with a complete solution. The problem should be solvable, verifiable, and adhere to the specified format.",
    "run_id": "34",
    "outer_attempt": 1,
    "topic_slug": "calculus_of_variations_and_optimization",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem.**  \nA bead slides under the influence of gravity (constant acceleration $g$) along a frictionless wire from point $A(0,0)$ to point $B(x_1,y_1)$ with $y_1>0$. The bead starts from rest at $A$. Find the shape of the wire, i.e., the curve $y(x)$ for $0\\le x\\le x_1$ with $y(0)=0$ and $y(x_1)=y_1$, that minimizes the time of descent.\n\nShow that the time functional is  \n\n$$\nT[y]=\\int_{0}^{x_1}\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{2g\\,y}}\\;dx,\n$$\n\nand determine the minimizing curve explicitly.\n\n---\n\n**Solution.**  \n\n### 1. Derivation of the functional  \nLet the curve be described by $y=y(x)$, $y(0)=0$, $y(x_1)=y_1$. The speed of the bead at a height $y$ follows from conservation of energy:  \n\n$$\n\\frac{1}{2}mv^{2}=mgy\\quad\\Longrightarrow\\quad v=\\sqrt{2gy}.\n$$\n\nAn infinitesimal arc length along the curve is $ds=\\sqrt{1+(y')^{2}}\\,dx$. The time taken to traverse that element is $dt=ds/v$. Hence the total time is  \n\n$$\nT[y]=\\int_{0}^{x_1}\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{2gy}}\\;dx.\n$$\n\nWe ignore the constant factor $1/\\sqrt{2g}$ because it does not affect the minimizer. Thus we study the functional  \n\n$$\nJ[y]=\\int_{0}^{x_1}F(y,y')\\,dx,\\qquad F(y,y')=\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}.\n$$\n\n### 2. Calculus of variations setup  \nWe seek a twice differentiable function $y(x)>0$ for $x>0$ satisfying the fixed endpoints $y(0)=0$, $y(x_1)=y_1$ that minimizes $J$. The Euler\u2011Lagrange equation is  \n\n$$\n\\frac{\\partial F}{\\partial y}-\\frac{d}{dx}\\frac{\\partial F}{\\partial y'}=0.\n$$\n\nBecause $F$ does not depend explicitly on $x$, we may use the **Beltrami identity** (first integral of the Euler\u2011Lagrange equation):  \n\n$$\nF-y'\\frac{\\partial F}{\\partial y'}=C,\\qquad C\\text{ constant}.\n$$\n\nWe verify that this is legitimate: differentiating the left\u2011hand side with respect to $x$ and using the Euler\u2011Lagrange equation yields zero.\n\n### 3. Computing the first integral  \nCompute  \n\n$$\n\\frac{\\partial F}{\\partial y'}=\\frac{1}{\\sqrt{y}}\\cdot\\frac{y'}{\\sqrt{1+(y')^{2}}}=\\frac{y'}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}.\n$$\n\nThen  \n\n$$\nF-y'\\frac{\\partial F}{\\partial y'}=\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}-\\frac{(y')^{2}}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}\n=\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}\\Bigl(1+(y')^{2}-(y')^{2}\\Bigr)\n=\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}.\n$$\n\nHence the Beltrami identity gives  \n\n$$\n\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}=C.\n$$\n\nSquaring and rearranging,  \n\n$$\ny\\,(1+(y')^{2})=\\frac{1}{C^{2}}\\equiv k,\n$$\n\nwhere $k>0$ is a constant. Thus we have the first\u2011order differential equation  \n\n$$\ny\\,(1+(y')^{2})=k. \\tag{1}\n$$\n\n### 4. Solving the ODE  \nEquation (1) can be rewritten as  \n\n$$\n(y')^{2}=\\frac{k-y}{y}\\quad\\Longrightarrow\\quad y'=\\pm\\sqrt{\\frac{k-y}{y}}.\n$$\n\nSince the bead descends, $y$ increases from $0$ to a positive value; however, from (1) we see that $y\\le k$. At the starting point $y=0$, the right\u2011hand side is infinite, so the curve has a vertical tangent there. For $x>0$ we expect $y$ to increase, so $y'>0$. But note: if we take the positive square root, then $y'=\\sqrt{(k-y)/y}>0$. As $y\\to0^{+}$, $y'\\to+\\infty$, consistent with a vertical start. Therefore we choose the **positive** sign:  \n\n$$\n\\frac{dy}{dx}=\\sqrt{\\frac{k-y}{y}}.\n$$\n\nSeparating variables,  \n\n$$\ndx=\\sqrt{\\frac{y}{k-y}}\\;dy. \\tag{2}\n$$\n\n### 5. Parametric integration  \nTo integrate (2), set  \n\n$$\ny=\\frac{k}{2}(1-\\cos\\theta)=k\\sin^{2}\\frac{\\theta}{2},\\qquad 0\\le\\theta\\le\\pi\\;\\;(\\text{so that }0\\le y\\le k).\n$$\n\nThen  \n\n$$\ndy=\\frac{k}{2}\\sin\\theta\\,d\\theta.\n$$\n\nAlso  \n\n$$\n\\sqrt{\\frac{y}{k-y}}=\\sqrt{\\frac{k\\sin^{2}(\\theta/2)}{k\\cos^{2}(\\theta/2)}}=\\tan\\frac{\\theta}{2}.\n$$\n\nSubstituting into (2):  \n\n$$\ndx=\\tan\\frac{\\theta}{2}\\cdot\\frac{k}{2}\\sin\\theta\\,d\\theta.\n$$\n\nUsing $\\sin\\theta=2\\sin(\\theta/2)\\cos(\\theta/2)$,  \n\n$$\n\\tan\\frac{\\theta}{2}\\sin\\theta=2\\sin^{2}\\frac{\\theta}{2}.\n$$\n\nHence  \n\n$$\ndx=\\frac{k}{2}\\cdot2\\sin^{2}\\frac{\\theta}{2}\\,d\\theta=k\\sin^{2}\\frac{\\theta}{2}\\,d\\theta\n=\\frac{k}{2}(1-\\cos\\theta)\\,d\\theta.\n$$\n\nIntegrating,  \n\n$$\nx=\\frac{k}{2}\\int(1-\\cos\\theta)\\,d\\theta=\\frac{k}{2}(\\theta-\\sin\\theta)+D,\n$$\n\nwhere $D$ is a constant of integration.\n\n### 6. Imposing the initial condition  \nAt the starting point $A$ we have $x=0$, $y=0$, which corresponds to $\\theta=0$. Substituting gives $0=\\frac{k}{2}(0-0)+D$, so $D=0$. Therefore the curve is given parametrically by  \n\n$$\n\\boxed{\\begin{aligned}\nx(\\theta)&=\\frac{k}{2}(\\theta-\\sin\\theta),\\$$2mm]\ny(\\theta)&=\\frac{k}{2}(1-\\cos\\theta),\n\\end{aligned}}\\qquad 0\\le\\theta\\le\\theta_1,\n$$\n\nwhere $\\theta_1$ is the value for which $x(\\theta_1)=x_1$ and $y(\\theta_1)=y_1$. This is a **cycloid** generated by a circle of radius $k/2$ rolling along the underside of the line $y=0$.\n\n### 7. Determining the constant $k$  \nThe constant $k$ (or equivalently the radius) is fixed by the requirement that the curve passes through $B(x_1,y_1)$. From the parametric equations,  \n\n$$\nx_1=\\frac{k}{2}(\\theta_1-\\sin\\theta_1),\\qquad y_1=\\frac{k}{2}(1-\\cos\\theta_1).\n$$\n\nEliminating $k$ gives  \n\n$$\n\\frac{y_1}{x_1}=\\frac{1-\\cos\\theta_1}{\\theta_1-\\sin\\theta_1},\n$$\n\nwhich determines $\\theta_1$ uniquely for given $x_1,y_1$ (provided a cycloid connecting the points exists). Then $k=2y_1/(1-\\cos\\theta_1)$. In practice, $\\theta_1$ must be solved numerically, but the existence of a solution is guaranteed for $x_1>0$, $y_1>0$.\n\n### 8. Verification of minimality  \nThe Legendre condition for a weak minimum requires $F_{y'y'}>0$ along the extremal. Compute  \n\n$$\nF_{y'y'}=\\frac{\\partial^{2}}{\\partial (y')^{2}}\\left(\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}\\right)\n=\\frac{1}{\\sqrt{y}}\\cdot\\frac{1}{(1+(y')^{2})^{3/2}}>0\\quad\\text{for }y>0.\n$$\n\nThus the extremal satisfies the necessary condition for a weak local minimum. Moreover, because the functional is convex in $y'$ for fixed $y>0$ and the extremal is unique, it indeed furnishes the global minimum.\n\n### 9. Conclusion  \nThe curve that minimizes the time of descent is a **cycloid** given by the parametric equations above. This famous result is the solution to the brachistochrone problem, first solved by Johann Bernoulli in 1696.\n\n---",
        "raw_answer": "**Problem.**  \nA bead slides under the influence of gravity (constant acceleration \\(g\\)) along a frictionless wire from point \\(A(0,0)\\) to point \\(B(x_1,y_1)\\) with \\(y_1>0\\). The bead starts from rest at \\(A\\). Find the shape of the wire, i.e., the curve \\(y(x)\\) for \\(0\\le x\\le x_1\\) with \\(y(0)=0\\) and \\(y(x_1)=y_1\\), that minimizes the time of descent.\n\nShow that the time functional is  \n\n\\[\nT[y]=\\int_{0}^{x_1}\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{2g\\,y}}\\;dx,\n\\]\n\nand determine the minimizing curve explicitly.\n\n---\n\n**Solution.**  \n\n### 1. Derivation of the functional  \nLet the curve be described by \\(y=y(x)\\), \\(y(0)=0\\), \\(y(x_1)=y_1\\). The speed of the bead at a height \\(y\\) follows from conservation of energy:  \n\n\\[\n\\frac{1}{2}mv^{2}=mgy\\quad\\Longrightarrow\\quad v=\\sqrt{2gy}.\n\\]\n\nAn infinitesimal arc length along the curve is \\(ds=\\sqrt{1+(y')^{2}}\\,dx\\). The time taken to traverse that element is \\(dt=ds/v\\). Hence the total time is  \n\n\\[\nT[y]=\\int_{0}^{x_1}\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{2gy}}\\;dx.\n\\]\n\nWe ignore the constant factor \\(1/\\sqrt{2g}\\) because it does not affect the minimizer. Thus we study the functional  \n\n\\[\nJ[y]=\\int_{0}^{x_1}F(y,y')\\,dx,\\qquad F(y,y')=\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}.\n\\]\n\n### 2. Calculus of variations setup  \nWe seek a twice differentiable function \\(y(x)>0\\) for \\(x>0\\) satisfying the fixed endpoints \\(y(0)=0\\), \\(y(x_1)=y_1\\) that minimizes \\(J\\). The Euler\u2011Lagrange equation is  \n\n\\[\n\\frac{\\partial F}{\\partial y}-\\frac{d}{dx}\\frac{\\partial F}{\\partial y'}=0.\n\\]\n\nBecause \\(F\\) does not depend explicitly on \\(x\\), we may use the **Beltrami identity** (first integral of the Euler\u2011Lagrange equation):  \n\n\\[\nF-y'\\frac{\\partial F}{\\partial y'}=C,\\qquad C\\text{ constant}.\n\\]\n\nWe verify that this is legitimate: differentiating the left\u2011hand side with respect to \\(x\\) and using the Euler\u2011Lagrange equation yields zero.\n\n### 3. Computing the first integral  \nCompute  \n\n\\[\n\\frac{\\partial F}{\\partial y'}=\\frac{1}{\\sqrt{y}}\\cdot\\frac{y'}{\\sqrt{1+(y')^{2}}}=\\frac{y'}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}.\n\\]\n\nThen  \n\n\\[\nF-y'\\frac{\\partial F}{\\partial y'}=\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}-\\frac{(y')^{2}}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}\n=\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}\\Bigl(1+(y')^{2}-(y')^{2}\\Bigr)\n=\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}.\n\\]\n\nHence the Beltrami identity gives  \n\n\\[\n\\frac{1}{\\sqrt{y}\\,\\sqrt{1+(y')^{2}}}=C.\n\\]\n\nSquaring and rearranging,  \n\n\\[\ny\\,(1+(y')^{2})=\\frac{1}{C^{2}}\\equiv k,\n\\]\n\nwhere \\(k>0\\) is a constant. Thus we have the first\u2011order differential equation  \n\n\\[\ny\\,(1+(y')^{2})=k. \\tag{1}\n\\]\n\n### 4. Solving the ODE  \nEquation (1) can be rewritten as  \n\n\\[\n(y')^{2}=\\frac{k-y}{y}\\quad\\Longrightarrow\\quad y'=\\pm\\sqrt{\\frac{k-y}{y}}.\n\\]\n\nSince the bead descends, \\(y\\) increases from \\(0\\) to a positive value; however, from (1) we see that \\(y\\le k\\). At the starting point \\(y=0\\), the right\u2011hand side is infinite, so the curve has a vertical tangent there. For \\(x>0\\) we expect \\(y\\) to increase, so \\(y'>0\\). But note: if we take the positive square root, then \\(y'=\\sqrt{(k-y)/y}>0\\). As \\(y\\to0^{+}\\), \\(y'\\to+\\infty\\), consistent with a vertical start. Therefore we choose the **positive** sign:  \n\n\\[\n\\frac{dy}{dx}=\\sqrt{\\frac{k-y}{y}}.\n\\]\n\nSeparating variables,  \n\n\\[\ndx=\\sqrt{\\frac{y}{k-y}}\\;dy. \\tag{2}\n\\]\n\n### 5. Parametric integration  \nTo integrate (2), set  \n\n\\[\ny=\\frac{k}{2}(1-\\cos\\theta)=k\\sin^{2}\\frac{\\theta}{2},\\qquad 0\\le\\theta\\le\\pi\\;\\;(\\text{so that }0\\le y\\le k).\n\\]\n\nThen  \n\n\\[\ndy=\\frac{k}{2}\\sin\\theta\\,d\\theta.\n\\]\n\nAlso  \n\n\\[\n\\sqrt{\\frac{y}{k-y}}=\\sqrt{\\frac{k\\sin^{2}(\\theta/2)}{k\\cos^{2}(\\theta/2)}}=\\tan\\frac{\\theta}{2}.\n\\]\n\nSubstituting into (2):  \n\n\\[\ndx=\\tan\\frac{\\theta}{2}\\cdot\\frac{k}{2}\\sin\\theta\\,d\\theta.\n\\]\n\nUsing \\(\\sin\\theta=2\\sin(\\theta/2)\\cos(\\theta/2)\\),  \n\n\\[\n\\tan\\frac{\\theta}{2}\\sin\\theta=2\\sin^{2}\\frac{\\theta}{2}.\n\\]\n\nHence  \n\n\\[\ndx=\\frac{k}{2}\\cdot2\\sin^{2}\\frac{\\theta}{2}\\,d\\theta=k\\sin^{2}\\frac{\\theta}{2}\\,d\\theta\n=\\frac{k}{2}(1-\\cos\\theta)\\,d\\theta.\n\\]\n\nIntegrating,  \n\n\\[\nx=\\frac{k}{2}\\int(1-\\cos\\theta)\\,d\\theta=\\frac{k}{2}(\\theta-\\sin\\theta)+D,\n\\]\n\nwhere \\(D\\) is a constant of integration.\n\n### 6. Imposing the initial condition  \nAt the starting point \\(A\\) we have \\(x=0\\), \\(y=0\\), which corresponds to \\(\\theta=0\\). Substituting gives \\(0=\\frac{k}{2}(0-0)+D\\), so \\(D=0\\). Therefore the curve is given parametrically by  \n\n\\[\n\\boxed{\\begin{aligned}\nx(\\theta)&=\\frac{k}{2}(\\theta-\\sin\\theta),\\\\[2mm]\ny(\\theta)&=\\frac{k}{2}(1-\\cos\\theta),\n\\end{aligned}}\\qquad 0\\le\\theta\\le\\theta_1,\n\\]\n\nwhere \\(\\theta_1\\) is the value for which \\(x(\\theta_1)=x_1\\) and \\(y(\\theta_1)=y_1\\). This is a **cycloid** generated by a circle of radius \\(k/2\\) rolling along the underside of the line \\(y=0\\).\n\n### 7. Determining the constant \\(k\\)  \nThe constant \\(k\\) (or equivalently the radius) is fixed by the requirement that the curve passes through \\(B(x_1,y_1)\\). From the parametric equations,  \n\n\\[\nx_1=\\frac{k}{2}(\\theta_1-\\sin\\theta_1),\\qquad y_1=\\frac{k}{2}(1-\\cos\\theta_1).\n\\]\n\nEliminating \\(k\\) gives  \n\n\\[\n\\frac{y_1}{x_1}=\\frac{1-\\cos\\theta_1}{\\theta_1-\\sin\\theta_1},\n\\]\n\nwhich determines \\(\\theta_1\\) uniquely for given \\(x_1,y_1\\) (provided a cycloid connecting the points exists). Then \\(k=2y_1/(1-\\cos\\theta_1)\\). In practice, \\(\\theta_1\\) must be solved numerically, but the existence of a solution is guaranteed for \\(x_1>0\\), \\(y_1>0\\).\n\n### 8. Verification of minimality  \nThe Legendre condition for a weak minimum requires \\(F_{y'y'}>0\\) along the extremal. Compute  \n\n\\[\nF_{y'y'}=\\frac{\\partial^{2}}{\\partial (y')^{2}}\\left(\\frac{\\sqrt{1+(y')^{2}}}{\\sqrt{y}}\\right)\n=\\frac{1}{\\sqrt{y}}\\cdot\\frac{1}{(1+(y')^{2})^{3/2}}>0\\quad\\text{for }y>0.\n\\]\n\nThus the extremal satisfies the necessary condition for a weak local minimum. Moreover, because the functional is convex in \\(y'\\) for fixed \\(y>0\\) and the extremal is unique, it indeed furnishes the global minimum.\n\n### 9. Conclusion  \nThe curve that minimizes the time of descent is a **cycloid** given by the parametric equations above. This famous result is the solution to the brachistochrone problem, first solved by Johann Bernoulli in 1696.\n\n---",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Geometry, along with a complete and verifiable solution. The problem must be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Choose a geometry topic\nTo create a challenging problem, we need to select a topic within geometry that is rich enough to allow for a non-trivial question. Let's consider problems related to geometric shapes, such as triangles, circles, or more complex figures.\n\n## Step 3: Formulate a problem\nLet's formulate a problem involving a triangle and a circle, as these are fundamental geometric objects. A potential problem could involve the properties of inscribed angles, the relationship between a triangle and its circumcircle, or the application of geometric theorems like Ptolemy's theorem.\n\n## Step 4: Create a specific problem\nConsider the following problem: \"Let $ABC$ be a triangle with $AB = 5$, $AC = 6$, and $BC = 7$. The circumcircle of triangle $ABC$ has center $O$. Let $D$ be the point on $BC$ such that $AD$ is the angle bisector of $\\angle BAC$. Find the length of $AD$.\"\n\n## Step 5: Verify the problem meets the criteria\n- **Well-Posedness and Completeness**: The triangle $ABC$ is well-defined by its side lengths (5, 6, 7), and $D$ is defined as the point on $BC$ where $AD$ bisects $\\angle BAC$. The circumcircle and its center $O$ are also well-defined.\n- **Clarity**: The problem statement is clear and unambiguous.\n- **Non-Triviality**: The problem requires applying geometric principles, such as the Angle Bisector Theorem and possibly properties of the circumcircle.\n- **Solvability and Verification**: The problem is solvable using established geometric methods.\n\n## Step 6: Solve the problem\nTo solve this, we can use the Angle Bisector Theorem to find $BD$ and $DC$, and then apply the Stewart's Theorem to find $AD$.\n\n### Step 6.1: Apply the Angle Bisector Theorem\nThe Angle Bisector Theorem states that $\\frac{BD}{DC} = \\frac{AB}{AC}$. So, $\\frac{BD}{DC} = \\frac{5}{6}$.\n\n### Step 6.2: Calculate $BD$ and $DC$\nGiven $BC = 7$, we have $BD + DC = 7$. From the Angle Bisector Theorem, we can write $BD = \\frac{5}{11} \\times 7$ and $DC = \\frac{6}{11} \\times 7$. Thus, $BD = \\frac{35}{11}$ and $DC = \\frac{42}{11}$.\n\n### Step 6.3: Apply Stewart's Theorem to find $AD$\nStewart's Theorem states that $b^2n + c^2m = a(d^2 + m*n)$, where $a = BC = 7$, $b = AC = 6$, $c = AB = 5$, $d = AD$, $m = BD = \\frac{35}{11}$, and $n = DC = \\frac{42}{11}$. Substituting these values gives us an equation to solve for $d = AD$.\n\n## Step 7: Perform Stewart's Theorem calculation\nLet's substitute the given values into Stewart's Theorem:\n$6^2(\\frac{35}{11}) + 5^2(\\frac{42}{11}) = 7(AD^2 + \\frac{35}{11}*\\frac{42}{11})$.\nSimplifying yields:\n$36(\\frac{35}{11}) + 25(\\frac{42}{11}) = 7(AD^2 + \\frac{1470}{121})$.\nThis simplifies to:\n$\\frac{1260}{11} + \\frac{1050}{11} = 7AD^2 + \\frac{7*1470}{121}$.\nFurther simplification gives:\n$\\frac{2310}{11} = 7AD^2 + \\frac{10290}{121}$.\nConverting to a common denominator:\n$\\frac{2310*11}{121} = 7AD^2 + \\frac{10290}{121}$,\n$\\frac{25410}{121} = 7AD^2 + \\frac{10290}{121}$.\nSimplifying:\n$7AD^2 = \\frac{25410 - 10290}{121}$,\n$7AD^2 = \\frac{15120}{121}$,\n$AD^2 = \\frac{15120}{7*121}$,\n$AD^2 = \\frac{2160}{121}$,\n$AD = \\sqrt{\\frac{2160}{121}}$.\n\n## Step 8: Simplify $AD$\n$AD = \\sqrt{\\frac{2160}{121}} = \\sqrt{\\frac{16*135}{121}} = \\sqrt{\\frac{16*9*15}{121}} = \\frac{4*3}{11}\\sqrt{15} = \\frac{12\\sqrt{15}}{11}$.\n\nThe final answer is: \n\nLet $ABC$ be a triangle with $AB = 5$, $AC = 6$, and $BC = 7$. The circumcircle of triangle $ABC$ has center $O$. Let $D$ be the point on $BC$ such that $AD$ is the angle bisector of $\\angle BAC$. Find the length of $AD$.",
    "run_id": "35",
    "outer_attempt": 1,
    "topic_slug": "geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are given triangle $ABC$ with side lengths $AB = 5$, $AC = 6$, $BC = 7$.  \nPoint $D$ lies on $BC$ such that $AD$ bisects $\\angle BAC$.  \nWe are to find the length $AD$.\n\n---\n\n### Step 1: Apply the Angle Bisector Theorem\n\nThe Angle Bisector Theorem states that for any triangle, the internal bisector of an angle divides the opposite side into segments proportional to the adjacent sides.  \nThus,\n$$\n\\frac{BD}{DC} = \\frac{AB}{AC} = \\frac{5}{6}.\n$$\nSince $BD + DC = BC = 7$, we set\n$$\nBD = \\frac{5}{5+6}\\cdot 7 = \\frac{35}{11}, \\qquad\nDC = \\frac{6}{5+6}\\cdot 7 = \\frac{42}{11}.\n$$\n\n---\n\n### Step 2: Apply Stewart\u2019s Theorem\n\nStewart\u2019s Theorem relates the sides of a triangle and the length of a cevian.  \nFor $\\triangle ABC$ with sides $a = BC = 7$, $b = AC = 6$, $c = AB = 5$, and cevian $AD$ of length $d$ meeting $BC$ at $D$ with $BD = m = \\frac{35}{11}$, $DC = n = \\frac{42}{11}$, the theorem states:\n$$\nb^2 m + c^2 n = a\\bigl(d^2 + m n\\bigr).\n$$\n\nSubstitute the known values:\n$$\n\\begin{aligned}\nb^2 m &= 6^2 \\cdot \\frac{35}{11} = 36 \\cdot \\frac{35}{11} = \\frac{1260}{11},\\$$4pt]\nc^2 n &= 5^2 \\cdot \\frac{42}{11} = 25 \\cdot \\frac{42}{11} = \\frac{1050}{11},\\$$4pt]\n\\text{Sum} &= \\frac{1260}{11} + \\frac{1050}{11} = \\frac{2310}{11}.\n\\end{aligned}\n$$\n$$\nm n = \\frac{35}{11} \\cdot \\frac{42}{11} = \\frac{1470}{121}.\n$$\nThus the right\u2011hand side becomes\n$$\n7\\left(d^2 + \\frac{1470}{121}\\right) = 7d^2 + \\frac{10290}{121}.\n$$\n\nEquating both sides:\n$$\n\\frac{2310}{11} = 7d^2 + \\frac{10290}{121}.\n$$\n\nConvert the left side to denominator $121$:\n$$\n\\frac{2310}{11} = \\frac{2310 \\times 11}{121} = \\frac{25410}{121}.\n$$\nHence,\n$$\n\\frac{25410}{121} = 7d^2 + \\frac{10290}{121}.\n$$\nSubtract $\\frac{10290}{121}$:\n$$\n7d^2 = \\frac{25410 - 10290}{121} = \\frac{15120}{121}.\n$$\nDivide by $7$:\n$$\nd^2 = \\frac{15120}{7 \\times 121} = \\frac{2160}{121}.\n$$\n\n---\n\n### Step 3: Simplify $d = AD$\n\n$$\nd = \\sqrt{\\frac{2160}{121}} = \\frac{\\sqrt{2160}}{11}.\n$$\nFactor $2160$:\n$$\n2160 = 16 \\times 135 = 16 \\times 9 \\times 15 = 4^2 \\times 3^2 \\times 15,\n$$\nso\n$$\n\\sqrt{2160} = \\sqrt{4^2 \\times 3^2 \\times 15} = 4 \\times 3 \\times \\sqrt{15} = 12\\sqrt{15}.\n$$\nTherefore,\n$$\nAD = \\frac{12\\sqrt{15}}{11}.\n$$\n\n---\n\n### Final Answer\n\n$$\n\\boxed{\\dfrac{12\\sqrt{15}}{11}}\n$$",
        "raw_answer": "We are given triangle $ABC$ with side lengths $AB = 5$, $AC = 6$, $BC = 7$.  \nPoint $D$ lies on $BC$ such that $AD$ bisects $\\angle BAC$.  \nWe are to find the length $AD$.\n\n---\n\n### Step 1: Apply the Angle Bisector Theorem\n\nThe Angle Bisector Theorem states that for any triangle, the internal bisector of an angle divides the opposite side into segments proportional to the adjacent sides.  \nThus,\n\\[\n\\frac{BD}{DC} = \\frac{AB}{AC} = \\frac{5}{6}.\n\\]\nSince $BD + DC = BC = 7$, we set\n\\[\nBD = \\frac{5}{5+6}\\cdot 7 = \\frac{35}{11}, \\qquad\nDC = \\frac{6}{5+6}\\cdot 7 = \\frac{42}{11}.\n\\]\n\n---\n\n### Step 2: Apply Stewart\u2019s Theorem\n\nStewart\u2019s Theorem relates the sides of a triangle and the length of a cevian.  \nFor $\\triangle ABC$ with sides $a = BC = 7$, $b = AC = 6$, $c = AB = 5$, and cevian $AD$ of length $d$ meeting $BC$ at $D$ with $BD = m = \\frac{35}{11}$, $DC = n = \\frac{42}{11}$, the theorem states:\n\\[\nb^2 m + c^2 n = a\\bigl(d^2 + m n\\bigr).\n\\]\n\nSubstitute the known values:\n\\[\n\\begin{aligned}\nb^2 m &= 6^2 \\cdot \\frac{35}{11} = 36 \\cdot \\frac{35}{11} = \\frac{1260}{11},\\\\[4pt]\nc^2 n &= 5^2 \\cdot \\frac{42}{11} = 25 \\cdot \\frac{42}{11} = \\frac{1050}{11},\\\\[4pt]\n\\text{Sum} &= \\frac{1260}{11} + \\frac{1050}{11} = \\frac{2310}{11}.\n\\end{aligned}\n\\]\n\\[\nm n = \\frac{35}{11} \\cdot \\frac{42}{11} = \\frac{1470}{121}.\n\\]\nThus the right\u2011hand side becomes\n\\[\n7\\left(d^2 + \\frac{1470}{121}\\right) = 7d^2 + \\frac{10290}{121}.\n\\]\n\nEquating both sides:\n\\[\n\\frac{2310}{11} = 7d^2 + \\frac{10290}{121}.\n\\]\n\nConvert the left side to denominator $121$:\n\\[\n\\frac{2310}{11} = \\frac{2310 \\times 11}{121} = \\frac{25410}{121}.\n\\]\nHence,\n\\[\n\\frac{25410}{121} = 7d^2 + \\frac{10290}{121}.\n\\]\nSubtract $\\frac{10290}{121}$:\n\\[\n7d^2 = \\frac{25410 - 10290}{121} = \\frac{15120}{121}.\n\\]\nDivide by $7$:\n\\[\nd^2 = \\frac{15120}{7 \\times 121} = \\frac{2160}{121}.\n\\]\n\n---\n\n### Step 3: Simplify $d = AD$\n\n\\[\nd = \\sqrt{\\frac{2160}{121}} = \\frac{\\sqrt{2160}}{11}.\n\\]\nFactor $2160$:\n\\[\n2160 = 16 \\times 135 = 16 \\times 9 \\times 15 = 4^2 \\times 3^2 \\times 15,\n\\]\nso\n\\[\n\\sqrt{2160} = \\sqrt{4^2 \\times 3^2 \\times 15} = 4 \\times 3 \\times \\sqrt{15} = 12\\sqrt{15}.\n\\]\nTherefore,\n\\[\nAD = \\frac{12\\sqrt{15}}{11}.\n\\]\n\n---\n\n### Final Answer\n\n\\[\n\\boxed{\\dfrac{12\\sqrt{15}}{11}}\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Convex and discrete geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Convex and discrete geometry\nConvex and discrete geometry encompasses a broad range of topics including the geometry of convex sets, polytopes, and discrete geometric structures. A suitable topic could involve properties of convex polytopes, such as their faces, volumes, or the relationships between their vertices and facets.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem related to the properties of a specific convex polytope. A well-known result in convex geometry is the characterization of regular polytopes. However, a more challenging and less straightforward problem could involve understanding the relationship between the number of vertices, edges, and faces of a polytope.\n\n## Step 4: Generate a problem statement\nConsider a 3-dimensional convex polytope $P$ that is simple (every vertex is incident to exactly 3 edges) and has $V$ vertices, $E$ edges, and $F$ faces. The problem is to prove that for such a polytope, Euler's formula ($V - E + F = 2$) holds, and then use this to derive a relationship between $V$ and $F$.\n\n## Step 5: Write down the problem in the required format\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces. Prove that $V - E + F = 2$ and derive a formula relating $V$ and $F$ using the fact that $P$ is simple.",
    "run_id": "36",
    "outer_attempt": 1,
    "topic_slug": "convex_and_discrete_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe prove Euler's formula for any convex polyhedron and then specialize to simple polytopes.\n\n---\n\n### 1. Euler's formula $V - E + F = 2$\n\nLet $P$ be a convex polyhedron with $V$ vertices, $E$ edges and $F$ faces.\n\n**Planar graph representation.**  \nChoose a face of $P$ and project $P$ onto a plane from a point just outside that face. The image is a planar graph $G$ whose vertices correspond to the vertices of $P$, edges correspond to the edges of $P$, and faces correspond to the faces of $P$ (the chosen face becomes the outer face). Because the 1\u2011skeleton of a convex polyhedron is connected, $G$ is connected.\n\n**Proof by induction on $E$.**  \nWe prove that for any connected planar graph embedded in the plane, $V - E + F = 2$, where $F$ includes the unbounded outer face.\n\n*Base case: $G$ is a tree.*  \nA tree has no cycles, hence it has only one face (the outer face). For a tree, $E = V - 1$. Then  \n$$\nV - (V-1) + 1 = 2.\n$$\n\n*Inductive step.*  \nAssume the formula holds for all connected planar graphs with fewer than $E$ edges. If $G$ has no cycle, it is a tree and we are done. Otherwise, choose an edge $e$ that lies on a cycle. Removing $e$ yields a graph $G'$ that remains connected (because $e$ is not a bridge) and planar. In the embedding, $e$ separates two distinct faces; its removal merges those two faces into one. Hence  \n$$\nV' = V,\\quad E' = E-1,\\quad F' = F-1.\n$$  \nBy the induction hypothesis, $V' - E' + F' = 2$. Substituting gives  \n$$\nV - (E-1) + (F-1) = 2 \\;\\Longrightarrow\\; V - E + F = 2.\n$$\n\nThus Euler\u2019s formula holds for $G$ and therefore for the original polyhedron $P$.\n\n---\n\n### 2. Relation for simple polytopes\n\nA **simple** 3\u2011dimensional polytope has exactly three edges meeting at every vertex, i.e., each vertex has degree $3$. Counting edge\u2011vertex incidences in two ways gives  \n$$\n\\sum_{v} \\deg(v) = 2E.\n$$  \nBecause all degrees equal $3$, we obtain $3V = 2E$, so  \n$$\nE = \\frac{3}{2}V.\n$$\n\nSubstitute this into Euler\u2019s formula:  \n$$\nV - \\frac{3}{2}V + F = 2 \\;\\Longrightarrow\\; -\\frac{1}{2}V + F = 2 \\;\\Longrightarrow\\; F = 2 + \\frac{V}{2}.\n$$\n\nHence for any simple convex 3\u2011polytope,  \n$$\n\\boxed{F = 2 + \\frac{V}{2}}.\n$$  \nIn particular, $V$ must be even. This agrees with examples: the cube ($V=8,\\;F=6$) and the regular dodecahedron ($V=20,\\;F=12$).",
        "raw_answer": "**Solution**\n\nWe prove Euler's formula for any convex polyhedron and then specialize to simple polytopes.\n\n---\n\n### 1. Euler's formula \\(V - E + F = 2\\)\n\nLet \\(P\\) be a convex polyhedron with \\(V\\) vertices, \\(E\\) edges and \\(F\\) faces.\n\n**Planar graph representation.**  \nChoose a face of \\(P\\) and project \\(P\\) onto a plane from a point just outside that face. The image is a planar graph \\(G\\) whose vertices correspond to the vertices of \\(P\\), edges correspond to the edges of \\(P\\), and faces correspond to the faces of \\(P\\) (the chosen face becomes the outer face). Because the 1\u2011skeleton of a convex polyhedron is connected, \\(G\\) is connected.\n\n**Proof by induction on \\(E\\).**  \nWe prove that for any connected planar graph embedded in the plane, \\(V - E + F = 2\\), where \\(F\\) includes the unbounded outer face.\n\n*Base case: \\(G\\) is a tree.*  \nA tree has no cycles, hence it has only one face (the outer face). For a tree, \\(E = V - 1\\). Then  \n\\[\nV - (V-1) + 1 = 2.\n\\]\n\n*Inductive step.*  \nAssume the formula holds for all connected planar graphs with fewer than \\(E\\) edges. If \\(G\\) has no cycle, it is a tree and we are done. Otherwise, choose an edge \\(e\\) that lies on a cycle. Removing \\(e\\) yields a graph \\(G'\\) that remains connected (because \\(e\\) is not a bridge) and planar. In the embedding, \\(e\\) separates two distinct faces; its removal merges those two faces into one. Hence  \n\\[\nV' = V,\\quad E' = E-1,\\quad F' = F-1.\n\\]  \nBy the induction hypothesis, \\(V' - E' + F' = 2\\). Substituting gives  \n\\[\nV - (E-1) + (F-1) = 2 \\;\\Longrightarrow\\; V - E + F = 2.\n\\]\n\nThus Euler\u2019s formula holds for \\(G\\) and therefore for the original polyhedron \\(P\\).\n\n---\n\n### 2. Relation for simple polytopes\n\nA **simple** 3\u2011dimensional polytope has exactly three edges meeting at every vertex, i.e., each vertex has degree \\(3\\). Counting edge\u2011vertex incidences in two ways gives  \n\\[\n\\sum_{v} \\deg(v) = 2E.\n\\]  \nBecause all degrees equal \\(3\\), we obtain \\(3V = 2E\\), so  \n\\[\nE = \\frac{3}{2}V.\n\\]\n\nSubstitute this into Euler\u2019s formula:  \n\\[\nV - \\frac{3}{2}V + F = 2 \\;\\Longrightarrow\\; -\\frac{1}{2}V + F = 2 \\;\\Longrightarrow\\; F = 2 + \\frac{V}{2}.\n\\]\n\nHence for any simple convex 3\u2011polytope,  \n\\[\n\\boxed{F = 2 + \\frac{V}{2}}.\n\\]  \nIn particular, \\(V\\) must be even. This agrees with examples: the cube (\\(V=8,\\;F=6\\)) and the regular dodecahedron (\\(V=20,\\;F=12\\)).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of differential geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within differential geometry\nDifferential geometry is a broad field that includes the study of curves and surfaces, Riemannian geometry, and more. A suitable topic could involve the properties of curves or surfaces, such as curvature, geodesics, or the application of differential geometry to other areas like physics.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the curvature of a surface. A classic result in differential geometry is the Theorema Egregium of Gauss, which states that the Gaussian curvature of a surface is invariant under isometric deformations. A challenging problem could involve calculating or utilizing this curvature.\n\n## Step 4: Construct the problem statement\nTo create a problem, let's consider a specific surface and ask a question about its geometric properties. For example, we could examine the surface given by $z = x^2 + y^2$ and ask to compute its Gaussian curvature at a given point.\n\n## Step 5: Write the problem statement\nLet's define the problem: \"Let $S$ be the surface given by $z = x^2 + y^2$. Compute the Gaussian curvature $K$ of $S$ at the point $(1,1,2)$.\"\n\n## Step 6: Provide the solution\nTo solve this, we first need to parameterize the surface. The surface $S$ can be parameterized by $\\vec{r}(x,y) = (x, y, x^2 + y^2)$. The Gaussian curvature $K$ can be found using the formula $K = \\frac{LN - M^2}{EG - F^2}$, where $E, F, G$ are coefficients of the first fundamental form, and $L, M, N$ are coefficients of the second fundamental form.\n\n## Step 7: Calculate the first and second fundamental forms\nFirst, compute $\\vec{r}_x = (1, 0, 2x)$ and $\\vec{r}_y = (0, 1, 2y)$. Then, $E = \\vec{r}_x \\cdot \\vec{r}_x = 1 + 4x^2$, $F = \\vec{r}_x \\cdot \\vec{r}_y = 4xy$, and $G = \\vec{r}_y \\cdot \\vec{r}_y = 1 + 4y^2$. The normal vector $\\vec{n} = \\frac{\\vec{r}_x \\times \\vec{r}_y}{\\|\\vec{r}_x \\times \\vec{r}_y\\|}$, and $\\vec{r}_x \\times \\vec{r}_y = (-2x, -2y, 1)$, so $\\|\\vec{r}_x \\times \\vec{r}_y\\| = \\sqrt{4x^2 + 4y^2 + 1}$. Thus, $\\vec{n} = \\frac{1}{\\sqrt{4x^2 + 4y^2 + 1}}(-2x, -2y, 1)$.\n\n## Step 8: Continue with the calculation of $L, M, N$\n$L = \\vec{r}_{xx} \\cdot \\vec{n}$, $M = \\vec{r}_{xy} \\cdot \\vec{n}$, and $N = \\vec{r}_{yy} \\cdot \\vec{n}$. We have $\\vec{r}_{xx} = (0, 0, 2)$, $\\vec{r}_{xy} = (0, 0, 0)$, and $\\vec{r}_{yy} = (0, 0, 2)$. So, $L = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}}$, $M = 0$, and $N = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}}$.\n\n## Step 9: Evaluate $K$ at $(1,1,2)$\nAt $(1,1,2)$, $x = 1$, $y = 1$, so $E = 5$, $F = 4$, $G = 5$, $L = \\frac{2}{3}$, $M = 0$, and $N = \\frac{2}{3}$. Thus, $EG - F^2 = 25 - 16 = 9$ and $LN - M^2 = \\frac{4}{9}$.\n\n## Step 10: Calculate $K$\n$K = \\frac{LN - M^2}{EG - F^2} = \\frac{\\frac{4}{9}}{9} = \\frac{4}{81}$.\n\nThe final answer is: \n\nLet $S$ be the surface given by $z = x^2 + y^2$. Compute the Gaussian curvature $K$ of $S$ at the point $(1,1,2)$.",
    "run_id": "37",
    "outer_attempt": 1,
    "topic_slug": "differential_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe compute the Gaussian curvature $K$ of the surface $S$ defined by $z = x^2 + y^2$ at the point $(1,1,2)$.\n\n**1. Parameterization.**  \nLet $\\mathbf{r}(x,y) = (x,\\; y,\\; x^2 + y^2)$ be a parametrization of $S$.\n\n**2. First fundamental form.**  \nFirst partial derivatives:  \n$$\n\\mathbf{r}_x = (1,\\,0,\\,2x),\\qquad \\mathbf{r}_y = (0,\\,1,\\,2y).\n$$  \nCoefficients:  \n$$\n\\begin{aligned}\nE &= \\mathbf{r}_x\\cdot\\mathbf{r}_x = 1 + 4x^2,\\$$2pt]\nF &= \\mathbf{r}_x\\cdot\\mathbf{r}_y = 4xy,\\$$2pt]\nG &= \\mathbf{r}_y\\cdot\\mathbf{r}_y = 1 + 4y^2.\n\\end{aligned}\n$$\n\n**3. Unit normal vector.**  \n$$\n\\mathbf{r}_x \\times \\mathbf{r}_y = \\begin{vmatrix}\n\\mathbf{i} & \\mathbf{j} & \\mathbf{k}\\\\\n1 & 0 & 2x\\\\\n0 & 1 & 2y\n\\end{vmatrix} = (-2x,\\,-2y,\\,1).\n$$  \nIts magnitude is $\\|\\mathbf{r}_x \\times \\mathbf{r}_y\\| = \\sqrt{4x^2 + 4y^2 + 1}$.  \nHence  \n$$\n\\mathbf{n} = \\frac{(-2x,\\,-2y,\\,1)}{\\sqrt{4x^2 + 4y^2 + 1}}.\n$$\n\n**4. Second fundamental form.**  \nSecond partial derivatives:  \n$$\n\\mathbf{r}_{xx} = (0,0,2),\\quad \\mathbf{r}_{xy} = (0,0,0),\\quad \\mathbf{r}_{yy} = (0,0,2).\n$$  \nCoefficients:  \n$$\n\\begin{aligned}\nL &= \\mathbf{r}_{xx}\\cdot\\mathbf{n} = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}},\\$$2pt]\nM &= \\mathbf{r}_{xy}\\cdot\\mathbf{n} = 0,\\$$2pt]\nN &= \\mathbf{r}_{yy}\\cdot\\mathbf{n} = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}}.\n\\end{aligned}\n$$\n\n**5. Gaussian curvature.**  \nThe Gaussian curvature is given by  \n$$\nK = \\frac{LN - M^2}{EG - F^2}.\n$$  \nCompute the denominator:  \n$$\nEG - F^2 = (1+4x^2)(1+4y^2) - (4xy)^2 = 1 + 4x^2 + 4y^2.\n$$  \nCompute the numerator:  \n$$\nLN - M^2 = \\left(\\frac{2}{\\sqrt{1+4(x^2+y^2)}}\\right)^2 - 0 = \\frac{4}{1+4(x^2+y^2)}.\n$$  \nThus  \n$$\nK = \\frac{4}{1+4(x^2+y^2)} \\Big/ \\bigl(1+4(x^2+y^2)\\bigr) = \\frac{4}{\\bigl(1+4(x^2+y^2)\\bigr)^2}.\n$$\n\n**6. Evaluation at $(1,1,2)$.**  \nThe point has coordinates $x=1$, $y=1$ (and indeed $z=1^2+1^2=2$). Then  \n$$\nx^2+y^2 = 2 \\quad\\Longrightarrow\\quad 1+4(x^2+y^2) = 1+8 = 9.\n$$  \nTherefore  \n$$\nK = \\frac{4}{9^2} = \\frac{4}{81}.\n$$\n\n**Conclusion.**  \nThe Gaussian curvature of the surface $S$ at the point $(1,1,2)$ is  \n\n$$\n\\boxed{\\dfrac{4}{81}}.\n$$",
        "raw_answer": "**Solution**\n\nWe compute the Gaussian curvature \\(K\\) of the surface \\(S\\) defined by \\(z = x^2 + y^2\\) at the point \\((1,1,2)\\).\n\n**1. Parameterization.**  \nLet \\(\\mathbf{r}(x,y) = (x,\\; y,\\; x^2 + y^2)\\) be a parametrization of \\(S\\).\n\n**2. First fundamental form.**  \nFirst partial derivatives:  \n\\[\n\\mathbf{r}_x = (1,\\,0,\\,2x),\\qquad \\mathbf{r}_y = (0,\\,1,\\,2y).\n\\]  \nCoefficients:  \n\\[\n\\begin{aligned}\nE &= \\mathbf{r}_x\\cdot\\mathbf{r}_x = 1 + 4x^2,\\\\[2pt]\nF &= \\mathbf{r}_x\\cdot\\mathbf{r}_y = 4xy,\\\\[2pt]\nG &= \\mathbf{r}_y\\cdot\\mathbf{r}_y = 1 + 4y^2.\n\\end{aligned}\n\\]\n\n**3. Unit normal vector.**  \n\\[\n\\mathbf{r}_x \\times \\mathbf{r}_y = \\begin{vmatrix}\n\\mathbf{i} & \\mathbf{j} & \\mathbf{k}\\\\\n1 & 0 & 2x\\\\\n0 & 1 & 2y\n\\end{vmatrix} = (-2x,\\,-2y,\\,1).\n\\]  \nIts magnitude is \\(\\|\\mathbf{r}_x \\times \\mathbf{r}_y\\| = \\sqrt{4x^2 + 4y^2 + 1}\\).  \nHence  \n\\[\n\\mathbf{n} = \\frac{(-2x,\\,-2y,\\,1)}{\\sqrt{4x^2 + 4y^2 + 1}}.\n\\]\n\n**4. Second fundamental form.**  \nSecond partial derivatives:  \n\\[\n\\mathbf{r}_{xx} = (0,0,2),\\quad \\mathbf{r}_{xy} = (0,0,0),\\quad \\mathbf{r}_{yy} = (0,0,2).\n\\]  \nCoefficients:  \n\\[\n\\begin{aligned}\nL &= \\mathbf{r}_{xx}\\cdot\\mathbf{n} = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}},\\\\[2pt]\nM &= \\mathbf{r}_{xy}\\cdot\\mathbf{n} = 0,\\\\[2pt]\nN &= \\mathbf{r}_{yy}\\cdot\\mathbf{n} = \\frac{2}{\\sqrt{4x^2 + 4y^2 + 1}}.\n\\end{aligned}\n\\]\n\n**5. Gaussian curvature.**  \nThe Gaussian curvature is given by  \n\\[\nK = \\frac{LN - M^2}{EG - F^2}.\n\\]  \nCompute the denominator:  \n\\[\nEG - F^2 = (1+4x^2)(1+4y^2) - (4xy)^2 = 1 + 4x^2 + 4y^2.\n\\]  \nCompute the numerator:  \n\\[\nLN - M^2 = \\left(\\frac{2}{\\sqrt{1+4(x^2+y^2)}}\\right)^2 - 0 = \\frac{4}{1+4(x^2+y^2)}.\n\\]  \nThus  \n\\[\nK = \\frac{4}{1+4(x^2+y^2)} \\Big/ \\bigl(1+4(x^2+y^2)\\bigr) = \\frac{4}{\\bigl(1+4(x^2+y^2)\\bigr)^2}.\n\\]\n\n**6. Evaluation at \\((1,1,2)\\).**  \nThe point has coordinates \\(x=1\\), \\(y=1\\) (and indeed \\(z=1^2+1^2=2\\)). Then  \n\\[\nx^2+y^2 = 2 \\quad\\Longrightarrow\\quad 1+4(x^2+y^2) = 1+8 = 9.\n\\]  \nTherefore  \n\\[\nK = \\frac{4}{9^2} = \\frac{4}{81}.\n\\]\n\n**Conclusion.**  \nThe Gaussian curvature of the surface \\(S\\) at the point \\((1,1,2)\\) is  \n\n\\[\n\\boxed{\\dfrac{4}{81}}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of general topology, along with a complete solution, following specific guidelines.\n[/QUESTION]",
    "run_id": "38",
    "outer_attempt": 1,
    "topic_slug": "general_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Problem.**  \nDefine the *Sorgenfrey line* $\\mathbb{R}_\\ell$ as the topological space on $\\mathbb{R}$ whose basis consists of all half\u2011open intervals $[a,b)$ with $a<b$.  \nProve that $\\mathbb{R}_\\ell$ is a normal topological space, but the product space $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ (the *Sorgenfrey plane*) is not normal.\n\n---\n\n**Solution.**\n\n### 1. Normality of $\\mathbb{R}_\\ell$\n\nWe first establish that $\\mathbb{R}_\\ell$ is $T_1$, regular, and Lindel\u00f6f; then a general lemma shows that every regular Lindel\u00f6f space is normal.\n\n---\n\n**Lemma 1.** $\\mathbb{R}_\\ell$ is $T_1$.\n\n*Proof.* For any $x\\in\\mathbb{R}$, the complement $\\mathbb{R}\\setminus\\{x\\}=(-\\infty,x)\\cup[x,\\infty)$ is open: $(-\\infty,x)=\\bigcup_{n=1}^{\\infty}[x-n,x)$ and $[x,\\infty)=\\bigcup_{n=1}^{\\infty}[x,x+n)$ are unions of basic open sets. Hence $\\{x\\}$ is closed. \u220e\n\n---\n\n**Lemma 2.** $\\mathbb{R}_\\ell$ is regular.\n\n*Proof.* Let $x\\in\\mathbb{R}_\\ell$ and let $C\\subseteq\\mathbb{R}_\\ell$ be closed with $x\\notin C$. Then $U=\\mathbb{R}_\\ell\\setminus C$ is open and contains $x$, so there exists $\\varepsilon>0$ such that $[x,x+\\varepsilon)\\subseteq U$. The set $[x,x+\\varepsilon)$ is both open (by definition) and closed (its complement $(-\\infty,x)\\cup[x+\\varepsilon,\\infty)$ is a union of basic open sets). Set $V=\\mathbb{R}_\\ell\\setminus[x,x+\\varepsilon)$, which is open. Then $x\\in[x,x+\\varepsilon)$, $C\\subseteq V$, and $[x,x+\\varepsilon)\\cap V=\\varnothing$. Thus $\\mathbb{R}_\\ell$ is regular. \u220e\n\n---\n\n**Lemma 3.** $\\mathbb{R}_\\ell$ is Lindel\u00f6f.\n\n*Proof.* Let $\\mathcal{U}$ be an open cover of $\\mathbb{R}_\\ell$. For each $x\\in\\mathbb{R}$ choose $U_x\\in\\mathcal{U}$ and $\\varepsilon_x>0$ with $[x,x+\\varepsilon_x)\\subseteq U_x$. Consider the family of ordinary open intervals $\\mathcal{I}=\\{(x,x+\\varepsilon_x):x\\in\\mathbb{R}\\}$ in the usual topology on $\\mathbb{R}$. Let $V=\\bigcup_{x\\in\\mathbb{R}}(x,x+\\varepsilon_x)$ and $K=\\mathbb{R}\\setminus V$.\n\n*$K$ is countable.* For each $y\\in K$, the interval $(y,y+\\varepsilon_y)$ is non\u2011empty. If $y_1,y_2\\in K$ with $y_1<y_2$ and $(y_1,y_1+\\varepsilon_{y_1})\\cap(y_2,y_2+\\varepsilon_{y_2})\\neq\\varnothing$, pick $z$ in the intersection. Then $y_1<z<y_1+\\varepsilon_{y_1}$ and $y_2<z<y_2+\\varepsilon_{y_2}$, so $y_2\\in(y_1,y_1+\\varepsilon_{y_1})$, contradicting $y_2\\in K$ (since $y_2$ would then belong to some $(x,x+\\varepsilon_x)$). Hence the intervals $\\{(y,y+\\varepsilon_y):y\\in K\\}$ are pairwise disjoint. Each contains a rational number; choosing one rational per interval gives an injection $K\\hookrightarrow\\mathbb{Q}$, so $K$ is countable.\n\n*Cover $V$ by a countable subfamily.* $V$ is open in the usual topology, and $\\mathcal{I}$ is an open cover of $V$. The usual topology on $\\mathbb{R}$ is second countable, hence Lindel\u00f6f, so there exists a countable set $X\\subseteq\\mathbb{R}$ such that $V\\subseteq\\bigcup_{x\\in X}(x,x+\\varepsilon_x)$. Then the corresponding $U_x$ (for $x\\in X$) together with the $U_y$ for $y\\in K$ form a countable subcover of $\\mathcal{U}$. Indeed, every point of $V$ lies in some $(x,x+\\varepsilon_x)$ with $x\\in X$, hence also in $[x,x+\\varepsilon_x)\\subseteq U_x$; every point of $K$ is covered by its own $U_y$. Therefore $\\mathbb{R}_\\ell$ is Lindel\u00f6f. \u220e\n\n---\n\n**Lemma 4.** Every regular Lindel\u00f6f space is normal.\n\n*Proof.* Let $X$ be regular and Lindel\u00f6f, and let $A,B\\subseteq X$ be disjoint closed sets. For each $a\\in A$ choose an open neighbourhood $U_a$ of $a$ with $\\overline{U_a}\\cap B=\\varnothing$ (regularity gives disjoint neighbourhoods of $a$ and $B$; take the one containing $a$ and note that its closure stays away from $B$ because the neighbourhood of $B$ is open). Similarly, for each $b\\in B$ choose an open $V_b$ with $\\overline{V_b}\\cap A=\\varnothing$. The families $\\{U_a\\}_{a\\in A}$ and $\\{V_b\\}_{b\\in B}$ cover $A$ and $B$, respectively. Since closed subsets of a Lindel\u00f6f space are Lindel\u00f6f, $A$ and $B$ are Lindel\u00f6f, so we can extract countable subcovers $\\{U_n\\}_{n\\in\\mathbb{N}}$ of $A$ and $\\{V_n\\}_{n\\in\\mathbb{N}}$ of $B$, still satisfying $\\overline{U_n}\\cap B=\\varnothing$, $\\overline{V_n}\\cap A=\\varnothing$.\n\nDefine\n$$\nU_n' = U_n \\setminus \\bigcup_{i=1}^{n} \\overline{V_i},\\qquad\nV_n' = V_n \\setminus \\bigcup_{i=1}^{n} \\overline{U_i},\n$$\nand set $U=\\bigcup_n U_n'$, $V=\\bigcup_n V_n'$. Each $U_n'$, $V_n'$ is open (difference of an open set and a closed set). If $a\\in A$, let $n$ be the smallest index with $a\\in U_n$; then $a\\notin\\bigcup_{i=1}^{n}\\overline{V_i}$ (because $\\overline{V_i}\\cap A=\\varnothing$), so $a\\in U_n'\\subseteq U$. Hence $A\\subseteq U$. Similarly $B\\subseteq V$.\n\nSuppose $x\\in U\\cap V$. Then $x\\in U_n'$ for some $n$ and $x\\in V_m'$ for some $m$. Assume $n\\le m$ (the other case is symmetric). Then $x\\in U_n\\subseteq\\overline{U_n}$, but $V_m'$ is disjoint from $\\bigcup_{i=1}^{m}\\overline{U_i}$, which contains $\\overline{U_n}$ because $n\\le m$. Thus $x\\notin V_m'$, contradiction. Therefore $U\\cap V=\\varnothing$, and $X$ is normal. \u220e\n\nCombining Lemmas 1\u20134, $\\mathbb{R}_\\ell$ is normal (and $T_1$, hence $T_4$).\n\n---\n\n### 2. Non\u2011normality of $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$\n\nFirst, note that the product of $T_1$ spaces is $T_1$, so $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is $T_1$.\n\n---\n\n**Lemma 5.** $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is separable.\n\n*Proof.* $\\mathbb{Q}\\times\\mathbb{Q}$ is countable. Any basic open set in the product has the form $[a,b)\\times[c,d)$. Since $\\mathbb{Q}$ is dense in $\\mathbb{R}$ (in the usual topology, hence also in $\\mathbb{R}_\\ell$ because the Sorgenfrey topology is finer), there exist $q_1\\in(a,b)$ and $q_2\\in(c,d)$. Then $(q_1,q_2)\\in[a,b)\\times[c,d)$. Thus $\\mathbb{Q}\\times\\mathbb{Q}$ meets every nonempty basic open set, so it is dense. \u220e\n\n---\n\n**Lemma 6.** The set $L=\\{(x,-x):x\\in\\mathbb{R}\\}$ is an uncountable closed discrete subspace of $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$.\n\n*Proof.* The map $x\\mapsto(x,-x)$ is a bijection onto $\\mathbb{R}$, so $|L|=\\mathfrak{c}=2^{\\aleph_0}$.\n\n*Closed.* The Euclidean topology on $\\mathbb{R}^2$ is coarser than the Sorgenfrey plane topology: every Euclidean open set is open in $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ because a Euclidean ball around a point contains a product of half\u2011open intervals. Hence every Euclidean closed set is also closed in the finer topology. $L$ is closed in the Euclidean plane (it is the zero set of the continuous function $(x,y)\\mapsto x+y$), so $L$ is closed in $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$.\n\n*Discrete.* For $(x,-x)\\in L$, the basic open set $[x,x+1)\\times[-x,-x+1)$ intersects $L$ only in $\\{(x,-x)\\}$: if $(t,-t)\\in L$ also lies in this product, then $t\\in[x,x+1)$ and $-t\\in[-x,-x+1)$. The second condition gives $-x\\le -t<-x+1$, i.e., $x\\ge t>x-1$. Together with $t\\ge x$ we obtain $t=x$. Hence $\\{(x,-x)\\}$ is open in the subspace topology, so $L$ is discrete. \u220e\n\n---\n\n**Lemma 7 (Jones\u2019 Lemma).** Let $X$ be a normal topological space, $D\\subseteq X$ a dense subset, and $S\\subseteq X$ a closed discrete subspace. Then $2^{|S|}\\le 2^{|D|}$.\n\n*Proof.* For each $T\\subseteq S$, the sets $T$ and $S\\setminus T$ are disjoint and closed in $X$ (every subset of a closed discrete subspace is closed). By normality there exist disjoint open sets $U_T,V_T$ with $T\\subseteq U_T$, $S\\setminus T\\subseteq V_T$. Then $\\overline{U_T}\\subseteq X\\setminus V_T$, so $\\overline{U_T}\\cap(S\\setminus T)=\\varnothing$. Consequently $\\overline{U_T}\\cap S=T$.\n\nDefine $f:\\mathcal{P}(S)\\to\\mathcal{P}(D)$ by $f(T)=\\overline{U_T}\\cap D$. We show $f$ is injective. Suppose $T_1\\neq T_2$; without loss of generality, pick $s\\in T_1\\setminus T_2$. Then $s\\in\\overline{U_{T_1}}$ and $s\\in S\\setminus T_2\\subseteq V_{T_2}$. Because $\\overline{U_{T_2}}\\subseteq X\\setminus V_{T_2}$, we have $s\\notin\\overline{U_{T_2}}$. Thus $\\overline{U_{T_1}}\\neq\\overline{U_{T_2}}$. Since $D$ is dense, $\\overline{U_T}=\\overline{U_T\\cap D}$ for any $T$. If $f(T_1)=f(T_2)$, then $\\overline{U_{T_1}}\\cap D=\\overline{U_{T_2}}\\cap D$, and taking closures gives $\\overline{U_{T_1}}=\\overline{U_{T_2}}$, a contradiction. Hence $f$ is injective, yielding $|\\mathcal{P}(S)|\\le|\\mathcal{P}(D)|$, i.e., $2^{|S|}\\le 2^{|D|}$. \u220e\n\n---\n\n**Conclusion.** Assume, for contradiction, that $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is normal. Take $D=\\mathbb{Q}\\times\\mathbb{Q}$ (countable, $|D|=\\aleph_0$) and $S=L$ (with $|S|=\\mathfrak{c}$). By Jones\u2019 Lemma,\n$$\n2^{\\mathfrak{c}} \\le 2^{\\aleph_0} = \\mathfrak{c}.\n$$\nBut Cantor\u2019s theorem states $\\mathfrak{c}<2^{\\mathfrak{c}}$, a contradiction. Therefore $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ cannot be normal.\n\n---\n\nThus the Sorgenfrey line is normal, while the Sorgenfrey plane is not. \u220e",
        "raw_answer": "**Problem.**  \nDefine the *Sorgenfrey line* $\\mathbb{R}_\\ell$ as the topological space on $\\mathbb{R}$ whose basis consists of all half\u2011open intervals $[a,b)$ with $a<b$.  \nProve that $\\mathbb{R}_\\ell$ is a normal topological space, but the product space $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ (the *Sorgenfrey plane*) is not normal.\n\n---\n\n**Solution.**\n\n### 1. Normality of $\\mathbb{R}_\\ell$\n\nWe first establish that $\\mathbb{R}_\\ell$ is $T_1$, regular, and Lindel\u00f6f; then a general lemma shows that every regular Lindel\u00f6f space is normal.\n\n---\n\n**Lemma 1.** $\\mathbb{R}_\\ell$ is $T_1$.\n\n*Proof.* For any $x\\in\\mathbb{R}$, the complement $\\mathbb{R}\\setminus\\{x\\}=(-\\infty,x)\\cup[x,\\infty)$ is open: $(-\\infty,x)=\\bigcup_{n=1}^{\\infty}[x-n,x)$ and $[x,\\infty)=\\bigcup_{n=1}^{\\infty}[x,x+n)$ are unions of basic open sets. Hence $\\{x\\}$ is closed. \u220e\n\n---\n\n**Lemma 2.** $\\mathbb{R}_\\ell$ is regular.\n\n*Proof.* Let $x\\in\\mathbb{R}_\\ell$ and let $C\\subseteq\\mathbb{R}_\\ell$ be closed with $x\\notin C$. Then $U=\\mathbb{R}_\\ell\\setminus C$ is open and contains $x$, so there exists $\\varepsilon>0$ such that $[x,x+\\varepsilon)\\subseteq U$. The set $[x,x+\\varepsilon)$ is both open (by definition) and closed (its complement $(-\\infty,x)\\cup[x+\\varepsilon,\\infty)$ is a union of basic open sets). Set $V=\\mathbb{R}_\\ell\\setminus[x,x+\\varepsilon)$, which is open. Then $x\\in[x,x+\\varepsilon)$, $C\\subseteq V$, and $[x,x+\\varepsilon)\\cap V=\\varnothing$. Thus $\\mathbb{R}_\\ell$ is regular. \u220e\n\n---\n\n**Lemma 3.** $\\mathbb{R}_\\ell$ is Lindel\u00f6f.\n\n*Proof.* Let $\\mathcal{U}$ be an open cover of $\\mathbb{R}_\\ell$. For each $x\\in\\mathbb{R}$ choose $U_x\\in\\mathcal{U}$ and $\\varepsilon_x>0$ with $[x,x+\\varepsilon_x)\\subseteq U_x$. Consider the family of ordinary open intervals $\\mathcal{I}=\\{(x,x+\\varepsilon_x):x\\in\\mathbb{R}\\}$ in the usual topology on $\\mathbb{R}$. Let $V=\\bigcup_{x\\in\\mathbb{R}}(x,x+\\varepsilon_x)$ and $K=\\mathbb{R}\\setminus V$.\n\n*$K$ is countable.* For each $y\\in K$, the interval $(y,y+\\varepsilon_y)$ is non\u2011empty. If $y_1,y_2\\in K$ with $y_1<y_2$ and $(y_1,y_1+\\varepsilon_{y_1})\\cap(y_2,y_2+\\varepsilon_{y_2})\\neq\\varnothing$, pick $z$ in the intersection. Then $y_1<z<y_1+\\varepsilon_{y_1}$ and $y_2<z<y_2+\\varepsilon_{y_2}$, so $y_2\\in(y_1,y_1+\\varepsilon_{y_1})$, contradicting $y_2\\in K$ (since $y_2$ would then belong to some $(x,x+\\varepsilon_x)$). Hence the intervals $\\{(y,y+\\varepsilon_y):y\\in K\\}$ are pairwise disjoint. Each contains a rational number; choosing one rational per interval gives an injection $K\\hookrightarrow\\mathbb{Q}$, so $K$ is countable.\n\n*Cover $V$ by a countable subfamily.* $V$ is open in the usual topology, and $\\mathcal{I}$ is an open cover of $V$. The usual topology on $\\mathbb{R}$ is second countable, hence Lindel\u00f6f, so there exists a countable set $X\\subseteq\\mathbb{R}$ such that $V\\subseteq\\bigcup_{x\\in X}(x,x+\\varepsilon_x)$. Then the corresponding $U_x$ (for $x\\in X$) together with the $U_y$ for $y\\in K$ form a countable subcover of $\\mathcal{U}$. Indeed, every point of $V$ lies in some $(x,x+\\varepsilon_x)$ with $x\\in X$, hence also in $[x,x+\\varepsilon_x)\\subseteq U_x$; every point of $K$ is covered by its own $U_y$. Therefore $\\mathbb{R}_\\ell$ is Lindel\u00f6f. \u220e\n\n---\n\n**Lemma 4.** Every regular Lindel\u00f6f space is normal.\n\n*Proof.* Let $X$ be regular and Lindel\u00f6f, and let $A,B\\subseteq X$ be disjoint closed sets. For each $a\\in A$ choose an open neighbourhood $U_a$ of $a$ with $\\overline{U_a}\\cap B=\\varnothing$ (regularity gives disjoint neighbourhoods of $a$ and $B$; take the one containing $a$ and note that its closure stays away from $B$ because the neighbourhood of $B$ is open). Similarly, for each $b\\in B$ choose an open $V_b$ with $\\overline{V_b}\\cap A=\\varnothing$. The families $\\{U_a\\}_{a\\in A}$ and $\\{V_b\\}_{b\\in B}$ cover $A$ and $B$, respectively. Since closed subsets of a Lindel\u00f6f space are Lindel\u00f6f, $A$ and $B$ are Lindel\u00f6f, so we can extract countable subcovers $\\{U_n\\}_{n\\in\\mathbb{N}}$ of $A$ and $\\{V_n\\}_{n\\in\\mathbb{N}}$ of $B$, still satisfying $\\overline{U_n}\\cap B=\\varnothing$, $\\overline{V_n}\\cap A=\\varnothing$.\n\nDefine\n\\[\nU_n' = U_n \\setminus \\bigcup_{i=1}^{n} \\overline{V_i},\\qquad\nV_n' = V_n \\setminus \\bigcup_{i=1}^{n} \\overline{U_i},\n\\]\nand set $U=\\bigcup_n U_n'$, $V=\\bigcup_n V_n'$. Each $U_n'$, $V_n'$ is open (difference of an open set and a closed set). If $a\\in A$, let $n$ be the smallest index with $a\\in U_n$; then $a\\notin\\bigcup_{i=1}^{n}\\overline{V_i}$ (because $\\overline{V_i}\\cap A=\\varnothing$), so $a\\in U_n'\\subseteq U$. Hence $A\\subseteq U$. Similarly $B\\subseteq V$.\n\nSuppose $x\\in U\\cap V$. Then $x\\in U_n'$ for some $n$ and $x\\in V_m'$ for some $m$. Assume $n\\le m$ (the other case is symmetric). Then $x\\in U_n\\subseteq\\overline{U_n}$, but $V_m'$ is disjoint from $\\bigcup_{i=1}^{m}\\overline{U_i}$, which contains $\\overline{U_n}$ because $n\\le m$. Thus $x\\notin V_m'$, contradiction. Therefore $U\\cap V=\\varnothing$, and $X$ is normal. \u220e\n\nCombining Lemmas 1\u20134, $\\mathbb{R}_\\ell$ is normal (and $T_1$, hence $T_4$).\n\n---\n\n### 2. Non\u2011normality of $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$\n\nFirst, note that the product of $T_1$ spaces is $T_1$, so $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is $T_1$.\n\n---\n\n**Lemma 5.** $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is separable.\n\n*Proof.* $\\mathbb{Q}\\times\\mathbb{Q}$ is countable. Any basic open set in the product has the form $[a,b)\\times[c,d)$. Since $\\mathbb{Q}$ is dense in $\\mathbb{R}$ (in the usual topology, hence also in $\\mathbb{R}_\\ell$ because the Sorgenfrey topology is finer), there exist $q_1\\in(a,b)$ and $q_2\\in(c,d)$. Then $(q_1,q_2)\\in[a,b)\\times[c,d)$. Thus $\\mathbb{Q}\\times\\mathbb{Q}$ meets every nonempty basic open set, so it is dense. \u220e\n\n---\n\n**Lemma 6.** The set $L=\\{(x,-x):x\\in\\mathbb{R}\\}$ is an uncountable closed discrete subspace of $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$.\n\n*Proof.* The map $x\\mapsto(x,-x)$ is a bijection onto $\\mathbb{R}$, so $|L|=\\mathfrak{c}=2^{\\aleph_0}$.\n\n*Closed.* The Euclidean topology on $\\mathbb{R}^2$ is coarser than the Sorgenfrey plane topology: every Euclidean open set is open in $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ because a Euclidean ball around a point contains a product of half\u2011open intervals. Hence every Euclidean closed set is also closed in the finer topology. $L$ is closed in the Euclidean plane (it is the zero set of the continuous function $(x,y)\\mapsto x+y$), so $L$ is closed in $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$.\n\n*Discrete.* For $(x,-x)\\in L$, the basic open set $[x,x+1)\\times[-x,-x+1)$ intersects $L$ only in $\\{(x,-x)\\}$: if $(t,-t)\\in L$ also lies in this product, then $t\\in[x,x+1)$ and $-t\\in[-x,-x+1)$. The second condition gives $-x\\le -t<-x+1$, i.e., $x\\ge t>x-1$. Together with $t\\ge x$ we obtain $t=x$. Hence $\\{(x,-x)\\}$ is open in the subspace topology, so $L$ is discrete. \u220e\n\n---\n\n**Lemma 7 (Jones\u2019 Lemma).** Let $X$ be a normal topological space, $D\\subseteq X$ a dense subset, and $S\\subseteq X$ a closed discrete subspace. Then $2^{|S|}\\le 2^{|D|}$.\n\n*Proof.* For each $T\\subseteq S$, the sets $T$ and $S\\setminus T$ are disjoint and closed in $X$ (every subset of a closed discrete subspace is closed). By normality there exist disjoint open sets $U_T,V_T$ with $T\\subseteq U_T$, $S\\setminus T\\subseteq V_T$. Then $\\overline{U_T}\\subseteq X\\setminus V_T$, so $\\overline{U_T}\\cap(S\\setminus T)=\\varnothing$. Consequently $\\overline{U_T}\\cap S=T$.\n\nDefine $f:\\mathcal{P}(S)\\to\\mathcal{P}(D)$ by $f(T)=\\overline{U_T}\\cap D$. We show $f$ is injective. Suppose $T_1\\neq T_2$; without loss of generality, pick $s\\in T_1\\setminus T_2$. Then $s\\in\\overline{U_{T_1}}$ and $s\\in S\\setminus T_2\\subseteq V_{T_2}$. Because $\\overline{U_{T_2}}\\subseteq X\\setminus V_{T_2}$, we have $s\\notin\\overline{U_{T_2}}$. Thus $\\overline{U_{T_1}}\\neq\\overline{U_{T_2}}$. Since $D$ is dense, $\\overline{U_T}=\\overline{U_T\\cap D}$ for any $T$. If $f(T_1)=f(T_2)$, then $\\overline{U_{T_1}}\\cap D=\\overline{U_{T_2}}\\cap D$, and taking closures gives $\\overline{U_{T_1}}=\\overline{U_{T_2}}$, a contradiction. Hence $f$ is injective, yielding $|\\mathcal{P}(S)|\\le|\\mathcal{P}(D)|$, i.e., $2^{|S|}\\le 2^{|D|}$. \u220e\n\n---\n\n**Conclusion.** Assume, for contradiction, that $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ is normal. Take $D=\\mathbb{Q}\\times\\mathbb{Q}$ (countable, $|D|=\\aleph_0$) and $S=L$ (with $|S|=\\mathfrak{c}$). By Jones\u2019 Lemma,\n\\[\n2^{\\mathfrak{c}} \\le 2^{\\aleph_0} = \\mathfrak{c}.\n\\]\nBut Cantor\u2019s theorem states $\\mathfrak{c}<2^{\\mathfrak{c}}$, a contradiction. Therefore $\\mathbb{R}_\\ell\\times\\mathbb{R}_\\ell$ cannot be normal.\n\n---\n\nThus the Sorgenfrey line is normal, while the Sorgenfrey plane is not. \u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $X = S^1 \\vee S^1$ be the wedge sum of two circles, where the wedge point is $x_0$. Compute $\\pi_1(X, x_0)$.",
    "run_id": "39",
    "outer_attempt": 1,
    "topic_slug": "algebraic_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We wish to compute the fundamental group of the wedge sum $X = S^1 \\vee S^1$ with basepoint $x_0$ (the wedge point).  \nThe result is the free group on two generators: $\\pi_1(X, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} \\cong F_2$.\n\nWe prove this using the Seifert\u2013van Kampen theorem.\n\n---\n\n### 1. Geometric model\n\nRealise $X$ as the figure\u2011eight in $\\mathbb{R}^2$:  \n$$\nA = \\{(x,y) : (x+1)^2 + y^2 = 1\\},\\qquad \nB = \\{(x,y) : (x-1)^2 + y^2 = 1\\},\n$$  \nwith the two circles intersecting exactly at the origin $x_0 = (0,0)$.  \nThen $X = A \\cup B$ with the subspace topology inherited from $\\mathbb{R}^2$.\n\n---\n\n### 2. Choice of open sets\n\nPick a small $\\delta > 0$ (e.g. $\\delta = \\frac12$) and let  \n$$\nN = B_\\delta(x_0) \\cap X,\n$$  \nwhere $B_\\delta(x_0)$ is the open disc of radius $\\delta$ centred at $x_0$.  \n$N$ is open in $X$ and consists of two open arcs, one on each circle, meeting at $x_0$.\n\nDefine  \n$$\nU = A \\cup N,\\qquad V = B \\cup N.\n$$\n\nBoth $U$ and $V$ are open in $X$:\n\n- If $p \\in A \\setminus \\{x_0\\}$, the circles intersect only at $x_0$, so we can choose $\\varepsilon$ small enough that $B_\\varepsilon(p) \\cap B = \\varnothing$. Then $B_\\varepsilon(p) \\cap X \\subseteq A \\subseteq U$, hence $p$ is an interior point of $U$.\n- If $p = x_0$, then $N$ itself is an open neighbourhood of $x_0$ contained in $U$.\n- The argument for $V$ is symmetric.\n\nClearly $U$ and $V$ are path\u2011connected (each contains a circle plus a contractible \u201carm\u201d) and both contain the basepoint $x_0$. Moreover, $X = U \\cup V$ and $U \\cap V = N$.\n\n---\n\n### 3. Fundamental groups of $U$, $V$ and $U \\cap V$\n\n**Claim 1:** $U$ deformation retracts onto $A$.  \nDefine $H : U \\times [0,1] \\to U$ as follows.  \n\n- For a point $a \\in A$, set $H(a,t) = a$ for all $t$.  \n- For a point $q \\in N \\cap B$, parameterise the (unique) arc of $B$ from $q$ to $x_0$ that lies inside $N$ (this is possible because $N \\cap B$ is homeomorphic to an open interval). Slide $q$ along this arc linearly with respect to the arc length: let $\\gamma_q : [0,1] \\to N \\cap B$ be a continuous path with $\\gamma_q(0)=q$, $\\gamma_q(1)=x_0$ and $\\gamma_q(s)$ staying in $N \\cap B$ for $s<1$. Set $H(q,t) = \\gamma_q(t)$.  \n\nOn the overlap $A \\cap N = \\{x_0\\}$ the definition is consistent because $H(x_0,t)=x_0$. The map $H$ is continuous (by the pasting lemma and because the retraction is defined separately on the closed sets $A$ and $\\overline{N \\cap B}$, which cover $U$).  \nThus $U \\simeq A$ and in particular $\\pi_1(U, x_0) \\cong \\pi_1(A, x_0) \\cong \\mathbb{Z}$.  \nA generator is the homotopy class of the loop that goes once around $A$ (the left circle).\n\n**Claim 2:** Similarly, $V$ deformation retracts onto $B$, so $\\pi_1(V, x_0) \\cong \\pi_1(B, x_0) \\cong \\mathbb{Z}$.  \nA generator is the homotopy class of the loop that goes once around $B$ (the right circle).\n\n**Claim 3:** $N = U \\cap V$ is contractible.  \n$N$ is the union of two open arcs meeting at $x_0$. Each arc can be linearly retracted to $x_0$ along itself; doing this simultaneously on both arcs gives a deformation retraction of $N$ onto $\\{x_0\\}$. Hence $N$ is simply connected: $\\pi_1(N, x_0) = 1$.\n\n---\n\n### 4. Application of the Seifert\u2013van Kampen theorem\n\nThe theorem states: if $X = U \\cup V$ with $U,V$ open, path\u2011connected, and $U \\cap V$ path\u2011connected, all containing the basepoint $x_0$, then  \n$$\n\\pi_1(X, x_0) \\cong \\pi_1(U, x_0) *_{\\pi_1(U \\cap V, x_0)} \\pi_1(V, x_0),\n$$  \ni.e. the amalgamated free product over $\\pi_1(U \\cap V, x_0)$.\n\nBecause $\\pi_1(U \\cap V, x_0) = 1$, the amalgamation is trivial and we obtain the free product:  \n$$\n\\pi_1(X, x_0) \\cong \\pi_1(U, x_0) * \\pi_1(V, x_0) \\cong \\mathbb{Z} * \\mathbb{Z}.\n$$\n\nThe free product $\\mathbb{Z} * \\mathbb{Z}$ is the free group on two generators.  \nConcretely, if $a$ denotes the loop around the left circle and $b$ the loop around the right circle, every element of $\\pi_1(X, x_0)$ can be written uniquely as a reduced word in $a, b, a^{-1}, b^{-1}$.\n\n---\n\n### 5. Conclusion\n\n$$\n\\boxed{\\pi_1(S^1 \\vee S^1, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} \\cong F_2}\n$$  \nwhere $F_2$ denotes the free group on two generators.",
        "raw_answer": "We wish to compute the fundamental group of the wedge sum \\(X = S^1 \\vee S^1\\) with basepoint \\(x_0\\) (the wedge point).  \nThe result is the free group on two generators: \\(\\pi_1(X, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} \\cong F_2\\).\n\nWe prove this using the Seifert\u2013van Kampen theorem.\n\n---\n\n### 1. Geometric model\n\nRealise \\(X\\) as the figure\u2011eight in \\(\\mathbb{R}^2\\):  \n\\[\nA = \\{(x,y) : (x+1)^2 + y^2 = 1\\},\\qquad \nB = \\{(x,y) : (x-1)^2 + y^2 = 1\\},\n\\]  \nwith the two circles intersecting exactly at the origin \\(x_0 = (0,0)\\).  \nThen \\(X = A \\cup B\\) with the subspace topology inherited from \\(\\mathbb{R}^2\\).\n\n---\n\n### 2. Choice of open sets\n\nPick a small \\(\\delta > 0\\) (e.g. \\(\\delta = \\frac12\\)) and let  \n\\[\nN = B_\\delta(x_0) \\cap X,\n\\]  \nwhere \\(B_\\delta(x_0)\\) is the open disc of radius \\(\\delta\\) centred at \\(x_0\\).  \n\\(N\\) is open in \\(X\\) and consists of two open arcs, one on each circle, meeting at \\(x_0\\).\n\nDefine  \n\\[\nU = A \\cup N,\\qquad V = B \\cup N.\n\\]\n\nBoth \\(U\\) and \\(V\\) are open in \\(X\\):\n\n- If \\(p \\in A \\setminus \\{x_0\\}\\), the circles intersect only at \\(x_0\\), so we can choose \\(\\varepsilon\\) small enough that \\(B_\\varepsilon(p) \\cap B = \\varnothing\\). Then \\(B_\\varepsilon(p) \\cap X \\subseteq A \\subseteq U\\), hence \\(p\\) is an interior point of \\(U\\).\n- If \\(p = x_0\\), then \\(N\\) itself is an open neighbourhood of \\(x_0\\) contained in \\(U\\).\n- The argument for \\(V\\) is symmetric.\n\nClearly \\(U\\) and \\(V\\) are path\u2011connected (each contains a circle plus a contractible \u201carm\u201d) and both contain the basepoint \\(x_0\\). Moreover, \\(X = U \\cup V\\) and \\(U \\cap V = N\\).\n\n---\n\n### 3. Fundamental groups of \\(U\\), \\(V\\) and \\(U \\cap V\\)\n\n**Claim 1:** \\(U\\) deformation retracts onto \\(A\\).  \nDefine \\(H : U \\times [0,1] \\to U\\) as follows.  \n\n- For a point \\(a \\in A\\), set \\(H(a,t) = a\\) for all \\(t\\).  \n- For a point \\(q \\in N \\cap B\\), parameterise the (unique) arc of \\(B\\) from \\(q\\) to \\(x_0\\) that lies inside \\(N\\) (this is possible because \\(N \\cap B\\) is homeomorphic to an open interval). Slide \\(q\\) along this arc linearly with respect to the arc length: let \\(\\gamma_q : [0,1] \\to N \\cap B\\) be a continuous path with \\(\\gamma_q(0)=q\\), \\(\\gamma_q(1)=x_0\\) and \\(\\gamma_q(s)\\) staying in \\(N \\cap B\\) for \\(s<1\\). Set \\(H(q,t) = \\gamma_q(t)\\).  \n\nOn the overlap \\(A \\cap N = \\{x_0\\}\\) the definition is consistent because \\(H(x_0,t)=x_0\\). The map \\(H\\) is continuous (by the pasting lemma and because the retraction is defined separately on the closed sets \\(A\\) and \\(\\overline{N \\cap B}\\), which cover \\(U\\)).  \nThus \\(U \\simeq A\\) and in particular \\(\\pi_1(U, x_0) \\cong \\pi_1(A, x_0) \\cong \\mathbb{Z}\\).  \nA generator is the homotopy class of the loop that goes once around \\(A\\) (the left circle).\n\n**Claim 2:** Similarly, \\(V\\) deformation retracts onto \\(B\\), so \\(\\pi_1(V, x_0) \\cong \\pi_1(B, x_0) \\cong \\mathbb{Z}\\).  \nA generator is the homotopy class of the loop that goes once around \\(B\\) (the right circle).\n\n**Claim 3:** \\(N = U \\cap V\\) is contractible.  \n\\(N\\) is the union of two open arcs meeting at \\(x_0\\). Each arc can be linearly retracted to \\(x_0\\) along itself; doing this simultaneously on both arcs gives a deformation retraction of \\(N\\) onto \\(\\{x_0\\}\\). Hence \\(N\\) is simply connected: \\(\\pi_1(N, x_0) = 1\\).\n\n---\n\n### 4. Application of the Seifert\u2013van Kampen theorem\n\nThe theorem states: if \\(X = U \\cup V\\) with \\(U,V\\) open, path\u2011connected, and \\(U \\cap V\\) path\u2011connected, all containing the basepoint \\(x_0\\), then  \n\\[\n\\pi_1(X, x_0) \\cong \\pi_1(U, x_0) *_{\\pi_1(U \\cap V, x_0)} \\pi_1(V, x_0),\n\\]  \ni.e. the amalgamated free product over \\(\\pi_1(U \\cap V, x_0)\\).\n\nBecause \\(\\pi_1(U \\cap V, x_0) = 1\\), the amalgamation is trivial and we obtain the free product:  \n\\[\n\\pi_1(X, x_0) \\cong \\pi_1(U, x_0) * \\pi_1(V, x_0) \\cong \\mathbb{Z} * \\mathbb{Z}.\n\\]\n\nThe free product \\(\\mathbb{Z} * \\mathbb{Z}\\) is the free group on two generators.  \nConcretely, if \\(a\\) denotes the loop around the left circle and \\(b\\) the loop around the right circle, every element of \\(\\pi_1(X, x_0)\\) can be written uniquely as a reduced word in \\(a, b, a^{-1}, b^{-1}\\).\n\n---\n\n### 5. Conclusion\n\n\\[\n\\boxed{\\pi_1(S^1 \\vee S^1, x_0) \\cong \\mathbb{Z} * \\mathbb{Z} \\cong F_2}\n\\]  \nwhere \\(F_2\\) denotes the free group on two generators.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Manifolds and cell complexes\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within the domain\nA suitable topic within \"Manifolds and cell complexes\" could involve the properties or constructions related to manifolds or cell complexes, such as their topology, geometry, or algebraic invariants.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the Euler characteristic of a manifold, which is a fundamental concept in algebraic topology that relates to both manifolds and cell complexes. The Euler characteristic is a topological invariant that can be computed using a cell decomposition of a manifold.\n\n## Step 4: Construct the problem statement\nConsider a 2-dimensional manifold $M$ that is homeomorphic to a sphere with $g$ handles (i.e., a surface of genus $g$). The task is to prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.\n\n## Step 5: Provide the problem statement in the required format\n\nLet $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles. Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.",
    "run_id": "40",
    "outer_attempt": 1,
    "topic_slug": "manifolds_and_cell_complexes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove that the Euler characteristic of a closed orientable surface of genus $g$ (a sphere with $g$ handles) is $2-2g$. The Euler characteristic $\\chi(M)$ of a compact surface $M$ is defined as $\\chi(M)=V-E+F$ for any finite cell decomposition (or triangulation) of $M$ into $V$ vertices, $E$ edges, and $F$ faces. It is a topological invariant: homeomorphic surfaces have the same Euler characteristic.\n\nWe construct an explicit cell decomposition for the surface $\\Sigma_g$ of genus $g$ (including $g=0$) and compute its Euler characteristic.\n\n---\n\n### 1. The case $g=0$\n\nThe sphere $S^2$ is homeomorphic to a sphere with $0$ handles. A simple CW\u2011structure consists of one $0$-cell (a point) and one $2$-cell attached via the constant map (collapsing the boundary of the disk to the $0$-cell). This yields $V=1$, $E=0$, $F=1$, hence $\\chi(S^2)=1-0+1=2$, which agrees with $2-2\\cdot0=2$.\n\n---\n\n### 2. The case $g\\ge 1$\n\nConsider a $4g$-sided polygon $P$ (a topological disk). Label its sides consecutively as\n$$\na_1,\\; b_1,\\; a_1^{-1},\\; b_1^{-1},\\; a_2,\\; b_2,\\; a_2^{-1},\\; b_2^{-1},\\;\\dots,\\; a_g,\\; b_g,\\; a_g^{-1},\\; b_g^{-1},\n$$\nwhere the notation indicates that sides with the same letter are to be identified, but with opposite orientations. More precisely, for each $i=1,\\dots,g$, side $a_i$ is identified with side $a_i^{-1}$ by a homeomorphism that reverses the direction (so that the head of $a_i$ is glued to the tail of $a_i^{-1}$, etc.), and similarly for $b_i$ and $b_i^{-1}$. The identifications are performed in the standard pattern that yields an orientable surface.\n\nAfter all identifications, we obtain a quotient space $\\Sigma_g$. It is a classical fact (easily verified) that $\\Sigma_g$ is a compact, connected, orientable surface of genus $g$. Let us briefly check the local Euclidean structure:\n\n* **Interior points of $P$:** a small open disk inside $P$ remains unchanged and is a neighbourhood homeomorphic to $\\mathbb{R}^2$.\n* **Points on the interior of a side:** a small half\u2011disk on each side of the side in $P$ is glued to a half\u2011disk from the paired side; together they form a full open disk.\n* **The unique vertex:** all $4g$ vertices of $P$ are identified to a single point. Take a small neighbourhood of each vertex in $P$ consisting of a small sector of the polygon. Under the identification, these sectors are arranged cyclically around the point; because the gluing pattern follows the cyclic order $a_1b_1a_1^{-1}b_1^{-1}\\cdots a_gb_ga_g^{-1}b_g^{-1}$, the sectors combine to form a single open disk (the total angle sums to $2\\pi$ after a suitable smoothing, which is always possible topologically).\n\nThus $\\Sigma_g$ is indeed a topological $2$-manifold without boundary.\n\n---\n\n### 3. Cell count\n\nWe view the quotient $\\Sigma_g$ as a CW complex:\n\n* The **$2$-cell** is the interior of the polygon $P$ (or $P$ itself).\n* The **$1$-cells** are the images of the sides after identification. Each pair $(a_i, a_i^{-1})$ gives one $1$-cell; similarly each pair $(b_i, b_i^{-1})$ gives one $1$-cell. Hence there are $2g$ distinct $1$-cells.\n* The **$0$-cells** are the images of the vertices. All $4g$ vertices of $P$ are identified to a single point, so there is exactly one $0$-cell.\n\nTherefore,\n$$\nV = 1,\\qquad E = 2g,\\qquad F = 1.\n$$\n\n---\n\n### 4. Euler characteristic\n\nUsing the definition $\\chi = V - E + F$ we obtain\n$$\n\\chi(\\Sigma_g) = 1 - 2g + 1 = 2 - 2g.\n$$\n\n---\n\n### 5. General case\n\nLet $M$ be any $2$-dimensional manifold homeomorphic to a sphere with $g$ handles. Then $M$ is homeomorphic to $\\Sigma_g$. Since the Euler characteristic is a topological invariant,\n$$\n\\chi(M) = \\chi(\\Sigma_g) = 2 - 2g.\n$$\n\n---\n\n### 6. Conclusion\n\nWe have shown that for every integer $g\\ge 0$, the Euler characteristic of a closed orientable surface of genus $g$ is $2-2g$. In particular, for a sphere with $g$ handles, $\\chi(M)=2-2g$. $\\square$",
        "raw_answer": "We prove that the Euler characteristic of a closed orientable surface of genus \\(g\\) (a sphere with \\(g\\) handles) is \\(2-2g\\). The Euler characteristic \\(\\chi(M)\\) of a compact surface \\(M\\) is defined as \\(\\chi(M)=V-E+F\\) for any finite cell decomposition (or triangulation) of \\(M\\) into \\(V\\) vertices, \\(E\\) edges, and \\(F\\) faces. It is a topological invariant: homeomorphic surfaces have the same Euler characteristic.\n\nWe construct an explicit cell decomposition for the surface \\(\\Sigma_g\\) of genus \\(g\\) (including \\(g=0\\)) and compute its Euler characteristic.\n\n---\n\n### 1. The case \\(g=0\\)\n\nThe sphere \\(S^2\\) is homeomorphic to a sphere with \\(0\\) handles. A simple CW\u2011structure consists of one \\(0\\)-cell (a point) and one \\(2\\)-cell attached via the constant map (collapsing the boundary of the disk to the \\(0\\)-cell). This yields \\(V=1\\), \\(E=0\\), \\(F=1\\), hence \\(\\chi(S^2)=1-0+1=2\\), which agrees with \\(2-2\\cdot0=2\\).\n\n---\n\n### 2. The case \\(g\\ge 1\\)\n\nConsider a \\(4g\\)-sided polygon \\(P\\) (a topological disk). Label its sides consecutively as\n\\[\na_1,\\; b_1,\\; a_1^{-1},\\; b_1^{-1},\\; a_2,\\; b_2,\\; a_2^{-1},\\; b_2^{-1},\\;\\dots,\\; a_g,\\; b_g,\\; a_g^{-1},\\; b_g^{-1},\n\\]\nwhere the notation indicates that sides with the same letter are to be identified, but with opposite orientations. More precisely, for each \\(i=1,\\dots,g\\), side \\(a_i\\) is identified with side \\(a_i^{-1}\\) by a homeomorphism that reverses the direction (so that the head of \\(a_i\\) is glued to the tail of \\(a_i^{-1}\\), etc.), and similarly for \\(b_i\\) and \\(b_i^{-1}\\). The identifications are performed in the standard pattern that yields an orientable surface.\n\nAfter all identifications, we obtain a quotient space \\(\\Sigma_g\\). It is a classical fact (easily verified) that \\(\\Sigma_g\\) is a compact, connected, orientable surface of genus \\(g\\). Let us briefly check the local Euclidean structure:\n\n* **Interior points of \\(P\\):** a small open disk inside \\(P\\) remains unchanged and is a neighbourhood homeomorphic to \\(\\mathbb{R}^2\\).\n* **Points on the interior of a side:** a small half\u2011disk on each side of the side in \\(P\\) is glued to a half\u2011disk from the paired side; together they form a full open disk.\n* **The unique vertex:** all \\(4g\\) vertices of \\(P\\) are identified to a single point. Take a small neighbourhood of each vertex in \\(P\\) consisting of a small sector of the polygon. Under the identification, these sectors are arranged cyclically around the point; because the gluing pattern follows the cyclic order \\(a_1b_1a_1^{-1}b_1^{-1}\\cdots a_gb_ga_g^{-1}b_g^{-1}\\), the sectors combine to form a single open disk (the total angle sums to \\(2\\pi\\) after a suitable smoothing, which is always possible topologically).\n\nThus \\(\\Sigma_g\\) is indeed a topological \\(2\\)-manifold without boundary.\n\n---\n\n### 3. Cell count\n\nWe view the quotient \\(\\Sigma_g\\) as a CW complex:\n\n* The **\\(2\\)-cell** is the interior of the polygon \\(P\\) (or \\(P\\) itself).\n* The **\\(1\\)-cells** are the images of the sides after identification. Each pair \\((a_i, a_i^{-1})\\) gives one \\(1\\)-cell; similarly each pair \\((b_i, b_i^{-1})\\) gives one \\(1\\)-cell. Hence there are \\(2g\\) distinct \\(1\\)-cells.\n* The **\\(0\\)-cells** are the images of the vertices. All \\(4g\\) vertices of \\(P\\) are identified to a single point, so there is exactly one \\(0\\)-cell.\n\nTherefore,\n\\[\nV = 1,\\qquad E = 2g,\\qquad F = 1.\n\\]\n\n---\n\n### 4. Euler characteristic\n\nUsing the definition \\(\\chi = V - E + F\\) we obtain\n\\[\n\\chi(\\Sigma_g) = 1 - 2g + 1 = 2 - 2g.\n\\]\n\n---\n\n### 5. General case\n\nLet \\(M\\) be any \\(2\\)-dimensional manifold homeomorphic to a sphere with \\(g\\) handles. Then \\(M\\) is homeomorphic to \\(\\Sigma_g\\). Since the Euler characteristic is a topological invariant,\n\\[\n\\chi(M) = \\chi(\\Sigma_g) = 2 - 2g.\n\\]\n\n---\n\n### 6. Conclusion\n\nWe have shown that for every integer \\(g\\ge 0\\), the Euler characteristic of a closed orientable surface of genus \\(g\\) is \\(2-2g\\). In particular, for a sphere with \\(g\\) handles, \\(\\chi(M)=2-2g\\). \\(\\square\\)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Global analysis, analysis on manifolds\" along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify key concepts in the domain\nGlobal analysis and analysis on manifolds involve the study of geometric and topological properties of manifolds using analytical techniques. Key concepts include differential forms, integration on manifolds, Stokes' theorem, and the study of differential equations on manifolds.\n\n## Step 3: Formulate a problem\nTo create a problem, we need to identify a specific concept or technique within global analysis or analysis on manifolds that can be used to formulate a challenging yet solvable question. One such concept is the application of Stokes' theorem, which relates the integral of a differential form over a manifold to the integral of its exterior derivative over the boundary of the manifold.\n\n## Step 4: Construct the problem\nLet's consider a specific manifold and a differential form. A common example is the unit sphere $S^2$ in $\\mathbb{R}^3$. We can formulate a problem involving the integration of a differential form over $S^2$ and applying Stokes' theorem.\n\n## Step 5: Specify the problem\nLet $\\omega = y \\, dx \\wedge dz$ be a 2-form on $\\mathbb{R}^3$. Consider the unit sphere $S^2 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 = 1 \\}$ oriented with the outward unit normal. Evaluate $\\int_{S^2} \\omega$.\n\n## Step 6: Provide the solution\nTo solve this, we can directly integrate $\\omega$ over $S^2$ or apply Stokes' theorem. Stokes' theorem states that $\\int_M d\\omega = \\int_{\\partial M} \\omega$, where $M$ is a manifold with boundary $\\partial M$. Here, we can consider $M = B^3 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 \\leq 1 \\}$, so $\\partial M = S^2$.\n\n## Step 7: Calculate $d\\omega$\n$d\\omega = d(y \\, dx \\wedge dz) = dy \\wedge dx \\wedge dz = -dx \\wedge dy \\wedge dz$ because $d(y) = dy$, $d(dx) = 0$, and $d(dz) = 0$. So, $d\\omega = -dx \\wedge dy \\wedge dz$.\n\n## Step 8: Apply Stokes' theorem\n$\\int_{S^2} \\omega = \\int_{B^3} d\\omega = \\int_{B^3} -dx \\wedge dy \\wedge dz = -\\int_{B^3} dV$, where $dV = dx \\wedge dy \\wedge dz$ is the volume form on $\\mathbb{R}^3$. Thus, $\\int_{S^2} \\omega = -\\text{Vol}(B^3)$.\n\n## Step 9: Calculate the volume of $B^3$\nThe volume of the unit ball $B^3$ is given by $\\frac{4}{3}\\pi(1)^3 = \\frac{4}{3}\\pi$.\n\n## Step 10: Conclude the solution\n$\\int_{S^2} \\omega = -\\frac{4}{3}\\pi$.\n\nThe final answer is: \n\nLet $\\omega = y \\, dx \\wedge dz$ be a 2-form on $\\mathbb{R}^3$. Consider the unit sphere $S^2 = \\{ (x, y, z) \\in \\mathbb{R}^3 : x^2 + y^2 + z^2 = 1 \\}$ oriented with the outward unit normal. Evaluate $\\int_{S^2} \\omega$.",
    "run_id": "41",
    "outer_attempt": 1,
    "topic_slug": "global_analysis_on_manifolds",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked to evaluate the integral of the 2\u2011form $\\omega = y\\,dx\\wedge dz$ over the unit sphere  \n$S^2 = \\{(x,y,z)\\in\\mathbb{R}^3 : x^2+y^2+z^2=1\\}$ oriented by the outward unit normal.\n\nWe will use the generalised Stokes theorem.  \nLet $B = \\{(x,y,z)\\in\\mathbb{R}^3 : x^2+y^2+z^2\\le 1\\}$ be the closed unit ball, equipped with the standard orientation given by the volume form $dx\\wedge dy\\wedge dz$.  \nThe boundary $\\partial B$ is $S^2$. The induced orientation on $\\partial B$ is precisely the orientation defined by the outward unit normal (i.e., a basis $(v_1,v_2)$ of the tangent space to $S^2$ is positively oriented if $(n_{\\text{out}}, v_1, v_2)$ is a positively oriented basis of $\\mathbb{R}^3$).  \nSince $\\omega$ is a smooth 2\u2011form on $\\mathbb{R}^3$, Stokes\u2019 theorem applies:\n\n$$\n\\int_{S^2} \\omega = \\int_{B} d\\omega.\n$$\n\nNow compute the exterior derivative of $\\omega$:\n\n$$\nd\\omega = d(y\\,dx\\wedge dz) = dy \\wedge dx \\wedge dz + y\\,d(dx\\wedge dz).\n$$\n\nBecause $d(dx)=0$ and $d(dz)=0$, the second term vanishes. Hence\n\n$$\nd\\omega = dy \\wedge dx \\wedge dz.\n$$\n\nRecall that the standard volume form on $\\mathbb{R}^3$ is $dx\\wedge dy\\wedge dz$.  \nInterchanging the first two factors gives $dy\\wedge dx\\wedge dz = -\\,dx\\wedge dy\\wedge dz$. Therefore\n\n$$\nd\\omega = -\\,dx\\wedge dy\\wedge dz.\n$$\n\nThus\n\n$$\n\\int_{B} d\\omega = \\int_{B} (-\\,dx\\wedge dy\\wedge dz) = -\\int_{B} dx\\wedge dy\\wedge dz.\n$$\n\nThe integral of the volume form over $B$ is simply the volume of the unit ball:\n\n$$\n\\int_{B} dx\\wedge dy\\wedge dz = \\operatorname{Vol}(B) = \\frac{4}{3}\\pi.\n$$\n\nConsequently,\n\n$$\n\\int_{S^2} \\omega = -\\frac{4}{3}\\pi.\n$$\n\n**Answer:** $\\displaystyle \\int_{S^2} \\omega = -\\frac{4\\pi}{3}.$",
        "raw_answer": "We are asked to evaluate the integral of the 2\u2011form \\(\\omega = y\\,dx\\wedge dz\\) over the unit sphere  \n\\(S^2 = \\{(x,y,z)\\in\\mathbb{R}^3 : x^2+y^2+z^2=1\\}\\) oriented by the outward unit normal.\n\nWe will use the generalised Stokes theorem.  \nLet \\(B = \\{(x,y,z)\\in\\mathbb{R}^3 : x^2+y^2+z^2\\le 1\\}\\) be the closed unit ball, equipped with the standard orientation given by the volume form \\(dx\\wedge dy\\wedge dz\\).  \nThe boundary \\(\\partial B\\) is \\(S^2\\). The induced orientation on \\(\\partial B\\) is precisely the orientation defined by the outward unit normal (i.e., a basis \\((v_1,v_2)\\) of the tangent space to \\(S^2\\) is positively oriented if \\((n_{\\text{out}}, v_1, v_2)\\) is a positively oriented basis of \\(\\mathbb{R}^3\\)).  \nSince \\(\\omega\\) is a smooth 2\u2011form on \\(\\mathbb{R}^3\\), Stokes\u2019 theorem applies:\n\n\\[\n\\int_{S^2} \\omega = \\int_{B} d\\omega.\n\\]\n\nNow compute the exterior derivative of \\(\\omega\\):\n\n\\[\nd\\omega = d(y\\,dx\\wedge dz) = dy \\wedge dx \\wedge dz + y\\,d(dx\\wedge dz).\n\\]\n\nBecause \\(d(dx)=0\\) and \\(d(dz)=0\\), the second term vanishes. Hence\n\n\\[\nd\\omega = dy \\wedge dx \\wedge dz.\n\\]\n\nRecall that the standard volume form on \\(\\mathbb{R}^3\\) is \\(dx\\wedge dy\\wedge dz\\).  \nInterchanging the first two factors gives \\(dy\\wedge dx\\wedge dz = -\\,dx\\wedge dy\\wedge dz\\). Therefore\n\n\\[\nd\\omega = -\\,dx\\wedge dy\\wedge dz.\n\\]\n\nThus\n\n\\[\n\\int_{B} d\\omega = \\int_{B} (-\\,dx\\wedge dy\\wedge dz) = -\\int_{B} dx\\wedge dy\\wedge dz.\n\\]\n\nThe integral of the volume form over \\(B\\) is simply the volume of the unit ball:\n\n\\[\n\\int_{B} dx\\wedge dy\\wedge dz = \\operatorname{Vol}(B) = \\frac{4}{3}\\pi.\n\\]\n\nConsequently,\n\n\\[\n\\int_{S^2} \\omega = -\\frac{4}{3}\\pi.\n\\]\n\n**Answer:** \\(\\displaystyle \\int_{S^2} \\omega = -\\frac{4\\pi}{3}.\\)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $X$ and $Y$ be independent random variables with $X \\sim \\text{Exp}(\\lambda)$ and $Y \\sim \\text{Exp}(\\mu)$, where $\\lambda > 0$ and $\\mu > 0$ are the rate parameters. Define $Z = \\min(X, Y)$. Derive the probability density function (pdf) of $Z$ and compute $\\mathbb{E}[Z]$.",
    "run_id": "42",
    "outer_attempt": 1,
    "topic_slug": "probability_theory_and_stochastic_processes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are given independent random variables $X \\sim \\text{Exp}(\\lambda)$ and $Y \\sim \\text{Exp}(\\mu)$ with rate parameters $\\lambda>0$, $\\mu>0$. Define $Z = \\min(X,Y)$. We derive the probability density function (pdf) of $Z$ and compute $\\mathbb{E}[Z]$.\n\nRecall that for an exponential random variable with rate $\\lambda$, the pdf is $f_X(x) = \\lambda e^{-\\lambda x}$ for $x \\ge 0$, and the survival function is $P(X > t) = e^{-\\lambda t}$ for $t \\ge 0$.\n\n### Step 1: Survival function of $Z$\n\nFor any $t \\ge 0$,\n$$\nP(Z > t) = P(\\min(X,Y) > t) = P(X > t \\text{ and } Y > t).\n$$\nSince $X$ and $Y$ are independent,\n$$\nP(Z > t) = P(X > t) \\, P(Y > t) = e^{-\\lambda t} e^{-\\mu t} = e^{-(\\lambda+\\mu) t}.\n$$\nFor $t < 0$, $P(Z > t) = 1$ because $Z$ is non\u2011negative, but the survival function is usually considered for all real $t$; we will handle the distribution function accordingly.\n\n### Step 2: Cumulative distribution function (CDF) of $Z$\n\nThe CDF $F_Z(t) = P(Z \\le t) = 1 - P(Z > t)$. Hence for $t \\ge 0$,\n$$\nF_Z(t) = 1 - e^{-(\\lambda+\\mu) t},\n$$\nand for $t < 0$, $F_Z(t) = 0$.\n\n### Step 3: Probability density function (pdf) of $Z$\n\nDifferentiate the CDF with respect to $t$ (for $t>0$; at $t=0$ the derivative can be defined in the almost\u2011everywhere sense). For $t \\ge 0$,\n$$\nf_Z(t) = \\frac{d}{dt} F_Z(t) = (\\lambda+\\mu) e^{-(\\lambda+\\mu) t}.\n$$\nFor $t < 0$, $f_Z(t) = 0$. Thus\n$$\n\\boxed{f_Z(z) = (\\lambda+\\mu) e^{-(\\lambda+\\mu) z} \\quad \\text{for } z \\ge 0,\\quad \\text{and } 0 \\text{ otherwise}.}\n$$\n\nThis shows that $Z$ itself follows an exponential distribution with rate $\\lambda+\\mu$.\n\n### Step 4: Expectation of $Z$\n\nThe expectation can be computed either by integrating against the pdf or by using the survival function.\n\n**Method 1 (using the pdf):**\n$$\n\\mathbb{E}[Z] = \\int_{0}^{\\infty} t \\, f_Z(t) \\, dt = (\\lambda+\\mu) \\int_{0}^{\\infty} t \\, e^{-(\\lambda+\\mu) t} \\, dt.\n$$\nThe integral $\\int_{0}^{\\infty} t e^{-a t} dt = \\frac{1}{a^2}$ for $a>0$. With $a = \\lambda+\\mu$,\n$$\n\\mathbb{E}[Z] = (\\lambda+\\mu) \\cdot \\frac{1}{(\\lambda+\\mu)^2} = \\frac{1}{\\lambda+\\mu}.\n$$\n\n**Method 2 (using the survival function):** For a non\u2011negative random variable,\n$$\n\\mathbb{E}[Z] = \\int_{0}^{\\infty} P(Z > t) \\, dt = \\int_{0}^{\\infty} e^{-(\\lambda+\\mu) t} \\, dt = \\frac{1}{\\lambda+\\mu}.\n$$\n\nThus,\n$$\n\\boxed{\\mathbb{E}[Z] = \\frac{1}{\\lambda+\\mu}}.\n$$\n\n### Verification and completeness\n\nWe have derived the pdf explicitly and computed the expectation. The derivation used only the independence and the known survival functions of exponential distributions. The result holds for all $\\lambda>0$, $\\mu>0$. The solution is complete.",
        "raw_answer": "We are given independent random variables $X \\sim \\text{Exp}(\\lambda)$ and $Y \\sim \\text{Exp}(\\mu)$ with rate parameters $\\lambda>0$, $\\mu>0$. Define $Z = \\min(X,Y)$. We derive the probability density function (pdf) of $Z$ and compute $\\mathbb{E}[Z]$.\n\nRecall that for an exponential random variable with rate $\\lambda$, the pdf is $f_X(x) = \\lambda e^{-\\lambda x}$ for $x \\ge 0$, and the survival function is $P(X > t) = e^{-\\lambda t}$ for $t \\ge 0$.\n\n### Step 1: Survival function of $Z$\n\nFor any $t \\ge 0$,\n\\[\nP(Z > t) = P(\\min(X,Y) > t) = P(X > t \\text{ and } Y > t).\n\\]\nSince $X$ and $Y$ are independent,\n\\[\nP(Z > t) = P(X > t) \\, P(Y > t) = e^{-\\lambda t} e^{-\\mu t} = e^{-(\\lambda+\\mu) t}.\n\\]\nFor $t < 0$, $P(Z > t) = 1$ because $Z$ is non\u2011negative, but the survival function is usually considered for all real $t$; we will handle the distribution function accordingly.\n\n### Step 2: Cumulative distribution function (CDF) of $Z$\n\nThe CDF $F_Z(t) = P(Z \\le t) = 1 - P(Z > t)$. Hence for $t \\ge 0$,\n\\[\nF_Z(t) = 1 - e^{-(\\lambda+\\mu) t},\n\\]\nand for $t < 0$, $F_Z(t) = 0$.\n\n### Step 3: Probability density function (pdf) of $Z$\n\nDifferentiate the CDF with respect to $t$ (for $t>0$; at $t=0$ the derivative can be defined in the almost\u2011everywhere sense). For $t \\ge 0$,\n\\[\nf_Z(t) = \\frac{d}{dt} F_Z(t) = (\\lambda+\\mu) e^{-(\\lambda+\\mu) t}.\n\\]\nFor $t < 0$, $f_Z(t) = 0$. Thus\n\\[\n\\boxed{f_Z(z) = (\\lambda+\\mu) e^{-(\\lambda+\\mu) z} \\quad \\text{for } z \\ge 0,\\quad \\text{and } 0 \\text{ otherwise}.}\n\\]\n\nThis shows that $Z$ itself follows an exponential distribution with rate $\\lambda+\\mu$.\n\n### Step 4: Expectation of $Z$\n\nThe expectation can be computed either by integrating against the pdf or by using the survival function.\n\n**Method 1 (using the pdf):**\n\\[\n\\mathbb{E}[Z] = \\int_{0}^{\\infty} t \\, f_Z(t) \\, dt = (\\lambda+\\mu) \\int_{0}^{\\infty} t \\, e^{-(\\lambda+\\mu) t} \\, dt.\n\\]\nThe integral $\\int_{0}^{\\infty} t e^{-a t} dt = \\frac{1}{a^2}$ for $a>0$. With $a = \\lambda+\\mu$,\n\\[\n\\mathbb{E}[Z] = (\\lambda+\\mu) \\cdot \\frac{1}{(\\lambda+\\mu)^2} = \\frac{1}{\\lambda+\\mu}.\n\\]\n\n**Method 2 (using the survival function):** For a non\u2011negative random variable,\n\\[\n\\mathbb{E}[Z] = \\int_{0}^{\\infty} P(Z > t) \\, dt = \\int_{0}^{\\infty} e^{-(\\lambda+\\mu) t} \\, dt = \\frac{1}{\\lambda+\\mu}.\n\\]\n\nThus,\n\\[\n\\boxed{\\mathbb{E}[Z] = \\frac{1}{\\lambda+\\mu}}.\n\\]\n\n### Verification and completeness\n\nWe have derived the pdf explicitly and computed the expectation. The derivation used only the independence and the known survival functions of exponential distributions. The result holds for all $\\lambda>0$, $\\mu>0$. The solution is complete.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $X$ and $Y$ be independent random variables with $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ and $Y \\sim \\mathcal{N}(0, 1)$, where $\\mu \\in \\mathbb{R}$ and $\\sigma > 0$ are unknown parameters. Suppose we have a sample of $n$ independent observations from $X$ and $m$ independent observations from $Y$, denoted as $x_1, x_2, \\ldots, x_n$ and $y_1, y_2, \\ldots, y_m$, respectively. Derive the likelihood ratio test statistic for testing $H_0: \\mu = 0, \\sigma = 1$ against $H_1: \\mu \\neq 0 \\text{ or } \\sigma \\neq 1$.",
    "run_id": "43",
    "outer_attempt": 1,
    "topic_slug": "statistics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are given two independent samples: $x_1,\\dots,x_n$ from $X\\sim\\mathcal{N}(\\mu,\\sigma^2)$ and $y_1,\\dots,y_m$ from $Y\\sim\\mathcal{N}(0,1)$, with $\\mu,\\sigma$ unknown. We test $H_0:\\mu=0,\\sigma=1$ against $H_1:\\mu\\neq0$ or $\\sigma\\neq1$. The likelihood ratio test statistic is derived as follows.\n\n### Joint likelihood\nThe joint likelihood for the parameters $(\\mu,\\sigma)$ is\n$$\nL(\\mu,\\sigma)=\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\!\\left(-\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right)\\;\\cdot\\;\\prod_{j=1}^m\\frac{1}{\\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{y_j^2}{2}\\right).\n$$\nThe factor for the $y$'s does not depend on $(\\mu,\\sigma)$; it is the same under $H_0$ and $H_1$. Hence it cancels in the likelihood ratio.\n\n### Restricted (null) likelihood\nUnder $H_0$, $\\mu=0,\\sigma=1$, so the contribution from the $x$\u2011sample is\n$$\nL_0 = L_X(0,1) = (2\\pi)^{-n/2}\\exp\\!\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right).\n$$\n\n### Unrestricted (alternative) likelihood\nUnder $H_1$ we maximise $L_X(\\mu,\\sigma)$ over $\\mu\\in\\mathbb{R},\\sigma>0$. The MLEs based on the $x$\u2011sample are\n$$\n\\hat\\mu = \\bar x = \\frac1n\\sum_{i=1}^n x_i,\\qquad\n\\hat\\sigma^2 = \\frac1n\\sum_{i=1}^n (x_i-\\bar x)^2.\n$$\nPlugging these into the $x$\u2011likelihood gives\n$$\n\\sup_{\\mu,\\sigma}L_X(\\mu,\\sigma)=L_X(\\hat\\mu,\\hat\\sigma)=(2\\pi\\hat\\sigma^2)^{-n/2}\\exp\\!\\left(-\\frac{1}{2\\hat\\sigma^2}\\sum_{i=1}^n (x_i-\\bar x)^2\\right)\n=(2\\pi\\hat\\sigma^2)^{-n/2}\\exp\\!\\left(-\\frac{n}{2}\\right),\n$$\nbecause $\\sum_{i=1}^n (x_i-\\bar x)^2 = n\\hat\\sigma^2$.\n\n### Likelihood ratio\n$$\n\\lambda = \\frac{L_0}{\\sup L_X} = \\frac{(2\\pi)^{-n/2}\\exp\\!\\left(-\\frac{1}{2}\\sum x_i^2\\right)}{(2\\pi\\hat\\sigma^2)^{-n/2}\\exp\\!\\left(-\\frac{n}{2}\\right)}\n= (\\hat\\sigma^2)^{n/2}\\exp\\!\\left(-\\frac{1}{2}\\Bigl(\\sum x_i^2 - n\\Bigr)\\right).\n$$\nNow $\\sum x_i^2 = \\sum (x_i-\\bar x)^2 + n\\bar x^2 = n\\hat\\sigma^2 + n\\bar x^2$, so\n$$\n\\sum x_i^2 - n = n(\\hat\\sigma^2 + \\bar x^2 - 1).\n$$\nThus\n$$\n\\lambda = (\\hat\\sigma^2)^{n/2}\\exp\\!\\left(-\\frac{n}{2}\\bigl(\\hat\\sigma^2 + \\bar x^2 - 1\\bigr)\\right).\n$$\n\n### Test statistic\nThe likelihood ratio test statistic is usually taken as $-2\\log\\lambda$:\n$$\n\\Lambda = -2\\log\\lambda = -2\\Bigl[\\frac{n}{2}\\log\\hat\\sigma^2 - \\frac{n}{2}\\bigl(\\hat\\sigma^2 + \\bar x^2 - 1\\bigr)\\Bigr]\n= n\\Bigl(\\hat\\sigma^2 + \\bar x^2 - 1 - \\log\\hat\\sigma^2\\Bigr).\n$$\n\nTherefore, the likelihood ratio test statistic is\n$$\n\\boxed{\\Lambda = n\\left(\\hat\\sigma^2 + \\bar x^2 - 1 - \\log\\hat\\sigma^2\\right)},\\qquad\n\\text{with }\\ \\hat\\sigma^2 = \\frac1n\\sum_{i=1}^n (x_i-\\bar x)^2,\\ \\ \\bar x = \\frac1n\\sum_{i=1}^n x_i.\n$$\n\n**Remarks.** The $y$\u2011sample does not appear in $\\Lambda$ because its density is identical under both hypotheses. Under $H_0$, as $n\\to\\infty$, $\\Lambda$ converges in distribution to a $\\chi^2_2$ random variable (Wilks\u2019 theorem). For finite $n$, the exact distribution depends only on $n$ and can be simulated.",
        "raw_answer": "We are given two independent samples: $x_1,\\dots,x_n$ from $X\\sim\\mathcal{N}(\\mu,\\sigma^2)$ and $y_1,\\dots,y_m$ from $Y\\sim\\mathcal{N}(0,1)$, with $\\mu,\\sigma$ unknown. We test $H_0:\\mu=0,\\sigma=1$ against $H_1:\\mu\\neq0$ or $\\sigma\\neq1$. The likelihood ratio test statistic is derived as follows.\n\n### Joint likelihood\nThe joint likelihood for the parameters $(\\mu,\\sigma)$ is\n\\[\nL(\\mu,\\sigma)=\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\!\\left(-\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right)\\;\\cdot\\;\\prod_{j=1}^m\\frac{1}{\\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{y_j^2}{2}\\right).\n\\]\nThe factor for the $y$'s does not depend on $(\\mu,\\sigma)$; it is the same under $H_0$ and $H_1$. Hence it cancels in the likelihood ratio.\n\n### Restricted (null) likelihood\nUnder $H_0$, $\\mu=0,\\sigma=1$, so the contribution from the $x$\u2011sample is\n\\[\nL_0 = L_X(0,1) = (2\\pi)^{-n/2}\\exp\\!\\left(-\\frac{1}{2}\\sum_{i=1}^n x_i^2\\right).\n\\]\n\n### Unrestricted (alternative) likelihood\nUnder $H_1$ we maximise $L_X(\\mu,\\sigma)$ over $\\mu\\in\\mathbb{R},\\sigma>0$. The MLEs based on the $x$\u2011sample are\n\\[\n\\hat\\mu = \\bar x = \\frac1n\\sum_{i=1}^n x_i,\\qquad\n\\hat\\sigma^2 = \\frac1n\\sum_{i=1}^n (x_i-\\bar x)^2.\n\\]\nPlugging these into the $x$\u2011likelihood gives\n\\[\n\\sup_{\\mu,\\sigma}L_X(\\mu,\\sigma)=L_X(\\hat\\mu,\\hat\\sigma)=(2\\pi\\hat\\sigma^2)^{-n/2}\\exp\\!\\left(-\\frac{1}{2\\hat\\sigma^2}\\sum_{i=1}^n (x_i-\\bar x)^2\\right)\n=(2\\pi\\hat\\sigma^2)^{-n/2}\\exp\\!\\left(-\\frac{n}{2}\\right),\n\\]\nbecause $\\sum_{i=1}^n (x_i-\\bar x)^2 = n\\hat\\sigma^2$.\n\n### Likelihood ratio\n\\[\n\\lambda = \\frac{L_0}{\\sup L_X} = \\frac{(2\\pi)^{-n/2}\\exp\\!\\left(-\\frac{1}{2}\\sum x_i^2\\right)}{(2\\pi\\hat\\sigma^2)^{-n/2}\\exp\\!\\left(-\\frac{n}{2}\\right)}\n= (\\hat\\sigma^2)^{n/2}\\exp\\!\\left(-\\frac{1}{2}\\Bigl(\\sum x_i^2 - n\\Bigr)\\right).\n\\]\nNow $\\sum x_i^2 = \\sum (x_i-\\bar x)^2 + n\\bar x^2 = n\\hat\\sigma^2 + n\\bar x^2$, so\n\\[\n\\sum x_i^2 - n = n(\\hat\\sigma^2 + \\bar x^2 - 1).\n\\]\nThus\n\\[\n\\lambda = (\\hat\\sigma^2)^{n/2}\\exp\\!\\left(-\\frac{n}{2}\\bigl(\\hat\\sigma^2 + \\bar x^2 - 1\\bigr)\\right).\n\\]\n\n### Test statistic\nThe likelihood ratio test statistic is usually taken as $-2\\log\\lambda$:\n\\[\n\\Lambda = -2\\log\\lambda = -2\\Bigl[\\frac{n}{2}\\log\\hat\\sigma^2 - \\frac{n}{2}\\bigl(\\hat\\sigma^2 + \\bar x^2 - 1\\bigr)\\Bigr]\n= n\\Bigl(\\hat\\sigma^2 + \\bar x^2 - 1 - \\log\\hat\\sigma^2\\Bigr).\n\\]\n\nTherefore, the likelihood ratio test statistic is\n\\[\n\\boxed{\\Lambda = n\\left(\\hat\\sigma^2 + \\bar x^2 - 1 - \\log\\hat\\sigma^2\\right)},\\qquad\n\\text{with }\\ \\hat\\sigma^2 = \\frac1n\\sum_{i=1}^n (x_i-\\bar x)^2,\\ \\ \\bar x = \\frac1n\\sum_{i=1}^n x_i.\n\\]\n\n**Remarks.** The $y$\u2011sample does not appear in $\\Lambda$ because its density is identical under both hypotheses. Under $H_0$, as $n\\to\\infty$, $\\Lambda$ converges in distribution to a $\\chi^2_2$ random variable (Wilks\u2019 theorem). For finite $n$, the exact distribution depends only on $n$ and can be simulated.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Consider the function $f(x) = e^x - 2x - 1$. We want to approximate the root of $f(x)$ in the interval $[0,1]$ using the Newton-Raphson method. Starting with $x_0 = 1$, perform two iterations of the Newton-Raphson method to find $x_2$. Provide the exact value of $x_2$.",
    "run_id": "44",
    "outer_attempt": 1,
    "topic_slug": "numerical_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution**\n\nWe are given $f(x) = e^x - 2x - 1$ and its derivative $f'(x) = e^x - 2$.  \nThe Newton\u2013Raphson iteration formula is  \n\n$$\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}.\n$$\n\nWe start with $x_0 = 1$.\n\n---\n\n**First iteration ($x_1$):**\n\n$$\nf(1) = e^1 - 2\\cdot 1 - 1 = e - 3, \\qquad f'(1) = e - 2.\n$$\n\n$$\nx_1 = 1 - \\frac{e-3}{e-2} = \\frac{(e-2) - (e-3)}{e-2} = \\frac{1}{e-2}.\n$$\n\nThus  \n\n$$\nx_1 = \\frac{1}{e-2}.\n$$\n\n(Note that $e-2 > 0$, so the division is valid.)\n\n---\n\n**Second iteration ($x_2$):**\n\nLet $a = x_1 = \\dfrac{1}{e-2}$. Then  \n\n$$\nf(a) = e^{a} - 2a - 1, \\qquad f'(a) = e^{a} - 2.\n$$\n\n$$\nx_2 = a - \\frac{f(a)}{f'(a)} = a - \\frac{e^{a} - 2a - 1}{e^{a} - 2}.\n$$\n\nSimplify the expression:\n\n$$\nx_2 = \\frac{a(e^{a} - 2) - (e^{a} - 2a - 1)}{e^{a} - 2}\n   = \\frac{a e^{a} - 2a - e^{a} + 2a + 1}{e^{a} - 2}\n   = \\frac{e^{a}(a - 1) + 1}{e^{a} - 2}.\n$$\n\nNow substitute back $a = \\dfrac{1}{e-2}$:\n\n$$\nx_2 = \\frac{ e^{\\frac{1}{e-2}} \\left( \\frac{1}{e-2} - 1 \\right) + 1 }{ e^{\\frac{1}{e-2}} - 2 }.\n$$\n\nThe term in parentheses can be rewritten as  \n\n$$\n\\frac{1}{e-2} - 1 = \\frac{1 - (e-2)}{e-2} = \\frac{3 - e}{e-2},\n$$\n\ngiving an alternative exact form:\n\n$$\nx_2 = \\frac{ e^{\\frac{1}{e-2}} \\cdot \\frac{3-e}{e-2} + 1 }{ e^{\\frac{1}{e-2}} - 2 }.\n$$\n\nAll these expressions are equivalent and represent the **exact value** of $x_2$ after two Newton\u2013Raphson iterations.\n\n(We note that $e^{a} - 2 \\neq 0$ because $a \\approx 1.392 > \\ln 2$, so the iteration is well\u2011defined.)\n\n---\n\n**Final answer:**\n\n$$\n\\boxed{ x_2 = \\frac{ e^{\\frac{1}{e-2}} \\left( \\frac{1}{e-2} - 1 \\right) + 1 }{ e^{\\frac{1}{e-2}} - 2 } }\n$$",
        "raw_answer": "**Solution**\n\nWe are given \\(f(x) = e^x - 2x - 1\\) and its derivative \\(f'(x) = e^x - 2\\).  \nThe Newton\u2013Raphson iteration formula is  \n\n\\[\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}.\n\\]\n\nWe start with \\(x_0 = 1\\).\n\n---\n\n**First iteration (\\(x_1\\)):**\n\n\\[\nf(1) = e^1 - 2\\cdot 1 - 1 = e - 3, \\qquad f'(1) = e - 2.\n\\]\n\n\\[\nx_1 = 1 - \\frac{e-3}{e-2} = \\frac{(e-2) - (e-3)}{e-2} = \\frac{1}{e-2}.\n\\]\n\nThus  \n\n\\[\nx_1 = \\frac{1}{e-2}.\n\\]\n\n(Note that \\(e-2 > 0\\), so the division is valid.)\n\n---\n\n**Second iteration (\\(x_2\\)):**\n\nLet \\(a = x_1 = \\dfrac{1}{e-2}\\). Then  \n\n\\[\nf(a) = e^{a} - 2a - 1, \\qquad f'(a) = e^{a} - 2.\n\\]\n\n\\[\nx_2 = a - \\frac{f(a)}{f'(a)} = a - \\frac{e^{a} - 2a - 1}{e^{a} - 2}.\n\\]\n\nSimplify the expression:\n\n\\[\nx_2 = \\frac{a(e^{a} - 2) - (e^{a} - 2a - 1)}{e^{a} - 2}\n   = \\frac{a e^{a} - 2a - e^{a} + 2a + 1}{e^{a} - 2}\n   = \\frac{e^{a}(a - 1) + 1}{e^{a} - 2}.\n\\]\n\nNow substitute back \\(a = \\dfrac{1}{e-2}\\):\n\n\\[\nx_2 = \\frac{ e^{\\frac{1}{e-2}} \\left( \\frac{1}{e-2} - 1 \\right) + 1 }{ e^{\\frac{1}{e-2}} - 2 }.\n\\]\n\nThe term in parentheses can be rewritten as  \n\n\\[\n\\frac{1}{e-2} - 1 = \\frac{1 - (e-2)}{e-2} = \\frac{3 - e}{e-2},\n\\]\n\ngiving an alternative exact form:\n\n\\[\nx_2 = \\frac{ e^{\\frac{1}{e-2}} \\cdot \\frac{3-e}{e-2} + 1 }{ e^{\\frac{1}{e-2}} - 2 }.\n\\]\n\nAll these expressions are equivalent and represent the **exact value** of \\(x_2\\) after two Newton\u2013Raphson iterations.\n\n(We note that \\(e^{a} - 2 \\neq 0\\) because \\(a \\approx 1.392 > \\ln 2\\), so the iteration is well\u2011defined.)\n\n---\n\n**Final answer:**\n\n\\[\n\\boxed{ x_2 = \\frac{ e^{\\frac{1}{e-2}} \\left( \\frac{1}{e-2} - 1 \\right) + 1 }{ e^{\\frac{1}{e-2}} - 2 } }\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $G$ be a simple graph with $n$ vertices. Prove that if $G$ is a tree (i.e., it is connected and has no cycles), then it has exactly $n-1$ edges.",
    "run_id": "2",
    "outer_attempt": 2,
    "topic_slug": "combinatorics",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Proof.**  \nWe proceed by induction on the number of vertices $n$.\n\n**Base case:** $n = 1$.  \nA tree with one vertex has no edges, and $1 - 1 = 0$. Hence the statement holds.\n\n**Inductive step:** Assume that every tree with $k$ vertices, where $1 \\le k < n$, has exactly $k - 1$ edges. Consider a tree $T$ with $n > 1$ vertices.\n\nFirst, we show that $T$ has at least two leaves (vertices of degree $1$). Since $T$ is finite and has at least two vertices, choose a longest path $P$ in $T$. Let $u$ and $v$ be the endpoints of $P$. If $u$ had degree at least $2$, then $u$ would be incident to an edge not in $P$. That edge either connects to a vertex already on $P$, creating a cycle (contradicting that $T$ is acyclic), or to a vertex not on $P$, allowing us to extend $P$ to a longer path (contradicting maximality). Therefore $\\deg(u) = 1$. The same argument gives $\\deg(v) = 1$. Thus $T$ has at least two leaves.\n\nPick a leaf $x$ of $T$ and let $e$ be the unique edge incident with $x$. Delete $x$ and $e$ to obtain the graph $T' = T - x$. We claim $T'$ is still a tree.\n\n* $T'$ is **acyclic**: removing a vertex cannot create a cycle, and $T$ itself has no cycles.  \n* $T'$ is **connected**: Take any two vertices $a, b \\in V(T')$. In $T$ there is a unique path $Q$ between $a$ and $b$ (trees have unique simple paths between any two vertices). Because $x$ is a leaf, its only neighbor is the vertex $y$ incident with $e$. If $Q$ contained $x$, then $x$ would have to be an interior vertex of $Q$ (since $a, b \\neq x$), implying that $x$ would have degree at least $2$ on $Q$ (one edge entering, one leaving). This contradicts $\\deg(x) = 1$. Hence $Q$ avoids $x$ and lies entirely in $T'$, so $a$ and $b$ are connected in $T'$.\n\nThus $T'$ is a tree with $n-1$ vertices. By the induction hypothesis, $T'$ has $(n-1)-1 = n-2$ edges. Since we removed exactly one edge $e$, the original tree $T$ has $(n-2) + 1 = n-1$ edges.\n\nThis completes the inductive step.\n\nBy the principle of mathematical induction, every tree on $n$ vertices has exactly $n-1$ edges. $\\square$",
        "raw_answer": "**Proof.**  \nWe proceed by induction on the number of vertices \\(n\\).\n\n**Base case:** \\(n = 1\\).  \nA tree with one vertex has no edges, and \\(1 - 1 = 0\\). Hence the statement holds.\n\n**Inductive step:** Assume that every tree with \\(k\\) vertices, where \\(1 \\le k < n\\), has exactly \\(k - 1\\) edges. Consider a tree \\(T\\) with \\(n > 1\\) vertices.\n\nFirst, we show that \\(T\\) has at least two leaves (vertices of degree \\(1\\)). Since \\(T\\) is finite and has at least two vertices, choose a longest path \\(P\\) in \\(T\\). Let \\(u\\) and \\(v\\) be the endpoints of \\(P\\). If \\(u\\) had degree at least \\(2\\), then \\(u\\) would be incident to an edge not in \\(P\\). That edge either connects to a vertex already on \\(P\\), creating a cycle (contradicting that \\(T\\) is acyclic), or to a vertex not on \\(P\\), allowing us to extend \\(P\\) to a longer path (contradicting maximality). Therefore \\(\\deg(u) = 1\\). The same argument gives \\(\\deg(v) = 1\\). Thus \\(T\\) has at least two leaves.\n\nPick a leaf \\(x\\) of \\(T\\) and let \\(e\\) be the unique edge incident with \\(x\\). Delete \\(x\\) and \\(e\\) to obtain the graph \\(T' = T - x\\). We claim \\(T'\\) is still a tree.\n\n* \\(T'\\) is **acyclic**: removing a vertex cannot create a cycle, and \\(T\\) itself has no cycles.  \n* \\(T'\\) is **connected**: Take any two vertices \\(a, b \\in V(T')\\). In \\(T\\) there is a unique path \\(Q\\) between \\(a\\) and \\(b\\) (trees have unique simple paths between any two vertices). Because \\(x\\) is a leaf, its only neighbor is the vertex \\(y\\) incident with \\(e\\). If \\(Q\\) contained \\(x\\), then \\(x\\) would have to be an interior vertex of \\(Q\\) (since \\(a, b \\neq x\\)), implying that \\(x\\) would have degree at least \\(2\\) on \\(Q\\) (one edge entering, one leaving). This contradicts \\(\\deg(x) = 1\\). Hence \\(Q\\) avoids \\(x\\) and lies entirely in \\(T'\\), so \\(a\\) and \\(b\\) are connected in \\(T'\\).\n\nThus \\(T'\\) is a tree with \\(n-1\\) vertices. By the induction hypothesis, \\(T'\\) has \\((n-1)-1 = n-2\\) edges. Since we removed exactly one edge \\(e\\), the original tree \\(T\\) has \\((n-2) + 1 = n-1\\) edges.\n\nThis completes the inductive step.\n\nBy the principle of mathematical induction, every tree on \\(n\\) vertices has exactly \\(n-1\\) edges. \\(\\square\\)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of algebraic geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within algebraic geometry\nAlgebraic geometry is a broad field that involves the study of geometric objects, such as varieties and schemes, using tools from abstract algebra. A suitable topic could involve the study of curves, surfaces, or higher-dimensional varieties, and their properties.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem involving the intersection of curves on a surface. A classic result in algebraic geometry is B\u00e9zout's theorem, which describes the intersection of two curves on a projective plane. We can formulate a problem related to this.\n\n## Step 4: State the problem\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.\n\n## Step 5: Provide the solution\nTo find the intersection points, we need to solve the system of equations given by $f(x,y,z) = 0$ and $g(x,y,z) = 0$. This means we have to solve $x^2 + y^2 - z^2 = 0$ and $xy - z^2 = 0$ simultaneously.\n\n## Step 6: Solve the system of equations using B\u00e9zout's theorem\nB\u00e9zout's theorem states that two curves of degrees $d_1$ and $d_2$ intersect in $d_1d_2$ points, counted with multiplicity, if they have no common components. Here, $C_1$ and $C_2$ are both of degree 2, so they should intersect in $2 \\times 2 = 4$ points.\n\n## Step 7: Verify if $C_1$ and $C_2$ have any common components\nTo check if $C_1$ and $C_2$ have common components, we need to see if $f$ and $g$ have a common factor. This involves checking if there's a non-constant polynomial that divides both $f$ and $g$.\n\n## Step 8: Check for common factors\nWe examine if there's a linear combination of $f$ and $g$ that simplifies to a constant or a factorable expression. However, given the nature of $f$ and $g$, and without loss of generality, we can directly apply B\u00e9zout's theorem if we confirm they don't share a component.\n\n## Step 9: Apply B\u00e9zout's theorem\nSince both $f$ and $g$ are of degree 2 and there's no immediate indication they share a factor (which would be a linear factor given their degree), we can conclude they intersect in 4 points counted with multiplicity.\n\n## Step 10: Conclude the number of intersection points\nBy B\u00e9zout's theorem, $C_1$ and $C_2$ intersect in 4 points.\n\nThe final answer is: \n\n\nConsider two curves $C_1$ and $C_2$ on $\\mathbb{P}^2$, defined by homogeneous polynomials $f(x,y,z) = x^2 + y^2 - z^2$ and $g(x,y,z) = xy - z^2$, respectively. Find the number of intersection points of $C_1$ and $C_2$ in $\\mathbb{P}^2$, counted with multiplicity.",
    "run_id": "8",
    "outer_attempt": 2,
    "topic_slug": "algebraic_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We need to find the number of intersection points of the two curves in the projective plane, counted with multiplicities. The curves are given by the homogeneous equations\n\n$$\nC_1:\\; f(x,y,z)=x^2+y^2-z^2=0,\\qquad C_2:\\; g(x,y,z)=xy-z^2=0.\n$$\n\nWe work over an algebraically closed field (typically $\\mathbb{C}$) so that B\u00e9zout's theorem applies.\n\n---\n\n### Step 1. Reduce the system\n\nFrom $g=0$ we have $z^2=xy$. Substituting into $f=0$ gives\n\n$$\nx^2+y^2 = xy \\quad\\Longrightarrow\\quad x^2 - xy + y^2 = 0. \\tag{1}\n$$\n\nEquation (1) is homogeneous of degree 2, so together with $z^2=xy$ it determines the intersection points in $\\mathbb{P}^2$.\n\n### Step 2. Check the line at infinity $z=0$\n\nIf $z=0$, then $g=0$ forces $xy=0$. So either $x=0$ or $y=0$.\n\n- If $x=0$, then $f=0$ gives $y^2=0$ $\\Rightarrow$ $y=0$, yielding $(0,0,0)$ which is not a point in $\\mathbb{P}^2$.\n- If $y=0$, then $f=0$ gives $x^2=0$ $\\Rightarrow$ $x=0$, again $(0,0,0)$.\n\nThus there is **no intersection point with $z=0$**. All intersection points lie in the affine chart $z\\neq0$.\n\n### Step 3. Work in the affine chart $z=1$\n\nSet $z=1$. Then the equations become\n\n$$\nx^2+y^2 = 1,\\qquad xy = 1. \\tag{2}\n$$\n\nFrom $xy=1$ we have $y = 1/x$ (note that $x\\neq0$ because otherwise $xy=0\\neq1$). Substitute into the first equation:\n\n$$\nx^2 + \\frac{1}{x^2} = 1 \\quad\\Longrightarrow\\quad x^4 - x^2 + 1 = 0. \\tag{3}\n$$\n\n### Step 4. Solve the quartic\n\nLet $u = x^2$. Then (3) becomes $u^2 - u + 1 = 0$. The discriminant is $\\Delta = 1 - 4 = -3$, so\n\n$$\nu = \\frac{1 \\pm i\\sqrt{3}}{2} = e^{\\pm i\\pi/3}.\n$$\n\nFor each $u$ we obtain two square roots: $x = \\pm\\sqrt{u}$. Since the two values of $u$ are distinct and nonzero, the four values of $x$ are distinct. Correspondingly, $y = 1/x$ gives four distinct pairs $(x,y)$. Hence we obtain four distinct affine points $(x,y,1)$.\n\nExplicitly, the four solutions are\n\n$$\nx = \\pm\\sqrt{\\frac{1\\pm i\\sqrt{3}}{2}},\\qquad y = \\frac{1}{x}.\n$$\n\nAll satisfy $z=1$, so they give four distinct points in $\\mathbb{P}^2$.\n\n### Step 5. Intersection number and multiplicities\n\nBoth $C_1$ and $C_2$ are curves of degree $2$. B\u00e9zout's theorem states that if they have no common component, the total intersection number (sum of intersection multiplicities) is $2\\cdot2 = 4$.\n\nWe must verify that $C_1$ and $C_2$ share no common component. Both are irreducible (their defining quadratic forms have non\u2011zero determinant, hence cannot factor into linear factors). Moreover, if they shared a component, the intersection would contain a whole curve, but we have already found only finitely many points (exactly four in the affine chart and none at infinity). Thus they are distinct and have no common component, so B\u00e9zout applies.\n\nSince we have found four distinct intersection points, the sum of the multiplicities is exactly the number of points, each must have multiplicity $1$. Therefore, the number of intersection points **counted with multiplicity** is $4$.\n\n---\n\n### Conclusion\n\n$$\n\\boxed{4}\n$$",
        "raw_answer": "We need to find the number of intersection points of the two curves in the projective plane, counted with multiplicities. The curves are given by the homogeneous equations\n\n\\[\nC_1:\\; f(x,y,z)=x^2+y^2-z^2=0,\\qquad C_2:\\; g(x,y,z)=xy-z^2=0.\n\\]\n\nWe work over an algebraically closed field (typically \\(\\mathbb{C}\\)) so that B\u00e9zout's theorem applies.\n\n---\n\n### Step 1. Reduce the system\n\nFrom \\(g=0\\) we have \\(z^2=xy\\). Substituting into \\(f=0\\) gives\n\n\\[\nx^2+y^2 = xy \\quad\\Longrightarrow\\quad x^2 - xy + y^2 = 0. \\tag{1}\n\\]\n\nEquation (1) is homogeneous of degree 2, so together with \\(z^2=xy\\) it determines the intersection points in \\(\\mathbb{P}^2\\).\n\n### Step 2. Check the line at infinity \\(z=0\\)\n\nIf \\(z=0\\), then \\(g=0\\) forces \\(xy=0\\). So either \\(x=0\\) or \\(y=0\\).\n\n- If \\(x=0\\), then \\(f=0\\) gives \\(y^2=0\\) \\(\\Rightarrow\\) \\(y=0\\), yielding \\((0,0,0)\\) which is not a point in \\(\\mathbb{P}^2\\).\n- If \\(y=0\\), then \\(f=0\\) gives \\(x^2=0\\) \\(\\Rightarrow\\) \\(x=0\\), again \\((0,0,0)\\).\n\nThus there is **no intersection point with \\(z=0\\)**. All intersection points lie in the affine chart \\(z\\neq0\\).\n\n### Step 3. Work in the affine chart \\(z=1\\)\n\nSet \\(z=1\\). Then the equations become\n\n\\[\nx^2+y^2 = 1,\\qquad xy = 1. \\tag{2}\n\\]\n\nFrom \\(xy=1\\) we have \\(y = 1/x\\) (note that \\(x\\neq0\\) because otherwise \\(xy=0\\neq1\\)). Substitute into the first equation:\n\n\\[\nx^2 + \\frac{1}{x^2} = 1 \\quad\\Longrightarrow\\quad x^4 - x^2 + 1 = 0. \\tag{3}\n\\]\n\n### Step 4. Solve the quartic\n\nLet \\(u = x^2\\). Then (3) becomes \\(u^2 - u + 1 = 0\\). The discriminant is \\(\\Delta = 1 - 4 = -3\\), so\n\n\\[\nu = \\frac{1 \\pm i\\sqrt{3}}{2} = e^{\\pm i\\pi/3}.\n\\]\n\nFor each \\(u\\) we obtain two square roots: \\(x = \\pm\\sqrt{u}\\). Since the two values of \\(u\\) are distinct and nonzero, the four values of \\(x\\) are distinct. Correspondingly, \\(y = 1/x\\) gives four distinct pairs \\((x,y)\\). Hence we obtain four distinct affine points \\((x,y,1)\\).\n\nExplicitly, the four solutions are\n\n\\[\nx = \\pm\\sqrt{\\frac{1\\pm i\\sqrt{3}}{2}},\\qquad y = \\frac{1}{x}.\n\\]\n\nAll satisfy \\(z=1\\), so they give four distinct points in \\(\\mathbb{P}^2\\).\n\n### Step 5. Intersection number and multiplicities\n\nBoth \\(C_1\\) and \\(C_2\\) are curves of degree \\(2\\). B\u00e9zout's theorem states that if they have no common component, the total intersection number (sum of intersection multiplicities) is \\(2\\cdot2 = 4\\).\n\nWe must verify that \\(C_1\\) and \\(C_2\\) share no common component. Both are irreducible (their defining quadratic forms have non\u2011zero determinant, hence cannot factor into linear factors). Moreover, if they shared a component, the intersection would contain a whole curve, but we have already found only finitely many points (exactly four in the affine chart and none at infinity). Thus they are distinct and have no common component, so B\u00e9zout applies.\n\nSince we have found four distinct intersection points, the sum of the multiplicities is exactly the number of points, each must have multiplicity \\(1\\). Therefore, the number of intersection points **counted with multiplicity** is \\(4\\).\n\n---\n\n### Conclusion\n\n\\[\n\\boxed{4}\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the given topic\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Sequences, series, summability\" along with a complete and verifiable solution. The problem should be simpler than the given previous attempt and must adhere to the quality rubric provided.\n\n## Step 2: Review the quality rubric for question generation\nThe question must be well-posed, clear, non-trivial, solvable, and verifiable. It should not have missing constraints, contradictory premises, multiple incompatible interpretations, undefined objects, or external dependencies.\n\n## Step 3: Analyze the previous attempt\nThe previous attempt was to evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{n(n+1)}$. This problem involves series and summability, indicating the topic is appropriate. However, the new problem should be simpler.\n\n## Step 4: Generate a new problem that is simpler and well-posed\nTo create a simpler problem, consider a basic series that is well-known and easy to compute. A good candidate could be evaluating a finite series or a simple infinite series that converges to a known value.\n\n## Step 5: Propose a specific problem\nLet's consider the series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$. This is a geometric series with the first term $a = \\frac{1}{2}$ and common ratio $r = \\frac{1}{2}$. The sum of an infinite geometric series is given by $\\frac{a}{1 - r}$ when $|r| < 1$, which applies here.\n\n## Step 6: Formulate the problem statement\nThe problem statement could be: \"Evaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$.\"\n\n## Step 7: Provide a complete solution\nTo solve $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$, recognize it as a geometric series. The sum $S$ of the first $n$ terms of a geometric series can be calculated using $S_n = a\\frac{1-r^n}{1-r}$, where $a$ is the first term and $r$ is the common ratio. For an infinite geometric series where $|r| < 1$, the sum is $S = \\frac{a}{1-r}$.\n\n## Step 8: Calculate the sum\nHere, $a = \\frac{1}{2}$ and $r = \\frac{1}{2}$. So, $S = \\frac{\\frac{1}{2}}{1 - \\frac{1}{2}} = \\frac{\\frac{1}{2}}{\\frac{1}{2}} = 1$.\n\n## Step 9: Write the problem and solution in the required format\n\nEvaluate the infinite series $\\sum_{n=1}^{\\infty} \\frac{1}{2^n}$.",
    "run_id": "26",
    "outer_attempt": 2,
    "topic_slug": "sequences_series_and_summability",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The series is a geometric series:\n\n$$\n\\sum_{n=1}^{\\infty} \\frac{1}{2^n} = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\cdots\n$$\n\nWe can write it in the standard form $\\sum_{n=1}^{\\infty} a r^{n-1}$ with first term $a = \\frac{1}{2}$ and common ratio $r = \\frac{1}{2}$ because\n\n$$\n\\frac{1}{2^n} = \\frac{1}{2} \\cdot \\left(\\frac{1}{2}\\right)^{n-1}.\n$$\n\nFor a geometric series, the sum converges if $|r| < 1$, which holds here. The sum is\n\n$$\nS = \\frac{a}{1-r} = \\frac{\\frac{1}{2}}{1 - \\frac{1}{2}} = \\frac{\\frac{1}{2}}{\\frac{1}{2}} = 1.\n$$\n\nAlternatively, one can compute the partial sums:\n\n$$\nS_N = \\sum_{n=1}^{N} \\frac{1}{2^n} = \\frac{\\frac{1}{2}\\left(1 - \\left(\\frac{1}{2}\\right)^N\\right)}{1 - \\frac{1}{2}} = 1 - \\frac{1}{2^N},\n$$\n\nand then\n\n$$\n\\lim_{N\\to\\infty} S_N = \\lim_{N\\to\\infty} \\left(1 - \\frac{1}{2^N}\\right) = 1.\n$$\n\nThus, the infinite series evaluates to $1$.\n\n$$\n\\boxed{1}\n$$",
        "raw_answer": "The series is a geometric series:\n\n\\[\n\\sum_{n=1}^{\\infty} \\frac{1}{2^n} = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\cdots\n\\]\n\nWe can write it in the standard form \\(\\sum_{n=1}^{\\infty} a r^{n-1}\\) with first term \\(a = \\frac{1}{2}\\) and common ratio \\(r = \\frac{1}{2}\\) because\n\n\\[\n\\frac{1}{2^n} = \\frac{1}{2} \\cdot \\left(\\frac{1}{2}\\right)^{n-1}.\n\\]\n\nFor a geometric series, the sum converges if \\(|r| < 1\\), which holds here. The sum is\n\n\\[\nS = \\frac{a}{1-r} = \\frac{\\frac{1}{2}}{1 - \\frac{1}{2}} = \\frac{\\frac{1}{2}}{\\frac{1}{2}} = 1.\n\\]\n\nAlternatively, one can compute the partial sums:\n\n\\[\nS_N = \\sum_{n=1}^{N} \\frac{1}{2^n} = \\frac{\\frac{1}{2}\\left(1 - \\left(\\frac{1}{2}\\right)^N\\right)}{1 - \\frac{1}{2}} = 1 - \\frac{1}{2^N},\n\\]\n\nand then\n\n\\[\n\\lim_{N\\to\\infty} S_N = \\lim_{N\\to\\infty} \\left(1 - \\frac{1}{2^N}\\right) = 1.\n\\]\n\nThus, the infinite series evaluates to \\(1\\).\n\n\\[\n\\boxed{1}\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the given topic\nThe task is to generate a challenging but solvable mathematics problem in the domain of \"Harmonic analysis on Euclidean spaces\" along with a complete and verifiable solution. The problem should be simpler than the given previous attempts but still challenging.\n\n## Step 2: Review the previous attempts and identify the complexity\nThe previous attempt was to prove that a function $f \\in L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$ with its Fourier transform $\\hat{f}$ supported in $B(0,1)$ is smooth and satisfies a certain decay condition. This involves understanding the properties of the Fourier transform, its relation to smoothness, and decay properties of functions.\n\n## Step 3: Simplify the problem while maintaining relevance to the topic\nTo simplify, we can consider a specific case or a related property. For instance, examining the properties of the Fourier transform on $L^2(\\mathbb{R}^n)$ or exploring the smoothness and decay properties for a specific class of functions.\n\n## Step 4: Formulate a new problem\nLet's consider a problem that involves understanding the Fourier transform and its properties. A potential problem could be: \"Let $f(x) = e^{-\\pi|x|^2}$ for $x \\in \\mathbb{R}^n$. Show that $f$ is an eigenfunction of the Fourier transform, i.e., $\\hat{f}(\\xi) = c f(\\xi)$ for some constant $c$, and determine $c$.\"\n\n## Step 5: Verify that the new problem is well-posed and solvable\nThe function $f(x) = e^{-\\pi|x|^2}$ is well-defined and belongs to $L^1(\\mathbb{R}^n) \\cap L^2(\\mathbb{R}^n)$. The Fourier transform of $f$ is given by $\\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} e^{-\\pi|x|^2} e^{-2\\pi i x \\cdot \\xi} dx$. This is a standard Gaussian integral, which can be evaluated.\n\n## Step 6: Solve the problem\nTo solve, we compute $\\hat{f}(\\xi)$. For $n=1$, $\\hat{f}(\\xi) = \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} e^{-2\\pi i x \\xi} dx = e^{-\\pi \\xi^2}$, using the known Fourier transform of a Gaussian. For $\\mathbb{R}^n$, the result generalizes to $\\hat{f}(\\xi) = e^{-\\pi |\\xi|^2}$ because the integral separates into $n$ one-dimensional integrals.\n\n## Step 7: Determine the constant $c$\nSince $\\hat{f}(\\xi) = e^{-\\pi |\\xi|^2} = f(\\xi)$, we have $c = 1$.\n\n## Step 8: Present the problem and solution in the required format\n\nLet $f(x) = e^{-\\pi|x|^2}$ for $x \\in \\mathbb{R}^n$. Show that $f$ is an eigenfunction of the Fourier transform, i.e., $\\hat{f}(\\xi) = c f(\\xi)$ for some constant $c$, and determine $c$.",
    "run_id": "28",
    "outer_attempt": 2,
    "topic_slug": "harmonic_analysis_on_euclidean_spaces",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We define the Fourier transform on $\\mathbb{R}^n$ by\n\n$$\n\\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} f(x)\\, e^{-2\\pi i x\\cdot \\xi}\\, dx,\n$$\n\nwhich is the standard normalization that makes the Fourier transform an isometry on $L^2(\\mathbb{R}^n)$. The function $f(x)=e^{-\\pi|x|^2}$ belongs to $L^1(\\mathbb{R}^n)\\cap L^2(\\mathbb{R}^n)$, so the integral converges absolutely and defines a continuous function.\n\nWe first compute the one\u2011dimensional Fourier transform of $g(x)=e^{-\\pi x^2}$. For $\\xi\\in\\mathbb{R}$,\n\n$$\n\\hat{g}(\\xi) = \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} e^{-2\\pi i x\\xi}\\, dx.\n$$\n\nComplete the square in the exponent:\n\n$$\n-\\pi x^2 - 2\\pi i x\\xi = -\\pi\\bigl(x^2 + 2i x\\xi\\bigr) = -\\pi\\bigl((x + i\\xi)^2 + \\xi^2\\bigr),\n$$\n\nbecause $(x+i\\xi)^2 = x^2 + 2i x\\xi - \\xi^2$. Hence\n\n$$\n\\hat{g}(\\xi) = e^{-\\pi \\xi^2} \\int_{-\\infty}^{\\infty} e^{-\\pi (x + i\\xi)^2}\\, dx.\n$$\n\nLet $I(\\xi) = \\int_{-\\infty}^{\\infty} e^{-\\pi (x + i\\xi)^2}\\, dx$. We show that $I(\\xi)$ is independent of $\\xi$ and equals $\\int_{-\\infty}^{\\infty} e^{-\\pi x^2}\\, dx = 1$.\n\nConsider the entire function $h(z)=e^{-\\pi z^2}$. For a fixed $\\xi$, take the contour $\\Gamma_R$ consisting of the four segments:\n- $\\gamma_1:$ from $-R$ to $R$ along the real axis,\n- $\\gamma_2:$ from $R$ to $R+i\\xi$ vertically,\n- $\\gamma_3:$ from $R+i\\xi$ to $-R+i\\xi$ horizontally,\n- $\\gamma_4:$ from $-R+i\\xi$ to $-R$ vertically.\n\nBy Cauchy\u2019s theorem, $\\oint_{\\Gamma_R} h(z)\\, dz = 0$ because $h$ is analytic. As $R\\to\\infty$, the integrals over the vertical segments $\\gamma_2$ and $\\gamma_4$ vanish. Indeed, on $\\gamma_2$ we have $z = R + i t$ with $t\\in[0,\\xi]$ (or $[\\xi,0]$ depending on sign), and\n\n$$\n|h(z)| = |e^{-\\pi (R+it)^2}| = e^{-\\pi (R^2 - t^2)} \\le e^{-\\pi R^2}\\, e^{\\pi \\xi^2},\n$$\n\nso $\\left|\\int_{\\gamma_2} h(z)\\, dz\\right| \\le |\\xi|\\, e^{-\\pi R^2}\\, e^{\\pi \\xi^2} \\to 0.$\nSimilarly for $\\gamma_4$. Therefore, in the limit,\n\n$$\n\\int_{-\\infty}^{\\infty} h(x)\\, dx = \\int_{-\\infty}^{\\infty} h(x+i\\xi)\\, dx.\n$$\n\nBut $h(x+i\\xi) = e^{-\\pi (x+i\\xi)^2}$, and the right\u2011hand side is exactly $I(\\xi)$. The left\u2011hand side is the well\u2011known Gaussian integral\n\n$$\n\\int_{-\\infty}^{\\infty} e^{-\\pi x^2}\\, dx = 1.\n$$\n\nThus $I(\\xi)=1$ for all $\\xi$, and\n\n$$\n\\hat{g}(\\xi) = e^{-\\pi \\xi^2} = g(\\xi).\n$$\n\nNow for the $n$-dimensional case, write $x=(x_1,\\dots,x_n)$, $\\xi=(\\xi_1,\\dots,\\xi_n)$. Then\n\n$$\nf(x) = \\prod_{j=1}^{n} e^{-\\pi x_j^2}.\n$$\n\nThe Fourier transform factorizes because the exponential $e^{-2\\pi i x\\cdot\\xi} = \\prod_{j=1}^{n} e^{-2\\pi i x_j\\xi_j}$ and the integral over $\\mathbb{R}^n$ is a product of one\u2011dimensional integrals by Fubini\u2019s theorem (the integrand is absolutely integrable). Hence\n\n$$\n\\begin{aligned}\n\\hat{f}(\\xi) &= \\int_{\\mathbb{R}^n} \\left(\\prod_{j=1}^{n} e^{-\\pi x_j^2}\\right) \\left(\\prod_{j=1}^{n} e^{-2\\pi i x_j\\xi_j}\\right) dx \\\\\n&= \\prod_{j=1}^{n} \\int_{-\\infty}^{\\infty} e^{-\\pi x_j^2} e^{-2\\pi i x_j\\xi_j}\\, dx_j \\\\\n&= \\prod_{j=1}^{n} e^{-\\pi \\xi_j^2} = e^{-\\pi |\\xi|^2} = f(\\xi).\n\\end{aligned}\n$$\n\nTherefore, $\\hat{f}(\\xi) = f(\\xi)$ for all $\\xi\\in\\mathbb{R}^n$, which means that $f$ is an eigenfunction of the Fourier transform with eigenvalue $c=1$.\n\n$$\n\\boxed{c = 1}\n$$",
        "raw_answer": "We define the Fourier transform on \\(\\mathbb{R}^n\\) by\n\n\\[\n\\hat{f}(\\xi) = \\int_{\\mathbb{R}^n} f(x)\\, e^{-2\\pi i x\\cdot \\xi}\\, dx,\n\\]\n\nwhich is the standard normalization that makes the Fourier transform an isometry on \\(L^2(\\mathbb{R}^n)\\). The function \\(f(x)=e^{-\\pi|x|^2}\\) belongs to \\(L^1(\\mathbb{R}^n)\\cap L^2(\\mathbb{R}^n)\\), so the integral converges absolutely and defines a continuous function.\n\nWe first compute the one\u2011dimensional Fourier transform of \\(g(x)=e^{-\\pi x^2}\\). For \\(\\xi\\in\\mathbb{R}\\),\n\n\\[\n\\hat{g}(\\xi) = \\int_{-\\infty}^{\\infty} e^{-\\pi x^2} e^{-2\\pi i x\\xi}\\, dx.\n\\]\n\nComplete the square in the exponent:\n\n\\[\n-\\pi x^2 - 2\\pi i x\\xi = -\\pi\\bigl(x^2 + 2i x\\xi\\bigr) = -\\pi\\bigl((x + i\\xi)^2 + \\xi^2\\bigr),\n\\]\n\nbecause \\((x+i\\xi)^2 = x^2 + 2i x\\xi - \\xi^2\\). Hence\n\n\\[\n\\hat{g}(\\xi) = e^{-\\pi \\xi^2} \\int_{-\\infty}^{\\infty} e^{-\\pi (x + i\\xi)^2}\\, dx.\n\\]\n\nLet \\(I(\\xi) = \\int_{-\\infty}^{\\infty} e^{-\\pi (x + i\\xi)^2}\\, dx\\). We show that \\(I(\\xi)\\) is independent of \\(\\xi\\) and equals \\(\\int_{-\\infty}^{\\infty} e^{-\\pi x^2}\\, dx = 1\\).\n\nConsider the entire function \\(h(z)=e^{-\\pi z^2}\\). For a fixed \\(\\xi\\), take the contour \\(\\Gamma_R\\) consisting of the four segments:\n- \\(\\gamma_1:\\) from \\(-R\\) to \\(R\\) along the real axis,\n- \\(\\gamma_2:\\) from \\(R\\) to \\(R+i\\xi\\) vertically,\n- \\(\\gamma_3:\\) from \\(R+i\\xi\\) to \\(-R+i\\xi\\) horizontally,\n- \\(\\gamma_4:\\) from \\(-R+i\\xi\\) to \\(-R\\) vertically.\n\nBy Cauchy\u2019s theorem, \\(\\oint_{\\Gamma_R} h(z)\\, dz = 0\\) because \\(h\\) is analytic. As \\(R\\to\\infty\\), the integrals over the vertical segments \\(\\gamma_2\\) and \\(\\gamma_4\\) vanish. Indeed, on \\(\\gamma_2\\) we have \\(z = R + i t\\) with \\(t\\in[0,\\xi]\\) (or \\([\\xi,0]\\) depending on sign), and\n\n\\[\n|h(z)| = |e^{-\\pi (R+it)^2}| = e^{-\\pi (R^2 - t^2)} \\le e^{-\\pi R^2}\\, e^{\\pi \\xi^2},\n\\]\n\nso \\(\\left|\\int_{\\gamma_2} h(z)\\, dz\\right| \\le |\\xi|\\, e^{-\\pi R^2}\\, e^{\\pi \\xi^2} \\to 0.\\)\nSimilarly for \\(\\gamma_4\\). Therefore, in the limit,\n\n\\[\n\\int_{-\\infty}^{\\infty} h(x)\\, dx = \\int_{-\\infty}^{\\infty} h(x+i\\xi)\\, dx.\n\\]\n\nBut \\(h(x+i\\xi) = e^{-\\pi (x+i\\xi)^2}\\), and the right\u2011hand side is exactly \\(I(\\xi)\\). The left\u2011hand side is the well\u2011known Gaussian integral\n\n\\[\n\\int_{-\\infty}^{\\infty} e^{-\\pi x^2}\\, dx = 1.\n\\]\n\nThus \\(I(\\xi)=1\\) for all \\(\\xi\\), and\n\n\\[\n\\hat{g}(\\xi) = e^{-\\pi \\xi^2} = g(\\xi).\n\\]\n\nNow for the \\(n\\)-dimensional case, write \\(x=(x_1,\\dots,x_n)\\), \\(\\xi=(\\xi_1,\\dots,\\xi_n)\\). Then\n\n\\[\nf(x) = \\prod_{j=1}^{n} e^{-\\pi x_j^2}.\n\\]\n\nThe Fourier transform factorizes because the exponential \\(e^{-2\\pi i x\\cdot\\xi} = \\prod_{j=1}^{n} e^{-2\\pi i x_j\\xi_j}\\) and the integral over \\(\\mathbb{R}^n\\) is a product of one\u2011dimensional integrals by Fubini\u2019s theorem (the integrand is absolutely integrable). Hence\n\n\\[\n\\begin{aligned}\n\\hat{f}(\\xi) &= \\int_{\\mathbb{R}^n} \\left(\\prod_{j=1}^{n} e^{-\\pi x_j^2}\\right) \\left(\\prod_{j=1}^{n} e^{-2\\pi i x_j\\xi_j}\\right) dx \\\\\n&= \\prod_{j=1}^{n} \\int_{-\\infty}^{\\infty} e^{-\\pi x_j^2} e^{-2\\pi i x_j\\xi_j}\\, dx_j \\\\\n&= \\prod_{j=1}^{n} e^{-\\pi \\xi_j^2} = e^{-\\pi |\\xi|^2} = f(\\xi).\n\\end{aligned}\n\\]\n\nTherefore, \\(\\hat{f}(\\xi) = f(\\xi)\\) for all \\(\\xi\\in\\mathbb{R}^n\\), which means that \\(f\\) is an eigenfunction of the Fourier transform with eigenvalue \\(c=1\\).\n\n\\[\n\\boxed{c = 1}\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging but solvable mathematics problem in the domain of Operator Theory, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Review the given topic and previous attempts\nThe topic is Operator Theory, and a previous attempt was made with the question: \"Let $T: L^2[0,1] \\to L^2[0,1]$ be defined by $Tf(x) = \\int_{0}^{x} f(t) dt$. Prove that $T$ is compact and find its spectrum.\" This question was adjudicated incorrect, and we need to generate a materially different, well-posed, and simpler question.\n\n## Step 3: Identify key concepts in Operator Theory\nOperator Theory involves the study of linear operators between vector spaces, particularly focusing on their properties such as boundedness, compactness, and spectral properties. A simpler question should still involve these concepts but in a more straightforward manner.\n\n## Step 4: Generate a new problem\nTo create a simpler problem, consider a basic operator and ask a fundamental question about its properties. For example, consider the operator $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ defined by a matrix. We can ask to determine if $T$ is bounded and find its spectrum.\n\n## Step 5: Formulate the problem\nLet's define $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ by $T(x, y) = (x + y, y)$. This can be represented by the matrix $\\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$. The task is to show that $T$ is bounded and to find its spectrum.\n\n## Step 6: Write the problem statement\n\"Let $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ be defined by $T(x, y) = (x + y, y)$. Show that $T$ is a bounded operator and find its spectrum.\"\n\n## Step 7: Provide the solution\nTo show $T$ is bounded, we need to show there exists a constant $M$ such that $\\|T(x, y)\\| \\leq M\\|(x, y)\\|$ for all $(x, y) \\in \\mathbb{C}^2$. Using the standard Euclidean norm, $\\|(x, y)\\| = \\sqrt{|x|^2 + |y|^2}$, we have $\\|T(x, y)\\| = \\|(x + y, y)\\| = \\sqrt{|x + y|^2 + |y|^2}$. By the triangle inequality, $|x + y| \\leq |x| + |y|$, so $|x + y|^2 \\leq (|x| + |y|)^2 \\leq 2(|x|^2 + |y|^2)$, hence $\\|T(x, y)\\| = \\sqrt{|x + y|^2 + |y|^2} \\leq \\sqrt{2(|x|^2 + |y|^2) + |y|^2} = \\sqrt{2|x|^2 + 3|y|^2} \\leq \\sqrt{3(|x|^2 + |y|^2)} = \\sqrt{3}\\|(x, y)\\|$. Thus, $T$ is bounded with $M = \\sqrt{3}$.\n\nTo find the spectrum, we need to find $\\lambda$ such that $T - \\lambda I$ is not invertible. The matrix representation of $T - \\lambda I$ is $\\begin{pmatrix} 1 - \\lambda & 1 \\\\ 0 & 1 - \\lambda \\end{pmatrix}$. This matrix is not invertible if its determinant is zero, i.e., $(1 - \\lambda)^2 = 0$. Thus, $\\lambda = 1$ is the only eigenvalue, and since $T$ is a bounded operator on a finite-dimensional space, its spectrum consists of its eigenvalues. Hence, the spectrum of $T$ is $\\{1\\}$.\n\n## Step 8: Format the output\n\nLet $T: \\mathbb{C}^2 \\to \\mathbb{C}^2$ be defined by $T(x, y) = (x + y, y)$. Show that $T$ is a bounded operator and find its spectrum.",
    "run_id": "33",
    "outer_attempt": 2,
    "topic_slug": "operator_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked to show that the linear operator $T:\\mathbb{C}^2\\to\\mathbb{C}^2$ defined by $T(x,y)=(x+y,y)$ is bounded and to find its spectrum. The space $\\mathbb{C}^2$ is equipped with the usual Euclidean norm $\\|(x,y)\\|=\\sqrt{|x|^2+|y|^2}$, which makes it a finite\u2011dimensional Hilbert space. The solution proceeds in two parts.\n\n---\n\n### 1. Boundedness of $T$\n\nA linear operator on a normed space is **bounded** if there exists a constant $M\\ge0$ such that $\\|Tv\\|\\le M\\|v\\|$ for every vector $v$. Because $\\mathbb{C}^2$ is finite\u2011dimensional, every linear operator is automatically bounded (continuous). Nevertheless, we provide an explicit bound to illustrate the definition.\n\nFor any $(x,y)\\in\\mathbb{C}^2$,\n\n$$\n\\|T(x,y)\\|^2 = \\|(x+y,\\,y)\\|^2 = |x+y|^2 + |y|^2.\n$$\n\nUsing the triangle inequality $|x+y|\\le |x|+|y|$, we obtain\n\n$$\n|x+y|^2 \\le (|x|+|y|)^2 = |x|^2 + 2|x||y| + |y|^2.\n$$\n\nHence\n\n$$\n\\|T(x,y)\\|^2 \\le |x|^2 + 2|x||y| + |y|^2 + |y|^2 = |x|^2 + 2|x||y| + 2|y|^2.\n$$\n\nNow apply the elementary inequality $2ab \\le a^2+b^2$ (which follows from $(a-b)^2\\ge0$) with $a=|x|$, $b=|y|$:\n\n$$\n2|x||y| \\le |x|^2 + |y|^2.\n$$\n\nSubstituting this gives\n\n$$\n\\|T(x,y)\\|^2 \\le |x|^2 + (|x|^2+|y|^2) + 2|y|^2 = 2|x|^2 + 3|y|^2.\n$$\n\nBecause $|x|^2,|y|^2 \\le |x|^2+|y|^2$, we have $2|x|^2+3|y|^2 \\le 3(|x|^2+|y|^2)$. Therefore\n\n$$\n\\|T(x,y)\\|^2 \\le 3(|x|^2+|y|^2) = 3\\|(x,y)\\|^2,\n$$\n\nand taking square roots yields\n\n$$\n\\|T(x,y)\\| \\le \\sqrt{3}\\,\\|(x,y)\\| \\qquad \\forall\\,(x,y)\\in\\mathbb{C}^2.\n$$\n\nThus $T$ is bounded (with operator norm at most $\\sqrt{3}$).\n\n---\n\n### 2. Spectrum of $T$\n\nThe **spectrum** $\\sigma(T)$ of a bounded linear operator $T$ on a Banach space is the set of all $\\lambda\\in\\mathbb{C}$ for which $T-\\lambda I$ is not invertible. Since we are in a finite\u2011dimensional space, $T-\\lambda I$ fails to be invertible exactly when its determinant vanishes, i.e., when $\\lambda$ is an eigenvalue.\n\nRepresent $T$ by its matrix with respect to the standard basis of $\\mathbb{C}^2$:\n\n$$\nA = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}.\n$$\n\nThen for any $\\lambda\\in\\mathbb{C}$,\n\n$$\nA - \\lambda I = \\begin{pmatrix} 1-\\lambda & 1 \\\\ 0 & 1-\\lambda \\end{pmatrix}.\n$$\n\nIts determinant is\n\n$$\n\\det(A-\\lambda I) = (1-\\lambda)^2.\n$$\n\nConsequently, $A-\\lambda I$ is singular (non\u2011invertible) if and only if $(1-\\lambda)^2 = 0$, i.e., $\\lambda = 1$. For $\\lambda \\neq 1$ the matrix is invertible; indeed,\n\n$$\n(A-\\lambda I)^{-1} = \\frac{1}{(1-\\lambda)^2} \\begin{pmatrix} 1-\\lambda & -1 \\\\ 0 & 1-\\lambda \\end{pmatrix}.\n$$\n\nTherefore the spectrum consists of the single point\n\n$$\n\\sigma(T) = \\{1\\}.\n$$\n\nOne may also note that $\\lambda=1$ is an eigenvalue: solving $(A-I)v=0$ gives\n\n$$\n\\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} v = 0 \\quad\\Longrightarrow\\quad v = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n\n(up to scalar multiples), confirming that $1$ belongs to the point spectrum.\n\n---\n\n### Conclusion\n\nThe operator $T$ is bounded (as shown by the explicit estimate $\\|T\\|\\le\\sqrt{3}$) and its spectrum is $\\sigma(T)=\\{1\\}$.",
        "raw_answer": "We are asked to show that the linear operator \\(T:\\mathbb{C}^2\\to\\mathbb{C}^2\\) defined by \\(T(x,y)=(x+y,y)\\) is bounded and to find its spectrum. The space \\(\\mathbb{C}^2\\) is equipped with the usual Euclidean norm \\(\\|(x,y)\\|=\\sqrt{|x|^2+|y|^2}\\), which makes it a finite\u2011dimensional Hilbert space. The solution proceeds in two parts.\n\n---\n\n### 1. Boundedness of \\(T\\)\n\nA linear operator on a normed space is **bounded** if there exists a constant \\(M\\ge0\\) such that \\(\\|Tv\\|\\le M\\|v\\|\\) for every vector \\(v\\). Because \\(\\mathbb{C}^2\\) is finite\u2011dimensional, every linear operator is automatically bounded (continuous). Nevertheless, we provide an explicit bound to illustrate the definition.\n\nFor any \\((x,y)\\in\\mathbb{C}^2\\),\n\n\\[\n\\|T(x,y)\\|^2 = \\|(x+y,\\,y)\\|^2 = |x+y|^2 + |y|^2.\n\\]\n\nUsing the triangle inequality \\(|x+y|\\le |x|+|y|\\), we obtain\n\n\\[\n|x+y|^2 \\le (|x|+|y|)^2 = |x|^2 + 2|x||y| + |y|^2.\n\\]\n\nHence\n\n\\[\n\\|T(x,y)\\|^2 \\le |x|^2 + 2|x||y| + |y|^2 + |y|^2 = |x|^2 + 2|x||y| + 2|y|^2.\n\\]\n\nNow apply the elementary inequality \\(2ab \\le a^2+b^2\\) (which follows from \\((a-b)^2\\ge0\\)) with \\(a=|x|\\), \\(b=|y|\\):\n\n\\[\n2|x||y| \\le |x|^2 + |y|^2.\n\\]\n\nSubstituting this gives\n\n\\[\n\\|T(x,y)\\|^2 \\le |x|^2 + (|x|^2+|y|^2) + 2|y|^2 = 2|x|^2 + 3|y|^2.\n\\]\n\nBecause \\(|x|^2,|y|^2 \\le |x|^2+|y|^2\\), we have \\(2|x|^2+3|y|^2 \\le 3(|x|^2+|y|^2)\\). Therefore\n\n\\[\n\\|T(x,y)\\|^2 \\le 3(|x|^2+|y|^2) = 3\\|(x,y)\\|^2,\n\\]\n\nand taking square roots yields\n\n\\[\n\\|T(x,y)\\| \\le \\sqrt{3}\\,\\|(x,y)\\| \\qquad \\forall\\,(x,y)\\in\\mathbb{C}^2.\n\\]\n\nThus \\(T\\) is bounded (with operator norm at most \\(\\sqrt{3}\\)).\n\n---\n\n### 2. Spectrum of \\(T\\)\n\nThe **spectrum** \\(\\sigma(T)\\) of a bounded linear operator \\(T\\) on a Banach space is the set of all \\(\\lambda\\in\\mathbb{C}\\) for which \\(T-\\lambda I\\) is not invertible. Since we are in a finite\u2011dimensional space, \\(T-\\lambda I\\) fails to be invertible exactly when its determinant vanishes, i.e., when \\(\\lambda\\) is an eigenvalue.\n\nRepresent \\(T\\) by its matrix with respect to the standard basis of \\(\\mathbb{C}^2\\):\n\n\\[\nA = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}.\n\\]\n\nThen for any \\(\\lambda\\in\\mathbb{C}\\),\n\n\\[\nA - \\lambda I = \\begin{pmatrix} 1-\\lambda & 1 \\\\ 0 & 1-\\lambda \\end{pmatrix}.\n\\]\n\nIts determinant is\n\n\\[\n\\det(A-\\lambda I) = (1-\\lambda)^2.\n\\]\n\nConsequently, \\(A-\\lambda I\\) is singular (non\u2011invertible) if and only if \\((1-\\lambda)^2 = 0\\), i.e., \\(\\lambda = 1\\). For \\(\\lambda \\neq 1\\) the matrix is invertible; indeed,\n\n\\[\n(A-\\lambda I)^{-1} = \\frac{1}{(1-\\lambda)^2} \\begin{pmatrix} 1-\\lambda & -1 \\\\ 0 & 1-\\lambda \\end{pmatrix}.\n\\]\n\nTherefore the spectrum consists of the single point\n\n\\[\n\\sigma(T) = \\{1\\}.\n\\]\n\nOne may also note that \\(\\lambda=1\\) is an eigenvalue: solving \\((A-I)v=0\\) gives\n\n\\[\n\\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} v = 0 \\quad\\Longrightarrow\\quad v = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n\\]\n\n(up to scalar multiples), confirming that \\(1\\) belongs to the point spectrum.\n\n---\n\n### Conclusion\n\nThe operator \\(T\\) is bounded (as shown by the explicit estimate \\(\\|T\\|\\le\\sqrt{3}\\)) and its spectrum is \\(\\sigma(T)=\\{1\\}\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task requires generating a challenging but solvable mathematics problem in the domain of calculus of variations and optimal control, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable problem in the domain\nA classic problem in calculus of variations is finding the curve that minimizes the distance between two points. However, to make it more challenging and relevant to optimal control, we can consider a problem that involves optimizing a functional subject to certain constraints.\n\n## Step 3: Formulate the problem\nLet's consider the problem of finding the function $y(x)$ that minimizes the functional $J[y] = \\int_{0}^{1} (y'^2 + y) \\,dx$, subject to the boundary conditions $y(0) = 0$ and $y(1) = 1$. This problem is relevant to the calculus of variations and involves optimizing a functional.\n\n## Step 4: Write down the problem statement\nThe problem can be stated as: \"Minimize $J[y] = \\int_{0}^{1} (y'^2 + y) \\,dx$ subject to $y(0) = 0$ and $y(1) = 1$, where $y(x)$ is a continuously differentiable function on $[0,1]$.\"\n\n## Step 5: Provide the solution to the problem\nTo solve this, we use the Euler-Lagrange equation, which states that for a functional $J[y] = \\int_{a}^{b} F(x, y, y') \\,dx$, the extremal $y(x)$ satisfies $\\frac{\\partial F}{\\partial y} - \\frac{d}{dx}(\\frac{\\partial F}{\\partial y'}) = 0$. Here, $F = y'^2 + y$, so $\\frac{\\partial F}{\\partial y} = 1$ and $\\frac{\\partial F}{\\partial y'} = 2y'$.\n\n## Step 6: Apply the Euler-Lagrange equation\nSubstituting into the Euler-Lagrange equation gives $1 - \\frac{d}{dx}(2y') = 0$, which simplifies to $1 - 2y'' = 0$. Thus, $y'' = \\frac{1}{2}$.\n\n## Step 7: Solve the differential equation\nIntegrating $y'' = \\frac{1}{2}$ twice gives $y(x) = \\frac{x^2}{4} + Ax + B$, where $A$ and $B$ are constants.\n\n## Step 8: Apply the boundary conditions\nUsing $y(0) = 0$ gives $B = 0$, and $y(1) = 1$ gives $1 = \\frac{1}{4} + A$, so $A = \\frac{3}{4}$.\n\n## Step 9: Write the solution\nThus, $y(x) = \\frac{x^2}{4} + \\frac{3x}{4}$.\n\n## Step 10: Verify the solution\nTo verify, we check that $y(x)$ satisfies the boundary conditions and the Euler-Lagrange equation. $y(0) = 0$ and $y(1) = \\frac{1}{4} + \\frac{3}{4} = 1$, so the boundary conditions are satisfied. The function $y(x)$ is also continuously differentiable.\n\nThe final answer is:\n\n\n\nMinimize $J[y] = \\int_{0}^{1} (y'^2 + y) \\,dx$ subject to $y(0) = 0$ and $y(1) = 1$, where $y(x)$ is a continuously differentiable function on $[0,1]$.",
    "run_id": "34",
    "outer_attempt": 2,
    "topic_slug": "calculus_of_variations_and_optimization",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked to minimize the functional\n\n$$\nJ[y] = \\int_{0}^{1} \\bigl( y'(x)^2 + y(x) \\bigr) \\,dx\n$$\n\nsubject to the boundary conditions $y(0)=0$, $y(1)=1$, where $y$ is a continuously differentiable function on $[0,1]$.\n\n---\n\n### Solution\n\n**1. Euler\u2013Lagrange equation.**  \nThe integrand is $F(x,y,y') = y'^2 + y$. For a minimizer $y$ that is $C^2$ (or piecewise $C^2$), the Euler\u2013Lagrange equation\n\n$$\n\\frac{\\partial F}{\\partial y} - \\frac{d}{dx}\\frac{\\partial F}{\\partial y'} = 0\n$$\n\nmust be satisfied. Compute the partial derivatives:\n\n$$\n\\frac{\\partial F}{\\partial y} = 1,\\qquad \\frac{\\partial F}{\\partial y'} = 2y'.\n$$\n\nHence\n\n$$\n\\frac{d}{dx}\\frac{\\partial F}{\\partial y'} = \\frac{d}{dx}(2y') = 2y''.\n$$\n\nSubstituting into the Euler\u2013Lagrange equation gives\n\n$$\n1 - 2y'' = 0 \\quad\\Longrightarrow\\quad y'' = \\frac{1}{2}.\n$$\n\n**2. Solve the differential equation.**  \nIntegrate twice:\n\n$$\ny'(x) = \\frac{1}{2}x + C_1,\n$$\n$$\ny(x) = \\frac{1}{4}x^2 + C_1 x + C_2,\n$$\n\nwhere $C_1, C_2$ are constants.\n\n**3. Apply the boundary conditions.**  \n\n- $y(0)=0$:  \n  $$\n  \\frac{1}{4}\\cdot 0 + C_1\\cdot 0 + C_2 = 0 \\;\\Longrightarrow\\; C_2 = 0.\n  $$\n\n- $y(1)=1$:  \n  $$\n  \\frac{1}{4}\\cdot 1 + C_1\\cdot 1 + 0 = 1 \\;\\Longrightarrow\\; \\frac{1}{4} + C_1 = 1 \\;\\Longrightarrow\\; C_1 = \\frac{3}{4}.\n  $$\n\nThus the candidate extremal is\n\n$$\n\\boxed{y(x) = \\frac{x^2}{4} + \\frac{3x}{4}}.\n$$\n\n**4. Verification that it gives a minimum.**  \n\nThe second variation of $J$ is\n\n$$\n\\delta^2 J = \\int_0^1 \\frac{\\partial^2 F}{\\partial y'^2} (\\delta y')^2 \\,dx = \\int_0^1 2 (\\delta y')^2 \\,dx \\ge 0,\n$$\n\nand it is zero only if $\\delta y' \\equiv 0$, i.e., for variations that are constant. Because the boundary conditions fix the variation to be zero at the endpoints, the only admissible variation with $\\delta y' \\equiv 0$ is the zero variation. Hence the second variation is strictly positive for all non\u2011zero admissible variations, which shows that the extremal is a strict local minimizer.\n\nMoreover, the integrand $F$ is convex in $(y,y')$: indeed, $F_{y'y'} = 2 > 0$ everywhere, and $F$ is linear in $y$ (hence convex). For a convex integrand, any solution of the Euler\u2013Lagrange equation yields a global minimum. Therefore $y(x) = \\frac{x^2}{4} + \\frac{3x}{4}$ is the unique global minimizer of $J$ among all $C^1$ functions satisfying the given boundary conditions.\n\n**5. Check the boundary conditions and the differential equation.**  \n\n- $y(0) = 0 + 0 = 0$, $y(1) = \\frac{1}{4} + \\frac{3}{4} = 1$.  \n- $y''(x) = \\frac{1}{2}$ (constant), so the Euler\u2013Lagrange equation is satisfied.\n\nThus the solution is complete.\n\n---\n\n**Final answer:** The function that minimizes the functional is\n\n$$\n\\boxed{y(x) = \\frac{x^{2}}{4} + \\frac{3x}{4}}.\n$$",
        "raw_answer": "We are asked to minimize the functional\n\n\\[\nJ[y] = \\int_{0}^{1} \\bigl( y'(x)^2 + y(x) \\bigr) \\,dx\n\\]\n\nsubject to the boundary conditions \\(y(0)=0\\), \\(y(1)=1\\), where \\(y\\) is a continuously differentiable function on \\([0,1]\\).\n\n---\n\n### Solution\n\n**1. Euler\u2013Lagrange equation.**  \nThe integrand is \\(F(x,y,y') = y'^2 + y\\). For a minimizer \\(y\\) that is \\(C^2\\) (or piecewise \\(C^2\\)), the Euler\u2013Lagrange equation\n\n\\[\n\\frac{\\partial F}{\\partial y} - \\frac{d}{dx}\\frac{\\partial F}{\\partial y'} = 0\n\\]\n\nmust be satisfied. Compute the partial derivatives:\n\n\\[\n\\frac{\\partial F}{\\partial y} = 1,\\qquad \\frac{\\partial F}{\\partial y'} = 2y'.\n\\]\n\nHence\n\n\\[\n\\frac{d}{dx}\\frac{\\partial F}{\\partial y'} = \\frac{d}{dx}(2y') = 2y''.\n\\]\n\nSubstituting into the Euler\u2013Lagrange equation gives\n\n\\[\n1 - 2y'' = 0 \\quad\\Longrightarrow\\quad y'' = \\frac{1}{2}.\n\\]\n\n**2. Solve the differential equation.**  \nIntegrate twice:\n\n\\[\ny'(x) = \\frac{1}{2}x + C_1,\n\\]\n\\[\ny(x) = \\frac{1}{4}x^2 + C_1 x + C_2,\n\\]\n\nwhere \\(C_1, C_2\\) are constants.\n\n**3. Apply the boundary conditions.**  \n\n- \\(y(0)=0\\):  \n  \\[\n  \\frac{1}{4}\\cdot 0 + C_1\\cdot 0 + C_2 = 0 \\;\\Longrightarrow\\; C_2 = 0.\n  \\]\n\n- \\(y(1)=1\\):  \n  \\[\n  \\frac{1}{4}\\cdot 1 + C_1\\cdot 1 + 0 = 1 \\;\\Longrightarrow\\; \\frac{1}{4} + C_1 = 1 \\;\\Longrightarrow\\; C_1 = \\frac{3}{4}.\n  \\]\n\nThus the candidate extremal is\n\n\\[\n\\boxed{y(x) = \\frac{x^2}{4} + \\frac{3x}{4}}.\n\\]\n\n**4. Verification that it gives a minimum.**  \n\nThe second variation of \\(J\\) is\n\n\\[\n\\delta^2 J = \\int_0^1 \\frac{\\partial^2 F}{\\partial y'^2} (\\delta y')^2 \\,dx = \\int_0^1 2 (\\delta y')^2 \\,dx \\ge 0,\n\\]\n\nand it is zero only if \\(\\delta y' \\equiv 0\\), i.e., for variations that are constant. Because the boundary conditions fix the variation to be zero at the endpoints, the only admissible variation with \\(\\delta y' \\equiv 0\\) is the zero variation. Hence the second variation is strictly positive for all non\u2011zero admissible variations, which shows that the extremal is a strict local minimizer.\n\nMoreover, the integrand \\(F\\) is convex in \\((y,y')\\): indeed, \\(F_{y'y'} = 2 > 0\\) everywhere, and \\(F\\) is linear in \\(y\\) (hence convex). For a convex integrand, any solution of the Euler\u2013Lagrange equation yields a global minimum. Therefore \\(y(x) = \\frac{x^2}{4} + \\frac{3x}{4}\\) is the unique global minimizer of \\(J\\) among all \\(C^1\\) functions satisfying the given boundary conditions.\n\n**5. Check the boundary conditions and the differential equation.**  \n\n- \\(y(0) = 0 + 0 = 0\\), \\(y(1) = \\frac{1}{4} + \\frac{3}{4} = 1\\).  \n- \\(y''(x) = \\frac{1}{2}\\) (constant), so the Euler\u2013Lagrange equation is satisfied.\n\nThus the solution is complete.\n\n---\n\n**Final answer:** The function that minimizes the functional is\n\n\\[\n\\boxed{y(x) = \\frac{x^{2}}{4} + \\frac{3x}{4}}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of Convex and discrete geometry, along with a complete and verifiable solution. The problem should be well-posed, clear, non-trivial, and solvable with established mathematical methods.\n\n## Step 2: Identify a suitable topic within Convex and discrete geometry\nConvex and discrete geometry encompasses a broad range of topics including the geometry of convex sets, polytopes, and discrete geometric structures. A suitable topic could involve properties of convex polytopes, such as their faces, volumes, or the relationships between their vertices and facets.\n\n## Step 3: Formulate a specific problem\nLet's consider a problem related to the properties of a specific convex polytope. A well-known result in convex geometry is the characterization of regular polytopes. However, a more challenging and less straightforward problem could involve understanding the relationship between the number of vertices, edges, and faces of a polytope.\n\n## Step 4: Generate a problem statement\nConsider a 3-dimensional convex polytope $P$ that is simple (every vertex is incident to exactly 3 edges) and has $V$ vertices, $E$ edges, and $F$ faces. The problem is to prove that for such a polytope, Euler's formula ($V - E + F = 2$) holds, and then use this to derive a relationship between $V$ and $F$.\n\n## Step 5: Write down the problem in the required format\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces. Prove that $V - E + F = 2$ and derive a formula relating $V$ and $F$ using the fact that $P$ is simple.\n\n\nLet $P$ be a simple 3-dimensional convex polytope with $V$ vertices, $E$ edges, and $F$ faces. Prove that $V - E + F = 2$ and derive a formula relating $V$ and $F$ using the fact that $P$ is simple.",
    "run_id": "36",
    "outer_attempt": 2,
    "topic_slug": "convex_and_discrete_geometry",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are given a simple 3-dimensional convex polytope $P$ with $V$ vertices, $E$ edges, and $F$ faces. We must prove Euler's formula $V - E + F = 2$ and then use the simplicity condition to derive a relation between $V$ and $F$.\n\n---\n\n### Part 1: Proof of Euler's formula $V - E + F = 2$\n\n**Step 1: Reduce to a planar graph.**  \nBecause $P$ is convex, we can project its vertices and edges onto a plane to obtain a planar graph that faithfully encodes the combinatorial structure. Choose a point $O$ just outside one face of $P$ and project the polytope onto a plane not parallel to that face (for instance, a plane parallel to the chosen face). The projection sends each vertex to a distinct point and each edge to a straight segment. Since $P$ is convex, the images of the edges do not cross; they form a **planar embedding** of a connected graph $G$. The graph $G$ has exactly $V$ vertices and $E$ edges. Moreover, the faces of $G$ correspond bijectively to the faces of $P$: the chosen face becomes the unbounded (outer) face of $G$, and every other face of $P$ becomes a bounded face. Hence $G$ has exactly $F$ faces (including the outer face). Therefore, proving Euler's formula for $P$ is equivalent to proving it for the connected planar graph $G$.\n\n**Step 2: Euler's formula for connected planar graphs.**  \nLet $G$ be any connected planar graph with $V$ vertices, $E$ edges, and $F$ faces (the outer face counted as one). We prove $V - E + F = 2$ by induction on $E$.\n\n*Base case:* $E = 0$. A connected graph with no edges must consist of a single vertex ($V = 1$). It has exactly one face (the outer face), so $F = 1$. Then $V - E + F = 1 - 0 + 1 = 2$. The formula holds.\n\n*Inductive step:* Assume the formula holds for all connected planar graphs with fewer than $E$ edges, where $E \\ge 1$. Consider a connected planar graph $G$ with $V$ vertices, $E$ edges, and $F$ faces.\n\n- **If $G$ contains a cycle:** Choose an edge $e$ that lies on a cycle. Removing $e$ yields a graph $G'$ that remains connected (because $e$ is not a bridge) and is still planar. In $G'$, the number of vertices is unchanged ($V$), the number of edges is $E-1$, and the number of faces is $F-1$ (since the edge $e$ separated two distinct faces, which merge into one after removal). By the induction hypothesis, $G'$ satisfies  \n  $$\n  V - (E-1) + (F-1) = 2.\n  $$  \n  Simplifying gives $V - E + F = 2$, so the formula holds for $G$.\n\n- **If $G$ contains no cycle:** Then $G$ is a tree. A tree with $V$ vertices has $E = V-1$ edges and exactly one face (the outer face), i.e., $F = 1$. Substituting,  \n  $$\n  V - (V-1) + 1 = 2,\n  $$  \n  which again yields the formula.\n\nThus, by induction, Euler's formula holds for all connected planar graphs. Applying it to the graph $G$ obtained from $P$ gives $V - E + F = 2$ for the original polytope.\n\n---\n\n### Part 2: Deriving a relation between $V$ and $F$ using simplicity\n\nA **simple** 3\u2011dimensional polytope is defined by the property that exactly three edges meet at every vertex. Hence each vertex has degree $3$. The handshaking lemma (double counting of edge\u2011vertex incidences) states  \n$$\n\\sum_{v \\in \\text{vertices}} \\deg(v) = 2E.\n$$  \nBecause every vertex has degree $3$, the left side equals $3V$. Therefore  \n$$\n3V = 2E \\quad \\Longrightarrow \\quad E = \\frac{3V}{2}.\n$$\n\nSubstitute this expression for $E$ into Euler's formula:  \n$$\nV - \\frac{3V}{2} + F = 2.\n$$  \nSimplifying,  \n$$\n-\\frac{V}{2} + F = 2 \\quad \\Longrightarrow \\quad F = 2 + \\frac{V}{2}.\n$$\n\nThus the desired relation is  \n\n$$\n\\boxed{F = 2 + \\frac{V}{2}}.\n$$\n\n(As a corollary, $V$ must be even because $F$ is an integer, which is a well\u2011known parity condition for simple 3\u2011polytopes.)\n\n---\n\nThis completes the solution.",
        "raw_answer": "We are given a simple 3-dimensional convex polytope \\(P\\) with \\(V\\) vertices, \\(E\\) edges, and \\(F\\) faces. We must prove Euler's formula \\(V - E + F = 2\\) and then use the simplicity condition to derive a relation between \\(V\\) and \\(F\\).\n\n---\n\n### Part 1: Proof of Euler's formula \\(V - E + F = 2\\)\n\n**Step 1: Reduce to a planar graph.**  \nBecause \\(P\\) is convex, we can project its vertices and edges onto a plane to obtain a planar graph that faithfully encodes the combinatorial structure. Choose a point \\(O\\) just outside one face of \\(P\\) and project the polytope onto a plane not parallel to that face (for instance, a plane parallel to the chosen face). The projection sends each vertex to a distinct point and each edge to a straight segment. Since \\(P\\) is convex, the images of the edges do not cross; they form a **planar embedding** of a connected graph \\(G\\). The graph \\(G\\) has exactly \\(V\\) vertices and \\(E\\) edges. Moreover, the faces of \\(G\\) correspond bijectively to the faces of \\(P\\): the chosen face becomes the unbounded (outer) face of \\(G\\), and every other face of \\(P\\) becomes a bounded face. Hence \\(G\\) has exactly \\(F\\) faces (including the outer face). Therefore, proving Euler's formula for \\(P\\) is equivalent to proving it for the connected planar graph \\(G\\).\n\n**Step 2: Euler's formula for connected planar graphs.**  \nLet \\(G\\) be any connected planar graph with \\(V\\) vertices, \\(E\\) edges, and \\(F\\) faces (the outer face counted as one). We prove \\(V - E + F = 2\\) by induction on \\(E\\).\n\n*Base case:* \\(E = 0\\). A connected graph with no edges must consist of a single vertex (\\(V = 1\\)). It has exactly one face (the outer face), so \\(F = 1\\). Then \\(V - E + F = 1 - 0 + 1 = 2\\). The formula holds.\n\n*Inductive step:* Assume the formula holds for all connected planar graphs with fewer than \\(E\\) edges, where \\(E \\ge 1\\). Consider a connected planar graph \\(G\\) with \\(V\\) vertices, \\(E\\) edges, and \\(F\\) faces.\n\n- **If \\(G\\) contains a cycle:** Choose an edge \\(e\\) that lies on a cycle. Removing \\(e\\) yields a graph \\(G'\\) that remains connected (because \\(e\\) is not a bridge) and is still planar. In \\(G'\\), the number of vertices is unchanged (\\(V\\)), the number of edges is \\(E-1\\), and the number of faces is \\(F-1\\) (since the edge \\(e\\) separated two distinct faces, which merge into one after removal). By the induction hypothesis, \\(G'\\) satisfies  \n  \\[\n  V - (E-1) + (F-1) = 2.\n  \\]  \n  Simplifying gives \\(V - E + F = 2\\), so the formula holds for \\(G\\).\n\n- **If \\(G\\) contains no cycle:** Then \\(G\\) is a tree. A tree with \\(V\\) vertices has \\(E = V-1\\) edges and exactly one face (the outer face), i.e., \\(F = 1\\). Substituting,  \n  \\[\n  V - (V-1) + 1 = 2,\n  \\]  \n  which again yields the formula.\n\nThus, by induction, Euler's formula holds for all connected planar graphs. Applying it to the graph \\(G\\) obtained from \\(P\\) gives \\(V - E + F = 2\\) for the original polytope.\n\n---\n\n### Part 2: Deriving a relation between \\(V\\) and \\(F\\) using simplicity\n\nA **simple** 3\u2011dimensional polytope is defined by the property that exactly three edges meet at every vertex. Hence each vertex has degree \\(3\\). The handshaking lemma (double counting of edge\u2011vertex incidences) states  \n\\[\n\\sum_{v \\in \\text{vertices}} \\deg(v) = 2E.\n\\]  \nBecause every vertex has degree \\(3\\), the left side equals \\(3V\\). Therefore  \n\\[\n3V = 2E \\quad \\Longrightarrow \\quad E = \\frac{3V}{2}.\n\\]\n\nSubstitute this expression for \\(E\\) into Euler's formula:  \n\\[\nV - \\frac{3V}{2} + F = 2.\n\\]  \nSimplifying,  \n\\[\n-\\frac{V}{2} + F = 2 \\quad \\Longrightarrow \\quad F = 2 + \\frac{V}{2}.\n\\]\n\nThus the desired relation is  \n\n\\[\n\\boxed{F = 2 + \\frac{V}{2}}.\n\\]\n\n(As a corollary, \\(V\\) must be even because \\(F\\) is an integer, which is a well\u2011known parity condition for simple 3\u2011polytopes.)\n\n---\n\nThis completes the solution.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task\nThe task is to generate a challenging mathematical problem in the domain of general topology, along with a complete solution, following specific guidelines.\n\n## Step 2: Review the guidelines for a well-posed question\nThe question must be self-contained, clear, non-trivial, and solvable with established mathematical methods. It should not require external dependencies or be culturally dependent.\n\n## Step 3: Identify a topic within general topology\nGeneral topology involves the study of topological spaces, continuous functions, and topological properties. A suitable topic could involve properties of specific topological spaces or the behavior of continuous functions.\n\n## Step 4: Generate a problem\nLet's consider a problem involving the concept of compactness and continuous functions. A well-known result in general topology is that the continuous image of a compact space is compact.\n\n## Step 5: Formulate the problem\n\"Let $X = [0,1] \\cup [2,3]$ be a subspace of $\\mathbb{R}$ with the standard topology. Define a function $f: X \\to \\mathbb{R}$ by $f(x) = x^2$. Prove that $f(X)$ is compact.\"\n\n## Step 6: Verify that the problem is well-posed\n- The domain $X$ is explicitly defined.\n- The function $f$ is clearly defined.\n- The task is to prove a specific property ($f(X)$ being compact) which is a well-defined mathematical concept.\n- The problem does not require external dependencies.\n\n## Step 7: Provide a solution to the problem\nTo prove that $f(X)$ is compact, we need to show that it is closed and bounded since $f(X) \\subset \\mathbb{R}$ and $\\mathbb{R}$ is a metric space.\n\n## Step 8: Calculate $f(X)$\nGiven $X = [0,1] \\cup [2,3]$, $f(X) = f([0,1]) \\cup f([2,3]) = [0,1] \\cup [4,9]$.\n\n## Step 9: Show that $f(X)$ is compact\n$f(X) = [0,1] \\cup [4,9]$ is a union of two closed and bounded intervals, hence it is closed and bounded. Therefore, $f(X)$ is compact because it is a closed and bounded subset of $\\mathbb{R}$.\n\n## Step 10: Write the problem and solution in the required format\n\nLet $X = [0,1] \\cup [2,3]$ be a subspace of $\\mathbb{R}$ with the standard topology. Define a function $f: X \\to \\mathbb{R}$ by $f(x) = x^2$. Prove that $f(X)$ is compact.",
    "run_id": "38",
    "outer_attempt": 2,
    "topic_slug": "general_topology",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We prove that $f(X)$ is compact by showing that $X$ is compact and $f$ is continuous, then invoking the theorem that the continuous image of a compact space is compact.\n\n**Step 1: $X$ is compact.**  \n$X = [0,1] \\cup [2,3]$ is a subset of $\\mathbb{R}$ with the standard Euclidean topology.  \n- **Boundedness:** $X \\subseteq [0,3]$, so $X$ is bounded.  \n- **Closedness:** Each interval $[0,1]$ and $[2,3]$ is closed in $\\mathbb{R}$ (they contain all their limit points). The finite union of closed sets is closed, hence $X$ is closed.  \n\nBy the Heine\u2013Borel theorem (a subset of $\\mathbb{R}$ is compact iff it is closed and bounded), $X$ is compact.\n\n**Step 2: $f$ is continuous.**  \nThe function $f(x) = x^2$ is a polynomial, and polynomials are continuous on $\\mathbb{R}$. The restriction of a continuous function to a subspace (with the subspace topology) remains continuous. Therefore $f: X \\to \\mathbb{R}$ is continuous.\n\n**Step 3: Image of a compact set under a continuous map.**  \nA standard result in topology states: if $X$ is compact and $f: X \\to Y$ is continuous, then $f(X)$ is compact. Applying this with $Y = \\mathbb{R}$ yields that $f(X)$ is compact.\n\nThus we have proved that $f(X)$ is compact. \u220e\n\n(One may also compute $f(X) = [0,1] \\cup [4,9]$ directly and note that this union is closed and bounded, hence compact by Heine\u2013Borel; the above argument avoids explicit computation while remaining rigorous.)",
        "raw_answer": "We prove that \\(f(X)\\) is compact by showing that \\(X\\) is compact and \\(f\\) is continuous, then invoking the theorem that the continuous image of a compact space is compact.\n\n**Step 1: \\(X\\) is compact.**  \n\\(X = [0,1] \\cup [2,3]\\) is a subset of \\(\\mathbb{R}\\) with the standard Euclidean topology.  \n- **Boundedness:** \\(X \\subseteq [0,3]\\), so \\(X\\) is bounded.  \n- **Closedness:** Each interval \\([0,1]\\) and \\([2,3]\\) is closed in \\(\\mathbb{R}\\) (they contain all their limit points). The finite union of closed sets is closed, hence \\(X\\) is closed.  \n\nBy the Heine\u2013Borel theorem (a subset of \\(\\mathbb{R}\\) is compact iff it is closed and bounded), \\(X\\) is compact.\n\n**Step 2: \\(f\\) is continuous.**  \nThe function \\(f(x) = x^2\\) is a polynomial, and polynomials are continuous on \\(\\mathbb{R}\\). The restriction of a continuous function to a subspace (with the subspace topology) remains continuous. Therefore \\(f: X \\to \\mathbb{R}\\) is continuous.\n\n**Step 3: Image of a compact set under a continuous map.**  \nA standard result in topology states: if \\(X\\) is compact and \\(f: X \\to Y\\) is continuous, then \\(f(X)\\) is compact. Applying this with \\(Y = \\mathbb{R}\\) yields that \\(f(X)\\) is compact.\n\nThus we have proved that \\(f(X)\\) is compact. \u220e\n\n(One may also compute \\(f(X) = [0,1] \\cup [4,9]\\) directly and note that this union is closed and bounded, hence compact by Heine\u2013Borel; the above argument avoids explicit computation while remaining rigorous.)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $g(x) = x^3 - x - 1$. We are tasked with approximating the root of $g(x)$ in the interval $[1,2]$ using the bisection method. Perform two iterations of the bisection method starting with the initial interval $[1,2]$ to find the interval that contains the root after two iterations.",
    "run_id": "44",
    "outer_attempt": 2,
    "topic_slug": "numerical_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are given $g(x) = x^3 - x - 1$ and the initial interval $[1,2]$. The function is continuous, and we check the signs at the endpoints:\n\n$$\ng(1) = 1^3 - 1 - 1 = -1 < 0, \\qquad g(2) = 2^3 - 2 - 1 = 8 - 2 - 1 = 5 > 0.\n$$\n\nSince $g(1)$ and $g(2)$ have opposite signs, by the Intermediate Value Theorem there is at least one root in $(1,2)$. We apply the bisection method.\n\n**Iteration 1:**  \nMidpoint: $c_1 = \\frac{1+2}{2} = 1.5$.  \nEvaluate $g(c_1)$:\n\n$$\ng(1.5) = (1.5)^3 - 1.5 - 1 = 3.375 - 1.5 - 1 = 0.875 > 0.\n$$\n\nBecause $g(1) < 0$ and $g(1.5) > 0$, the root lies in the subinterval $[1, 1.5]$.\n\n**Iteration 2:**  \nNow the interval is $[1, 1.5]$.  \nMidpoint: $c_2 = \\frac{1 + 1.5}{2} = 1.25$.  \nEvaluate $g(c_2)$:\n\n$$\ng(1.25) = (1.25)^3 - 1.25 - 1 = 1.953125 - 1.25 - 1 = -0.296875 < 0.\n$$\n\nNow $g(1) < 0$ and $g(1.25) < 0$, while $g(1.5) > 0$. Hence the root must be in $[1.25, 1.5]$.\n\nAfter two iterations, the interval that contains the root is $[1.25, 1.5]$ (equivalently $\\left[\\frac{5}{4}, \\frac{3}{2}\\right]$). The length of this interval is $0.25$, consistent with the expected reduction after two bisections.\n\nThus, the final answer is $\\boxed{[1.25, 1.5]}$.",
        "raw_answer": "We are given \\(g(x) = x^3 - x - 1\\) and the initial interval \\([1,2]\\). The function is continuous, and we check the signs at the endpoints:\n\n\\[\ng(1) = 1^3 - 1 - 1 = -1 < 0, \\qquad g(2) = 2^3 - 2 - 1 = 8 - 2 - 1 = 5 > 0.\n\\]\n\nSince \\(g(1)\\) and \\(g(2)\\) have opposite signs, by the Intermediate Value Theorem there is at least one root in \\((1,2)\\). We apply the bisection method.\n\n**Iteration 1:**  \nMidpoint: \\(c_1 = \\frac{1+2}{2} = 1.5\\).  \nEvaluate \\(g(c_1)\\):\n\n\\[\ng(1.5) = (1.5)^3 - 1.5 - 1 = 3.375 - 1.5 - 1 = 0.875 > 0.\n\\]\n\nBecause \\(g(1) < 0\\) and \\(g(1.5) > 0\\), the root lies in the subinterval \\([1, 1.5]\\).\n\n**Iteration 2:**  \nNow the interval is \\([1, 1.5]\\).  \nMidpoint: \\(c_2 = \\frac{1 + 1.5}{2} = 1.25\\).  \nEvaluate \\(g(c_2)\\):\n\n\\[\ng(1.25) = (1.25)^3 - 1.25 - 1 = 1.953125 - 1.25 - 1 = -0.296875 < 0.\n\\]\n\nNow \\(g(1) < 0\\) and \\(g(1.25) < 0\\), while \\(g(1.5) > 0\\). Hence the root must be in \\([1.25, 1.5]\\).\n\nAfter two iterations, the interval that contains the root is \\([1.25, 1.5]\\) (equivalently \\(\\left[\\frac{5}{4}, \\frac{3}{2}\\right]\\)). The length of this interval is \\(0.25\\), consistent with the expected reduction after two bisections.\n\nThus, the final answer is \\(\\boxed{[1.25, 1.5]}\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $P(x)$ be the predicate \"$x$ is a prime number.\" Formalize the statement \"There are infinitely many prime numbers\" using the predicate $P(x)$, and determine whether it is true or false. If true, provide a proof; if false, provide a counterexample.",
    "run_id": "1",
    "outer_attempt": 3,
    "topic_slug": "mathematical_logic_and_foundations",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked to formalize the statement \u201cThere are infinitely many prime numbers\u201d using the predicate $P(x)$ (where $P(x)$ means \u201c$x$ is a prime number\u201d) and then determine its truth value, providing a proof if true or a counterexample if false.\n\n## Formalization\n\nLet the domain be the set of natural numbers $\\mathbb{N} = \\{1,2,3,\\dots\\}$.  \nThe statement \u201cthere are infinitely many prime numbers\u201d means that the set of primes is unbounded; equivalently, for every natural number $N$ there exists a prime larger than $N$. Using the predicate $P(x)$, this can be written as:\n\n$$\n\\forall N \\in \\mathbb{N}\\; \\exists x \\in \\mathbb{N}\\; \\bigl( x > N \\;\\land\\; P(x) \\bigr).\n$$\n\nAn equivalent formulation is\n\n$$\n\\lnot \\exists N \\in \\mathbb{N}\\; \\forall x \\in \\mathbb{N}\\; \\bigl( P(x) \\to x \\le N \\bigr).\n$$\n\nBoth capture the idea that there is no largest prime and that primes are infinite in number.\n\n## Truth Value\n\nThe statement is **true**.\n\n## Proof (Euclid\u2019s classic proof)\n\nWe prove the formalized statement $\\forall N \\in \\mathbb{N}\\; \\exists x \\in \\mathbb{N}\\; (x > N \\land P(x))$.\n\nLet $N$ be an arbitrary natural number. We need to exhibit a prime greater than $N$.  \nConsider the finite set of all primes that are $\\le N$. If there are no such primes, then $N < 2$ and we can simply take $2$ as a prime greater than $N$. Otherwise, let $p_1, p_2, \\dots, p_k$ be the list of all primes not exceeding $N$ (there is at least one, namely $2$).  \n\nDefine the number  \n\n$$\nM = p_1 p_2 \\cdots p_k + 1.\n$$\n\nClearly $M > 1$. By the fundamental theorem of arithmetic (or the simpler fact that every integer greater than $1$ has a prime divisor), $M$ has at least one prime divisor, call it $q$.\n\nWe claim that $q > N$.  \nSuppose, for contradiction, that $q \\le N$. Then $q$ would be one of the primes $p_1,\\dots,p_k$ because by construction those are **all** primes $\\le N$. But if $q = p_i$ for some $i$, then $p_i$ divides the product $p_1 p_2 \\cdots p_k$. Since $p_i$ also divides $M$, it would divide the difference  \n\n$$\nM - p_1 p_2 \\cdots p_k = 1,\n$$\n\nwhich is impossible because no prime divides $1$. Hence $q$ cannot be $\\le N$; therefore $q > N$.\n\nThus we have found a prime $q$ (namely, any prime divisor of $M$) that satisfies $q > N$. Since $N$ was arbitrary, we have shown  \n\n$$\n\\forall N \\in \\mathbb{N}\\; \\exists x \\in \\mathbb{N}\\; (x > N \\land P(x)).\n$$\n\nHence the statement \u201cthere are infinitely many prime numbers\u201d is true.\n\n\u220e\n\n## Additional Remarks\n\nThe proof above actually shows a stronger result: for any finite list of primes, there exists a prime not in that list. This directly contradicts the assumption that the set of primes is finite, establishing infinitude.\n\n## Conclusion\n\nThe formalization using $P(x)$ is correct, and the statement is true, as proven by Euclid\u2019s argument.",
        "raw_answer": "We are asked to formalize the statement \u201cThere are infinitely many prime numbers\u201d using the predicate \\(P(x)\\) (where \\(P(x)\\) means \u201c\\(x\\) is a prime number\u201d) and then determine its truth value, providing a proof if true or a counterexample if false.\n\n## Formalization\n\nLet the domain be the set of natural numbers \\(\\mathbb{N} = \\{1,2,3,\\dots\\}\\).  \nThe statement \u201cthere are infinitely many prime numbers\u201d means that the set of primes is unbounded; equivalently, for every natural number \\(N\\) there exists a prime larger than \\(N\\). Using the predicate \\(P(x)\\), this can be written as:\n\n\\[\n\\forall N \\in \\mathbb{N}\\; \\exists x \\in \\mathbb{N}\\; \\bigl( x > N \\;\\land\\; P(x) \\bigr).\n\\]\n\nAn equivalent formulation is\n\n\\[\n\\lnot \\exists N \\in \\mathbb{N}\\; \\forall x \\in \\mathbb{N}\\; \\bigl( P(x) \\to x \\le N \\bigr).\n\\]\n\nBoth capture the idea that there is no largest prime and that primes are infinite in number.\n\n## Truth Value\n\nThe statement is **true**.\n\n## Proof (Euclid\u2019s classic proof)\n\nWe prove the formalized statement \\(\\forall N \\in \\mathbb{N}\\; \\exists x \\in \\mathbb{N}\\; (x > N \\land P(x))\\).\n\nLet \\(N\\) be an arbitrary natural number. We need to exhibit a prime greater than \\(N\\).  \nConsider the finite set of all primes that are \\(\\le N\\). If there are no such primes, then \\(N < 2\\) and we can simply take \\(2\\) as a prime greater than \\(N\\). Otherwise, let \\(p_1, p_2, \\dots, p_k\\) be the list of all primes not exceeding \\(N\\) (there is at least one, namely \\(2\\)).  \n\nDefine the number  \n\n\\[\nM = p_1 p_2 \\cdots p_k + 1.\n\\]\n\nClearly \\(M > 1\\). By the fundamental theorem of arithmetic (or the simpler fact that every integer greater than \\(1\\) has a prime divisor), \\(M\\) has at least one prime divisor, call it \\(q\\).\n\nWe claim that \\(q > N\\).  \nSuppose, for contradiction, that \\(q \\le N\\). Then \\(q\\) would be one of the primes \\(p_1,\\dots,p_k\\) because by construction those are **all** primes \\(\\le N\\). But if \\(q = p_i\\) for some \\(i\\), then \\(p_i\\) divides the product \\(p_1 p_2 \\cdots p_k\\). Since \\(p_i\\) also divides \\(M\\), it would divide the difference  \n\n\\[\nM - p_1 p_2 \\cdots p_k = 1,\n\\]\n\nwhich is impossible because no prime divides \\(1\\). Hence \\(q\\) cannot be \\(\\le N\\); therefore \\(q > N\\).\n\nThus we have found a prime \\(q\\) (namely, any prime divisor of \\(M\\)) that satisfies \\(q > N\\). Since \\(N\\) was arbitrary, we have shown  \n\n\\[\n\\forall N \\in \\mathbb{N}\\; \\exists x \\in \\mathbb{N}\\; (x > N \\land P(x)).\n\\]\n\nHence the statement \u201cthere are infinitely many prime numbers\u201d is true.\n\n\u220e\n\n## Additional Remarks\n\nThe proof above actually shows a stronger result: for any finite list of primes, there exists a prime not in that list. This directly contradicts the assumption that the set of primes is finite, establishing infinitude.\n\n## Conclusion\n\nThe formalization using \\(P(x)\\) is correct, and the statement is true, as proven by Euclid\u2019s argument.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Determine whether the polynomial $p(x) = x^4 + 1$ is irreducible over the field $\\mathbb{Q}$ of rational numbers.",
    "run_id": "6",
    "outer_attempt": 4,
    "topic_slug": "field_theory_and_polynomials",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Solution:**\n\nWe determine whether $p(x)=x^4+1$ is irreducible over $\\mathbb{Q}$. A polynomial is irreducible over $\\mathbb{Q}$ if it cannot be written as a product of two non\u2011constant polynomials with rational coefficients.\n\nSince $\\deg p = 4$, any non\u2011trivial factorization must be of one of the following types:\n- a linear factor times a cubic factor, or\n- a product of two quadratic factors.\n\n(If a linear factor exists, it would already be covered by the first case; a product of four linear factors would contain a linear factor, etc. Hence it suffices to rule out these two possibilities.)\n\n---\n\n### 1. No linear factor\n\nSuppose $p(x)$ has a linear factor $x - r$ with $r \\in \\mathbb{Q}$. Then $r$ is a rational root. By the Rational Root Theorem, any rational root in lowest terms $p/q$ must satisfy $p \\mid 1$ and $q \\mid 1$; thus the only possible rational roots are $\\pm 1$. Evaluating:\n$$\np(1)=1^4+1=2\\neq 0,\\qquad p(-1)=(-1)^4+1=2\\neq 0.\n$$\nHence no rational root exists, and therefore $p(x)$ has no linear factor over $\\mathbb{Q}$.\n\n---\n\n### 2. No factorization into two quadratics\n\nAssume, for contradiction, that\n$$\np(x) = (x^2 + a x + b)(x^2 + c x + d)\n$$\nwith $a,b,c,d \\in \\mathbb{Q}$. (We may take both quadratics monic because the product of their leading coefficients must equal the leading coefficient 1 of $p$; any rational factorization can be scaled to this form without loss of generality.)\n\nExpanding the product gives\n$$\nx^4 + (a+c)x^3 + (ac + b + d)x^2 + (ad + bc)x + bd.\n$$\nEquating coefficients with $p(x)=x^4+0x^3+0x^2+0x+1$ yields the system:\n$$\n\\begin{cases}\na + c = 0 & (1)\\$$2pt]\nac + b + d = 0 & (2)\\$$2pt]\nad + bc = 0 & (3)\\$$2pt]\nbd = 1 & (4)\n\\end{cases}\n$$\n\nFrom (1) we have $c = -a$. Substitute into (3):\n$$\nad + b(-a) = a(d - b) = 0.\n$$\nThus either $a = 0$ or $d = b$.\n\n- **Case $a = 0$.** Then $c = 0$. Equation (2) becomes $0 + b + d = 0$, i.e., $d = -b$. Equation (4) gives $bd = -b^2 = 1$, so $b^2 = -1$. This has no solution in $\\mathbb{Q}$ (indeed no real solution). Contradiction.\n\n- **Case $d = b$.** Then (4) becomes $b^2 = 1$, so $b = 1$ or $b = -1$.  \n  Equation (2) becomes $ac + b + d = a(-a) + b + b = -a^2 + 2b = 0$, i.e., $a^2 = 2b$.  \n  * If $b = 1$, then $a^2 = 2$. No rational number squares to $2$ (since $\\sqrt{2}$ is irrational).  \n  * If $b = -1$, then $a^2 = -2$. No rational (or even real) number squares to a negative number.  \n  Both subcases lead to contradictions.\n\nSince every possible case yields a contradiction, there is no factorization of $p(x)$ into two quadratics with rational coefficients.\n\n---\n\n### Conclusion\n\n$p(x)$ has no linear factor and cannot be expressed as a product of two quadratic factors over $\\mathbb{Q}$. Therefore $p(x) = x^4 + 1$ is **irreducible** over $\\mathbb{Q}$. \u220e",
        "raw_answer": "**Solution:**\n\nWe determine whether \\(p(x)=x^4+1\\) is irreducible over \\(\\mathbb{Q}\\). A polynomial is irreducible over \\(\\mathbb{Q}\\) if it cannot be written as a product of two non\u2011constant polynomials with rational coefficients.\n\nSince \\(\\deg p = 4\\), any non\u2011trivial factorization must be of one of the following types:\n- a linear factor times a cubic factor, or\n- a product of two quadratic factors.\n\n(If a linear factor exists, it would already be covered by the first case; a product of four linear factors would contain a linear factor, etc. Hence it suffices to rule out these two possibilities.)\n\n---\n\n### 1. No linear factor\n\nSuppose \\(p(x)\\) has a linear factor \\(x - r\\) with \\(r \\in \\mathbb{Q}\\). Then \\(r\\) is a rational root. By the Rational Root Theorem, any rational root in lowest terms \\(p/q\\) must satisfy \\(p \\mid 1\\) and \\(q \\mid 1\\); thus the only possible rational roots are \\(\\pm 1\\). Evaluating:\n\\[\np(1)=1^4+1=2\\neq 0,\\qquad p(-1)=(-1)^4+1=2\\neq 0.\n\\]\nHence no rational root exists, and therefore \\(p(x)\\) has no linear factor over \\(\\mathbb{Q}\\).\n\n---\n\n### 2. No factorization into two quadratics\n\nAssume, for contradiction, that\n\\[\np(x) = (x^2 + a x + b)(x^2 + c x + d)\n\\]\nwith \\(a,b,c,d \\in \\mathbb{Q}\\). (We may take both quadratics monic because the product of their leading coefficients must equal the leading coefficient 1 of \\(p\\); any rational factorization can be scaled to this form without loss of generality.)\n\nExpanding the product gives\n\\[\nx^4 + (a+c)x^3 + (ac + b + d)x^2 + (ad + bc)x + bd.\n\\]\nEquating coefficients with \\(p(x)=x^4+0x^3+0x^2+0x+1\\) yields the system:\n\\[\n\\begin{cases}\na + c = 0 & (1)\\\\[2pt]\nac + b + d = 0 & (2)\\\\[2pt]\nad + bc = 0 & (3)\\\\[2pt]\nbd = 1 & (4)\n\\end{cases}\n\\]\n\nFrom (1) we have \\(c = -a\\). Substitute into (3):\n\\[\nad + b(-a) = a(d - b) = 0.\n\\]\nThus either \\(a = 0\\) or \\(d = b\\).\n\n- **Case \\(a = 0\\).** Then \\(c = 0\\). Equation (2) becomes \\(0 + b + d = 0\\), i.e., \\(d = -b\\). Equation (4) gives \\(bd = -b^2 = 1\\), so \\(b^2 = -1\\). This has no solution in \\(\\mathbb{Q}\\) (indeed no real solution). Contradiction.\n\n- **Case \\(d = b\\).** Then (4) becomes \\(b^2 = 1\\), so \\(b = 1\\) or \\(b = -1\\).  \n  Equation (2) becomes \\(ac + b + d = a(-a) + b + b = -a^2 + 2b = 0\\), i.e., \\(a^2 = 2b\\).  \n  * If \\(b = 1\\), then \\(a^2 = 2\\). No rational number squares to \\(2\\) (since \\(\\sqrt{2}\\) is irrational).  \n  * If \\(b = -1\\), then \\(a^2 = -2\\). No rational (or even real) number squares to a negative number.  \n  Both subcases lead to contradictions.\n\nSince every possible case yields a contradiction, there is no factorization of \\(p(x)\\) into two quadratics with rational coefficients.\n\n---\n\n### Conclusion\n\n\\(p(x)\\) has no linear factor and cannot be expressed as a product of two quadratic factors over \\(\\mathbb{Q}\\). Therefore \\(p(x) = x^4 + 1\\) is **irreducible** over \\(\\mathbb{Q}\\). \u220e",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $\\mathfrak{sl}(2, \\mathbb{R})$ be the Lie algebra of $2 \\times 2$ real matrices with trace zero, with the Lie bracket $[A, B] = AB - BA$. Show that the matrices $H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $X = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, and $Y = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$ form a basis for $\\mathfrak{sl}(2, \\mathbb{R})$ and compute the structure constants with respect to this basis.",
    "run_id": "11",
    "outer_attempt": 4,
    "topic_slug": "nonassociative_rings_and_algebras",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Answer:**\n\nLet $\\mathfrak{sl}(2,\\mathbb{R}) = \\{ A \\in M_2(\\mathbb{R}) \\mid \\operatorname{tr}(A) = 0 \\}$. This is a real vector space. Its dimension is $3$ because the trace is a non\u2011zero linear functional on the $4$-dimensional space $M_2(\\mathbb{R})$, so its kernel has dimension $4-1=3$.\n\nConsider the matrices\n$$\nH = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix},\\quad\nX = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix},\\quad\nY = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}.\n$$\n\n**1.  Belonging to $\\mathfrak{sl}(2,\\mathbb{R})$:**  \n$\\operatorname{tr}(H)=1+(-1)=0$, $\\operatorname{tr}(X)=0$, $\\operatorname{tr}(Y)=0$, so $H,X,Y \\in \\mathfrak{sl}(2,\\mathbb{R})$.\n\n**2.  Linear independence:**  \nSuppose $a H + b X + c Y = 0$ for some $a,b,c \\in \\mathbb{R}$. Then\n$$\n\\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix},\n$$\nso $a = b = c = 0$. Hence $\\{H,X,Y\\}$ is linearly independent.\n\n**3.  Spanning:**  \nLet $A = \\begin{pmatrix} p & q \\\\ r & s \\end{pmatrix} \\in \\mathfrak{sl}(2,\\mathbb{R})$. The condition $\\operatorname{tr}(A)=p+s=0$ gives $s = -p$. Thus\n$$\nA = \\begin{pmatrix} p & q \\\\ r & -p \\end{pmatrix} = p \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + q \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + r \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = p H + q X + r Y.\n$$\nTherefore every element of $\\mathfrak{sl}(2,\\mathbb{R})$ is a linear combination of $H,X,Y$.\n\nSince $\\{H,X,Y\\}$ is linearly independent and spans $\\mathfrak{sl}(2,\\mathbb{R})$, it is a basis.\n\n**4.  Lie brackets:**  \nWe compute the commutators using matrix multiplication.\n\n- $[H, X] = HX - XH$:\n$$\nHX = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = X,\n$$\n$$\nXH = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix} = -X,\n$$\nso $[H, X] = X - (-X) = 2X$.\n\n- $[H, Y] = HY - YH$:\n$$\nHY = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix} = -Y,\n$$\n$$\nYH = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = Y,\n$$\nso $[H, Y] = -Y - Y = -2Y$.\n\n- $[X, Y] = XY - YX$:\n$$\nXY = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix},\n$$\n$$\nYX = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix},\n$$\nso $[X, Y] = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = H$.\n\n**5.  Structure constants:**  \nChoose the ordered basis $\\{e_1, e_2, e_3\\} = \\{H, X, Y\\}$. The structure constants $c_{ij}^k \\in \\mathbb{R}$ are defined by\n$$\n[e_i, e_j] = \\sum_{k=1}^3 c_{ij}^k e_k.\n$$\nFrom the computed brackets:\n$$\n[e_1, e_2] = 2 e_2,\\quad\n[e_1, e_3] = -2 e_3,\\quad\n[e_2, e_3] = e_1.\n$$\nAll other brackets follow by antisymmetry: $[e_2, e_1] = -2 e_2$, $[e_3, e_1] = 2 e_3$, $[e_3, e_2] = - e_1$.\n\nThus the non\u2011zero structure constants (for $i<j$) are\n$$\nc_{12}^2 = 2,\\qquad c_{13}^3 = -2,\\qquad c_{23}^1 = 1.\n$$\nEquivalently, the full set of non\u2011zero constants (including those obtained from antisymmetry) is\n$$\nc_{12}^2 = 2,\\; c_{21}^2 = -2;\\quad\nc_{13}^3 = -2,\\; c_{31}^3 = 2;\\quad\nc_{23}^1 = 1,\\; c_{32}^1 = -1,\n$$\nand all other $c_{ij}^k$ are zero.\n\n**Conclusion:** The matrices $H, X, Y$ form a basis of $\\mathfrak{sl}(2,\\mathbb{R})$, and the structure constants with respect to this basis are as given above.",
        "raw_answer": "**Answer:**\n\nLet $\\mathfrak{sl}(2,\\mathbb{R}) = \\{ A \\in M_2(\\mathbb{R}) \\mid \\operatorname{tr}(A) = 0 \\}$. This is a real vector space. Its dimension is $3$ because the trace is a non\u2011zero linear functional on the $4$-dimensional space $M_2(\\mathbb{R})$, so its kernel has dimension $4-1=3$.\n\nConsider the matrices\n\\[\nH = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix},\\quad\nX = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix},\\quad\nY = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}.\n\\]\n\n**1.  Belonging to $\\mathfrak{sl}(2,\\mathbb{R})$:**  \n$\\operatorname{tr}(H)=1+(-1)=0$, $\\operatorname{tr}(X)=0$, $\\operatorname{tr}(Y)=0$, so $H,X,Y \\in \\mathfrak{sl}(2,\\mathbb{R})$.\n\n**2.  Linear independence:**  \nSuppose $a H + b X + c Y = 0$ for some $a,b,c \\in \\mathbb{R}$. Then\n\\[\n\\begin{pmatrix} a & b \\\\ c & -a \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix},\n\\]\nso $a = b = c = 0$. Hence $\\{H,X,Y\\}$ is linearly independent.\n\n**3.  Spanning:**  \nLet $A = \\begin{pmatrix} p & q \\\\ r & s \\end{pmatrix} \\in \\mathfrak{sl}(2,\\mathbb{R})$. The condition $\\operatorname{tr}(A)=p+s=0$ gives $s = -p$. Thus\n\\[\nA = \\begin{pmatrix} p & q \\\\ r & -p \\end{pmatrix} = p \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} + q \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + r \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = p H + q X + r Y.\n\\]\nTherefore every element of $\\mathfrak{sl}(2,\\mathbb{R})$ is a linear combination of $H,X,Y$.\n\nSince $\\{H,X,Y\\}$ is linearly independent and spans $\\mathfrak{sl}(2,\\mathbb{R})$, it is a basis.\n\n**4.  Lie brackets:**  \nWe compute the commutators using matrix multiplication.\n\n- $[H, X] = HX - XH$:\n\\[\nHX = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = X,\n\\]\n\\[\nXH = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix} = -X,\n\\]\nso $[H, X] = X - (-X) = 2X$.\n\n- $[H, Y] = HY - YH$:\n\\[\nHY = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix} = -Y,\n\\]\n\\[\nYH = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = Y,\n\\]\nso $[H, Y] = -Y - Y = -2Y$.\n\n- $[X, Y] = XY - YX$:\n\\[\nXY = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix},\n\\]\n\\[\nYX = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix},\n\\]\nso $[X, Y] = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = H$.\n\n**5.  Structure constants:**  \nChoose the ordered basis $\\{e_1, e_2, e_3\\} = \\{H, X, Y\\}$. The structure constants $c_{ij}^k \\in \\mathbb{R}$ are defined by\n\\[\n[e_i, e_j] = \\sum_{k=1}^3 c_{ij}^k e_k.\n\\]\nFrom the computed brackets:\n\\[\n[e_1, e_2] = 2 e_2,\\quad\n[e_1, e_3] = -2 e_3,\\quad\n[e_2, e_3] = e_1.\n\\]\nAll other brackets follow by antisymmetry: $[e_2, e_1] = -2 e_2$, $[e_3, e_1] = 2 e_3$, $[e_3, e_2] = - e_1$.\n\nThus the non\u2011zero structure constants (for $i<j$) are\n\\[\nc_{12}^2 = 2,\\qquad c_{13}^3 = -2,\\qquad c_{23}^1 = 1.\n\\]\nEquivalently, the full set of non\u2011zero constants (including those obtained from antisymmetry) is\n\\[\nc_{12}^2 = 2,\\; c_{21}^2 = -2;\\quad\nc_{13}^3 = -2,\\; c_{31}^3 = 2;\\quad\nc_{23}^1 = 1,\\; c_{32}^1 = -1,\n\\]\nand all other $c_{ij}^k$ are zero.\n\n**Conclusion:** The matrices $H, X, Y$ form a basis of $\\mathfrak{sl}(2,\\mathbb{R})$, and the structure constants with respect to this basis are as given above.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "## Step 1: Understand the task and the given domain\nThe task is to generate a challenging but solvable mathematics problem in the domain of special functions, along with a complete and verifiable solution. The given domain is special functions, and we need to create a problem that is simpler than the previously attempted questions but still challenging.\n\n## Step 2: Recall the properties and examples of special functions\nSpecial functions include the Gamma function, Bessel functions, elliptic functions, and others. The Gamma function, denoted by $\\Gamma(x)$, is defined as $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$ for $x > 0$. It has various properties and applications in mathematics and physics.\n\n## Step 3: Formulate a problem related to special functions\nTo create a problem, let's consider a basic property or application of special functions. One fundamental property is the Gamma function's relation to factorials for positive integers, given by $\\Gamma(n+1) = n!$. A simple and challenging problem could involve proving or verifying an identity or inequality related to the Gamma function.\n\n## Step 4: Generate a specific problem\nLet's consider the problem: \"Prove that $\\Gamma(x+1) = x\\Gamma(x)$ for $x > 0$, where $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.\"\n\n## Step 5: Provide a solution to the generated problem\nTo prove that $\\Gamma(x+1) = x\\Gamma(x)$, we start with the definition of $\\Gamma(x+1)$:\n$\\Gamma(x+1) = \\int_{0}^{\\infty} t^{x}e^{-t}dt$.\nUsing integration by parts with $u = t^x$ and $dv = e^{-t}dt$, we have $du = xt^{x-1}dt$ and $v = -e^{-t}$. Thus,\n$\\Gamma(x+1) = \\left[-t^xe^{-t}\\right]_{0}^{\\infty} + x\\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.\nThe first term vanishes at both limits because $e^{-t}$ decays faster than $t^x$ grows as $t \\to \\infty$ for $x > 0$, and at $t = 0$, $t^x = 0$ for $x > 0$. Thus,\n$\\Gamma(x+1) = x\\int_{0}^{\\infty} t^{x-1}e^{-t}dt = x\\Gamma(x)$.\n\n## Step 6: Format the problem and solution according to the required output format\n\nProve that $\\Gamma(x+1) = x\\Gamma(x)$ for $x > 0$, where $\\Gamma(x) = \\int_{0}^{\\infty} t^{x-1}e^{-t}dt$.",
    "run_id": "21",
    "outer_attempt": 3,
    "topic_slug": "special_functions",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "We are asked to prove the functional equation of the Gamma function:\n\n$$\n\\Gamma(x+1)=x\\,\\Gamma(x),\\qquad x>0,\n$$\n\nwhere\n\n$$\n\\Gamma(x)=\\int_{0}^{\\infty}t^{x-1}e^{-t}\\,dt.\n$$\n\n---\n\n### Proof\n\nFor $x>0$, the integrals defining $\\Gamma(x)$ and $\\Gamma(x+1)$ converge absolutely.  We start from the definition of $\\Gamma(x+1)$:\n\n$$\n\\Gamma(x+1)=\\int_{0}^{\\infty}t^{x}e^{-t}\\,dt.\n$$\n\nWe evaluate this integral using integration by parts.  To handle the improper limits, we first consider the integral over a finite interval $[a,b]$ with $0<a<b<\\infty$ and then take the limits $a\\to0^+$ and $b\\to\\infty$.\n\nFor any $0<a<b<\\infty$, set\n\n$$\nu = t^{x},\\qquad dv = e^{-t}\\,dt.\n$$\n\nThen\n\n$$\ndu = x\\,t^{x-1}\\,dt,\\qquad v = -e^{-t}.\n$$\n\nIntegration by parts gives\n\n$$\n\\int_{a}^{b} t^{x}e^{-t}\\,dt = \\bigl[ u\\,v \\bigr]_{a}^{b} - \\int_{a}^{b} v\\,du\n= \\Bigl[ -t^{x}e^{-t} \\Bigr]_{a}^{b} - \\int_{a}^{b} (-e^{-t})\\,x\\,t^{x-1}\\,dt.\n$$\n\nThus\n\n$$\n\\int_{a}^{b} t^{x}e^{-t}\\,dt = -\\Bigl[ t^{x}e^{-t} \\Bigr]_{a}^{b} + x\\int_{a}^{b} t^{x-1}e^{-t}\\,dt.\n$$\n\nNow we examine the boundary term as $a\\to0^+$ and $b\\to\\infty$.\n\n* **Limit as $b\\to\\infty$:**  For fixed $x>0$, $t^{x}e^{-t}\\to0$ as $t\\to\\infty$ because the exponential decay dominates any polynomial growth.  More formally, using e.g. L'H\u00f4pital's rule repeatedly, one finds $\\lim_{t\\to\\infty}t^{x}e^{-t}=0$.\n\n* **Limit as $a\\to0^+$:**  Since $x>0$, $t^{x}\\to0$ as $t\\to0^+$, and $e^{-t}\\to1$.  Hence $\\lim_{a\\to0^+} a^{x}e^{-a}=0$.\n\nTherefore\n\n$$\n\\lim_{\\substack{a\\to0^+\\\\ b\\to\\infty}} \\Bigl[ -t^{x}e^{-t} \\Bigr]_{a}^{b}\n= -\\Bigl( \\lim_{b\\to\\infty} b^{x}e^{-b} - \\lim_{a\\to0^+} a^{x}e^{-a} \\Bigr) = -(0-0)=0.\n$$\n\nTaking the limits in the remaining integral, we obtain\n\n$$\n\\lim_{\\substack{a\\to0^+\\\\ b\\to\\infty}} x\\int_{a}^{b} t^{x-1}e^{-t}\\,dt = x\\int_{0}^{\\infty} t^{x-1}e^{-t}\\,dt = x\\,\\Gamma(x).\n$$\n\nAll limits exist, so\n\n$$\n\\Gamma(x+1) = \\int_{0}^{\\infty} t^{x}e^{-t}\\,dt = 0 + x\\,\\Gamma(x) = x\\,\\Gamma(x).\n$$\n\nThis completes the proof. \u220e\n\n---\n\n### Remarks\n\n* The condition $x>0$ is essential: it guarantees the convergence of the integrals at both endpoints and ensures that the boundary term vanishes at $t=0$.  For $x\\le0$ the definition of $\\Gamma(x)$ is not given by the integral above; the functional equation can be used to analytically continue the Gamma function.\n\n* The proof is rigorous because we justified the vanishing of the boundary term and the interchange of limits with the integration by parts by first working on a compact interval and then passing to the limits.\n\nThus we have shown $\\Gamma(x+1)=x\\,\\Gamma(x)$ for all $x>0$.",
        "raw_answer": "We are asked to prove the functional equation of the Gamma function:\n\n\\[\n\\Gamma(x+1)=x\\,\\Gamma(x),\\qquad x>0,\n\\]\n\nwhere\n\n\\[\n\\Gamma(x)=\\int_{0}^{\\infty}t^{x-1}e^{-t}\\,dt.\n\\]\n\n---\n\n### Proof\n\nFor \\(x>0\\), the integrals defining \\(\\Gamma(x)\\) and \\(\\Gamma(x+1)\\) converge absolutely.  We start from the definition of \\(\\Gamma(x+1)\\):\n\n\\[\n\\Gamma(x+1)=\\int_{0}^{\\infty}t^{x}e^{-t}\\,dt.\n\\]\n\nWe evaluate this integral using integration by parts.  To handle the improper limits, we first consider the integral over a finite interval \\([a,b]\\) with \\(0<a<b<\\infty\\) and then take the limits \\(a\\to0^+\\) and \\(b\\to\\infty\\).\n\nFor any \\(0<a<b<\\infty\\), set\n\n\\[\nu = t^{x},\\qquad dv = e^{-t}\\,dt.\n\\]\n\nThen\n\n\\[\ndu = x\\,t^{x-1}\\,dt,\\qquad v = -e^{-t}.\n\\]\n\nIntegration by parts gives\n\n\\[\n\\int_{a}^{b} t^{x}e^{-t}\\,dt = \\bigl[ u\\,v \\bigr]_{a}^{b} - \\int_{a}^{b} v\\,du\n= \\Bigl[ -t^{x}e^{-t} \\Bigr]_{a}^{b} - \\int_{a}^{b} (-e^{-t})\\,x\\,t^{x-1}\\,dt.\n\\]\n\nThus\n\n\\[\n\\int_{a}^{b} t^{x}e^{-t}\\,dt = -\\Bigl[ t^{x}e^{-t} \\Bigr]_{a}^{b} + x\\int_{a}^{b} t^{x-1}e^{-t}\\,dt.\n\\]\n\nNow we examine the boundary term as \\(a\\to0^+\\) and \\(b\\to\\infty\\).\n\n* **Limit as \\(b\\to\\infty\\):**  For fixed \\(x>0\\), \\(t^{x}e^{-t}\\to0\\) as \\(t\\to\\infty\\) because the exponential decay dominates any polynomial growth.  More formally, using e.g. L'H\u00f4pital's rule repeatedly, one finds \\(\\lim_{t\\to\\infty}t^{x}e^{-t}=0\\).\n\n* **Limit as \\(a\\to0^+\\):**  Since \\(x>0\\), \\(t^{x}\\to0\\) as \\(t\\to0^+\\), and \\(e^{-t}\\to1\\).  Hence \\(\\lim_{a\\to0^+} a^{x}e^{-a}=0\\).\n\nTherefore\n\n\\[\n\\lim_{\\substack{a\\to0^+\\\\ b\\to\\infty}} \\Bigl[ -t^{x}e^{-t} \\Bigr]_{a}^{b}\n= -\\Bigl( \\lim_{b\\to\\infty} b^{x}e^{-b} - \\lim_{a\\to0^+} a^{x}e^{-a} \\Bigr) = -(0-0)=0.\n\\]\n\nTaking the limits in the remaining integral, we obtain\n\n\\[\n\\lim_{\\substack{a\\to0^+\\\\ b\\to\\infty}} x\\int_{a}^{b} t^{x-1}e^{-t}\\,dt = x\\int_{0}^{\\infty} t^{x-1}e^{-t}\\,dt = x\\,\\Gamma(x).\n\\]\n\nAll limits exist, so\n\n\\[\n\\Gamma(x+1) = \\int_{0}^{\\infty} t^{x}e^{-t}\\,dt = 0 + x\\,\\Gamma(x) = x\\,\\Gamma(x).\n\\]\n\nThis completes the proof. \u220e\n\n---\n\n### Remarks\n\n* The condition \\(x>0\\) is essential: it guarantees the convergence of the integrals at both endpoints and ensures that the boundary term vanishes at \\(t=0\\).  For \\(x\\le0\\) the definition of \\(\\Gamma(x)\\) is not given by the integral above; the functional equation can be used to analytically continue the Gamma function.\n\n* The proof is rigorous because we justified the vanishing of the boundary term and the interchange of limits with the integration by parts by first working on a compact interval and then passing to the limits.\n\nThus we have shown \\(\\Gamma(x+1)=x\\,\\Gamma(x)\\) for all \\(x>0\\).",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $G$ be a finite abelian group and $\\mu$ be the counting measure on $G$. For $f \\in L^2(G, \\mu)$, define the Fourier transform $\\hat{f}: \\hat{G} \\to \\mathbb{C}$ by $\\hat{f}(\\chi) = \\sum_{x \\in G} f(x) \\overline{\\chi(x)}$, where $\\hat{G}$ is the dual group of $G$. Prove that the inverse Fourier transform of $\\hat{f}$ is given by $f(x) = \\frac{1}{|G|} \\sum_{\\chi \\in \\hat{G}} \\hat{f}(\\chi) \\chi(x)$ for all $x \\in G$.",
    "run_id": "29",
    "outer_attempt": 3,
    "topic_slug": "abstract_harmonic_analysis",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Proof.** Let $N = |G|$. The dual group $\\widehat{G}$ consists of all group homomorphisms $\\chi: G \\to \\mathbb{S}^1$, where $\\mathbb{S}^1 = \\{z \\in \\mathbb{C}: |z| = 1\\}$.\n\nWe first establish the orthogonality relations for characters.\n\n**Lemma 1 (Orthogonality).** For any $\\chi, \\psi \\in \\widehat{G}$,\n$$\n\\sum_{x \\in G} \\chi(x) \\overline{\\psi(x)} = N \\,\\delta_{\\chi,\\psi}.\n$$\n\n*Proof.* If $\\chi = \\psi$, then $\\chi(x)\\overline{\\chi(x)} = |\\chi(x)|^2 = 1$ for every $x$, so the sum equals $N$. If $\\chi \\neq \\psi$, define $\\lambda(x) = \\chi(x) \\overline{\\psi(x)}$. Since $\\overline{\\psi}$ is also a character ($\\overline{\\psi}(x) = \\psi(x)^{-1}$) and the product of characters is a character, $\\lambda \\in \\widehat{G}$. Moreover, $\\lambda \\neq \\mathbf{1}$ (the trivial character) because $\\chi \\neq \\psi$. Hence there exists $a \\in G$ such that $\\lambda(a) \\neq 1$. Now compute\n$$\n\\sum_{x \\in G} \\lambda(x) = \\sum_{x \\in G} \\lambda(ax) = \\lambda(a) \\sum_{x \\in G} \\lambda(x),\n$$\nwhere the first equality follows from the fact that $x \\mapsto ax$ is a permutation of $G$. Thus $(1 - \\lambda(a)) \\sum_{x} \\lambda(x) = 0$, and since $1 - \\lambda(a) \\neq 0$, we obtain $\\sum_{x} \\lambda(x) = 0$. But $\\sum_{x} \\lambda(x) = \\sum_{x} \\chi(x) \\overline{\\psi(x)}$, which completes the proof. \u220e\n\nNext, we need the size of the dual group.\n\n**Lemma 2.** $|\\widehat{G}| = N$.\n\n*Proof.* Because $G$ is a finite abelian group, it decomposes as a direct product of cyclic groups:\n$$\nG \\cong \\mathbb{Z}/n_1\\mathbb{Z} \\times \\cdots \\times \\mathbb{Z}/n_k\\mathbb{Z},\n$$\nwhere $n_i \\ge 2$ and $\\prod_{i=1}^k n_i = N$. For each cyclic factor $\\mathbb{Z}/n_i\\mathbb{Z}$, its dual group consists of the $n_i$ characters $\\chi^{(i)}_t$ ($t = 0,\\dots,n_i-1$) given by $\\chi^{(i)}_t(m_i) = e^{2\\pi i t m_i / n_i}$, where $m_i$ is an integer mod $n_i$. For the direct product, every character $\\chi$ of $G$ is uniquely determined by its restrictions to the factors, i.e., $\\chi = \\chi^{(1)}_{t_1} \\otimes \\cdots \\otimes \\chi^{(k)}_{t_k}$ with $t_i \\in \\{0,\\dots,n_i-1\\}$. Consequently, there are exactly $\\prod_{i=1}^k n_i = N$ distinct characters. \u220e\n\nNow consider the vector space $V = \\mathbb{C}^G$ of all complex-valued functions on $G$, equipped with the inner product\n$$\n\\langle f, g \\rangle = \\sum_{x \\in G} f(x) \\overline{g(x)}.\n$$\nThe dimension of $V$ is $N$. From Lemma 1, the family $\\{ \\chi/\\sqrt{N} : \\chi \\in \\widehat{G} \\}$ is an orthonormal set in $V$:\n$$\n\\left\\langle \\frac{\\chi}{\\sqrt{N}}, \\frac{\\psi}{\\sqrt{N}} \\right\\rangle = \\frac{1}{N} \\sum_{x \\in G} \\chi(x) \\overline{\\psi(x)} = \\delta_{\\chi,\\psi}.\n$$\nBy Lemma 2, this orthonormal set has size $N$, hence it is an orthonormal basis of $V$.\n\nTherefore, any $f \\in V$ can be expanded in this basis:\n$$\nf = \\sum_{\\chi \\in \\widehat{G}} \\left\\langle f, \\frac{\\chi}{\\sqrt{N}} \\right\\rangle \\frac{\\chi}{\\sqrt{N}}\n= \\frac{1}{N} \\sum_{\\chi \\in \\widehat{G}} \\langle f, \\chi \\rangle \\, \\chi.\n$$\nBut $\\langle f, \\chi \\rangle = \\sum_{x \\in G} f(x) \\overline{\\chi(x)} = \\widehat{f}(\\chi)$. Substituting this and evaluating at $x \\in G$ yields\n$$\nf(x) = \\frac{1}{N} \\sum_{\\chi \\in \\widehat{G}} \\widehat{f}(\\chi) \\, \\chi(x).\n$$\nThis is precisely the claimed inverse Fourier transform formula. \u220e\n\n(Note: Since $G$ is finite, $L^2(G,\\mu) = \\mathbb{C}^G$, so the result holds for all $f \\in L^2(G,\\mu)$.)",
        "raw_answer": "**Proof.** Let $N = |G|$. The dual group $\\widehat{G}$ consists of all group homomorphisms $\\chi: G \\to \\mathbb{S}^1$, where $\\mathbb{S}^1 = \\{z \\in \\mathbb{C}: |z| = 1\\}$.\n\nWe first establish the orthogonality relations for characters.\n\n**Lemma 1 (Orthogonality).** For any $\\chi, \\psi \\in \\widehat{G}$,\n\\[\n\\sum_{x \\in G} \\chi(x) \\overline{\\psi(x)} = N \\,\\delta_{\\chi,\\psi}.\n\\]\n\n*Proof.* If $\\chi = \\psi$, then $\\chi(x)\\overline{\\chi(x)} = |\\chi(x)|^2 = 1$ for every $x$, so the sum equals $N$. If $\\chi \\neq \\psi$, define $\\lambda(x) = \\chi(x) \\overline{\\psi(x)}$. Since $\\overline{\\psi}$ is also a character ($\\overline{\\psi}(x) = \\psi(x)^{-1}$) and the product of characters is a character, $\\lambda \\in \\widehat{G}$. Moreover, $\\lambda \\neq \\mathbf{1}$ (the trivial character) because $\\chi \\neq \\psi$. Hence there exists $a \\in G$ such that $\\lambda(a) \\neq 1$. Now compute\n\\[\n\\sum_{x \\in G} \\lambda(x) = \\sum_{x \\in G} \\lambda(ax) = \\lambda(a) \\sum_{x \\in G} \\lambda(x),\n\\]\nwhere the first equality follows from the fact that $x \\mapsto ax$ is a permutation of $G$. Thus $(1 - \\lambda(a)) \\sum_{x} \\lambda(x) = 0$, and since $1 - \\lambda(a) \\neq 0$, we obtain $\\sum_{x} \\lambda(x) = 0$. But $\\sum_{x} \\lambda(x) = \\sum_{x} \\chi(x) \\overline{\\psi(x)}$, which completes the proof. \u220e\n\nNext, we need the size of the dual group.\n\n**Lemma 2.** $|\\widehat{G}| = N$.\n\n*Proof.* Because $G$ is a finite abelian group, it decomposes as a direct product of cyclic groups:\n\\[\nG \\cong \\mathbb{Z}/n_1\\mathbb{Z} \\times \\cdots \\times \\mathbb{Z}/n_k\\mathbb{Z},\n\\]\nwhere $n_i \\ge 2$ and $\\prod_{i=1}^k n_i = N$. For each cyclic factor $\\mathbb{Z}/n_i\\mathbb{Z}$, its dual group consists of the $n_i$ characters $\\chi^{(i)}_t$ ($t = 0,\\dots,n_i-1$) given by $\\chi^{(i)}_t(m_i) = e^{2\\pi i t m_i / n_i}$, where $m_i$ is an integer mod $n_i$. For the direct product, every character $\\chi$ of $G$ is uniquely determined by its restrictions to the factors, i.e., $\\chi = \\chi^{(1)}_{t_1} \\otimes \\cdots \\otimes \\chi^{(k)}_{t_k}$ with $t_i \\in \\{0,\\dots,n_i-1\\}$. Consequently, there are exactly $\\prod_{i=1}^k n_i = N$ distinct characters. \u220e\n\nNow consider the vector space $V = \\mathbb{C}^G$ of all complex-valued functions on $G$, equipped with the inner product\n\\[\n\\langle f, g \\rangle = \\sum_{x \\in G} f(x) \\overline{g(x)}.\n\\]\nThe dimension of $V$ is $N$. From Lemma 1, the family $\\{ \\chi/\\sqrt{N} : \\chi \\in \\widehat{G} \\}$ is an orthonormal set in $V$:\n\\[\n\\left\\langle \\frac{\\chi}{\\sqrt{N}}, \\frac{\\psi}{\\sqrt{N}} \\right\\rangle = \\frac{1}{N} \\sum_{x \\in G} \\chi(x) \\overline{\\psi(x)} = \\delta_{\\chi,\\psi}.\n\\]\nBy Lemma 2, this orthonormal set has size $N$, hence it is an orthonormal basis of $V$.\n\nTherefore, any $f \\in V$ can be expanded in this basis:\n\\[\nf = \\sum_{\\chi \\in \\widehat{G}} \\left\\langle f, \\frac{\\chi}{\\sqrt{N}} \\right\\rangle \\frac{\\chi}{\\sqrt{N}}\n= \\frac{1}{N} \\sum_{\\chi \\in \\widehat{G}} \\langle f, \\chi \\rangle \\, \\chi.\n\\]\nBut $\\langle f, \\chi \\rangle = \\sum_{x \\in G} f(x) \\overline{\\chi(x)} = \\widehat{f}(\\chi)$. Substituting this and evaluating at $x \\in G$ yields\n\\[\nf(x) = \\frac{1}{N} \\sum_{\\chi \\in \\widehat{G}} \\widehat{f}(\\chi) \\, \\chi(x).\n\\]\nThis is precisely the claimed inverse Fourier transform formula. \u220e\n\n(Note: Since $G$ is finite, $L^2(G,\\mu) = \\mathbb{C}^G$, so the result holds for all $f \\in L^2(G,\\mu)$.)",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $M$ be a 2-dimensional manifold homeomorphic to a sphere with $g$ handles. Prove that the Euler characteristic $\\chi(M)$ of $M$ is given by $\\chi(M) = 2 - 2g$.",
    "run_id": "40",
    "outer_attempt": 3,
    "topic_slug": "manifolds_and_cell_complexes",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "**Proof.**  \n\nThe Euler characteristic $\\chi(X)$ of a finite CW complex $X$ is defined as  \n$$\n\\chi(X)=\\sum_{i=0}^{\\dim X}(-1)^i\\,(\\text{number of }i\\text{-cells}).\n$$  \nIt is a topological invariant: homeomorphic spaces have the same Euler characteristic. Hence we may compute $\\chi(M)$ using any convenient CW structure on $M$.\n\nWe distinguish two cases.\n\n---\n\n**Case $g = 0$.**  \nThen $M$ is the $2$-sphere $S^2$. A simple CW structure on $S^2$ consists of one $0$-cell and one $2$-cell attached by the constant map (the boundary of the disk is collapsed to the $0$-cell). This gives  \n$$\n\\chi(S^2)=1-0+1=2,\n$$  \nwhich agrees with $2-2\\cdot0=2$.\n\n---\n\n**Case $g \\ge 1$.**  \nA sphere with $g$ handles is known to be homeomorphic to the orientable closed surface of genus $g$. Such a surface can be constructed as the quotient space of a regular $4g$-gon by identifying its edges in pairs according to the scheme  \n\n$$\na_1 b_1 a_1^{-1} b_1^{-1}\\; a_2 b_2 a_2^{-1} b_2^{-1}\\;\\cdots\\; a_g b_g a_g^{-1} b_g^{-1}.\n$$\n\nMore explicitly, label the edges of the polygon consecutively as  \n\n$$\na_1,\\; b_1,\\; a_1',\\; b_1',\\; a_2,\\; b_2,\\; a_2',\\; b_2',\\;\\dots,\\; a_g,\\; b_g,\\; a_g',\\; b_g',\n$$\n\nand then identify $a_i$ with $a_i'$ and $b_i$ with $b_i'$, reversing the orientation (so that the arrow on $a_i$ points opposite to the arrow on $a_i'$, and similarly for $b_i$). Under these identifications, all $4g$ vertices of the polygon become identified to a single point. (One can verify this by tracing the vertex cycles: starting from any vertex and following the edge identifications brings one to every other vertex.)\n\nThe quotient space $X$ obtained in this way is a compact $2$-dimensional CW complex with  \n\n* one $0$-cell: the unique vertex,  \n* $2g$ $1$-cells: each pair $(a_i,a_i')$ and $(b_i,b_i')$ yields one $1$-cell,  \n* one $2$-cell: the interior of the polygon, attached to the $1$-skeleton via the map that sends the boundary to the sequence of edges $a_1b_1a_1^{-1}b_1^{-1}\\cdots a_g b_g a_g^{-1}b_g^{-1}$.\n\nIt is a standard fact (and can be checked locally) that $X$ is a closed $2$-manifold without boundary and is homeomorphic to a sphere with $g$ handles, i.e., to $M$. Therefore,  \n\n$$\n\\chi(M)=\\chi(X)=1-2g+1=2-2g.\n$$\n\n---\n\nCombining both cases, we conclude that for every integer $g\\ge 0$,  \n\n$$\n\\boxed{\\chi(M)=2-2g}.\n$$",
        "raw_answer": "**Proof.**  \n\nThe Euler characteristic \\(\\chi(X)\\) of a finite CW complex \\(X\\) is defined as  \n\\[\n\\chi(X)=\\sum_{i=0}^{\\dim X}(-1)^i\\,(\\text{number of }i\\text{-cells}).\n\\]  \nIt is a topological invariant: homeomorphic spaces have the same Euler characteristic. Hence we may compute \\(\\chi(M)\\) using any convenient CW structure on \\(M\\).\n\nWe distinguish two cases.\n\n---\n\n**Case \\(g = 0\\).**  \nThen \\(M\\) is the \\(2\\)-sphere \\(S^2\\). A simple CW structure on \\(S^2\\) consists of one \\(0\\)-cell and one \\(2\\)-cell attached by the constant map (the boundary of the disk is collapsed to the \\(0\\)-cell). This gives  \n\\[\n\\chi(S^2)=1-0+1=2,\n\\]  \nwhich agrees with \\(2-2\\cdot0=2\\).\n\n---\n\n**Case \\(g \\ge 1\\).**  \nA sphere with \\(g\\) handles is known to be homeomorphic to the orientable closed surface of genus \\(g\\). Such a surface can be constructed as the quotient space of a regular \\(4g\\)-gon by identifying its edges in pairs according to the scheme  \n\n\\[\na_1 b_1 a_1^{-1} b_1^{-1}\\; a_2 b_2 a_2^{-1} b_2^{-1}\\;\\cdots\\; a_g b_g a_g^{-1} b_g^{-1}.\n\\]\n\nMore explicitly, label the edges of the polygon consecutively as  \n\n\\[\na_1,\\; b_1,\\; a_1',\\; b_1',\\; a_2,\\; b_2,\\; a_2',\\; b_2',\\;\\dots,\\; a_g,\\; b_g,\\; a_g',\\; b_g',\n\\]\n\nand then identify \\(a_i\\) with \\(a_i'\\) and \\(b_i\\) with \\(b_i'\\), reversing the orientation (so that the arrow on \\(a_i\\) points opposite to the arrow on \\(a_i'\\), and similarly for \\(b_i\\)). Under these identifications, all \\(4g\\) vertices of the polygon become identified to a single point. (One can verify this by tracing the vertex cycles: starting from any vertex and following the edge identifications brings one to every other vertex.)\n\nThe quotient space \\(X\\) obtained in this way is a compact \\(2\\)-dimensional CW complex with  \n\n* one \\(0\\)-cell: the unique vertex,  \n* \\(2g\\) \\(1\\)-cells: each pair \\((a_i,a_i')\\) and \\((b_i,b_i')\\) yields one \\(1\\)-cell,  \n* one \\(2\\)-cell: the interior of the polygon, attached to the \\(1\\)-skeleton via the map that sends the boundary to the sequence of edges \\(a_1b_1a_1^{-1}b_1^{-1}\\cdots a_g b_g a_g^{-1}b_g^{-1}\\).\n\nIt is a standard fact (and can be checked locally) that \\(X\\) is a closed \\(2\\)-manifold without boundary and is homeomorphic to a sphere with \\(g\\) handles, i.e., to \\(M\\). Therefore,  \n\n\\[\n\\chi(M)=\\chi(X)=1-2g+1=2-2g.\n\\]\n\n---\n\nCombining both cases, we conclude that for every integer \\(g\\ge 0\\),  \n\n\\[\n\\boxed{\\chi(M)=2-2g}.\n\\]",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": false,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  },
  {
    "question_model": "meta-llama-llama-4-maverick",
    "answer_model": "deepseek-deepseek-v3.2-speciale",
    "question": "Let $D = \\{x \\in \\mathbb{R}^2: |x| < 1\\}$ be the unit disk in $\\mathbb{R}^2$. Find the solution $u(x)$ to the Dirichlet problem $\\Delta u = 0$ in $D$, $u(x) = \\log|x - (1,0)|$ on $\\partial D$.",
    "run_id": "19",
    "outer_attempt": 5,
    "topic_slug": "potential_theory",
    "status": "succeeded",
    "attempts": [
      {
        "round": 1,
        "answer": "The question is ill\u2011posed for the following reasons.\n\n1. **Undefined boundary condition.**  \n   The Dirichlet data is given as $u(x)=\\log|x-(1,0)|$ for all $x\\in\\partial D$.  \n   At $x=(1,0)\\in\\partial D$ the right\u2011hand side is $\\log 0$, which is undefined in $\\mathbb{R}$.  \n   Hence the boundary condition is not a function from $\\partial D$ to $\\mathbb{R}$, violating the requirement that a Dirichlet problem be properly specified.\n\n2. **Non\u2011uniqueness even after a natural interpretation.**  \n   If we interpret the condition as  \n   $$\n   u(x)=\\log|x-(1,0)|\\quad\\text{for }x\\in\\partial D\\setminus\\{(1,0)\\},\\qquad\n   \\lim_{x\\to(1,0)}u(x)=-\\infty,\n   $$  \n   the solution is not unique. For any constant $c\\le 0$, the function  \n   $$\n   u_c(x)=\\log|x-(1,0)|+c\\,\\frac{1-|x|^2}{|x-(1,0)|^2}\n   $$  \n   is harmonic in $D$ (the added term is a multiple of the Poisson kernel with pole at $(1,0)$).  \n   For every $\\xi\\in\\partial D\\setminus\\{(1,0)\\}$, $u_c(x)\\to\\log|\\xi-(1,0)|$ as $x\\to\\xi$, and  \n   $u_c(x)\\to-\\infty$ as $x\\to(1,0)$. Thus there are infinitely many distinct solutions.\n\nWithout additional constraints (e.g., boundedness away from the singularity, a prescribed growth rate, or the requirement that $u$ be given by the Poisson integral of the data), the problem is underspecified and does not admit a unique answer. Consequently, the question is ill\u2011posed.",
        "raw_answer": "The question is ill\u2011posed for the following reasons.\n\n1. **Undefined boundary condition.**  \n   The Dirichlet data is given as \\(u(x)=\\log|x-(1,0)|\\) for all \\(x\\in\\partial D\\).  \n   At \\(x=(1,0)\\in\\partial D\\) the right\u2011hand side is \\(\\log 0\\), which is undefined in \\(\\mathbb{R}\\).  \n   Hence the boundary condition is not a function from \\(\\partial D\\) to \\(\\mathbb{R}\\), violating the requirement that a Dirichlet problem be properly specified.\n\n2. **Non\u2011uniqueness even after a natural interpretation.**  \n   If we interpret the condition as  \n   \\[\n   u(x)=\\log|x-(1,0)|\\quad\\text{for }x\\in\\partial D\\setminus\\{(1,0)\\},\\qquad\n   \\lim_{x\\to(1,0)}u(x)=-\\infty,\n   \\]  \n   the solution is not unique. For any constant \\(c\\le 0\\), the function  \n   \\[\n   u_c(x)=\\log|x-(1,0)|+c\\,\\frac{1-|x|^2}{|x-(1,0)|^2}\n   \\]  \n   is harmonic in \\(D\\) (the added term is a multiple of the Poisson kernel with pole at \\((1,0)\\)).  \n   For every \\(\\xi\\in\\partial D\\setminus\\{(1,0)\\}\\), \\(u_c(x)\\to\\log|\\xi-(1,0)|\\) as \\(x\\to\\xi\\), and  \n   \\(u_c(x)\\to-\\infty\\) as \\(x\\to(1,0)\\). Thus there are infinitely many distinct solutions.\n\nWithout additional constraints (e.g., boundedness away from the singularity, a prescribed growth rate, or the requirement that \\(u\\) be given by the Poisson integral of the data), the problem is underspecified and does not admit a unique answer. Consequently, the question is ill\u2011posed.",
        "evaluation": {
          "verdict": "pass",
          "ill_posed": true,
          "issues": [],
          "improvements": ""
        }
      }
    ]
  }
]