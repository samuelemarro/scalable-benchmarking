[
  {
    "run_id": "1",
    "outer_attempt": 1,
    "topic_slug": "mathematical_logic_and_foundations",
    "topic_name": "Mathematical logic and foundations",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $(\\varphi_e)_{e \\in \\mathbb{N}}$ be a standard acceptable numbering of all partial recursive functions (for instance, derived from a fixed enumeration of Turing machines). Define\n$$\n\\mathrm{Tot} = \\{ e \\in \\mathbb{N} \\mid \\varphi_e \\text{ is total} \\}.\n$$\nProve that $\\mathrm{Tot}$ is not recursively enumerable.",
            "answer": "Assume, for contradiction, that $\\mathrm{Tot}$ is recursively enumerable. Then there exists a total computable function $f \\colon \\mathbb{N} \\to \\mathbb{N}$ whose range is exactly $\\mathrm{Tot}$. (This is a basic fact: every r.e. set is the range of some total recursive function.)\n\nDefine a function $g \\colon \\mathbb{N} \\to \\mathbb{N}$ by\n$$\ng(x) = \\varphi_{f(x)}(x) + 1.\n$$\nBecause $f(x) \\in \\mathrm{Tot}$, the function $\\varphi_{f(x)}$ is total, so $\\varphi_{f(x)}(x)$ is defined and the computation halts. Moreover, the procedure to compute $g$ is effective: on input $x$, first compute $f(x)$ (possible since $f$ is computable), then simulate a universal Turing machine on the pair $(f(x), x)$; by totality of $\\varphi_{f(x)}$ this simulation eventually halts and yields a value; finally add $1$. Hence $g$ is total computable.\n\nSince $g$ is total computable, it has an index $e_0$ in the numbering, i.e., $\\varphi_{e_0} = g$. Consequently, $e_0 \\in \\mathrm{Tot}$.\n\nBecause the range of $f$ is $\\mathrm{Tot}$, there exists some $n \\in \\mathbb{N}$ such that $f(n) = e_0$. Evaluating $g$ at $n$ gives:\n$$\ng(n) = \\varphi_{f(n)}(n) + 1 = \\varphi_{e_0}(n) + 1 = g(n) + 1,\n$$\nwhich is a contradiction. Therefore our assumption was false, and $\\mathrm{Tot}$ is not recursively enumerable. $\\square$",
            "raw_answer": "[QUESTION]\nLet $(\\varphi_e)_{e \\in \\mathbb{N}}$ be a standard acceptable numbering of all partial recursive functions (for instance, derived from a fixed enumeration of Turing machines). Define\n\\[\n\\mathrm{Tot} = \\{ e \\in \\mathbb{N} \\mid \\varphi_e \\text{ is total} \\}.\n\\]\nProve that $\\mathrm{Tot}$ is not recursively enumerable.\n\n[ANSWER]\nAssume, for contradiction, that $\\mathrm{Tot}$ is recursively enumerable. Then there exists a total computable function $f \\colon \\mathbb{N} \\to \\mathbb{N}$ whose range is exactly $\\mathrm{Tot}$. (This is a basic fact: every r.e. set is the range of some total recursive function.)\n\nDefine a function $g \\colon \\mathbb{N} \\to \\mathbb{N}$ by\n\\[\ng(x) = \\varphi_{f(x)}(x) + 1.\n\\]\nBecause $f(x) \\in \\mathrm{Tot}$, the function $\\varphi_{f(x)}$ is total, so $\\varphi_{f(x)}(x)$ is defined and the computation halts. Moreover, the procedure to compute $g$ is effective: on input $x$, first compute $f(x)$ (possible since $f$ is computable), then simulate a universal Turing machine on the pair $(f(x), x)$; by totality of $\\varphi_{f(x)}$ this simulation eventually halts and yields a value; finally add $1$. Hence $g$ is total computable.\n\nSince $g$ is total computable, it has an index $e_0$ in the numbering, i.e., $\\varphi_{e_0} = g$. Consequently, $e_0 \\in \\mathrm{Tot}$.\n\nBecause the range of $f$ is $\\mathrm{Tot}$, there exists some $n \\in \\mathbb{N}$ such that $f(n) = e_0$. Evaluating $g$ at $n$ gives:\n\\[\ng(n) = \\varphi_{f(n)}(n) + 1 = \\varphi_{e_0}(n) + 1 = g(n) + 1,\n\\]\nwhich is a contradiction. Therefore our assumption was false, and $\\mathrm{Tot}$ is not recursively enumerable. $\\square$",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "2",
    "outer_attempt": 1,
    "topic_slug": "combinatorics",
    "topic_name": "Combinatorics",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Prove that for every nonnegative integer $n$,\n$$\n\\sum_{k=0}^{n} (-1)^{k} \\binom{n}{k} \\binom{2k}{k} 4^{n-k} = \\binom{2n}{n}.\n$$",
            "answer": "We begin with a lemma that holds for any complex number $a$ and any nonnegative integer $n$:\n$$\n\\sum_{k=0}^{n} \\binom{n}{k} \\binom{a}{k} = \\binom{n+a}{n}. \\tag{1}\n$$\n\n*Proof of (1).* For a fixed $a$, the binomial coefficient $\\binom{a}{k}$ is the coefficient of $z^{k}$ in the expansion of $(1+z)^{a}$ about $z=0$. By Cauchy's integral formula, for a small circle $\\gamma$ around $0$ that does not enclose the branch point $z=-1$ (e.g., $|z|=\\varepsilon<1$),\n$$\n\\binom{a}{k} = \\frac{1}{2\\pi i} \\oint_{\\gamma} \\frac{(1+z)^{a}}{z^{k+1}} \\, dz.\n$$\nSumming with the weights $\\binom{n}{k}$ (a finite sum) gives\n$$\n\\sum_{k=0}^{n} \\binom{n}{k} \\binom{a}{k}\n= \\frac{1}{2\\pi i} \\oint_{\\gamma} (1+z)^{a} \\sum_{k=0}^{n} \\binom{n}{k} \\frac{1}{z^{k+1}} \\, dz\n= \\frac{1}{2\\pi i} \\oint_{\\gamma} (1+z)^{a} \\left(1+\\frac{1}{z}\\right)^{\\!n} \\frac{dz}{z}.\n$$\nNow $(1+1/z)^{n} = z^{-n}(1+z)^{n}$, so the integrand becomes $(1+z)^{a+n} z^{-n-1} dz$. Hence\n$$\n\\sum_{k=0}^{n} \\binom{n}{k} \\binom{a}{k}\n= \\frac{1}{2\\pi i} \\oint_{\\gamma} \\frac{(1+z)^{a+n}}{z^{n+1}} \\, dz\n= [z^{n}] (1+z)^{a+n} = \\binom{a+n}{n},\n$$\nwhere $[z^{n}]$ denotes the coefficient of $z^{n}$. This establishes (1). $\\square$\n\nNow set $a = -\\frac12$ in (1):\n$$\n\\sum_{k=0}^{n} \\binom{n}{k} \\binom{-\\frac12}{k} = \\binom{n-\\frac12}{n}. \\tag{2}\n$$\n\nNext, express the central binomial coefficient in terms of $\\binom{-\\frac12}{k}$. Using the definition,\n$$\n\\binom{-\\frac12}{k}\n= \\frac{(-\\frac12)(-\\frac32)\\cdots\\bigl(-\\frac{2k-1}{2}\\bigr)}{k!}\n= (-1)^{k} \\frac{1\\cdot 3\\cdot 5\\cdots(2k-1)}{2^{k} k!}.\n$$\nThe product of the first $k$ odd positive integers equals $(2k)!/(2^{k} k!)$. Therefore,\n$$\n\\binom{-\\frac12}{k} = (-1)^{k} \\frac{(2k)!}{2^{2k} k! k!}\n= (-1)^{k} 4^{-k} \\binom{2k}{k},\n$$\nwhich is equivalent to\n$$\n\\binom{2k}{k} = (-4)^{k} \\binom{-\\frac12}{k}. \\tag{3}\n$$\n\nNow consider the required sum:\n$$\nS_n = \\sum_{k=0}^{n} (-1)^{k} \\binom{n}{k} \\binom{2k}{k} 4^{n-k}.\n$$\nSubstitute (3):\n$$\nS_n = \\sum_{k=0}^{n} (-1)^{k} \\binom{n}{k} \\left[ (-4)^{k} \\binom{-\\frac12}{k} \\right] 4^{n-k}\n= \\sum_{k=0}^{n} \\binom{n}{k} \\binom{-\\frac12}{k} \\, (-1)^{k}(-4)^{k} 4^{n-k}.\n$$\nSince $(-1)^{k}(-4)^{k} = 4^{k}$, we obtain\n$$\nS_n = \\sum_{k=0}^{n} \\binom{n}{k} \\binom{-\\frac12}{k} 4^{k} 4^{n-k}\n= 4^{n} \\sum_{k=0}^{n} \\binom{n}{k} \\binom{-\\frac12}{k}.\n$$\nUsing (2), this becomes\n$$\nS_n = 4^{n} \\binom{n-\\frac12}{n}. \\tag{4}\n$$\n\nIt remains to simplify $\\binom{n-\\frac12}{n}$. By definition,\n$$\n\\binom{n-\\frac12}{n}\n= \\frac{(n-\\frac12)(n-\\frac32)\\cdots(\\frac12)}{n!}.\n$$\nMultiply numerator and denominator by $2^{n}$:\n$$\n\\binom{n-\\frac12}{n}\n= \\frac{(2n-1)(2n-3)\\cdots 1}{2^{n} n!}.\n$$\nThe numerator is the product of the first $n$ odd positive integers, which equals $(2n)!/(2^{n} n!)$. Hence\n$$\n\\binom{n-\\frac12}{n}\n= \\frac{(2n)!}{2^{n} n! \\cdot 2^{n} n!}\n= \\frac{(2n)!}{2^{2n} (n!)^{2}}\n= \\frac{1}{4^{n}} \\binom{2n}{n}. \\tag{5}\n$$\n\nFinally, substitute (5) into (4):\n$$\nS_n = 4^{n} \\cdot \\frac{1}{4^{n}} \\binom{2n}{n} = \\binom{2n}{n}.\n$$\n\nThus the identity is proved for all nonnegative integers $n$.",
            "raw_answer": "[QUESTION]\nProve that for every nonnegative integer $n$,\n\\[\n\\sum_{k=0}^{n} (-1)^{k} \\binom{n}{k} \\binom{2k}{k} 4^{n-k} = \\binom{2n}{n}.\n\\]\n\n[ANSWER]\nWe begin with a lemma that holds for any complex number $a$ and any nonnegative integer $n$:\n\\[\n\\sum_{k=0}^{n} \\binom{n}{k} \\binom{a}{k} = \\binom{n+a}{n}. \\tag{1}\n\\]\n\n*Proof of (1).* For a fixed $a$, the binomial coefficient $\\binom{a}{k}$ is the coefficient of $z^{k}$ in the expansion of $(1+z)^{a}$ about $z=0$. By Cauchy's integral formula, for a small circle $\\gamma$ around $0$ that does not enclose the branch point $z=-1$ (e.g., $|z|=\\varepsilon<1$),\n\\[\n\\binom{a}{k} = \\frac{1}{2\\pi i} \\oint_{\\gamma} \\frac{(1+z)^{a}}{z^{k+1}} \\, dz.\n\\]\nSumming with the weights $\\binom{n}{k}$ (a finite sum) gives\n\\[\n\\sum_{k=0}^{n} \\binom{n}{k} \\binom{a}{k}\n= \\frac{1}{2\\pi i} \\oint_{\\gamma} (1+z)^{a} \\sum_{k=0}^{n} \\binom{n}{k} \\frac{1}{z^{k+1}} \\, dz\n= \\frac{1}{2\\pi i} \\oint_{\\gamma} (1+z)^{a} \\left(1+\\frac{1}{z}\\right)^{\\!n} \\frac{dz}{z}.\n\\]\nNow $(1+1/z)^{n} = z^{-n}(1+z)^{n}$, so the integrand becomes $(1+z)^{a+n} z^{-n-1} dz$. Hence\n\\[\n\\sum_{k=0}^{n} \\binom{n}{k} \\binom{a}{k}\n= \\frac{1}{2\\pi i} \\oint_{\\gamma} \\frac{(1+z)^{a+n}}{z^{n+1}} \\, dz\n= [z^{n}] (1+z)^{a+n} = \\binom{a+n}{n},\n\\]\nwhere $[z^{n}]$ denotes the coefficient of $z^{n}$. This establishes (1). $\\square$\n\nNow set $a = -\\frac12$ in (1):\n\\[\n\\sum_{k=0}^{n} \\binom{n}{k} \\binom{-\\frac12}{k} = \\binom{n-\\frac12}{n}. \\tag{2}\n\\]\n\nNext, express the central binomial coefficient in terms of $\\binom{-\\frac12}{k}$. Using the definition,\n\\[\n\\binom{-\\frac12}{k}\n= \\frac{(-\\frac12)(-\\frac32)\\cdots\\bigl(-\\frac{2k-1}{2}\\bigr)}{k!}\n= (-1)^{k} \\frac{1\\cdot 3\\cdot 5\\cdots(2k-1)}{2^{k} k!}.\n\\]\nThe product of the first $k$ odd positive integers equals $(2k)!/(2^{k} k!)$. Therefore,\n\\[\n\\binom{-\\frac12}{k} = (-1)^{k} \\frac{(2k)!}{2^{2k} k! k!}\n= (-1)^{k} 4^{-k} \\binom{2k}{k},\n\\]\nwhich is equivalent to\n\\[\n\\binom{2k}{k} = (-4)^{k} \\binom{-\\frac12}{k}. \\tag{3}\n\\]\n\nNow consider the required sum:\n\\[\nS_n = \\sum_{k=0}^{n} (-1)^{k} \\binom{n}{k} \\binom{2k}{k} 4^{n-k}.\n\\]\nSubstitute (3):\n\\[\nS_n = \\sum_{k=0}^{n} (-1)^{k} \\binom{n}{k} \\left[ (-4)^{k} \\binom{-\\frac12}{k} \\right] 4^{n-k}\n= \\sum_{k=0}^{n} \\binom{n}{k} \\binom{-\\frac12}{k} \\, (-1)^{k}(-4)^{k} 4^{n-k}.\n\\]\nSince $(-1)^{k}(-4)^{k} = 4^{k}$, we obtain\n\\[\nS_n = \\sum_{k=0}^{n} \\binom{n}{k} \\binom{-\\frac12}{k} 4^{k} 4^{n-k}\n= 4^{n} \\sum_{k=0}^{n} \\binom{n}{k} \\binom{-\\frac12}{k}.\n\\]\nUsing (2), this becomes\n\\[\nS_n = 4^{n} \\binom{n-\\frac12}{n}. \\tag{4}\n\\]\n\nIt remains to simplify $\\binom{n-\\frac12}{n}$. By definition,\n\\[\n\\binom{n-\\frac12}{n}\n= \\frac{(n-\\frac12)(n-\\frac32)\\cdots(\\frac12)}{n!}.\n\\]\nMultiply numerator and denominator by $2^{n}$:\n\\[\n\\binom{n-\\frac12}{n}\n= \\frac{(2n-1)(2n-3)\\cdots 1}{2^{n} n!}.\n\\]\nThe numerator is the product of the first $n$ odd positive integers, which equals $(2n)!/(2^{n} n!)$. Hence\n\\[\n\\binom{n-\\frac12}{n}\n= \\frac{(2n)!}{2^{n} n! \\cdot 2^{n} n!}\n= \\frac{(2n)!}{2^{2n} (n!)^{2}}\n= \\frac{1}{4^{n}} \\binom{2n}{n}. \\tag{5}\n\\]\n\nFinally, substitute (5) into (4):\n\\[\nS_n = 4^{n} \\cdot \\frac{1}{4^{n}} \\binom{2n}{n} = \\binom{2n}{n}.\n\\]\n\nThus the identity is proved for all nonnegative integers $n$.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "3",
    "outer_attempt": 1,
    "topic_slug": "number_theory",
    "topic_name": "Number theory",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Find all integer solutions $(x, y)$ to the equation $y^3 = x^2 + 2$.",
            "answer": "We will solve the Diophantine equation $y^3 = x^2 + 2$ over integers.\n\nFirst, note that if $x$ is a solution, then $(-x)^2 = x^2$, so we may first consider $x \\ge 0$ and later include negatives. Also, $y$ must be positive because $y^3 = x^2+2 \\ge 2$.\n\nRewrite as $x^2 + 2 = y^3$. In the ring $\\mathbb{Z}[\\sqrt{-2}]$, which is a Euclidean domain (hence a unique factorization domain), factor the left-hand side as\n$$\n(x + \\sqrt{-2})(x - \\sqrt{-2}) = y^3.\n$$\n\nWe claim that the two factors $x + \\sqrt{-2}$ and $x - \\sqrt{-2}$ are coprime in $\\mathbb{Z}[\\sqrt{-2}]$. Indeed, any common divisor $\\delta$ divides their difference $2\\sqrt{-2}$ and their sum $2x$. Thus $\\delta$ divides $2\\sqrt{-2}$ and $2x$. The norm of $\\delta$, $N(\\delta)$, divides both $N(2\\sqrt{-2}) = 8$ and $N(2x) = 4x^2$. If a prime integer $p$ divides $N(\\delta)$, then $p$ divides both $8$ and $4x^2$, so $p \\in \\{2\\}$. Hence any common prime divisor could only be $2$. But we show that $2$ cannot divide both factors simultaneously. If $2 \\mid (x + \\sqrt{-2})$ in $\\mathbb{Z}[\\sqrt{-2}]$, then $x + \\sqrt{-2} = 2(a + b\\sqrt{-2})$ which implies $x$ even and then $x^2$ divisible by $4$. Then $y^3 = x^2 + 2 \\equiv 2 \\pmod{4}$, impossible because cubes mod 4 are $0,1,3$. Hence $2$ does not divide the factors. Therefore the two factors are coprime.\n\nSince their product is a perfect cube and they are coprime, each factor must be a cube up to a unit. The units in $\\mathbb{Z}[\\sqrt{-2}]$ are $\\pm 1$, both of which are cubes ($1 = 1^3$, $-1 = (-1)^3$). Hence we can write\n$$\nx + \\sqrt{-2} = (a + b\\sqrt{-2})^3\n$$\nfor some integers $a, b$. Expanding the right-hand side:\n$$\n(a + b\\sqrt{-2})^3 = a^3 + 3a^2 b \\sqrt{-2} + 3a b^2 (\\sqrt{-2})^2 + b^3 (\\sqrt{-2})^3.\n$$\nSince $(\\sqrt{-2})^2 = -2$ and $(\\sqrt{-2})^3 = -2\\sqrt{-2}$, we obtain\n$$\n(a + b\\sqrt{-2})^3 = (a^3 - 6a b^2) + (3a^2 b - 2b^3) \\sqrt{-2}.\n$$\nEquating with $x + \\sqrt{-2}$ gives the system:\n$$\n\\begin{cases}\nx = a^3 - 6a b^2,\\\\\n1 = 3a^2 b - 2b^3 = b(3a^2 - 2b^2).\n\\end{cases}\n$$\n\nThe second equation, $b(3a^2 - 2b^2) = 1$, with integers $a, b$, implies that $b$ divides $1$, so $b = \\pm 1$.\n\n- If $b = 1$, then $3a^2 - 2 = 1$ \u21d2 $3a^2 = 3$ \u21d2 $a^2 = 1$ \u21d2 $a = \\pm 1$.\n- If $b = -1$, then $3a^2 - 2(-1)^2 = 3a^2 - 2 = -1$? Actually plugging $b = -1$: $b(3a^2 - 2b^2) = (-1)(3a^2 - 2) = - (3a^2 - 2) = 1$ \u21d2 $3a^2 - 2 = -1$ \u21d2 $3a^2 = 1$ \u21d2 no integer solution.\n\nThus the only possibilities are $b = 1$, $a = \\pm 1$.\n\nFor $a = 1, b = 1$: $x = 1^3 - 6\\cdot1\\cdot1^2 = 1 - 6 = -5$.\nFor $a = -1, b = 1$: $x = (-1)^3 - 6(-1)\\cdot1^2 = -1 + 6 = 5$.\n\nHence $x = \\pm 5$. The corresponding $y$ is obtained from the norm: $N(x + \\sqrt{-2}) = x^2 + 2 = y^3$, but also $N(a + b\\sqrt{-2}) = a^2 + 2b^2$, so\n$$\ny^3 = (a^2 + 2b^2)^3 \\quad \\Rightarrow \\quad y = a^2 + 2b^2 = 1 + 2 = 3.\n$$\nThus $y = 3$.\n\nTherefore the only integer solutions are $(x, y) = (5, 3)$ and $(x, y) = (-5, 3)$.\n\nWe should also check the possibility $x = 0$? Then $y^3 = 2$, no integer. So these are all.\n\nHence the complete solution set is $\\boxed{(x, y) = (\\pm 5, 3)}$.",
            "raw_answer": "[QUESTION]\nFind all integer solutions \\((x, y)\\) to the equation \\(y^3 = x^2 + 2\\).\n\n[ANSWER]\nWe will solve the Diophantine equation \\(y^3 = x^2 + 2\\) over integers.\n\nFirst, note that if \\(x\\) is a solution, then \\((-x)^2 = x^2\\), so we may first consider \\(x \\ge 0\\) and later include negatives. Also, \\(y\\) must be positive because \\(y^3 = x^2+2 \\ge 2\\).\n\nRewrite as \\(x^2 + 2 = y^3\\). In the ring \\(\\mathbb{Z}[\\sqrt{-2}]\\), which is a Euclidean domain (hence a unique factorization domain), factor the left-hand side as\n\\[\n(x + \\sqrt{-2})(x - \\sqrt{-2}) = y^3.\n\\]\n\nWe claim that the two factors \\(x + \\sqrt{-2}\\) and \\(x - \\sqrt{-2}\\) are coprime in \\(\\mathbb{Z}[\\sqrt{-2}]\\). Indeed, any common divisor \\(\\delta\\) divides their difference \\(2\\sqrt{-2}\\) and their sum \\(2x\\). Thus \\(\\delta\\) divides \\(2\\sqrt{-2}\\) and \\(2x\\). The norm of \\(\\delta\\), \\(N(\\delta)\\), divides both \\(N(2\\sqrt{-2}) = 8\\) and \\(N(2x) = 4x^2\\). If a prime integer \\(p\\) divides \\(N(\\delta)\\), then \\(p\\) divides both \\(8\\) and \\(4x^2\\), so \\(p \\in \\{2\\}\\). Hence any common prime divisor could only be \\(2\\). But we show that \\(2\\) cannot divide both factors simultaneously. If \\(2 \\mid (x + \\sqrt{-2})\\) in \\(\\mathbb{Z}[\\sqrt{-2}]\\), then \\(x + \\sqrt{-2} = 2(a + b\\sqrt{-2})\\) which implies \\(x\\) even and then \\(x^2\\) divisible by \\(4\\). Then \\(y^3 = x^2 + 2 \\equiv 2 \\pmod{4}\\), impossible because cubes mod 4 are \\(0,1,3\\). Hence \\(2\\) does not divide the factors. Therefore the two factors are coprime.\n\nSince their product is a perfect cube and they are coprime, each factor must be a cube up to a unit. The units in \\(\\mathbb{Z}[\\sqrt{-2}]\\) are \\(\\pm 1\\), both of which are cubes (\\(1 = 1^3\\), \\(-1 = (-1)^3\\)). Hence we can write\n\\[\nx + \\sqrt{-2} = (a + b\\sqrt{-2})^3\n\\]\nfor some integers \\(a, b\\). Expanding the right-hand side:\n\\[\n(a + b\\sqrt{-2})^3 = a^3 + 3a^2 b \\sqrt{-2} + 3a b^2 (\\sqrt{-2})^2 + b^3 (\\sqrt{-2})^3.\n\\]\nSince \\((\\sqrt{-2})^2 = -2\\) and \\((\\sqrt{-2})^3 = -2\\sqrt{-2}\\), we obtain\n\\[\n(a + b\\sqrt{-2})^3 = (a^3 - 6a b^2) + (3a^2 b - 2b^3) \\sqrt{-2}.\n\\]\nEquating with \\(x + \\sqrt{-2}\\) gives the system:\n\\[\n\\begin{cases}\nx = a^3 - 6a b^2,\\\\\n1 = 3a^2 b - 2b^3 = b(3a^2 - 2b^2).\n\\end{cases}\n\\]\n\nThe second equation, \\(b(3a^2 - 2b^2) = 1\\), with integers \\(a, b\\), implies that \\(b\\) divides \\(1\\), so \\(b = \\pm 1\\).\n\n- If \\(b = 1\\), then \\(3a^2 - 2 = 1\\) \u21d2 \\(3a^2 = 3\\) \u21d2 \\(a^2 = 1\\) \u21d2 \\(a = \\pm 1\\).\n- If \\(b = -1\\), then \\(3a^2 - 2(-1)^2 = 3a^2 - 2 = -1\\)? Actually plugging \\(b = -1\\): \\(b(3a^2 - 2b^2) = (-1)(3a^2 - 2) = - (3a^2 - 2) = 1\\) \u21d2 \\(3a^2 - 2 = -1\\) \u21d2 \\(3a^2 = 1\\) \u21d2 no integer solution.\n\nThus the only possibilities are \\(b = 1\\), \\(a = \\pm 1\\).\n\nFor \\(a = 1, b = 1\\): \\(x = 1^3 - 6\\cdot1\\cdot1^2 = 1 - 6 = -5\\).\nFor \\(a = -1, b = 1\\): \\(x = (-1)^3 - 6(-1)\\cdot1^2 = -1 + 6 = 5\\).\n\nHence \\(x = \\pm 5\\). The corresponding \\(y\\) is obtained from the norm: \\(N(x + \\sqrt{-2}) = x^2 + 2 = y^3\\), but also \\(N(a + b\\sqrt{-2}) = a^2 + 2b^2\\), so\n\\[\ny^3 = (a^2 + 2b^2)^3 \\quad \\Rightarrow \\quad y = a^2 + 2b^2 = 1 + 2 = 3.\n\\]\nThus \\(y = 3\\).\n\nTherefore the only integer solutions are \\((x, y) = (5, 3)\\) and \\((x, y) = (-5, 3)\\).\n\nWe should also check the possibility \\(x = 0\\)? Then \\(y^3 = 2\\), no integer. So these are all.\n\nHence the complete solution set is \\(\\boxed{(x, y) = (\\pm 5, 3)}\\).",
            "evaluation": {
              "verdict": "fail",
              "ill_posed": false,
              "issues": [
                "The justification that the factors are coprime is flawed. The argument that any common prime divisor must be 2 is incorrect; the prime element \u221a-2 could be a common divisor, and showing that 2 does not divide the factors does not rule out \u221a-2. This gap undermines the proof."
              ],
              "improvements": "Revise the coprime argument: Show that any common divisor \u03b4 divides 2\u221a-2. Since 2\u221a-2 = (\u221a-2)^3 (up to a unit), the only prime divisor is \u221a-2. Thus any common prime divisor must be an associate of \u221a-2. Then prove that \u221a-2 cannot divide x+\u221a-2: if \u221a-2 | (x+\u221a-2), then x is even, leading to y^3 \u2261 2 mod4, contradiction. Hence the factors are coprime. Alternatively, use a norm argument: if a non-unit \u03b4 divides both, then N(\u03b4) divides both 8 and y^3, and N(\u03b4) is a power of 2. Then show that \u03b4 must be associate to a power of \u221a-2, and that \u221a-2 dividing both leads to contradiction mod4."
            }
          },
          {
            "round": 2,
            "question": "Find all integer solutions $(x, y)$ to the equation $y^3 = x^2 + 2$.",
            "answer": "We will solve the Diophantine equation \\(y^3 = x^2 + 2\\) over integers.\n\nFirst, note that if \\((x,y)\\) is a solution, then \\((-x)^2 = x^2\\), so we may first consider \\(x \\ge 0\\) and later include negatives. Also, \\(y^3 = x^2+2 \\ge 2\\) implies \\(y > 0\\).\n\nRewrite the equation in the ring \\(\\mathbb{Z}[\\sqrt{-2}]\\), which is a Euclidean domain (hence a unique factorization domain):\n\\[\n(x + \\sqrt{-2})(x - \\sqrt{-2}) = y^3.\n\\]\n\nWe claim that the two factors \\(x + \\sqrt{-2}\\) and \\(x - \\sqrt{-2}\\) are coprime in \\(\\mathbb{Z}[\\sqrt{-2}]\\).\n\n**Proof of coprimality:** Let \\(\\delta\\) be a common divisor. Then \\(\\delta\\) divides their difference\n\\[\n(x + \\sqrt{-2}) - (x - \\sqrt{-2}) = 2\\sqrt{-2}.\n\\]\nThus \\(\\delta \\mid 2\\sqrt{-2}\\). In \\(\\mathbb{Z}[\\sqrt{-2}]\\), the element \\(2\\sqrt{-2}\\) factors (up to a unit) as \\((\\sqrt{-2})^3\\) because \\((\\sqrt{-2})^3 = -2\\sqrt{-2}\\), so \\(2\\sqrt{-2} = -(\\sqrt{-2})^3\\). Since \\(\\sqrt{-2}\\) is prime (its norm \\(N(\\sqrt{-2}) = 2\\) is prime), the only prime factor of \\(2\\sqrt{-2}\\) is \\(\\sqrt{-2}\\) (or its associates). Hence any divisor of \\(2\\sqrt{-2}\\) is of the form \\(u (\\sqrt{-2})^k\\) with \\(u\\) a unit and \\(k \\ge 0\\). Therefore \\(\\delta = u (\\sqrt{-2})^k\\).\n\nIf \\(k \\ge 1\\), then \\(\\sqrt{-2} \\mid \\delta\\), so \\(\\sqrt{-2}\\) divides both \\(x + \\sqrt{-2}\\) and \\(x - \\sqrt{-2}\\). In particular, \\(\\sqrt{-2} \\mid (x + \\sqrt{-2})\\). Then there exist integers \\(c, d\\) such that\n\\[\nx + \\sqrt{-2} = \\sqrt{-2} (c + d\\sqrt{-2}) = -2d + c\\sqrt{-2}.\n\\]\nEquating coefficients gives \\(x = -2d\\) and \\(1 = c\\). Thus \\(x\\) is even. Then \\(x^2\\) is divisible by \\(4\\), so\n\\[\ny^3 = x^2 + 2 \\equiv 2 \\pmod{4}.\n\\]\nBut cubes modulo \\(4\\) are \\(0, 1, 3\\) only (since \\(0^3\\equiv0\\), \\(1^3\\equiv1\\), \\(2^3\\equiv0\\), \\(3^3\\equiv3\\)). Hence \\(2 \\pmod{4}\\) is impossible, a contradiction. Therefore \\(k = 0\\) and \\(\\delta\\) is a unit. Thus the two factors are coprime. \\(\\square\\)\n\nSince the product of two coprime elements is a perfect cube, each factor must be a cube up to a unit. The units in \\(\\mathbb{Z}[\\sqrt{-2}]\\) are \\(\\pm 1\\), and both are cubes (\\(1 = 1^3\\), \\(-1 = (-1)^3\\)). Hence we can write\n\\[\nx + \\sqrt{-2} = (a + b\\sqrt{-2})^3\n\\]\nfor some integers \\(a, b\\).\n\nExpand the cube:\n\\[\n(a + b\\sqrt{-2})^3 = a^3 + 3a^2 b \\sqrt{-2} + 3a b^2 (\\sqrt{-2})^2 + b^3 (\\sqrt{-2})^3.\n\\]\nUsing \\((\\sqrt{-2})^2 = -2\\) and \\((\\sqrt{-2})^3 = -2\\sqrt{-2}\\), we obtain\n\\[\n(a + b\\sqrt{-2})^3 = (a^3 - 6a b^2) + (3a^2 b - 2b^3) \\sqrt{-2}.\n\\]\n\nEquating with \\(x + \\sqrt{-2}\\) gives the system\n\\[\n\\begin{cases}\nx = a^3 - 6a b^2,\\\\[2pt]\n1 = 3a^2 b - 2b^3 = b(3a^2 - 2b^2).\n\\end{cases}\n\\]\n\nThe second equation, \\(b(3a^2 - 2b^2) = 1\\), with integers \\(a, b\\), implies that \\(b\\) divides \\(1\\), so \\(b = \\pm 1\\).\n\n- If \\(b = 1\\), then \\(3a^2 - 2 = 1\\) \\(\\Rightarrow\\) \\(3a^2 = 3\\) \\(\\Rightarrow\\) \\(a^2 = 1\\) \\(\\Rightarrow\\) \\(a = \\pm 1\\).\n- If \\(b = -1\\), then \\((-1)(3a^2 - 2) = 1\\) \\(\\Rightarrow\\) \\(3a^2 - 2 = -1\\) \\(\\Rightarrow\\) \\(3a^2 = 1\\), which has no integer solution.\n\nThus the only possibilities are \\((a,b) = (1,1)\\) or \\((-1,1)\\).\n\nCompute \\(x\\):\n- For \\(a = 1, b = 1\\): \\(x = 1^3 - 6 \\cdot 1 \\cdot 1^2 = 1 - 6 = -5\\).\n- For \\(a = -1, b = 1\\): \\(x = (-1)^3 - 6(-1) \\cdot 1^2 = -1 + 6 = 5\\).\n\nHence \\(x = \\pm 5\\).\n\nNow compute \\(y\\). The norm of \\(x + \\sqrt{-2}\\) is \\(x^2 + 2 = y^3\\). But also\n\\[\nN(x + \\sqrt{-2}) = N(a + b\\sqrt{-2})^3 = (a^2 + 2b^2)^3,\n\\]\nso \\(y^3 = (a^2 + 2b^2)^3\\) and therefore \\(y = a^2 + 2b^2\\). For both cases, \\(a^2 + 2b^2 = 1 + 2 = 3\\). Thus \\(y = 3\\).\n\nWe have obtained the solutions \\((x,y) = (5,3)\\) and \\((-5,3)\\). Checking: \\(5^2 + 2 = 27 = 3^3\\), \\((-5)^2 + 2 = 27 = 3^3\\). No other integer solutions exist because the argument above covered all possibilities (including the trivial check \\(x = 0\\) gives \\(y^3 = 2\\), impossible).\n\nTherefore, the complete set of integer solutions is\n\\[\n\\boxed{(x, y) = (\\pm 5, 3)}.\n\\]",
            "raw_answer": "We will solve the Diophantine equation \\(y^3 = x^2 + 2\\) over integers.\n\nFirst, note that if \\((x,y)\\) is a solution, then \\((-x)^2 = x^2\\), so we may first consider \\(x \\ge 0\\) and later include negatives. Also, \\(y^3 = x^2+2 \\ge 2\\) implies \\(y > 0\\).\n\nRewrite the equation in the ring \\(\\mathbb{Z}[\\sqrt{-2}]\\), which is a Euclidean domain (hence a unique factorization domain):\n\\[\n(x + \\sqrt{-2})(x - \\sqrt{-2}) = y^3.\n\\]\n\nWe claim that the two factors \\(x + \\sqrt{-2}\\) and \\(x - \\sqrt{-2}\\) are coprime in \\(\\mathbb{Z}[\\sqrt{-2}]\\).\n\n**Proof of coprimality:** Let \\(\\delta\\) be a common divisor. Then \\(\\delta\\) divides their difference\n\\[\n(x + \\sqrt{-2}) - (x - \\sqrt{-2}) = 2\\sqrt{-2}.\n\\]\nThus \\(\\delta \\mid 2\\sqrt{-2}\\). In \\(\\mathbb{Z}[\\sqrt{-2}]\\), the element \\(2\\sqrt{-2}\\) factors (up to a unit) as \\((\\sqrt{-2})^3\\) because \\((\\sqrt{-2})^3 = -2\\sqrt{-2}\\), so \\(2\\sqrt{-2} = -(\\sqrt{-2})^3\\). Since \\(\\sqrt{-2}\\) is prime (its norm \\(N(\\sqrt{-2}) = 2\\) is prime), the only prime factor of \\(2\\sqrt{-2}\\) is \\(\\sqrt{-2}\\) (or its associates). Hence any divisor of \\(2\\sqrt{-2}\\) is of the form \\(u (\\sqrt{-2})^k\\) with \\(u\\) a unit and \\(k \\ge 0\\). Therefore \\(\\delta = u (\\sqrt{-2})^k\\).\n\nIf \\(k \\ge 1\\), then \\(\\sqrt{-2} \\mid \\delta\\), so \\(\\sqrt{-2}\\) divides both \\(x + \\sqrt{-2}\\) and \\(x - \\sqrt{-2}\\). In particular, \\(\\sqrt{-2} \\mid (x + \\sqrt{-2})\\). Then there exist integers \\(c, d\\) such that\n\\[\nx + \\sqrt{-2} = \\sqrt{-2} (c + d\\sqrt{-2}) = -2d + c\\sqrt{-2}.\n\\]\nEquating coefficients gives \\(x = -2d\\) and \\(1 = c\\). Thus \\(x\\) is even. Then \\(x^2\\) is divisible by \\(4\\), so\n\\[\ny^3 = x^2 + 2 \\equiv 2 \\pmod{4}.\n\\]\nBut cubes modulo \\(4\\) are \\(0, 1, 3\\) only (since \\(0^3\\equiv0\\), \\(1^3\\equiv1\\), \\(2^3\\equiv0\\), \\(3^3\\equiv3\\)). Hence \\(2 \\pmod{4}\\) is impossible, a contradiction. Therefore \\(k = 0\\) and \\(\\delta\\) is a unit. Thus the two factors are coprime. \\(\\square\\)\n\nSince the product of two coprime elements is a perfect cube, each factor must be a cube up to a unit. The units in \\(\\mathbb{Z}[\\sqrt{-2}]\\) are \\(\\pm 1\\), and both are cubes (\\(1 = 1^3\\), \\(-1 = (-1)^3\\)). Hence we can write\n\\[\nx + \\sqrt{-2} = (a + b\\sqrt{-2})^3\n\\]\nfor some integers \\(a, b\\).\n\nExpand the cube:\n\\[\n(a + b\\sqrt{-2})^3 = a^3 + 3a^2 b \\sqrt{-2} + 3a b^2 (\\sqrt{-2})^2 + b^3 (\\sqrt{-2})^3.\n\\]\nUsing \\((\\sqrt{-2})^2 = -2\\) and \\((\\sqrt{-2})^3 = -2\\sqrt{-2}\\), we obtain\n\\[\n(a + b\\sqrt{-2})^3 = (a^3 - 6a b^2) + (3a^2 b - 2b^3) \\sqrt{-2}.\n\\]\n\nEquating with \\(x + \\sqrt{-2}\\) gives the system\n\\[\n\\begin{cases}\nx = a^3 - 6a b^2,\\\\[2pt]\n1 = 3a^2 b - 2b^3 = b(3a^2 - 2b^2).\n\\end{cases}\n\\]\n\nThe second equation, \\(b(3a^2 - 2b^2) = 1\\), with integers \\(a, b\\), implies that \\(b\\) divides \\(1\\), so \\(b = \\pm 1\\).\n\n- If \\(b = 1\\), then \\(3a^2 - 2 = 1\\) \\(\\Rightarrow\\) \\(3a^2 = 3\\) \\(\\Rightarrow\\) \\(a^2 = 1\\) \\(\\Rightarrow\\) \\(a = \\pm 1\\).\n- If \\(b = -1\\), then \\((-1)(3a^2 - 2) = 1\\) \\(\\Rightarrow\\) \\(3a^2 - 2 = -1\\) \\(\\Rightarrow\\) \\(3a^2 = 1\\), which has no integer solution.\n\nThus the only possibilities are \\((a,b) = (1,1)\\) or \\((-1,1)\\).\n\nCompute \\(x\\):\n- For \\(a = 1, b = 1\\): \\(x = 1^3 - 6 \\cdot 1 \\cdot 1^2 = 1 - 6 = -5\\).\n- For \\(a = -1, b = 1\\): \\(x = (-1)^3 - 6(-1) \\cdot 1^2 = -1 + 6 = 5\\).\n\nHence \\(x = \\pm 5\\).\n\nNow compute \\(y\\). The norm of \\(x + \\sqrt{-2}\\) is \\(x^2 + 2 = y^3\\). But also\n\\[\nN(x + \\sqrt{-2}) = N(a + b\\sqrt{-2})^3 = (a^2 + 2b^2)^3,\n\\]\nso \\(y^3 = (a^2 + 2b^2)^3\\) and therefore \\(y = a^2 + 2b^2\\). For both cases, \\(a^2 + 2b^2 = 1 + 2 = 3\\). Thus \\(y = 3\\).\n\nWe have obtained the solutions \\((x,y) = (5,3)\\) and \\((-5,3)\\). Checking: \\(5^2 + 2 = 27 = 3^3\\), \\((-5)^2 + 2 = 27 = 3^3\\). No other integer solutions exist because the argument above covered all possibilities (including the trivial check \\(x = 0\\) gives \\(y^3 = 2\\), impossible).\n\nTherefore, the complete set of integer solutions is\n\\[\n\\boxed{(x, y) = (\\pm 5, 3)}.\n\\]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "4",
    "outer_attempt": 1,
    "topic_slug": "order_lattices_and_ordered_algebraic_structures",
    "topic_name": "Order, lattices, ordered algebraic structures",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $L$ be a finite distributive lattice with least element $0$ and greatest element $1$. An element $j \\in L$ is called **join-irreducible** if $j \\neq 0$ and whenever $j = x \\vee y$ for some $x, y \\in L$, we have $j = x$ or $j = y$. Let $J(L)$ denote the set of join-irreducible elements of $L$, ordered by the restriction of the order of $L$.\n\nA subset $I \\subseteq J(L)$ is an **order ideal** (or down-set) if whenever $x \\in I$ and $y \\in J(L)$ with $y \\leq x$, we have $y \\in I$. The set $D(J(L))$ of all order ideals of $J(L)$ forms a distributive lattice under union (join) and intersection (meet).\n\nDefine $\\varphi: L \\to D(J(L))$ by $\\varphi(a) = \\{ j \\in J(L) \\mid j \\leq a \\}$.\n\nProve that $\\varphi$ is a lattice isomorphism, i.e., that $\\varphi$ is bijective and satisfies $\\varphi(a \\vee b) = \\varphi(a) \\cup \\varphi(b)$ and $\\varphi(a \\wedge b) = \\varphi(a) \\cap \\varphi(b)$ for all $a, b \\in L$.\n[/QUESTION]",
            "answer": "We prove that $\\varphi$ is a lattice isomorphism through a series of lemmas.\n\n**Lemma 1** (Join-irreducible decomposition). In any finite lattice, every element $a \\neq 0$ can be expressed as a join of join-irreducible elements.\n\n*Proof.* Suppose, for contradiction, that there exists a non-zero element that cannot be written as a join of join-irreducibles. Because the lattice is finite, choose a minimal such element $a$ (with respect to the order). Since $a \\neq 0$ and is not join-irreducible (otherwise it would be a join of itself), we have $a = x \\vee y$ for some $x, y < a$. By minimality, both $x$ and $y$ are joins of join-irreducible elements. Hence $a = x \\vee y$ is also a join of join-irreducible elements, a contradiction. \u220e\n\n**Lemma 2** (Join-irreducible implies join-prime in distributive lattices). Let $L$ be a distributive lattice and let $j \\in L$ be join-irreducible. If $j \\leq \\bigvee_{i=1}^{n} x_i$ for some finite set $\\{x_1,\\dots,x_n\\} \\subseteq L$, then there exists an index $i$ such that $j \\leq x_i$. In particular, for $n=2$, $j \\leq x \\vee y$ implies $j \\leq x$ or $j \\leq y$.\n\n*Proof.* By distributivity,\n$$\nj = j \\wedge \\left( \\bigvee_{i=1}^{n} x_i \\right) = \\bigvee_{i=1}^{n} (j \\wedge x_i).\n$$\nSince $j$ is join-irreducible, the join on the right cannot be a proper join; therefore one of the terms must equal $j$, i.e., $j = j \\wedge x_i$ for some $i$, which means $j \\leq x_i$. \u220e\n\n**Well-definedness.** For any $a \\in L$, $\\varphi(a) = \\{j \\in J(L) : j \\leq a\\}$ is an order ideal of $J(L)$: if $j \\in \\varphi(a)$ and $k \\in J(L)$ with $k \\leq j$, then $k \\leq j \\leq a$, so $k \\in \\varphi(a)$. Hence $\\varphi(a) \\in D(J(L))$.\n\n**Injectivity.** We show that $a = \\bigvee \\varphi(a)$ for every $a \\in L$.\n\n- If $a = 0$, then $\\varphi(0) = \\emptyset$ and the empty join is defined to be $0$, so $0 = \\bigvee \\varphi(0)$.\n- If $a \\neq 0$, by Lemma 1 there exists a finite nonempty set $T \\subseteq J(L)$ such that $a = \\bigvee T$. Clearly $T \\subseteq \\varphi(a)$ because each $t \\in T$ satisfies $t \\leq a$. Therefore\n  $$\n  a = \\bigvee T \\leq \\bigvee \\varphi(a) \\leq a,\n  $$\n  where the last inequality holds because every element of $\\varphi(a)$ is $\\leq a$. Hence $a = \\bigvee \\varphi(a)$.\n\nConsequently, if $\\varphi(a) = \\varphi(b)$, then\n$$\na = \\bigvee \\varphi(a) = \\bigvee \\varphi(b) = b,\n$$\nso $\\varphi$ is injective.\n\n**Surjectivity.** Let $I \\in D(J(L))$ be an order ideal. Since $L$ is finite, $I$ is finite. Set $a = \\bigvee I$ (with the convention that $\\bigvee \\emptyset = 0$). We claim that $\\varphi(a) = I$.\n\n- $I \\subseteq \\varphi(a)$: If $j \\in I$, then $j \\leq \\bigvee I = a$, so $j \\in \\varphi(a)$.\n- $\\varphi(a) \\subseteq I$: Let $j \\in \\varphi(a)$, i.e., $j \\in J(L)$ and $j \\leq a = \\bigvee I$. If $I = \\emptyset$, then $a = 0$ and $\\varphi(0) = \\emptyset$, so the inclusion is trivial. If $I \\neq \\emptyset$, apply Lemma\u202f2 to the finite set $I$: there exists some $i \\in I$ such that $j \\leq i$. Since $I$ is an order ideal and $i \\in I$, we have $j \\in I$.\n\nThus $\\varphi(a) = I$, proving surjectivity.\n\n**Preservation of operations.** For any $a, b \\in L$:\n\n- **Join:** $\\varphi(a \\vee b) = \\{ j \\in J(L) : j \\leq a \\vee b \\}$. By Lemma\u202f2 (binary case), $j \\leq a \\vee b$ iff $j \\leq a$ or $j \\leq b$. Hence\n  $$\n  \\varphi(a \\vee b) = \\{ j \\in J(L) : j \\leq a\\} \\cup \\{ j \\in J(L) : j \\leq b\\} = \\varphi(a) \\cup \\varphi(b).\n  $$\n\n- **Meet:** $\\varphi(a \\wedge b) = \\{ j \\in J(L) : j \\leq a \\wedge b \\}$. Since $j \\leq a \\wedge b$ is equivalent to $j \\leq a$ and $j \\leq b$, we have\n  $$\n  \\varphi(a \\wedge b) = \\varphi(a) \\cap \\varphi(b).\n  $$\n\nThus $\\varphi$ is a lattice homomorphism. Because it is bijective, it is a lattice isomorphism.\n\nTherefore, $\\varphi: L \\to D(J(L))$ is a lattice isomorphism, completing the proof. \u220e\n[/ANSWER]",
            "raw_answer": "[QUESTION]\nLet \\(L\\) be a finite distributive lattice with least element \\(0\\) and greatest element \\(1\\). An element \\(j \\in L\\) is called **join-irreducible** if \\(j \\neq 0\\) and whenever \\(j = x \\vee y\\) for some \\(x, y \\in L\\), we have \\(j = x\\) or \\(j = y\\). Let \\(J(L)\\) denote the set of join-irreducible elements of \\(L\\), ordered by the restriction of the order of \\(L\\).\n\nA subset \\(I \\subseteq J(L)\\) is an **order ideal** (or down-set) if whenever \\(x \\in I\\) and \\(y \\in J(L)\\) with \\(y \\leq x\\), we have \\(y \\in I\\). The set \\(D(J(L))\\) of all order ideals of \\(J(L)\\) forms a distributive lattice under union (join) and intersection (meet).\n\nDefine \\(\\varphi: L \\to D(J(L))\\) by \\(\\varphi(a) = \\{ j \\in J(L) \\mid j \\leq a \\}\\).\n\nProve that \\(\\varphi\\) is a lattice isomorphism, i.e., that \\(\\varphi\\) is bijective and satisfies \\(\\varphi(a \\vee b) = \\varphi(a) \\cup \\varphi(b)\\) and \\(\\varphi(a \\wedge b) = \\varphi(a) \\cap \\varphi(b)\\) for all \\(a, b \\in L\\).\n[/QUESTION]\n\n[ANSWER]\nWe prove that \\(\\varphi\\) is a lattice isomorphism through a series of lemmas.\n\n**Lemma 1** (Join-irreducible decomposition). In any finite lattice, every element \\(a \\neq 0\\) can be expressed as a join of join-irreducible elements.\n\n*Proof.* Suppose, for contradiction, that there exists a non-zero element that cannot be written as a join of join-irreducibles. Because the lattice is finite, choose a minimal such element \\(a\\) (with respect to the order). Since \\(a \\neq 0\\) and is not join-irreducible (otherwise it would be a join of itself), we have \\(a = x \\vee y\\) for some \\(x, y < a\\). By minimality, both \\(x\\) and \\(y\\) are joins of join-irreducible elements. Hence \\(a = x \\vee y\\) is also a join of join-irreducible elements, a contradiction. \u220e\n\n**Lemma 2** (Join-irreducible implies join-prime in distributive lattices). Let \\(L\\) be a distributive lattice and let \\(j \\in L\\) be join-irreducible. If \\(j \\leq \\bigvee_{i=1}^{n} x_i\\) for some finite set \\(\\{x_1,\\dots,x_n\\} \\subseteq L\\), then there exists an index \\(i\\) such that \\(j \\leq x_i\\). In particular, for \\(n=2\\), \\(j \\leq x \\vee y\\) implies \\(j \\leq x\\) or \\(j \\leq y\\).\n\n*Proof.* By distributivity,\n\\[\nj = j \\wedge \\left( \\bigvee_{i=1}^{n} x_i \\right) = \\bigvee_{i=1}^{n} (j \\wedge x_i).\n\\]\nSince \\(j\\) is join-irreducible, the join on the right cannot be a proper join; therefore one of the terms must equal \\(j\\), i.e., \\(j = j \\wedge x_i\\) for some \\(i\\), which means \\(j \\leq x_i\\). \u220e\n\n**Well-definedness.** For any \\(a \\in L\\), \\(\\varphi(a) = \\{j \\in J(L) : j \\leq a\\}\\) is an order ideal of \\(J(L)\\): if \\(j \\in \\varphi(a)\\) and \\(k \\in J(L)\\) with \\(k \\leq j\\), then \\(k \\leq j \\leq a\\), so \\(k \\in \\varphi(a)\\). Hence \\(\\varphi(a) \\in D(J(L))\\).\n\n**Injectivity.** We show that \\(a = \\bigvee \\varphi(a)\\) for every \\(a \\in L\\).\n\n- If \\(a = 0\\), then \\(\\varphi(0) = \\emptyset\\) and the empty join is defined to be \\(0\\), so \\(0 = \\bigvee \\varphi(0)\\).\n- If \\(a \\neq 0\\), by Lemma 1 there exists a finite nonempty set \\(T \\subseteq J(L)\\) such that \\(a = \\bigvee T\\). Clearly \\(T \\subseteq \\varphi(a)\\) because each \\(t \\in T\\) satisfies \\(t \\leq a\\). Therefore\n  \\[\n  a = \\bigvee T \\leq \\bigvee \\varphi(a) \\leq a,\n  \\]\n  where the last inequality holds because every element of \\(\\varphi(a)\\) is \\(\\leq a\\). Hence \\(a = \\bigvee \\varphi(a)\\).\n\nConsequently, if \\(\\varphi(a) = \\varphi(b)\\), then\n\\[\na = \\bigvee \\varphi(a) = \\bigvee \\varphi(b) = b,\n\\]\nso \\(\\varphi\\) is injective.\n\n**Surjectivity.** Let \\(I \\in D(J(L))\\) be an order ideal. Since \\(L\\) is finite, \\(I\\) is finite. Set \\(a = \\bigvee I\\) (with the convention that \\(\\bigvee \\emptyset = 0\\)). We claim that \\(\\varphi(a) = I\\).\n\n- \\(I \\subseteq \\varphi(a)\\): If \\(j \\in I\\), then \\(j \\leq \\bigvee I = a\\), so \\(j \\in \\varphi(a)\\).\n- \\(\\varphi(a) \\subseteq I\\): Let \\(j \\in \\varphi(a)\\), i.e., \\(j \\in J(L)\\) and \\(j \\leq a = \\bigvee I\\). If \\(I = \\emptyset\\), then \\(a = 0\\) and \\(\\varphi(0) = \\emptyset\\), so the inclusion is trivial. If \\(I \\neq \\emptyset\\), apply Lemma\u202f2 to the finite set \\(I\\): there exists some \\(i \\in I\\) such that \\(j \\leq i\\). Since \\(I\\) is an order ideal and \\(i \\in I\\), we have \\(j \\in I\\).\n\nThus \\(\\varphi(a) = I\\), proving surjectivity.\n\n**Preservation of operations.** For any \\(a, b \\in L\\):\n\n- **Join:** \\(\\varphi(a \\vee b) = \\{ j \\in J(L) : j \\leq a \\vee b \\}\\). By Lemma\u202f2 (binary case), \\(j \\leq a \\vee b\\) iff \\(j \\leq a\\) or \\(j \\leq b\\). Hence\n  \\[\n  \\varphi(a \\vee b) = \\{ j \\in J(L) : j \\leq a\\} \\cup \\{ j \\in J(L) : j \\leq b\\} = \\varphi(a) \\cup \\varphi(b).\n  \\]\n\n- **Meet:** \\(\\varphi(a \\wedge b) = \\{ j \\in J(L) : j \\leq a \\wedge b \\}\\). Since \\(j \\leq a \\wedge b\\) is equivalent to \\(j \\leq a\\) and \\(j \\leq b\\), we have\n  \\[\n  \\varphi(a \\wedge b) = \\varphi(a) \\cap \\varphi(b).\n  \\]\n\nThus \\(\\varphi\\) is a lattice homomorphism. Because it is bijective, it is a lattice isomorphism.\n\nTherefore, \\(\\varphi: L \\to D(J(L))\\) is a lattice isomorphism, completing the proof. \u220e\n[/ANSWER]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "5",
    "outer_attempt": 1,
    "topic_slug": "general_algebraic_systems",
    "topic_name": "General algebraic systems",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $S$ be a semigroup (i.e., a set with an associative binary operation) such that for all $a, b \\in S$, $a = aba$. Prove that $S$ is a rectangular band: that is, show that\n\n1. $a^2 = a$ for all $a \\in S$ (idempotence), and\n2. $xyz = xz$ for all $x, y, z \\in S$.",
            "answer": "**Proof.**  \n\n**Idempotence.**  \nFor any $a \\in S$, take $b = a$ in the given identity to obtain  \n$$\na = a a a = a^3.\n$$  \nNext, take $b = a^2$ (which belongs to $S$ because $S$ is closed under the operation) to obtain  \n$$\na = a (a^2) a.\n$$  \nCompute the right\u2011hand side using associativity:  \n$$\na (a^2) a = (a a^2) a = a^3 a = a^4.\n$$  \nHence $a = a^4$. Together with $a = a^3$ we have $a^4 = a^3$, i.e., $a^3 a = a^3$. Since $a^3 = a$, this simplifies to $a a = a$, i.e., $a^2 = a$. Thus every element of $S$ is idempotent.\n\n**Rectangular identity.**  \nNote that the condition $a = aba$ is equivalent to $aba = a$ for all $a,b \\in S$. Now let $x, y, z \\in S$ be arbitrary.\n\n1. Apply the identity with $a = x$ and $b = yz$ (note $yz \\in S$) to get  \n   $$\n   x = x (yz) x = x y z x.\n   $$  \n   Multiplying on the right by $z$ yields  \n   $$\n   x z = (x y z x) z = x y z (x z). \\tag{1}\n   $$  \n   Hence $(x y z)(x z) = x z$.\n\n2. Compute the same product $(x y z)(x z)$ in a different way. Using associativity and the identity with $a = z$, $b = x$ (which gives $z = z x z$, i.e., $z x z = z$) we obtain  \n   $$\n   (x y z)(x z) = ((x y) z)(x z) = (x y)(z x z) = (x y) z = x y z. \\tag{2}\n   $$\n\nComparing (1) and (2) gives $x y z = x z$, which is exactly the required identity.\n\nTherefore $S$ satisfies both properties of a rectangular band. \u220e",
            "raw_answer": "[QUESTION]\nLet $S$ be a semigroup (i.e., a set with an associative binary operation) such that for all $a, b \\in S$, $a = aba$. Prove that $S$ is a rectangular band: that is, show that\n\n1. $a^2 = a$ for all $a \\in S$ (idempotence), and\n2. $xyz = xz$ for all $x, y, z \\in S$.\n\n[ANSWER]\n**Proof.**  \n\n**Idempotence.**  \nFor any $a \\in S$, take $b = a$ in the given identity to obtain  \n\\[\na = a a a = a^3.\n\\]  \nNext, take $b = a^2$ (which belongs to $S$ because $S$ is closed under the operation) to obtain  \n\\[\na = a (a^2) a.\n\\]  \nCompute the right\u2011hand side using associativity:  \n\\[\na (a^2) a = (a a^2) a = a^3 a = a^4.\n\\]  \nHence $a = a^4$. Together with $a = a^3$ we have $a^4 = a^3$, i.e., $a^3 a = a^3$. Since $a^3 = a$, this simplifies to $a a = a$, i.e., $a^2 = a$. Thus every element of $S$ is idempotent.\n\n**Rectangular identity.**  \nNote that the condition $a = aba$ is equivalent to $aba = a$ for all $a,b \\in S$. Now let $x, y, z \\in S$ be arbitrary.\n\n1. Apply the identity with $a = x$ and $b = yz$ (note $yz \\in S$) to get  \n   \\[\n   x = x (yz) x = x y z x.\n   \\]  \n   Multiplying on the right by $z$ yields  \n   \\[\n   x z = (x y z x) z = x y z (x z). \\tag{1}\n   \\]  \n   Hence $(x y z)(x z) = x z$.\n\n2. Compute the same product $(x y z)(x z)$ in a different way. Using associativity and the identity with $a = z$, $b = x$ (which gives $z = z x z$, i.e., $z x z = z$) we obtain  \n   \\[\n   (x y z)(x z) = ((x y) z)(x z) = (x y)(z x z) = (x y) z = x y z. \\tag{2}\n   \\]\n\nComparing (1) and (2) gives $x y z = x z$, which is exactly the required identity.\n\nTherefore $S$ satisfies both properties of a rectangular band. \u220e",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "6",
    "outer_attempt": 1,
    "topic_slug": "field_theory_and_polynomials",
    "topic_name": "Field theory and polynomials",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Find the minimal polynomial of $\\alpha = \\sqrt{2} + \\sqrt{3} + \\sqrt{5}$ over $\\mathbb{Q}$. Prove that your polynomial is indeed the minimal polynomial.",
            "answer": "**Solution.**  \n\nWe determine the minimal polynomial of $\\alpha = \\sqrt{2}+\\sqrt{3}+\\sqrt{5}$ over $\\mathbb{Q}$ by first studying the field extension $\\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5})$ and then deriving an explicit monic polynomial of degree\u202f8 satisfied by $\\alpha$. The proof that this polynomial is the minimal polynomial relies on showing that $[\\mathbb{Q}(\\alpha):\\mathbb{Q}] = 8$.\n\n---\n\n### 1. Degree of $\\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5})$ over $\\mathbb{Q}$\n\n**Lemma 1.** $[\\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5}):\\mathbb{Q}] = 8$.\n\n*Proof.*  \nClearly $[\\mathbb{Q}(\\sqrt{2}):\\mathbb{Q}] = 2$ because $x^2-2$ is irreducible over $\\mathbb{Q}$.  \n\nWe show $\\sqrt{3} \\notin \\mathbb{Q}(\\sqrt{2})$. Assume $\\sqrt{3} = a + b\\sqrt{2}$ with $a,b\\in\\mathbb{Q}$. Squaring gives  \n$$\n3 = a^2 + 2b^2 + 2ab\\sqrt{2}.\n$$  \nIf $ab \\neq 0$, then $\\sqrt{2}$ would be rational, contradiction. Hence $ab=0$.  \nIf $b=0$ then $\\sqrt{3}=a\\in\\mathbb{Q}$, impossible.  \nIf $a=0$ then $\\sqrt{3}=b\\sqrt{2}$ leads to $3=2b^2$, i.e. $b^2=3/2$, which has no rational solution.  \nThus $\\sqrt{3}\\notin \\mathbb{Q}(\\sqrt{2})$ and $[\\mathbb{Q}(\\sqrt{2},\\sqrt{3}):\\mathbb{Q}] = 4$.\n\nNow we prove $\\sqrt{5}\\notin \\mathbb{Q}(\\sqrt{2},\\sqrt{3})$. Suppose  \n$$\n\\sqrt{5} = a + b\\sqrt{2} + c\\sqrt{3} + d\\sqrt{6} \\qquad (a,b,c,d\\in\\mathbb{Q}).\n$$  \nConsider the automorphism $\\sigma$ of $\\mathbb{Q}(\\sqrt{2},\\sqrt{3})$ defined by $\\sigma(\\sqrt{2}) = -\\sqrt{2}$, $\\sigma(\\sqrt{3}) = \\sqrt{3}$. Since $\\sigma$ fixes $\\mathbb{Q}(\\sqrt{3})$, it must map $\\sqrt{5}$ to a conjugate, i.e. either $\\sqrt{5}$ or $-\\sqrt{5}$. Compute  \n$$\n\\sigma(\\sqrt{5}) = a - b\\sqrt{2} + c\\sqrt{3} - d\\sqrt{6}.\n$$\n\n*Case 1:* $\\sigma(\\sqrt{5}) = \\sqrt{5}$. Then subtracting the two expressions yields  \n$-b\\sqrt{2} - d\\sqrt{6} = b\\sqrt{2} + d\\sqrt{6}$, hence $2b\\sqrt{2}+2d\\sqrt{6}=0$, so $b=d=0$. Then $\\sqrt{5}=a+c\\sqrt{3}$.  \nApply the automorphism $\\tau$ with $\\tau(\\sqrt{2})=\\sqrt{2}$, $\\tau(\\sqrt{3})=-\\sqrt{3}$. Then  \n$\\tau(\\sqrt{5}) = a - c\\sqrt{3}$. This must again be $\\pm\\sqrt{5}$.  \nIf $\\tau(\\sqrt{5})=\\sqrt{5}$, we get $a-c\\sqrt{3}=a+c\\sqrt{3} \\Rightarrow c=0$, so $\\sqrt{5}=a\\in\\mathbb{Q}$, contradiction.  \nIf $\\tau(\\sqrt{5})=-\\sqrt{5}$, then $a-c\\sqrt{3} = -a - c\\sqrt{3} \\Rightarrow 2a=0 \\Rightarrow a=0$, so $\\sqrt{5}=c\\sqrt{3} \\Rightarrow 5=3c^2$, impossible for rational $c$.  \nHence this case cannot occur.\n\n*Case 2:* $\\sigma(\\sqrt{5}) = -\\sqrt{5}$. Then  \n$$\na - b\\sqrt{2} + c\\sqrt{3} - d\\sqrt{6} = -a - b\\sqrt{2} - c\\sqrt{3} - d\\sqrt{6}.\n$$  \nBringing terms together gives $2a + 2c\\sqrt{3}=0$, so $a=c=0$. Then $\\sqrt{5}=b\\sqrt{2}+d\\sqrt{6} = \\sqrt{2}(b+d\\sqrt{3})$.  \nNow apply $\\tau$: $\\tau(\\sqrt{5}) = b\\sqrt{2} - d\\sqrt{6} = \\sqrt{2}(b-d\\sqrt{3})$. This must equal $\\pm\\sqrt{5} = \\pm\\sqrt{2}(b+d\\sqrt{3})$.  \nIf it equals $\\sqrt{5}$, then $b-d\\sqrt{3}=b+d\\sqrt{3} \\Rightarrow d=0$, so $\\sqrt{5}=b\\sqrt{2} \\Rightarrow 5=2b^2$, impossible.  \nIf it equals $-\\sqrt{5}$, then $b-d\\sqrt{3} = -b - d\\sqrt{3} \\Rightarrow 2b=0 \\Rightarrow b=0$, so $\\sqrt{5}=d\\sqrt{6} \\Rightarrow 5=6d^2$, also impossible.  \nThus case\u202f2 also leads to contradiction.\n\nTherefore $\\sqrt{5}\\notin \\mathbb{Q}(\\sqrt{2},\\sqrt{3})$. By the tower law,  \n$$\n[\\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5}):\\mathbb{Q}] = [\\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5}):\\mathbb{Q}(\\sqrt{2},\\sqrt{3})] \\cdot [\\mathbb{Q}(\\sqrt{2},\\sqrt{3}):\\mathbb{Q}] = 2 \\cdot 4 = 8. \\quad \\square\n$$\n\n---\n\n### 2. Galois group of $K = \\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5})$\n\n**Lemma 2.** $K$ is Galois over $\\mathbb{Q}$ and $\\operatorname{Gal}(K/\\mathbb{Q}) \\cong (\\mathbb{Z}/2\\mathbb{Z})^3$. Explicitly, each automorphism $\\sigma$ is determined by  \n$$\n\\sigma(\\sqrt{2}) = \\pm \\sqrt{2},\\quad \\sigma(\\sqrt{3}) = \\pm \\sqrt{3},\\quad \\sigma(\\sqrt{5}) = \\pm \\sqrt{5},\n$$  \nand all eight sign choices occur.\n\n*Proof.* $K$ is the splitting field of the separable polynomial $(x^2-2)(x^2-3)(x^2-5)$ over $\\mathbb{Q}$, hence Galois. Since $[K:\\mathbb{Q}]=8$, the Galois group has order\u202f8. For any choice of signs, the map sending each $\\sqrt{p}$ to the chosen sign times itself extends uniquely to an automorphism of $K$ (it respects the defining relations). Thus there are at least\u202f8 automorphisms; because the order is exactly\u202f8, all possibilities occur. $\\square$\n\n---\n\n### 3. Degree of $\\mathbb{Q}(\\alpha)$ over $\\mathbb{Q}$\n\n**Lemma 3.** $[\\mathbb{Q}(\\alpha):\\mathbb{Q}] = 8$; consequently the minimal polynomial of $\\alpha$ over $\\mathbb{Q}$ has degree\u202f8.\n\n*Proof.* Let $G = \\operatorname{Gal}(K/\\mathbb{Q})$. Consider the stabilizer  \n$H = \\{\\sigma \\in G \\mid \\sigma(\\alpha) = \\alpha\\}$.  \nIf $\\sigma$ changes the sign of $\\sqrt{2}$ (keeping the others fixed), then  \n$\\sigma(\\alpha) = -\\sqrt{2}+\\sqrt{3}+\\sqrt{5} = \\alpha - 2\\sqrt{2} \\neq \\alpha$ because $\\sqrt{2}\\neq 0$.  \nSimilarly, changing only $\\sqrt{3}$ or only $\\sqrt{5}$ gives a different value. If $\\sigma$ changes two or three signs, the difference is a non\u2011zero linear combination of $\\sqrt{2},\\sqrt{3},\\sqrt{5}$ and again cannot vanish. Hence no non\u2011identity automorphism fixes $\\alpha$, i.e. $H = \\{ \\mathrm{id} \\}$.  \n\nBy the Galois correspondence, the fixed field of $H$ is $\\mathbb{Q}(\\alpha)$. But the fixed field of the trivial subgroup is the whole field $K$. Therefore $\\mathbb{Q}(\\alpha) = K$ and  \n$[\\mathbb{Q}(\\alpha):\\mathbb{Q}] = [K:\\mathbb{Q}] = 8$. $\\square$\n\n---\n\n### 4. Derivation of a degree\u20118 polynomial satisfied by $\\alpha$\n\nSet $\\alpha = \\sqrt{2}+\\sqrt{3}+\\sqrt{5}$. Isolate $\\sqrt{5}$:\n\n$$\n\\alpha - \\sqrt{5} = \\sqrt{2}+\\sqrt{3}.\n$$\n\nSquare both sides:\n\n$$\n(\\alpha - \\sqrt{5})^2 = (\\sqrt{2}+\\sqrt{3})^2,\n$$\n$$\n\\alpha^2 - 2\\sqrt{5}\\alpha + 5 = 2 + 3 + 2\\sqrt{6} = 5 + 2\\sqrt{6}.\n$$\n\nCancel 5:\n\n$$\n\\alpha^2 - 2\\sqrt{5}\\alpha = 2\\sqrt{6}. \\tag{1}\n$$\n\nRewrite (1) as\n\n$$\n\\alpha^2 = 2\\sqrt{5}\\alpha + 2\\sqrt{6}. \\tag{1'}\n$$\n\nSquare (1'):\n\n$$\n\\alpha^4 = (2\\sqrt{5}\\alpha + 2\\sqrt{6})^2 = 20\\alpha^2 + 8\\sqrt{30}\\alpha + 24.\n$$\n\nThus\n\n$$\n\\alpha^4 - 20\\alpha^2 - 24 = 8\\sqrt{30}\\alpha. \\tag{2}\n$$\n\nSquare (2):\n\n$$\n(\\alpha^4 - 20\\alpha^2 - 24)^2 = 64 \\cdot 30 \\, \\alpha^2 = 1920 \\alpha^2.\n$$\n\nExpand the left\u2011hand side:\n\n$$\n(\\alpha^4 - 20\\alpha^2 - 24)^2 = \\alpha^8 - 40\\alpha^6 + 352\\alpha^4 - 960\\alpha^2 + 576.\n$$\n\n(Detailed expansion:  \n$(\\alpha^4)^2 = \\alpha^8$;  \n$2(\\alpha^4)(-20\\alpha^2) = -40\\alpha^6$;  \n$2(\\alpha^4)(-24) = -48\\alpha^4$;  \n$(-20\\alpha^2)^2 = 400\\alpha^4$;  \n$2(-20\\alpha^2)(-24) = 960\\alpha^2$;  \n$(-24)^2 = 576$.  \nSumming: $\\alpha^8 - 40\\alpha^6 + (400-48)\\alpha^4 + 960\\alpha^2 + 576 = \\alpha^8 - 40\\alpha^6 + 352\\alpha^4 + 960\\alpha^2 + 576$.  \nThen subtracting $1920\\alpha^2$ gives the polynomial below.)\n\nTherefore\n\n$$\n\\alpha^8 - 40\\alpha^6 + 352\\alpha^4 - 960\\alpha^2 + 576 = 0.\n$$\n\nHence $\\alpha$ is a root of the monic polynomial\n\n$$\nP(x) = x^8 - 40x^6 + 352x^4 - 960x^2 + 576 \\in \\mathbb{Z}[x].\n$$\n\n---\n\n### 5. Conclusion\n\nBy Lemma\u202f3, the minimal polynomial of $\\alpha$ over $\\mathbb{Q}$ has degree\u202f8. Since $P(x)$ is a monic polynomial of degree\u202f8 with rational coefficients and $\\alpha$ as a root, it must be that minimal polynomial. Consequently, the minimal polynomial of $\\sqrt{2}+\\sqrt{3}+\\sqrt{5}$ over $\\mathbb{Q}$ is\n\n$$\n\\boxed{x^8 - 40x^6 + 352x^4 - 960x^2 + 576}.\n$$",
            "raw_answer": "[QUESTION]\nFind the minimal polynomial of \\(\\alpha = \\sqrt{2} + \\sqrt{3} + \\sqrt{5}\\) over \\(\\mathbb{Q}\\). Prove that your polynomial is indeed the minimal polynomial.\n\n[ANSWER]\n**Solution.**  \n\nWe determine the minimal polynomial of \\(\\alpha = \\sqrt{2}+\\sqrt{3}+\\sqrt{5}\\) over \\(\\mathbb{Q}\\) by first studying the field extension \\(\\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5})\\) and then deriving an explicit monic polynomial of degree\u202f8 satisfied by \\(\\alpha\\). The proof that this polynomial is the minimal polynomial relies on showing that \\([\\mathbb{Q}(\\alpha):\\mathbb{Q}] = 8\\).\n\n---\n\n### 1. Degree of \\(\\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5})\\) over \\(\\mathbb{Q}\\)\n\n**Lemma 1.** \\([\\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5}):\\mathbb{Q}] = 8\\).\n\n*Proof.*  \nClearly \\([\\mathbb{Q}(\\sqrt{2}):\\mathbb{Q}] = 2\\) because \\(x^2-2\\) is irreducible over \\(\\mathbb{Q}\\).  \n\nWe show \\(\\sqrt{3} \\notin \\mathbb{Q}(\\sqrt{2})\\). Assume \\(\\sqrt{3} = a + b\\sqrt{2}\\) with \\(a,b\\in\\mathbb{Q}\\). Squaring gives  \n\\[\n3 = a^2 + 2b^2 + 2ab\\sqrt{2}.\n\\]  \nIf \\(ab \\neq 0\\), then \\(\\sqrt{2}\\) would be rational, contradiction. Hence \\(ab=0\\).  \nIf \\(b=0\\) then \\(\\sqrt{3}=a\\in\\mathbb{Q}\\), impossible.  \nIf \\(a=0\\) then \\(\\sqrt{3}=b\\sqrt{2}\\) leads to \\(3=2b^2\\), i.e. \\(b^2=3/2\\), which has no rational solution.  \nThus \\(\\sqrt{3}\\notin \\mathbb{Q}(\\sqrt{2})\\) and \\([\\mathbb{Q}(\\sqrt{2},\\sqrt{3}):\\mathbb{Q}] = 4\\).\n\nNow we prove \\(\\sqrt{5}\\notin \\mathbb{Q}(\\sqrt{2},\\sqrt{3})\\). Suppose  \n\\[\n\\sqrt{5} = a + b\\sqrt{2} + c\\sqrt{3} + d\\sqrt{6} \\qquad (a,b,c,d\\in\\mathbb{Q}).\n\\]  \nConsider the automorphism \\(\\sigma\\) of \\(\\mathbb{Q}(\\sqrt{2},\\sqrt{3})\\) defined by \\(\\sigma(\\sqrt{2}) = -\\sqrt{2}\\), \\(\\sigma(\\sqrt{3}) = \\sqrt{3}\\). Since \\(\\sigma\\) fixes \\(\\mathbb{Q}(\\sqrt{3})\\), it must map \\(\\sqrt{5}\\) to a conjugate, i.e. either \\(\\sqrt{5}\\) or \\(-\\sqrt{5}\\). Compute  \n\\[\n\\sigma(\\sqrt{5}) = a - b\\sqrt{2} + c\\sqrt{3} - d\\sqrt{6}.\n\\]\n\n*Case 1:* \\(\\sigma(\\sqrt{5}) = \\sqrt{5}\\). Then subtracting the two expressions yields  \n\\(-b\\sqrt{2} - d\\sqrt{6} = b\\sqrt{2} + d\\sqrt{6}\\), hence \\(2b\\sqrt{2}+2d\\sqrt{6}=0\\), so \\(b=d=0\\). Then \\(\\sqrt{5}=a+c\\sqrt{3}\\).  \nApply the automorphism \\(\\tau\\) with \\(\\tau(\\sqrt{2})=\\sqrt{2}\\), \\(\\tau(\\sqrt{3})=-\\sqrt{3}\\). Then  \n\\(\\tau(\\sqrt{5}) = a - c\\sqrt{3}\\). This must again be \\(\\pm\\sqrt{5}\\).  \nIf \\(\\tau(\\sqrt{5})=\\sqrt{5}\\), we get \\(a-c\\sqrt{3}=a+c\\sqrt{3} \\Rightarrow c=0\\), so \\(\\sqrt{5}=a\\in\\mathbb{Q}\\), contradiction.  \nIf \\(\\tau(\\sqrt{5})=-\\sqrt{5}\\), then \\(a-c\\sqrt{3} = -a - c\\sqrt{3} \\Rightarrow 2a=0 \\Rightarrow a=0\\), so \\(\\sqrt{5}=c\\sqrt{3} \\Rightarrow 5=3c^2\\), impossible for rational \\(c\\).  \nHence this case cannot occur.\n\n*Case 2:* \\(\\sigma(\\sqrt{5}) = -\\sqrt{5}\\). Then  \n\\[\na - b\\sqrt{2} + c\\sqrt{3} - d\\sqrt{6} = -a - b\\sqrt{2} - c\\sqrt{3} - d\\sqrt{6}.\n\\]  \nBringing terms together gives \\(2a + 2c\\sqrt{3}=0\\), so \\(a=c=0\\). Then \\(\\sqrt{5}=b\\sqrt{2}+d\\sqrt{6} = \\sqrt{2}(b+d\\sqrt{3})\\).  \nNow apply \\(\\tau\\): \\(\\tau(\\sqrt{5}) = b\\sqrt{2} - d\\sqrt{6} = \\sqrt{2}(b-d\\sqrt{3})\\). This must equal \\(\\pm\\sqrt{5} = \\pm\\sqrt{2}(b+d\\sqrt{3})\\).  \nIf it equals \\(\\sqrt{5}\\), then \\(b-d\\sqrt{3}=b+d\\sqrt{3} \\Rightarrow d=0\\), so \\(\\sqrt{5}=b\\sqrt{2} \\Rightarrow 5=2b^2\\), impossible.  \nIf it equals \\(-\\sqrt{5}\\), then \\(b-d\\sqrt{3} = -b - d\\sqrt{3} \\Rightarrow 2b=0 \\Rightarrow b=0\\), so \\(\\sqrt{5}=d\\sqrt{6} \\Rightarrow 5=6d^2\\), also impossible.  \nThus case\u202f2 also leads to contradiction.\n\nTherefore \\(\\sqrt{5}\\notin \\mathbb{Q}(\\sqrt{2},\\sqrt{3})\\). By the tower law,  \n\\[\n[\\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5}):\\mathbb{Q}] = [\\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5}):\\mathbb{Q}(\\sqrt{2},\\sqrt{3})] \\cdot [\\mathbb{Q}(\\sqrt{2},\\sqrt{3}):\\mathbb{Q}] = 2 \\cdot 4 = 8. \\quad \\square\n\\]\n\n---\n\n### 2. Galois group of \\(K = \\mathbb{Q}(\\sqrt{2},\\sqrt{3},\\sqrt{5})\\)\n\n**Lemma 2.** \\(K\\) is Galois over \\(\\mathbb{Q}\\) and \\(\\operatorname{Gal}(K/\\mathbb{Q}) \\cong (\\mathbb{Z}/2\\mathbb{Z})^3\\). Explicitly, each automorphism \\(\\sigma\\) is determined by  \n\\[\n\\sigma(\\sqrt{2}) = \\pm \\sqrt{2},\\quad \\sigma(\\sqrt{3}) = \\pm \\sqrt{3},\\quad \\sigma(\\sqrt{5}) = \\pm \\sqrt{5},\n\\]  \nand all eight sign choices occur.\n\n*Proof.* \\(K\\) is the splitting field of the separable polynomial \\((x^2-2)(x^2-3)(x^2-5)\\) over \\(\\mathbb{Q}\\), hence Galois. Since \\([K:\\mathbb{Q}]=8\\), the Galois group has order\u202f8. For any choice of signs, the map sending each \\(\\sqrt{p}\\) to the chosen sign times itself extends uniquely to an automorphism of \\(K\\) (it respects the defining relations). Thus there are at least\u202f8 automorphisms; because the order is exactly\u202f8, all possibilities occur. \\(\\square\\)\n\n---\n\n### 3. Degree of \\(\\mathbb{Q}(\\alpha)\\) over \\(\\mathbb{Q}\\)\n\n**Lemma 3.** \\([\\mathbb{Q}(\\alpha):\\mathbb{Q}] = 8\\); consequently the minimal polynomial of \\(\\alpha\\) over \\(\\mathbb{Q}\\) has degree\u202f8.\n\n*Proof.* Let \\(G = \\operatorname{Gal}(K/\\mathbb{Q})\\). Consider the stabilizer  \n\\(H = \\{\\sigma \\in G \\mid \\sigma(\\alpha) = \\alpha\\}\\).  \nIf \\(\\sigma\\) changes the sign of \\(\\sqrt{2}\\) (keeping the others fixed), then  \n\\(\\sigma(\\alpha) = -\\sqrt{2}+\\sqrt{3}+\\sqrt{5} = \\alpha - 2\\sqrt{2} \\neq \\alpha\\) because \\(\\sqrt{2}\\neq 0\\).  \nSimilarly, changing only \\(\\sqrt{3}\\) or only \\(\\sqrt{5}\\) gives a different value. If \\(\\sigma\\) changes two or three signs, the difference is a non\u2011zero linear combination of \\(\\sqrt{2},\\sqrt{3},\\sqrt{5}\\) and again cannot vanish. Hence no non\u2011identity automorphism fixes \\(\\alpha\\), i.e. \\(H = \\{ \\mathrm{id} \\}\\).  \n\nBy the Galois correspondence, the fixed field of \\(H\\) is \\(\\mathbb{Q}(\\alpha)\\). But the fixed field of the trivial subgroup is the whole field \\(K\\). Therefore \\(\\mathbb{Q}(\\alpha) = K\\) and  \n\\([\\mathbb{Q}(\\alpha):\\mathbb{Q}] = [K:\\mathbb{Q}] = 8\\). \\(\\square\\)\n\n---\n\n### 4. Derivation of a degree\u20118 polynomial satisfied by \\(\\alpha\\)\n\nSet \\(\\alpha = \\sqrt{2}+\\sqrt{3}+\\sqrt{5}\\). Isolate \\(\\sqrt{5}\\):\n\n\\[\n\\alpha - \\sqrt{5} = \\sqrt{2}+\\sqrt{3}.\n\\]\n\nSquare both sides:\n\n\\[\n(\\alpha - \\sqrt{5})^2 = (\\sqrt{2}+\\sqrt{3})^2,\n\\]\n\\[\n\\alpha^2 - 2\\sqrt{5}\\alpha + 5 = 2 + 3 + 2\\sqrt{6} = 5 + 2\\sqrt{6}.\n\\]\n\nCancel 5:\n\n\\[\n\\alpha^2 - 2\\sqrt{5}\\alpha = 2\\sqrt{6}. \\tag{1}\n\\]\n\nRewrite (1) as\n\n\\[\n\\alpha^2 = 2\\sqrt{5}\\alpha + 2\\sqrt{6}. \\tag{1'}\n\\]\n\nSquare (1'):\n\n\\[\n\\alpha^4 = (2\\sqrt{5}\\alpha + 2\\sqrt{6})^2 = 20\\alpha^2 + 8\\sqrt{30}\\alpha + 24.\n\\]\n\nThus\n\n\\[\n\\alpha^4 - 20\\alpha^2 - 24 = 8\\sqrt{30}\\alpha. \\tag{2}\n\\]\n\nSquare (2):\n\n\\[\n(\\alpha^4 - 20\\alpha^2 - 24)^2 = 64 \\cdot 30 \\, \\alpha^2 = 1920 \\alpha^2.\n\\]\n\nExpand the left\u2011hand side:\n\n\\[\n(\\alpha^4 - 20\\alpha^2 - 24)^2 = \\alpha^8 - 40\\alpha^6 + 352\\alpha^4 - 960\\alpha^2 + 576.\n\\]\n\n(Detailed expansion:  \n\\((\\alpha^4)^2 = \\alpha^8\\);  \n\\(2(\\alpha^4)(-20\\alpha^2) = -40\\alpha^6\\);  \n\\(2(\\alpha^4)(-24) = -48\\alpha^4\\);  \n\\((-20\\alpha^2)^2 = 400\\alpha^4\\);  \n\\(2(-20\\alpha^2)(-24) = 960\\alpha^2\\);  \n\\((-24)^2 = 576\\).  \nSumming: \\(\\alpha^8 - 40\\alpha^6 + (400-48)\\alpha^4 + 960\\alpha^2 + 576 = \\alpha^8 - 40\\alpha^6 + 352\\alpha^4 + 960\\alpha^2 + 576\\).  \nThen subtracting \\(1920\\alpha^2\\) gives the polynomial below.)\n\nTherefore\n\n\\[\n\\alpha^8 - 40\\alpha^6 + 352\\alpha^4 - 960\\alpha^2 + 576 = 0.\n\\]\n\nHence \\(\\alpha\\) is a root of the monic polynomial\n\n\\[\nP(x) = x^8 - 40x^6 + 352x^4 - 960x^2 + 576 \\in \\mathbb{Z}[x].\n\\]\n\n---\n\n### 5. Conclusion\n\nBy Lemma\u202f3, the minimal polynomial of \\(\\alpha\\) over \\(\\mathbb{Q}\\) has degree\u202f8. Since \\(P(x)\\) is a monic polynomial of degree\u202f8 with rational coefficients and \\(\\alpha\\) as a root, it must be that minimal polynomial. Consequently, the minimal polynomial of \\(\\sqrt{2}+\\sqrt{3}+\\sqrt{5}\\) over \\(\\mathbb{Q}\\) is\n\n\\[\n\\boxed{x^8 - 40x^6 + 352x^4 - 960x^2 + 576}.\n\\]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "7",
    "outer_attempt": 1,
    "topic_slug": "commutative_algebra",
    "topic_name": "Commutative algebra",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $R$ be a Noetherian commutative ring with identity. An element $r \\in R$ is called a **zero-divisor** if there exists a nonzero $s \\in R$ such that $rs = 0$. An **associated prime** of $R$ is a prime ideal that can be written as $\\operatorname{Ann}(x) = \\{ r \\in R \\mid r x = 0\\}$ for some nonzero $x \\in R$. Prove that the set of zero-divisors of $R$ is exactly the union of all associated primes of $R$.",
            "answer": "We prove the equality by showing two inclusions.\n\n**1. Every element of an associated prime is a zero-divisor.**  \nIf $r$ belongs to an associated prime $P = \\operatorname{Ann}(x)$ with $x \\neq 0$, then by definition $r x = 0$. Since $x \\neq 0$, $r$ is a zero-divisor. Hence\n$$\n\\bigcup_{P \\in \\operatorname{Ass}(R)} P \\subseteq Z(R),\n$$\nwhere $Z(R)$ denotes the set of zero-divisors.\n\n**2. Every zero-divisor belongs to some associated prime.**  \nAssume $r \\in Z(R)$, so there exists a nonzero $s \\in R$ with $rs = 0$. Consider the set\n$$\n\\mathcal{S} = \\{\\, \\operatorname{Ann}(y) \\mid y \\in R,\\ y \\neq 0,\\ \\text{and } r \\in \\operatorname{Ann}(y) \\,\\}.\n$$\nThe condition $r \\in \\operatorname{Ann}(y)$ means $r y = 0$. Because $s \\neq 0$ and $r s = 0$, we have $\\operatorname{Ann}(s) \\in \\mathcal{S}$; thus $\\mathcal{S}$ is nonempty.\n\nSince $R$ is Noetherian, every nonempty set of ideals has a maximal element with respect to inclusion. (If a nonempty set had no maximal element, one could construct an infinite strictly ascending chain, contradicting the ascending chain condition.) Choose a maximal element of $\\mathcal{S}$ and denote it by $P = \\operatorname{Ann}(z)$, where $z \\neq 0$ and $r z = 0$. We claim that $P$ is a prime ideal.\n\nTo prove that $P$ is prime, let $a, b \\in R$ with $ab \\in P$, i.e., $abz = 0$. We must show that $a \\in P$ or $b \\in P$. Suppose $a \\notin P$; then $a z \\neq 0$. Consider the element $b z$.\n\n- If $b z = 0$, then $b \\in P$ and we are done.\n- If $b z \\neq 0$, then $\\operatorname{Ann}(b z)$ is the annihilator of a nonzero element. Observe:\n  * From $abz = 0$ we have $a \\in \\operatorname{Ann}(b z)$.\n  * For any $u \\in \\operatorname{Ann}(z)$, $u z = 0$ implies $u(b z) = 0$; hence $\\operatorname{Ann}(z) \\subseteq \\operatorname{Ann}(b z)$.\n  * Because $a \\notin \\operatorname{Ann}(z)$ but $a \\in \\operatorname{Ann}(b z)$, the inclusion $\\operatorname{Ann}(z) \\subseteq \\operatorname{Ann}(b z)$ is strict.\n  * Moreover, $r \\in \\operatorname{Ann}(z) \\subseteq \\operatorname{Ann}(b z)$, so $\\operatorname{Ann}(b z) \\in \\mathcal{S}$.\n\nThus we have found an element $\\operatorname{Ann}(b z) \\in \\mathcal{S}$ that strictly contains the maximal element $\\operatorname{Ann}(z)$, a contradiction. Therefore the case $b z \\neq 0$ cannot occur; we must have $b z = 0$, which gives $b \\in P$.\n\nHence $P$ is prime. By construction, $r \\in P$ and $P = \\operatorname{Ann}(z)$ is an associated prime. Consequently,\n$$\nZ(R) \\subseteq \\bigcup_{P \\in \\operatorname{Ass}(R)} P.\n$$\n\nCombining both inclusions yields $Z(R) = \\bigcup_{P \\in \\operatorname{Ass}(R)} P$, as required. \u220e",
            "raw_answer": "[QUESTION]\nLet \\(R\\) be a Noetherian commutative ring with identity. An element \\(r \\in R\\) is called a **zero-divisor** if there exists a nonzero \\(s \\in R\\) such that \\(rs = 0\\). An **associated prime** of \\(R\\) is a prime ideal that can be written as \\(\\operatorname{Ann}(x) = \\{ r \\in R \\mid r x = 0\\}\\) for some nonzero \\(x \\in R\\). Prove that the set of zero-divisors of \\(R\\) is exactly the union of all associated primes of \\(R\\).\n\n[ANSWER]\nWe prove the equality by showing two inclusions.\n\n**1. Every element of an associated prime is a zero-divisor.**  \nIf \\(r\\) belongs to an associated prime \\(P = \\operatorname{Ann}(x)\\) with \\(x \\neq 0\\), then by definition \\(r x = 0\\). Since \\(x \\neq 0\\), \\(r\\) is a zero-divisor. Hence\n\\[\n\\bigcup_{P \\in \\operatorname{Ass}(R)} P \\subseteq Z(R),\n\\]\nwhere \\(Z(R)\\) denotes the set of zero-divisors.\n\n**2. Every zero-divisor belongs to some associated prime.**  \nAssume \\(r \\in Z(R)\\), so there exists a nonzero \\(s \\in R\\) with \\(rs = 0\\). Consider the set\n\\[\n\\mathcal{S} = \\{\\, \\operatorname{Ann}(y) \\mid y \\in R,\\ y \\neq 0,\\ \\text{and } r \\in \\operatorname{Ann}(y) \\,\\}.\n\\]\nThe condition \\(r \\in \\operatorname{Ann}(y)\\) means \\(r y = 0\\). Because \\(s \\neq 0\\) and \\(r s = 0\\), we have \\(\\operatorname{Ann}(s) \\in \\mathcal{S}\\); thus \\(\\mathcal{S}\\) is nonempty.\n\nSince \\(R\\) is Noetherian, every nonempty set of ideals has a maximal element with respect to inclusion. (If a nonempty set had no maximal element, one could construct an infinite strictly ascending chain, contradicting the ascending chain condition.) Choose a maximal element of \\(\\mathcal{S}\\) and denote it by \\(P = \\operatorname{Ann}(z)\\), where \\(z \\neq 0\\) and \\(r z = 0\\). We claim that \\(P\\) is a prime ideal.\n\nTo prove that \\(P\\) is prime, let \\(a, b \\in R\\) with \\(ab \\in P\\), i.e., \\(abz = 0\\). We must show that \\(a \\in P\\) or \\(b \\in P\\). Suppose \\(a \\notin P\\); then \\(a z \\neq 0\\). Consider the element \\(b z\\).\n\n- If \\(b z = 0\\), then \\(b \\in P\\) and we are done.\n- If \\(b z \\neq 0\\), then \\(\\operatorname{Ann}(b z)\\) is the annihilator of a nonzero element. Observe:\n  * From \\(abz = 0\\) we have \\(a \\in \\operatorname{Ann}(b z)\\).\n  * For any \\(u \\in \\operatorname{Ann}(z)\\), \\(u z = 0\\) implies \\(u(b z) = 0\\); hence \\(\\operatorname{Ann}(z) \\subseteq \\operatorname{Ann}(b z)\\).\n  * Because \\(a \\notin \\operatorname{Ann}(z)\\) but \\(a \\in \\operatorname{Ann}(b z)\\), the inclusion \\(\\operatorname{Ann}(z) \\subseteq \\operatorname{Ann}(b z)\\) is strict.\n  * Moreover, \\(r \\in \\operatorname{Ann}(z) \\subseteq \\operatorname{Ann}(b z)\\), so \\(\\operatorname{Ann}(b z) \\in \\mathcal{S}\\).\n\nThus we have found an element \\(\\operatorname{Ann}(b z) \\in \\mathcal{S}\\) that strictly contains the maximal element \\(\\operatorname{Ann}(z)\\), a contradiction. Therefore the case \\(b z \\neq 0\\) cannot occur; we must have \\(b z = 0\\), which gives \\(b \\in P\\).\n\nHence \\(P\\) is prime. By construction, \\(r \\in P\\) and \\(P = \\operatorname{Ann}(z)\\) is an associated prime. Consequently,\n\\[\nZ(R) \\subseteq \\bigcup_{P \\in \\operatorname{Ass}(R)} P.\n\\]\n\nCombining both inclusions yields \\(Z(R) = \\bigcup_{P \\in \\operatorname{Ass}(R)} P\\), as required. \u220e",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "8",
    "outer_attempt": 1,
    "topic_slug": "algebraic_geometry",
    "topic_name": "Algebraic geometry",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Consider the rational map $\\varphi: \\mathbb{P}^2 \\to \\mathbb{P}^2$ over $\\mathbb{C}$ given in homogeneous coordinates by\n$$\n\\varphi(x:y:z) = (yz : xz : xy).\n$$\nLet $X$ be the blow-up of $\\mathbb{P}^2$ at the three points \n$$\nP_1 = (1:0:0),\\quad P_2 = (0:1:0),\\quad P_3 = (0:0:1).\n$$\nDenote by $\\pi: X \\to \\mathbb{P}^2$ the blow-down morphism, and let $E_1, E_2, E_3$ be the exceptional divisors over $P_1, P_2, P_3$ respectively. Let $H = \\pi^* \\mathcal{O}_{\\mathbb{P}^2}(1)$ be the pullback of the hyperplane class.\n\n(a) Show that $\\varphi$ lifts to a morphism $\\Phi: X \\to \\mathbb{P}^2$ (i.e., $\\Phi = \\varphi \\circ \\pi$ is a morphism).\n(b) Compute the class of the line bundle $\\Phi^* \\mathcal{O}_{\\mathbb{P}^2}(1)$ in $\\operatorname{Pic}(X)$ in terms of $H, E_1, E_2, E_3$.\n(c) Prove that $\\varphi$ is birational and determine its inverse rational map.",
            "answer": "**Solution (a).**  \nWe work in affine charts; by symmetry it suffices to examine the neighbourhood of $P_1$.  \nOn the affine open where $x \\neq 0$, set $x=1$. Then $\\varphi$ becomes $(yz : z : y)$ and $P_1$ corresponds to $(y,z)=(0,0)$.  \nBlow up $\\mathbb{A}^2$ at the origin:  \n$\\operatorname{Bl}_{(0,0)}\\mathbb{A}^2 = \\{((y,z),[u:v])\\in\\mathbb{A}^2\\times\\mathbb{P}^1 \\mid u z = v y\\}$.  \nTake the two standard affine charts:\n\n- **Chart $U_1$:** $u\\neq 0$, set $u=1$, then $z = v y$. Coordinates are $(y,v)$; the exceptional divisor $E_1$ is $y=0$.\n- **Chart $U_2$:** $v\\neq 0$, set $v=1$, then $y = u z$. Coordinates are $(u,z)$; $E_1$ is $z=0$.\n\nIn $U_1$ the pullbacks of the homogeneous coordinates of $\\varphi$ are  \n$$\n(yz, xz, xy) = (y\\cdot(v y),\\, 1\\cdot(v y),\\, 1\\cdot y) = (v y^2,\\; v y,\\; y).\n$$\nAll three entries are divisible by $y$. Since the map to $\\mathbb{P}^2$ is defined up to an overall scalar, we may divide the triple by $y$ (a unit away from $E_1$) to obtain an equivalent representation  \n$$\n(v y,\\; v,\\; 1).\n$$\nThis expression is polynomial in $y,v$ and is defined for all $(y,v)$, including points on $E_1$ (where $y=0$), giving $(0,v,1)$ which is a valid point in $\\mathbb{P}^2$. Hence on $U_1$ we define $\\Phi$ by $(v y : v : 1)$.\n\nIn $U_2$ the pullbacks are  \n$$\n(yz, xz, xy) = ((u z)\\cdot z,\\; 1\\cdot z,\\; 1\\cdot (u z)) = (u z^2,\\; z,\\; u z).\n$$\nDividing by $z$ yields  \n$$\n(u z,\\; 1,\\; u),\n$$\nwhich at $z=0$ gives $(0,1,u)$, again well\u2011defined. So on $U_2$ we set $\\Phi(u,z) = (u z : 1 : u)$.\n\nOn the overlap $U_1\\cap U_2$ (where $y\\neq0,\\;z\\neq0$) we have $v = z/y$ and $u = y/z$. The two definitions agree because  \n$$\n(v y : v : 1) = (z : z/y : 1) \\quad\\text{and}\\quad (u z : 1 : u) = (y : 1 : y/z),\n$$\nand these triples are proportional: multiplying the first by $y$ gives $(yz,z,y)$, multiplying the second by $z$ gives $(yz,z,y)$. Therefore $\\Phi$ is a well\u2011defined morphism on $\\pi^{-1}(\\{x\\neq0\\})$.\n\nBy symmetry, analogous charts around $P_2$ and $P_3$ show that $\\Phi$ extends to a morphism on the whole blow\u2011up $X$. Hence $\\varphi$ lifts to a morphism $\\Phi: X \\to \\mathbb{P}^2$.\n\n**Solution (b).**  \nThe morphism $\\Phi$ is given by the three global sections  \n$$\ns_0 = \\pi^*(yz),\\quad s_1 = \\pi^*(xz),\\quad s_2 = \\pi^*(xy)\n$$\nof the line bundle $\\pi^*\\mathcal{O}_{\\mathbb{P}^2}(2) = \\mathcal{O}_X(2H)$.  \nWe claim that these sections actually belong to the subsheaf $\\mathcal{O}_X(2H - E_1 - E_2 - E_3) \\subset \\mathcal{O}_X(2H)$, i.e. they vanish along each exceptional divisor.  \n\nNear a generic point of $E_1$, using chart $U_1$ as above, we have $s_0 = v y^2$, $s_1 = v y$, $s_2 = y$. All are divisible by $y$, the local equation of $E_1$; hence they vanish along $E_1$. By symmetry they vanish along $E_2$ and $E_3$ as well. Consequently, $s_0,s_1,s_2$ are global sections of the line bundle  \n$$\nL := \\mathcal{O}_X(2H - E_1 - E_2 - E_3).\n$$\n\nThese three sections have no common zero on $X$: outside the exceptional divisors this follows because $\\varphi$ is dominant; on an exceptional divisor, say $E_1$ in chart $U_1$, $\\Phi(y=0,v) = (0:v:1)$ which is never $(0:0:0)$. Thus the sections generate $L$ at every point, and therefore they define the morphism $\\Phi$. By the standard property of morphisms to projective space we obtain  \n$$\n\\Phi^*\\mathcal{O}_{\\mathbb{P}^2}(1) \\cong L = \\mathcal{O}_X(2H - E_1 - E_2 - E_3).\n$$\n\n**Solution (c).**  \nCompute the composition $\\varphi \\circ \\varphi$ as rational maps. For a point $(x:y:z)$ where all coordinates are non\u2011zero (a dense open set where $\\varphi$ is defined),  \n$$\n\\varphi(\\varphi(x:y:z)) = \\varphi(yz : xz : xy) \n= \\big( (xz)(xy) : (yz)(xy) : (yz)(xz) \\big) \n= (x^2 y z : x y^2 z : x y z^2).\n$$\nSince $x y z \\neq 0$, we may factor out $x y z$ to obtain $(x : y : z)$. Hence $\\varphi \\circ \\varphi = \\operatorname{id}_{\\mathbb{P}^2}$ as rational maps. Therefore $\\varphi$ is birational, and its inverse is $\\varphi$ itself.",
            "raw_answer": "[QUESTION]\nConsider the rational map \\(\\varphi: \\mathbb{P}^2 \\to \\mathbb{P}^2\\) over \\(\\mathbb{C}\\) given in homogeneous coordinates by\n\\[\n\\varphi(x:y:z) = (yz : xz : xy).\n\\]\nLet \\(X\\) be the blow-up of \\(\\mathbb{P}^2\\) at the three points \n\\[\nP_1 = (1:0:0),\\quad P_2 = (0:1:0),\\quad P_3 = (0:0:1).\n\\]\nDenote by \\(\\pi: X \\to \\mathbb{P}^2\\) the blow-down morphism, and let \\(E_1, E_2, E_3\\) be the exceptional divisors over \\(P_1, P_2, P_3\\) respectively. Let \\(H = \\pi^* \\mathcal{O}_{\\mathbb{P}^2}(1)\\) be the pullback of the hyperplane class.\n\n(a) Show that \\(\\varphi\\) lifts to a morphism \\(\\Phi: X \\to \\mathbb{P}^2\\) (i.e., \\(\\Phi = \\varphi \\circ \\pi\\) is a morphism).\n(b) Compute the class of the line bundle \\(\\Phi^* \\mathcal{O}_{\\mathbb{P}^2}(1)\\) in \\(\\operatorname{Pic}(X)\\) in terms of \\(H, E_1, E_2, E_3\\).\n(c) Prove that \\(\\varphi\\) is birational and determine its inverse rational map.\n\n[ANSWER]\n**Solution (a).**  \nWe work in affine charts; by symmetry it suffices to examine the neighbourhood of \\(P_1\\).  \nOn the affine open where \\(x \\neq 0\\), set \\(x=1\\). Then \\(\\varphi\\) becomes \\((yz : z : y)\\) and \\(P_1\\) corresponds to \\((y,z)=(0,0)\\).  \nBlow up \\(\\mathbb{A}^2\\) at the origin:  \n\\(\\operatorname{Bl}_{(0,0)}\\mathbb{A}^2 = \\{((y,z),[u:v])\\in\\mathbb{A}^2\\times\\mathbb{P}^1 \\mid u z = v y\\}\\).  \nTake the two standard affine charts:\n\n- **Chart \\(U_1\\):** \\(u\\neq 0\\), set \\(u=1\\), then \\(z = v y\\). Coordinates are \\((y,v)\\); the exceptional divisor \\(E_1\\) is \\(y=0\\).\n- **Chart \\(U_2\\):** \\(v\\neq 0\\), set \\(v=1\\), then \\(y = u z\\). Coordinates are \\((u,z)\\); \\(E_1\\) is \\(z=0\\).\n\nIn \\(U_1\\) the pullbacks of the homogeneous coordinates of \\(\\varphi\\) are  \n\\[\n(yz, xz, xy) = (y\\cdot(v y),\\, 1\\cdot(v y),\\, 1\\cdot y) = (v y^2,\\; v y,\\; y).\n\\]\nAll three entries are divisible by \\(y\\). Since the map to \\(\\mathbb{P}^2\\) is defined up to an overall scalar, we may divide the triple by \\(y\\) (a unit away from \\(E_1\\)) to obtain an equivalent representation  \n\\[\n(v y,\\; v,\\; 1).\n\\]\nThis expression is polynomial in \\(y,v\\) and is defined for all \\((y,v)\\), including points on \\(E_1\\) (where \\(y=0\\)), giving \\((0,v,1)\\) which is a valid point in \\(\\mathbb{P}^2\\). Hence on \\(U_1\\) we define \\(\\Phi\\) by \\((v y : v : 1)\\).\n\nIn \\(U_2\\) the pullbacks are  \n\\[\n(yz, xz, xy) = ((u z)\\cdot z,\\; 1\\cdot z,\\; 1\\cdot (u z)) = (u z^2,\\; z,\\; u z).\n\\]\nDividing by \\(z\\) yields  \n\\[\n(u z,\\; 1,\\; u),\n\\]\nwhich at \\(z=0\\) gives \\((0,1,u)\\), again well\u2011defined. So on \\(U_2\\) we set \\(\\Phi(u,z) = (u z : 1 : u)\\).\n\nOn the overlap \\(U_1\\cap U_2\\) (where \\(y\\neq0,\\;z\\neq0\\)) we have \\(v = z/y\\) and \\(u = y/z\\). The two definitions agree because  \n\\[\n(v y : v : 1) = (z : z/y : 1) \\quad\\text{and}\\quad (u z : 1 : u) = (y : 1 : y/z),\n\\]\nand these triples are proportional: multiplying the first by \\(y\\) gives \\((yz,z,y)\\), multiplying the second by \\(z\\) gives \\((yz,z,y)\\). Therefore \\(\\Phi\\) is a well\u2011defined morphism on \\(\\pi^{-1}(\\{x\\neq0\\})\\).\n\nBy symmetry, analogous charts around \\(P_2\\) and \\(P_3\\) show that \\(\\Phi\\) extends to a morphism on the whole blow\u2011up \\(X\\). Hence \\(\\varphi\\) lifts to a morphism \\(\\Phi: X \\to \\mathbb{P}^2\\).\n\n**Solution (b).**  \nThe morphism \\(\\Phi\\) is given by the three global sections  \n\\[\ns_0 = \\pi^*(yz),\\quad s_1 = \\pi^*(xz),\\quad s_2 = \\pi^*(xy)\n\\]\nof the line bundle \\(\\pi^*\\mathcal{O}_{\\mathbb{P}^2}(2) = \\mathcal{O}_X(2H)\\).  \nWe claim that these sections actually belong to the subsheaf \\(\\mathcal{O}_X(2H - E_1 - E_2 - E_3) \\subset \\mathcal{O}_X(2H)\\), i.e. they vanish along each exceptional divisor.  \n\nNear a generic point of \\(E_1\\), using chart \\(U_1\\) as above, we have \\(s_0 = v y^2\\), \\(s_1 = v y\\), \\(s_2 = y\\). All are divisible by \\(y\\), the local equation of \\(E_1\\); hence they vanish along \\(E_1\\). By symmetry they vanish along \\(E_2\\) and \\(E_3\\) as well. Consequently, \\(s_0,s_1,s_2\\) are global sections of the line bundle  \n\\[\nL := \\mathcal{O}_X(2H - E_1 - E_2 - E_3).\n\\]\n\nThese three sections have no common zero on \\(X\\): outside the exceptional divisors this follows because \\(\\varphi\\) is dominant; on an exceptional divisor, say \\(E_1\\) in chart \\(U_1\\), \\(\\Phi(y=0,v) = (0:v:1)\\) which is never \\((0:0:0)\\). Thus the sections generate \\(L\\) at every point, and therefore they define the morphism \\(\\Phi\\). By the standard property of morphisms to projective space we obtain  \n\\[\n\\Phi^*\\mathcal{O}_{\\mathbb{P}^2}(1) \\cong L = \\mathcal{O}_X(2H - E_1 - E_2 - E_3).\n\\]\n\n**Solution (c).**  \nCompute the composition \\(\\varphi \\circ \\varphi\\) as rational maps. For a point \\((x:y:z)\\) where all coordinates are non\u2011zero (a dense open set where \\(\\varphi\\) is defined),  \n\\[\n\\varphi(\\varphi(x:y:z)) = \\varphi(yz : xz : xy) \n= \\big( (xz)(xy) : (yz)(xy) : (yz)(xz) \\big) \n= (x^2 y z : x y^2 z : x y z^2).\n\\]\nSince \\(x y z \\neq 0\\), we may factor out \\(x y z\\) to obtain \\((x : y : z)\\). Hence \\(\\varphi \\circ \\varphi = \\operatorname{id}_{\\mathbb{P}^2}\\) as rational maps. Therefore \\(\\varphi\\) is birational, and its inverse is \\(\\varphi\\) itself.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "9",
    "outer_attempt": 1,
    "topic_slug": "linear_and_multilinear_algebra",
    "topic_name": "Linear and multilinear algebra; matrix theory",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $A$ be an $n \\times n$ complex matrix. Prove that $e^A = I$ (where $I$ is the identity matrix) if and only if $A$ is diagonalizable and every eigenvalue of $A$ is an integer multiple of $2\\pi i$.",
            "answer": "We prove both directions of the equivalence.\n\n**($\\Leftarrow$) Direction:**  \nAssume $A$ is diagonalizable and that each eigenvalue $\\lambda$ of $A$ satisfies $\\lambda = 2\\pi i k$ for some integer $k$. Then there exists an invertible matrix $P$ and a diagonal matrix $D = \\operatorname{diag}(2\\pi i k_1,\\dots,2\\pi i k_n)$ such that $A = PDP^{-1}$. Using the property $e^{PDP^{-1}} = P e^D P^{-1}$, we compute\n$$\ne^D = \\operatorname{diag}\\bigl(e^{2\\pi i k_1},\\dots,e^{2\\pi i k_n}\\bigr) = \\operatorname{diag}(1,\\dots,1) = I,\n$$\nbecause $e^{2\\pi i k}=1$ for every integer $k$. Hence $e^A = P I P^{-1} = I$.\n\n**($\\Rightarrow$) Direction:**  \nAssume $e^A = I$. Let $J$ be the Jordan canonical form of $A$, i.e., $A = PJP^{-1}$ where $J$ is a block diagonal matrix\n$$\nJ = \\bigoplus_{i=1}^{m} J_i(\\lambda_i),\n$$\neach $J_i(\\lambda_i)$ being a Jordan block of size $r_i$ associated with an eigenvalue $\\lambda_i \\in \\mathbb{C}$. Then\n$$\ne^A = P e^{J} P^{-1} = I \\quad\\Longrightarrow\\quad e^{J} = I.\n$$\nSince $e^{J}$ is block diagonal with blocks $e^{J_i(\\lambda_i)}$, we must have\n$$\ne^{J_i(\\lambda_i)} = I_{r_i} \\qquad\\text{for every } i.\n$$\n\nNow fix one Jordan block $J(\\lambda)$ of size $r$. Write it as $J(\\lambda) = \\lambda I_r + N$, where $N$ is the nilpotent matrix with $1$'s on the superdiagonal and zeros elsewhere. The matrices $\\lambda I_r$ and $N$ commute, so\n$$\ne^{J(\\lambda)} = e^{\\lambda I_r + N} = e^{\\lambda I_r} e^{N} = e^{\\lambda} I_r \\cdot e^{N} = e^{\\lambda} e^{N}.\n$$\nThe exponential of $N$ is a finite sum because $N^r = 0$:\n$$\ne^{N} = I_r + N + \\frac{N^2}{2!} + \\cdots + \\frac{N^{r-1}}{(r-1)!}.\n$$\nIts entries are: $1$ on the main diagonal, $1$ on the first superdiagonal, $\\frac{1}{2!}$ on the second superdiagonal, etc. In particular, if $r \\ge 2$, the $(1,2)$ entry of $e^{N}$ is $1$, and therefore the $(1,2)$ entry of $e^{J(\\lambda)}$ is $e^{\\lambda}\\cdot 1$.\n\nFor $e^{J(\\lambda)}$ to equal $I_r$, all off\u2011diagonal entries must be zero. If $r \\ge 2$, we would need $e^{\\lambda}=0$ to cancel the non\u2011zero off\u2011diagonal entries, but the exponential function never vanishes. Hence it is impossible to have $r \\ge 2$. Therefore every Jordan block must have size $r = 1$. Consequently $J$ is a diagonal matrix, which means $A$ is diagonalizable.\n\nNow each Jordan block is simply a $1\\times 1$ scalar $\\lambda_i$, and the condition $e^{J_i(\\lambda_i)} = 1$ becomes $e^{\\lambda_i} = 1$. Thus $\\lambda_i = 2\\pi i k_i$ for some integer $k_i$. This completes the proof. \u220e",
            "raw_answer": "[QUESTION]\nLet $A$ be an $n \\times n$ complex matrix. Prove that $e^A = I$ (where $I$ is the identity matrix) if and only if $A$ is diagonalizable and every eigenvalue of $A$ is an integer multiple of $2\\pi i$.\n\n[ANSWER]\nWe prove both directions of the equivalence.\n\n**($\\Leftarrow$) Direction:**  \nAssume $A$ is diagonalizable and that each eigenvalue $\\lambda$ of $A$ satisfies $\\lambda = 2\\pi i k$ for some integer $k$. Then there exists an invertible matrix $P$ and a diagonal matrix $D = \\operatorname{diag}(2\\pi i k_1,\\dots,2\\pi i k_n)$ such that $A = PDP^{-1}$. Using the property $e^{PDP^{-1}} = P e^D P^{-1}$, we compute\n\\[\ne^D = \\operatorname{diag}\\bigl(e^{2\\pi i k_1},\\dots,e^{2\\pi i k_n}\\bigr) = \\operatorname{diag}(1,\\dots,1) = I,\n\\]\nbecause $e^{2\\pi i k}=1$ for every integer $k$. Hence $e^A = P I P^{-1} = I$.\n\n**($\\Rightarrow$) Direction:**  \nAssume $e^A = I$. Let $J$ be the Jordan canonical form of $A$, i.e., $A = PJP^{-1}$ where $J$ is a block diagonal matrix\n\\[\nJ = \\bigoplus_{i=1}^{m} J_i(\\lambda_i),\n\\]\neach $J_i(\\lambda_i)$ being a Jordan block of size $r_i$ associated with an eigenvalue $\\lambda_i \\in \\mathbb{C}$. Then\n\\[\ne^A = P e^{J} P^{-1} = I \\quad\\Longrightarrow\\quad e^{J} = I.\n\\]\nSince $e^{J}$ is block diagonal with blocks $e^{J_i(\\lambda_i)}$, we must have\n\\[\ne^{J_i(\\lambda_i)} = I_{r_i} \\qquad\\text{for every } i.\n\\]\n\nNow fix one Jordan block $J(\\lambda)$ of size $r$. Write it as $J(\\lambda) = \\lambda I_r + N$, where $N$ is the nilpotent matrix with $1$'s on the superdiagonal and zeros elsewhere. The matrices $\\lambda I_r$ and $N$ commute, so\n\\[\ne^{J(\\lambda)} = e^{\\lambda I_r + N} = e^{\\lambda I_r} e^{N} = e^{\\lambda} I_r \\cdot e^{N} = e^{\\lambda} e^{N}.\n\\]\nThe exponential of $N$ is a finite sum because $N^r = 0$:\n\\[\ne^{N} = I_r + N + \\frac{N^2}{2!} + \\cdots + \\frac{N^{r-1}}{(r-1)!}.\n\\]\nIts entries are: $1$ on the main diagonal, $1$ on the first superdiagonal, $\\frac{1}{2!}$ on the second superdiagonal, etc. In particular, if $r \\ge 2$, the $(1,2)$ entry of $e^{N}$ is $1$, and therefore the $(1,2)$ entry of $e^{J(\\lambda)}$ is $e^{\\lambda}\\cdot 1$.\n\nFor $e^{J(\\lambda)}$ to equal $I_r$, all off\u2011diagonal entries must be zero. If $r \\ge 2$, we would need $e^{\\lambda}=0$ to cancel the non\u2011zero off\u2011diagonal entries, but the exponential function never vanishes. Hence it is impossible to have $r \\ge 2$. Therefore every Jordan block must have size $r = 1$. Consequently $J$ is a diagonal matrix, which means $A$ is diagonalizable.\n\nNow each Jordan block is simply a $1\\times 1$ scalar $\\lambda_i$, and the condition $e^{J_i(\\lambda_i)} = 1$ becomes $e^{\\lambda_i} = 1$. Thus $\\lambda_i = 2\\pi i k_i$ for some integer $k_i$. This completes the proof. \u220e",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "10",
    "outer_attempt": 1,
    "topic_slug": "associative_rings_and_algebras",
    "topic_name": "Associative rings and algebras",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $R$ be a commutative ring with identity. Denote by $T_n(R)$ the ring of $n \\times n$ upper triangular matrices over $R$, i.e., matrices $(a_{ij})$ with $a_{ij} \\in R$ for $i \\le j$ and $a_{ij}=0$ for $i > j$. Prove that the Jacobson radical $J(T_n(R))$ is exactly the set\n$$\n\\{ A = (a_{ij}) \\in T_n(R) \\mid a_{ii} \\in J(R) \\text{ for all } i = 1,\\dots,n \\}.\n$$",
            "answer": "We prove the equality in two steps: first we show that every matrix whose diagonal entries lie in $J(R)$ belongs to $J(T_n(R))$, and then we show that any matrix in $J(T_n(R))$ must have its diagonal entries in $J(R)$. The main tools are the ideal $I$ of strictly upper triangular matrices, the isomorphism $T_n(R)/I \\cong R^n$, and standard properties of the Jacobson radical.\n\n---\n\n### 1. Notation and preliminary facts\n\nFor any ring $S$, $J(S)$ denotes its Jacobson radical (the intersection of all maximal right ideals, which coincides with the intersection of all maximal left ideals). We recall two basic properties:\n\n* If $K$ is a nilpotent ideal of $S$, then $K \\subseteq J(S)$.\n* If $K \\subseteq J(S)$, then $J(S)/K = J(S/K)$.\n\n---\n\n### 2. The ideal $I$ of strictly upper triangular matrices\n\nDefine  \n$$\nI = \\{ (a_{ij}) \\in T_n(R) \\mid a_{ii}=0 \\text{ for all } i \\}.\n$$\n$I$ is a two\u2011sided ideal of $T_n(R)$ because it is closed under addition and under left/right multiplication by any element of $T_n(R)$ (the diagonal entries of a product are products of the corresponding diagonal entries, so multiplying by a matrix with zero diagonal keeps the diagonal zero). Moreover, $I$ is nilpotent: $I^n = 0$. Indeed, the $(i,j)$\u2011entry of a product of $k$ matrices from $I$ is zero whenever $j < i+k-1$; for $k=n$ we obtain the zero matrix. Hence $I \\subseteq J(T_n(R))$ by the first property above.\n\n---\n\n### 3. The quotient $T_n(R)/I$\n\nConsider the natural surjection $\\pi: T_n(R) \\to T_n(R)/I$. For a matrix $A = (a_{ij})$, its diagonal entries are unchanged modulo $I$ because $I$ contains only matrices with zero diagonal. Define a map  \n$$\n\\varphi: T_n(R)/I \\longrightarrow R^n,\\qquad \\varphi(A+I) = (a_{11}, a_{22}, \\dots, a_{nn}).\n$$\nThis map is well defined, and it is a ring homomorphism because for any $A,B \\in T_n(R)$ we have  \n$$\n(AB)_{ii} = a_{ii}b_{ii} \\quad\\text{for each } i,\n$$\nas all off\u2011diagonal contributions vanish (see the computation below). Hence $\\varphi((A+I)(B+I)) = \\varphi(AB+I) = (a_{11}b_{11},\\dots,a_{nn}b_{nn}) = \\varphi(A+I)\\,\\varphi(B+I)$. Clearly $\\varphi$ is surjective (lift any $n$\u2011tuple to the corresponding diagonal matrix) and its kernel consists exactly of those $A+I$ with $a_{ii}=0$ for all $i$, i.e., $A \\in I$; thus $\\ker\\varphi = \\{I\\}$. Therefore $\\varphi$ is a ring isomorphism:\n$$\nT_n(R)/I \\cong R^n.\n$$\n\n*Computation of $(AB)_{ii}$:*  \nSince $A$ and $B$ are upper triangular, $a_{ik}=0$ for $k<i$ and $b_{ki}=0$ for $k>i$. Hence\n$$\n(AB)_{ii} = \\sum_{k=1}^n a_{ik}b_{ki} = a_{ii}b_{ii},\n$$\nbecause the only possibly non\u2011zero term occurs when $k=i$.\n\n---\n\n### 4. Jacobson radical of a finite direct product\n\nFor any finite family of rings $S_1,\\dots,S_n$, the Jacobson radical of the direct product is the product of the individual radicals:\n$$\nJ(S_1 \\times \\cdots \\times S_n) = J(S_1) \\times \\cdots \\times J(S_n).\n$$\nThis follows either from the characterisation via units ($(x_1,\\dots,x_n) \\in J$ iff each $x_i \\in J(S_i)$) or from the description of maximal ideals in a product. Applying this with $S_i = R$ gives\n$$\nJ(R^n) = J(R)^n.\n$$\n\n---\n\n### 5. Determination of $J(T_n(R))$\n\nBecause $I \\subseteq J(T_n(R))$, we may use the second property mentioned in \u00a71:\n$$\nJ(T_n(R))/I = J(T_n(R)/I).\n$$\nUnder the isomorphism $\\varphi$, $J(T_n(R)/I)$ corresponds to $J(R^n) = J(R)^n$. Therefore\n$$\nJ(T_n(R))/I \\cong J(R)^n.\n$$\nConsequently, an element $A \\in T_n(R)$ belongs to $J(T_n(R))$ if and only if its image in $T_n(R)/I$ lies in $J(T_n(R)/I)$, i.e., if and only if $\\varphi(A+I) \\in J(R)^n$. By definition of $\\varphi$, this condition is exactly\n$$\n(a_{11}, a_{22}, \\dots, a_{nn}) \\in J(R)^n,\n$$\nwhich means $a_{ii} \\in J(R)$ for every $i = 1,\\dots,n$. No restriction is imposed on the off\u2011diagonal entries. Hence\n$$\nJ(T_n(R)) = \\{ A = (a_{ij}) \\in T_n(R) \\mid a_{ii} \\in J(R) \\text{ for all } i \\}.\n$$\n\n---\n\n### 6. Conclusion\n\nThe proof is complete. The argument uses only elementary properties of the Jacobson radical and the structure of upper triangular matrices, and it does not rely on any further assumptions on $R$ beyond commutativity and the existence of a multiplicative identity.",
            "raw_answer": "[QUESTION]\nLet $R$ be a commutative ring with identity. Denote by $T_n(R)$ the ring of $n \\times n$ upper triangular matrices over $R$, i.e., matrices $(a_{ij})$ with $a_{ij} \\in R$ for $i \\le j$ and $a_{ij}=0$ for $i > j$. Prove that the Jacobson radical $J(T_n(R))$ is exactly the set\n\\[\n\\{ A = (a_{ij}) \\in T_n(R) \\mid a_{ii} \\in J(R) \\text{ for all } i = 1,\\dots,n \\}.\n\\]\n\n[ANSWER]\nWe prove the equality in two steps: first we show that every matrix whose diagonal entries lie in $J(R)$ belongs to $J(T_n(R))$, and then we show that any matrix in $J(T_n(R))$ must have its diagonal entries in $J(R)$. The main tools are the ideal $I$ of strictly upper triangular matrices, the isomorphism $T_n(R)/I \\cong R^n$, and standard properties of the Jacobson radical.\n\n---\n\n### 1. Notation and preliminary facts\n\nFor any ring $S$, $J(S)$ denotes its Jacobson radical (the intersection of all maximal right ideals, which coincides with the intersection of all maximal left ideals). We recall two basic properties:\n\n* If $K$ is a nilpotent ideal of $S$, then $K \\subseteq J(S)$.\n* If $K \\subseteq J(S)$, then $J(S)/K = J(S/K)$.\n\n---\n\n### 2. The ideal $I$ of strictly upper triangular matrices\n\nDefine  \n\\[\nI = \\{ (a_{ij}) \\in T_n(R) \\mid a_{ii}=0 \\text{ for all } i \\}.\n\\]\n$I$ is a two\u2011sided ideal of $T_n(R)$ because it is closed under addition and under left/right multiplication by any element of $T_n(R)$ (the diagonal entries of a product are products of the corresponding diagonal entries, so multiplying by a matrix with zero diagonal keeps the diagonal zero). Moreover, $I$ is nilpotent: $I^n = 0$. Indeed, the $(i,j)$\u2011entry of a product of $k$ matrices from $I$ is zero whenever $j < i+k-1$; for $k=n$ we obtain the zero matrix. Hence $I \\subseteq J(T_n(R))$ by the first property above.\n\n---\n\n### 3. The quotient $T_n(R)/I$\n\nConsider the natural surjection $\\pi: T_n(R) \\to T_n(R)/I$. For a matrix $A = (a_{ij})$, its diagonal entries are unchanged modulo $I$ because $I$ contains only matrices with zero diagonal. Define a map  \n\\[\n\\varphi: T_n(R)/I \\longrightarrow R^n,\\qquad \\varphi(A+I) = (a_{11}, a_{22}, \\dots, a_{nn}).\n\\]\nThis map is well defined, and it is a ring homomorphism because for any $A,B \\in T_n(R)$ we have  \n\\[\n(AB)_{ii} = a_{ii}b_{ii} \\quad\\text{for each } i,\n\\]\nas all off\u2011diagonal contributions vanish (see the computation below). Hence $\\varphi((A+I)(B+I)) = \\varphi(AB+I) = (a_{11}b_{11},\\dots,a_{nn}b_{nn}) = \\varphi(A+I)\\,\\varphi(B+I)$. Clearly $\\varphi$ is surjective (lift any $n$\u2011tuple to the corresponding diagonal matrix) and its kernel consists exactly of those $A+I$ with $a_{ii}=0$ for all $i$, i.e., $A \\in I$; thus $\\ker\\varphi = \\{I\\}$. Therefore $\\varphi$ is a ring isomorphism:\n\\[\nT_n(R)/I \\cong R^n.\n\\]\n\n*Computation of $(AB)_{ii}$:*  \nSince $A$ and $B$ are upper triangular, $a_{ik}=0$ for $k<i$ and $b_{ki}=0$ for $k>i$. Hence\n\\[\n(AB)_{ii} = \\sum_{k=1}^n a_{ik}b_{ki} = a_{ii}b_{ii},\n\\]\nbecause the only possibly non\u2011zero term occurs when $k=i$.\n\n---\n\n### 4. Jacobson radical of a finite direct product\n\nFor any finite family of rings $S_1,\\dots,S_n$, the Jacobson radical of the direct product is the product of the individual radicals:\n\\[\nJ(S_1 \\times \\cdots \\times S_n) = J(S_1) \\times \\cdots \\times J(S_n).\n\\]\nThis follows either from the characterisation via units ($(x_1,\\dots,x_n) \\in J$ iff each $x_i \\in J(S_i)$) or from the description of maximal ideals in a product. Applying this with $S_i = R$ gives\n\\[\nJ(R^n) = J(R)^n.\n\\]\n\n---\n\n### 5. Determination of $J(T_n(R))$\n\nBecause $I \\subseteq J(T_n(R))$, we may use the second property mentioned in \u00a71:\n\\[\nJ(T_n(R))/I = J(T_n(R)/I).\n\\]\nUnder the isomorphism $\\varphi$, $J(T_n(R)/I)$ corresponds to $J(R^n) = J(R)^n$. Therefore\n\\[\nJ(T_n(R))/I \\cong J(R)^n.\n\\]\nConsequently, an element $A \\in T_n(R)$ belongs to $J(T_n(R))$ if and only if its image in $T_n(R)/I$ lies in $J(T_n(R)/I)$, i.e., if and only if $\\varphi(A+I) \\in J(R)^n$. By definition of $\\varphi$, this condition is exactly\n\\[\n(a_{11}, a_{22}, \\dots, a_{nn}) \\in J(R)^n,\n\\]\nwhich means $a_{ii} \\in J(R)$ for every $i = 1,\\dots,n$. No restriction is imposed on the off\u2011diagonal entries. Hence\n\\[\nJ(T_n(R)) = \\{ A = (a_{ij}) \\in T_n(R) \\mid a_{ii} \\in J(R) \\text{ for all } i \\}.\n\\]\n\n---\n\n### 6. Conclusion\n\nThe proof is complete. The argument uses only elementary properties of the Jacobson radical and the structure of upper triangular matrices, and it does not rely on any further assumptions on $R$ beyond commutativity and the existence of a multiplicative identity.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "11",
    "outer_attempt": 1,
    "topic_slug": "nonassociative_rings_and_algebras",
    "topic_name": "Nonassociative rings and algebras",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $\\mathfrak{g}$ be a finite-dimensional Lie algebra over a field $F$ of characteristic $0$. For $x \\in \\mathfrak{g}$, define the adjoint operator $\\operatorname{ad}_x : \\mathfrak{g} \\to \\mathfrak{g}$ by $\\operatorname{ad}_x(y) = [x, y]$. The Killing form is defined by\n$$\n\\kappa(x, y) = \\operatorname{tr}(\\operatorname{ad}_x \\circ \\operatorname{ad}_y), \\qquad x, y \\in \\mathfrak{g}.\n$$\n\n(a) Show that $\\kappa$ is a symmetric bilinear form.\n\n(b) Prove that $\\kappa$ is invariant, i.e., for all $x, y, z \\in \\mathfrak{g}$,\n$$\n\\kappa([x, y], z) = \\kappa(x, [y, z]).\n$$\n\n(c) Show that the radical of $\\kappa$,\n$$\n\\operatorname{Rad}(\\kappa) = \\{ x \\in \\mathfrak{g} \\mid \\kappa(x, y) = 0 \\text{ for all } y \\in \\mathfrak{g} \\},\n$$\nis an ideal of $\\mathfrak{g}$.\n\n(d) Prove that if $\\kappa$ is nondegenerate (i.e., $\\operatorname{Rad}(\\kappa) = 0$), then $\\mathfrak{g}$ is semisimple, i.e., $\\mathfrak{g}$ contains no nonzero abelian ideals.",
            "answer": "**(a) Symmetric bilinear form.**  \nBilinearity follows because the map $(x,y) \\mapsto \\operatorname{ad}_x \\circ \\operatorname{ad}_y$ is bilinear (ad is linear in $x$ and composition is bilinear) and the trace is linear.  \nSymmetry: for any $x,y \\in \\mathfrak{g}$,\n$$\n\\kappa(x,y) = \\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_y) = \\operatorname{tr}(\\operatorname{ad}_y \\operatorname{ad}_x) = \\kappa(y,x),\n$$\nsince $\\operatorname{tr}(AB) = \\operatorname{tr}(BA)$ for any linear maps $A,B$ on a finite-dimensional vector space.\n\n**(b) Invariance.**  \nUsing that $\\operatorname{ad}$ is a Lie algebra homomorphism, we have $\\operatorname{ad}_{[x,y]} = [\\operatorname{ad}_x, \\operatorname{ad}_y] = \\operatorname{ad}_x \\operatorname{ad}_y - \\operatorname{ad}_y \\operatorname{ad}_x$. Then\n$$\n\\kappa([x,y],z) = \\operatorname{tr}(\\operatorname{ad}_{[x,y]} \\operatorname{ad}_z) = \\operatorname{tr}((\\operatorname{ad}_x \\operatorname{ad}_y - \\operatorname{ad}_y \\operatorname{ad}_x)\\operatorname{ad}_z)\n= \\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_y \\operatorname{ad}_z) - \\operatorname{tr}(\\operatorname{ad}_y \\operatorname{ad}_x \\operatorname{ad}_z).\n$$\nOn the other hand,\n$$\n\\kappa(x,[y,z]) = \\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_{[y,z]}) = \\operatorname{tr}(\\operatorname{ad}_x (\\operatorname{ad}_y \\operatorname{ad}_z - \\operatorname{ad}_z \\operatorname{ad}_y))\n= \\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_y \\operatorname{ad}_z) - \\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_z \\operatorname{ad}_y).\n$$\nBy the cyclic property of the trace, $\\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_z \\operatorname{ad}_y) = \\operatorname{tr}(\\operatorname{ad}_y \\operatorname{ad}_x \\operatorname{ad}_z)$. Hence the two expressions coincide, proving invariance.\n\n**(c) Radical is an ideal.**  \nLet $r \\in \\operatorname{Rad}(\\kappa)$ and $g \\in \\mathfrak{g}$. For any $s \\in \\mathfrak{g}$, using invariance from part (b),\n$$\n\\kappa([r,g], s) = \\kappa(r, [g,s]) = 0,\n$$\nbecause $r$ is in the radical. Thus $[r,g] \\in \\operatorname{Rad}(\\kappa)$. Since $\\operatorname{Rad}(\\kappa)$ is a subspace (bilinearity of $\\kappa$), it is an ideal.\n\n**(d) Nondegeneracy implies semisimplicity.**  \nWe prove the contrapositive: if $\\mathfrak{g}$ is not semisimple (i.e., contains a nonzero abelian ideal), then $\\kappa$ is degenerate.\n\nSuppose $I$ is a nonzero abelian ideal of $\\mathfrak{g}$. Choose $0 \\neq a \\in I$. For any $x \\in \\mathfrak{g}$, consider the linear operator $T = \\operatorname{ad}_a \\circ \\operatorname{ad}_x$ on $\\mathfrak{g}$. We claim $T^2 = 0$. Indeed, for any $y \\in \\mathfrak{g}$,\n$$\nT(y) = [a, [x, y]].\n$$\nBecause $I$ is an ideal, $[a, [x, y]] \\in I$, so $T(y) \\in I$. Applying $T$ again,\n$$\nT(T(y)) = [a, [x, T(y)]].\n$$\nNow $T(y) \\in I$, and since $I$ is an ideal, $[x, T(y)] \\in I$. As $I$ is abelian, $[a, [x, T(y)]] = 0$. Hence $T^2(y)=0$ for all $y$, i.e., $T^2 = 0$. Thus $T$ is nilpotent, and its trace is $0$. But $\\operatorname{tr}(T) = \\operatorname{tr}(\\operatorname{ad}_a \\operatorname{ad}_x) = \\kappa(a,x)$. Therefore $\\kappa(a,x)=0$ for all $x \\in \\mathfrak{g}$, so $a \\in \\operatorname{Rad}(\\kappa)$. Since $a \\neq 0$, the radical is nonzero, i.e., $\\kappa$ is degenerate.\n\nNow, if $\\mathfrak{g}$ had a nonzero solvable ideal $J$, then the derived series $J^{(k)}$ (with $J^{(0)} = J$, $J^{(i+1)} = [J^{(i)}, J^{(i)}]$) eventually yields a nonzero term $J^{(m)}$ that is abelian and still an ideal of $\\mathfrak{g}$ (each derived term of an ideal is an ideal). Hence $\\mathfrak{g}$ would contain a nonzero abelian ideal, making $\\kappa$ degenerate. Consequently, if $\\kappa$ is nondegenerate, $\\mathfrak{g}$ cannot have any nonzero solvable ideal; in particular, it has no nonzero abelian ideals, i.e., $\\mathfrak{g}$ is semisimple. \u220e",
            "raw_answer": "[QUESTION]\nLet $\\mathfrak{g}$ be a finite-dimensional Lie algebra over a field $F$ of characteristic $0$. For $x \\in \\mathfrak{g}$, define the adjoint operator $\\operatorname{ad}_x : \\mathfrak{g} \\to \\mathfrak{g}$ by $\\operatorname{ad}_x(y) = [x, y]$. The Killing form is defined by\n\\[\n\\kappa(x, y) = \\operatorname{tr}(\\operatorname{ad}_x \\circ \\operatorname{ad}_y), \\qquad x, y \\in \\mathfrak{g}.\n\\]\n\n(a) Show that $\\kappa$ is a symmetric bilinear form.\n\n(b) Prove that $\\kappa$ is invariant, i.e., for all $x, y, z \\in \\mathfrak{g}$,\n\\[\n\\kappa([x, y], z) = \\kappa(x, [y, z]).\n\\]\n\n(c) Show that the radical of $\\kappa$,\n\\[\n\\operatorname{Rad}(\\kappa) = \\{ x \\in \\mathfrak{g} \\mid \\kappa(x, y) = 0 \\text{ for all } y \\in \\mathfrak{g} \\},\n\\]\nis an ideal of $\\mathfrak{g}$.\n\n(d) Prove that if $\\kappa$ is nondegenerate (i.e., $\\operatorname{Rad}(\\kappa) = 0$), then $\\mathfrak{g}$ is semisimple, i.e., $\\mathfrak{g}$ contains no nonzero abelian ideals.\n\n[ANSWER]\n**(a) Symmetric bilinear form.**  \nBilinearity follows because the map $(x,y) \\mapsto \\operatorname{ad}_x \\circ \\operatorname{ad}_y$ is bilinear (ad is linear in $x$ and composition is bilinear) and the trace is linear.  \nSymmetry: for any $x,y \\in \\mathfrak{g}$,\n\\[\n\\kappa(x,y) = \\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_y) = \\operatorname{tr}(\\operatorname{ad}_y \\operatorname{ad}_x) = \\kappa(y,x),\n\\]\nsince $\\operatorname{tr}(AB) = \\operatorname{tr}(BA)$ for any linear maps $A,B$ on a finite-dimensional vector space.\n\n**(b) Invariance.**  \nUsing that $\\operatorname{ad}$ is a Lie algebra homomorphism, we have $\\operatorname{ad}_{[x,y]} = [\\operatorname{ad}_x, \\operatorname{ad}_y] = \\operatorname{ad}_x \\operatorname{ad}_y - \\operatorname{ad}_y \\operatorname{ad}_x$. Then\n\\[\n\\kappa([x,y],z) = \\operatorname{tr}(\\operatorname{ad}_{[x,y]} \\operatorname{ad}_z) = \\operatorname{tr}((\\operatorname{ad}_x \\operatorname{ad}_y - \\operatorname{ad}_y \\operatorname{ad}_x)\\operatorname{ad}_z)\n= \\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_y \\operatorname{ad}_z) - \\operatorname{tr}(\\operatorname{ad}_y \\operatorname{ad}_x \\operatorname{ad}_z).\n\\]\nOn the other hand,\n\\[\n\\kappa(x,[y,z]) = \\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_{[y,z]}) = \\operatorname{tr}(\\operatorname{ad}_x (\\operatorname{ad}_y \\operatorname{ad}_z - \\operatorname{ad}_z \\operatorname{ad}_y))\n= \\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_y \\operatorname{ad}_z) - \\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_z \\operatorname{ad}_y).\n\\]\nBy the cyclic property of the trace, $\\operatorname{tr}(\\operatorname{ad}_x \\operatorname{ad}_z \\operatorname{ad}_y) = \\operatorname{tr}(\\operatorname{ad}_y \\operatorname{ad}_x \\operatorname{ad}_z)$. Hence the two expressions coincide, proving invariance.\n\n**(c) Radical is an ideal.**  \nLet $r \\in \\operatorname{Rad}(\\kappa)$ and $g \\in \\mathfrak{g}$. For any $s \\in \\mathfrak{g}$, using invariance from part (b),\n\\[\n\\kappa([r,g], s) = \\kappa(r, [g,s]) = 0,\n\\]\nbecause $r$ is in the radical. Thus $[r,g] \\in \\operatorname{Rad}(\\kappa)$. Since $\\operatorname{Rad}(\\kappa)$ is a subspace (bilinearity of $\\kappa$), it is an ideal.\n\n**(d) Nondegeneracy implies semisimplicity.**  \nWe prove the contrapositive: if $\\mathfrak{g}$ is not semisimple (i.e., contains a nonzero abelian ideal), then $\\kappa$ is degenerate.\n\nSuppose $I$ is a nonzero abelian ideal of $\\mathfrak{g}$. Choose $0 \\neq a \\in I$. For any $x \\in \\mathfrak{g}$, consider the linear operator $T = \\operatorname{ad}_a \\circ \\operatorname{ad}_x$ on $\\mathfrak{g}$. We claim $T^2 = 0$. Indeed, for any $y \\in \\mathfrak{g}$,\n\\[\nT(y) = [a, [x, y]].\n\\]\nBecause $I$ is an ideal, $[a, [x, y]] \\in I$, so $T(y) \\in I$. Applying $T$ again,\n\\[\nT(T(y)) = [a, [x, T(y)]].\n\\]\nNow $T(y) \\in I$, and since $I$ is an ideal, $[x, T(y)] \\in I$. As $I$ is abelian, $[a, [x, T(y)]] = 0$. Hence $T^2(y)=0$ for all $y$, i.e., $T^2 = 0$. Thus $T$ is nilpotent, and its trace is $0$. But $\\operatorname{tr}(T) = \\operatorname{tr}(\\operatorname{ad}_a \\operatorname{ad}_x) = \\kappa(a,x)$. Therefore $\\kappa(a,x)=0$ for all $x \\in \\mathfrak{g}$, so $a \\in \\operatorname{Rad}(\\kappa)$. Since $a \\neq 0$, the radical is nonzero, i.e., $\\kappa$ is degenerate.\n\nNow, if $\\mathfrak{g}$ had a nonzero solvable ideal $J$, then the derived series $J^{(k)}$ (with $J^{(0)} = J$, $J^{(i+1)} = [J^{(i)}, J^{(i)}]$) eventually yields a nonzero term $J^{(m)}$ that is abelian and still an ideal of $\\mathfrak{g}$ (each derived term of an ideal is an ideal). Hence $\\mathfrak{g}$ would contain a nonzero abelian ideal, making $\\kappa$ degenerate. Consequently, if $\\kappa$ is nondegenerate, $\\mathfrak{g}$ cannot have any nonzero solvable ideal; in particular, it has no nonzero abelian ideals, i.e., $\\mathfrak{g}$ is semisimple. \u220e",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "12",
    "outer_attempt": 1,
    "topic_slug": "category_theory_and_homological_algebra",
    "topic_name": "Category theory; homological algebra",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $R = \\mathbb{Z}/4\\mathbb{Z}$ and let $M = \\mathbb{Z}/2\\mathbb{Z}$ be the $R$-module where the action is given by the natural surjection $R \\to \\mathbb{Z}/2\\mathbb{Z}$ (i.e., $r \\cdot a = \\overline{r} \\, a$, where $\\overline{r}$ denotes reduction modulo $2$). Compute $\\operatorname{Ext}^n_R(M, M)$ for all integers $n \\ge 0$. Moreover, describe the structure of the graded ring $\\operatorname{Ext}^*_R(M, M) = \\bigoplus_{n \\ge 0} \\operatorname{Ext}^n_R(M, M)$ with the Yoneda product. (Is it isomorphic to a polynomial ring over $\\mathbb{Z}/2\\mathbb{Z}$? If so, determine the degree of the generator.)",
            "answer": "We compute $\\operatorname{Ext}^n_R(M,M)$ and determine the Yoneda product structure.\n\nFirst, note that $M \\cong R/(2)$, where $(2)$ is the ideal generated by $2 \\in R$. There is a short exact sequence of $R$-modules\n$$\n0 \\longrightarrow M \\stackrel{i}{\\longrightarrow} R \\stackrel{\\pi}{\\longrightarrow} M \\longrightarrow 0,\n$$\nwhere $i(1_M) = 2$ (since $2$ generates the kernel of $\\pi$) and $\\pi$ is the natural projection $r \\mapsto r \\bmod 2$. One checks easily that $i$ is injective, $\\pi$ is surjective, and $\\operatorname{im} i = \\ker \\pi = \\{0,2\\} \\cong M$, so the sequence is exact.\n\nBecause $R$ is a free (hence projective) $R$-module, $\\operatorname{Ext}^i_R(R, N) = 0$ for all $i \\ge 1$ and any $R$-module $N$. Applying the contravariant functor $\\operatorname{Hom}_R(-, M)$ to the above short exact sequence yields a long exact sequence:\n$$\n0 \\to \\operatorname{Hom}_R(M,M) \\to \\operatorname{Hom}_R(R,M) \\to \\operatorname{Hom}_R(M,M) \\to \\operatorname{Ext}^1_R(M,M) \\to \\operatorname{Ext}^1_R(R,M) \\to \\operatorname{Ext}^1_R(M,M) \\to \\operatorname{Ext}^2_R(M,M) \\to \\cdots\n$$\nSince $\\operatorname{Ext}^i_R(R,M)=0$ for $i\\ge 1$, this simplifies to\n$$\n0 \\to \\operatorname{Hom}_R(M,M) \\to \\operatorname{Hom}_R(R,M) \\to \\operatorname{Hom}_R(M,M) \\to \\operatorname{Ext}^1_R(M,M) \\to 0\n$$\nand for every $n \\ge 1$ an isomorphism\n$$\n0 \\to \\operatorname{Ext}^n_R(M,M) \\to \\operatorname{Ext}^{n+1}_R(M,M) \\to 0,\n$$\ni.e., $\\operatorname{Ext}^n_R(M,M) \\cong \\operatorname{Ext}^{n+1}_R(M,M)$ for all $n \\ge 1$.\n\nWe now compute the Hom groups. Any $R$-module homomorphism $\\varphi: M \\to M$ is automatically a homomorphism of abelian groups; conversely, any group homomorphism respects the $R$-action because for any $r \\in R$, $r \\cdot \\varphi(a) = \\overline{r} \\varphi(a)$ and $\\varphi(r \\cdot a) = \\varphi(\\overline{r} a) = \\overline{r} \\varphi(a)$ (since $\\varphi$ is $\\mathbb{Z}$-linear). Hence $\\operatorname{Hom}_R(M,M) \\cong \\operatorname{Hom}_{\\mathbb{Z}}(\\mathbb{Z}/2\\mathbb{Z}, \\mathbb{Z}/2\\mathbb{Z}) \\cong \\mathbb{Z}/2\\mathbb{Z}$. The isomorphism sends a homomorphism to its value on the generator $1_M$; the identity map corresponds to $1 \\in \\mathbb{Z}/2\\mathbb{Z}$.\n\nSimilarly, $\\operatorname{Hom}_R(R, M) \\cong M$ via evaluation at $1_R$: any $f: R \\to M$ is determined by $f(1)$, and the map $f \\mapsto f(1)$ is an isomorphism of abelian groups. Thus $\\operatorname{Hom}_R(R,M) \\cong \\mathbb{Z}/2\\mathbb{Z}$ as well.\n\nWe need to understand the maps in the long exact sequence. The first map $\\operatorname{Hom}_R(M,M) \\to \\operatorname{Hom}_R(R,M)$ is induced by $\\pi: R \\to M$. Concretely, it sends $\\varphi \\in \\operatorname{Hom}_R(M,M)$ to $\\varphi \\circ \\pi$. Under the isomorphisms above, if $\\varphi(1_M)=a$, then $(\\varphi\\circ\\pi)(1_R) = \\varphi(\\pi(1_R)) = \\varphi(1_M) = a$. Hence this map corresponds to the identity map on $\\mathbb{Z}/2\\mathbb{Z}$; in particular it is an isomorphism.\n\nThe second map $\\operatorname{Hom}_R(R,M) \\to \\operatorname{Hom}_R(M,M)$ is induced by $i: M \\to R$. It sends $\\psi \\in \\operatorname{Hom}_R(R,M)$ to $\\psi \\circ i$. If $\\psi(1_R)=b$, then $(\\psi\\circ i)(1_M) = \\psi(i(1_M)) = \\psi(2) = 2b$ (since $\\psi$ is $R$-linear). But in $M$, $2b = 0$ for any $b$ because $2$ acts as $0$. Therefore $\\psi \\circ i$ is the zero homomorphism. Consequently, the second map is the zero map.\n\nPlugging this into the exact sequence we obtain:\n$$\n0 \\to \\mathbb{Z}/2\\mathbb{Z} \\stackrel{\\cong}{\\to} \\mathbb{Z}/2\\mathbb{Z} \\stackrel{0}{\\to} \\mathbb{Z}/2\\mathbb{Z} \\to \\operatorname{Ext}^1_R(M,M) \\to 0.\n$$\nExactness at the third term $\\mathbb{Z}/2\\mathbb{Z}$ means $\\ker(\\mathbb{Z}/2\\mathbb{Z} \\to \\operatorname{Ext}^1) = \\operatorname{im}(0) = 0$, so the map $\\mathbb{Z}/2\\mathbb{Z} \\to \\operatorname{Ext}^1$ is injective. Exactness at the fourth term says this map is also surjective (since the next term is $0$). Hence $\\operatorname{Ext}^1_R(M,M) \\cong \\mathbb{Z}/2\\mathbb{Z}$ and the map $\\operatorname{Hom}_R(M,M) \\to \\operatorname{Ext}^1_R(M,M)$ is an isomorphism.\n\nFrom the isomorphisms $\\operatorname{Ext}^n_R(M,M) \\cong \\operatorname{Ext}^{n+1}_R(M,M)$ for $n \\ge 1$, we immediately get by induction that $\\operatorname{Ext}^n_R(M,M) \\cong \\mathbb{Z}/2\\mathbb{Z}$ for all $n \\ge 0$. (For $n=0$, $\\operatorname{Hom}_R(M,M) \\cong \\mathbb{Z}/2\\mathbb{Z}$ already.)\n\nNow we turn to the graded ring structure. Let $\\varepsilon \\in \\operatorname{Ext}^1_R(M,M)$ be the class of the short exact sequence\n$$\n0 \\to M \\stackrel{i}{\\to} R \\stackrel{\\pi}{\\to} M \\to 0.\n$$\nA fundamental fact in homological algebra is that the connecting homomorphism $\\delta_n: \\operatorname{Ext}^n_R(M,M) \\to \\operatorname{Ext}^{n+1}_R(M,M)$ appearing in the long exact sequence derived from the above short exact sequence (by applying $\\operatorname{Hom}_R(-,M)$) coincides with the Yoneda product with $\\varepsilon$ on the right: $\\delta_n(\\alpha) = \\alpha \\smile \\varepsilon$ (or equivalently $\\varepsilon \\smile \\alpha$; in characteristic $2$ there is no sign difference). This can be seen by unravelling the definition of the connecting homomorphism in terms of splicing of extensions.\n\nFrom our long exact sequence we have, for each $n \\ge 0$, an exact segment\n$$\n\\operatorname{Ext}^n_R(R,M) \\to \\operatorname{Ext}^n_R(M,M) \\stackrel{\\delta_n}{\\to} \\operatorname{Ext}^{n+1}_R(M,M) \\to \\operatorname{Ext}^{n+1}_R(R,M).\n$$\nSince $\\operatorname{Ext}^i_R(R,M)=0$ for $i\\ge 1$, for $n \\ge 1$ we obtain isomorphisms $\\delta_n: \\operatorname{Ext}^n_R(M,M) \\stackrel{\\cong}{\\to} \\operatorname{Ext}^{n+1}_R(M,M)$. For $n=0$, we have the exact sequence\n$$\n0 \\to \\operatorname{Hom}_R(M,M) \\to \\operatorname{Hom}_R(R,M) \\to \\operatorname{Hom}_R(M,M) \\stackrel{\\delta_0}{\\to} \\operatorname{Ext}^1_R(M,M) \\to 0,\n$$\nand we already determined that $\\delta_0$ is an isomorphism as well (because the previous map is zero and the sequence is exact). Therefore, $\\delta_n$ is an isomorphism for every $n \\ge 0$.\n\nBecause $\\delta_n(\\alpha) = \\alpha \\smile \\varepsilon$, we conclude that right multiplication by $\\varepsilon$ gives an isomorphism from $\\operatorname{Ext}^n_R(M,M)$ onto $\\operatorname{Ext}^{n+1}_R(M,M)$ for all $n$. In particular, $\\varepsilon$ is nonzero, and $\\varepsilon^2 = \\varepsilon \\smile \\varepsilon = \\delta_1(\\varepsilon)$ is nonzero (since $\\delta_1$ is an isomorphism). By induction, $\\varepsilon^k \\neq 0$ for all $k \\ge 0$. Since each $\\operatorname{Ext}^n_R(M,M)$ is a one\u2011dimensional vector space over $\\mathbb{Z}/2\\mathbb{Z}$, the map $\\alpha \\mapsto \\alpha \\smile \\varepsilon$ must be an isomorphism, and consequently $\\varepsilon^n$ generates $\\operatorname{Ext}^n_R(M,M)$.\n\nThe Yoneda product is associative and, because we work over a ring of characteristic $2$, it is commutative in the graded sense (there are no sign issues). Hence the graded ring $\\operatorname{Ext}^*_R(M,M)$ is isomorphic to the polynomial ring $(\\mathbb{Z}/2\\mathbb{Z})[t]$ with $t$ placed in degree $1$, where $t$ corresponds to $\\varepsilon$.\n\nTo summarise:\n$$\n\\operatorname{Ext}^n_R(M,M) \\cong \\mathbb{Z}/2\\mathbb{Z} \\quad \\text{for all } n \\ge 0,\n$$\nand as a graded $\\mathbb{Z}/2\\mathbb{Z}$-algebra,\n$$\n\\operatorname{Ext}^*_R(M,M) \\cong (\\mathbb{Z}/2\\mathbb{Z})[t], \\qquad \\deg t = 1.\n$$\n\nThis completes the solution.",
            "raw_answer": "[QUESTION]\nLet $R = \\mathbb{Z}/4\\mathbb{Z}$ and let $M = \\mathbb{Z}/2\\mathbb{Z}$ be the $R$-module where the action is given by the natural surjection $R \\to \\mathbb{Z}/2\\mathbb{Z}$ (i.e., $r \\cdot a = \\overline{r} \\, a$, where $\\overline{r}$ denotes reduction modulo $2$). Compute $\\operatorname{Ext}^n_R(M, M)$ for all integers $n \\ge 0$. Moreover, describe the structure of the graded ring $\\operatorname{Ext}^*_R(M, M) = \\bigoplus_{n \\ge 0} \\operatorname{Ext}^n_R(M, M)$ with the Yoneda product. (Is it isomorphic to a polynomial ring over $\\mathbb{Z}/2\\mathbb{Z}$? If so, determine the degree of the generator.)\n\n[ANSWER]\nWe compute $\\operatorname{Ext}^n_R(M,M)$ and determine the Yoneda product structure.\n\nFirst, note that $M \\cong R/(2)$, where $(2)$ is the ideal generated by $2 \\in R$. There is a short exact sequence of $R$-modules\n\\[\n0 \\longrightarrow M \\stackrel{i}{\\longrightarrow} R \\stackrel{\\pi}{\\longrightarrow} M \\longrightarrow 0,\n\\]\nwhere $i(1_M) = 2$ (since $2$ generates the kernel of $\\pi$) and $\\pi$ is the natural projection $r \\mapsto r \\bmod 2$. One checks easily that $i$ is injective, $\\pi$ is surjective, and $\\operatorname{im} i = \\ker \\pi = \\{0,2\\} \\cong M$, so the sequence is exact.\n\nBecause $R$ is a free (hence projective) $R$-module, $\\operatorname{Ext}^i_R(R, N) = 0$ for all $i \\ge 1$ and any $R$-module $N$. Applying the contravariant functor $\\operatorname{Hom}_R(-, M)$ to the above short exact sequence yields a long exact sequence:\n\\[\n0 \\to \\operatorname{Hom}_R(M,M) \\to \\operatorname{Hom}_R(R,M) \\to \\operatorname{Hom}_R(M,M) \\to \\operatorname{Ext}^1_R(M,M) \\to \\operatorname{Ext}^1_R(R,M) \\to \\operatorname{Ext}^1_R(M,M) \\to \\operatorname{Ext}^2_R(M,M) \\to \\cdots\n\\]\nSince $\\operatorname{Ext}^i_R(R,M)=0$ for $i\\ge 1$, this simplifies to\n\\[\n0 \\to \\operatorname{Hom}_R(M,M) \\to \\operatorname{Hom}_R(R,M) \\to \\operatorname{Hom}_R(M,M) \\to \\operatorname{Ext}^1_R(M,M) \\to 0\n\\]\nand for every $n \\ge 1$ an isomorphism\n\\[\n0 \\to \\operatorname{Ext}^n_R(M,M) \\to \\operatorname{Ext}^{n+1}_R(M,M) \\to 0,\n\\]\ni.e., $\\operatorname{Ext}^n_R(M,M) \\cong \\operatorname{Ext}^{n+1}_R(M,M)$ for all $n \\ge 1$.\n\nWe now compute the Hom groups. Any $R$-module homomorphism $\\varphi: M \\to M$ is automatically a homomorphism of abelian groups; conversely, any group homomorphism respects the $R$-action because for any $r \\in R$, $r \\cdot \\varphi(a) = \\overline{r} \\varphi(a)$ and $\\varphi(r \\cdot a) = \\varphi(\\overline{r} a) = \\overline{r} \\varphi(a)$ (since $\\varphi$ is $\\mathbb{Z}$-linear). Hence $\\operatorname{Hom}_R(M,M) \\cong \\operatorname{Hom}_{\\mathbb{Z}}(\\mathbb{Z}/2\\mathbb{Z}, \\mathbb{Z}/2\\mathbb{Z}) \\cong \\mathbb{Z}/2\\mathbb{Z}$. The isomorphism sends a homomorphism to its value on the generator $1_M$; the identity map corresponds to $1 \\in \\mathbb{Z}/2\\mathbb{Z}$.\n\nSimilarly, $\\operatorname{Hom}_R(R, M) \\cong M$ via evaluation at $1_R$: any $f: R \\to M$ is determined by $f(1)$, and the map $f \\mapsto f(1)$ is an isomorphism of abelian groups. Thus $\\operatorname{Hom}_R(R,M) \\cong \\mathbb{Z}/2\\mathbb{Z}$ as well.\n\nWe need to understand the maps in the long exact sequence. The first map $\\operatorname{Hom}_R(M,M) \\to \\operatorname{Hom}_R(R,M)$ is induced by $\\pi: R \\to M$. Concretely, it sends $\\varphi \\in \\operatorname{Hom}_R(M,M)$ to $\\varphi \\circ \\pi$. Under the isomorphisms above, if $\\varphi(1_M)=a$, then $(\\varphi\\circ\\pi)(1_R) = \\varphi(\\pi(1_R)) = \\varphi(1_M) = a$. Hence this map corresponds to the identity map on $\\mathbb{Z}/2\\mathbb{Z}$; in particular it is an isomorphism.\n\nThe second map $\\operatorname{Hom}_R(R,M) \\to \\operatorname{Hom}_R(M,M)$ is induced by $i: M \\to R$. It sends $\\psi \\in \\operatorname{Hom}_R(R,M)$ to $\\psi \\circ i$. If $\\psi(1_R)=b$, then $(\\psi\\circ i)(1_M) = \\psi(i(1_M)) = \\psi(2) = 2b$ (since $\\psi$ is $R$-linear). But in $M$, $2b = 0$ for any $b$ because $2$ acts as $0$. Therefore $\\psi \\circ i$ is the zero homomorphism. Consequently, the second map is the zero map.\n\nPlugging this into the exact sequence we obtain:\n\\[\n0 \\to \\mathbb{Z}/2\\mathbb{Z} \\stackrel{\\cong}{\\to} \\mathbb{Z}/2\\mathbb{Z} \\stackrel{0}{\\to} \\mathbb{Z}/2\\mathbb{Z} \\to \\operatorname{Ext}^1_R(M,M) \\to 0.\n\\]\nExactness at the third term $\\mathbb{Z}/2\\mathbb{Z}$ means $\\ker(\\mathbb{Z}/2\\mathbb{Z} \\to \\operatorname{Ext}^1) = \\operatorname{im}(0) = 0$, so the map $\\mathbb{Z}/2\\mathbb{Z} \\to \\operatorname{Ext}^1$ is injective. Exactness at the fourth term says this map is also surjective (since the next term is $0$). Hence $\\operatorname{Ext}^1_R(M,M) \\cong \\mathbb{Z}/2\\mathbb{Z}$ and the map $\\operatorname{Hom}_R(M,M) \\to \\operatorname{Ext}^1_R(M,M)$ is an isomorphism.\n\nFrom the isomorphisms $\\operatorname{Ext}^n_R(M,M) \\cong \\operatorname{Ext}^{n+1}_R(M,M)$ for $n \\ge 1$, we immediately get by induction that $\\operatorname{Ext}^n_R(M,M) \\cong \\mathbb{Z}/2\\mathbb{Z}$ for all $n \\ge 0$. (For $n=0$, $\\operatorname{Hom}_R(M,M) \\cong \\mathbb{Z}/2\\mathbb{Z}$ already.)\n\nNow we turn to the graded ring structure. Let $\\varepsilon \\in \\operatorname{Ext}^1_R(M,M)$ be the class of the short exact sequence\n\\[\n0 \\to M \\stackrel{i}{\\to} R \\stackrel{\\pi}{\\to} M \\to 0.\n\\]\nA fundamental fact in homological algebra is that the connecting homomorphism $\\delta_n: \\operatorname{Ext}^n_R(M,M) \\to \\operatorname{Ext}^{n+1}_R(M,M)$ appearing in the long exact sequence derived from the above short exact sequence (by applying $\\operatorname{Hom}_R(-,M)$) coincides with the Yoneda product with $\\varepsilon$ on the right: $\\delta_n(\\alpha) = \\alpha \\smile \\varepsilon$ (or equivalently $\\varepsilon \\smile \\alpha$; in characteristic $2$ there is no sign difference). This can be seen by unravelling the definition of the connecting homomorphism in terms of splicing of extensions.\n\nFrom our long exact sequence we have, for each $n \\ge 0$, an exact segment\n\\[\n\\operatorname{Ext}^n_R(R,M) \\to \\operatorname{Ext}^n_R(M,M) \\stackrel{\\delta_n}{\\to} \\operatorname{Ext}^{n+1}_R(M,M) \\to \\operatorname{Ext}^{n+1}_R(R,M).\n\\]\nSince $\\operatorname{Ext}^i_R(R,M)=0$ for $i\\ge 1$, for $n \\ge 1$ we obtain isomorphisms $\\delta_n: \\operatorname{Ext}^n_R(M,M) \\stackrel{\\cong}{\\to} \\operatorname{Ext}^{n+1}_R(M,M)$. For $n=0$, we have the exact sequence\n\\[\n0 \\to \\operatorname{Hom}_R(M,M) \\to \\operatorname{Hom}_R(R,M) \\to \\operatorname{Hom}_R(M,M) \\stackrel{\\delta_0}{\\to} \\operatorname{Ext}^1_R(M,M) \\to 0,\n\\]\nand we already determined that $\\delta_0$ is an isomorphism as well (because the previous map is zero and the sequence is exact). Therefore, $\\delta_n$ is an isomorphism for every $n \\ge 0$.\n\nBecause $\\delta_n(\\alpha) = \\alpha \\smile \\varepsilon$, we conclude that right multiplication by $\\varepsilon$ gives an isomorphism from $\\operatorname{Ext}^n_R(M,M)$ onto $\\operatorname{Ext}^{n+1}_R(M,M)$ for all $n$. In particular, $\\varepsilon$ is nonzero, and $\\varepsilon^2 = \\varepsilon \\smile \\varepsilon = \\delta_1(\\varepsilon)$ is nonzero (since $\\delta_1$ is an isomorphism). By induction, $\\varepsilon^k \\neq 0$ for all $k \\ge 0$. Since each $\\operatorname{Ext}^n_R(M,M)$ is a one\u2011dimensional vector space over $\\mathbb{Z}/2\\mathbb{Z}$, the map $\\alpha \\mapsto \\alpha \\smile \\varepsilon$ must be an isomorphism, and consequently $\\varepsilon^n$ generates $\\operatorname{Ext}^n_R(M,M)$.\n\nThe Yoneda product is associative and, because we work over a ring of characteristic $2$, it is commutative in the graded sense (there are no sign issues). Hence the graded ring $\\operatorname{Ext}^*_R(M,M)$ is isomorphic to the polynomial ring $(\\mathbb{Z}/2\\mathbb{Z})[t]$ with $t$ placed in degree $1$, where $t$ corresponds to $\\varepsilon$.\n\nTo summarise:\n\\[\n\\operatorname{Ext}^n_R(M,M) \\cong \\mathbb{Z}/2\\mathbb{Z} \\quad \\text{for all } n \\ge 0,\n\\]\nand as a graded $\\mathbb{Z}/2\\mathbb{Z}$-algebra,\n\\[\n\\operatorname{Ext}^*_R(M,M) \\cong (\\mathbb{Z}/2\\mathbb{Z})[t], \\qquad \\deg t = 1.\n\\]\n\nThis completes the solution.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "13",
    "outer_attempt": 1,
    "topic_slug": "k_theory",
    "topic_name": "K-theory",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $k$ be a nonzero integer. Define $X_k$ to be the CW complex obtained by attaching a $3$-cell to the $2$-sphere $S^2$ via a map $f: S^2 \\to S^2$ of degree $k$. Compute the complex topological K-theory groups $K^0(X_k)$ and $K^1(X_k)$.",
            "answer": "We compute the groups using the long exact sequence in K-theory for a CW pair.\n\n1. **Setup.**  \n   Let $A = S^2$ be the $2$-skeleton of $X_k$. Then the quotient $X_k/A$ is homeomorphic to $S^3$. For any CW pair $(X,A)$ there is a six-term exact sequence\n   $$\n   K^0(X,A) \\to K^0(X) \\to K^0(A) \\to K^1(X,A) \\to K^1(X) \\to K^1(A).\n   $$\n   Moreover, for a pair we have $K^*(X,A) \\cong \\tilde{K}^*(X/A)$, where $\\tilde{K}^*$ denotes reduced K-theory.\n\n2. **K-groups of spheres.**  \n   Recall the following (complex) K-theory groups:\n   $$\n   K^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z},\\qquad K^1(S^2) = 0,\n   $$\n   $$\n   K^0(S^3) \\cong \\mathbb{Z},\\qquad K^1(S^3) \\cong \\mathbb{Z}.\n   $$\n   In reduced terms,\n   $$\n   \\tilde{K}^0(S^2) \\cong \\mathbb{Z},\\quad \\tilde{K}^1(S^2)=0,\\quad\n   \\tilde{K}^0(S^3)=0,\\quad \\tilde{K}^1(S^3)\\cong\\mathbb{Z}.\n   $$\n   The generator of $\\tilde{K}^0(S^2)$ can be taken as $u = [H] - 1$, where $H$ is the Hopf line bundle over $S^2$; the generator of $\\tilde{K}^1(S^3)$ is its suspension, denoted $v$.\n\n3. **Exact sequence for $(X_k,A)$.**  \n   Using $K^0(X_k,A) \\cong \\tilde{K}^0(S^3)=0$ and $K^1(X_k,A) \\cong \\tilde{K}^1(S^3)\\cong\\mathbb{Z}$, the six-term sequence becomes\n   $$\n   0 \\to K^0(X_k) \\to K^0(S^2) \\xrightarrow{\\alpha} \\mathbb{Z} \\to K^1(X_k) \\to 0,\n   $$\n   where $\\alpha$ is the boundary map.\n\n4. **Identify the boundary map.**  \n   To determine $\\alpha$, it is convenient to work with reduced K-theory. The reduced exact sequence for the cofibration $A \\hookrightarrow X_k \\to X_k/A$ is\n   $$\n   \\tilde{K}^0(X_k/A) \\to \\tilde{K}^0(X_k) \\to \\tilde{K}^0(A) \\to \\tilde{K}^1(X_k/A) \\to \\tilde{K}^1(X_k) \\to \\tilde{K}^1(A).\n   $$\n   Substituting $X_k/A = S^3$ and $A=S^2$ gives\n   $$\n   0 \\to \\tilde{K}^0(X_k) \\to \\tilde{K}^0(S^2) \\xrightarrow{\\partial} \\tilde{K}^1(S^3) \\to \\tilde{K}^1(X_k) \\to 0.\n   $$\n   The boundary map $\\partial$ can be described as follows. In a cofibration coming from attaching an $(n+1)$-cell via a map $f: S^n \\to A$, the map $\\Sigma A \\to X/A$ that appears in the cofibration sequence is precisely the suspension $\\Sigma f$. For our case, $n=2$, $A=S^2$, and $\\Sigma f: S^3 \\to S^3$ has degree $k$. The boundary map $\\partial$ is the composition\n   $$\n   \\tilde{K}^0(S^2) \\xrightarrow{S} \\tilde{K}^1(\\Sigma S^2) \\xrightarrow{(\\Sigma f)^*} \\tilde{K}^1(S^3),\n   $$\n   where $S$ is the suspension isomorphism (an isomorphism). The suspension isomorphism sends the generator $u$ to the generator $v$. Since $(\\Sigma f)^*$ is multiplication by $k$ (the degree of $\\Sigma f$), we obtain $\\partial(u) = k\\, v$. Hence $\\partial$ is multiplication by $k$.\n\n5. **Compute reduced groups.**  \n   The reduced exact sequence now reads\n   $$\n   0 \\to \\tilde{K}^0(X_k) \\to \\mathbb{Z} \\xrightarrow{\\times k} \\mathbb{Z} \\to \\tilde{K}^1(X_k) \\to 0.\n   $$\n   Exactness yields:\n   $$\n   \\tilde{K}^0(X_k) \\cong \\ker(\\times k) = 0 \\quad (\\text{since } k\\neq 0),\n   $$\n   $$\n   \\tilde{K}^1(X_k) \\cong \\operatorname{coker}(\\times k) = \\mathbb{Z}/k\\mathbb{Z}.\n   $$\n\n6. **Recover full K-theory.**  \n   Because $X_k$ is connected, we have\n   $$\n   K^0(X_k) \\cong \\mathbb{Z} \\oplus \\tilde{K}^0(X_k) \\cong \\mathbb{Z},\n   $$\n   and\n   $$\n   K^1(X_k) \\cong \\tilde{K}^1(X_k) \\cong \\mathbb{Z}/k\\mathbb{Z}.\n   $$\n\n7. **Conclusion.**  \n   $$\n   \\boxed{K^0(X_k) \\cong \\mathbb{Z},\\qquad K^1(X_k) \\cong \\mathbb{Z}/k\\mathbb{Z}.}\n   $$\n\n   (For $k=0$ the space is different and the result would change, but the problem assumes $k\\neq 0$.)\n\nThis completes the computation.",
            "raw_answer": "[QUESTION]\nLet $k$ be a nonzero integer. Define $X_k$ to be the CW complex obtained by attaching a $3$-cell to the $2$-sphere $S^2$ via a map $f: S^2 \\to S^2$ of degree $k$. Compute the complex topological K-theory groups $K^0(X_k)$ and $K^1(X_k)$.\n\n[ANSWER]\nWe compute the groups using the long exact sequence in K-theory for a CW pair.\n\n1. **Setup.**  \n   Let $A = S^2$ be the $2$-skeleton of $X_k$. Then the quotient $X_k/A$ is homeomorphic to $S^3$. For any CW pair $(X,A)$ there is a six-term exact sequence\n   \\[\n   K^0(X,A) \\to K^0(X) \\to K^0(A) \\to K^1(X,A) \\to K^1(X) \\to K^1(A).\n   \\]\n   Moreover, for a pair we have $K^*(X,A) \\cong \\tilde{K}^*(X/A)$, where $\\tilde{K}^*$ denotes reduced K-theory.\n\n2. **K-groups of spheres.**  \n   Recall the following (complex) K-theory groups:\n   \\[\n   K^0(S^2) \\cong \\mathbb{Z} \\oplus \\mathbb{Z},\\qquad K^1(S^2) = 0,\n   \\]\n   \\[\n   K^0(S^3) \\cong \\mathbb{Z},\\qquad K^1(S^3) \\cong \\mathbb{Z}.\n   \\]\n   In reduced terms,\n   \\[\n   \\tilde{K}^0(S^2) \\cong \\mathbb{Z},\\quad \\tilde{K}^1(S^2)=0,\\quad\n   \\tilde{K}^0(S^3)=0,\\quad \\tilde{K}^1(S^3)\\cong\\mathbb{Z}.\n   \\]\n   The generator of $\\tilde{K}^0(S^2)$ can be taken as $u = [H] - 1$, where $H$ is the Hopf line bundle over $S^2$; the generator of $\\tilde{K}^1(S^3)$ is its suspension, denoted $v$.\n\n3. **Exact sequence for $(X_k,A)$.**  \n   Using $K^0(X_k,A) \\cong \\tilde{K}^0(S^3)=0$ and $K^1(X_k,A) \\cong \\tilde{K}^1(S^3)\\cong\\mathbb{Z}$, the six-term sequence becomes\n   \\[\n   0 \\to K^0(X_k) \\to K^0(S^2) \\xrightarrow{\\alpha} \\mathbb{Z} \\to K^1(X_k) \\to 0,\n   \\]\n   where $\\alpha$ is the boundary map.\n\n4. **Identify the boundary map.**  \n   To determine $\\alpha$, it is convenient to work with reduced K-theory. The reduced exact sequence for the cofibration $A \\hookrightarrow X_k \\to X_k/A$ is\n   \\[\n   \\tilde{K}^0(X_k/A) \\to \\tilde{K}^0(X_k) \\to \\tilde{K}^0(A) \\to \\tilde{K}^1(X_k/A) \\to \\tilde{K}^1(X_k) \\to \\tilde{K}^1(A).\n   \\]\n   Substituting $X_k/A = S^3$ and $A=S^2$ gives\n   \\[\n   0 \\to \\tilde{K}^0(X_k) \\to \\tilde{K}^0(S^2) \\xrightarrow{\\partial} \\tilde{K}^1(S^3) \\to \\tilde{K}^1(X_k) \\to 0.\n   \\]\n   The boundary map $\\partial$ can be described as follows. In a cofibration coming from attaching an $(n+1)$-cell via a map $f: S^n \\to A$, the map $\\Sigma A \\to X/A$ that appears in the cofibration sequence is precisely the suspension $\\Sigma f$. For our case, $n=2$, $A=S^2$, and $\\Sigma f: S^3 \\to S^3$ has degree $k$. The boundary map $\\partial$ is the composition\n   \\[\n   \\tilde{K}^0(S^2) \\xrightarrow{S} \\tilde{K}^1(\\Sigma S^2) \\xrightarrow{(\\Sigma f)^*} \\tilde{K}^1(S^3),\n   \\]\n   where $S$ is the suspension isomorphism (an isomorphism). The suspension isomorphism sends the generator $u$ to the generator $v$. Since $(\\Sigma f)^*$ is multiplication by $k$ (the degree of $\\Sigma f$), we obtain $\\partial(u) = k\\, v$. Hence $\\partial$ is multiplication by $k$.\n\n5. **Compute reduced groups.**  \n   The reduced exact sequence now reads\n   \\[\n   0 \\to \\tilde{K}^0(X_k) \\to \\mathbb{Z} \\xrightarrow{\\times k} \\mathbb{Z} \\to \\tilde{K}^1(X_k) \\to 0.\n   \\]\n   Exactness yields:\n   \\[\n   \\tilde{K}^0(X_k) \\cong \\ker(\\times k) = 0 \\quad (\\text{since } k\\neq 0),\n   \\]\n   \\[\n   \\tilde{K}^1(X_k) \\cong \\operatorname{coker}(\\times k) = \\mathbb{Z}/k\\mathbb{Z}.\n   \\]\n\n6. **Recover full K-theory.**  \n   Because $X_k$ is connected, we have\n   \\[\n   K^0(X_k) \\cong \\mathbb{Z} \\oplus \\tilde{K}^0(X_k) \\cong \\mathbb{Z},\n   \\]\n   and\n   \\[\n   K^1(X_k) \\cong \\tilde{K}^1(X_k) \\cong \\mathbb{Z}/k\\mathbb{Z}.\n   \\]\n\n7. **Conclusion.**  \n   \\[\n   \\boxed{K^0(X_k) \\cong \\mathbb{Z},\\qquad K^1(X_k) \\cong \\mathbb{Z}/k\\mathbb{Z}.}\n   \\]\n\n   (For $k=0$ the space is different and the result would change, but the problem assumes $k\\neq 0$.)\n\nThis completes the computation.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "14",
    "outer_attempt": 1,
    "topic_slug": "group_theory_and_generalizations",
    "topic_name": "Group theory and generalizations",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $G$ be a finite group such that the automorphism group $\\operatorname{Aut}(G)$ is trivial (i.e., the only automorphism of $G$ is the identity map). Prove that $G$ is either the trivial group or the cyclic group of order $2$.",
            "answer": "Assume $G$ is a finite group with $\\operatorname{Aut}(G) = \\{\\mathrm{id}_G\\}$. If $G$ is trivial, the statement holds, so we may assume $G$ is nontrivial.\n\n1. **$G$ is abelian.**  \n   For any $g \\in G$, the conjugation map $\\gamma_g : G \\to G$ defined by $\\gamma_g(x) = g x g^{-1}$ is an inner automorphism, hence $\\gamma_g \\in \\operatorname{Aut}(G)$. By hypothesis $\\operatorname{Aut}(G)$ is trivial, so $\\gamma_g = \\mathrm{id}_G$. Therefore $g x g^{-1} = x$ for all $x \\in G$, which implies $g x = x g$ for all $x,g \\in G$. Thus $G$ is abelian.\n\n2. **$G$ has exponent $2$.**  \n   Because $G$ is abelian, the map $\\iota : G \\to G$ given by $\\iota(x) = x^{-1}$ is a homomorphism: $\\iota(xy) = (xy)^{-1} = y^{-1}x^{-1} = x^{-1}y^{-1} = \\iota(x)\\iota(y)$. Moreover $\\iota$ is bijective (it is its own inverse). Hence $\\iota \\in \\operatorname{Aut}(G)$. By triviality of $\\operatorname{Aut}(G)$ we must have $\\iota = \\mathrm{id}_G$, i.e., $x^{-1} = x$ for all $x \\in G$. Equivalently, $x^2 = e$ for every $x \\in G$, so $G$ is an elementary abelian $2$-group.\n\n3. **Structure of $G$.**  \n   An elementary abelian $2$-group is isomorphic to a direct product of copies of the cyclic group $C_2$; i.e., $G \\cong C_2^{\\, d}$ for some integer $d \\ge 1$ (since $G$ is nontrivial). The automorphism group of $C_2^{\\, d}$ is isomorphic to the general linear group $\\operatorname{GL}(d, \\mathbb{F}_2)$ (the group of invertible $d \\times d$ matrices over the field $\\mathbb{F}_2$). If $d \\ge 2$, then $\\operatorname{GL}(d, \\mathbb{F}_2)$ is nontrivial (for example, the matrix that swaps two coordinates gives a nontrivial automorphism). This would contradict the hypothesis that $\\operatorname{Aut}(G)$ is trivial. Therefore $d = 1$, and $G \\cong C_2$.\n\n4. **Conclusion.**  \n   The only possibilities are $G$ trivial or $G \\cong C_2$, and both indeed have trivial automorphism group (for $C_2$ the only automorphism is the identity because there is exactly one non\u2011identity element). This completes the proof.",
            "raw_answer": "[QUESTION]\nLet $G$ be a finite group such that the automorphism group $\\operatorname{Aut}(G)$ is trivial (i.e., the only automorphism of $G$ is the identity map). Prove that $G$ is either the trivial group or the cyclic group of order $2$.\n\n[ANSWER]\nAssume $G$ is a finite group with $\\operatorname{Aut}(G) = \\{\\mathrm{id}_G\\}$. If $G$ is trivial, the statement holds, so we may assume $G$ is nontrivial.\n\n1. **$G$ is abelian.**  \n   For any $g \\in G$, the conjugation map $\\gamma_g : G \\to G$ defined by $\\gamma_g(x) = g x g^{-1}$ is an inner automorphism, hence $\\gamma_g \\in \\operatorname{Aut}(G)$. By hypothesis $\\operatorname{Aut}(G)$ is trivial, so $\\gamma_g = \\mathrm{id}_G$. Therefore $g x g^{-1} = x$ for all $x \\in G$, which implies $g x = x g$ for all $x,g \\in G$. Thus $G$ is abelian.\n\n2. **$G$ has exponent $2$.**  \n   Because $G$ is abelian, the map $\\iota : G \\to G$ given by $\\iota(x) = x^{-1}$ is a homomorphism: $\\iota(xy) = (xy)^{-1} = y^{-1}x^{-1} = x^{-1}y^{-1} = \\iota(x)\\iota(y)$. Moreover $\\iota$ is bijective (it is its own inverse). Hence $\\iota \\in \\operatorname{Aut}(G)$. By triviality of $\\operatorname{Aut}(G)$ we must have $\\iota = \\mathrm{id}_G$, i.e., $x^{-1} = x$ for all $x \\in G$. Equivalently, $x^2 = e$ for every $x \\in G$, so $G$ is an elementary abelian $2$-group.\n\n3. **Structure of $G$.**  \n   An elementary abelian $2$-group is isomorphic to a direct product of copies of the cyclic group $C_2$; i.e., $G \\cong C_2^{\\, d}$ for some integer $d \\ge 1$ (since $G$ is nontrivial). The automorphism group of $C_2^{\\, d}$ is isomorphic to the general linear group $\\operatorname{GL}(d, \\mathbb{F}_2)$ (the group of invertible $d \\times d$ matrices over the field $\\mathbb{F}_2$). If $d \\ge 2$, then $\\operatorname{GL}(d, \\mathbb{F}_2)$ is nontrivial (for example, the matrix that swaps two coordinates gives a nontrivial automorphism). This would contradict the hypothesis that $\\operatorname{Aut}(G)$ is trivial. Therefore $d = 1$, and $G \\cong C_2$.\n\n4. **Conclusion.**  \n   The only possibilities are $G$ trivial or $G \\cong C_2$, and both indeed have trivial automorphism group (for $C_2$ the only automorphism is the identity because there is exactly one non\u2011identity element). This completes the proof.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "15",
    "outer_attempt": 1,
    "topic_slug": "topological_groups_and_lie_groups",
    "topic_name": "Topological groups, Lie groups",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $G$ be a connected topological group with identity element $e$. Prove that the fundamental group $\\pi_1(G,e)$ is abelian.",
            "answer": "We need to show that for any two loops $\\alpha,\\beta: [0,1]\\to G$ based at $e$ (i.e., $\\alpha(0)=\\alpha(1)=\\beta(0)=\\beta(1)=e$), the homotopy classes satisfy $[\\alpha][\\beta]=[\\beta][\\alpha]$ under the usual concatenation product.\n\nDefine the continuous map $H: [0,1]\\times[0,1] \\to G$ by\n$$\nH(s,t) = \\alpha(s)\\beta(t).\n$$\nContinuity follows from continuity of multiplication in $G$ and of $\\alpha,\\beta$.\n\nObserve the values on the edges:\n$$\n\\begin{aligned}\nH(s,0) &= \\alpha(s)e = \\alpha(s), \\\\\nH(s,1) &= \\alpha(s)e = \\alpha(s), \\\\\nH(0,t) &= e\\beta(t) = \\beta(t), \\\\\nH(1,t) &= e\\beta(t) = \\beta(t).\n\\end{aligned}\n$$\n\nNow consider the loop that goes around the boundary of the square in the counterclockwise direction, starting at $(0,0)$. A parametrization $\\gamma: [0,1] \\to \\partial([0,1]^2)$ can be chosen as follows:\n$$\n\\gamma(u) = \n\\begin{cases}\n(4u,0) & 0\\le u\\le 1/4,\\\\\n(1,4(u-1/4)) & 1/4\\le u\\le 1/2,\\\\\n(1-4(u-1/2),1) & 1/2\\le u\\le 3/4,\\\\\n(0,1-4(u-3/4)) & 3/4\\le u\\le 1.\n\\end{cases}\n$$\nThen the composition $H\\circ \\gamma$ yields a loop in $G$ based at $e$. Explicitly,\n$$\n(H\\circ \\gamma)(u) = \n\\begin{cases}\n\\alpha(4u) & 0\\le u\\le 1/4,\\\\\n\\beta(4(u-1/4)) & 1/4\\le u\\le 1/2,\\\\\n\\alpha(1-4(u-1/2)) & 1/2\\le u\\le 3/4,\\\\\n\\beta(1-4(u-3/4)) & 3/4\\le u\\le 1.\n\\end{cases}\n$$\nThis is precisely the concatenation $\\alpha * \\beta * \\alpha^{-1} * \\beta^{-1}$, where $\\alpha^{-1}(s)=\\alpha(1-s)$ and $\\beta^{-1}(s)=\\beta(1-s)$.\n\nBecause $H$ is defined on the entire square, the loop $H\\circ \\gamma$ is null-homotopic. Indeed, the square $[0,1]^2$ is contractible; define $F: [0,1]\\times [0,1] \\to G$ by\n$$\nF(r,u) = H\\bigl((1-r)\\cdot \\gamma(u)\\bigr).\n$$\nHere $(1-r)\\cdot \\gamma(u)$ means scaling the coordinates of $\\gamma(u)$ by the factor $1-r$; this stays inside $[0,1]^2$ because the square is convex. Then $F(0,u)=H(\\gamma(u)) = (H\\circ \\gamma)(u)$ and $F(1,u)=H(0,0)=e$ for all $u$. Continuity follows from continuity of $H$ and $\\gamma$. Moreover, $F(r,0)=F(r,1)=e$ because $\\gamma(0)=\\gamma(1)=(0,0)$ and $H(0,0)=e$. Hence $F$ is a homotopy relative to the basepoint from $\\alpha * \\beta * \\alpha^{-1} * \\beta^{-1}$ to the constant loop.\n\nThus, in the fundamental group we have\n$$\n[\\alpha][\\beta][\\alpha]^{-1}[\\beta]^{-1} = 1,\n$$\nwhich implies $[\\alpha][\\beta] = [\\beta][\\alpha]$. Since $\\alpha,\\beta$ were arbitrary, $\\pi_1(G,e)$ is abelian.\n\n\u220e",
            "raw_answer": "[QUESTION]\nLet \\(G\\) be a connected topological group with identity element \\(e\\). Prove that the fundamental group \\(\\pi_1(G,e)\\) is abelian.\n\n[ANSWER]\nWe need to show that for any two loops \\(\\alpha,\\beta: [0,1]\\to G\\) based at \\(e\\) (i.e., \\(\\alpha(0)=\\alpha(1)=\\beta(0)=\\beta(1)=e\\)), the homotopy classes satisfy \\([\\alpha][\\beta]=[\\beta][\\alpha]\\) under the usual concatenation product.\n\nDefine the continuous map \\(H: [0,1]\\times[0,1] \\to G\\) by\n\\[\nH(s,t) = \\alpha(s)\\beta(t).\n\\]\nContinuity follows from continuity of multiplication in \\(G\\) and of \\(\\alpha,\\beta\\).\n\nObserve the values on the edges:\n\\[\n\\begin{aligned}\nH(s,0) &= \\alpha(s)e = \\alpha(s), \\\\\nH(s,1) &= \\alpha(s)e = \\alpha(s), \\\\\nH(0,t) &= e\\beta(t) = \\beta(t), \\\\\nH(1,t) &= e\\beta(t) = \\beta(t).\n\\end{aligned}\n\\]\n\nNow consider the loop that goes around the boundary of the square in the counterclockwise direction, starting at \\((0,0)\\). A parametrization \\(\\gamma: [0,1] \\to \\partial([0,1]^2)\\) can be chosen as follows:\n\\[\n\\gamma(u) = \n\\begin{cases}\n(4u,0) & 0\\le u\\le 1/4,\\\\\n(1,4(u-1/4)) & 1/4\\le u\\le 1/2,\\\\\n(1-4(u-1/2),1) & 1/2\\le u\\le 3/4,\\\\\n(0,1-4(u-3/4)) & 3/4\\le u\\le 1.\n\\end{cases}\n\\]\nThen the composition \\(H\\circ \\gamma\\) yields a loop in \\(G\\) based at \\(e\\). Explicitly,\n\\[\n(H\\circ \\gamma)(u) = \n\\begin{cases}\n\\alpha(4u) & 0\\le u\\le 1/4,\\\\\n\\beta(4(u-1/4)) & 1/4\\le u\\le 1/2,\\\\\n\\alpha(1-4(u-1/2)) & 1/2\\le u\\le 3/4,\\\\\n\\beta(1-4(u-3/4)) & 3/4\\le u\\le 1.\n\\end{cases}\n\\]\nThis is precisely the concatenation \\(\\alpha * \\beta * \\alpha^{-1} * \\beta^{-1}\\), where \\(\\alpha^{-1}(s)=\\alpha(1-s)\\) and \\(\\beta^{-1}(s)=\\beta(1-s)\\).\n\nBecause \\(H\\) is defined on the entire square, the loop \\(H\\circ \\gamma\\) is null-homotopic. Indeed, the square \\([0,1]^2\\) is contractible; define \\(F: [0,1]\\times [0,1] \\to G\\) by\n\\[\nF(r,u) = H\\bigl((1-r)\\cdot \\gamma(u)\\bigr).\n\\]\nHere \\((1-r)\\cdot \\gamma(u)\\) means scaling the coordinates of \\(\\gamma(u)\\) by the factor \\(1-r\\); this stays inside \\([0,1]^2\\) because the square is convex. Then \\(F(0,u)=H(\\gamma(u)) = (H\\circ \\gamma)(u)\\) and \\(F(1,u)=H(0,0)=e\\) for all \\(u\\). Continuity follows from continuity of \\(H\\) and \\(\\gamma\\). Moreover, \\(F(r,0)=F(r,1)=e\\) because \\(\\gamma(0)=\\gamma(1)=(0,0)\\) and \\(H(0,0)=e\\). Hence \\(F\\) is a homotopy relative to the basepoint from \\(\\alpha * \\beta * \\alpha^{-1} * \\beta^{-1}\\) to the constant loop.\n\nThus, in the fundamental group we have\n\\[\n[\\alpha][\\beta][\\alpha]^{-1}[\\beta]^{-1} = 1,\n\\]\nwhich implies \\([\\alpha][\\beta] = [\\beta][\\alpha]\\). Since \\(\\alpha,\\beta\\) were arbitrary, \\(\\pi_1(G,e)\\) is abelian.\n\n\u220e",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "16",
    "outer_attempt": 1,
    "topic_slug": "real_functions",
    "topic_name": "Real functions",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $f:[0,1]\\to\\mathbb{R}$ be a function satisfying $|f(x)-f(y)|\\le 2|x-y|$ for all $x,y\\in[0,1]$. Suppose $f(0)=0$ and $f(1)=1$. Determine the maximum possible value of $\\int_0^1 f(x)\\,dx$.",
            "answer": "The maximum possible value is $\\frac{7}{8}$.\n\n**Solution.**  \nWe first derive a pointwise upper bound for any admissible $f$. From the Lipschitz condition with $y=0$ we have\n$$\n|f(x)-f(0)|\\le 2|x-0| = 2x,\n$$\nwhich gives $f(x)\\le 2x$. Using $y=1$ we obtain\n$$\n|f(x)-f(1)|\\le 2|1-x| = 2(1-x),\n$$\nso that $f(x)\\le 1+2(1-x)=3-2x$. Consequently, for every $x\\in[0,1]$,\n$$\nf(x)\\le \\min(2x,\\,3-2x).\n$$\n\nDefine\n$$\ng(x)=\\min(2x,\\,3-2x)=\n\\begin{cases}\n2x, & 0\\le x\\le \\frac34,\\$$4pt]\n3-2x, & \\frac34\\le x\\le 1.\n\\end{cases}\n$$\nThen $f(x)\\le g(x)$ for all $x$, and therefore\n$$\n\\int_0^1 f(x)\\,dx \\le \\int_0^1 g(x)\\,dx.\n$$\n\nNow compute the integral of $g$:\n$$\n\\int_0^{3/4} 2x\\,dx = \\Bigl[x^2\\Bigr]_0^{3/4} = \\frac{9}{16},\n$$\n$$\n\\int_{3/4}^1 (3-2x)\\,dx = \\Bigl[3x - x^2\\Bigr]_{3/4}^1 = (3-1) - \\Bigl(3\\cdot\\frac34 - \\Bigl(\\frac34\\Bigr)^2\\Bigr) = 2 - \\Bigl(\\frac94 - \\frac{9}{16}\\Bigr) = 2 - \\frac{27}{16} = \\frac{32}{16} - \\frac{27}{16} = \\frac{5}{16}.\n$$\nAdding these, $\\int_0^1 g(x)\\,dx = \\frac{9}{16}+\\frac{5}{16}=\\frac{14}{16}=\\frac78$.\n\nThus every admissible $f$ satisfies $\\int_0^1 f(x)\\,dx\\le\\frac78$.\n\nFinally, the function $g$ itself is admissible: it is continuous, satisfies $g(0)=0$ and $g(1)=1$, and because its derivative (where it exists) is either $2$ or $-2$, it is $2$-Lipschitz (one can verify directly that $|g(x)-g(y)|\\le 2|x-y|$ for all $x,y$). Hence $g$ attains the bound, proving that $\\frac78$ is indeed the maximum possible value.",
            "raw_answer": "[QUESTION]\nLet \\(f:[0,1]\\to\\mathbb{R}\\) be a function satisfying \\(|f(x)-f(y)|\\le 2|x-y|\\) for all \\(x,y\\in[0,1]\\). Suppose \\(f(0)=0\\) and \\(f(1)=1\\). Determine the maximum possible value of \\(\\int_0^1 f(x)\\,dx\\).\n\n[ANSWER]\nThe maximum possible value is \\(\\frac{7}{8}\\).\n\n**Solution.**  \nWe first derive a pointwise upper bound for any admissible \\(f\\). From the Lipschitz condition with \\(y=0\\) we have\n\\[\n|f(x)-f(0)|\\le 2|x-0| = 2x,\n\\]\nwhich gives \\(f(x)\\le 2x\\). Using \\(y=1\\) we obtain\n\\[\n|f(x)-f(1)|\\le 2|1-x| = 2(1-x),\n\\]\nso that \\(f(x)\\le 1+2(1-x)=3-2x\\). Consequently, for every \\(x\\in[0,1]\\),\n\\[\nf(x)\\le \\min(2x,\\,3-2x).\n\\]\n\nDefine\n\\[\ng(x)=\\min(2x,\\,3-2x)=\n\\begin{cases}\n2x, & 0\\le x\\le \\frac34,\\\\[4pt]\n3-2x, & \\frac34\\le x\\le 1.\n\\end{cases}\n\\]\nThen \\(f(x)\\le g(x)\\) for all \\(x\\), and therefore\n\\[\n\\int_0^1 f(x)\\,dx \\le \\int_0^1 g(x)\\,dx.\n\\]\n\nNow compute the integral of \\(g\\):\n\\[\n\\int_0^{3/4} 2x\\,dx = \\Bigl[x^2\\Bigr]_0^{3/4} = \\frac{9}{16},\n\\]\n\\[\n\\int_{3/4}^1 (3-2x)\\,dx = \\Bigl[3x - x^2\\Bigr]_{3/4}^1 = (3-1) - \\Bigl(3\\cdot\\frac34 - \\Bigl(\\frac34\\Bigr)^2\\Bigr) = 2 - \\Bigl(\\frac94 - \\frac{9}{16}\\Bigr) = 2 - \\frac{27}{16} = \\frac{32}{16} - \\frac{27}{16} = \\frac{5}{16}.\n\\]\nAdding these, \\(\\int_0^1 g(x)\\,dx = \\frac{9}{16}+\\frac{5}{16}=\\frac{14}{16}=\\frac78\\).\n\nThus every admissible \\(f\\) satisfies \\(\\int_0^1 f(x)\\,dx\\le\\frac78\\).\n\nFinally, the function \\(g\\) itself is admissible: it is continuous, satisfies \\(g(0)=0\\) and \\(g(1)=1\\), and because its derivative (where it exists) is either \\(2\\) or \\(-2\\), it is \\(2\\)-Lipschitz (one can verify directly that \\(|g(x)-g(y)|\\le 2|x-y|\\) for all \\(x,y\\)). Hence \\(g\\) attains the bound, proving that \\(\\frac78\\) is indeed the maximum possible value.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "17",
    "outer_attempt": 1,
    "topic_slug": "measure_and_integration",
    "topic_name": "Measure and integration",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Prove that there exists a Lebesgue measurable set $E \\subseteq \\mathbb{R}$ such that for every nonempty open interval $I \\subseteq \\mathbb{R}$, we have $0 < m(E \\cap I) < m(I)$, where $m$ denotes Lebesgue measure.",
            "answer": "We construct such a set explicitly.\n\n1. **Countable base.** Let $\\{I_n\\}_{n=1}^\\infty$ be an enumeration of all open intervals with rational endpoints. This family is countable and forms a base for the topology of $\\mathbb{R}$; in particular, every open interval contains some $I_n$.\n\n2. **Inductive construction.** We will construct by induction two sequences $\\{A_n\\}_{n=1}^\\infty$ and $\\{B_n\\}_{n=1}^\\infty$ of subsets of $\\mathbb{R}$ with the following properties for each $n$:\n   - $A_n$ and $B_n$ are disjoint compact nowhere dense sets of positive Lebesgue measure.\n   - $A_n \\cup B_n \\subseteq I_n$.\n   - $A_n$ and $B_n$ are disjoint from all previously constructed sets:  \n     $A_n \\cap \\bigcup_{k<n}(A_k\\cup B_k)=\\emptyset$ and $B_n \\cap \\bigcup_{k<n}(A_k\\cup B_k)=\\emptyset$.\n\n   **Base step:** $n=1$. Choose any open interval $J_1 \\subseteq I_1$ (e.g., $J_1=I_1$ itself). Inside $J_1$ pick two disjoint closed intervals $J_1^a, J_1^b$. In each of these construct a *fat Cantor set* (also called Smith\u2013Volterra\u2013Cantor set) of positive measure. A fat Cantor set inside a closed interval $[c,d]$ is obtained by removing a sequence of open subintervals whose total length is less than $d-c$, leaving a compact, perfect, nowhere dense set with positive measure. (For instance, start with $[c,d]$, remove the middle open interval of length $(d-c)/4$, then from the two remaining intervals remove the middle open intervals of length $(d-c)/16$, and so on; the total removed length is $(d-c)/2$, so the remaining set has measure $(d-c)/2$.) Let $A_1$ and $B_1$ be such sets constructed inside $J_1^a$ and $J_1^b$, respectively. Then $A_1,B_1$ satisfy the required properties.\n\n   **Inductive step:** Assume that for all $k < n$ the sets $A_k,B_k$ have been constructed and satisfy the properties. Define $S_{n-1} = \\bigcup_{k<n}(A_k\\cup B_k)$. Each $A_k,B_k$ is compact and nowhere dense, so their finite union $S_{n-1}$ is also compact and nowhere dense. In particular, $S_{n-1}$ is closed and has empty interior. Consequently, $I_n \\setminus S_{n-1}$ is a nonempty open set (as the intersection of the open interval $I_n$ with the complement of the closed set $S_{n-1}$). Choose an open interval $J_n \\subseteq I_n \\setminus S_{n-1}$. Now, exactly as in the base step, pick two disjoint closed subintervals $J_n^a, J_n^b \\subset J_n$ and construct inside them fat Cantor sets $A_n$ and $B_n$ of positive measure. By construction, $A_n,B_n \\subseteq J_n \\subseteq I_n$, they are disjoint from each other, and because $J_n \\cap S_{n-1} = \\emptyset$, they are also disjoint from all previously constructed sets. This completes the induction.\n\n3. **Definition of $E$.** Set $E = \\bigcup_{n=1}^\\infty A_n$. Since each $A_n$ is measurable, $E$ is Lebesgue measurable.\n\n4. **Verification of the required property.**\n   - First, fix an index $n$. Because $A_n \\subseteq I_n$, we have $E \\cap I_n \\supseteq A_n$, so $m(E \\cap I_n) \\ge m(A_n) > 0$. Moreover, $B_n \\subseteq I_n$ and $B_n \\cap E = \\emptyset$ (by construction $B_n$ is disjoint from every $A_k$, hence from $E$). Therefore $B_n \\subseteq I_n \\setminus E$, implying $m(I_n \\setminus E) \\ge m(B_n) > 0$. Thus $0 < m(E \\cap I_n) < m(I_n)$ for every $n$.\n\n   - Now let $I$ be an arbitrary nonempty open interval. Since the family $\\{I_n\\}$ is a base, there exists some $n$ such that $I_n \\subseteq I$ (explicitly: choose rational numbers $a<b$ with $(a,b) \\subseteq I$; then $(a,b)$ is one of the $I_n$). Then\n     $$\n     m(E \\cap I) \\ge m(E \\cap I_n) > 0 \\quad\\text{and}\\quad m(I \\setminus E) \\ge m(I_n \\setminus E) > 0,\n     $$\n     which yields $0 < m(E \\cap I) < m(I)$.\n\n5. **Conclusion.** The set $E$ constructed above is Lebesgue measurable and satisfies $0 < m(E \\cap I) < m(I)$ for every nonempty open interval $I \\subseteq \\mathbb{R}$. \u220e",
            "raw_answer": "[QUESTION]\nProve that there exists a Lebesgue measurable set $E \\subseteq \\mathbb{R}$ such that for every nonempty open interval $I \\subseteq \\mathbb{R}$, we have $0 < m(E \\cap I) < m(I)$, where $m$ denotes Lebesgue measure.\n\n[ANSWER]\nWe construct such a set explicitly.\n\n1. **Countable base.** Let $\\{I_n\\}_{n=1}^\\infty$ be an enumeration of all open intervals with rational endpoints. This family is countable and forms a base for the topology of $\\mathbb{R}$; in particular, every open interval contains some $I_n$.\n\n2. **Inductive construction.** We will construct by induction two sequences $\\{A_n\\}_{n=1}^\\infty$ and $\\{B_n\\}_{n=1}^\\infty$ of subsets of $\\mathbb{R}$ with the following properties for each $n$:\n   - $A_n$ and $B_n$ are disjoint compact nowhere dense sets of positive Lebesgue measure.\n   - $A_n \\cup B_n \\subseteq I_n$.\n   - $A_n$ and $B_n$ are disjoint from all previously constructed sets:  \n     $A_n \\cap \\bigcup_{k<n}(A_k\\cup B_k)=\\emptyset$ and $B_n \\cap \\bigcup_{k<n}(A_k\\cup B_k)=\\emptyset$.\n\n   **Base step:** $n=1$. Choose any open interval $J_1 \\subseteq I_1$ (e.g., $J_1=I_1$ itself). Inside $J_1$ pick two disjoint closed intervals $J_1^a, J_1^b$. In each of these construct a *fat Cantor set* (also called Smith\u2013Volterra\u2013Cantor set) of positive measure. A fat Cantor set inside a closed interval $[c,d]$ is obtained by removing a sequence of open subintervals whose total length is less than $d-c$, leaving a compact, perfect, nowhere dense set with positive measure. (For instance, start with $[c,d]$, remove the middle open interval of length $(d-c)/4$, then from the two remaining intervals remove the middle open intervals of length $(d-c)/16$, and so on; the total removed length is $(d-c)/2$, so the remaining set has measure $(d-c)/2$.) Let $A_1$ and $B_1$ be such sets constructed inside $J_1^a$ and $J_1^b$, respectively. Then $A_1,B_1$ satisfy the required properties.\n\n   **Inductive step:** Assume that for all $k < n$ the sets $A_k,B_k$ have been constructed and satisfy the properties. Define $S_{n-1} = \\bigcup_{k<n}(A_k\\cup B_k)$. Each $A_k,B_k$ is compact and nowhere dense, so their finite union $S_{n-1}$ is also compact and nowhere dense. In particular, $S_{n-1}$ is closed and has empty interior. Consequently, $I_n \\setminus S_{n-1}$ is a nonempty open set (as the intersection of the open interval $I_n$ with the complement of the closed set $S_{n-1}$). Choose an open interval $J_n \\subseteq I_n \\setminus S_{n-1}$. Now, exactly as in the base step, pick two disjoint closed subintervals $J_n^a, J_n^b \\subset J_n$ and construct inside them fat Cantor sets $A_n$ and $B_n$ of positive measure. By construction, $A_n,B_n \\subseteq J_n \\subseteq I_n$, they are disjoint from each other, and because $J_n \\cap S_{n-1} = \\emptyset$, they are also disjoint from all previously constructed sets. This completes the induction.\n\n3. **Definition of $E$.** Set $E = \\bigcup_{n=1}^\\infty A_n$. Since each $A_n$ is measurable, $E$ is Lebesgue measurable.\n\n4. **Verification of the required property.**\n   - First, fix an index $n$. Because $A_n \\subseteq I_n$, we have $E \\cap I_n \\supseteq A_n$, so $m(E \\cap I_n) \\ge m(A_n) > 0$. Moreover, $B_n \\subseteq I_n$ and $B_n \\cap E = \\emptyset$ (by construction $B_n$ is disjoint from every $A_k$, hence from $E$). Therefore $B_n \\subseteq I_n \\setminus E$, implying $m(I_n \\setminus E) \\ge m(B_n) > 0$. Thus $0 < m(E \\cap I_n) < m(I_n)$ for every $n$.\n\n   - Now let $I$ be an arbitrary nonempty open interval. Since the family $\\{I_n\\}$ is a base, there exists some $n$ such that $I_n \\subseteq I$ (explicitly: choose rational numbers $a<b$ with $(a,b) \\subseteq I$; then $(a,b)$ is one of the $I_n$). Then\n     \\[\n     m(E \\cap I) \\ge m(E \\cap I_n) > 0 \\quad\\text{and}\\quad m(I \\setminus E) \\ge m(I_n \\setminus E) > 0,\n     \\]\n     which yields $0 < m(E \\cap I) < m(I)$.\n\n5. **Conclusion.** The set $E$ constructed above is Lebesgue measurable and satisfies $0 < m(E \\cap I) < m(I)$ for every nonempty open interval $I \\subseteq \\mathbb{R}$. \u220e",
            "evaluation": {
              "verdict": "fail",
              "ill_posed": false,
              "issues": [
                "The construction does not guarantee that m(E) is finite, which is required for the condition to hold for unbounded intervals (e.g., I = \u211d). The verification only addresses bounded intervals and does not show m(E\u2229I) < \u221e when m(I) = \u221e."
              ],
              "improvements": "Modify the construction to ensure total measure of E is finite, e.g., by choosing the fat Cantor sets A_n with measures such that \u03a3 m(A_n) < \u221e. This can be done by selecting J_n small enough and constructing A_n with measure at most 2^{-n}. Then for any unbounded I, m(E\u2229I) \u2264 m(E) < \u221e, and the condition 0 < m(E\u2229I) < m(I) holds."
            }
          },
          {
            "round": 2,
            "question": "Prove that there exists a Lebesgue measurable set $E \\subseteq \\mathbb{R}$ such that for every nonempty open interval $I \\subseteq \\mathbb{R}$, we have $0 < m(E \\cap I) < m(I)$, where $m$ denotes Lebesgue measure.",
            "answer": "We construct such a set explicitly.\n\n1. **Countable base.** Let $\\{I_n\\}_{n=1}^\\infty$ be an enumeration of all open intervals with rational endpoints. This family is countable and forms a base for the topology of $\\mathbb{R}$; in particular, every nonempty open interval contains some $I_n$.\n\n2. **Inductive construction.** We construct by induction two sequences $\\{A_n\\}_{n=1}^\\infty$ and $\\{B_n\\}_{n=1}^\\infty$ of subsets of $\\mathbb{R}$ with the following properties for each $n$:\n   - $A_n$ and $B_n$ are disjoint compact nowhere dense sets of positive Lebesgue measure.\n   - $A_n \\cup B_n \\subseteq I_n$.\n   - $A_n$ and $B_n$ are disjoint from all previously constructed sets:  \n     $A_n \\cap \\bigcup_{k<n}(A_k\\cup B_k)=\\emptyset$ and $B_n \\cap \\bigcup_{k<n}(A_k\\cup B_k)=\\emptyset$.\n   - Moreover, we will ensure that the measures of the $A_n$ are summable, so that $E = \\bigcup_{n=1}^\\infty A_n$ has finite total measure.\n\n   **Base step ($n=1$).** Since $I_1$ is open and nonempty, choose an open interval $J_1 \\subseteq I_1$ with length $\\ell_1 < 2^{-1}$. Inside $J_1$ pick two disjoint closed intervals $J_1^a, J_1^b$ each of length $\\ell_1/4$. In each of these closed intervals construct a *fat Cantor set* (Smith\u2013Volterra\u2013Cantor set) of measure exactly $\\ell_1/8$. (For example, start with the closed interval, remove the middle open interval of length $\\ell_1/8$, then from the two remaining intervals remove middle open intervals of length $\\ell_1/32$, and continue so that the total removed length is $\\ell_1/8$; the remaining set is compact, nowhere dense, and has measure $\\ell_1/8$.) Let $A_1$ be the fat Cantor set inside $J_1^a$ and $B_1$ the one inside $J_1^b$. Then $A_1,B_1$ satisfy the required properties.\n\n   **Inductive step.** Assume that for all $k < n$ the sets $A_k,B_k$ have been constructed. Define $S_{n-1} = \\bigcup_{k<n}(A_k\\cup B_k)$. Each $A_k,B_k$ is compact and nowhere dense, so $S_{n-1}$ (a finite union) is also compact and nowhere dense. Consequently, $I_n \\setminus S_{n-1}$ is a nonempty open set. Choose an open interval $J_n \\subseteq I_n \\setminus S_{n-1}$ with length $\\ell_n < 2^{-n}$. Inside $J_n$ pick two disjoint closed intervals $J_n^a, J_n^b$ each of length $\\ell_n/4$. As in the base step, construct inside $J_n^a$ a fat Cantor set $A_n$ of measure $\\ell_n/8$, and inside $J_n^b$ a fat Cantor set $B_n$ of measure $\\ell_n/8$. By construction, $A_n,B_n \\subseteq J_n \\subseteq I_n$, they are disjoint from each other, and because $J_n \\cap S_{n-1} = \\emptyset$, they are also disjoint from all previously constructed sets. This completes the induction.\n\n3. **Definition of $E$.** Set $E = \\bigcup_{n=1}^\\infty A_n$. Each $A_n$ is measurable, so $E$ is Lebesgue measurable. Moreover,\n   \\[\n   m(E) = \\sum_{n=1}^\\infty m(A_n) = \\sum_{n=1}^\\infty \\frac{\\ell_n}{8} \\le \\frac{1}{8}\\sum_{n=1}^\\infty 2^{-n} = \\frac{1}{8} < \\infty,\n   \\]\n   so $E$ has finite positive measure (since $m(A_1)>0$).\n\n4. **Verification of the required property.**\n   - First, fix $n$. Because $A_n \\subseteq I_n$, we have $m(E \\cap I_n) \\ge m(A_n) = \\ell_n/8 > 0$. Also $B_n \\subseteq I_n$ and $B_n \\cap E = \\emptyset$, so $m(I_n \\setminus E) \\ge m(B_n) = \\ell_n/8 > 0$. Since $I_n$ is bounded, $m(I_n)$ is finite, and therefore\n     \\[\n     m(E \\cap I_n) = m(I_n) - m(I_n \\setminus E) < m(I_n).\n     \\]\n     Hence $0 < m(E \\cap I_n) < m(I_n)$ for every $n$.\n\n   - Now let $I$ be an arbitrary nonempty open interval. Because $\\{I_n\\}$ is a base, there exists some $n$ such that $I_n \\subseteq I$. Then:\n     * **Positivity:** $m(E \\cap I) \\ge m(E \\cap I_n) > 0$.\n     * **Upper bound:**  \n       - If $I$ is bounded, then $m(I)$ is finite and $m(I \\setminus E) \\ge m(I_n \\setminus E) > 0$, so $m(E \\cap I) = m(I) - m(I \\setminus E) < m(I)$.  \n       - If $I$ is unbounded, then $m(I) = \\infty$, while $m(E \\cap I) \\le m(E) < \\infty$, so $m(E \\cap I) < \\infty = m(I)$.\n     In all cases we obtain $0 < m(E \\cap I) < m(I)$.\n\n5. **Conclusion.** The set $E$ constructed above is Lebesgue measurable and satisfies $0 < m(E \\cap I) < m(I)$ for every nonempty open interval $I \\subseteq \\mathbb{R}$. \u220e",
            "raw_answer": "We construct such a set explicitly.\n\n1. **Countable base.** Let $\\{I_n\\}_{n=1}^\\infty$ be an enumeration of all open intervals with rational endpoints. This family is countable and forms a base for the topology of $\\mathbb{R}$; in particular, every nonempty open interval contains some $I_n$.\n\n2. **Inductive construction.** We construct by induction two sequences $\\{A_n\\}_{n=1}^\\infty$ and $\\{B_n\\}_{n=1}^\\infty$ of subsets of $\\mathbb{R}$ with the following properties for each $n$:\n   - $A_n$ and $B_n$ are disjoint compact nowhere dense sets of positive Lebesgue measure.\n   - $A_n \\cup B_n \\subseteq I_n$.\n   - $A_n$ and $B_n$ are disjoint from all previously constructed sets:  \n     $A_n \\cap \\bigcup_{k<n}(A_k\\cup B_k)=\\emptyset$ and $B_n \\cap \\bigcup_{k<n}(A_k\\cup B_k)=\\emptyset$.\n   - Moreover, we will ensure that the measures of the $A_n$ are summable, so that $E = \\bigcup_{n=1}^\\infty A_n$ has finite total measure.\n\n   **Base step ($n=1$).** Since $I_1$ is open and nonempty, choose an open interval $J_1 \\subseteq I_1$ with length $\\ell_1 < 2^{-1}$. Inside $J_1$ pick two disjoint closed intervals $J_1^a, J_1^b$ each of length $\\ell_1/4$. In each of these closed intervals construct a *fat Cantor set* (Smith\u2013Volterra\u2013Cantor set) of measure exactly $\\ell_1/8$. (For example, start with the closed interval, remove the middle open interval of length $\\ell_1/8$, then from the two remaining intervals remove middle open intervals of length $\\ell_1/32$, and continue so that the total removed length is $\\ell_1/8$; the remaining set is compact, nowhere dense, and has measure $\\ell_1/8$.) Let $A_1$ be the fat Cantor set inside $J_1^a$ and $B_1$ the one inside $J_1^b$. Then $A_1,B_1$ satisfy the required properties.\n\n   **Inductive step.** Assume that for all $k < n$ the sets $A_k,B_k$ have been constructed. Define $S_{n-1} = \\bigcup_{k<n}(A_k\\cup B_k)$. Each $A_k,B_k$ is compact and nowhere dense, so $S_{n-1}$ (a finite union) is also compact and nowhere dense. Consequently, $I_n \\setminus S_{n-1}$ is a nonempty open set. Choose an open interval $J_n \\subseteq I_n \\setminus S_{n-1}$ with length $\\ell_n < 2^{-n}$. Inside $J_n$ pick two disjoint closed intervals $J_n^a, J_n^b$ each of length $\\ell_n/4$. As in the base step, construct inside $J_n^a$ a fat Cantor set $A_n$ of measure $\\ell_n/8$, and inside $J_n^b$ a fat Cantor set $B_n$ of measure $\\ell_n/8$. By construction, $A_n,B_n \\subseteq J_n \\subseteq I_n$, they are disjoint from each other, and because $J_n \\cap S_{n-1} = \\emptyset$, they are also disjoint from all previously constructed sets. This completes the induction.\n\n3. **Definition of $E$.** Set $E = \\bigcup_{n=1}^\\infty A_n$. Each $A_n$ is measurable, so $E$ is Lebesgue measurable. Moreover,\n   \\[\n   m(E) = \\sum_{n=1}^\\infty m(A_n) = \\sum_{n=1}^\\infty \\frac{\\ell_n}{8} \\le \\frac{1}{8}\\sum_{n=1}^\\infty 2^{-n} = \\frac{1}{8} < \\infty,\n   \\]\n   so $E$ has finite positive measure (since $m(A_1)>0$).\n\n4. **Verification of the required property.**\n   - First, fix $n$. Because $A_n \\subseteq I_n$, we have $m(E \\cap I_n) \\ge m(A_n) = \\ell_n/8 > 0$. Also $B_n \\subseteq I_n$ and $B_n \\cap E = \\emptyset$, so $m(I_n \\setminus E) \\ge m(B_n) = \\ell_n/8 > 0$. Since $I_n$ is bounded, $m(I_n)$ is finite, and therefore\n     \\[\n     m(E \\cap I_n) = m(I_n) - m(I_n \\setminus E) < m(I_n).\n     \\]\n     Hence $0 < m(E \\cap I_n) < m(I_n)$ for every $n$.\n\n   - Now let $I$ be an arbitrary nonempty open interval. Because $\\{I_n\\}$ is a base, there exists some $n$ such that $I_n \\subseteq I$. Then:\n     * **Positivity:** $m(E \\cap I) \\ge m(E \\cap I_n) > 0$.\n     * **Upper bound:**  \n       - If $I$ is bounded, then $m(I)$ is finite and $m(I \\setminus E) \\ge m(I_n \\setminus E) > 0$, so $m(E \\cap I) = m(I) - m(I \\setminus E) < m(I)$.  \n       - If $I$ is unbounded, then $m(I) = \\infty$, while $m(E \\cap I) \\le m(E) < \\infty$, so $m(E \\cap I) < \\infty = m(I)$.\n     In all cases we obtain $0 < m(E \\cap I) < m(I)$.\n\n5. **Conclusion.** The set $E$ constructed above is Lebesgue measurable and satisfies $0 < m(E \\cap I) < m(I)$ for every nonempty open interval $I \\subseteq \\mathbb{R}$. \u220e",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "18",
    "outer_attempt": 1,
    "topic_slug": "functions_of_a_complex_variable",
    "topic_name": "Functions of a complex variable",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Evaluate the improper integral\n$$\n\\int_{0}^{\\infty} \\frac{(\\ln x)^2}{x^2+1} \\, dx.\n$$\nProvide an exact value.",
            "answer": "We evaluate the integral using complex analysis.\n\nLet\n$$\nI = \\int_{0}^{\\infty} \\frac{(\\ln x)^2}{x^2+1} \\, dx.\n$$\n\n**Step 1: Substitution**  \nSet $x = e^t$, so $dx = e^t\\,dt$. When $x \\to 0^+$, $t \\to -\\infty$; when $x \\to \\infty$, $t \\to \\infty$. Then\n$$\nI = \\int_{-\\infty}^{\\infty} \\frac{t^2 e^t}{e^{2t}+1}\\,dt = \\int_{-\\infty}^{\\infty} \\frac{t^2}{e^t+e^{-t}}\\,dt = \\frac12 \\int_{-\\infty}^{\\infty} t^2 \\operatorname{sech} t \\, dt,\n$$\nbecause $\\operatorname{sech} t = \\dfrac{2}{e^t+e^{-t}}$. Denote\n$$\nJ = \\int_{-\\infty}^{\\infty} t^2 \\operatorname{sech} t \\, dt,\n$$\nso that $I = \\dfrac12 J$.\n\n**Step 2: Contour integral for $J$**  \nConsider the function\n$$\nf(z) = z^2 \\operatorname{sech} z = \\frac{z^2}{\\cosh z}.\n$$\n$\\cosh z$ has simple zeros at $z = i\\pi/2 + i\\pi k,\\; k\\in\\mathbb{Z}$, so $f$ has simple poles at these points.  \nWe use the rectangular contour $\\Gamma_R$ with vertices $-R$, $R$, $R+i\\pi$, $-R+i\\pi$, traversed counterclockwise.\n\nFor large $R$, the integrals on the vertical sides vanish. Indeed, on $z = R+iy$ ($0\\le y\\le\\pi$),\n$$\n|\\operatorname{sech}(R+iy)| = \\frac{2}{|e^{R+iy}+e^{-R-iy}|} \\le \\frac{2}{e^{R}-e^{-R}} \\to 0 \\quad\\text{as }R\\to\\infty,\n$$\nand $|z^2|$ grows only like $R^2$, so the integrand decays exponentially. The same holds on the left side $z = -R+iy$.\n\nThe only pole of $f$ inside $\\Gamma_R$ (for $R>0$) is $z = i\\pi/2$. Its residue is\n$$\n\\operatorname{Res}(f, i\\pi/2) = (i\\pi/2)^2 \\cdot \\operatorname{Res}(\\operatorname{sech} z, i\\pi/2).\n$$\nSince $\\cosh z$ has a simple zero, $\\operatorname{Res}(\\operatorname{sech} z, i\\pi/2) = \\dfrac{1}{\\sinh(i\\pi/2)} = \\frac{1}{i} = -i$. Thus\n$$\n\\operatorname{Res}(f, i\\pi/2) = \\left(-\\frac{\\pi^2}{4}\\right)(-i) = i\\,\\frac{\\pi^2}{4}.\n$$\nHence, by the residue theorem,\n$$\n\\oint_{\\Gamma_R} f(z)\\,dz = 2\\pi i \\cdot \\operatorname{Res}(f, i\\pi/2) = 2\\pi i \\cdot i\\,\\frac{\\pi^2}{4} = -\\frac{\\pi^3}{2}.\n$$\n\n**Step 3: Express the contour integral in terms of $J$**  \nWrite the contour integral as the sum of four parts:\n- Bottom: $\\int_{-R}^{R} t^2 \\operatorname{sech} t \\, dt$.\n- Top: parameterize as $z = t + i\\pi$, $t$ from $R$ to $-R$:\n  $$\n  \\int_{R}^{-R} (t+i\\pi)^2 \\operatorname{sech}(t+i\\pi)\\,dt = -\\int_{-R}^{R} (t+i\\pi)^2 \\operatorname{sech}(t+i\\pi)\\,dt.\n  $$\n- Right and left vertical sides, which vanish as $R\\to\\infty$.\n\nTaking $R\\to\\infty$ and using the vanishing of the vertical sides, we obtain\n$$\n\\oint_{\\Gamma_R} f(z)\\,dz \\;\\longrightarrow\\; \\int_{-\\infty}^{\\infty} t^2 \\operatorname{sech} t \\, dt \\;-\\; \\int_{-\\infty}^{\\infty} (t+i\\pi)^2 \\operatorname{sech}(t+i\\pi)\\,dt.\n$$\n\nNow use the identity $\\operatorname{sech}(t+i\\pi) = -\\operatorname{sech} t$ (because $\\cosh(t+i\\pi) = -\\cosh t$). Therefore the second integral becomes\n$$\n- \\int_{-\\infty}^{\\infty} (t+i\\pi)^2 (-\\operatorname{sech} t)\\,dt = \\int_{-\\infty}^{\\infty} (t+i\\pi)^2 \\operatorname{sech} t \\, dt.\n$$\nThus\n$$\n\\oint = \\int_{-\\infty}^{\\infty} \\bigl[ t^2 + (t+i\\pi)^2 \\bigr] \\operatorname{sech} t \\, dt.\n$$\n\nExpand $(t+i\\pi)^2 = t^2 + 2i\\pi t - \\pi^2$. Then\n$$\n\\oint = \\int_{-\\infty}^{\\infty} (2t^2 + 2i\\pi t - \\pi^2) \\operatorname{sech} t \\, dt.\n$$\n\nThe function $t \\operatorname{sech} t$ is odd, so its integral over $\\mathbb{R}$ vanishes. Hence\n$$\n\\oint = \\int_{-\\infty}^{\\infty} (2t^2 - \\pi^2) \\operatorname{sech} t \\, dt = 2J - \\pi^2 \\int_{-\\infty}^{\\infty} \\operatorname{sech} t \\, dt.\n$$\n\n**Step 4: Evaluate $K = \\int_{-\\infty}^{\\infty} \\operatorname{sech} t \\, dt$**  \nThis is a standard integral; we can compute it with the same rectangular contour. For $g(z)=\\operatorname{sech} z$,\n$$\n\\oint_{\\Gamma_R} g(z)\\,dz = 2\\pi i \\operatorname{Res}(g, i\\pi/2) = 2\\pi i (-i) = 2\\pi.\n$$\nDecomposing as before,\n$$\n\\oint = \\int_{-\\infty}^{\\infty} \\operatorname{sech} t \\, dt - \\int_{-\\infty}^{\\infty} \\operatorname{sech}(t+i\\pi)\\,dt = \\int_{-\\infty}^{\\infty} \\operatorname{sech} t \\, dt - \\int_{-\\infty}^{\\infty} (-\\operatorname{sech} t)\\,dt = 2K.\n$$\nThus $2K = 2\\pi$, so $K = \\pi$.\n\n**Step 5: Solve for $J$**  \nSubstituting $K = \\pi$ into the expression for $\\oint$ gives\n$$\n\\oint = 2J - \\pi^2 \\cdot \\pi = 2J - \\pi^3.\n$$\nBut we already found $\\oint = -\\dfrac{\\pi^3}{2}$. Therefore\n$$\n2J - \\pi^3 = -\\frac{\\pi^3}{2} \\quad\\Longrightarrow\\quad 2J = \\pi^3 - \\frac{\\pi^3}{2} = \\frac{\\pi^3}{2} \\quad\\Longrightarrow\\quad J = \\frac{\\pi^3}{4}.\n$$\n\n**Step 6: Obtain $I$**  \nFinally,\n$$\nI = \\frac12 J = \\frac12 \\cdot \\frac{\\pi^3}{4} = \\frac{\\pi^3}{8}.\n$$\n\n$$\n\\boxed{\\displaystyle \\int_{0}^{\\infty} \\frac{(\\ln x)^2}{x^2+1} \\, dx = \\frac{\\pi^3}{8}}\n$$",
            "raw_answer": "[QUESTION]\nEvaluate the improper integral\n\\[\n\\int_{0}^{\\infty} \\frac{(\\ln x)^2}{x^2+1} \\, dx.\n\\]\nProvide an exact value.\n\n[ANSWER]\nWe evaluate the integral using complex analysis.\n\nLet\n\\[\nI = \\int_{0}^{\\infty} \\frac{(\\ln x)^2}{x^2+1} \\, dx.\n\\]\n\n**Step 1: Substitution**  \nSet \\(x = e^t\\), so \\(dx = e^t\\,dt\\). When \\(x \\to 0^+\\), \\(t \\to -\\infty\\); when \\(x \\to \\infty\\), \\(t \\to \\infty\\). Then\n\\[\nI = \\int_{-\\infty}^{\\infty} \\frac{t^2 e^t}{e^{2t}+1}\\,dt = \\int_{-\\infty}^{\\infty} \\frac{t^2}{e^t+e^{-t}}\\,dt = \\frac12 \\int_{-\\infty}^{\\infty} t^2 \\operatorname{sech} t \\, dt,\n\\]\nbecause \\(\\operatorname{sech} t = \\dfrac{2}{e^t+e^{-t}}\\). Denote\n\\[\nJ = \\int_{-\\infty}^{\\infty} t^2 \\operatorname{sech} t \\, dt,\n\\]\nso that \\(I = \\dfrac12 J\\).\n\n**Step 2: Contour integral for \\(J\\)**  \nConsider the function\n\\[\nf(z) = z^2 \\operatorname{sech} z = \\frac{z^2}{\\cosh z}.\n\\]\n\\(\\cosh z\\) has simple zeros at \\(z = i\\pi/2 + i\\pi k,\\; k\\in\\mathbb{Z}\\), so \\(f\\) has simple poles at these points.  \nWe use the rectangular contour \\(\\Gamma_R\\) with vertices \\(-R\\), \\(R\\), \\(R+i\\pi\\), \\(-R+i\\pi\\), traversed counterclockwise.\n\nFor large \\(R\\), the integrals on the vertical sides vanish. Indeed, on \\(z = R+iy\\) (\\(0\\le y\\le\\pi\\)),\n\\[\n|\\operatorname{sech}(R+iy)| = \\frac{2}{|e^{R+iy}+e^{-R-iy}|} \\le \\frac{2}{e^{R}-e^{-R}} \\to 0 \\quad\\text{as }R\\to\\infty,\n\\]\nand \\(|z^2|\\) grows only like \\(R^2\\), so the integrand decays exponentially. The same holds on the left side \\(z = -R+iy\\).\n\nThe only pole of \\(f\\) inside \\(\\Gamma_R\\) (for \\(R>0\\)) is \\(z = i\\pi/2\\). Its residue is\n\\[\n\\operatorname{Res}(f, i\\pi/2) = (i\\pi/2)^2 \\cdot \\operatorname{Res}(\\operatorname{sech} z, i\\pi/2).\n\\]\nSince \\(\\cosh z\\) has a simple zero, \\(\\operatorname{Res}(\\operatorname{sech} z, i\\pi/2) = \\dfrac{1}{\\sinh(i\\pi/2)} = \\frac{1}{i} = -i\\). Thus\n\\[\n\\operatorname{Res}(f, i\\pi/2) = \\left(-\\frac{\\pi^2}{4}\\right)(-i) = i\\,\\frac{\\pi^2}{4}.\n\\]\nHence, by the residue theorem,\n\\[\n\\oint_{\\Gamma_R} f(z)\\,dz = 2\\pi i \\cdot \\operatorname{Res}(f, i\\pi/2) = 2\\pi i \\cdot i\\,\\frac{\\pi^2}{4} = -\\frac{\\pi^3}{2}.\n\\]\n\n**Step 3: Express the contour integral in terms of \\(J\\)**  \nWrite the contour integral as the sum of four parts:\n- Bottom: \\(\\int_{-R}^{R} t^2 \\operatorname{sech} t \\, dt\\).\n- Top: parameterize as \\(z = t + i\\pi\\), \\(t\\) from \\(R\\) to \\(-R\\):\n  \\[\n  \\int_{R}^{-R} (t+i\\pi)^2 \\operatorname{sech}(t+i\\pi)\\,dt = -\\int_{-R}^{R} (t+i\\pi)^2 \\operatorname{sech}(t+i\\pi)\\,dt.\n  \\]\n- Right and left vertical sides, which vanish as \\(R\\to\\infty\\).\n\nTaking \\(R\\to\\infty\\) and using the vanishing of the vertical sides, we obtain\n\\[\n\\oint_{\\Gamma_R} f(z)\\,dz \\;\\longrightarrow\\; \\int_{-\\infty}^{\\infty} t^2 \\operatorname{sech} t \\, dt \\;-\\; \\int_{-\\infty}^{\\infty} (t+i\\pi)^2 \\operatorname{sech}(t+i\\pi)\\,dt.\n\\]\n\nNow use the identity \\(\\operatorname{sech}(t+i\\pi) = -\\operatorname{sech} t\\) (because \\(\\cosh(t+i\\pi) = -\\cosh t\\)). Therefore the second integral becomes\n\\[\n- \\int_{-\\infty}^{\\infty} (t+i\\pi)^2 (-\\operatorname{sech} t)\\,dt = \\int_{-\\infty}^{\\infty} (t+i\\pi)^2 \\operatorname{sech} t \\, dt.\n\\]\nThus\n\\[\n\\oint = \\int_{-\\infty}^{\\infty} \\bigl[ t^2 + (t+i\\pi)^2 \\bigr] \\operatorname{sech} t \\, dt.\n\\]\n\nExpand \\((t+i\\pi)^2 = t^2 + 2i\\pi t - \\pi^2\\). Then\n\\[\n\\oint = \\int_{-\\infty}^{\\infty} (2t^2 + 2i\\pi t - \\pi^2) \\operatorname{sech} t \\, dt.\n\\]\n\nThe function \\(t \\operatorname{sech} t\\) is odd, so its integral over \\(\\mathbb{R}\\) vanishes. Hence\n\\[\n\\oint = \\int_{-\\infty}^{\\infty} (2t^2 - \\pi^2) \\operatorname{sech} t \\, dt = 2J - \\pi^2 \\int_{-\\infty}^{\\infty} \\operatorname{sech} t \\, dt.\n\\]\n\n**Step 4: Evaluate \\(K = \\int_{-\\infty}^{\\infty} \\operatorname{sech} t \\, dt\\)**  \nThis is a standard integral; we can compute it with the same rectangular contour. For \\(g(z)=\\operatorname{sech} z\\),\n\\[\n\\oint_{\\Gamma_R} g(z)\\,dz = 2\\pi i \\operatorname{Res}(g, i\\pi/2) = 2\\pi i (-i) = 2\\pi.\n\\]\nDecomposing as before,\n\\[\n\\oint = \\int_{-\\infty}^{\\infty} \\operatorname{sech} t \\, dt - \\int_{-\\infty}^{\\infty} \\operatorname{sech}(t+i\\pi)\\,dt = \\int_{-\\infty}^{\\infty} \\operatorname{sech} t \\, dt - \\int_{-\\infty}^{\\infty} (-\\operatorname{sech} t)\\,dt = 2K.\n\\]\nThus \\(2K = 2\\pi\\), so \\(K = \\pi\\).\n\n**Step 5: Solve for \\(J\\)**  \nSubstituting \\(K = \\pi\\) into the expression for \\(\\oint\\) gives\n\\[\n\\oint = 2J - \\pi^2 \\cdot \\pi = 2J - \\pi^3.\n\\]\nBut we already found \\(\\oint = -\\dfrac{\\pi^3}{2}\\). Therefore\n\\[\n2J - \\pi^3 = -\\frac{\\pi^3}{2} \\quad\\Longrightarrow\\quad 2J = \\pi^3 - \\frac{\\pi^3}{2} = \\frac{\\pi^3}{2} \\quad\\Longrightarrow\\quad J = \\frac{\\pi^3}{4}.\n\\]\n\n**Step 6: Obtain \\(I\\)**  \nFinally,\n\\[\nI = \\frac12 J = \\frac12 \\cdot \\frac{\\pi^3}{4} = \\frac{\\pi^3}{8}.\n\\]\n\n\\[\n\\boxed{\\displaystyle \\int_{0}^{\\infty} \\frac{(\\ln x)^2}{x^2+1} \\, dx = \\frac{\\pi^3}{8}}\n\\]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "19",
    "outer_attempt": 1,
    "topic_slug": "potential_theory",
    "topic_name": "Potential theory",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Consider the probability measure $\\mu$ on the interval $[-1,1]$ defined by\n$$\nd\\mu(x) = \\frac{1}{\\pi\\sqrt{1-x^2}}\\,dx.\n$$\nIts logarithmic potential is\n$$\nU_\\mu(z) = \\int_{-1}^{1} \\log\\frac{1}{|z-x|}\\,d\\mu(x),\\qquad z\\in\\mathbb{C},\n$$\nwhere $\\log$ denotes the natural logarithm. Show that for every $z\\in[-1,1]$ (i.e., $z$ is real with $-1\\le z\\le 1$), $U_\\mu(z)$ is constant (independent of $z$) and find the value of this constant.",
            "answer": "We prove that $U_\\mu(z)=\\log 2$ for all $z\\in[-1,1]$.\n\n**Step 1. Parametrization.**  \nFor $z\\in[-1,1]$ write $z=\\cos\\phi$ with $\\phi\\in[0,\\pi]$.  \nIn the integral, substitute $x=\\cos\\theta$, $\\theta\\in[0,\\pi]$. Then $dx=-\\sin\\theta\\,d\\theta$ and $\\sqrt{1-x^2}=\\sin\\theta$ (since $\\sin\\theta\\ge0$ on $[0,\\pi]$). Hence\n$$\nd\\mu(x)=\\frac{1}{\\pi\\sqrt{1-x^2}}\\,dx\n      =\\frac{1}{\\pi\\sin\\theta}\\,(-\\sin\\theta\\,d\\theta)\n      =-\\frac{1}{\\pi}\\,d\\theta.\n$$\nWhen $x$ runs from $-1$ to $1$, $\\theta$ runs from $\\pi$ to $0$, so changing the limits gives\n$$\nU_\\mu(z)=\\int_{-1}^{1}\\log\\frac{1}{|z-x|}\\,d\\mu(x)\n        =\\int_{\\theta=\\pi}^{0}\\log\\frac{1}{|\\cos\\phi-\\cos\\theta|}\\left(-\\frac{1}{\\pi}\\right)d\\theta\n        =\\frac{1}{\\pi}\\int_{0}^{\\pi}\\log\\frac{1}{|\\cos\\phi-\\cos\\theta|}\\,d\\theta.\n$$\nThus\n$$\nU_\\mu(z)=-\\frac{1}{\\pi}\\int_{0}^{\\pi}\\log|\\cos\\phi-\\cos\\theta|\\,d\\theta.\n\\tag{1}\n$$\n\n**Step 2. Trigonometric identity.**  \nUsing\n$$\n\\cos\\phi-\\cos\\theta = -2\\sin\\frac{\\phi+\\theta}{2}\\sin\\frac{\\phi-\\theta}{2},\n$$\nwe have\n$$\n|\\cos\\phi-\\cos\\theta| = 2\\left|\\sin\\frac{\\phi+\\theta}{2}\\right|\\,\n                         \\left|\\sin\\frac{\\phi-\\theta}{2}\\right|,\n$$\nand therefore\n$$\n\\log|\\cos\\phi-\\cos\\theta| = \\log 2 \n   + \\log\\left|\\sin\\frac{\\phi+\\theta}{2}\\right|\n   + \\log\\left|\\sin\\frac{\\phi-\\theta}{2}\\right|.\n\\tag{2}\n$$\n\n**Step 3. Split the integral.**  \nInsert (2) into the integral in (1):\n$$\nI(\\phi):=\\int_{0}^{\\pi}\\log|\\cos\\phi-\\cos\\theta|\\,d\\theta\n= \\pi\\log 2 + A + B,\n$$\nwhere\n$$\nA = \\int_{0}^{\\pi}\\log\\left|\\sin\\frac{\\phi+\\theta}{2}\\right|d\\theta,\\qquad\nB = \\int_{0}^{\\pi}\\log\\left|\\sin\\frac{\\phi-\\theta}{2}\\right|d\\theta.\n$$\n\n**Step 4. Change variables in $A$ and $B$.**  \n\n- For $A$, set $u=\\frac{\\phi+\\theta}{2}$. Then $d\\theta=2\\,du$, and the limits become $\\theta=0\\Rightarrow u=\\phi/2$, $\\theta=\\pi\\Rightarrow u=(\\pi+\\phi)/2$. Hence\n$$\nA = 2\\int_{\\phi/2}^{(\\pi+\\phi)/2} \\log|\\sin u|\\,du.\n$$\n\n- For $B$, set $v=\\frac{\\phi-\\theta}{2}$. Then $d\\theta=-2\\,dv$, and the limits: $\\theta=0\\Rightarrow v=\\phi/2$, $\\theta=\\pi\\Rightarrow v=(\\phi-\\pi)/2=-(\\pi-\\phi)/2$. Thus\n$$\nB = \\int_{\\phi/2}^{-(\\pi-\\phi)/2} \\log|\\sin v|\\,(-2\\,dv)\n   = 2\\int_{-(\\pi-\\phi)/2}^{\\phi/2} \\log|\\sin v|\\,dv.\n$$\n\n**Step 5. Combine the two integrals.**  \nNotice that the integration intervals for $A$ and $B$ are adjacent:\n$$\n[\\phi/2,\\,(\\pi+\\phi)/2] \\quad\\text{and}\\quad [-(\\pi-\\phi)/2,\\,\\phi/2].\n$$\nTheir union is the interval $[-(\\pi-\\phi)/2,\\,(\\pi+\\phi)/2]$, whose length is\n$$\n(\\pi+\\phi)/2 - (-(\\pi-\\phi)/2) = \\pi.\n$$\nThe function $f(u)=\\log|\\sin u|$ is $\\pi$-periodic because $|\\sin(u+\\pi)|=|\\sin u|$. Therefore the integral of $f$ over any interval of length $\\pi$ is the same. In particular,\n$$\n\\int_{-(\\pi-\\phi)/2}^{(\\pi+\\phi)/2} \\log|\\sin u|\\,du = \\int_{0}^{\\pi} \\log\\sin u\\,du,\n$$\nwhere we can drop the absolute value since $\\sin u\\ge0$ for $u\\in[0,\\pi]$. Consequently,\n$$\nA+B = 2\\int_{-(\\pi-\\phi)/2}^{(\\pi+\\phi)/2} \\log|\\sin u|\\,du\n     = 2\\int_{0}^{\\pi} \\log\\sin u\\,du.\n\\tag{3}\n$$\n\n**Step 6. Evaluate $\\displaystyle\\int_{0}^{\\pi}\\log\\sin u\\,du$.**  \nLet $J=\\int_{0}^{\\pi}\\log\\sin u\\,du$. A standard computation gives $J=-\\pi\\log2$. One short proof:\n$$\nJ &= 2\\int_{0}^{\\pi/2}\\log\\sin u\\,du \\quad\\text{(by symmetry)}\\\\\n  &= 2I,\\quad\\text{where } I=\\int_{0}^{\\pi/2}\\log\\sin u\\,du.\n$$\nUsing the substitution $u\\to\\frac{\\pi}{2}-u$, we also have $I=\\int_{0}^{\\pi/2}\\log\\cos u\\,du$. Then\n$$\n2I = \\int_{0}^{\\pi/2}(\\log\\sin u+\\log\\cos u)\\,du\n    = \\int_{0}^{\\pi/2}\\log\\left(\\frac{\\sin2u}{2}\\right)du\n    = \\int_{0}^{\\pi/2}\\log\\sin2u\\,du - \\int_{0}^{\\pi/2}\\log2\\,du.\n$$\nIn the first integral set $t=2u$, $dt=2du$:\n$$\n\\int_{0}^{\\pi/2}\\log\\sin2u\\,du = \\frac12\\int_{0}^{\\pi}\\log\\sin t\\,dt = \\frac12 J = I.\n$$\nThus $2I = I - \\frac{\\pi}{2}\\log2$, so $I = -\\frac{\\pi}{2}\\log2$ and $J = -\\pi\\log2$.\n\n**Step 7. Conclude $I(\\phi)$ is constant.**  \nFrom (3) and the value of $J$,\n$$\nA+B = 2J = -2\\pi\\log2.\n$$\nHence\n$$\nI(\\phi) = \\pi\\log2 + (-2\\pi\\log2) = -\\pi\\log2,\n$$\nwhich is independent of $\\phi$.\n\n**Step 8. Compute $U_\\mu(z)$.**  \nFinally, using (1),\n$$\nU_\\mu(z) = -\\frac{1}{\\pi} I(\\phi) = -\\frac{1}{\\pi}(-\\pi\\log2) = \\log2.\n$$\n\nThus for every $z\\in[-1,1]$, $U_\\mu(z)=\\log2$, a constant. \u220e",
            "raw_answer": "[QUESTION]\nConsider the probability measure $\\mu$ on the interval $[-1,1]$ defined by\n\\[\nd\\mu(x) = \\frac{1}{\\pi\\sqrt{1-x^2}}\\,dx.\n\\]\nIts logarithmic potential is\n\\[\nU_\\mu(z) = \\int_{-1}^{1} \\log\\frac{1}{|z-x|}\\,d\\mu(x),\\qquad z\\in\\mathbb{C},\n\\]\nwhere $\\log$ denotes the natural logarithm. Show that for every $z\\in[-1,1]$ (i.e., $z$ is real with $-1\\le z\\le 1$), $U_\\mu(z)$ is constant (independent of $z$) and find the value of this constant.\n\n[ANSWER]\nWe prove that $U_\\mu(z)=\\log 2$ for all $z\\in[-1,1]$.\n\n**Step 1. Parametrization.**  \nFor $z\\in[-1,1]$ write $z=\\cos\\phi$ with $\\phi\\in[0,\\pi]$.  \nIn the integral, substitute $x=\\cos\\theta$, $\\theta\\in[0,\\pi]$. Then $dx=-\\sin\\theta\\,d\\theta$ and $\\sqrt{1-x^2}=\\sin\\theta$ (since $\\sin\\theta\\ge0$ on $[0,\\pi]$). Hence\n\\[\nd\\mu(x)=\\frac{1}{\\pi\\sqrt{1-x^2}}\\,dx\n      =\\frac{1}{\\pi\\sin\\theta}\\,(-\\sin\\theta\\,d\\theta)\n      =-\\frac{1}{\\pi}\\,d\\theta.\n\\]\nWhen $x$ runs from $-1$ to $1$, $\\theta$ runs from $\\pi$ to $0$, so changing the limits gives\n\\[\nU_\\mu(z)=\\int_{-1}^{1}\\log\\frac{1}{|z-x|}\\,d\\mu(x)\n        =\\int_{\\theta=\\pi}^{0}\\log\\frac{1}{|\\cos\\phi-\\cos\\theta|}\\left(-\\frac{1}{\\pi}\\right)d\\theta\n        =\\frac{1}{\\pi}\\int_{0}^{\\pi}\\log\\frac{1}{|\\cos\\phi-\\cos\\theta|}\\,d\\theta.\n\\]\nThus\n\\[\nU_\\mu(z)=-\\frac{1}{\\pi}\\int_{0}^{\\pi}\\log|\\cos\\phi-\\cos\\theta|\\,d\\theta.\n\\tag{1}\n\\]\n\n**Step 2. Trigonometric identity.**  \nUsing\n\\[\n\\cos\\phi-\\cos\\theta = -2\\sin\\frac{\\phi+\\theta}{2}\\sin\\frac{\\phi-\\theta}{2},\n\\]\nwe have\n\\[\n|\\cos\\phi-\\cos\\theta| = 2\\left|\\sin\\frac{\\phi+\\theta}{2}\\right|\\,\n                         \\left|\\sin\\frac{\\phi-\\theta}{2}\\right|,\n\\]\nand therefore\n\\[\n\\log|\\cos\\phi-\\cos\\theta| = \\log 2 \n   + \\log\\left|\\sin\\frac{\\phi+\\theta}{2}\\right|\n   + \\log\\left|\\sin\\frac{\\phi-\\theta}{2}\\right|.\n\\tag{2}\n\\]\n\n**Step 3. Split the integral.**  \nInsert (2) into the integral in (1):\n\\[\nI(\\phi):=\\int_{0}^{\\pi}\\log|\\cos\\phi-\\cos\\theta|\\,d\\theta\n= \\pi\\log 2 + A + B,\n\\]\nwhere\n\\[\nA = \\int_{0}^{\\pi}\\log\\left|\\sin\\frac{\\phi+\\theta}{2}\\right|d\\theta,\\qquad\nB = \\int_{0}^{\\pi}\\log\\left|\\sin\\frac{\\phi-\\theta}{2}\\right|d\\theta.\n\\]\n\n**Step 4. Change variables in $A$ and $B$.**  \n\n- For $A$, set $u=\\frac{\\phi+\\theta}{2}$. Then $d\\theta=2\\,du$, and the limits become $\\theta=0\\Rightarrow u=\\phi/2$, $\\theta=\\pi\\Rightarrow u=(\\pi+\\phi)/2$. Hence\n\\[\nA = 2\\int_{\\phi/2}^{(\\pi+\\phi)/2} \\log|\\sin u|\\,du.\n\\]\n\n- For $B$, set $v=\\frac{\\phi-\\theta}{2}$. Then $d\\theta=-2\\,dv$, and the limits: $\\theta=0\\Rightarrow v=\\phi/2$, $\\theta=\\pi\\Rightarrow v=(\\phi-\\pi)/2=-(\\pi-\\phi)/2$. Thus\n\\[\nB = \\int_{\\phi/2}^{-(\\pi-\\phi)/2} \\log|\\sin v|\\,(-2\\,dv)\n   = 2\\int_{-(\\pi-\\phi)/2}^{\\phi/2} \\log|\\sin v|\\,dv.\n\\]\n\n**Step 5. Combine the two integrals.**  \nNotice that the integration intervals for $A$ and $B$ are adjacent:\n\\[\n[\\phi/2,\\,(\\pi+\\phi)/2] \\quad\\text{and}\\quad [-(\\pi-\\phi)/2,\\,\\phi/2].\n\\]\nTheir union is the interval $[-(\\pi-\\phi)/2,\\,(\\pi+\\phi)/2]$, whose length is\n\\[\n(\\pi+\\phi)/2 - (-(\\pi-\\phi)/2) = \\pi.\n\\]\nThe function $f(u)=\\log|\\sin u|$ is $\\pi$-periodic because $|\\sin(u+\\pi)|=|\\sin u|$. Therefore the integral of $f$ over any interval of length $\\pi$ is the same. In particular,\n\\[\n\\int_{-(\\pi-\\phi)/2}^{(\\pi+\\phi)/2} \\log|\\sin u|\\,du = \\int_{0}^{\\pi} \\log\\sin u\\,du,\n\\]\nwhere we can drop the absolute value since $\\sin u\\ge0$ for $u\\in[0,\\pi]$. Consequently,\n\\[\nA+B = 2\\int_{-(\\pi-\\phi)/2}^{(\\pi+\\phi)/2} \\log|\\sin u|\\,du\n     = 2\\int_{0}^{\\pi} \\log\\sin u\\,du.\n\\tag{3}\n\\]\n\n**Step 6. Evaluate $\\displaystyle\\int_{0}^{\\pi}\\log\\sin u\\,du$.**  \nLet $J=\\int_{0}^{\\pi}\\log\\sin u\\,du$. A standard computation gives $J=-\\pi\\log2$. One short proof:\n\\begin{align*}\nJ &= 2\\int_{0}^{\\pi/2}\\log\\sin u\\,du \\quad\\text{(by symmetry)}\\\\\n  &= 2I,\\quad\\text{where } I=\\int_{0}^{\\pi/2}\\log\\sin u\\,du.\n\\end{align*}\nUsing the substitution $u\\to\\frac{\\pi}{2}-u$, we also have $I=\\int_{0}^{\\pi/2}\\log\\cos u\\,du$. Then\n\\[\n2I = \\int_{0}^{\\pi/2}(\\log\\sin u+\\log\\cos u)\\,du\n    = \\int_{0}^{\\pi/2}\\log\\left(\\frac{\\sin2u}{2}\\right)du\n    = \\int_{0}^{\\pi/2}\\log\\sin2u\\,du - \\int_{0}^{\\pi/2}\\log2\\,du.\n\\]\nIn the first integral set $t=2u$, $dt=2du$:\n\\[\n\\int_{0}^{\\pi/2}\\log\\sin2u\\,du = \\frac12\\int_{0}^{\\pi}\\log\\sin t\\,dt = \\frac12 J = I.\n\\]\nThus $2I = I - \\frac{\\pi}{2}\\log2$, so $I = -\\frac{\\pi}{2}\\log2$ and $J = -\\pi\\log2$.\n\n**Step 7. Conclude $I(\\phi)$ is constant.**  \nFrom (3) and the value of $J$,\n\\[\nA+B = 2J = -2\\pi\\log2.\n\\]\nHence\n\\[\nI(\\phi) = \\pi\\log2 + (-2\\pi\\log2) = -\\pi\\log2,\n\\]\nwhich is independent of $\\phi$.\n\n**Step 8. Compute $U_\\mu(z)$.**  \nFinally, using (1),\n\\[\nU_\\mu(z) = -\\frac{1}{\\pi} I(\\phi) = -\\frac{1}{\\pi}(-\\pi\\log2) = \\log2.\n\\]\n\nThus for every $z\\in[-1,1]$, $U_\\mu(z)=\\log2$, a constant. \u220e",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "20",
    "outer_attempt": 1,
    "topic_slug": "several_complex_variables_and_analytic_spaces",
    "topic_name": "Several complex variables and analytic spaces",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $B = \\{ z \\in \\mathbb{C}^n \\mid \\|z\\| < 1 \\}$ be the unit ball in $\\mathbb{C}^n$ ($n \\ge 1$), where $\\|z\\|^2 = \\sum_{i=1}^n |z_i|^2$. Suppose $f: B \\to B$ is a biholomorphism (i.e., $f$ is holomorphic, bijective, and its inverse $f^{-1}$ is also holomorphic) such that $f(0) = 0$. Prove that $f$ is a linear unitary transformation; that is, there exists an $n \\times n$ unitary matrix $U$ such that $f(z) = U z$ for all $z \\in B$.",
            "answer": "**Solution.**\n\n1. **Schwarz lemma for the unit ball.**  \n   *Lemma.* If $g: B \\to B$ is holomorphic and $g(0)=0$, then $\\|g(z)\\| \\le \\|z\\|$ for all $z \\in B$.  \n   *Proof.* For $z=0$ the inequality is trivial. For $z \\neq 0$, define $\\varphi: \\mathbb{D} \\to B$ by $\\varphi(\\lambda) = g(\\lambda z / \\|z\\|)$. Since $g(0)=0$, we have $\\varphi(0)=0$. Consider the holomorphic map  \n   $$\n   \\psi(\\lambda) = \\frac{\\varphi(\\lambda)}{\\lambda}\\quad (\\lambda \\neq 0),\\qquad \\psi(0) = \\varphi'(0) = Dg(0)\\Bigl(\\frac{z}{\\|z\\|}\\Bigr).\n   $$\n   Then $\\psi$ is holomorphic on $\\mathbb{D}$. For any $r \\in (0,1)$ and $|\\lambda| = r$,  \n   $$\n   \\|\\psi(\\lambda)\\| = \\frac{\\|\\varphi(\\lambda)\\|}{|\\lambda|} \\le \\frac{1}{r},\n   $$\n   because $\\|\\varphi(\\lambda)\\| < 1$. By the maximum principle, $\\|\\psi(\\lambda)\\| \\le 1/r$ for all $|\\lambda| \\le r$. Letting $r \\to 1^-$ we obtain $\\|\\psi(\\lambda)\\| \\le 1$ for all $|\\lambda| \\le 1$. In particular, for $\\lambda = \\|z\\|$ (note $|\\|z\\|| = \\|z\\| < 1$),  \n   $$\n   \\|\\psi(\\|z\\|)\\| = \\frac{\\|g(z)\\|}{\\|z\\|} \\le 1,\n   $$\n   hence $\\|g(z)\\| \\le \\|z\\|$. $\\square$\n\n2. **Applying the lemma to $f$ and its inverse.**  \n   Because $f$ is a biholomorphism of $B$ onto itself with $f(0)=0$, the inverse map $f^{-1}: B \\to B$ is also holomorphic and satisfies $f^{-1}(0)=0$. By the lemma,\n   $$\n   \\|f(z)\\| \\le \\|z\\| \\quad \\text{and} \\quad \\|f^{-1}(w)\\| \\le \\|w\\| \\qquad \\text{for all } z,w \\in B.\n   $$\n   For any $z \\in B$, set $w = f(z)$. Then\n   $$\n   \\|z\\| = \\|f^{-1}(w)\\| \\le \\|w\\| = \\|f(z)\\|.\n   $$\n   Together with $\\|f(z)\\| \\le \\|z\\|$ this yields $\\|f(z)\\| = \\|z\\|$ for every $z \\in B$.\n\n3. **Consequences of the equality $\\|f(z)\\| = \\|z\\|$.**  \n   We now prove that any holomorphic map $h: B \\to B$ with $h(0)=0$ satisfying $\\|h(z)\\| = \\|z\\|$ for all $z \\in B$ must be a linear unitary transformation.\n\n   Expand $h$ in a Taylor series about the origin:\n   $$\n   h(z) = \\sum_{k=1}^{\\infty} P_k(z),\n   $$\n   where each $P_k$ is a homogeneous polynomial of degree $k$ (i.e., $P_k(tz) = t^k P_k(z)$ for all $t \\in \\mathbb{C}$). The series converges absolutely on compact subsets of $B$.\n\n   Fix an arbitrary $z \\in \\mathbb{C}^n$ with $\\|z\\|$ small enough so that $z \\in B$. For a complex parameter $t$ with $|t|$ sufficiently small, we have $t z \\in B$. Using homogeneity,\n   $$\n   h(tz) = \\sum_{k=1}^{\\infty} P_k(z) \\, t^k.\n   $$\n   The condition $\\|h(tz)\\| = \\|tz\\|$ becomes\n   $$\n   \\Bigl\\| \\sum_{k=1}^{\\infty} P_k(z) t^k \\Bigr\\| = |t| \\, \\|z\\|.\n   $$\n   Squaring both sides gives\n   $$\n   \\sum_{k,l \\ge 1} \\langle P_k(z), P_l(z) \\rangle \\, t^k \\overline{t}^l = \\|z\\|^2 \\, |t|^2 = \\|z\\|^2 \\, t \\overline{t}.\n   $$\n   This identity holds for all $t$ in a neighbourhood of $0$. Interpreting the left\u2011hand side as a power series in $t$ and $\\overline{t}$, we compare coefficients. The right\u2011hand side contains only the monomial $t \\overline{t}$. Therefore, for every pair $(k,l) \\neq (1,1)$ we must have\n   $$\n   \\langle P_k(z), P_l(z) \\rangle = 0 \\qquad \\text{for all } z.\n   $$\n   In particular, taking $l = k \\ge 2$ yields $\\|P_k(z)\\|^2 = 0$ for all $z$, hence $P_k \\equiv 0$ for all $k \\ge 2$. Consequently,\n   $$\n   h(z) = P_1(z),\n   $$\n   i.e., $h$ is linear. The condition $\\|h(z)\\| = \\|z\\|$ for all $z$ now implies that $h$ preserves the Hermitian norm; thus its matrix $U$ satisfies $U^* U = I$, so $U$ is unitary.\n\n4. **Conclusion.**  \n   Applying this result to $f$ shows that $f$ is a linear unitary transformation. $\\square$",
            "raw_answer": "[QUESTION]\nLet \\(B = \\{ z \\in \\mathbb{C}^n \\mid \\|z\\| < 1 \\}\\) be the unit ball in \\(\\mathbb{C}^n\\) (\\(n \\ge 1\\)), where \\(\\|z\\|^2 = \\sum_{i=1}^n |z_i|^2\\). Suppose \\(f: B \\to B\\) is a biholomorphism (i.e., \\(f\\) is holomorphic, bijective, and its inverse \\(f^{-1}\\) is also holomorphic) such that \\(f(0) = 0\\). Prove that \\(f\\) is a linear unitary transformation; that is, there exists an \\(n \\times n\\) unitary matrix \\(U\\) such that \\(f(z) = U z\\) for all \\(z \\in B\\).\n\n[ANSWER]\n**Solution.**\n\n1. **Schwarz lemma for the unit ball.**  \n   *Lemma.* If \\(g: B \\to B\\) is holomorphic and \\(g(0)=0\\), then \\(\\|g(z)\\| \\le \\|z\\|\\) for all \\(z \\in B\\).  \n   *Proof.* For \\(z=0\\) the inequality is trivial. For \\(z \\neq 0\\), define \\(\\varphi: \\mathbb{D} \\to B\\) by \\(\\varphi(\\lambda) = g(\\lambda z / \\|z\\|)\\). Since \\(g(0)=0\\), we have \\(\\varphi(0)=0\\). Consider the holomorphic map  \n   \\[\n   \\psi(\\lambda) = \\frac{\\varphi(\\lambda)}{\\lambda}\\quad (\\lambda \\neq 0),\\qquad \\psi(0) = \\varphi'(0) = Dg(0)\\Bigl(\\frac{z}{\\|z\\|}\\Bigr).\n   \\]\n   Then \\(\\psi\\) is holomorphic on \\(\\mathbb{D}\\). For any \\(r \\in (0,1)\\) and \\(|\\lambda| = r\\),  \n   \\[\n   \\|\\psi(\\lambda)\\| = \\frac{\\|\\varphi(\\lambda)\\|}{|\\lambda|} \\le \\frac{1}{r},\n   \\]\n   because \\(\\|\\varphi(\\lambda)\\| < 1\\). By the maximum principle, \\(\\|\\psi(\\lambda)\\| \\le 1/r\\) for all \\(|\\lambda| \\le r\\). Letting \\(r \\to 1^-\\) we obtain \\(\\|\\psi(\\lambda)\\| \\le 1\\) for all \\(|\\lambda| \\le 1\\). In particular, for \\(\\lambda = \\|z\\|\\) (note \\(|\\|z\\|| = \\|z\\| < 1\\)),  \n   \\[\n   \\|\\psi(\\|z\\|)\\| = \\frac{\\|g(z)\\|}{\\|z\\|} \\le 1,\n   \\]\n   hence \\(\\|g(z)\\| \\le \\|z\\|\\). \\(\\square\\)\n\n2. **Applying the lemma to \\(f\\) and its inverse.**  \n   Because \\(f\\) is a biholomorphism of \\(B\\) onto itself with \\(f(0)=0\\), the inverse map \\(f^{-1}: B \\to B\\) is also holomorphic and satisfies \\(f^{-1}(0)=0\\). By the lemma,\n   \\[\n   \\|f(z)\\| \\le \\|z\\| \\quad \\text{and} \\quad \\|f^{-1}(w)\\| \\le \\|w\\| \\qquad \\text{for all } z,w \\in B.\n   \\]\n   For any \\(z \\in B\\), set \\(w = f(z)\\). Then\n   \\[\n   \\|z\\| = \\|f^{-1}(w)\\| \\le \\|w\\| = \\|f(z)\\|.\n   \\]\n   Together with \\(\\|f(z)\\| \\le \\|z\\|\\) this yields \\(\\|f(z)\\| = \\|z\\|\\) for every \\(z \\in B\\).\n\n3. **Consequences of the equality \\(\\|f(z)\\| = \\|z\\|\\).**  \n   We now prove that any holomorphic map \\(h: B \\to B\\) with \\(h(0)=0\\) satisfying \\(\\|h(z)\\| = \\|z\\|\\) for all \\(z \\in B\\) must be a linear unitary transformation.\n\n   Expand \\(h\\) in a Taylor series about the origin:\n   \\[\n   h(z) = \\sum_{k=1}^{\\infty} P_k(z),\n   \\]\n   where each \\(P_k\\) is a homogeneous polynomial of degree \\(k\\) (i.e., \\(P_k(tz) = t^k P_k(z)\\) for all \\(t \\in \\mathbb{C}\\)). The series converges absolutely on compact subsets of \\(B\\).\n\n   Fix an arbitrary \\(z \\in \\mathbb{C}^n\\) with \\(\\|z\\|\\) small enough so that \\(z \\in B\\). For a complex parameter \\(t\\) with \\(|t|\\) sufficiently small, we have \\(t z \\in B\\). Using homogeneity,\n   \\[\n   h(tz) = \\sum_{k=1}^{\\infty} P_k(z) \\, t^k.\n   \\]\n   The condition \\(\\|h(tz)\\| = \\|tz\\|\\) becomes\n   \\[\n   \\Bigl\\| \\sum_{k=1}^{\\infty} P_k(z) t^k \\Bigr\\| = |t| \\, \\|z\\|.\n   \\]\n   Squaring both sides gives\n   \\[\n   \\sum_{k,l \\ge 1} \\langle P_k(z), P_l(z) \\rangle \\, t^k \\overline{t}^l = \\|z\\|^2 \\, |t|^2 = \\|z\\|^2 \\, t \\overline{t}.\n   \\]\n   This identity holds for all \\(t\\) in a neighbourhood of \\(0\\). Interpreting the left\u2011hand side as a power series in \\(t\\) and \\(\\overline{t}\\), we compare coefficients. The right\u2011hand side contains only the monomial \\(t \\overline{t}\\). Therefore, for every pair \\((k,l) \\neq (1,1)\\) we must have\n   \\[\n   \\langle P_k(z), P_l(z) \\rangle = 0 \\qquad \\text{for all } z.\n   \\]\n   In particular, taking \\(l = k \\ge 2\\) yields \\(\\|P_k(z)\\|^2 = 0\\) for all \\(z\\), hence \\(P_k \\equiv 0\\) for all \\(k \\ge 2\\). Consequently,\n   \\[\n   h(z) = P_1(z),\n   \\]\n   i.e., \\(h\\) is linear. The condition \\(\\|h(z)\\| = \\|z\\|\\) for all \\(z\\) now implies that \\(h\\) preserves the Hermitian norm; thus its matrix \\(U\\) satisfies \\(U^* U = I\\), so \\(U\\) is unitary.\n\n4. **Conclusion.**  \n   Applying this result to \\(f\\) shows that \\(f\\) is a linear unitary transformation. \\(\\square\\)",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "21",
    "outer_attempt": 1,
    "topic_slug": "special_functions",
    "topic_name": "Special functions",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Evaluate the definite integral\n$$\n\\int_0^1 \\ln \\Gamma(x) \\, dx,\n$$\nwhere $\\Gamma$ denotes the Euler gamma function. Give the exact value.",
            "answer": "We will evaluate $I = \\int_0^1 \\ln \\Gamma(x) \\, dx$.\n\nFirst, note that the integral converges because near $x=0$, $\\Gamma(x) \\sim 1/x$, so $\\ln \\Gamma(x) \\sim -\\ln x$, which is integrable on $[0,1]$.\n\nUsing the substitution $x \\mapsto 1-x$, we have\n$$\nI = \\int_0^1 \\ln \\Gamma(1-x) \\, dx.\n$$\nAdding this to the original expression gives\n$$\n2I = \\int_0^1 \\bigl[ \\ln \\Gamma(x) + \\ln \\Gamma(1-x) \\bigr] \\, dx = \\int_0^1 \\ln \\bigl( \\Gamma(x) \\Gamma(1-x) \\bigr) \\, dx.\n$$\n\nBy the reflection formula for the gamma function,\n$$\n\\Gamma(x) \\Gamma(1-x) = \\frac{\\pi}{\\sin(\\pi x)}, \\qquad 0 < x < 1.\n$$\nThus,\n$$\n2I = \\int_0^1 \\ln \\left( \\frac{\\pi}{\\sin(\\pi x)} \\right) dx = \\int_0^1 \\bigl( \\ln \\pi - \\ln \\sin(\\pi x) \\bigr) dx = \\ln \\pi - \\int_0^1 \\ln \\sin(\\pi x) \\, dx.\n$$\n\nLet $J = \\int_0^1 \\ln \\sin(\\pi x) \\, dx$. Substitute $u = \\pi x$, $du = \\pi dx$:\n$$\nJ = \\frac{1}{\\pi} \\int_0^\\pi \\ln \\sin u \\, du.\n$$\n\nNow evaluate $K = \\int_0^\\pi \\ln \\sin u \\, du$. We compute $K$ using symmetry:\n$$\nK = \\int_0^\\pi \\ln \\sin u \\, du = 2 \\int_0^{\\pi/2} \\ln \\sin u \\, du.\n$$\nSet $L = \\int_0^{\\pi/2} \\ln \\sin u \\, du$. Note that also $L = \\int_0^{\\pi/2} \\ln \\cos u \\, du$ (by substituting $u \\mapsto \\frac{\\pi}{2} - u$). Hence\n$$\n2L = \\int_0^{\\pi/2} (\\ln \\sin u + \\ln \\cos u) \\, du = \\int_0^{\\pi/2} \\ln (\\sin u \\cos u) \\, du = \\int_0^{\\pi/2} \\ln \\left( \\frac{1}{2} \\sin 2u \\right) du.\n$$\nThis splits as\n$$\n\\int_0^{\\pi/2} \\ln \\frac{1}{2} \\, du + \\int_0^{\\pi/2} \\ln \\sin 2u \\, du = \\frac{\\pi}{2} \\ln \\frac{1}{2} + \\int_0^{\\pi/2} \\ln \\sin 2u \\, du.\n$$\nIn the last integral, set $v = 2u$, $dv = 2 du$, so\n$$\n\\int_0^{\\pi/2} \\ln \\sin 2u \\, du = \\frac{1}{2} \\int_0^\\pi \\ln \\sin v \\, dv = \\frac{1}{2} K.\n$$\nBut $K = 2L$, so $\\frac{1}{2} K = L$. Substituting back,\n$$\n2L = \\frac{\\pi}{2} \\ln \\frac{1}{2} + L \\quad \\Longrightarrow \\quad L = \\frac{\\pi}{2} \\ln \\frac{1}{2} = -\\frac{\\pi}{2} \\ln 2.\n$$\nTherefore,\n$$\nK = 2L = -\\pi \\ln 2.\n$$\n\nThus,\n$$\nJ = \\frac{1}{\\pi} (-\\pi \\ln 2) = -\\ln 2.\n$$\n\nReturning to the expression for $2I$:\n$$\n2I = \\ln \\pi - (-\\ln 2) = \\ln \\pi + \\ln 2 = \\ln(2\\pi).\n$$\nHence,\n$$\nI = \\frac{1}{2} \\ln(2\\pi).\n$$\n\nTherefore,\n$$\n\\boxed{\\frac{1}{2}\\ln(2\\pi)}.\n$$",
            "raw_answer": "[QUESTION]\nEvaluate the definite integral\n\\[\n\\int_0^1 \\ln \\Gamma(x) \\, dx,\n\\]\nwhere $\\Gamma$ denotes the Euler gamma function. Give the exact value.\n\n[ANSWER]\nWe will evaluate \\( I = \\int_0^1 \\ln \\Gamma(x) \\, dx \\).\n\nFirst, note that the integral converges because near \\(x=0\\), \\(\\Gamma(x) \\sim 1/x\\), so \\(\\ln \\Gamma(x) \\sim -\\ln x\\), which is integrable on \\([0,1]\\).\n\nUsing the substitution \\(x \\mapsto 1-x\\), we have\n\\[\nI = \\int_0^1 \\ln \\Gamma(1-x) \\, dx.\n\\]\nAdding this to the original expression gives\n\\[\n2I = \\int_0^1 \\bigl[ \\ln \\Gamma(x) + \\ln \\Gamma(1-x) \\bigr] \\, dx = \\int_0^1 \\ln \\bigl( \\Gamma(x) \\Gamma(1-x) \\bigr) \\, dx.\n\\]\n\nBy the reflection formula for the gamma function,\n\\[\n\\Gamma(x) \\Gamma(1-x) = \\frac{\\pi}{\\sin(\\pi x)}, \\qquad 0 < x < 1.\n\\]\nThus,\n\\[\n2I = \\int_0^1 \\ln \\left( \\frac{\\pi}{\\sin(\\pi x)} \\right) dx = \\int_0^1 \\bigl( \\ln \\pi - \\ln \\sin(\\pi x) \\bigr) dx = \\ln \\pi - \\int_0^1 \\ln \\sin(\\pi x) \\, dx.\n\\]\n\nLet \\( J = \\int_0^1 \\ln \\sin(\\pi x) \\, dx \\). Substitute \\( u = \\pi x \\), \\( du = \\pi dx \\):\n\\[\nJ = \\frac{1}{\\pi} \\int_0^\\pi \\ln \\sin u \\, du.\n\\]\n\nNow evaluate \\( K = \\int_0^\\pi \\ln \\sin u \\, du \\). We compute \\( K \\) using symmetry:\n\\[\nK = \\int_0^\\pi \\ln \\sin u \\, du = 2 \\int_0^{\\pi/2} \\ln \\sin u \\, du.\n\\]\nSet \\( L = \\int_0^{\\pi/2} \\ln \\sin u \\, du \\). Note that also \\( L = \\int_0^{\\pi/2} \\ln \\cos u \\, du \\) (by substituting \\( u \\mapsto \\frac{\\pi}{2} - u \\)). Hence\n\\[\n2L = \\int_0^{\\pi/2} (\\ln \\sin u + \\ln \\cos u) \\, du = \\int_0^{\\pi/2} \\ln (\\sin u \\cos u) \\, du = \\int_0^{\\pi/2} \\ln \\left( \\frac{1}{2} \\sin 2u \\right) du.\n\\]\nThis splits as\n\\[\n\\int_0^{\\pi/2} \\ln \\frac{1}{2} \\, du + \\int_0^{\\pi/2} \\ln \\sin 2u \\, du = \\frac{\\pi}{2} \\ln \\frac{1}{2} + \\int_0^{\\pi/2} \\ln \\sin 2u \\, du.\n\\]\nIn the last integral, set \\( v = 2u \\), \\( dv = 2 du \\), so\n\\[\n\\int_0^{\\pi/2} \\ln \\sin 2u \\, du = \\frac{1}{2} \\int_0^\\pi \\ln \\sin v \\, dv = \\frac{1}{2} K.\n\\]\nBut \\( K = 2L \\), so \\( \\frac{1}{2} K = L \\). Substituting back,\n\\[\n2L = \\frac{\\pi}{2} \\ln \\frac{1}{2} + L \\quad \\Longrightarrow \\quad L = \\frac{\\pi}{2} \\ln \\frac{1}{2} = -\\frac{\\pi}{2} \\ln 2.\n\\]\nTherefore,\n\\[\nK = 2L = -\\pi \\ln 2.\n\\]\n\nThus,\n\\[\nJ = \\frac{1}{\\pi} (-\\pi \\ln 2) = -\\ln 2.\n\\]\n\nReturning to the expression for \\( 2I \\):\n\\[\n2I = \\ln \\pi - (-\\ln 2) = \\ln \\pi + \\ln 2 = \\ln(2\\pi).\n\\]\nHence,\n\\[\nI = \\frac{1}{2} \\ln(2\\pi).\n\\]\n\nTherefore,\n\\[\n\\boxed{\\frac{1}{2}\\ln(2\\pi)}.\n\\]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "22",
    "outer_attempt": 1,
    "topic_slug": "ordinary_differential_equations",
    "topic_name": "Ordinary differential equations",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Find the general solution of the differential equation\n$$ (x^2 + y^2 + x)\\,dx + y\\,dy = 0. $$",
            "answer": "We solve by finding an integrating factor that depends on $r = x^2 + y^2$.\n\n1. **Check exactness:** Let $M = x^2 + y^2 + x$, $N = y$. Then\n   $$\n   \\frac{\\partial M}{\\partial y} = 2y,\\qquad \\frac{\\partial N}{\\partial x} = 0.\n   $$\n   Since $\\partial M/\\partial y \\neq \\partial N/\\partial x$, the equation is not exact.\n\n2. **Find an integrating factor $\\mu$ of the form $\\mu(r)$ with $r = x^2 + y^2$.**  \n   Compute the expression\n   $$\n   \\frac{M_y - N_x}{N r_x - M r_y} = \\frac{2y - 0}{y(2x) - (x^2+y^2+x)(2y)} = \\frac{2y}{2xy - 2y(x^2+y^2+x)} = \\frac{2y}{-2y(x^2+y^2)} = -\\frac{1}{x^2+y^2} = -\\frac{1}{r}.\n   $$\n   Because this depends only on $r$, an integrating factor $\\mu(r)$ exists and satisfies\n   $$\n   \\frac{d\\mu}{\\mu} = -\\frac{dr}{r} \\quad\\Longrightarrow\\quad \\ln\\mu = -\\ln r + C_0.\n   $$\n   Choosing the constant $C_0 = 0$ gives $\\mu = 1/r = 1/(x^2+y^2)$.\n\n3. **Multiply the equation by $\\mu$:**\n   $$\n   \\left(1 + \\frac{x}{x^2+y^2}\\right)dx + \\frac{y}{x^2+y^2}\\,dy = 0.\n   $$\n   Denote $\\widetilde{M} = 1 + \\frac{x}{x^2+y^2}$, $\\widetilde{N} = \\frac{y}{x^2+y^2}$. Now verify exactness:\n   $$\n   \\frac{\\partial \\widetilde{M}}{\\partial y} = -\\frac{2xy}{(x^2+y^2)^2},\\qquad\n   \\frac{\\partial \\widetilde{N}}{\\partial x} = -\\frac{2xy}{(x^2+y^2)^2},\n   $$\n   so the equation is exact.\n\n4. **Find a potential function $\\psi(x,y)$** such that $\\psi_x = \\widetilde{M}$ and $\\psi_y = \\widetilde{N}$.  \n   Integrate $\\psi_x$ with respect to $x$:\n   $$\n   \\psi = \\int \\left(1 + \\frac{x}{x^2+y^2}\\right)dx = x + \\frac{1}{2}\\ln(x^2+y^2) + h(y),\n   $$\n   where $h(y)$ is an arbitrary function of $y$.  \n   Differentiate with respect to $y$:\n   $$\n   \\psi_y = \\frac{1}{2}\\cdot\\frac{2y}{x^2+y^2} + h'(y) = \\frac{y}{x^2+y^2} + h'(y).\n   $$\n   Set $\\psi_y = \\widetilde{N} = \\frac{y}{x^2+y^2}$. Hence $h'(y) = 0$, so $h(y) = C_1$ (constant).\n\n   Therefore,\n   $$\n   \\psi(x,y) = x + \\frac{1}{2}\\ln(x^2+y^2) + C_1.\n   $$\n\n5. **General solution:** The equation is given implicitly by $\\psi(x,y) = \\text{constant}$:\n   $$\n   x + \\frac{1}{2}\\ln(x^2+y^2) = C,\n   $$\n   where $C$ is an arbitrary constant. This can be rewritten as\n   $$\n   \\ln(x^2+y^2) = 2(C - x) \\quad\\Longrightarrow\\quad x^2 + y^2 = e^{2C}e^{-2x}.\n   $$\n   Letting $K = e^{2C} > 0$, we obtain the solution in implicit form:\n   $$\n   \\boxed{x^2 + y^2 = K e^{-2x},\\qquad K > 0}.\n   $$\n   (The case $K = 0$ gives only the isolated point $(0,0)$, which does not represent a function solution, so we take $K > 0$.)",
            "raw_answer": "[QUESTION]\nFind the general solution of the differential equation\n\\[ (x^2 + y^2 + x)\\,dx + y\\,dy = 0. \\]\n\n[ANSWER]\nWe solve by finding an integrating factor that depends on \\(r = x^2 + y^2\\).\n\n1. **Check exactness:** Let \\(M = x^2 + y^2 + x\\), \\(N = y\\). Then\n   \\[\n   \\frac{\\partial M}{\\partial y} = 2y,\\qquad \\frac{\\partial N}{\\partial x} = 0.\n   \\]\n   Since \\(\\partial M/\\partial y \\neq \\partial N/\\partial x\\), the equation is not exact.\n\n2. **Find an integrating factor \\(\\mu\\) of the form \\(\\mu(r)\\) with \\(r = x^2 + y^2\\).**  \n   Compute the expression\n   \\[\n   \\frac{M_y - N_x}{N r_x - M r_y} = \\frac{2y - 0}{y(2x) - (x^2+y^2+x)(2y)} = \\frac{2y}{2xy - 2y(x^2+y^2+x)} = \\frac{2y}{-2y(x^2+y^2)} = -\\frac{1}{x^2+y^2} = -\\frac{1}{r}.\n   \\]\n   Because this depends only on \\(r\\), an integrating factor \\(\\mu(r)\\) exists and satisfies\n   \\[\n   \\frac{d\\mu}{\\mu} = -\\frac{dr}{r} \\quad\\Longrightarrow\\quad \\ln\\mu = -\\ln r + C_0.\n   \\]\n   Choosing the constant \\(C_0 = 0\\) gives \\(\\mu = 1/r = 1/(x^2+y^2)\\).\n\n3. **Multiply the equation by \\(\\mu\\):**\n   \\[\n   \\left(1 + \\frac{x}{x^2+y^2}\\right)dx + \\frac{y}{x^2+y^2}\\,dy = 0.\n   \\]\n   Denote \\(\\widetilde{M} = 1 + \\frac{x}{x^2+y^2}\\), \\(\\widetilde{N} = \\frac{y}{x^2+y^2}\\). Now verify exactness:\n   \\[\n   \\frac{\\partial \\widetilde{M}}{\\partial y} = -\\frac{2xy}{(x^2+y^2)^2},\\qquad\n   \\frac{\\partial \\widetilde{N}}{\\partial x} = -\\frac{2xy}{(x^2+y^2)^2},\n   \\]\n   so the equation is exact.\n\n4. **Find a potential function \\(\\psi(x,y)\\)** such that \\(\\psi_x = \\widetilde{M}\\) and \\(\\psi_y = \\widetilde{N}\\).  \n   Integrate \\(\\psi_x\\) with respect to \\(x\\):\n   \\[\n   \\psi = \\int \\left(1 + \\frac{x}{x^2+y^2}\\right)dx = x + \\frac{1}{2}\\ln(x^2+y^2) + h(y),\n   \\]\n   where \\(h(y)\\) is an arbitrary function of \\(y\\).  \n   Differentiate with respect to \\(y\\):\n   \\[\n   \\psi_y = \\frac{1}{2}\\cdot\\frac{2y}{x^2+y^2} + h'(y) = \\frac{y}{x^2+y^2} + h'(y).\n   \\]\n   Set \\(\\psi_y = \\widetilde{N} = \\frac{y}{x^2+y^2}\\). Hence \\(h'(y) = 0\\), so \\(h(y) = C_1\\) (constant).\n\n   Therefore,\n   \\[\n   \\psi(x,y) = x + \\frac{1}{2}\\ln(x^2+y^2) + C_1.\n   \\]\n\n5. **General solution:** The equation is given implicitly by \\(\\psi(x,y) = \\text{constant}\\):\n   \\[\n   x + \\frac{1}{2}\\ln(x^2+y^2) = C,\n   \\]\n   where \\(C\\) is an arbitrary constant. This can be rewritten as\n   \\[\n   \\ln(x^2+y^2) = 2(C - x) \\quad\\Longrightarrow\\quad x^2 + y^2 = e^{2C}e^{-2x}.\n   \\]\n   Letting \\(K = e^{2C} > 0\\), we obtain the solution in implicit form:\n   \\[\n   \\boxed{x^2 + y^2 = K e^{-2x},\\qquad K > 0}.\n   \\]\n   (The case \\(K = 0\\) gives only the isolated point \\((0,0)\\), which does not represent a function solution, so we take \\(K > 0\\).)",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "23",
    "outer_attempt": 1,
    "topic_slug": "partial_differential_equations",
    "topic_name": "Partial differential equations",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Consider the viscous Burgers equation\n$$\nu_t + u u_x = \\nu u_{xx}, \\qquad x \\in \\mathbb{R},\\ t>0,\n$$\nwith constant viscosity $\\nu > 0$.  Let the initial condition be a step function:\n$$\nu(x,0) = \\begin{cases}\nU, & x < 0,\\\\\n0, & x > 0,\n\\end{cases}\n$$\nwhere $U > 0$ is a constant.\n\n(a) Introduce the Cole\u2013Hopf transformation $u = -2\\nu (\\ln \\varphi)_x$ and show that $\\varphi$ satisfies the heat equation $\\varphi_t = \\nu \\varphi_{xx}$.\n\n(b) Determine an appropriate initial condition $\\varphi(x,0)$ consistent with the given $u(x,0)$.  (Choose the constant of integration so that $\\varphi(0,0)=1$.)\n\n(c) Solve the initial value problem for $\\varphi(x,t)$ by expressing $\\varphi$ as a convolution with the heat kernel and evaluating the integrals in terms of the complementary error function\n$$\n\\operatorname{erfc}(z) = \\frac{2}{\\sqrt{\\pi}} \\int_z^\\infty e^{-s^2}\\,ds.\n$$\n\n(d) Hence find the solution $u(x,t)$ in the closed form\n$$\nu(x,t) = \\frac{U \\; e^{U^2 t/(4\\nu)}\\; \\operatorname{erfc}\\!\\left( \\dfrac{x - U t}{\\sqrt{4\\nu t}} \\right)}\n{e^{U^2 t/(4\\nu)}\\; \\operatorname{erfc}\\!\\left( \\dfrac{x - U t}{\\sqrt{4\\nu t}} \\right) + e^{U x/(2\\nu)}\\; \\operatorname{erfc}\\!\\left( -\\dfrac{x}{\\sqrt{4\\nu t}} \\right)}.\n$$\n\n(e) (Optional) Verify that this solution tends to the initial step as $t \\to 0^+$.",
            "answer": "We solve the problem step by step.\n\n### (a) Cole\u2013Hopf transformation\n\nDefine $\\varphi(x,t)>0$ and set\n$$\nu = -2\\nu \\frac{\\partial}{\\partial x}\\ln\\varphi = -2\\nu \\frac{\\varphi_x}{\\varphi}.\n$$\nCompute the required derivatives:\n$$\nu_t = -2\\nu\\frac{\\varphi_{xt}\\varphi - \\varphi_x\\varphi_t}{\\varphi^2},\\quad\nu_x = -2\\nu\\frac{\\varphi_{xx}\\varphi - \\varphi_x^2}{\\varphi^2},\\quad\nu_{xx} = -2\\nu\\frac{\\varphi_{xxx}\\varphi - \\varphi_x\\varphi_{xx}}{\\varphi^2} + 4\\nu\\frac{\\varphi_x(\\varphi_{xx}\\varphi - \\varphi_x^2)}{\\varphi^3}.\n$$\nSubstituting into Burgers\u2019 equation $u_t+uu_x = \\nu u_{xx}$ and simplifying (the calculation is standard) yields\n$$\n\\varphi_t = \\nu \\varphi_{xx}.\n$$\nThus $\\varphi$ satisfies the heat equation.\n\n### (b) Initial condition for $\\varphi$\n\nFrom $u = -2\\nu\\varphi_x/\\varphi$ at $t=0$ we have\n$$\n\\frac{\\varphi_x(x,0)}{\\varphi(x,0)} = -\\frac{u(x,0)}{2\\nu}.\n$$\nIntegrate from $0$ to $x$ and use $\\varphi(0,0)=1$:\n$$\n\\ln\\varphi(x,0) = -\\frac{1}{2\\nu}\\int_0^x u(\\xi,0)\\,d\\xi.\n$$\nHence\n$$\n\\varphi(x,0) = \\exp\\left(-\\frac{1}{2\\nu}\\int_0^x u(\\xi,0)\\,d\\xi\\right).\n$$\nFor the step initial condition,\n$$\n\\int_0^x u(\\xi,0)\\,d\\xi = \n\\begin{cases}\n\\displaystyle\\int_0^x U\\,d\\xi = U x, & x<0,\\$$1.2em]\n0, & x>0.\n\\end{cases}\n$$\nTherefore\n$$\n\\varphi(x,0) = \n\\begin{cases}\ne^{-U x/(2\\nu)}, & x<0,\\\\\n1, & x>0.\n\\end{cases}\n$$\n(At $x=0$ both expressions give $1$, so $\\varphi$ is continuous.)\n\n### (c) Solving the heat equation for $\\varphi$\n\nThe solution of $\\varphi_t = \\nu\\varphi_{xx}$ with the above initial data is given by the convolution with the heat kernel:\n$$\n\\varphi(x,t) = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,\ne^{-(x-\\xi)^2/(4\\nu t)}\\,\\varphi(\\xi,0)\\,d\\xi.\n$$\nSplit the integral into the parts $\\xi<0$ and $\\xi>0$:\n$$\n\\varphi = I_- + I_+,\n$$\nwith\n$$\nI_- = \\int_{-\\infty}^{0} \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{-(x-\\xi)^2/(4\\nu t)}\\,e^{-U\\xi/(2\\nu)}\\,d\\xi,\\qquad\nI_+ = \\int_{0}^{\\infty} \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{-(x-\\xi)^2/(4\\nu t)}\\,d\\xi.\n$$\n\n#### Evaluation of $I_+$\n\nSet $\\sigma = \\sqrt{4\\nu t}$.  Using the substitution $s = (\\xi - x)/\\sigma$, we obtain\n$$\nI_+ = \\frac{1}{\\sqrt{\\pi}}\\int_{-x/\\sigma}^{\\infty} e^{-s^2}\\,ds\n= \\frac12\\operatorname{erfc}\\!\\left(-\\frac{x}{\\sigma}\\right).\n$$\n\n#### Evaluation of $I_-$\n\nChange variable $\\eta = -\\xi$ ($\\xi = -\\eta$, $d\\xi = -d\\eta$).  Then\n$$\nI_- = \\int_{\\infty}^{0} \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{-(x+\\eta)^2/(4\\nu t)}\\,e^{U\\eta/(2\\nu)}\\,(-d\\eta)\n= \\int_{0}^{\\infty} \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{-(x+\\eta)^2/(4\\nu t)}\\,e^{U\\eta/(2\\nu)}\\,d\\eta.\n$$\nCombine the exponentials:\n$$\n-\\frac{(x+\\eta)^2}{4\\nu t} + \\frac{U\\eta}{2\\nu}\n= -\\frac{x^2}{4\\nu t} -\\frac{x\\eta}{2\\nu t} -\\frac{\\eta^2}{4\\nu t} + \\frac{U\\eta}{2\\nu}.\n$$\nComplete the square in $\\eta$.  Write the $\\eta$-terms as\n$$\n-\\frac{1}{4\\nu t}\\bigl[\\eta^2 - 2(U t - x)\\eta\\bigr].\n$$\nThen\n$$\n\\eta^2 - 2(U t - x)\\eta = (\\eta - (U t - x))^2 - (U t - x)^2.\n$$\nHence the exponent becomes\n$$\n-\\frac{x^2}{4\\nu t} -\\frac{(\\eta - (U t - x))^2}{4\\nu t} + \\frac{(U t - x)^2}{4\\nu t}.\n$$\nNow\n$$\n\\frac{(U t - x)^2}{4\\nu t} - \\frac{x^2}{4\\nu t}\n= \\frac{U^2 t}{4\\nu} - \\frac{U x}{2\\nu}.\n$$\nThus\n$$\nI_- = \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{U^2 t/(4\\nu) - U x/(2\\nu)}\n\\int_{0}^{\\infty} e^{-(\\eta - (U t - x))^2/(4\\nu t)}\\,d\\eta.\n$$\nThe remaining integral is of the same type as in $I_+$.  Let $a = U t - x$.  With $s = (\\eta - a)/\\sigma$,\n$$\n\\int_{0}^{\\infty} e^{-(\\eta - a)^2/\\sigma^2}\\,d\\eta\n= \\sigma \\int_{-a/\\sigma}^{\\infty} e^{-s^2}\\,ds\n= \\sigma\\,\\frac{\\sqrt{\\pi}}{2}\\operatorname{erfc}\\!\\left(-\\frac{a}{\\sigma}\\right)\n= \\sqrt{\\pi\\nu t}\\,\\operatorname{erfc}\\!\\left(\\frac{x - U t}{\\sigma}\\right),\n$$\nbecause $-a/\\sigma = (x-U t)/\\sigma$.  Therefore\n$$\nI_- = \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{U^2 t/(4\\nu) - U x/(2\\nu)}\\,\n\\sqrt{\\pi\\nu t}\\;\\operatorname{erfc}\\!\\left(\\frac{x - U t}{\\sigma}\\right)\n= \\frac12\\,e^{U^2 t/(4\\nu) - U x/(2\\nu)}\\,\n\\operatorname{erfc}\\!\\left(\\frac{x - U t}{\\sqrt{4\\nu t}}\\right).\n$$\n\n#### Assembling $\\varphi$\n\n$$\n\\varphi(x,t) = I_- + I_+ \n= \\frac12\\left[ e^{U^2 t/(4\\nu) - U x/(2\\nu)}\\,\n\\operatorname{erfc}\\!\\left(\\frac{x - U t}{\\sqrt{4\\nu t}}\\right)\n+ \\operatorname{erfc}\\!\\left(-\\frac{x}{\\sqrt{4\\nu t}}\\right) \\right].\n$$\n\n### (d) Deriving $u(x,t)$\n\nIntroduce the abbreviations\n$$\nA = e^{U^2 t/(4\\nu)},\\quad\nB = e^{U x/(2\\nu)},\\quad\nC_1 = \\operatorname{erfc}\\!\\left(\\frac{x - U t}{\\sqrt{4\\nu t}}\\right),\\quad\nC_2 = \\operatorname{erfc}\\!\\left(-\\frac{x}{\\sqrt{4\\nu t}}\\right).\n$$\nThen\n$$\n\\varphi = \\frac12\\left( A e^{-U x/(2\\nu)} C_1 + C_2 \\right)\n= \\frac12 e^{-U x/(2\\nu)}\\bigl( A C_1 + B C_2 \\bigr).\n$$\nSet $D = A C_1 + B C_2$, so that $\\varphi = \\frac12 e^{-U x/(2\\nu)} D$.\n\nNow compute $u = -2\\nu\\varphi_x/\\varphi$.  First,\n$$\n\\ln\\varphi = -\\frac{U x}{2\\nu} + \\ln D - \\ln 2,\n$$\nhence\n$$\n\\frac{\\varphi_x}{\\varphi} = -\\frac{U}{2\\nu} + \\frac{D_x}{D}.\n$$\nTherefore\n$$\nu = -2\\nu\\left(-\\frac{U}{2\\nu} + \\frac{D_x}{D}\\right) = U - 2\\nu\\frac{D_x}{D}.\n$$\n\nWe need $D_x$.  Differentiate term by term:\n$$\nD_x = A C_{1x} + B_x C_2 + B C_{2x}.\n$$\nThe derivatives of the complementary error functions are\n$$\nC_{1x} = \\frac{d}{dx}\\operatorname{erfc}\\!\\left(\\frac{x-U t}{\\sqrt{4\\nu t}}\\right)\n= -\\frac{2}{\\sqrt{\\pi}}\\,e^{-(x-U t)^2/(4\\nu t)}\\cdot\\frac{1}{\\sqrt{4\\nu t}},\n$$\n$$\nC_{2x} = \\frac{d}{dx}\\operatorname{erfc}\\!\\left(-\\frac{x}{\\sqrt{4\\nu t}}\\right)\n= \\frac{2}{\\sqrt{\\pi}}\\,e^{-x^2/(4\\nu t)}\\cdot\\frac{1}{\\sqrt{4\\nu t}}.\n$$\nAlso $B_x = \\dfrac{U}{2\\nu}B$.\n\nNow examine the sum $A C_{1x} + B C_{2x}$.  Using the explicit forms,\n$$\nA C_{1x} = -A\\,\\frac{2}{\\sqrt{\\pi}\\sqrt{4\\nu t}}\\,e^{-(x-U t)^2/(4\\nu t)},\n\\qquad\nB C_{2x} = B\\,\\frac{2}{\\sqrt{\\pi}\\sqrt{4\\nu t}}\\,e^{-x^2/(4\\nu t)}.\n$$\nBut note the identity\n$$\nA\\,e^{-(x-U t)^2/(4\\nu t)} = e^{U^2 t/(4\\nu)}\\,e^{-(x^2 -2U t x + U^2 t^2)/(4\\nu t)}\n= e^{U x/(2\\nu)}\\,e^{-x^2/(4\\nu t)} = B\\,e^{-x^2/(4\\nu t)}.\n$$\nThus the two terms cancel exactly:\n$$\nA C_{1x} + B C_{2x} = 0.\n$$\nConsequently,\n$$\nD_x = B_x C_2 = \\frac{U}{2\\nu}\\,B\\,C_2.\n$$\n\nSubstituting into the expression for $u$:\n$$\n2\\nu\\frac{D_x}{D} = 2\\nu\\cdot\\frac{U}{2\\nu}\\,\\frac{B C_2}{D} = U\\,\\frac{B C_2}{D}.\n$$\nHence\n$$\nu = U - U\\frac{B C_2}{D} = U\\left(1 - \\frac{B C_2}{D}\\right)\n= U\\,\\frac{D - B C_2}{D} = U\\,\\frac{A C_1}{D}.\n$$\nFinally,\n$$\nu(x,t) = \\frac{U\\,A\\,C_1}{A\\,C_1 + B\\,C_2}\n= \\frac{U\\;e^{U^2 t/(4\\nu)}\\;\\operatorname{erfc}\\!\\left( \\dfrac{x - U t}{\\sqrt{4\\nu t}} \\right)}\n{e^{U^2 t/(4\\nu)}\\;\\operatorname{erfc}\\!\\left( \\dfrac{x - U t}{\\sqrt{4\\nu t}} \\right)\n+ e^{U x/(2\\nu)}\\;\\operatorname{erfc}\\!\\left( -\\dfrac{x}{\\sqrt{4\\nu t}} \\right)}.\n$$\n\n### (e) Behaviour as $t\\to 0^+$\n\nFor fixed $x \\neq 0$, as $t\\to 0^+$ we have\n$$\n\\frac{x}{\\sqrt{4\\nu t}} \\to \\begin{cases}\n+\\infty & (x>0),\\$$2pt]\n-\\infty & (x<0),\n\\end{cases}\n\\qquad\n\\frac{x-U t}{\\sqrt{4\\nu t}} \\to \\begin{cases}\n+\\infty & (x>0),\\$$2pt]\n-\\infty & (x<0).\n\\end{cases}\n$$\nUsing $\\operatorname{erfc}(+\\infty)=0$, $\\operatorname{erfc}(-\\infty)=2$, we obtain:\n\n- If $x>0$: $C_1\\to 0$, $C_2\\to 0$? Actually, for $x>0$, $-x/\\sqrt{4\\nu t}\\to -\\infty$, so $C_2 = \\operatorname{erfc}(-\\infty)=2$.  Meanwhile $C_1\\to 0$.  Hence\n  $$\n  u \\to \\frac{U\\cdot A\\cdot 0}{A\\cdot 0 + e^{U x/(2\\nu)}\\cdot 2} = 0.\n  $$\n\n- If $x<0$: then $x/\\sqrt{4\\nu t}\\to +\\infty$? Wait, $x<0$, so $-x/\\sqrt{4\\nu t}\\to +\\infty$, thus $C_2 = \\operatorname{erfc}(+\\infty)=0$.  Also $x-U t<0$ for sufficiently small $t$, so $(x-U t)/\\sqrt{4\\nu t}\\to -\\infty$, giving $C_1 = \\operatorname{erfc}(-\\infty)=2$.  Therefore\n  $$\n  u \\to \\frac{U\\cdot A\\cdot 2}{A\\cdot 2 + e^{U x/(2\\nu)}\\cdot 0} = U.\n  $$\n\nThus $u(x,t)$ tends to the initial step function as $t\\to 0^+$, as required.\n\nThis completes the solution.",
            "raw_answer": "[QUESTION]\nConsider the viscous Burgers equation\n\\[\nu_t + u u_x = \\nu u_{xx}, \\qquad x \\in \\mathbb{R},\\ t>0,\n\\]\nwith constant viscosity \\(\\nu > 0\\).  Let the initial condition be a step function:\n\\[\nu(x,0) = \\begin{cases}\nU, & x < 0,\\\\\n0, & x > 0,\n\\end{cases}\n\\]\nwhere \\(U > 0\\) is a constant.\n\n(a) Introduce the Cole\u2013Hopf transformation \\(u = -2\\nu (\\ln \\varphi)_x\\) and show that \\(\\varphi\\) satisfies the heat equation \\(\\varphi_t = \\nu \\varphi_{xx}\\).\n\n(b) Determine an appropriate initial condition \\(\\varphi(x,0)\\) consistent with the given \\(u(x,0)\\).  (Choose the constant of integration so that \\(\\varphi(0,0)=1\\).)\n\n(c) Solve the initial value problem for \\(\\varphi(x,t)\\) by expressing \\(\\varphi\\) as a convolution with the heat kernel and evaluating the integrals in terms of the complementary error function\n\\[\n\\operatorname{erfc}(z) = \\frac{2}{\\sqrt{\\pi}} \\int_z^\\infty e^{-s^2}\\,ds.\n\\]\n\n(d) Hence find the solution \\(u(x,t)\\) in the closed form\n\\[\nu(x,t) = \\frac{U \\; e^{U^2 t/(4\\nu)}\\; \\operatorname{erfc}\\!\\left( \\dfrac{x - U t}{\\sqrt{4\\nu t}} \\right)}\n{e^{U^2 t/(4\\nu)}\\; \\operatorname{erfc}\\!\\left( \\dfrac{x - U t}{\\sqrt{4\\nu t}} \\right) + e^{U x/(2\\nu)}\\; \\operatorname{erfc}\\!\\left( -\\dfrac{x}{\\sqrt{4\\nu t}} \\right)}.\n\\]\n\n(e) (Optional) Verify that this solution tends to the initial step as \\(t \\to 0^+\\).\n\n[ANSWER]\nWe solve the problem step by step.\n\n### (a) Cole\u2013Hopf transformation\n\nDefine \\(\\varphi(x,t)>0\\) and set\n\\[\nu = -2\\nu \\frac{\\partial}{\\partial x}\\ln\\varphi = -2\\nu \\frac{\\varphi_x}{\\varphi}.\n\\]\nCompute the required derivatives:\n\\[\nu_t = -2\\nu\\frac{\\varphi_{xt}\\varphi - \\varphi_x\\varphi_t}{\\varphi^2},\\quad\nu_x = -2\\nu\\frac{\\varphi_{xx}\\varphi - \\varphi_x^2}{\\varphi^2},\\quad\nu_{xx} = -2\\nu\\frac{\\varphi_{xxx}\\varphi - \\varphi_x\\varphi_{xx}}{\\varphi^2} + 4\\nu\\frac{\\varphi_x(\\varphi_{xx}\\varphi - \\varphi_x^2)}{\\varphi^3}.\n\\]\nSubstituting into Burgers\u2019 equation \\(u_t+uu_x = \\nu u_{xx}\\) and simplifying (the calculation is standard) yields\n\\[\n\\varphi_t = \\nu \\varphi_{xx}.\n\\]\nThus \\(\\varphi\\) satisfies the heat equation.\n\n### (b) Initial condition for \\(\\varphi\\)\n\nFrom \\(u = -2\\nu\\varphi_x/\\varphi\\) at \\(t=0\\) we have\n\\[\n\\frac{\\varphi_x(x,0)}{\\varphi(x,0)} = -\\frac{u(x,0)}{2\\nu}.\n\\]\nIntegrate from \\(0\\) to \\(x\\) and use \\(\\varphi(0,0)=1\\):\n\\[\n\\ln\\varphi(x,0) = -\\frac{1}{2\\nu}\\int_0^x u(\\xi,0)\\,d\\xi.\n\\]\nHence\n\\[\n\\varphi(x,0) = \\exp\\left(-\\frac{1}{2\\nu}\\int_0^x u(\\xi,0)\\,d\\xi\\right).\n\\]\nFor the step initial condition,\n\\[\n\\int_0^x u(\\xi,0)\\,d\\xi = \n\\begin{cases}\n\\displaystyle\\int_0^x U\\,d\\xi = U x, & x<0,\\\\[1.2em]\n0, & x>0.\n\\end{cases}\n\\]\nTherefore\n\\[\n\\varphi(x,0) = \n\\begin{cases}\ne^{-U x/(2\\nu)}, & x<0,\\\\\n1, & x>0.\n\\end{cases}\n\\]\n(At \\(x=0\\) both expressions give \\(1\\), so \\(\\varphi\\) is continuous.)\n\n### (c) Solving the heat equation for \\(\\varphi\\)\n\nThe solution of \\(\\varphi_t = \\nu\\varphi_{xx}\\) with the above initial data is given by the convolution with the heat kernel:\n\\[\n\\varphi(x,t) = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,\ne^{-(x-\\xi)^2/(4\\nu t)}\\,\\varphi(\\xi,0)\\,d\\xi.\n\\]\nSplit the integral into the parts \\(\\xi<0\\) and \\(\\xi>0\\):\n\\[\n\\varphi = I_- + I_+,\n\\]\nwith\n\\[\nI_- = \\int_{-\\infty}^{0} \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{-(x-\\xi)^2/(4\\nu t)}\\,e^{-U\\xi/(2\\nu)}\\,d\\xi,\\qquad\nI_+ = \\int_{0}^{\\infty} \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{-(x-\\xi)^2/(4\\nu t)}\\,d\\xi.\n\\]\n\n#### Evaluation of \\(I_+\\)\n\nSet \\(\\sigma = \\sqrt{4\\nu t}\\).  Using the substitution \\(s = (\\xi - x)/\\sigma\\), we obtain\n\\[\nI_+ = \\frac{1}{\\sqrt{\\pi}}\\int_{-x/\\sigma}^{\\infty} e^{-s^2}\\,ds\n= \\frac12\\operatorname{erfc}\\!\\left(-\\frac{x}{\\sigma}\\right).\n\\]\n\n#### Evaluation of \\(I_-\\)\n\nChange variable \\(\\eta = -\\xi\\) (\\(\\xi = -\\eta\\), \\(d\\xi = -d\\eta\\)).  Then\n\\[\nI_- = \\int_{\\infty}^{0} \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{-(x+\\eta)^2/(4\\nu t)}\\,e^{U\\eta/(2\\nu)}\\,(-d\\eta)\n= \\int_{0}^{\\infty} \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{-(x+\\eta)^2/(4\\nu t)}\\,e^{U\\eta/(2\\nu)}\\,d\\eta.\n\\]\nCombine the exponentials:\n\\[\n-\\frac{(x+\\eta)^2}{4\\nu t} + \\frac{U\\eta}{2\\nu}\n= -\\frac{x^2}{4\\nu t} -\\frac{x\\eta}{2\\nu t} -\\frac{\\eta^2}{4\\nu t} + \\frac{U\\eta}{2\\nu}.\n\\]\nComplete the square in \\(\\eta\\).  Write the \\(\\eta\\)-terms as\n\\[\n-\\frac{1}{4\\nu t}\\bigl[\\eta^2 - 2(U t - x)\\eta\\bigr].\n\\]\nThen\n\\[\n\\eta^2 - 2(U t - x)\\eta = (\\eta - (U t - x))^2 - (U t - x)^2.\n\\]\nHence the exponent becomes\n\\[\n-\\frac{x^2}{4\\nu t} -\\frac{(\\eta - (U t - x))^2}{4\\nu t} + \\frac{(U t - x)^2}{4\\nu t}.\n\\]\nNow\n\\[\n\\frac{(U t - x)^2}{4\\nu t} - \\frac{x^2}{4\\nu t}\n= \\frac{U^2 t}{4\\nu} - \\frac{U x}{2\\nu}.\n\\]\nThus\n\\[\nI_- = \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{U^2 t/(4\\nu) - U x/(2\\nu)}\n\\int_{0}^{\\infty} e^{-(\\eta - (U t - x))^2/(4\\nu t)}\\,d\\eta.\n\\]\nThe remaining integral is of the same type as in \\(I_+\\).  Let \\(a = U t - x\\).  With \\(s = (\\eta - a)/\\sigma\\),\n\\[\n\\int_{0}^{\\infty} e^{-(\\eta - a)^2/\\sigma^2}\\,d\\eta\n= \\sigma \\int_{-a/\\sigma}^{\\infty} e^{-s^2}\\,ds\n= \\sigma\\,\\frac{\\sqrt{\\pi}}{2}\\operatorname{erfc}\\!\\left(-\\frac{a}{\\sigma}\\right)\n= \\sqrt{\\pi\\nu t}\\,\\operatorname{erfc}\\!\\left(\\frac{x - U t}{\\sigma}\\right),\n\\]\nbecause \\(-a/\\sigma = (x-U t)/\\sigma\\).  Therefore\n\\[\nI_- = \\frac{1}{\\sqrt{4\\pi\\nu t}}\\,e^{U^2 t/(4\\nu) - U x/(2\\nu)}\\,\n\\sqrt{\\pi\\nu t}\\;\\operatorname{erfc}\\!\\left(\\frac{x - U t}{\\sigma}\\right)\n= \\frac12\\,e^{U^2 t/(4\\nu) - U x/(2\\nu)}\\,\n\\operatorname{erfc}\\!\\left(\\frac{x - U t}{\\sqrt{4\\nu t}}\\right).\n\\]\n\n#### Assembling \\(\\varphi\\)\n\n\\[\n\\varphi(x,t) = I_- + I_+ \n= \\frac12\\left[ e^{U^2 t/(4\\nu) - U x/(2\\nu)}\\,\n\\operatorname{erfc}\\!\\left(\\frac{x - U t}{\\sqrt{4\\nu t}}\\right)\n+ \\operatorname{erfc}\\!\\left(-\\frac{x}{\\sqrt{4\\nu t}}\\right) \\right].\n\\]\n\n### (d) Deriving \\(u(x,t)\\)\n\nIntroduce the abbreviations\n\\[\nA = e^{U^2 t/(4\\nu)},\\quad\nB = e^{U x/(2\\nu)},\\quad\nC_1 = \\operatorname{erfc}\\!\\left(\\frac{x - U t}{\\sqrt{4\\nu t}}\\right),\\quad\nC_2 = \\operatorname{erfc}\\!\\left(-\\frac{x}{\\sqrt{4\\nu t}}\\right).\n\\]\nThen\n\\[\n\\varphi = \\frac12\\left( A e^{-U x/(2\\nu)} C_1 + C_2 \\right)\n= \\frac12 e^{-U x/(2\\nu)}\\bigl( A C_1 + B C_2 \\bigr).\n\\]\nSet \\(D = A C_1 + B C_2\\), so that \\(\\varphi = \\frac12 e^{-U x/(2\\nu)} D\\).\n\nNow compute \\(u = -2\\nu\\varphi_x/\\varphi\\).  First,\n\\[\n\\ln\\varphi = -\\frac{U x}{2\\nu} + \\ln D - \\ln 2,\n\\]\nhence\n\\[\n\\frac{\\varphi_x}{\\varphi} = -\\frac{U}{2\\nu} + \\frac{D_x}{D}.\n\\]\nTherefore\n\\[\nu = -2\\nu\\left(-\\frac{U}{2\\nu} + \\frac{D_x}{D}\\right) = U - 2\\nu\\frac{D_x}{D}.\n\\]\n\nWe need \\(D_x\\).  Differentiate term by term:\n\\[\nD_x = A C_{1x} + B_x C_2 + B C_{2x}.\n\\]\nThe derivatives of the complementary error functions are\n\\[\nC_{1x} = \\frac{d}{dx}\\operatorname{erfc}\\!\\left(\\frac{x-U t}{\\sqrt{4\\nu t}}\\right)\n= -\\frac{2}{\\sqrt{\\pi}}\\,e^{-(x-U t)^2/(4\\nu t)}\\cdot\\frac{1}{\\sqrt{4\\nu t}},\n\\]\n\\[\nC_{2x} = \\frac{d}{dx}\\operatorname{erfc}\\!\\left(-\\frac{x}{\\sqrt{4\\nu t}}\\right)\n= \\frac{2}{\\sqrt{\\pi}}\\,e^{-x^2/(4\\nu t)}\\cdot\\frac{1}{\\sqrt{4\\nu t}}.\n\\]\nAlso \\(B_x = \\dfrac{U}{2\\nu}B\\).\n\nNow examine the sum \\(A C_{1x} + B C_{2x}\\).  Using the explicit forms,\n\\[\nA C_{1x} = -A\\,\\frac{2}{\\sqrt{\\pi}\\sqrt{4\\nu t}}\\,e^{-(x-U t)^2/(4\\nu t)},\n\\qquad\nB C_{2x} = B\\,\\frac{2}{\\sqrt{\\pi}\\sqrt{4\\nu t}}\\,e^{-x^2/(4\\nu t)}.\n\\]\nBut note the identity\n\\[\nA\\,e^{-(x-U t)^2/(4\\nu t)} = e^{U^2 t/(4\\nu)}\\,e^{-(x^2 -2U t x + U^2 t^2)/(4\\nu t)}\n= e^{U x/(2\\nu)}\\,e^{-x^2/(4\\nu t)} = B\\,e^{-x^2/(4\\nu t)}.\n\\]\nThus the two terms cancel exactly:\n\\[\nA C_{1x} + B C_{2x} = 0.\n\\]\nConsequently,\n\\[\nD_x = B_x C_2 = \\frac{U}{2\\nu}\\,B\\,C_2.\n\\]\n\nSubstituting into the expression for \\(u\\):\n\\[\n2\\nu\\frac{D_x}{D} = 2\\nu\\cdot\\frac{U}{2\\nu}\\,\\frac{B C_2}{D} = U\\,\\frac{B C_2}{D}.\n\\]\nHence\n\\[\nu = U - U\\frac{B C_2}{D} = U\\left(1 - \\frac{B C_2}{D}\\right)\n= U\\,\\frac{D - B C_2}{D} = U\\,\\frac{A C_1}{D}.\n\\]\nFinally,\n\\[\nu(x,t) = \\frac{U\\,A\\,C_1}{A\\,C_1 + B\\,C_2}\n= \\frac{U\\;e^{U^2 t/(4\\nu)}\\;\\operatorname{erfc}\\!\\left( \\dfrac{x - U t}{\\sqrt{4\\nu t}} \\right)}\n{e^{U^2 t/(4\\nu)}\\;\\operatorname{erfc}\\!\\left( \\dfrac{x - U t}{\\sqrt{4\\nu t}} \\right)\n+ e^{U x/(2\\nu)}\\;\\operatorname{erfc}\\!\\left( -\\dfrac{x}{\\sqrt{4\\nu t}} \\right)}.\n\\]\n\n### (e) Behaviour as \\(t\\to 0^+\\)\n\nFor fixed \\(x \\neq 0\\), as \\(t\\to 0^+\\) we have\n\\[\n\\frac{x}{\\sqrt{4\\nu t}} \\to \\begin{cases}\n+\\infty & (x>0),\\\\[2pt]\n-\\infty & (x<0),\n\\end{cases}\n\\qquad\n\\frac{x-U t}{\\sqrt{4\\nu t}} \\to \\begin{cases}\n+\\infty & (x>0),\\\\[2pt]\n-\\infty & (x<0).\n\\end{cases}\n\\]\nUsing \\(\\operatorname{erfc}(+\\infty)=0\\), \\(\\operatorname{erfc}(-\\infty)=2\\), we obtain:\n\n- If \\(x>0\\): \\(C_1\\to 0\\), \\(C_2\\to 0\\)? Actually, for \\(x>0\\), \\(-x/\\sqrt{4\\nu t}\\to -\\infty\\), so \\(C_2 = \\operatorname{erfc}(-\\infty)=2\\).  Meanwhile \\(C_1\\to 0\\).  Hence\n  \\[\n  u \\to \\frac{U\\cdot A\\cdot 0}{A\\cdot 0 + e^{U x/(2\\nu)}\\cdot 2} = 0.\n  \\]\n\n- If \\(x<0\\): then \\(x/\\sqrt{4\\nu t}\\to +\\infty\\)? Wait, \\(x<0\\), so \\(-x/\\sqrt{4\\nu t}\\to +\\infty\\), thus \\(C_2 = \\operatorname{erfc}(+\\infty)=0\\).  Also \\(x-U t<0\\) for sufficiently small \\(t\\), so \\((x-U t)/\\sqrt{4\\nu t}\\to -\\infty\\), giving \\(C_1 = \\operatorname{erfc}(-\\infty)=2\\).  Therefore\n  \\[\n  u \\to \\frac{U\\cdot A\\cdot 2}{A\\cdot 2 + e^{U x/(2\\nu)}\\cdot 0} = U.\n  \\]\n\nThus \\(u(x,t)\\) tends to the initial step function as \\(t\\to 0^+\\), as required.\n\nThis completes the solution.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "24",
    "outer_attempt": 1,
    "topic_slug": "dynamical_systems_and_ergodic_theory",
    "topic_name": "Dynamical systems and ergodic theory",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $\\theta$ be an irrational number. Define the rotation $R_\\theta: [0,1) \\to [0,1)$ by $R_\\theta(x) = x + \\theta \\pmod 1$, where we identify $[0,1)$ with the circle $\\mathbb{R}/\\mathbb{Z}$. Let $\\lambda$ denote the Lebesgue measure on $[0,1)$.\n\nProve the following:\n(a) $R_\\theta$ is ergodic with respect to $\\lambda$.\n(b) $R_\\theta$ is not strong mixing with respect to $\\lambda$.\n(c) $R_\\theta$ is uniquely ergodic, i.e., $\\lambda$ is the only $R_\\theta$-invariant Borel probability measure on $[0,1)$.\n[/QUESTION]",
            "answer": "**Solution (a): Ergodicity**\n\nFirst note that $R_\\theta$ preserves $\\lambda$ because translation modulo $1$ is Lebesgue measure invariant: for any measurable $A \\subset [0,1)$, $\\lambda(R_\\theta^{-1}A) = \\lambda(A - \\theta) = \\lambda(A)$.\n\nTo prove ergodicity we show that any $R_\\theta$-invariant $L^2$ function is constant almost everywhere. Let $f \\in L^2([0,1), \\lambda)$ satisfy $f \\circ R_\\theta = f$ a.e. Expand $f$ in a Fourier series (convergence in $L^2$):\n$$\nf(x) = \\sum_{k \\in \\mathbb{Z}} c_k e^{2\\pi i k x}, \\qquad c_k = \\int_0^1 f(x) e^{-2\\pi i k x}\\,dx.\n$$\nThen\n$$\nf(R_\\theta x) = \\sum_{k} c_k e^{2\\pi i k (x+\\theta)} = \\sum_{k} (c_k e^{2\\pi i k \\theta}) e^{2\\pi i k x}.\n$$\nSince $f = f \\circ R_\\theta$ a.e., the Fourier coefficients must coincide, giving\n$$\nc_k = c_k e^{2\\pi i k \\theta} \\quad \\text{for all } k.\n$$\nFor $k \\neq 0$, $e^{2\\pi i k \\theta} \\neq 1$ because $\\theta$ is irrational, hence $c_k = 0$. Therefore $f(x) = c_0$ constant almost everywhere.\n\nNow if $A \\subset [0,1)$ is a measurable $R_\\theta$-invariant set (i.e., $R_\\theta^{-1}A = A$), its indicator function $1_A$ belongs to $L^2$ and is invariant. By the argument above, $1_A$ is constant a.e., so either $1_A = 0$ a.e. or $1_A = 1$ a.e., which means $\\lambda(A)=0$ or $\\lambda(A)=1$. Thus $R_\\theta$ is ergodic.\n\n**Solution (b): Not strong mixing**\n\nWe exhibit a pair of measurable sets for which the mixing condition fails. Let $A = [0, 1/2)$. Then $\\lambda(A) = 1/2$. For $n \\in \\mathbb{N}$, set $\\alpha_n = n\\theta \\bmod 1 \\in [0,1)$. Because $R_\\theta^{-n}A = \\{ x : x + n\\theta \\bmod 1 \\in A \\} = A - \\alpha_n \\pmod 1$, we have\n$$\n\\lambda(A \\cap R_\\theta^{-n}A) = \\lambda\\big( A \\cap (A - \\alpha_n) \\big).\n$$\nDefine $f(\\alpha) = \\lambda( A \\cap (A - \\alpha) )$ for $\\alpha \\in [0,1)$. A direct computation yields:\n- If $0 \\le \\alpha \\le \\frac12$, then $A \\cap (A - \\alpha) = [0, \\frac12 - \\alpha)$ and $f(\\alpha) = \\frac12 - \\alpha$.\n- If $\\frac12 \\le \\alpha \\le 1$, then $A \\cap (A - \\alpha) = [1-\\alpha, \\frac12)$ and $f(\\alpha) = \\alpha - \\frac12$.\n\nThus $f$ is continuous on $[0,1)$ with $f(0) = \\frac12$, $f(\\frac12) = 0$, and $f(1^-) = \\frac12$ (by periodicity).\n\nSince $\\theta$ is irrational, the sequence $\\{\\alpha_n\\}_{n\\ge 1}$ is dense in $[0,1)$. Hence there exists a subsequence $n_k$ such that $\\alpha_{n_k} \\to 0$, and another subsequence $m_k$ such that $\\alpha_{m_k} \\to \\frac12$. By continuity of $f$,\n$$\n\\lim_{k\\to\\infty} \\lambda(A \\cap R_\\theta^{-n_k}A) = f(0) = \\frac12,\n\\qquad\n\\lim_{k\\to\\infty} \\lambda(A \\cap R_\\theta^{-m_k}A) = f(\\tfrac12) = 0.\n$$\nIf $R_\\theta$ were strong mixing, we would have\n$$\n\\lim_{n\\to\\infty} \\lambda(A \\cap R_\\theta^{-n}A) = \\lambda(A)\\lambda(A) = \\frac14,\n$$\nbut the above limits show that the limit does not exist (or at least has subsequential limits different from $\\frac14$). Therefore $R_\\theta$ is not strong mixing.\n\n**Solution (c): Unique ergodicity**\n\nLet $\\mu$ be any Borel probability measure on $[0,1)$ invariant under $R_\\theta$. Consider its Fourier coefficients\n$$\n\\hat{\\mu}(k) = \\int_0^1 e^{-2\\pi i k x}\\, d\\mu(x), \\qquad k \\in \\mathbb{Z}.\n$$\nInvariance $\\mu = \\mu \\circ R_\\theta^{-1}$ implies that for every $k$,\n$$\n\\hat{\\mu}(k) = \\int e^{-2\\pi i k (x+\\theta)}\\, d\\mu(x) = e^{-2\\pi i k \\theta} \\hat{\\mu}(k).\n$$\nThus $(1 - e^{-2\\pi i k \\theta})\\hat{\\mu}(k) = 0$. For $k \\neq 0$, $e^{-2\\pi i k \\theta} \\neq 1$ (because $\\theta$ is irrational), so $\\hat{\\mu}(k) = 0$. For $k = 0$, $\\hat{\\mu}(0) = \\mu([0,1)) = 1$.\n\nLebesgue measure $\\lambda$ has Fourier coefficients $\\hat{\\lambda}(k) = 0$ for $k \\neq 0$ and $\\hat{\\lambda}(0)=1$. Hence $\\hat{\\mu}(k) = \\hat{\\lambda}(k)$ for all $k \\in \\mathbb{Z}$.\n\nTo conclude $\\mu = \\lambda$, we use the fact that trigonometric polynomials are dense in the space of continuous functions on the circle (Stone\u2013Weierstrass). For any continuous function $g$ on $[0,1]$, choose a sequence of trigonometric polynomials $p_n$ converging uniformly to $g$. Then\n$$\n\\int g \\, d\\mu = \\lim_{n\\to\\infty} \\int p_n \\, d\\mu = \\lim_{n\\to\\infty} \\int p_n \\, d\\lambda = \\int g \\, d\\lambda,\n$$\nwhere the middle equality holds because $\\int p_n \\, d\\mu$ and $\\int p_n \\, d\\lambda$ are linear combinations of the Fourier coefficients, which coincide. By the Riesz representation theorem, two Borel probability measures that agree on all continuous functions are identical. Hence $\\mu = \\lambda$.\n\nThus $\\lambda$ is the unique $R_\\theta$-invariant Borel probability measure, i.e., $R_\\theta$ is uniquely ergodic.\n\n\u220e\n[/ANSWER]",
            "raw_answer": "[QUESTION]\nLet $\\theta$ be an irrational number. Define the rotation $R_\\theta: [0,1) \\to [0,1)$ by $R_\\theta(x) = x + \\theta \\pmod 1$, where we identify $[0,1)$ with the circle $\\mathbb{R}/\\mathbb{Z}$. Let $\\lambda$ denote the Lebesgue measure on $[0,1)$.\n\nProve the following:\n(a) $R_\\theta$ is ergodic with respect to $\\lambda$.\n(b) $R_\\theta$ is not strong mixing with respect to $\\lambda$.\n(c) $R_\\theta$ is uniquely ergodic, i.e., $\\lambda$ is the only $R_\\theta$-invariant Borel probability measure on $[0,1)$.\n[/QUESTION]\n\n[ANSWER]\n**Solution (a): Ergodicity**\n\nFirst note that $R_\\theta$ preserves $\\lambda$ because translation modulo $1$ is Lebesgue measure invariant: for any measurable $A \\subset [0,1)$, $\\lambda(R_\\theta^{-1}A) = \\lambda(A - \\theta) = \\lambda(A)$.\n\nTo prove ergodicity we show that any $R_\\theta$-invariant $L^2$ function is constant almost everywhere. Let $f \\in L^2([0,1), \\lambda)$ satisfy $f \\circ R_\\theta = f$ a.e. Expand $f$ in a Fourier series (convergence in $L^2$):\n$$\nf(x) = \\sum_{k \\in \\mathbb{Z}} c_k e^{2\\pi i k x}, \\qquad c_k = \\int_0^1 f(x) e^{-2\\pi i k x}\\,dx.\n$$\nThen\n$$\nf(R_\\theta x) = \\sum_{k} c_k e^{2\\pi i k (x+\\theta)} = \\sum_{k} (c_k e^{2\\pi i k \\theta}) e^{2\\pi i k x}.\n$$\nSince $f = f \\circ R_\\theta$ a.e., the Fourier coefficients must coincide, giving\n$$\nc_k = c_k e^{2\\pi i k \\theta} \\quad \\text{for all } k.\n$$\nFor $k \\neq 0$, $e^{2\\pi i k \\theta} \\neq 1$ because $\\theta$ is irrational, hence $c_k = 0$. Therefore $f(x) = c_0$ constant almost everywhere.\n\nNow if $A \\subset [0,1)$ is a measurable $R_\\theta$-invariant set (i.e., $R_\\theta^{-1}A = A$), its indicator function $1_A$ belongs to $L^2$ and is invariant. By the argument above, $1_A$ is constant a.e., so either $1_A = 0$ a.e. or $1_A = 1$ a.e., which means $\\lambda(A)=0$ or $\\lambda(A)=1$. Thus $R_\\theta$ is ergodic.\n\n**Solution (b): Not strong mixing**\n\nWe exhibit a pair of measurable sets for which the mixing condition fails. Let $A = [0, 1/2)$. Then $\\lambda(A) = 1/2$. For $n \\in \\mathbb{N}$, set $\\alpha_n = n\\theta \\bmod 1 \\in [0,1)$. Because $R_\\theta^{-n}A = \\{ x : x + n\\theta \\bmod 1 \\in A \\} = A - \\alpha_n \\pmod 1$, we have\n$$\n\\lambda(A \\cap R_\\theta^{-n}A) = \\lambda\\big( A \\cap (A - \\alpha_n) \\big).\n$$\nDefine $f(\\alpha) = \\lambda( A \\cap (A - \\alpha) )$ for $\\alpha \\in [0,1)$. A direct computation yields:\n- If $0 \\le \\alpha \\le \\frac12$, then $A \\cap (A - \\alpha) = [0, \\frac12 - \\alpha)$ and $f(\\alpha) = \\frac12 - \\alpha$.\n- If $\\frac12 \\le \\alpha \\le 1$, then $A \\cap (A - \\alpha) = [1-\\alpha, \\frac12)$ and $f(\\alpha) = \\alpha - \\frac12$.\n\nThus $f$ is continuous on $[0,1)$ with $f(0) = \\frac12$, $f(\\frac12) = 0$, and $f(1^-) = \\frac12$ (by periodicity).\n\nSince $\\theta$ is irrational, the sequence $\\{\\alpha_n\\}_{n\\ge 1}$ is dense in $[0,1)$. Hence there exists a subsequence $n_k$ such that $\\alpha_{n_k} \\to 0$, and another subsequence $m_k$ such that $\\alpha_{m_k} \\to \\frac12$. By continuity of $f$,\n$$\n\\lim_{k\\to\\infty} \\lambda(A \\cap R_\\theta^{-n_k}A) = f(0) = \\frac12,\n\\qquad\n\\lim_{k\\to\\infty} \\lambda(A \\cap R_\\theta^{-m_k}A) = f(\\tfrac12) = 0.\n$$\nIf $R_\\theta$ were strong mixing, we would have\n$$\n\\lim_{n\\to\\infty} \\lambda(A \\cap R_\\theta^{-n}A) = \\lambda(A)\\lambda(A) = \\frac14,\n$$\nbut the above limits show that the limit does not exist (or at least has subsequential limits different from $\\frac14$). Therefore $R_\\theta$ is not strong mixing.\n\n**Solution (c): Unique ergodicity**\n\nLet $\\mu$ be any Borel probability measure on $[0,1)$ invariant under $R_\\theta$. Consider its Fourier coefficients\n$$\n\\hat{\\mu}(k) = \\int_0^1 e^{-2\\pi i k x}\\, d\\mu(x), \\qquad k \\in \\mathbb{Z}.\n$$\nInvariance $\\mu = \\mu \\circ R_\\theta^{-1}$ implies that for every $k$,\n$$\n\\hat{\\mu}(k) = \\int e^{-2\\pi i k (x+\\theta)}\\, d\\mu(x) = e^{-2\\pi i k \\theta} \\hat{\\mu}(k).\n$$\nThus $(1 - e^{-2\\pi i k \\theta})\\hat{\\mu}(k) = 0$. For $k \\neq 0$, $e^{-2\\pi i k \\theta} \\neq 1$ (because $\\theta$ is irrational), so $\\hat{\\mu}(k) = 0$. For $k = 0$, $\\hat{\\mu}(0) = \\mu([0,1)) = 1$.\n\nLebesgue measure $\\lambda$ has Fourier coefficients $\\hat{\\lambda}(k) = 0$ for $k \\neq 0$ and $\\hat{\\lambda}(0)=1$. Hence $\\hat{\\mu}(k) = \\hat{\\lambda}(k)$ for all $k \\in \\mathbb{Z}$.\n\nTo conclude $\\mu = \\lambda$, we use the fact that trigonometric polynomials are dense in the space of continuous functions on the circle (Stone\u2013Weierstrass). For any continuous function $g$ on $[0,1]$, choose a sequence of trigonometric polynomials $p_n$ converging uniformly to $g$. Then\n$$\n\\int g \\, d\\mu = \\lim_{n\\to\\infty} \\int p_n \\, d\\mu = \\lim_{n\\to\\infty} \\int p_n \\, d\\lambda = \\int g \\, d\\lambda,\n$$\nwhere the middle equality holds because $\\int p_n \\, d\\mu$ and $\\int p_n \\, d\\lambda$ are linear combinations of the Fourier coefficients, which coincide. By the Riesz representation theorem, two Borel probability measures that agree on all continuous functions are identical. Hence $\\mu = \\lambda$.\n\nThus $\\lambda$ is the unique $R_\\theta$-invariant Borel probability measure, i.e., $R_\\theta$ is uniquely ergodic.\n\n\u220e\n[/ANSWER]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "25",
    "outer_attempt": 1,
    "topic_slug": "difference_and_functional_equations",
    "topic_name": "Difference and functional equations",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Find all functions $f: \\mathbb{R} \\to \\mathbb{R}$ such that\n$$\nf(x f(y) + f(x)) = f(x) f(y) + x\n$$\nfor all real numbers $x, y$.",
            "answer": "We will determine all functions satisfying the given equation.\n\n\\noindent \\textbf{Step 1. Determine $f(0)$.}\nPut $x = 0$ in the equation:\n$$\nf(0\\cdot f(y) + f(0)) = f(0) f(y) + 0 \\quad\\Longrightarrow\\quad f(f(0)) = f(0) f(y) \\quad \\forall y\\in\\mathbb{R}.\n$$\nThe left-hand side is constant (call it $C = f(f(0))$), while the right-hand side is $f(0) f(y)$. If $f(0) \\neq 0$, then $f(y) = C/f(0)$ is constant, say $f(y) = c$ for all $y$. Substituting into the original equation gives\n$$\nc = c^2 + x \\quad \\forall x\\in\\mathbb{R},\n$$\nwhich is impossible. Hence $f(0) = 0$.\n\n\\noindent \\textbf{Step 2. Obtain an involution.}\nNow put $y = 0$:\n$$\nf(x f(0) + f(x)) = f(x) f(0) + x \\quad\\Longrightarrow\\quad f(f(x)) = x \\quad \\forall x\\in\\mathbb{R}.\n$$\nThus $f$ is an involution; in particular, it is bijective (its own inverse).\n\n\\noindent \\textbf{Step 3. Simplify the equation.}\nBecause $f$ is surjective, for any $z \\in \\mathbb{R}$ there exists a $y$ with $z = f(y)$. Replacing $y$ by such a $y$ in the original equation and using $f(f(y)) = y$, we obtain\n$$\nf(x y + f(x)) = f(x) y + x \\qquad \\forall x, y \\in \\mathbb{R}. \\tag{1}\n$$\n\n\\noindent \\textbf{Step 4. Exploit a special value.}\nIn (1) set $x = 1$. Let $a = f(1)$. Then\n$$\nf(y + a) = a y + 1 \\qquad \\forall y \\in \\mathbb{R}. \\tag{2}\n$$\n\n\\noindent \\textbf{Step 5. Deduce the form of $f$.}\nEquation (2) shows that $f$ is affine. Indeed, for any $t \\in \\mathbb{R}$ take $y = t - a$ to get\n$$\nf(t) = a (t - a) + 1 = a t + 1 - a^2. \\tag{3}\n$$\n\n\\noindent \\textbf{Step 6. Use $f(0)=0$ to determine $a$.}\nSubstituting $t = 0$ into (3) and recalling $f(0)=0$ gives\n$$\n0 = 1 - a^2 \\quad\\Longrightarrow\\quad a^2 = 1 \\quad\\Longrightarrow\\quad a = 1 \\;\\text{or}\\; a = -1.\n$$\nThen (3) reduces to $f(t) = a t$, i.e. either $f(t) = t$ or $f(t) = -t$.\n\n\\noindent \\textbf{Step 7. Verification.}\nBoth functions satisfy the original equation:\n\\begin{itemize}\n\\item If $f(x) = x$, then $f(x f(y) + f(x)) = x y + x = f(x) f(y) + x$.\n\\item If $f(x) = -x$, then $f(x f(y) + f(x)) = f(-x y - x) = -(-x y - x) = x y + x = (-x)(-y) + x = f(x) f(y) + x$.\n\\end{itemize}\n\n\\noindent Hence the only solutions are\n$$\n\\boxed{f(x) = x \\quad \\forall x\\in\\mathbb{R}} \\qquad \\text{and} \\qquad \\boxed{f(x) = -x \\quad \\forall x\\in\\mathbb{R}}.\n$$",
            "raw_answer": "[QUESTION]\nFind all functions \\(f: \\mathbb{R} \\to \\mathbb{R}\\) such that\n\\[\nf(x f(y) + f(x)) = f(x) f(y) + x\n\\]\nfor all real numbers \\(x, y\\).\n\n[ANSWER]\nWe will determine all functions satisfying the given equation.\n\n\\noindent \\textbf{Step 1. Determine \\(f(0)\\).}\nPut \\(x = 0\\) in the equation:\n\\[\nf(0\\cdot f(y) + f(0)) = f(0) f(y) + 0 \\quad\\Longrightarrow\\quad f(f(0)) = f(0) f(y) \\quad \\forall y\\in\\mathbb{R}.\n\\]\nThe left-hand side is constant (call it \\(C = f(f(0))\\)), while the right-hand side is \\(f(0) f(y)\\). If \\(f(0) \\neq 0\\), then \\(f(y) = C/f(0)\\) is constant, say \\(f(y) = c\\) for all \\(y\\). Substituting into the original equation gives\n\\[\nc = c^2 + x \\quad \\forall x\\in\\mathbb{R},\n\\]\nwhich is impossible. Hence \\(f(0) = 0\\).\n\n\\noindent \\textbf{Step 2. Obtain an involution.}\nNow put \\(y = 0\\):\n\\[\nf(x f(0) + f(x)) = f(x) f(0) + x \\quad\\Longrightarrow\\quad f(f(x)) = x \\quad \\forall x\\in\\mathbb{R}.\n\\]\nThus \\(f\\) is an involution; in particular, it is bijective (its own inverse).\n\n\\noindent \\textbf{Step 3. Simplify the equation.}\nBecause \\(f\\) is surjective, for any \\(z \\in \\mathbb{R}\\) there exists a \\(y\\) with \\(z = f(y)\\). Replacing \\(y\\) by such a \\(y\\) in the original equation and using \\(f(f(y)) = y\\), we obtain\n\\[\nf(x y + f(x)) = f(x) y + x \\qquad \\forall x, y \\in \\mathbb{R}. \\tag{1}\n\\]\n\n\\noindent \\textbf{Step 4. Exploit a special value.}\nIn (1) set \\(x = 1\\). Let \\(a = f(1)\\). Then\n\\[\nf(y + a) = a y + 1 \\qquad \\forall y \\in \\mathbb{R}. \\tag{2}\n\\]\n\n\\noindent \\textbf{Step 5. Deduce the form of \\(f\\).}\nEquation (2) shows that \\(f\\) is affine. Indeed, for any \\(t \\in \\mathbb{R}\\) take \\(y = t - a\\) to get\n\\[\nf(t) = a (t - a) + 1 = a t + 1 - a^2. \\tag{3}\n\\]\n\n\\noindent \\textbf{Step 6. Use \\(f(0)=0\\) to determine \\(a\\).}\nSubstituting \\(t = 0\\) into (3) and recalling \\(f(0)=0\\) gives\n\\[\n0 = 1 - a^2 \\quad\\Longrightarrow\\quad a^2 = 1 \\quad\\Longrightarrow\\quad a = 1 \\;\\text{or}\\; a = -1.\n\\]\nThen (3) reduces to \\(f(t) = a t\\), i.e. either \\(f(t) = t\\) or \\(f(t) = -t\\).\n\n\\noindent \\textbf{Step 7. Verification.}\nBoth functions satisfy the original equation:\n\\begin{itemize}\n\\item If \\(f(x) = x\\), then \\(f(x f(y) + f(x)) = x y + x = f(x) f(y) + x\\).\n\\item If \\(f(x) = -x\\), then \\(f(x f(y) + f(x)) = f(-x y - x) = -(-x y - x) = x y + x = (-x)(-y) + x = f(x) f(y) + x\\).\n\\end{itemize}\n\n\\noindent Hence the only solutions are\n\\[\n\\boxed{f(x) = x \\quad \\forall x\\in\\mathbb{R}} \\qquad \\text{and} \\qquad \\boxed{f(x) = -x \\quad \\forall x\\in\\mathbb{R}}.\n\\]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "26",
    "outer_attempt": 1,
    "topic_slug": "sequences_series_and_summability",
    "topic_name": "Sequences, series, summability",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Evaluate the series\n$$\n\\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1} H_n}{n},\n$$\nwhere $H_n = \\sum_{k=1}^{n} \\frac{1}{k}$ denotes the $n$-th harmonic number. Provide the exact value in closed form.",
            "answer": "We compute $S = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1} H_n}{n}$.\n\n**1. Convergence.** The series converges conditionally by the alternating series test because $H_n = \\ln n + \\gamma + o(1)$ and $\\frac{\\ln n}{n}$ eventually decreases to zero.\n\n**2. Abel representation.** Since the series converges, Abel's theorem gives\n$$\nS = \\lim_{r \\to 1^-} \\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1} H_n}{n} \\, r^n .\n$$\n\n**3. Integral form of the power series.** For any $0 \\le r < 1$,\n$$\n\\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1} H_n}{n} r^n\n= \\sum_{n=1}^{\\infty} (-1)^{n-1} H_n \\int_0^r x^{n-1} \\, dx\n= \\int_0^r \\sum_{n=1}^{\\infty} (-1)^{n-1} H_n x^{n-1} \\, dx .\n$$\nThe interchange of sum and integral is justified because on $[0,r]$ the series converges uniformly: for $x \\in [0,r]$, $|(-1)^{n-1} H_n x^{n-1}| \\le H_n r^{n-1}$ and $\\sum H_n r^{n-1}$ converges by the ratio test. Hence,\n$$\n\\int_0^r \\sum_{n=1}^{\\infty} (-1)^{n-1} H_n x^{n-1} \\, dx\n= \\int_0^r \\frac{1}{x} \\sum_{n=1}^{\\infty} (-1)^{n-1} H_n x^n \\, dx .\n$$\n\n**4. Generating function for harmonic numbers.** For $|t|<1$,\n$$\n\\sum_{n=1}^{\\infty} H_n t^n = -\\frac{\\ln(1-t)}{1-t}.\n$$\nSetting $t = -x$ (with $0 \\le x < 1$) yields\n$$\n\\sum_{n=1}^{\\infty} H_n (-x)^n = -\\frac{\\ln(1+x)}{1+x}.\n$$\nNoting that $(-1)^{n-1} H_n x^n = - H_n (-x)^n$, we obtain\n$$\n\\sum_{n=1}^{\\infty} (-1)^{n-1} H_n x^n = - \\sum_{n=1}^{\\infty} H_n (-x)^n = \\frac{\\ln(1+x)}{1+x}.\n$$\n\n**5. Integral expression for $S$.** Substituting this into the integral,\n$$\n\\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1} H_n}{n} r^n\n= \\int_0^r \\frac{1}{x} \\cdot \\frac{\\ln(1+x)}{1+x} \\, dx\n= \\int_0^r \\frac{\\ln(1+x)}{x(1+x)} \\, dx .\n$$\nTaking the limit $r \\to 1^-$ and observing that the integrand is continuous on $[0,1]$ (with the value at $x=0$ defined as $1$ and at $x=1$ as $\\frac{\\ln 2}{2}$), we get\n$$\nS = \\int_0^1 \\frac{\\ln(1+x)}{x(1+x)} \\, dx .\n$$\n\n**6. Decomposition of the integral.** Write\n$$\n\\frac{1}{x(1+x)} = \\frac{1}{x} - \\frac{1}{1+x},\n$$\nso that\n$$\nS = \\int_0^1 \\frac{\\ln(1+x)}{x} \\, dx - \\int_0^1 \\frac{\\ln(1+x)}{1+x} \\, dx = I_1 - I_2.\n$$\n\n**7. Evaluation of $I_1$.** Expand $\\ln(1+x)$ in a power series for $|x|<1$:\n$$\n\\ln(1+x) = \\sum_{k=1}^{\\infty} \\frac{(-1)^{k-1}}{k} x^k .\n$$\nThen\n$$\n\\frac{\\ln(1+x)}{x} = \\sum_{k=1}^{\\infty} \\frac{(-1)^{k-1}}{k} x^{k-1}.\n$$\nIntegrate termwise on $[0,1]$ (justified by uniform convergence on $[0,1-\\varepsilon]$ and Abel's theorem for the endpoint):\n$$\nI_1 = \\sum_{k=1}^{\\infty} \\frac{(-1)^{k-1}}{k} \\int_0^1 x^{k-1} \\, dx\n= \\sum_{k=1}^{\\infty} \\frac{(-1)^{k-1}}{k^2}\n= \\frac{\\pi^2}{12}.\n$$\n\n**8. Evaluation of $I_2$.** Substitute $u = 1+x$, $du = dx$:\n$$\nI_2 = \\int_1^2 \\frac{\\ln u}{u} \\, du\n= \\left[ \\frac{1}{2} (\\ln u)^2 \\right]_1^2\n= \\frac{1}{2} (\\ln 2)^2.\n$$\n\n**9. Final result.**\n$$\nS = I_1 - I_2 = \\frac{\\pi^2}{12} - \\frac{1}{2} (\\ln 2)^2.\n$$\n\n$$\n\\boxed{\\dfrac{\\pi^{2}}{12} - \\dfrac{1}{2} (\\ln 2)^{2}}\n$$",
            "raw_answer": "[QUESTION]\nEvaluate the series\n\\[\n\\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1} H_n}{n},\n\\]\nwhere \\(H_n = \\sum_{k=1}^{n} \\frac{1}{k}\\) denotes the \\(n\\)-th harmonic number. Provide the exact value in closed form.\n\n[ANSWER]\nWe compute \\(S = \\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1} H_n}{n}\\).\n\n**1. Convergence.** The series converges conditionally by the alternating series test because \\(H_n = \\ln n + \\gamma + o(1)\\) and \\(\\frac{\\ln n}{n}\\) eventually decreases to zero.\n\n**2. Abel representation.** Since the series converges, Abel's theorem gives\n\\[\nS = \\lim_{r \\to 1^-} \\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1} H_n}{n} \\, r^n .\n\\]\n\n**3. Integral form of the power series.** For any \\(0 \\le r < 1\\),\n\\[\n\\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1} H_n}{n} r^n\n= \\sum_{n=1}^{\\infty} (-1)^{n-1} H_n \\int_0^r x^{n-1} \\, dx\n= \\int_0^r \\sum_{n=1}^{\\infty} (-1)^{n-1} H_n x^{n-1} \\, dx .\n\\]\nThe interchange of sum and integral is justified because on \\([0,r]\\) the series converges uniformly: for \\(x \\in [0,r]\\), \\(|(-1)^{n-1} H_n x^{n-1}| \\le H_n r^{n-1}\\) and \\(\\sum H_n r^{n-1}\\) converges by the ratio test. Hence,\n\\[\n\\int_0^r \\sum_{n=1}^{\\infty} (-1)^{n-1} H_n x^{n-1} \\, dx\n= \\int_0^r \\frac{1}{x} \\sum_{n=1}^{\\infty} (-1)^{n-1} H_n x^n \\, dx .\n\\]\n\n**4. Generating function for harmonic numbers.** For \\(|t|<1\\),\n\\[\n\\sum_{n=1}^{\\infty} H_n t^n = -\\frac{\\ln(1-t)}{1-t}.\n\\]\nSetting \\(t = -x\\) (with \\(0 \\le x < 1\\)) yields\n\\[\n\\sum_{n=1}^{\\infty} H_n (-x)^n = -\\frac{\\ln(1+x)}{1+x}.\n\\]\nNoting that \\((-1)^{n-1} H_n x^n = - H_n (-x)^n\\), we obtain\n\\[\n\\sum_{n=1}^{\\infty} (-1)^{n-1} H_n x^n = - \\sum_{n=1}^{\\infty} H_n (-x)^n = \\frac{\\ln(1+x)}{1+x}.\n\\]\n\n**5. Integral expression for \\(S\\).** Substituting this into the integral,\n\\[\n\\sum_{n=1}^{\\infty} \\frac{(-1)^{n-1} H_n}{n} r^n\n= \\int_0^r \\frac{1}{x} \\cdot \\frac{\\ln(1+x)}{1+x} \\, dx\n= \\int_0^r \\frac{\\ln(1+x)}{x(1+x)} \\, dx .\n\\]\nTaking the limit \\(r \\to 1^-\\) and observing that the integrand is continuous on \\([0,1]\\) (with the value at \\(x=0\\) defined as \\(1\\) and at \\(x=1\\) as \\(\\frac{\\ln 2}{2}\\)), we get\n\\[\nS = \\int_0^1 \\frac{\\ln(1+x)}{x(1+x)} \\, dx .\n\\]\n\n**6. Decomposition of the integral.** Write\n\\[\n\\frac{1}{x(1+x)} = \\frac{1}{x} - \\frac{1}{1+x},\n\\]\nso that\n\\[\nS = \\int_0^1 \\frac{\\ln(1+x)}{x} \\, dx - \\int_0^1 \\frac{\\ln(1+x)}{1+x} \\, dx = I_1 - I_2.\n\\]\n\n**7. Evaluation of \\(I_1\\).** Expand \\(\\ln(1+x)\\) in a power series for \\(|x|<1\\):\n\\[\n\\ln(1+x) = \\sum_{k=1}^{\\infty} \\frac{(-1)^{k-1}}{k} x^k .\n\\]\nThen\n\\[\n\\frac{\\ln(1+x)}{x} = \\sum_{k=1}^{\\infty} \\frac{(-1)^{k-1}}{k} x^{k-1}.\n\\]\nIntegrate termwise on \\([0,1]\\) (justified by uniform convergence on \\([0,1-\\varepsilon]\\) and Abel's theorem for the endpoint):\n\\[\nI_1 = \\sum_{k=1}^{\\infty} \\frac{(-1)^{k-1}}{k} \\int_0^1 x^{k-1} \\, dx\n= \\sum_{k=1}^{\\infty} \\frac{(-1)^{k-1}}{k^2}\n= \\frac{\\pi^2}{12}.\n\\]\n\n**8. Evaluation of \\(I_2\\).** Substitute \\(u = 1+x\\), \\(du = dx\\):\n\\[\nI_2 = \\int_1^2 \\frac{\\ln u}{u} \\, du\n= \\left[ \\frac{1}{2} (\\ln u)^2 \\right]_1^2\n= \\frac{1}{2} (\\ln 2)^2.\n\\]\n\n**9. Final result.**\n\\[\nS = I_1 - I_2 = \\frac{\\pi^2}{12} - \\frac{1}{2} (\\ln 2)^2.\n\\]\n\n\\[\n\\boxed{\\dfrac{\\pi^{2}}{12} - \\dfrac{1}{2} (\\ln 2)^{2}}\n\\]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "27",
    "outer_attempt": 1,
    "topic_slug": "approximations_and_expansions",
    "topic_name": "Approximations and expansions",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Find the first three terms in the asymptotic expansion (in powers of $1/n$) of\n$$\nT_n = \\sum_{k=1}^{n} \\frac{1}{n^2 + k^2}\n$$\nas $n \\to \\infty$. Express the coefficients in simplest form.\n[/QUESTION]",
            "answer": "We derive the expansion using the Euler\u2013Maclaurin summation formula.\n\nLet $h = 1/n$ and define $f(x) = \\dfrac{1}{1+x^2}$. Then\n$$\nT_n = \\frac{1}{n^2} \\sum_{k=1}^{n} f(kh).\n$$\n\nWe first obtain an asymptotic expansion for $S_n := \\sum_{k=1}^{n} f(kh)$. Start from the standard Euler\u2013Maclaurin formula for a smooth function on an interval with equally spaced points:\n$$\n\\sum_{k=0}^{n} f(kh) = \\frac{1}{h} \\int_{0}^{1} f(x)\\,dx + \\frac{f(0)+f(1)}{2} + \\sum_{j=1}^{\\infty} \\frac{B_{2j}}{(2j)!} h^{2j-1} \\bigl( f^{(2j-1)}(1) - f^{(2j-1)}(0) \\bigr),\n$$\nwhere $B_{2j}$ are the even-index Bernoulli numbers. Subtracting $f(0)$ from both sides gives\n$$\nS_n = \\sum_{k=1}^{n} f(kh) = n \\int_{0}^{1} f(x)\\,dx + \\frac{f(1)-f(0)}{2} + \\sum_{j=1}^{\\infty} \\frac{B_{2j}}{(2j)!} h^{2j-1} \\bigl( f^{(2j-1)}(1) - f^{(2j-1)}(0) \\bigr). \\tag{1}\n$$\n\nNow compute the required quantities.\n\n- Integral:\n$$\nI := \\int_{0}^{1} f(x)\\,dx = \\int_{0}^{1} \\frac{dx}{1+x^2} = \\arctan x \\,\\Big|_{0}^{1} = \\frac{\\pi}{4}.\n$$\n\n- Endpoint values:\n$$\nf(0) = 1, \\qquad f(1) = \\frac{1}{2}, \\quad \\text{so} \\quad \\frac{f(1)-f(0)}{2} = -\\frac{1}{4}.\n$$\n\n- First derivative:\n$$\nf'(x) = -\\frac{2x}{(1+x^2)^2}, \\qquad f'(0) = 0,\\; f'(1) = -\\frac{2}{(1+1)^2} = -\\frac{1}{2}.\n$$\nThus $f'(1)-f'(0) = -\\frac{1}{2}$.\n\n- Bernoulli number: $B_2 = \\dfrac{1}{6}$, and $\\dfrac{B_2}{2!} = \\dfrac{1}{12}$.\n\nThe $j=1$ term in the sum in (1) is\n$$\n\\frac{B_2}{2!} h^{1} \\bigl( f'(1)-f'(0) \\bigr) = \\frac{1}{12} \\cdot \\frac{1}{n} \\cdot \\left(-\\frac{1}{2}\\right) = -\\frac{1}{24 n}.\n$$\n\nTerms with $j \\ge 2$ involve $h^{2j-1} = 1/n^{2j-1}$ which are at least $1/n^3$. Hence we can write\n$$\nS_n = n \\cdot \\frac{\\pi}{4} - \\frac{1}{4} - \\frac{1}{24 n} + O\\!\\left(\\frac{1}{n^{3}}\\right).\n$$\n\nNow substitute into $T_n = S_n / n^2$:\n$$\nT_n = \\frac{1}{n^2} \\left( \\frac{\\pi n}{4} - \\frac{1}{4} - \\frac{1}{24 n} + O\\!\\left(\\frac{1}{n^{3}}\\right) \\right)\n= \\frac{\\pi}{4n} - \\frac{1}{4 n^2} - \\frac{1}{24 n^3} + O\\!\\left(\\frac{1}{n^{5}}\\right).\n$$\nThe error becomes $O(1/n^5)$ because the next correction from $S_n$ is of order $1/n^3$, and dividing by $n^2$ yields $1/n^5$.\n\nTherefore, the first three terms in the asymptotic expansion of $T_n$ are\n$$\n\\boxed{\\dfrac{\\pi}{4n} - \\dfrac{1}{4 n^2} - \\dfrac{1}{24 n^3}}.\n$$\n\n(One could compute further terms by evaluating higher derivatives and Bernoulli numbers; the next term is of order $1/n^5$.)\n[/ANSWER]",
            "raw_answer": "[QUESTION]\nFind the first three terms in the asymptotic expansion (in powers of \\(1/n\\)) of\n\\[\nT_n = \\sum_{k=1}^{n} \\frac{1}{n^2 + k^2}\n\\]\nas \\(n \\to \\infty\\). Express the coefficients in simplest form.\n[/QUESTION]\n\n[ANSWER]\nWe derive the expansion using the Euler\u2013Maclaurin summation formula.\n\nLet \\(h = 1/n\\) and define \\(f(x) = \\dfrac{1}{1+x^2}\\). Then\n\\[\nT_n = \\frac{1}{n^2} \\sum_{k=1}^{n} f(kh).\n\\]\n\nWe first obtain an asymptotic expansion for \\(S_n := \\sum_{k=1}^{n} f(kh)\\). Start from the standard Euler\u2013Maclaurin formula for a smooth function on an interval with equally spaced points:\n\\[\n\\sum_{k=0}^{n} f(kh) = \\frac{1}{h} \\int_{0}^{1} f(x)\\,dx + \\frac{f(0)+f(1)}{2} + \\sum_{j=1}^{\\infty} \\frac{B_{2j}}{(2j)!} h^{2j-1} \\bigl( f^{(2j-1)}(1) - f^{(2j-1)}(0) \\bigr),\n\\]\nwhere \\(B_{2j}\\) are the even-index Bernoulli numbers. Subtracting \\(f(0)\\) from both sides gives\n\\[\nS_n = \\sum_{k=1}^{n} f(kh) = n \\int_{0}^{1} f(x)\\,dx + \\frac{f(1)-f(0)}{2} + \\sum_{j=1}^{\\infty} \\frac{B_{2j}}{(2j)!} h^{2j-1} \\bigl( f^{(2j-1)}(1) - f^{(2j-1)}(0) \\bigr). \\tag{1}\n\\]\n\nNow compute the required quantities.\n\n- Integral:\n\\[\nI := \\int_{0}^{1} f(x)\\,dx = \\int_{0}^{1} \\frac{dx}{1+x^2} = \\arctan x \\,\\Big|_{0}^{1} = \\frac{\\pi}{4}.\n\\]\n\n- Endpoint values:\n\\[\nf(0) = 1, \\qquad f(1) = \\frac{1}{2}, \\quad \\text{so} \\quad \\frac{f(1)-f(0)}{2} = -\\frac{1}{4}.\n\\]\n\n- First derivative:\n\\[\nf'(x) = -\\frac{2x}{(1+x^2)^2}, \\qquad f'(0) = 0,\\; f'(1) = -\\frac{2}{(1+1)^2} = -\\frac{1}{2}.\n\\]\nThus \\(f'(1)-f'(0) = -\\frac{1}{2}\\).\n\n- Bernoulli number: \\(B_2 = \\dfrac{1}{6}\\), and \\(\\dfrac{B_2}{2!} = \\dfrac{1}{12}\\).\n\nThe \\(j=1\\) term in the sum in (1) is\n\\[\n\\frac{B_2}{2!} h^{1} \\bigl( f'(1)-f'(0) \\bigr) = \\frac{1}{12} \\cdot \\frac{1}{n} \\cdot \\left(-\\frac{1}{2}\\right) = -\\frac{1}{24 n}.\n\\]\n\nTerms with \\(j \\ge 2\\) involve \\(h^{2j-1} = 1/n^{2j-1}\\) which are at least \\(1/n^3\\). Hence we can write\n\\[\nS_n = n \\cdot \\frac{\\pi}{4} - \\frac{1}{4} - \\frac{1}{24 n} + O\\!\\left(\\frac{1}{n^{3}}\\right).\n\\]\n\nNow substitute into \\(T_n = S_n / n^2\\):\n\\[\nT_n = \\frac{1}{n^2} \\left( \\frac{\\pi n}{4} - \\frac{1}{4} - \\frac{1}{24 n} + O\\!\\left(\\frac{1}{n^{3}}\\right) \\right)\n= \\frac{\\pi}{4n} - \\frac{1}{4 n^2} - \\frac{1}{24 n^3} + O\\!\\left(\\frac{1}{n^{5}}\\right).\n\\]\nThe error becomes \\(O(1/n^5)\\) because the next correction from \\(S_n\\) is of order \\(1/n^3\\), and dividing by \\(n^2\\) yields \\(1/n^5\\).\n\nTherefore, the first three terms in the asymptotic expansion of \\(T_n\\) are\n\\[\n\\boxed{\\dfrac{\\pi}{4n} - \\dfrac{1}{4 n^2} - \\dfrac{1}{24 n^3}}.\n\\]\n\n(One could compute further terms by evaluating higher derivatives and Bernoulli numbers; the next term is of order \\(1/n^5\\).)\n[/ANSWER]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "28",
    "outer_attempt": 1,
    "topic_slug": "harmonic_analysis_on_euclidean_spaces",
    "topic_name": "Harmonic analysis on Euclidean spaces",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $f \\in L^2(\\mathbb{R})$ be a function with compact support, i.e., there exists $A > 0$ such that $f(x) = 0$ for almost every $|x| > A$. Define its Fourier transform by\n$$\n\\hat f(\\xi) = \\int_{\\mathbb{R}} f(x) e^{-2\\pi i x \\xi} \\, dx,\n$$\nwhich is well-defined as an $L^1$ integral because $f$ is integrable on $[-A,A]$. Prove that if $\\hat f$ also has compact support (i.e., there exists $B > 0$ such that $\\hat f(\\xi) = 0$ for almost every $|\\xi| > B$), then $f$ must be zero almost everywhere. In other words, there is no nonzero $L^2$ function with both $f$ and $\\hat f$ compactly supported.",
            "answer": "We will show that the only function satisfying the hypotheses is $f = 0$ a.e.\n\n**Step 1: $\\hat f$ extends to an entire function.**  \nSince $\\operatorname{supp} f \\subseteq [-A, A]$, we can write\n$$\n\\hat f(\\xi) = \\int_{-A}^{A} f(x) e^{-2\\pi i x \\xi} \\, dx.\n$$\nFor any complex number $z \\in \\mathbb{C}$, define\n$$\nF(z) = \\int_{-A}^{A} f(x) e^{-2\\pi i x z} \\, dx.\n$$\nBecause $|e^{-2\\pi i x z}| = e^{2\\pi x \\operatorname{Im} z} \\le e^{2\\pi A |\\operatorname{Im} z|}$ for $x \\in [-A,A]$, the integrand is dominated by $|f(x)| e^{2\\pi A |\\operatorname{Im} z|}$, which is integrable over $[-A,A]$ since $f \\in L^1([-A,A])$. Hence the integral converges absolutely and uniformly on compact subsets of $\\mathbb{C}$. Moreover, one may differentiate under the integral sign with respect to $z$ (by standard theorems) to see that $F$ is complex differentiable everywhere; thus $F$ is an entire function. Clearly $F(\\xi) = \\hat f(\\xi)$ for $\\xi \\in \\mathbb{R}$, so $F$ is an entire extension of $\\hat f$.\n\n**Step 2: If $\\hat f$ has compact support on $\\mathbb{R}$, then $F \\equiv 0$.**  \nAssume there exists $B > 0$ such that $\\hat f(\\xi) = 0$ for almost every $|\\xi| > B$. Since $\\hat f$ is continuous (as the Fourier transform of an $L^1$ function), we actually have $\\hat f(\\xi) = 0$ for all $|\\xi| > B$. (If it vanished only almost everywhere, continuity would force it to vanish everywhere on the open set $|\\xi|>B$.) In particular, $\\hat f(\\xi) = 0$ for all $\\xi$ in the interval $(B+1, B+2)$. This interval is a set of points in $\\mathbb{C}$ with an accumulation point (indeed, every point is a limit point). Since $F$ is entire and coincides with $\\hat f$ on the real line, $F$ vanishes on that interval. By the identity theorem for analytic functions, an entire function that vanishes on a set with an accumulation point must be identically zero. Hence $F(z) = 0$ for all $z \\in \\mathbb{C}$, and consequently $\\hat f(\\xi) = 0$ for all $\\xi \\in \\mathbb{R}$.\n\n**Step 3: $\\hat f \\equiv 0$ implies $f = 0$ a.e.**  \nWe now have $\\hat f(\\xi) = 0$ for every $\\xi$. To recover $f$ from its Fourier transform, we use the injectivity of the Fourier transform on $L^1(\\mathbb{R})$. One way is to consider Schwartz test functions. For any Schwartz function $\\varphi \\in \\mathcal{S}(\\mathbb{R})$, the following identity holds (by Fubini's theorem and the definition of the Fourier transform):\n$$\n\\int_{\\mathbb{R}} f(x) \\hat\\varphi(x) \\, dx = \\int_{\\mathbb{R}} \\hat f(\\xi) \\varphi(\\xi) \\, d\\xi = 0,\n$$\nbecause $\\hat f \\equiv 0$. Since the Fourier transform is an automorphism of $\\mathcal{S}(\\mathbb{R})$, the set $\\{\\hat\\varphi : \\varphi \\in \\mathcal{S}(\\mathbb{R})\\}$ is exactly $\\mathcal{S}(\\mathbb{R})$ itself. Therefore,\n$$\n\\int_{\\mathbb{R}} f(x) \\psi(x) \\, dx = 0 \\quad \\text{for all } \\psi \\in \\mathcal{S}(\\mathbb{R}).\n$$\nThe Schwartz space is dense in $L^2(\\mathbb{R})$, and $f \\in L^2(\\mathbb{R})$, so this implies $f = 0$ in $L^2$, i.e., $f(x) = 0$ almost everywhere. (Alternatively, one could invoke the Fourier inversion theorem: because $f \\in L^1$ and $\\hat f \\in L^1$, the inversion formula gives $f(x) = \\int \\hat f(\\xi) e^{2\\pi i x \\xi} d\\xi = 0$ a.e.)\n\nThus the assumption that both $f$ and $\\hat f$ are compactly supported forces $f$ to be zero almost everywhere. Consequently, no nonzero $L^2$ function can have both itself and its Fourier transform compactly supported. \u220e",
            "raw_answer": "[QUESTION]\nLet $f \\in L^2(\\mathbb{R})$ be a function with compact support, i.e., there exists $A > 0$ such that $f(x) = 0$ for almost every $|x| > A$. Define its Fourier transform by\n\\[\n\\hat f(\\xi) = \\int_{\\mathbb{R}} f(x) e^{-2\\pi i x \\xi} \\, dx,\n\\]\nwhich is well-defined as an $L^1$ integral because $f$ is integrable on $[-A,A]$. Prove that if $\\hat f$ also has compact support (i.e., there exists $B > 0$ such that $\\hat f(\\xi) = 0$ for almost every $|\\xi| > B$), then $f$ must be zero almost everywhere. In other words, there is no nonzero $L^2$ function with both $f$ and $\\hat f$ compactly supported.\n\n[ANSWER]\nWe will show that the only function satisfying the hypotheses is $f = 0$ a.e.\n\n**Step 1: $\\hat f$ extends to an entire function.**  \nSince $\\operatorname{supp} f \\subseteq [-A, A]$, we can write\n\\[\n\\hat f(\\xi) = \\int_{-A}^{A} f(x) e^{-2\\pi i x \\xi} \\, dx.\n\\]\nFor any complex number $z \\in \\mathbb{C}$, define\n\\[\nF(z) = \\int_{-A}^{A} f(x) e^{-2\\pi i x z} \\, dx.\n\\]\nBecause $|e^{-2\\pi i x z}| = e^{2\\pi x \\operatorname{Im} z} \\le e^{2\\pi A |\\operatorname{Im} z|}$ for $x \\in [-A,A]$, the integrand is dominated by $|f(x)| e^{2\\pi A |\\operatorname{Im} z|}$, which is integrable over $[-A,A]$ since $f \\in L^1([-A,A])$. Hence the integral converges absolutely and uniformly on compact subsets of $\\mathbb{C}$. Moreover, one may differentiate under the integral sign with respect to $z$ (by standard theorems) to see that $F$ is complex differentiable everywhere; thus $F$ is an entire function. Clearly $F(\\xi) = \\hat f(\\xi)$ for $\\xi \\in \\mathbb{R}$, so $F$ is an entire extension of $\\hat f$.\n\n**Step 2: If $\\hat f$ has compact support on $\\mathbb{R}$, then $F \\equiv 0$.**  \nAssume there exists $B > 0$ such that $\\hat f(\\xi) = 0$ for almost every $|\\xi| > B$. Since $\\hat f$ is continuous (as the Fourier transform of an $L^1$ function), we actually have $\\hat f(\\xi) = 0$ for all $|\\xi| > B$. (If it vanished only almost everywhere, continuity would force it to vanish everywhere on the open set $|\\xi|>B$.) In particular, $\\hat f(\\xi) = 0$ for all $\\xi$ in the interval $(B+1, B+2)$. This interval is a set of points in $\\mathbb{C}$ with an accumulation point (indeed, every point is a limit point). Since $F$ is entire and coincides with $\\hat f$ on the real line, $F$ vanishes on that interval. By the identity theorem for analytic functions, an entire function that vanishes on a set with an accumulation point must be identically zero. Hence $F(z) = 0$ for all $z \\in \\mathbb{C}$, and consequently $\\hat f(\\xi) = 0$ for all $\\xi \\in \\mathbb{R}$.\n\n**Step 3: $\\hat f \\equiv 0$ implies $f = 0$ a.e.**  \nWe now have $\\hat f(\\xi) = 0$ for every $\\xi$. To recover $f$ from its Fourier transform, we use the injectivity of the Fourier transform on $L^1(\\mathbb{R})$. One way is to consider Schwartz test functions. For any Schwartz function $\\varphi \\in \\mathcal{S}(\\mathbb{R})$, the following identity holds (by Fubini's theorem and the definition of the Fourier transform):\n\\[\n\\int_{\\mathbb{R}} f(x) \\hat\\varphi(x) \\, dx = \\int_{\\mathbb{R}} \\hat f(\\xi) \\varphi(\\xi) \\, d\\xi = 0,\n\\]\nbecause $\\hat f \\equiv 0$. Since the Fourier transform is an automorphism of $\\mathcal{S}(\\mathbb{R})$, the set $\\{\\hat\\varphi : \\varphi \\in \\mathcal{S}(\\mathbb{R})\\}$ is exactly $\\mathcal{S}(\\mathbb{R})$ itself. Therefore,\n\\[\n\\int_{\\mathbb{R}} f(x) \\psi(x) \\, dx = 0 \\quad \\text{for all } \\psi \\in \\mathcal{S}(\\mathbb{R}).\n\\]\nThe Schwartz space is dense in $L^2(\\mathbb{R})$, and $f \\in L^2(\\mathbb{R})$, so this implies $f = 0$ in $L^2$, i.e., $f(x) = 0$ almost everywhere. (Alternatively, one could invoke the Fourier inversion theorem: because $f \\in L^1$ and $\\hat f \\in L^1$, the inversion formula gives $f(x) = \\int \\hat f(\\xi) e^{2\\pi i x \\xi} d\\xi = 0$ a.e.)\n\nThus the assumption that both $f$ and $\\hat f$ are compactly supported forces $f$ to be zero almost everywhere. Consequently, no nonzero $L^2$ function can have both itself and its Fourier transform compactly supported. \u220e",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "29",
    "outer_attempt": 1,
    "topic_slug": "abstract_harmonic_analysis",
    "topic_name": "Abstract harmonic analysis",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $G$ be a compact abelian group with normalized Haar measure $\\mu$ (i.e., $\\mu(G)=1$). Denote by $\\widehat{G}$ the dual group of continuous characters $\\chi: G \\to \\mathbb{T}$, where $\\mathbb{T} = \\{z \\in \\mathbb{C}: |z|=1\\}$. For a function $f \\in L^1(G)$, define its Fourier transform $\\widehat{f}: \\widehat{G} \\to \\mathbb{C}$ by\n$$\n\\widehat{f}(\\chi) = \\int_G f(g) \\overline{\\chi(g)} \\, d\\mu(g).\n$$\nRecall that the characters separate points of $G$: for any distinct $x,y \\in G$, there exists $\\chi \\in \\widehat{G}$ such that $\\chi(x) \\neq \\chi(y)$.\n\n(a) Show that the set $\\widehat{G}$ is an orthonormal set in $L^2(G)$; that is, for $\\chi, \\psi \\in \\widehat{G}$,\n$$\n\\langle \\chi, \\psi \\rangle = \\int_G \\chi(g) \\overline{\\psi(g)} \\, d\\mu(g) = \\delta_{\\chi,\\psi}.\n$$\n\n(b) Using the Stone\u2013Weierstrass theorem, prove that the linear span of $\\widehat{G}$ is dense in $C(G)$ with respect to the uniform norm $\\|f\\|_\\infty = \\sup_{g\\in G} |f(g)|$.\n\n(c) Conclude that $\\widehat{G}$ is an orthonormal basis for $L^2(G)$.\n\n(d) Deduce the Plancherel identity: for every $f \\in L^2(G)$,\n$$\n\\int_G |f(g)|^2 \\, d\\mu(g) = \\sum_{\\chi \\in \\widehat{G}} |\\widehat{f}(\\chi)|^2.\n$$\n\nMake sure to justify all steps, including the application of the Stone\u2013Weierstrass theorem and the density arguments.",
            "answer": "We will prove each part in turn.\n\n\\subsection*{(a) Orthonormality}\nLet $\\chi, \\psi \\in \\widehat{G}$. Compute\n$$\n\\langle \\chi, \\psi \\rangle = \\int_G \\chi(g) \\overline{\\psi(g)} \\, d\\mu(g).\n$$\nIf $\\chi = \\psi$, then $\\chi(g)\\overline{\\chi(g)} = |\\chi(g)|^2 = 1$ for all $g$, so\n$$\n\\langle \\chi, \\chi \\rangle = \\int_G 1 \\, d\\mu(g) = \\mu(G) = 1.\n$$\n\nNow suppose $\\chi \\neq \\psi$. Then there exists $a \\in G$ such that $\\chi(a) \\neq \\psi(a)$. Using the left-invariance of the Haar measure (which for an abelian group is also right-invariant), we have for any $a \\in G$:\n$$\n\\int_G \\chi(g) \\overline{\\psi(g)} \\, d\\mu(g) = \\int_G \\chi(ag) \\overline{\\psi(ag)} \\, d\\mu(g).\n$$\nIndeed, the map $g \\mapsto ag$ is a measure-preserving transformation. Since $\\chi$ and $\\psi$ are homomorphisms,\n$$\n\\chi(ag) \\overline{\\psi(ag)} = \\chi(a)\\chi(g) \\overline{\\psi(a)}\\,\\overline{\\psi(g)} = \\chi(a)\\overline{\\psi(a)} \\; \\chi(g)\\overline{\\psi(g)}.\n$$\nThus\n$$\nI := \\langle \\chi, \\psi \\rangle = \\chi(a)\\overline{\\psi(a)} \\int_G \\chi(g)\\overline{\\psi(g)} \\, d\\mu(g) = \\chi(a)\\overline{\\psi(a)} \\, I.\n$$\nBecause $\\chi(a) \\neq \\psi(a)$, we have $\\chi(a)\\overline{\\psi(a)} \\neq 1$. Hence $I = 0$. This shows orthonormality.\n\n\\subsection*{(b) Density in $C(G)$ via Stone\u2013Weierstrass}\nLet $\\mathcal{A} = \\operatorname{span}(\\widehat{G})$, the set of all finite linear combinations of characters. We check the hypotheses of the Stone\u2013Weierstrass theorem for complex algebras on the compact Hausdorff space $G$.\n\n\\begin{itemize}\n    \\item $\\mathcal{A}$ is a \\textbf{subalgebra} of $C(G)$: The product of two characters $\\chi,\\psi \\in \\widehat{G}$ is again a character because\n    $$\n    (\\chi\\psi)(gh) = \\chi(gh)\\psi(gh) = \\chi(g)\\chi(h)\\psi(g)\\psi(h) = (\\chi\\psi)(g)(\\chi\\psi)(h),\n    $$\n    and continuity is clear. Hence the product of any two elements of $\\mathcal{A}$ is a finite linear combination of characters and therefore belongs to $\\mathcal{A}$.\n    \\item $\\mathcal{A}$ contains the \\textbf{constant function} $1$: the trivial character $\\chi_0(g) \\equiv 1$ is in $\\widehat{G}$, so $1 \\in \\mathcal{A}$.\n    \\item $\\mathcal{A}$ is \\textbf{closed under complex conjugation}: For any character $\\chi$, $\\overline{\\chi(g)} = \\chi(g)^{-1} = \\chi(g^{-1})$ is also a continuous homomorphism, hence a character. Thus $\\overline{\\chi} \\in \\widehat{G}$, and conjugation of a linear combination stays in $\\mathcal{A}$.\n    \\item $\\mathcal{A}$ \\textbf{separates points}: By assumption, for any distinct $x,y \\in G$ there exists $\\chi \\in \\widehat{G}$ with $\\chi(x) \\neq \\chi(y)$. This character (as an element of $\\mathcal{A}$) separates $x$ and $y$.\n\\end{itemize}\n\nAll conditions of the (complex) Stone\u2013Weierstrass theorem are satisfied. Consequently, $\\mathcal{A}$ is dense in $C(G)$ with respect to the uniform norm $\\|\\cdot\\|_\\infty$.\n\n\\subsection*{(c) $\\widehat{G}$ is an orthonormal basis for $L^2(G)$}\nWe already know from (a) that $\\widehat{G}$ is an orthonormal set in $L^2(G)$. To prove it is an orthonormal basis, we must show that its closed linear span is all of $L^2(G)$.\n\nFirst, note that $C(G)$ is dense in $L^2(G)$: because $\\mu$ is a finite Borel measure on a compact space, continuous functions are dense in $L^p$ for $1 \\le p < \\infty$ (this follows from Lusin's theorem or from the fact that simple functions can be approximated by continuous functions due to Urysohn's lemma). In particular, for any $f \\in L^2(G)$ and $\\varepsilon > 0$, there exists $g \\in C(G)$ with $\\|f - g\\|_2 < \\varepsilon/2$.\n\nFrom part (b), $\\mathcal{A}$ is dense in $C(G)$ in the uniform norm. Since $\\mu(G)=1$, uniform convergence implies $L^2$ convergence: for any $h \\in C(G)$,\n$$\n\\|h\\|_2 = \\left( \\int_G |h|^2 \\, d\\mu \\right)^{1/2} \\le \\left( \\int_G \\|h\\|_\\infty^2 \\, d\\mu \\right)^{1/2} = \\|h\\|_\\infty.\n$$\nHence, given the $g$ above, we can pick $p \\in \\mathcal{A}$ such that $\\|g - p\\|_\\infty < \\varepsilon/2$, which yields $\\|g - p\\|_2 < \\varepsilon/2$. Then\n$$\n\\|f - p\\|_2 \\le \\|f - g\\|_2 + \\|g - p\\|_2 < \\varepsilon.\n$$\nThus $\\mathcal{A}$ is dense in $L^2(G)$. But $\\mathcal{A}$ is exactly the linear span of $\\widehat{G}$. Therefore the closed linear span of $\\widehat{G}$ is $L^2(G)$, and together with orthonormality this means $\\widehat{G}$ is an orthonormal basis for $L^2(G)$.\n\n\\subsection*{(d) Plancherel identity}\nLet $f \\in L^2(G)$. Since $\\widehat{G}$ is an orthonormal basis, we have the Fourier expansion\n$$\nf = \\sum_{\\chi \\in \\widehat{G}} \\langle f, \\chi \\rangle \\, \\chi,\n$$\nwhere the series converges in $L^2(G)$ and the coefficients are\n$$\n\\langle f, \\chi \\rangle = \\int_G f(g) \\overline{\\chi(g)} \\, d\\mu(g) = \\widehat{f}(\\chi).\n$$\nParseval's identity (or the Pythagorean theorem for orthonormal bases) gives\n$$\n\\|f\\|_2^2 = \\sum_{\\chi \\in \\widehat{G}} |\\langle f, \\chi \\rangle|^2.\n$$\nThat is,\n$$\n\\int_G |f(g)|^2 \\, d\\mu(g) = \\sum_{\\chi \\in \\widehat{G}} |\\widehat{f}(\\chi)|^2,\n$$\nwhich is the Plancherel identity. Note that the sum is understood as a sum over an orthonormal basis; for each $f$ only countably many terms are non\u2011zero and the series converges unconditionally.\n\nThis completes the proof.",
            "raw_answer": "[QUESTION]\nLet \\(G\\) be a compact abelian group with normalized Haar measure \\(\\mu\\) (i.e., \\(\\mu(G)=1\\)). Denote by \\(\\widehat{G}\\) the dual group of continuous characters \\(\\chi: G \\to \\mathbb{T}\\), where \\(\\mathbb{T} = \\{z \\in \\mathbb{C}: |z|=1\\}\\). For a function \\(f \\in L^1(G)\\), define its Fourier transform \\(\\widehat{f}: \\widehat{G} \\to \\mathbb{C}\\) by\n\\[\n\\widehat{f}(\\chi) = \\int_G f(g) \\overline{\\chi(g)} \\, d\\mu(g).\n\\]\nRecall that the characters separate points of \\(G\\): for any distinct \\(x,y \\in G\\), there exists \\(\\chi \\in \\widehat{G}\\) such that \\(\\chi(x) \\neq \\chi(y)\\).\n\n(a) Show that the set \\(\\widehat{G}\\) is an orthonormal set in \\(L^2(G)\\); that is, for \\(\\chi, \\psi \\in \\widehat{G}\\),\n\\[\n\\langle \\chi, \\psi \\rangle = \\int_G \\chi(g) \\overline{\\psi(g)} \\, d\\mu(g) = \\delta_{\\chi,\\psi}.\n\\]\n\n(b) Using the Stone\u2013Weierstrass theorem, prove that the linear span of \\(\\widehat{G}\\) is dense in \\(C(G)\\) with respect to the uniform norm \\(\\|f\\|_\\infty = \\sup_{g\\in G} |f(g)|\\).\n\n(c) Conclude that \\(\\widehat{G}\\) is an orthonormal basis for \\(L^2(G)\\).\n\n(d) Deduce the Plancherel identity: for every \\(f \\in L^2(G)\\),\n\\[\n\\int_G |f(g)|^2 \\, d\\mu(g) = \\sum_{\\chi \\in \\widehat{G}} |\\widehat{f}(\\chi)|^2.\n\\]\n\nMake sure to justify all steps, including the application of the Stone\u2013Weierstrass theorem and the density arguments.\n\n[ANSWER]\nWe will prove each part in turn.\n\n\\subsection*{(a) Orthonormality}\nLet \\(\\chi, \\psi \\in \\widehat{G}\\). Compute\n\\[\n\\langle \\chi, \\psi \\rangle = \\int_G \\chi(g) \\overline{\\psi(g)} \\, d\\mu(g).\n\\]\nIf \\(\\chi = \\psi\\), then \\(\\chi(g)\\overline{\\chi(g)} = |\\chi(g)|^2 = 1\\) for all \\(g\\), so\n\\[\n\\langle \\chi, \\chi \\rangle = \\int_G 1 \\, d\\mu(g) = \\mu(G) = 1.\n\\]\n\nNow suppose \\(\\chi \\neq \\psi\\). Then there exists \\(a \\in G\\) such that \\(\\chi(a) \\neq \\psi(a)\\). Using the left-invariance of the Haar measure (which for an abelian group is also right-invariant), we have for any \\(a \\in G\\):\n\\[\n\\int_G \\chi(g) \\overline{\\psi(g)} \\, d\\mu(g) = \\int_G \\chi(ag) \\overline{\\psi(ag)} \\, d\\mu(g).\n\\]\nIndeed, the map \\(g \\mapsto ag\\) is a measure-preserving transformation. Since \\(\\chi\\) and \\(\\psi\\) are homomorphisms,\n\\[\n\\chi(ag) \\overline{\\psi(ag)} = \\chi(a)\\chi(g) \\overline{\\psi(a)}\\,\\overline{\\psi(g)} = \\chi(a)\\overline{\\psi(a)} \\; \\chi(g)\\overline{\\psi(g)}.\n\\]\nThus\n\\[\nI := \\langle \\chi, \\psi \\rangle = \\chi(a)\\overline{\\psi(a)} \\int_G \\chi(g)\\overline{\\psi(g)} \\, d\\mu(g) = \\chi(a)\\overline{\\psi(a)} \\, I.\n\\]\nBecause \\(\\chi(a) \\neq \\psi(a)\\), we have \\(\\chi(a)\\overline{\\psi(a)} \\neq 1\\). Hence \\(I = 0\\). This shows orthonormality.\n\n\\subsection*{(b) Density in \\(C(G)\\) via Stone\u2013Weierstrass}\nLet \\(\\mathcal{A} = \\operatorname{span}(\\widehat{G})\\), the set of all finite linear combinations of characters. We check the hypotheses of the Stone\u2013Weierstrass theorem for complex algebras on the compact Hausdorff space \\(G\\).\n\n\\begin{itemize}\n    \\item \\(\\mathcal{A}\\) is a \\textbf{subalgebra} of \\(C(G)\\): The product of two characters \\(\\chi,\\psi \\in \\widehat{G}\\) is again a character because\n    \\[\n    (\\chi\\psi)(gh) = \\chi(gh)\\psi(gh) = \\chi(g)\\chi(h)\\psi(g)\\psi(h) = (\\chi\\psi)(g)(\\chi\\psi)(h),\n    \\]\n    and continuity is clear. Hence the product of any two elements of \\(\\mathcal{A}\\) is a finite linear combination of characters and therefore belongs to \\(\\mathcal{A}\\).\n    \\item \\(\\mathcal{A}\\) contains the \\textbf{constant function} \\(1\\): the trivial character \\(\\chi_0(g) \\equiv 1\\) is in \\(\\widehat{G}\\), so \\(1 \\in \\mathcal{A}\\).\n    \\item \\(\\mathcal{A}\\) is \\textbf{closed under complex conjugation}: For any character \\(\\chi\\), \\(\\overline{\\chi(g)} = \\chi(g)^{-1} = \\chi(g^{-1})\\) is also a continuous homomorphism, hence a character. Thus \\(\\overline{\\chi} \\in \\widehat{G}\\), and conjugation of a linear combination stays in \\(\\mathcal{A}\\).\n    \\item \\(\\mathcal{A}\\) \\textbf{separates points}: By assumption, for any distinct \\(x,y \\in G\\) there exists \\(\\chi \\in \\widehat{G}\\) with \\(\\chi(x) \\neq \\chi(y)\\). This character (as an element of \\(\\mathcal{A}\\)) separates \\(x\\) and \\(y\\).\n\\end{itemize}\n\nAll conditions of the (complex) Stone\u2013Weierstrass theorem are satisfied. Consequently, \\(\\mathcal{A}\\) is dense in \\(C(G)\\) with respect to the uniform norm \\(\\|\\cdot\\|_\\infty\\).\n\n\\subsection*{(c) \\(\\widehat{G}\\) is an orthonormal basis for \\(L^2(G)\\)}\nWe already know from (a) that \\(\\widehat{G}\\) is an orthonormal set in \\(L^2(G)\\). To prove it is an orthonormal basis, we must show that its closed linear span is all of \\(L^2(G)\\).\n\nFirst, note that \\(C(G)\\) is dense in \\(L^2(G)\\): because \\(\\mu\\) is a finite Borel measure on a compact space, continuous functions are dense in \\(L^p\\) for \\(1 \\le p < \\infty\\) (this follows from Lusin's theorem or from the fact that simple functions can be approximated by continuous functions due to Urysohn's lemma). In particular, for any \\(f \\in L^2(G)\\) and \\(\\varepsilon > 0\\), there exists \\(g \\in C(G)\\) with \\(\\|f - g\\|_2 < \\varepsilon/2\\).\n\nFrom part (b), \\(\\mathcal{A}\\) is dense in \\(C(G)\\) in the uniform norm. Since \\(\\mu(G)=1\\), uniform convergence implies \\(L^2\\) convergence: for any \\(h \\in C(G)\\),\n\\[\n\\|h\\|_2 = \\left( \\int_G |h|^2 \\, d\\mu \\right)^{1/2} \\le \\left( \\int_G \\|h\\|_\\infty^2 \\, d\\mu \\right)^{1/2} = \\|h\\|_\\infty.\n\\]\nHence, given the \\(g\\) above, we can pick \\(p \\in \\mathcal{A}\\) such that \\(\\|g - p\\|_\\infty < \\varepsilon/2\\), which yields \\(\\|g - p\\|_2 < \\varepsilon/2\\). Then\n\\[\n\\|f - p\\|_2 \\le \\|f - g\\|_2 + \\|g - p\\|_2 < \\varepsilon.\n\\]\nThus \\(\\mathcal{A}\\) is dense in \\(L^2(G)\\). But \\(\\mathcal{A}\\) is exactly the linear span of \\(\\widehat{G}\\). Therefore the closed linear span of \\(\\widehat{G}\\) is \\(L^2(G)\\), and together with orthonormality this means \\(\\widehat{G}\\) is an orthonormal basis for \\(L^2(G)\\).\n\n\\subsection*{(d) Plancherel identity}\nLet \\(f \\in L^2(G)\\). Since \\(\\widehat{G}\\) is an orthonormal basis, we have the Fourier expansion\n\\[\nf = \\sum_{\\chi \\in \\widehat{G}} \\langle f, \\chi \\rangle \\, \\chi,\n\\]\nwhere the series converges in \\(L^2(G)\\) and the coefficients are\n\\[\n\\langle f, \\chi \\rangle = \\int_G f(g) \\overline{\\chi(g)} \\, d\\mu(g) = \\widehat{f}(\\chi).\n\\]\nParseval's identity (or the Pythagorean theorem for orthonormal bases) gives\n\\[\n\\|f\\|_2^2 = \\sum_{\\chi \\in \\widehat{G}} |\\langle f, \\chi \\rangle|^2.\n\\]\nThat is,\n\\[\n\\int_G |f(g)|^2 \\, d\\mu(g) = \\sum_{\\chi \\in \\widehat{G}} |\\widehat{f}(\\chi)|^2,\n\\]\nwhich is the Plancherel identity. Note that the sum is understood as a sum over an orthonormal basis; for each \\(f\\) only countably many terms are non\u2011zero and the series converges unconditionally.\n\nThis completes the proof.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "30",
    "outer_attempt": 1,
    "topic_slug": "integral_transforms_and_operational_calculus",
    "topic_name": "Integral transforms, operational calculus",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Consider the integral equation\n$$\nf(x) + \\lambda \\int_{-\\infty}^{\\infty} e^{-|x-t|} f(t) \\, dt = e^{-|x|}, \\qquad x \\in \\mathbb{R},\n$$\nwhere $\\lambda$ is a real constant. Use the Fourier transform defined by\n$$\n\\hat{g}(\\omega) = \\int_{-\\infty}^{\\infty} g(x) e^{-i\\omega x} \\, dx,\n$$\nwith the inverse transform given by\n$$\ng(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\hat{g}(\\omega) e^{i\\omega x} \\, d\\omega.\n$$\nDetermine the range of $\\lambda$ for which the equation admits a solution, and find the solution $f(x)$ in closed form.",
            "answer": "We solve the equation by Fourier transform methods.\n\n1. **Rewrite as a convolution.**  \n   Let $k(x) = e^{-|x|}$. The integral term is\n   $$\n   \\int_{-\\infty}^{\\infty} e^{-|x-t|} f(t) \\, dt = (k * f)(x),\n   $$\n   the convolution of $k$ and $f$. The equation becomes\n   $$\n   f(x) + \\lambda (k * f)(x) = k(x).\n   $$\n\n2. **Take the Fourier transform.**  \n   Using the convolution theorem $\\widehat{k * f} = \\hat{k}\\,\\hat{f}$ (with the given definition), we obtain\n   $$\n   \\hat{f}(\\omega) + \\lambda \\hat{k}(\\omega) \\hat{f}(\\omega) = \\hat{k}(\\omega),\n   $$\n   hence\n   $$\n   \\bigl(1 + \\lambda \\hat{k}(\\omega)\\bigr) \\hat{f}(\\omega) = \\hat{k}(\\omega)\n   \\quad\\Longrightarrow\\quad\n   \\hat{f}(\\omega) = \\frac{\\hat{k}(\\omega)}{1 + \\lambda \\hat{k}(\\omega)}.\n   $$\n\n3. **Compute $\\hat{k}(\\omega)$.**  \n   $$\n   \\hat{k}(\\omega) = \\int_{-\\infty}^{\\infty} e^{-|x|} e^{-i\\omega x} \\, dx\n   = \\int_{-\\infty}^{0} e^{x} e^{-i\\omega x} \\, dx + \\int_{0}^{\\infty} e^{-x} e^{-i\\omega x} \\, dx.\n   $$\n   The first integral:\n   $$\n   \\int_{-\\infty}^{0} e^{(1 - i\\omega)x} \\, dx = \\left[ \\frac{e^{(1 - i\\omega)x}}{1 - i\\omega} \\right]_{-\\infty}^{0} = \\frac{1}{1 - i\\omega}.\n   $$\n   The second:\n   $$\n   \\int_{0}^{\\infty} e^{-(1 + i\\omega)x} \\, dx = \\left[ -\\frac{e^{-(1 + i\\omega)x}}{1 + i\\omega} \\right]_{0}^{\\infty} = \\frac{1}{1 + i\\omega}.\n   $$\n   Adding gives\n   $$\n   \\hat{k}(\\omega) = \\frac{1}{1 - i\\omega} + \\frac{1}{1 + i\\omega}\n   = \\frac{2}{1 + \\omega^2}.\n   $$\n\n4. **Express $\\hat{f}(\\omega)$.**  \n   Substituting $\\hat{k}(\\omega) = 2/(1+\\omega^2)$ yields\n   $$\n   \\hat{f}(\\omega) = \\frac{\\frac{2}{1+\\omega^2}}{1 + \\lambda \\frac{2}{1+\\omega^2}}\n   = \\frac{2}{1+\\omega^2} \\cdot \\frac{1+\\omega^2}{1+\\omega^2 + 2\\lambda}\n   = \\frac{2}{\\omega^2 + (1+2\\lambda)}.\n   $$\n\n5. **Condition for existence.**  \n   For $\\hat{f}(\\omega)$ to be an ordinary function whose inverse Fourier transform exists as a classical function, the denominator must not vanish for any real $\\omega$. Since $\\omega^2 \\ge 0$, this requires\n   $$\n   1 + 2\\lambda > 0 \\quad\\Longleftrightarrow\\quad \\lambda > -\\frac{1}{2}.\n   $$\n   If $\\lambda \\le -1/2$, the denominator has zeros at $\\omega = \\pm\\sqrt{-(1+2\\lambda)}$ (for $\\lambda < -1/2$) or becomes $\\omega^2$ (for $\\lambda = -1/2$), leading to singularities on the real axis; in those cases no solution in ordinary function spaces exists. Hence we restrict to $\\lambda > -1/2$.\n\n6. **Invert the Fourier transform.**  \n   Set $a = \\sqrt{1+2\\lambda} > 0$. Then\n   $$\n   \\hat{f}(\\omega) = \\frac{2}{\\omega^2 + a^2}.\n   $$\n   We use the known Fourier transform pair:\n   $$\n   \\int_{-\\infty}^{\\infty} e^{-a|x|} e^{-i\\omega x} \\, dx = \\frac{2a}{\\omega^2 + a^2}.\n   $$\n   By the inversion formula,\n   $$\n   e^{-a|x|} = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{2a}{\\omega^2 + a^2} e^{i\\omega x} \\, d\\omega.\n   $$\n   Rearranging,\n   $$\n   \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{2}{\\omega^2 + a^2} e^{i\\omega x} \\, d\\omega = \\frac{1}{a} e^{-a|x|}.\n   $$\n   The left\u2011hand side is exactly the inverse Fourier transform of $\\hat{f}(\\omega)$. Therefore,\n   $$\n   f(x) = \\frac{1}{a} e^{-a|x|} = \\frac{1}{\\sqrt{1+2\\lambda}}\\, e^{-\\sqrt{1+2\\lambda}\\,|x|}, \\qquad \\lambda > -\\frac{1}{2}.\n   $$\n\n7. **Conclusion.**  \n   The integral equation admits a solution exactly for $\\lambda > -\\frac{1}{2}$, and the solution is\n   $$\n   \\boxed{f(x) = \\frac{1}{\\sqrt{1+2\\lambda}}\\; e^{-\\sqrt{1+2\\lambda}\\,|x|}}.\n   $$",
            "raw_answer": "[QUESTION]\nConsider the integral equation\n\\[\nf(x) + \\lambda \\int_{-\\infty}^{\\infty} e^{-|x-t|} f(t) \\, dt = e^{-|x|}, \\qquad x \\in \\mathbb{R},\n\\]\nwhere \\(\\lambda\\) is a real constant. Use the Fourier transform defined by\n\\[\n\\hat{g}(\\omega) = \\int_{-\\infty}^{\\infty} g(x) e^{-i\\omega x} \\, dx,\n\\]\nwith the inverse transform given by\n\\[\ng(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\hat{g}(\\omega) e^{i\\omega x} \\, d\\omega.\n\\]\nDetermine the range of \\(\\lambda\\) for which the equation admits a solution, and find the solution \\(f(x)\\) in closed form.\n\n[ANSWER]\nWe solve the equation by Fourier transform methods.\n\n1. **Rewrite as a convolution.**  \n   Let \\(k(x) = e^{-|x|}\\). The integral term is\n   \\[\n   \\int_{-\\infty}^{\\infty} e^{-|x-t|} f(t) \\, dt = (k * f)(x),\n   \\]\n   the convolution of \\(k\\) and \\(f\\). The equation becomes\n   \\[\n   f(x) + \\lambda (k * f)(x) = k(x).\n   \\]\n\n2. **Take the Fourier transform.**  \n   Using the convolution theorem \\(\\widehat{k * f} = \\hat{k}\\,\\hat{f}\\) (with the given definition), we obtain\n   \\[\n   \\hat{f}(\\omega) + \\lambda \\hat{k}(\\omega) \\hat{f}(\\omega) = \\hat{k}(\\omega),\n   \\]\n   hence\n   \\[\n   \\bigl(1 + \\lambda \\hat{k}(\\omega)\\bigr) \\hat{f}(\\omega) = \\hat{k}(\\omega)\n   \\quad\\Longrightarrow\\quad\n   \\hat{f}(\\omega) = \\frac{\\hat{k}(\\omega)}{1 + \\lambda \\hat{k}(\\omega)}.\n   \\]\n\n3. **Compute \\(\\hat{k}(\\omega)\\).**  \n   \\[\n   \\hat{k}(\\omega) = \\int_{-\\infty}^{\\infty} e^{-|x|} e^{-i\\omega x} \\, dx\n   = \\int_{-\\infty}^{0} e^{x} e^{-i\\omega x} \\, dx + \\int_{0}^{\\infty} e^{-x} e^{-i\\omega x} \\, dx.\n   \\]\n   The first integral:\n   \\[\n   \\int_{-\\infty}^{0} e^{(1 - i\\omega)x} \\, dx = \\left[ \\frac{e^{(1 - i\\omega)x}}{1 - i\\omega} \\right]_{-\\infty}^{0} = \\frac{1}{1 - i\\omega}.\n   \\]\n   The second:\n   \\[\n   \\int_{0}^{\\infty} e^{-(1 + i\\omega)x} \\, dx = \\left[ -\\frac{e^{-(1 + i\\omega)x}}{1 + i\\omega} \\right]_{0}^{\\infty} = \\frac{1}{1 + i\\omega}.\n   \\]\n   Adding gives\n   \\[\n   \\hat{k}(\\omega) = \\frac{1}{1 - i\\omega} + \\frac{1}{1 + i\\omega}\n   = \\frac{2}{1 + \\omega^2}.\n   \\]\n\n4. **Express \\(\\hat{f}(\\omega)\\).**  \n   Substituting \\(\\hat{k}(\\omega) = 2/(1+\\omega^2)\\) yields\n   \\[\n   \\hat{f}(\\omega) = \\frac{\\frac{2}{1+\\omega^2}}{1 + \\lambda \\frac{2}{1+\\omega^2}}\n   = \\frac{2}{1+\\omega^2} \\cdot \\frac{1+\\omega^2}{1+\\omega^2 + 2\\lambda}\n   = \\frac{2}{\\omega^2 + (1+2\\lambda)}.\n   \\]\n\n5. **Condition for existence.**  \n   For \\(\\hat{f}(\\omega)\\) to be an ordinary function whose inverse Fourier transform exists as a classical function, the denominator must not vanish for any real \\(\\omega\\). Since \\(\\omega^2 \\ge 0\\), this requires\n   \\[\n   1 + 2\\lambda > 0 \\quad\\Longleftrightarrow\\quad \\lambda > -\\frac{1}{2}.\n   \\]\n   If \\(\\lambda \\le -1/2\\), the denominator has zeros at \\(\\omega = \\pm\\sqrt{-(1+2\\lambda)}\\) (for \\(\\lambda < -1/2\\)) or becomes \\(\\omega^2\\) (for \\(\\lambda = -1/2\\)), leading to singularities on the real axis; in those cases no solution in ordinary function spaces exists. Hence we restrict to \\(\\lambda > -1/2\\).\n\n6. **Invert the Fourier transform.**  \n   Set \\(a = \\sqrt{1+2\\lambda} > 0\\). Then\n   \\[\n   \\hat{f}(\\omega) = \\frac{2}{\\omega^2 + a^2}.\n   \\]\n   We use the known Fourier transform pair:\n   \\[\n   \\int_{-\\infty}^{\\infty} e^{-a|x|} e^{-i\\omega x} \\, dx = \\frac{2a}{\\omega^2 + a^2}.\n   \\]\n   By the inversion formula,\n   \\[\n   e^{-a|x|} = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{2a}{\\omega^2 + a^2} e^{i\\omega x} \\, d\\omega.\n   \\]\n   Rearranging,\n   \\[\n   \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{2}{\\omega^2 + a^2} e^{i\\omega x} \\, d\\omega = \\frac{1}{a} e^{-a|x|}.\n   \\]\n   The left\u2011hand side is exactly the inverse Fourier transform of \\(\\hat{f}(\\omega)\\). Therefore,\n   \\[\n   f(x) = \\frac{1}{a} e^{-a|x|} = \\frac{1}{\\sqrt{1+2\\lambda}}\\, e^{-\\sqrt{1+2\\lambda}\\,|x|}, \\qquad \\lambda > -\\frac{1}{2}.\n   \\]\n\n7. **Conclusion.**  \n   The integral equation admits a solution exactly for \\(\\lambda > -\\frac{1}{2}\\), and the solution is\n   \\[\n   \\boxed{f(x) = \\frac{1}{\\sqrt{1+2\\lambda}}\\; e^{-\\sqrt{1+2\\lambda}\\,|x|}}.\n   \\]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "31",
    "outer_attempt": 1,
    "topic_slug": "integral_equations",
    "topic_name": "Integral equations",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Solve the following integral equation for $\\phi(x)$ on the interval $0 \\le x \\le 1$:\n\n$$\n\\phi(x) = x \\cos 1 + \\int_0^1 \\min(x,t) \\, \\phi(t) \\, dt,\n$$\n\nwhere $\\min(x,t)$ denotes the smaller of $x$ and $t$.",
            "answer": "We solve the integral equation by converting it into a differential equation.\n\nLet\n$$\nI(x) = \\int_0^1 \\min(x,t)\\,\\phi(t)\\,dt.\n$$\nFor a fixed $x$, we split the integral:\n$$\nI(x) = \\int_0^x t\\,\\phi(t)\\,dt + x\\int_x^1 \\phi(t)\\,dt.\n$$\n\nThe original equation is\n$$\n\\phi(x) = f(x) + I(x), \\qquad f(x) = x\\cos 1.\n$$\n\nDifferentiate $I(x)$ with respect to $x$ using Leibniz rule:\n$$\nI'(x) = \\frac{d}{dx}\\int_0^x t\\phi(t)\\,dt + \\frac{d}{dx}\\left(x\\int_x^1 \\phi(t)\\,dt\\right).\n$$\nThe first term gives $x\\phi(x)$. For the second term, apply the product rule:\n$$\n\\frac{d}{dx}\\left(x\\int_x^1 \\phi(t)\\,dt\\right) = \\int_x^1 \\phi(t)\\,dt + x\\cdot \\frac{d}{dx}\\int_x^1 \\phi(t)\\,dt.\n$$\nSince $\\frac{d}{dx}\\int_x^1 \\phi(t)\\,dt = -\\phi(x)$, we obtain\n$$\nI'(x) = x\\phi(x) + \\int_x^1 \\phi(t)\\,dt - x\\phi(x) = \\int_x^1 \\phi(t)\\,dt.\n$$\n\nNow differentiate the equation $\\phi = f + I$:\n$$\n\\phi'(x) = f'(x) + I'(x) = \\cos 1 + \\int_x^1 \\phi(t)\\,dt.\n$$\n\nDifferentiate once more:\n$$\n\\phi''(x) = \\frac{d}{dx}\\left(\\cos 1 + \\int_x^1 \\phi(t)\\,dt\\right) = -\\phi(x).\n$$\nThus\n$$\n\\phi''(x) + \\phi(x) = 0.\n$$\n\nWe also need boundary conditions. From the original equation at $x=0$:\n$$\n\\phi(0) = f(0) + I(0) = 0 + 0 = 0.\n$$\nFrom the expression for $\\phi'(x)$ at $x=1$:\n$$\n\\phi'(1) = \\cos 1 + \\int_1^1 \\phi(t)\\,dt = \\cos 1.\n$$\n\nTherefore we have the boundary value problem:\n$$\n\\phi'' + \\phi = 0,\\qquad \\phi(0)=0,\\quad \\phi'(1)=\\cos 1.\n$$\n\nThe general solution of $\\phi''+\\phi=0$ is\n$$\n\\phi(x) = A\\sin x + B\\cos x.\n$$\nUsing $\\phi(0)=0$ gives $B=0$. Then $\\phi(x)=A\\sin x$ and $\\phi'(x)=A\\cos x$. The condition $\\phi'(1)=\\cos 1$ yields\n$$\nA\\cos 1 = \\cos 1 \\quad\\Longrightarrow\\quad A=1 \\quad (\\text{since } \\cos 1\\neq 0).\n$$\nHence\n$$\n\\phi(x) = \\sin x.\n$$\n\nWe can verify by substituting back into the original equation. Compute the right\u2011hand side:\n$$\nx\\cos 1 + \\int_0^1 \\min(x,t)\\sin t\\,dt.\n$$\nSplit the integral:\n$$\n\\int_0^x t\\sin t\\,dt + x\\int_x^1 \\sin t\\,dt.\n$$\nThe first integral is $\\bigl[\\sin t - t\\cos t\\bigr]_0^x = \\sin x - x\\cos x$. The second integral is $\\bigl[-\\cos t\\bigr]_x^1 = -\\cos 1 + \\cos x$, multiplied by $x$ gives $-x\\cos 1 + x\\cos x$. Adding the two parts yields $\\sin x - x\\cos x - x\\cos 1 + x\\cos x = \\sin x - x\\cos 1$. Finally adding $x\\cos 1$ gives $\\sin x$, which matches the left\u2011hand side. Thus $\\phi(x)=\\sin x$ is the unique solution.",
            "raw_answer": "[QUESTION]\nSolve the following integral equation for \\(\\phi(x)\\) on the interval \\(0 \\le x \\le 1\\):\n\n\\[\n\\phi(x) = x \\cos 1 + \\int_0^1 \\min(x,t) \\, \\phi(t) \\, dt,\n\\]\n\nwhere \\(\\min(x,t)\\) denotes the smaller of \\(x\\) and \\(t\\).\n\n[ANSWER]\nWe solve the integral equation by converting it into a differential equation.\n\nLet\n\\[\nI(x) = \\int_0^1 \\min(x,t)\\,\\phi(t)\\,dt.\n\\]\nFor a fixed \\(x\\), we split the integral:\n\\[\nI(x) = \\int_0^x t\\,\\phi(t)\\,dt + x\\int_x^1 \\phi(t)\\,dt.\n\\]\n\nThe original equation is\n\\[\n\\phi(x) = f(x) + I(x), \\qquad f(x) = x\\cos 1.\n\\]\n\nDifferentiate \\(I(x)\\) with respect to \\(x\\) using Leibniz rule:\n\\[\nI'(x) = \\frac{d}{dx}\\int_0^x t\\phi(t)\\,dt + \\frac{d}{dx}\\left(x\\int_x^1 \\phi(t)\\,dt\\right).\n\\]\nThe first term gives \\(x\\phi(x)\\). For the second term, apply the product rule:\n\\[\n\\frac{d}{dx}\\left(x\\int_x^1 \\phi(t)\\,dt\\right) = \\int_x^1 \\phi(t)\\,dt + x\\cdot \\frac{d}{dx}\\int_x^1 \\phi(t)\\,dt.\n\\]\nSince \\(\\frac{d}{dx}\\int_x^1 \\phi(t)\\,dt = -\\phi(x)\\), we obtain\n\\[\nI'(x) = x\\phi(x) + \\int_x^1 \\phi(t)\\,dt - x\\phi(x) = \\int_x^1 \\phi(t)\\,dt.\n\\]\n\nNow differentiate the equation \\(\\phi = f + I\\):\n\\[\n\\phi'(x) = f'(x) + I'(x) = \\cos 1 + \\int_x^1 \\phi(t)\\,dt.\n\\]\n\nDifferentiate once more:\n\\[\n\\phi''(x) = \\frac{d}{dx}\\left(\\cos 1 + \\int_x^1 \\phi(t)\\,dt\\right) = -\\phi(x).\n\\]\nThus\n\\[\n\\phi''(x) + \\phi(x) = 0.\n\\]\n\nWe also need boundary conditions. From the original equation at \\(x=0\\):\n\\[\n\\phi(0) = f(0) + I(0) = 0 + 0 = 0.\n\\]\nFrom the expression for \\(\\phi'(x)\\) at \\(x=1\\):\n\\[\n\\phi'(1) = \\cos 1 + \\int_1^1 \\phi(t)\\,dt = \\cos 1.\n\\]\n\nTherefore we have the boundary value problem:\n\\[\n\\phi'' + \\phi = 0,\\qquad \\phi(0)=0,\\quad \\phi'(1)=\\cos 1.\n\\]\n\nThe general solution of \\(\\phi''+\\phi=0\\) is\n\\[\n\\phi(x) = A\\sin x + B\\cos x.\n\\]\nUsing \\(\\phi(0)=0\\) gives \\(B=0\\). Then \\(\\phi(x)=A\\sin x\\) and \\(\\phi'(x)=A\\cos x\\). The condition \\(\\phi'(1)=\\cos 1\\) yields\n\\[\nA\\cos 1 = \\cos 1 \\quad\\Longrightarrow\\quad A=1 \\quad (\\text{since } \\cos 1\\neq 0).\n\\]\nHence\n\\[\n\\phi(x) = \\sin x.\n\\]\n\nWe can verify by substituting back into the original equation. Compute the right\u2011hand side:\n\\[\nx\\cos 1 + \\int_0^1 \\min(x,t)\\sin t\\,dt.\n\\]\nSplit the integral:\n\\[\n\\int_0^x t\\sin t\\,dt + x\\int_x^1 \\sin t\\,dt.\n\\]\nThe first integral is \\(\\bigl[\\sin t - t\\cos t\\bigr]_0^x = \\sin x - x\\cos x\\). The second integral is \\(\\bigl[-\\cos t\\bigr]_x^1 = -\\cos 1 + \\cos x\\), multiplied by \\(x\\) gives \\(-x\\cos 1 + x\\cos x\\). Adding the two parts yields \\(\\sin x - x\\cos x - x\\cos 1 + x\\cos x = \\sin x - x\\cos 1\\). Finally adding \\(x\\cos 1\\) gives \\(\\sin x\\), which matches the left\u2011hand side. Thus \\(\\phi(x)=\\sin x\\) is the unique solution.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "32",
    "outer_attempt": 1,
    "topic_slug": "functional_analysis",
    "topic_name": "Functional analysis",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $C[0,1]$ denote the Banach space of complex-valued continuous functions on $[0,1]$ equipped with the supremum norm $\\|f\\|_\\infty = \\sup_{x\\in[0,1]}|f(x)|$. Define the Volterra operator $V: C[0,1] \\to C[0,1]$ by\n$$\n(Vf)(x) = \\int_0^x f(t)\\,dt, \\qquad x\\in[0,1].\n$$\nProve that $V$ is a compact linear operator and that its spectrum $\\sigma(V) = \\{0\\}$.",
            "answer": "We prove compactness and determine the spectrum in steps.\n\n**1. Linearity and boundedness.**  \nLinearity of $V$ follows from linearity of the integral. For any $f\\in C[0,1]$,\n$$\n|(Vf)(x)| \\le \\int_0^x |f(t)|\\,dt \\le x\\|f\\|_\\infty \\le \\|f\\|_\\infty,\n$$\nso $\\|Vf\\|_\\infty \\le \\|f\\|_\\infty$, hence $V$ is bounded with $\\|V\\|\\le 1$.\n\n**2. Compactness of $V$.**  \nWe use the Arzel\u00e0\u2013Ascoli theorem: a subset of $C[0,1]$ is relatively compact iff it is uniformly bounded and equicontinuous.  \nLet $B = \\{ f\\in C[0,1] : \\|f\\|_\\infty \\le M \\}$ be a bounded set. For any $f\\in B$ and $x\\in[0,1]$,\n$$\n|(Vf)(x)| \\le \\int_0^x |f(t)|\\,dt \\le M x \\le M,\n$$\nso $V(B)$ is uniformly bounded by $M$.  \nFor equicontinuity, take any $x,y\\in[0,1]$ with $x\\le y$ (the other case is symmetric). Then\n$$\n|(Vf)(y)-(Vf)(x)| = \\left|\\int_x^y f(t)\\,dt\\right| \\le M|y-x|.\n$$\nThus for every $\\varepsilon>0$, choose $\\delta = \\varepsilon/M$; then $|y-x|<\\delta$ implies $|(Vf)(y)-(Vf)(x)|<\\varepsilon$ for all $f\\in B$. Hence $V(B)$ is equicontinuous.  \nBy Arzel\u00e0\u2013Ascoli, $V(B)$ is relatively compact. Therefore $V$ maps bounded sets to relatively compact sets, i.e., $V$ is a compact operator.\n\n**3. $0\\in\\sigma(V)$.**  \nThe spectrum $\\sigma(V)$ consists of all $\\lambda\\in\\mathbb{C}$ for which $\\lambda I - V$ is not invertible.  \n$V$ is injective: if $Vf=0$, then differentiating gives $f=0$. However, $V$ is not surjective. For instance, the constant function $g(x)=1$ is in $C[0,1]$ but cannot be $Vf$ for any $f\\in C[0,1]$, because every function in the range satisfies $(Vf)(0)=0$. Hence $V$ is not bijective, and in particular $0 I - V = -V$ is not invertible. Thus $0\\in\\sigma(V)$.\n\n**4. $\\lambda\\neq 0$ belongs to the resolvent set $\\rho(V)$.**  \nWe show that the spectral radius $r(V)=\\lim_{n\\to\\infty}\\|V^n\\|^{1/n}=0$. Then for any $\\lambda\\neq 0$, $|\\lambda|>r(V)$ and the Neumann series $\\sum_{n=0}^\\infty V^n/\\lambda^{n+1}$ converges in operator norm to $(\\lambda I-V)^{-1}$, so $\\lambda\\notin\\sigma(V)$.\n\n*Estimate of $\\|V^n\\|$.* By induction one obtains\n$$\n(V^n f)(x) = \\int_0^x \\frac{(x-t)^{n-1}}{(n-1)!}\\, f(t)\\,dt.\n$$\nIndeed, the case $n=1$ is the definition. Assuming the formula for $n$, then\n$$\n(V^{n+1}f)(x) = V(V^n f)(x) = \\int_0^x (V^n f)(s)\\,ds\n= \\int_0^x \\int_0^s \\frac{(s-t)^{n-1}}{(n-1)!} f(t)\\,dt\\,ds.\n$$\nInterchanging the order of integration (Fubini) gives\n$$\n\\int_0^x \\int_t^x \\frac{(s-t)^{n-1}}{(n-1)!}\\,ds\\, f(t)\\,dt\n= \\int_0^x \\frac{(x-t)^n}{n!}\\, f(t)\\,dt,\n$$\nconfirming the formula.  \nNow for any $f$ with $\\|f\\|_\\infty\\le 1$,\n$$\n|(V^n f)(x)| \\le \\int_0^x \\frac{(x-t)^{n-1}}{(n-1)!}\\,|f(t)|\\,dt\n\\le \\int_0^x \\frac{(x-t)^{n-1}}{(n-1)!}\\,dt = \\frac{x^n}{n!} \\le \\frac{1}{n!}.\n$$\nTaking the supremum over $x\\in[0,1]$ and over $f$ with $\\|f\\|_\\infty\\le 1$ yields $\\|V^n\\|\\le 1/n!$.\n\n*Spectral radius.* Since $\\|V^n\\|^{1/n} \\le (1/n!)^{1/n} \\to 0$ as $n\\to\\infty$, we have $r(V)=\\lim_{n\\to\\infty}\\|V^n\\|^{1/n}=0$.\n\nTherefore for any $\\lambda\\neq 0$, the series $\\sum_{n=0}^\\infty V^n/\\lambda^{n+1}$ converges absolutely in operator norm (because $\\|V^n/\\lambda^{n+1}\\|\\le 1/(|\\lambda|^{n+1} n!)$ and $\\sum 1/(n!)$ converges). Its sum $R_\\lambda$ satisfies $(\\lambda I-V)R_\\lambda = I = R_\\lambda(\\lambda I-V)$, so $\\lambda I-V$ is invertible with bounded inverse. Hence $\\lambda\\notin\\sigma(V)$.\n\n**5. Conclusion.**  \nWe have shown $0\\in\\sigma(V)$ and every $\\lambda\\neq 0$ belongs to $\\rho(V)$. Consequently,\n$$\n\\sigma(V) = \\{0\\}.\n$$",
            "raw_answer": "[QUESTION]\nLet $C[0,1]$ denote the Banach space of complex-valued continuous functions on $[0,1]$ equipped with the supremum norm $\\|f\\|_\\infty = \\sup_{x\\in[0,1]}|f(x)|$. Define the Volterra operator $V: C[0,1] \\to C[0,1]$ by\n\\[\n(Vf)(x) = \\int_0^x f(t)\\,dt, \\qquad x\\in[0,1].\n\\]\nProve that $V$ is a compact linear operator and that its spectrum $\\sigma(V) = \\{0\\}$.\n\n[ANSWER]\nWe prove compactness and determine the spectrum in steps.\n\n**1. Linearity and boundedness.**  \nLinearity of $V$ follows from linearity of the integral. For any $f\\in C[0,1]$,\n\\[\n|(Vf)(x)| \\le \\int_0^x |f(t)|\\,dt \\le x\\|f\\|_\\infty \\le \\|f\\|_\\infty,\n\\]\nso $\\|Vf\\|_\\infty \\le \\|f\\|_\\infty$, hence $V$ is bounded with $\\|V\\|\\le 1$.\n\n**2. Compactness of $V$.**  \nWe use the Arzel\u00e0\u2013Ascoli theorem: a subset of $C[0,1]$ is relatively compact iff it is uniformly bounded and equicontinuous.  \nLet $B = \\{ f\\in C[0,1] : \\|f\\|_\\infty \\le M \\}$ be a bounded set. For any $f\\in B$ and $x\\in[0,1]$,\n\\[\n|(Vf)(x)| \\le \\int_0^x |f(t)|\\,dt \\le M x \\le M,\n\\]\nso $V(B)$ is uniformly bounded by $M$.  \nFor equicontinuity, take any $x,y\\in[0,1]$ with $x\\le y$ (the other case is symmetric). Then\n\\[\n|(Vf)(y)-(Vf)(x)| = \\left|\\int_x^y f(t)\\,dt\\right| \\le M|y-x|.\n\\]\nThus for every $\\varepsilon>0$, choose $\\delta = \\varepsilon/M$; then $|y-x|<\\delta$ implies $|(Vf)(y)-(Vf)(x)|<\\varepsilon$ for all $f\\in B$. Hence $V(B)$ is equicontinuous.  \nBy Arzel\u00e0\u2013Ascoli, $V(B)$ is relatively compact. Therefore $V$ maps bounded sets to relatively compact sets, i.e., $V$ is a compact operator.\n\n**3. $0\\in\\sigma(V)$.**  \nThe spectrum $\\sigma(V)$ consists of all $\\lambda\\in\\mathbb{C}$ for which $\\lambda I - V$ is not invertible.  \n$V$ is injective: if $Vf=0$, then differentiating gives $f=0$. However, $V$ is not surjective. For instance, the constant function $g(x)=1$ is in $C[0,1]$ but cannot be $Vf$ for any $f\\in C[0,1]$, because every function in the range satisfies $(Vf)(0)=0$. Hence $V$ is not bijective, and in particular $0 I - V = -V$ is not invertible. Thus $0\\in\\sigma(V)$.\n\n**4. $\\lambda\\neq 0$ belongs to the resolvent set $\\rho(V)$.**  \nWe show that the spectral radius $r(V)=\\lim_{n\\to\\infty}\\|V^n\\|^{1/n}=0$. Then for any $\\lambda\\neq 0$, $|\\lambda|>r(V)$ and the Neumann series $\\sum_{n=0}^\\infty V^n/\\lambda^{n+1}$ converges in operator norm to $(\\lambda I-V)^{-1}$, so $\\lambda\\notin\\sigma(V)$.\n\n*Estimate of $\\|V^n\\|$.* By induction one obtains\n\\[\n(V^n f)(x) = \\int_0^x \\frac{(x-t)^{n-1}}{(n-1)!}\\, f(t)\\,dt.\n\\]\nIndeed, the case $n=1$ is the definition. Assuming the formula for $n$, then\n\\[\n(V^{n+1}f)(x) = V(V^n f)(x) = \\int_0^x (V^n f)(s)\\,ds\n= \\int_0^x \\int_0^s \\frac{(s-t)^{n-1}}{(n-1)!} f(t)\\,dt\\,ds.\n\\]\nInterchanging the order of integration (Fubini) gives\n\\[\n\\int_0^x \\int_t^x \\frac{(s-t)^{n-1}}{(n-1)!}\\,ds\\, f(t)\\,dt\n= \\int_0^x \\frac{(x-t)^n}{n!}\\, f(t)\\,dt,\n\\]\nconfirming the formula.  \nNow for any $f$ with $\\|f\\|_\\infty\\le 1$,\n\\[\n|(V^n f)(x)| \\le \\int_0^x \\frac{(x-t)^{n-1}}{(n-1)!}\\,|f(t)|\\,dt\n\\le \\int_0^x \\frac{(x-t)^{n-1}}{(n-1)!}\\,dt = \\frac{x^n}{n!} \\le \\frac{1}{n!}.\n\\]\nTaking the supremum over $x\\in[0,1]$ and over $f$ with $\\|f\\|_\\infty\\le 1$ yields $\\|V^n\\|\\le 1/n!$.\n\n*Spectral radius.* Since $\\|V^n\\|^{1/n} \\le (1/n!)^{1/n} \\to 0$ as $n\\to\\infty$, we have $r(V)=\\lim_{n\\to\\infty}\\|V^n\\|^{1/n}=0$.\n\nTherefore for any $\\lambda\\neq 0$, the series $\\sum_{n=0}^\\infty V^n/\\lambda^{n+1}$ converges absolutely in operator norm (because $\\|V^n/\\lambda^{n+1}\\|\\le 1/(|\\lambda|^{n+1} n!)$ and $\\sum 1/(n!)$ converges). Its sum $R_\\lambda$ satisfies $(\\lambda I-V)R_\\lambda = I = R_\\lambda(\\lambda I-V)$, so $\\lambda I-V$ is invertible with bounded inverse. Hence $\\lambda\\notin\\sigma(V)$.\n\n**5. Conclusion.**  \nWe have shown $0\\in\\sigma(V)$ and every $\\lambda\\neq 0$ belongs to $\\rho(V)$. Consequently,\n\\[\n\\sigma(V) = \\{0\\}.\n\\]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "33",
    "outer_attempt": 1,
    "topic_slug": "operator_theory",
    "topic_name": "Operator theory",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $L^2[0,1]$ denote the Hilbert space of (equivalence classes of) Lebesgue measurable square-integrable functions on $[0,1]$ with the usual inner product $\\langle f,g\\rangle = \\int_0^1 f(x)\\overline{g(x)}\\,dx$. Define the Volterra operator $V:L^2[0,1]\\to L^2[0,1]$ by\n$$\n(Vf)(x) = \\int_0^x f(t)\\,dt,\\qquad x\\in[0,1].\n$$\nDetermine the operator norm $\\|V\\|$.",
            "answer": "We compute $\\|V\\|$ by finding the largest singular value of $V$. Since $V$ is a bounded linear operator on a Hilbert space, $\\|V\\|^2 = \\|V^*V\\|$, where $V^*$ is the adjoint. The operator $V^*V$ is compact and self-adjoint, so its norm equals its largest eigenvalue. We solve the eigenvalue problem $V^*V\\varphi = \\lambda\\varphi$.\n\n**Step 1: Adjoint of $V$.** For $f,g\\in L^2[0,1]$,\n$$\n\\langle Vf,g\\rangle = \\int_0^1\\left(\\int_0^x f(t)\\,dt\\right)\\overline{g(x)}\\,dx = \\int_0^1 f(t)\\left(\\int_t^1 \\overline{g(x)}\\,dx\\right)dt = \\langle f,V^*g\\rangle,\n$$\nhence\n$$\n(V^*g)(t) = \\int_t^1 g(x)\\,dx.\n$$\n\n**Step 2: Compute $V^*V$.** For $f\\in L^2[0,1]$,\n$$\n(V^*V f)(x) = \\int_x^1 (Vf)(t)\\,dt = \\int_x^1 \\left(\\int_0^t f(s)\\,ds\\right)dt.\n$$\nBy Fubini's theorem,\n$$\n(V^*V f)(x) = \\int_0^1 f(s)\\left(\\int_{\\max(x,s)}^1 dt\\right)ds = \\int_0^1 f(s)\\big(1-\\max(x,s)\\big)\\,ds.\n$$\nThus $V^*V$ is an integral operator with continuous symmetric kernel $K(x,s)=1-\\max(x,s)$; it is compact, self-adjoint, and positive.\n\n**Step 3: Eigenvalue equation.** Let $\\lambda>0$ and $\\varphi$ satisfy $V^*V\\varphi = \\lambda\\varphi$. Write\n$$\n(V^*V\\varphi)(x) = \\int_0^x (1-x)\\varphi(s)\\,ds + \\int_x^1 (1-s)\\varphi(s)\\,ds.\n$$\nDifferentiate once (justified by Leibniz rule):\n$$\n\\frac{d}{dx}(V^*V\\varphi)(x) = -\\int_0^x \\varphi(s)\\,ds.\n$$\nDifferentiate again:\n$$\n\\frac{d^2}{dx^2}(V^*V\\varphi)(x) = -\\varphi(x).\n$$\nSince $(V^*V\\varphi)(x)=\\lambda\\varphi(x)$, we obtain\n$$\n\\lambda\\varphi''(x) = -\\varphi(x) \\quad\\Longrightarrow\\quad \\varphi''(x) + \\frac{1}{\\lambda}\\varphi(x)=0.\n$$\n\n**Step 4: Boundary conditions.** From the integral form:\n- $(V^*V\\varphi)(1)=0$ gives $\\lambda\\varphi(1)=0$, so $\\varphi(1)=0$.\n- $(V^*V\\varphi)'(0)=0$ gives $\\lambda\\varphi'(0)=0$, so $\\varphi'(0)=0$.\n\n**Step 5: Solve the ODE.** Set $\\omega = 1/\\sqrt{\\lambda}$. Then $\\varphi''+\\omega^2\\varphi=0$. The general solution is $\\varphi(x)=A\\cos(\\omega x)+B\\sin(\\omega x)$. $\\varphi'(0)=0$ implies $B=0$, so $\\varphi(x)=A\\cos(\\omega x)$. $\\varphi(1)=0$ forces $\\cos\\omega=0$, i.e.,\n$$\n\\omega = \\frac{\\pi}{2} + n\\pi,\\quad n=0,1,2,\\dots\n$$\nThus\n$$\n\\omega_n = \\frac{(2n+1)\\pi}{2},\\qquad \\lambda_n = \\frac{1}{\\omega_n^2} = \\frac{4}{\\pi^2(2n+1)^2}.\n$$\n\n**Step 6: Largest eigenvalue and norm of $V$.** The eigenvalues $\\lambda_n$ are positive and decrease with $n$. The largest is $\\lambda_0 = 4/\\pi^2$. Hence $\\|V^*V\\| = \\lambda_0 = 4/\\pi^2$. Because $\\|V\\|^2 = \\|V^*V\\|$, we obtain\n$$\n\\|V\\| = \\sqrt{\\frac{4}{\\pi^2}} = \\frac{2}{\\pi}.\n$$\n\n**Step 7: Attainment (optional).** The norm is attained, e.g., by the eigenfunction $\\varphi_0(x)=\\cos(\\pi x/2)$, which satisfies $\\|V\\varphi_0\\| = (2/\\pi)\\|\\varphi_0\\|$.\n\nTherefore, the operator norm of the Volterra operator on $L^2[0,1]$ is $\\boxed{\\dfrac{2}{\\pi}}$.",
            "raw_answer": "[QUESTION]\nLet $L^2[0,1]$ denote the Hilbert space of (equivalence classes of) Lebesgue measurable square-integrable functions on $[0,1]$ with the usual inner product $\\langle f,g\\rangle = \\int_0^1 f(x)\\overline{g(x)}\\,dx$. Define the Volterra operator $V:L^2[0,1]\\to L^2[0,1]$ by\n\\[\n(Vf)(x) = \\int_0^x f(t)\\,dt,\\qquad x\\in[0,1].\n\\]\nDetermine the operator norm $\\|V\\|$.\n\n[ANSWER]\nWe compute $\\|V\\|$ by finding the largest singular value of $V$. Since $V$ is a bounded linear operator on a Hilbert space, $\\|V\\|^2 = \\|V^*V\\|$, where $V^*$ is the adjoint. The operator $V^*V$ is compact and self-adjoint, so its norm equals its largest eigenvalue. We solve the eigenvalue problem $V^*V\\varphi = \\lambda\\varphi$.\n\n**Step 1: Adjoint of $V$.** For $f,g\\in L^2[0,1]$,\n\\[\n\\langle Vf,g\\rangle = \\int_0^1\\left(\\int_0^x f(t)\\,dt\\right)\\overline{g(x)}\\,dx = \\int_0^1 f(t)\\left(\\int_t^1 \\overline{g(x)}\\,dx\\right)dt = \\langle f,V^*g\\rangle,\n\\]\nhence\n\\[\n(V^*g)(t) = \\int_t^1 g(x)\\,dx.\n\\]\n\n**Step 2: Compute $V^*V$.** For $f\\in L^2[0,1]$,\n\\[\n(V^*V f)(x) = \\int_x^1 (Vf)(t)\\,dt = \\int_x^1 \\left(\\int_0^t f(s)\\,ds\\right)dt.\n\\]\nBy Fubini's theorem,\n\\[\n(V^*V f)(x) = \\int_0^1 f(s)\\left(\\int_{\\max(x,s)}^1 dt\\right)ds = \\int_0^1 f(s)\\big(1-\\max(x,s)\\big)\\,ds.\n\\]\nThus $V^*V$ is an integral operator with continuous symmetric kernel $K(x,s)=1-\\max(x,s)$; it is compact, self-adjoint, and positive.\n\n**Step 3: Eigenvalue equation.** Let $\\lambda>0$ and $\\varphi$ satisfy $V^*V\\varphi = \\lambda\\varphi$. Write\n\\[\n(V^*V\\varphi)(x) = \\int_0^x (1-x)\\varphi(s)\\,ds + \\int_x^1 (1-s)\\varphi(s)\\,ds.\n\\]\nDifferentiate once (justified by Leibniz rule):\n\\[\n\\frac{d}{dx}(V^*V\\varphi)(x) = -\\int_0^x \\varphi(s)\\,ds.\n\\]\nDifferentiate again:\n\\[\n\\frac{d^2}{dx^2}(V^*V\\varphi)(x) = -\\varphi(x).\n\\]\nSince $(V^*V\\varphi)(x)=\\lambda\\varphi(x)$, we obtain\n\\[\n\\lambda\\varphi''(x) = -\\varphi(x) \\quad\\Longrightarrow\\quad \\varphi''(x) + \\frac{1}{\\lambda}\\varphi(x)=0.\n\\]\n\n**Step 4: Boundary conditions.** From the integral form:\n- $(V^*V\\varphi)(1)=0$ gives $\\lambda\\varphi(1)=0$, so $\\varphi(1)=0$.\n- $(V^*V\\varphi)'(0)=0$ gives $\\lambda\\varphi'(0)=0$, so $\\varphi'(0)=0$.\n\n**Step 5: Solve the ODE.** Set $\\omega = 1/\\sqrt{\\lambda}$. Then $\\varphi''+\\omega^2\\varphi=0$. The general solution is $\\varphi(x)=A\\cos(\\omega x)+B\\sin(\\omega x)$. $\\varphi'(0)=0$ implies $B=0$, so $\\varphi(x)=A\\cos(\\omega x)$. $\\varphi(1)=0$ forces $\\cos\\omega=0$, i.e.,\n\\[\n\\omega = \\frac{\\pi}{2} + n\\pi,\\quad n=0,1,2,\\dots\n\\]\nThus\n\\[\n\\omega_n = \\frac{(2n+1)\\pi}{2},\\qquad \\lambda_n = \\frac{1}{\\omega_n^2} = \\frac{4}{\\pi^2(2n+1)^2}.\n\\]\n\n**Step 6: Largest eigenvalue and norm of $V$.** The eigenvalues $\\lambda_n$ are positive and decrease with $n$. The largest is $\\lambda_0 = 4/\\pi^2$. Hence $\\|V^*V\\| = \\lambda_0 = 4/\\pi^2$. Because $\\|V\\|^2 = \\|V^*V\\|$, we obtain\n\\[\n\\|V\\| = \\sqrt{\\frac{4}{\\pi^2}} = \\frac{2}{\\pi}.\n\\]\n\n**Step 7: Attainment (optional).** The norm is attained, e.g., by the eigenfunction $\\varphi_0(x)=\\cos(\\pi x/2)$, which satisfies $\\|V\\varphi_0\\| = (2/\\pi)\\|\\varphi_0\\|$.\n\nTherefore, the operator norm of the Volterra operator on $L^2[0,1]$ is $\\boxed{\\dfrac{2}{\\pi}}$.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "34",
    "outer_attempt": 1,
    "topic_slug": "calculus_of_variations_and_optimization",
    "topic_name": "Calculus of variations and optimal control; optimization",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "A uniform chain of length $L > 1$ is suspended from two points at the same height, located at $(0,0)$ and $(1,0)$. By the principle of minimum potential energy, the chain adopts the shape $y(x)$ that minimizes\n$$\nU[y] = \\int_0^1 y(x) \\sqrt{1 + [y'(x)]^2} \\, dx\n$$\nsubject to the fixed length constraint\n$$\n\\int_0^1 \\sqrt{1 + [y'(x)]^2} \\, dx = L,\n$$\nand boundary conditions $y(0) = 0$, $y(1) = 0$.\n\nFind the function $y(x)$ describing the chain. Your answer should express $y(x)$ in terms of a parameter that is determined implicitly by $L$.",
            "answer": "We solve this isoperimetric problem using the calculus of variations. Introduce a Lagrange multiplier $\\lambda$ and consider the augmented functional\n$$\nJ[y] = \\int_0^1 \\left( y\\sqrt{1+y'^2} + \\lambda \\sqrt{1+y'^2} \\right) dx = \\int_0^1 (y+\\lambda)\\sqrt{1+y'^2}\\,dx.\n$$\nThe integrand $F(y,y') = (y+\\lambda)\\sqrt{1+y'^2}$ does not depend explicitly on $x$, so a first integral exists:\n$$\nF - y'F_{y'} = \\text{constant}.\n$$\nCompute\n$$\nF_{y'} = (y+\\lambda)\\,\\frac{y'}{\\sqrt{1+y'^2}},\n$$\nhence\n$$\nF - y'F_{y'} = (y+\\lambda)\\sqrt{1+y'^2} - y' \\cdot (y+\\lambda)\\frac{y'}{\\sqrt{1+y'^2}} = \\frac{y+\\lambda}{\\sqrt{1+y'^2}}.\n$$\nSet this equal to a constant $C$ (which we may take positive):\n$$\n\\frac{y+\\lambda}{\\sqrt{1+y'^2}} = C \\quad \\Longrightarrow \\quad y+\\lambda = C\\sqrt{1+y'^2}. \\tag{1}\n$$\n\nEquation (1) can be satisfied by the hyperbolic cosine ansatz. Indeed, if we set\n$$\ny+\\lambda = C\\cosh\\left(\\frac{x-x_0}{C}\\right),\n$$\nthen differentiating gives $y' = \\sinh\\bigl((x-x_0)/C\\bigr)$ and $\\sqrt{1+y'^2} = \\cosh\\bigl((x-x_0)/C\\bigr)$, so (1) holds. Thus the general solution is\n$$\ny(x) = C\\cosh\\left(\\frac{x-x_0}{C}\\right) - \\lambda. \\tag{2}\n$$\n\nNow impose the boundary conditions $y(0)=0$ and $y(1)=0$:\n$$\n0 = C\\cosh\\left(\\frac{-x_0}{C}\\right) - \\lambda = C\\cosh\\left(\\frac{x_0}{C}\\right) - \\lambda, \\tag{3}\n$$\n$$\n0 = C\\cosh\\left(\\frac{1-x_0}{C}\\right) - \\lambda. \\tag{4}\n$$\nFrom (3) and (4) we obtain\n$$\nC\\cosh\\left(\\frac{x_0}{C}\\right) = C\\cosh\\left(\\frac{1-x_0}{C}\\right).\n$$\nSince $C>0$ and $\\cosh$ is even and strictly increasing on $[0,\\infty)$, this forces\n$$\n\\frac{x_0}{C} = \\frac{1-x_0}{C} \\quad \\Longrightarrow \\quad x_0 = \\frac12.\n$$\n(The alternative $\\frac{x_0}{C} = -\\frac{1-x_0}{C}$ leads to $1=0$, impossible.) Substituting $x_0 = \\frac12$ into (3) gives\n$$\n\\lambda = C\\cosh\\left(\\frac{1}{2C}\\right).\n$$\n\nThus the shape becomes\n$$\ny(x) = C\\left[ \\cosh\\left(\\frac{x-\\frac12}{C}\\right) - \\cosh\\left(\\frac{1}{2C}\\right) \\right]. \\tag{5}\n$$\n\nIt remains to enforce the length constraint. Using $ds = \\sqrt{1+y'^2}\\,dx = \\cosh\\bigl((x-\\frac12)/C\\bigr)\\,dx$, we compute\n$$\nL = \\int_0^1 \\sqrt{1+y'^2}\\,dx = \\int_0^1 \\cosh\\left(\\frac{x-\\frac12}{C}\\right) dx.\n$$\nSubstitute $u = (x-\\frac12)/C$, $dx = C\\,du$; the limits become $u(0) = -1/(2C)$, $u(1) = 1/(2C)$. Then\n$$\nL = C \\int_{-1/(2C)}^{1/(2C)} \\cosh u \\, du = C\\Bigl[ \\sinh u \\Bigr]_{-1/(2C)}^{1/(2C)} = 2C \\sinh\\left(\\frac{1}{2C}\\right). \\tag{6}\n$$\n\nEquation (6) determines $C$ uniquely for any given $L>1$. Indeed, the function $g(C) = 2C \\sinh(1/(2C))$ satisfies $g(C) \\to 1^+$ as $C\\to\\infty$ and $g(C) \\to \\infty$ as $C\\to 0^+$, and is strictly decreasing (or one may check that it is monotonic), so for each $L>1$ there is exactly one $C>0$. Alternatively, set $a = 1/(2C)$; then (6) becomes\n$$\nL = \\frac{\\sinh a}{a},\n$$\nwhich also has a unique positive solution $a$ for $L>1$.\n\nThe final answer is therefore\n$$\n\\boxed{ y(x) = C\\left( \\cosh\\frac{x-\\frac12}{C} - \\cosh\\frac{1}{2C} \\right), \\qquad \\text{where } C>0 \\text{ satisfies } L = 2C \\sinh\\left(\\frac{1}{2C}\\right). }\n$$\n\nThis curve is a catenary symmetric about $x = \\frac12$, with its lowest point at $x = \\frac12$ where $y = C\\bigl(1 - \\cosh(1/(2C))\\bigr) < 0$.",
            "raw_answer": "[QUESTION]\nA uniform chain of length \\(L > 1\\) is suspended from two points at the same height, located at \\((0,0)\\) and \\((1,0)\\). By the principle of minimum potential energy, the chain adopts the shape \\(y(x)\\) that minimizes\n\\[\nU[y] = \\int_0^1 y(x) \\sqrt{1 + [y'(x)]^2} \\, dx\n\\]\nsubject to the fixed length constraint\n\\[\n\\int_0^1 \\sqrt{1 + [y'(x)]^2} \\, dx = L,\n\\]\nand boundary conditions \\(y(0) = 0\\), \\(y(1) = 0\\).\n\nFind the function \\(y(x)\\) describing the chain. Your answer should express \\(y(x)\\) in terms of a parameter that is determined implicitly by \\(L\\).\n\n[ANSWER]\nWe solve this isoperimetric problem using the calculus of variations. Introduce a Lagrange multiplier \\(\\lambda\\) and consider the augmented functional\n\\[\nJ[y] = \\int_0^1 \\left( y\\sqrt{1+y'^2} + \\lambda \\sqrt{1+y'^2} \\right) dx = \\int_0^1 (y+\\lambda)\\sqrt{1+y'^2}\\,dx.\n\\]\nThe integrand \\(F(y,y') = (y+\\lambda)\\sqrt{1+y'^2}\\) does not depend explicitly on \\(x\\), so a first integral exists:\n\\[\nF - y'F_{y'} = \\text{constant}.\n\\]\nCompute\n\\[\nF_{y'} = (y+\\lambda)\\,\\frac{y'}{\\sqrt{1+y'^2}},\n\\]\nhence\n\\[\nF - y'F_{y'} = (y+\\lambda)\\sqrt{1+y'^2} - y' \\cdot (y+\\lambda)\\frac{y'}{\\sqrt{1+y'^2}} = \\frac{y+\\lambda}{\\sqrt{1+y'^2}}.\n\\]\nSet this equal to a constant \\(C\\) (which we may take positive):\n\\[\n\\frac{y+\\lambda}{\\sqrt{1+y'^2}} = C \\quad \\Longrightarrow \\quad y+\\lambda = C\\sqrt{1+y'^2}. \\tag{1}\n\\]\n\nEquation (1) can be satisfied by the hyperbolic cosine ansatz. Indeed, if we set\n\\[\ny+\\lambda = C\\cosh\\left(\\frac{x-x_0}{C}\\right),\n\\]\nthen differentiating gives \\(y' = \\sinh\\bigl((x-x_0)/C\\bigr)\\) and \\(\\sqrt{1+y'^2} = \\cosh\\bigl((x-x_0)/C\\bigr)\\), so (1) holds. Thus the general solution is\n\\[\ny(x) = C\\cosh\\left(\\frac{x-x_0}{C}\\right) - \\lambda. \\tag{2}\n\\]\n\nNow impose the boundary conditions \\(y(0)=0\\) and \\(y(1)=0\\):\n\\[\n0 = C\\cosh\\left(\\frac{-x_0}{C}\\right) - \\lambda = C\\cosh\\left(\\frac{x_0}{C}\\right) - \\lambda, \\tag{3}\n\\]\n\\[\n0 = C\\cosh\\left(\\frac{1-x_0}{C}\\right) - \\lambda. \\tag{4}\n\\]\nFrom (3) and (4) we obtain\n\\[\nC\\cosh\\left(\\frac{x_0}{C}\\right) = C\\cosh\\left(\\frac{1-x_0}{C}\\right).\n\\]\nSince \\(C>0\\) and \\(\\cosh\\) is even and strictly increasing on \\([0,\\infty)\\), this forces\n\\[\n\\frac{x_0}{C} = \\frac{1-x_0}{C} \\quad \\Longrightarrow \\quad x_0 = \\frac12.\n\\]\n(The alternative \\(\\frac{x_0}{C} = -\\frac{1-x_0}{C}\\) leads to \\(1=0\\), impossible.) Substituting \\(x_0 = \\frac12\\) into (3) gives\n\\[\n\\lambda = C\\cosh\\left(\\frac{1}{2C}\\right).\n\\]\n\nThus the shape becomes\n\\[\ny(x) = C\\left[ \\cosh\\left(\\frac{x-\\frac12}{C}\\right) - \\cosh\\left(\\frac{1}{2C}\\right) \\right]. \\tag{5}\n\\]\n\nIt remains to enforce the length constraint. Using \\(ds = \\sqrt{1+y'^2}\\,dx = \\cosh\\bigl((x-\\frac12)/C\\bigr)\\,dx\\), we compute\n\\[\nL = \\int_0^1 \\sqrt{1+y'^2}\\,dx = \\int_0^1 \\cosh\\left(\\frac{x-\\frac12}{C}\\right) dx.\n\\]\nSubstitute \\(u = (x-\\frac12)/C\\), \\(dx = C\\,du\\); the limits become \\(u(0) = -1/(2C)\\), \\(u(1) = 1/(2C)\\). Then\n\\[\nL = C \\int_{-1/(2C)}^{1/(2C)} \\cosh u \\, du = C\\Bigl[ \\sinh u \\Bigr]_{-1/(2C)}^{1/(2C)} = 2C \\sinh\\left(\\frac{1}{2C}\\right). \\tag{6}\n\\]\n\nEquation (6) determines \\(C\\) uniquely for any given \\(L>1\\). Indeed, the function \\(g(C) = 2C \\sinh(1/(2C))\\) satisfies \\(g(C) \\to 1^+\\) as \\(C\\to\\infty\\) and \\(g(C) \\to \\infty\\) as \\(C\\to 0^+\\), and is strictly decreasing (or one may check that it is monotonic), so for each \\(L>1\\) there is exactly one \\(C>0\\). Alternatively, set \\(a = 1/(2C)\\); then (6) becomes\n\\[\nL = \\frac{\\sinh a}{a},\n\\]\nwhich also has a unique positive solution \\(a\\) for \\(L>1\\).\n\nThe final answer is therefore\n\\[\n\\boxed{ y(x) = C\\left( \\cosh\\frac{x-\\frac12}{C} - \\cosh\\frac{1}{2C} \\right), \\qquad \\text{where } C>0 \\text{ satisfies } L = 2C \\sinh\\left(\\frac{1}{2C}\\right). }\n\\]\n\nThis curve is a catenary symmetric about \\(x = \\frac12\\), with its lowest point at \\(x = \\frac12\\) where \\(y = C\\bigl(1 - \\cosh(1/(2C))\\bigr) < 0\\).",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "35",
    "outer_attempt": 1,
    "topic_slug": "geometry",
    "topic_name": "Geometry",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $\\triangle ABC$ have side lengths $AB = 13$, $AC = 15$, and $BC = 14$. Denote by $D$ the foot of the internal angle bisector from $A$ to side $BC$. Let the incircle of $\\triangle ABC$ touch side $BC$ at $E$. The line through $E$ perpendicular to $BC$ meets $AD$ at $F$. Find the length of $DF$.",
            "answer": "We first identify point $F$. The incircle touches $BC$ at $E$; the radius to the point of tangency is perpendicular to $BC$, so the line through $E$ perpendicular to $BC$ passes through the incenter $I$. Also, $AD$ is an angle bisector, and the incenter lies on all three angle bisectors. Hence $I$ lies on $AD$. Therefore the intersection of these two lines is exactly the incenter: $F = I$. Consequently, $DF = DI$.\n\nNow we compute $DI$.  \n\nThe semiperimeter of $\\triangle ABC$ is  \n$$\ns = \\frac{13+14+15}{2} = 21.\n$$  \nThe area $\\Delta$ can be found using Heron's formula:  \n$$\n\\Delta = \\sqrt{s(s-13)(s-14)(s-15)} = \\sqrt{21 \\cdot 8 \\cdot 7 \\cdot 6} = \\sqrt{7056} = 84.\n$$  \nThus the inradius is  \n$$\nr = \\frac{\\Delta}{s} = \\frac{84}{21} = 4.\n$$\n\nThe distances from $B$ to the points of tangency of the incircle with the sides are given by the standard formulas:  \n$$\nBE = s - AC = 21 - 15 = 6, \\qquad CE = s - AB = 21 - 13 = 8.\n$$  \nHence $E$ is located on $BC$ at a distance $6$ from $B$ (and $8$ from $C$).\n\nBy the Angle Bisector Theorem,  \n$$\n\\frac{BD}{DC} = \\frac{AB}{AC} = \\frac{13}{15}.\n$$  \nSince $BC = 14$, we have  \n$$\nBD = \\frac{13}{13+15} \\cdot 14 = \\frac{13}{28} \\cdot 14 = \\frac{13}{2} = 6.5,\n$$  \nand $DC = 14 - 6.5 = 7.5$. So $D$ is on $BC$ at a distance $6.5$ from $B$.\n\nThus the horizontal distance between $D$ and $E$ (both on $BC$) is  \n$$\nDE = |BD - BE| = |6.5 - 6| = 0.5.\n$$\n\nThe incenter $I$ lies directly above $E$ (because $IE \\perp BC$) at a height equal to the inradius: $IE = r = 4$. Therefore triangle $DIE$ is right\u2011angled at $E$, and  \n$$\nDI = \\sqrt{DE^2 + IE^2} = \\sqrt{(0.5)^2 + 4^2} = \\sqrt{0.25 + 16} = \\sqrt{16.25} = \\sqrt{\\frac{65}{4}} = \\frac{\\sqrt{65}}{2}.\n$$\n\nSince $F = I$, we conclude  \n$$\n\\boxed{\\dfrac{\\sqrt{65}}{2}}.\n$$",
            "raw_answer": "[QUESTION]\nLet \\( \\triangle ABC \\) have side lengths \\( AB = 13 \\), \\( AC = 15 \\), and \\( BC = 14 \\). Denote by \\( D \\) the foot of the internal angle bisector from \\( A \\) to side \\( BC \\). Let the incircle of \\( \\triangle ABC \\) touch side \\( BC \\) at \\( E \\). The line through \\( E \\) perpendicular to \\( BC \\) meets \\( AD \\) at \\( F \\). Find the length of \\( DF \\).\n\n[ANSWER]\nWe first identify point \\(F\\). The incircle touches \\(BC\\) at \\(E\\); the radius to the point of tangency is perpendicular to \\(BC\\), so the line through \\(E\\) perpendicular to \\(BC\\) passes through the incenter \\(I\\). Also, \\(AD\\) is an angle bisector, and the incenter lies on all three angle bisectors. Hence \\(I\\) lies on \\(AD\\). Therefore the intersection of these two lines is exactly the incenter: \\(F = I\\). Consequently, \\(DF = DI\\).\n\nNow we compute \\(DI\\).  \n\nThe semiperimeter of \\(\\triangle ABC\\) is  \n\\[\ns = \\frac{13+14+15}{2} = 21.\n\\]  \nThe area \\(\\Delta\\) can be found using Heron's formula:  \n\\[\n\\Delta = \\sqrt{s(s-13)(s-14)(s-15)} = \\sqrt{21 \\cdot 8 \\cdot 7 \\cdot 6} = \\sqrt{7056} = 84.\n\\]  \nThus the inradius is  \n\\[\nr = \\frac{\\Delta}{s} = \\frac{84}{21} = 4.\n\\]\n\nThe distances from \\(B\\) to the points of tangency of the incircle with the sides are given by the standard formulas:  \n\\[\nBE = s - AC = 21 - 15 = 6, \\qquad CE = s - AB = 21 - 13 = 8.\n\\]  \nHence \\(E\\) is located on \\(BC\\) at a distance \\(6\\) from \\(B\\) (and \\(8\\) from \\(C\\)).\n\nBy the Angle Bisector Theorem,  \n\\[\n\\frac{BD}{DC} = \\frac{AB}{AC} = \\frac{13}{15}.\n\\]  \nSince \\(BC = 14\\), we have  \n\\[\nBD = \\frac{13}{13+15} \\cdot 14 = \\frac{13}{28} \\cdot 14 = \\frac{13}{2} = 6.5,\n\\]  \nand \\(DC = 14 - 6.5 = 7.5\\). So \\(D\\) is on \\(BC\\) at a distance \\(6.5\\) from \\(B\\).\n\nThus the horizontal distance between \\(D\\) and \\(E\\) (both on \\(BC\\)) is  \n\\[\nDE = |BD - BE| = |6.5 - 6| = 0.5.\n\\]\n\nThe incenter \\(I\\) lies directly above \\(E\\) (because \\(IE \\perp BC\\)) at a height equal to the inradius: \\(IE = r = 4\\). Therefore triangle \\(DIE\\) is right\u2011angled at \\(E\\), and  \n\\[\nDI = \\sqrt{DE^2 + IE^2} = \\sqrt{(0.5)^2 + 4^2} = \\sqrt{0.25 + 16} = \\sqrt{16.25} = \\sqrt{\\frac{65}{4}} = \\frac{\\sqrt{65}}{2}.\n\\]\n\nSince \\(F = I\\), we conclude  \n\\[\n\\boxed{\\dfrac{\\sqrt{65}}{2}}.\n\\]",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "36",
    "outer_attempt": 1,
    "topic_slug": "convex_and_discrete_geometry",
    "topic_name": "Convex and discrete geometry",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $S$ be a finite set of points in the Euclidean plane, not all lying on a single line. Prove that there exists a line which contains exactly two points of $S$.",
            "answer": "**Proof.**  \nAssume, for contradiction, that every line determined by two points of $S$ contains at least three points of $S$. Because $S$ is finite, there are only finitely many lines determined by pairs of points of $S$. Consider all pairs $(p,\\ell)$ where $p\\in S$, $\\ell$ is a line through two (other) points of $S$, and $p\\notin\\ell$. The set of such pairs is finite. For each such pair, let $d(p,\\ell)$ be the perpendicular distance from $p$ to $\\ell$; this distance is positive because $p\\notin\\ell$. Choose a pair $(p,\\ell)$ for which $d(p,\\ell)$ is minimal, and denote $d = d(p,\\ell)$.\n\nBy our assumption, $\\ell$ contains at least three points of $S$. Pick three distinct points $A,B,C$ on $\\ell$. Let $F$ be the foot of the perpendicular from $p$ to $\\ell$. We distinguish two cases.\n\n**Case 1: $F$ is not equal to any point of $S$ on $\\ell$.**  \nThen none of $A,B,C$ coincides with $F$. The point $F$ splits the line $\\ell$ into two rays. Among the three points $A,B,C$, by the pigeonhole principle at least two lie on the same side of $F$. Call these two points $X$ and $Y$, and assume that $X$ is the one closer to $F$ (i.e., $|FX| < |FY|$). Consider the line $\\ell'$ through $p$ and $Y$. We claim that the distance from $X$ to $\\ell'$ is smaller than $d$.\n\nObserve that $X$ does not lie on $\\ell'$: if it did, then $p$, $X$, $Y$ would be collinear, and since $X,Y\\in\\ell$, this would force $p\\in\\ell$, contradicting $p\\notin\\ell$. Hence $(X,\\ell')$ is a valid pair (with $X\\in S$ and $\\ell'$ a line through two points $p,Y\\in S$). In triangle $p X Y$, the distance from $X$ to $\\ell'$ is the length of the altitude from $X$ to side $pY$. The area of $\\triangle p X Y$ can be computed in two ways:\n$$\n\\frac12 \\cdot |XY| \\cdot d = \\frac12 \\cdot |pY| \\cdot h,\n$$\nwhere $h$ is the altitude from $X$ to $pY$. Thus $h = \\dfrac{|XY|\\cdot d}{|pY|}$.\n\nBecause $X$ and $Y$ lie on the same side of $F$, we have $|XY| = |FY| - |FX| < |FY|$. In right triangle $p F Y$ (right angle at $F$), the hypotenuse $pY$ satisfies $|pY| > |FY|$. Consequently $|XY| < |pY|$, and therefore $h < d$. This gives a pair $(X,\\ell')$ with distance $h < d$, contradicting the minimality of $d$.\n\n**Case 2: $F$ coincides with one of the points on $\\ell$.**  \nWithout loss of generality, let $A = F$. Since $\\ell$ contains at least three points, there exists another point $B$ on $\\ell$ different from $A$. Consider the line $\\ell'$ through $p$ and $B$. We show that the distance from $A$ to $\\ell'$ is smaller than $d$.\n\nNote that $A$ is not on $\\ell'$: if $A$ were on $\\ell'$, then $p$, $A$, $B$ would be collinear. But $pA$ is perpendicular to $\\ell$ (since $A=F$), and $AB$ lies on $\\ell$, so the only way for $p$, $A$, $B$ to be collinear is if $B = A$, which is false. Hence $(A,\\ell')$ is a valid pair.\n\nTriangle $p A B$ is right\u2011angled at $A$ because $pA \\perp \\ell$ and $AB \\subset \\ell$. The distance from $A$ to $\\ell'$ is the altitude from the right angle to the hypotenuse $pB$. In a right triangle, this altitude $h$ satisfies\n$$\nh = \\frac{|pA|\\cdot|AB|}{|pB|}.\n$$\nSince $|pB| > |AB|$ (hypotenuse longer than each leg), we obtain $h < |pA| = d$. Thus we have found a pair $(A,\\ell')$ with distance $h < d$, again contradicting the minimality of $d$.\n\nIn both cases we reach a contradiction. Therefore our initial assumption must be false: there exists a line determined by two points of $S$ that contains exactly two points of $S$. \u220e",
            "raw_answer": "[QUESTION]\nLet $S$ be a finite set of points in the Euclidean plane, not all lying on a single line. Prove that there exists a line which contains exactly two points of $S$.\n\n[ANSWER]\n**Proof.**  \nAssume, for contradiction, that every line determined by two points of $S$ contains at least three points of $S$. Because $S$ is finite, there are only finitely many lines determined by pairs of points of $S$. Consider all pairs $(p,\\ell)$ where $p\\in S$, $\\ell$ is a line through two (other) points of $S$, and $p\\notin\\ell$. The set of such pairs is finite. For each such pair, let $d(p,\\ell)$ be the perpendicular distance from $p$ to $\\ell$; this distance is positive because $p\\notin\\ell$. Choose a pair $(p,\\ell)$ for which $d(p,\\ell)$ is minimal, and denote $d = d(p,\\ell)$.\n\nBy our assumption, $\\ell$ contains at least three points of $S$. Pick three distinct points $A,B,C$ on $\\ell$. Let $F$ be the foot of the perpendicular from $p$ to $\\ell$. We distinguish two cases.\n\n**Case 1: $F$ is not equal to any point of $S$ on $\\ell$.**  \nThen none of $A,B,C$ coincides with $F$. The point $F$ splits the line $\\ell$ into two rays. Among the three points $A,B,C$, by the pigeonhole principle at least two lie on the same side of $F$. Call these two points $X$ and $Y$, and assume that $X$ is the one closer to $F$ (i.e., $|FX| < |FY|$). Consider the line $\\ell'$ through $p$ and $Y$. We claim that the distance from $X$ to $\\ell'$ is smaller than $d$.\n\nObserve that $X$ does not lie on $\\ell'$: if it did, then $p$, $X$, $Y$ would be collinear, and since $X,Y\\in\\ell$, this would force $p\\in\\ell$, contradicting $p\\notin\\ell$. Hence $(X,\\ell')$ is a valid pair (with $X\\in S$ and $\\ell'$ a line through two points $p,Y\\in S$). In triangle $p X Y$, the distance from $X$ to $\\ell'$ is the length of the altitude from $X$ to side $pY$. The area of $\\triangle p X Y$ can be computed in two ways:\n\\[\n\\frac12 \\cdot |XY| \\cdot d = \\frac12 \\cdot |pY| \\cdot h,\n\\]\nwhere $h$ is the altitude from $X$ to $pY$. Thus $h = \\dfrac{|XY|\\cdot d}{|pY|}$.\n\nBecause $X$ and $Y$ lie on the same side of $F$, we have $|XY| = |FY| - |FX| < |FY|$. In right triangle $p F Y$ (right angle at $F$), the hypotenuse $pY$ satisfies $|pY| > |FY|$. Consequently $|XY| < |pY|$, and therefore $h < d$. This gives a pair $(X,\\ell')$ with distance $h < d$, contradicting the minimality of $d$.\n\n**Case 2: $F$ coincides with one of the points on $\\ell$.**  \nWithout loss of generality, let $A = F$. Since $\\ell$ contains at least three points, there exists another point $B$ on $\\ell$ different from $A$. Consider the line $\\ell'$ through $p$ and $B$. We show that the distance from $A$ to $\\ell'$ is smaller than $d$.\n\nNote that $A$ is not on $\\ell'$: if $A$ were on $\\ell'$, then $p$, $A$, $B$ would be collinear. But $pA$ is perpendicular to $\\ell$ (since $A=F$), and $AB$ lies on $\\ell$, so the only way for $p$, $A$, $B$ to be collinear is if $B = A$, which is false. Hence $(A,\\ell')$ is a valid pair.\n\nTriangle $p A B$ is right\u2011angled at $A$ because $pA \\perp \\ell$ and $AB \\subset \\ell$. The distance from $A$ to $\\ell'$ is the altitude from the right angle to the hypotenuse $pB$. In a right triangle, this altitude $h$ satisfies\n\\[\nh = \\frac{|pA|\\cdot|AB|}{|pB|}.\n\\]\nSince $|pB| > |AB|$ (hypotenuse longer than each leg), we obtain $h < |pA| = d$. Thus we have found a pair $(A,\\ell')$ with distance $h < d$, again contradicting the minimality of $d$.\n\nIn both cases we reach a contradiction. Therefore our initial assumption must be false: there exists a line determined by two points of $S$ that contains exactly two points of $S$. \u220e",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "37",
    "outer_attempt": 1,
    "topic_slug": "differential_geometry",
    "topic_name": "Differential geometry",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Consider the torus $T$ obtained by rotating a circle of radius $r$ about an axis in its plane that is a distance $R > r > 0$ from the circle's center. Using the standard parametrization\n$$\n\\mathbf{X}(\\theta, \\varphi) = \\big( (R + r\\cos\\varphi)\\cos\\theta,\\ (R + r\\cos\\varphi)\\sin\\theta,\\ r\\sin\\varphi \\big), \\qquad \\theta \\in [0,2\\pi),\\ \\varphi \\in [0,2\\pi),\n$$\ncompute the Gaussian curvature $K$ of the torus as a function of $\\varphi$ (it is independent of $\\theta$). Then evaluate the total Gaussian curvature $\\iint_T K \\, dA$ by direct integration, and verify that it equals zero.",
            "answer": "We proceed step by step.\n\n1. **First derivatives:**\n   $$\n   \\mathbf{X}_\\theta = \\frac{\\partial \\mathbf{X}}{\\partial \\theta} = \\big( -(R+r\\cos\\varphi)\\sin\\theta,\\ (R+r\\cos\\varphi)\\cos\\theta,\\ 0 \\big),\n   $$\n   $$\n   \\mathbf{X}_\\varphi = \\frac{\\partial \\mathbf{X}}{\\partial \\varphi} = \\big( -r\\sin\\varphi\\cos\\theta,\\ -r\\sin\\varphi\\sin\\theta,\\ r\\cos\\varphi \\big).\n   $$\n\n2. **First fundamental form:**\n   $$\n   E = \\mathbf{X}_\\theta\\cdot\\mathbf{X}_\\theta = (R+r\\cos\\varphi)^2,\n   $$\n   $$\n   F = \\mathbf{X}_\\theta\\cdot\\mathbf{X}_\\varphi = 0,\n   $$\n   $$\n   G = \\mathbf{X}_\\varphi\\cdot\\mathbf{X}_\\varphi = r^2.\n   $$\n   (The vanishing of $F$ is easily checked.)\n\n3. **Unit normal vector:**\n   The cross product is\n   $$\n   \\mathbf{X}_\\theta \\times \\mathbf{X}_\\varphi = \\begin{vmatrix}\n   \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\\n   -(R+r\\cos\\varphi)\\sin\\theta & (R+r\\cos\\varphi)\\cos\\theta & 0 \\\\\n   -r\\sin\\varphi\\cos\\theta & -r\\sin\\varphi\\sin\\theta & r\\cos\\varphi\n   \\end{vmatrix}\n   $$\n   $$\n   = \\big( (R+r\\cos\\varphi) r \\cos\\theta\\cos\\varphi,\\ (R+r\\cos\\varphi) r \\sin\\theta\\cos\\varphi,\\ (R+r\\cos\\varphi) r \\sin\\varphi \\big).\n   $$\n   Its length is\n   $$\n   |\\mathbf{X}_\\theta \\times \\mathbf{X}_\\varphi| = r(R+r\\cos\\varphi).\n   $$\n   Hence\n   $$\n   \\mathbf{n} = \\frac{\\mathbf{X}_\\theta \\times \\mathbf{X}_\\varphi}{|\\mathbf{X}_\\theta \\times \\mathbf{X}_\\varphi|} = \\big( \\cos\\theta\\cos\\varphi,\\ \\sin\\theta\\cos\\varphi,\\ \\sin\\varphi \\big).\n   $$\n\n4. **Second derivatives:**\n   $$\n   \\mathbf{X}_{\\theta\\theta} = \\frac{\\partial^2 \\mathbf{X}}{\\partial \\theta^2} = \\big( -(R+r\\cos\\varphi)\\cos\\theta,\\ -(R+r\\cos\\varphi)\\sin\\theta,\\ 0 \\big),\n   $$\n   $$\n   \\mathbf{X}_{\\theta\\varphi} = \\frac{\\partial^2 \\mathbf{X}}{\\partial \\theta\\,\\partial\\varphi} = \\big( r\\sin\\varphi\\sin\\theta,\\ -r\\sin\\varphi\\cos\\theta,\\ 0 \\big),\n   $$\n   $$\n   \\mathbf{X}_{\\varphi\\varphi} = \\frac{\\partial^2 \\mathbf{X}}{\\partial \\varphi^2} = \\big( -r\\cos\\varphi\\cos\\theta,\\ -r\\cos\\varphi\\sin\\theta,\\ -r\\sin\\varphi \\big).\n   $$\n\n5. **Second fundamental form coefficients:**\n   $$\n   L = \\mathbf{X}_{\\theta\\theta}\\cdot\\mathbf{n} = -(R+r\\cos\\varphi)\\cos\\varphi,\n   $$\n   $$\n   M = \\mathbf{X}_{\\theta\\varphi}\\cdot\\mathbf{n} = 0,\n   $$\n   $$\n   N = \\mathbf{X}_{\\varphi\\varphi}\\cdot\\mathbf{n} = -r.\n   $$\n\n6. **Gaussian curvature:**\n   $$\n   K = \\frac{LN - M^2}{EG - F^2} = \\frac{(-(R+r\\cos\\varphi)\\cos\\varphi)(-r)}{(R+r\\cos\\varphi)^2 \\cdot r^2} = \\frac{r(R+r\\cos\\varphi)\\cos\\varphi}{r^2 (R+r\\cos\\varphi)^2} = \\frac{\\cos\\varphi}{r(R+r\\cos\\varphi)}.\n   $$\n   As expected, $K$ depends only on $\\varphi$.\n\n7. **Area element:**\n   $$\n   dA = \\sqrt{EG - F^2}\\; d\\theta\\, d\\varphi = \\sqrt{(R+r\\cos\\varphi)^2 \\cdot r^2}\\; d\\theta\\, d\\varphi = r(R+r\\cos\\varphi)\\; d\\theta\\, d\\varphi.\n   $$\n\n8. **Total Gaussian curvature:**\n   $$\n   \\iint_T K\\, dA = \\int_{\\theta=0}^{2\\pi} \\int_{\\varphi=0}^{2\\pi} \\frac{\\cos\\varphi}{r(R+r\\cos\\varphi)} \\cdot r(R+r\\cos\\varphi)\\; d\\varphi\\, d\\theta\n   = \\int_0^{2\\pi} \\int_0^{2\\pi} \\cos\\varphi\\; d\\varphi\\, d\\theta.\n   $$\n   Since $\\int_0^{2\\pi} \\cos\\varphi\\, d\\varphi = 0$, the double integral equals $0$.\n\nThus the total Gaussian curvature of the torus is zero, as required.",
            "raw_answer": "[QUESTION]\nConsider the torus \\(T\\) obtained by rotating a circle of radius \\(r\\) about an axis in its plane that is a distance \\(R > r > 0\\) from the circle's center. Using the standard parametrization\n\\[\n\\mathbf{X}(\\theta, \\varphi) = \\big( (R + r\\cos\\varphi)\\cos\\theta,\\ (R + r\\cos\\varphi)\\sin\\theta,\\ r\\sin\\varphi \\big), \\qquad \\theta \\in [0,2\\pi),\\ \\varphi \\in [0,2\\pi),\n\\]\ncompute the Gaussian curvature \\(K\\) of the torus as a function of \\(\\varphi\\) (it is independent of \\(\\theta\\)). Then evaluate the total Gaussian curvature \\(\\iint_T K \\, dA\\) by direct integration, and verify that it equals zero.\n\n[ANSWER]\nWe proceed step by step.\n\n1. **First derivatives:**\n   \\[\n   \\mathbf{X}_\\theta = \\frac{\\partial \\mathbf{X}}{\\partial \\theta} = \\big( -(R+r\\cos\\varphi)\\sin\\theta,\\ (R+r\\cos\\varphi)\\cos\\theta,\\ 0 \\big),\n   \\]\n   \\[\n   \\mathbf{X}_\\varphi = \\frac{\\partial \\mathbf{X}}{\\partial \\varphi} = \\big( -r\\sin\\varphi\\cos\\theta,\\ -r\\sin\\varphi\\sin\\theta,\\ r\\cos\\varphi \\big).\n   \\]\n\n2. **First fundamental form:**\n   \\[\n   E = \\mathbf{X}_\\theta\\cdot\\mathbf{X}_\\theta = (R+r\\cos\\varphi)^2,\n   \\]\n   \\[\n   F = \\mathbf{X}_\\theta\\cdot\\mathbf{X}_\\varphi = 0,\n   \\]\n   \\[\n   G = \\mathbf{X}_\\varphi\\cdot\\mathbf{X}_\\varphi = r^2.\n   \\]\n   (The vanishing of \\(F\\) is easily checked.)\n\n3. **Unit normal vector:**\n   The cross product is\n   \\[\n   \\mathbf{X}_\\theta \\times \\mathbf{X}_\\varphi = \\begin{vmatrix}\n   \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\\n   -(R+r\\cos\\varphi)\\sin\\theta & (R+r\\cos\\varphi)\\cos\\theta & 0 \\\\\n   -r\\sin\\varphi\\cos\\theta & -r\\sin\\varphi\\sin\\theta & r\\cos\\varphi\n   \\end{vmatrix}\n   \\]\n   \\[\n   = \\big( (R+r\\cos\\varphi) r \\cos\\theta\\cos\\varphi,\\ (R+r\\cos\\varphi) r \\sin\\theta\\cos\\varphi,\\ (R+r\\cos\\varphi) r \\sin\\varphi \\big).\n   \\]\n   Its length is\n   \\[\n   |\\mathbf{X}_\\theta \\times \\mathbf{X}_\\varphi| = r(R+r\\cos\\varphi).\n   \\]\n   Hence\n   \\[\n   \\mathbf{n} = \\frac{\\mathbf{X}_\\theta \\times \\mathbf{X}_\\varphi}{|\\mathbf{X}_\\theta \\times \\mathbf{X}_\\varphi|} = \\big( \\cos\\theta\\cos\\varphi,\\ \\sin\\theta\\cos\\varphi,\\ \\sin\\varphi \\big).\n   \\]\n\n4. **Second derivatives:**\n   \\[\n   \\mathbf{X}_{\\theta\\theta} = \\frac{\\partial^2 \\mathbf{X}}{\\partial \\theta^2} = \\big( -(R+r\\cos\\varphi)\\cos\\theta,\\ -(R+r\\cos\\varphi)\\sin\\theta,\\ 0 \\big),\n   \\]\n   \\[\n   \\mathbf{X}_{\\theta\\varphi} = \\frac{\\partial^2 \\mathbf{X}}{\\partial \\theta\\,\\partial\\varphi} = \\big( r\\sin\\varphi\\sin\\theta,\\ -r\\sin\\varphi\\cos\\theta,\\ 0 \\big),\n   \\]\n   \\[\n   \\mathbf{X}_{\\varphi\\varphi} = \\frac{\\partial^2 \\mathbf{X}}{\\partial \\varphi^2} = \\big( -r\\cos\\varphi\\cos\\theta,\\ -r\\cos\\varphi\\sin\\theta,\\ -r\\sin\\varphi \\big).\n   \\]\n\n5. **Second fundamental form coefficients:**\n   \\[\n   L = \\mathbf{X}_{\\theta\\theta}\\cdot\\mathbf{n} = -(R+r\\cos\\varphi)\\cos\\varphi,\n   \\]\n   \\[\n   M = \\mathbf{X}_{\\theta\\varphi}\\cdot\\mathbf{n} = 0,\n   \\]\n   \\[\n   N = \\mathbf{X}_{\\varphi\\varphi}\\cdot\\mathbf{n} = -r.\n   \\]\n\n6. **Gaussian curvature:**\n   \\[\n   K = \\frac{LN - M^2}{EG - F^2} = \\frac{(-(R+r\\cos\\varphi)\\cos\\varphi)(-r)}{(R+r\\cos\\varphi)^2 \\cdot r^2} = \\frac{r(R+r\\cos\\varphi)\\cos\\varphi}{r^2 (R+r\\cos\\varphi)^2} = \\frac{\\cos\\varphi}{r(R+r\\cos\\varphi)}.\n   \\]\n   As expected, \\(K\\) depends only on \\(\\varphi\\).\n\n7. **Area element:**\n   \\[\n   dA = \\sqrt{EG - F^2}\\; d\\theta\\, d\\varphi = \\sqrt{(R+r\\cos\\varphi)^2 \\cdot r^2}\\; d\\theta\\, d\\varphi = r(R+r\\cos\\varphi)\\; d\\theta\\, d\\varphi.\n   \\]\n\n8. **Total Gaussian curvature:**\n   \\[\n   \\iint_T K\\, dA = \\int_{\\theta=0}^{2\\pi} \\int_{\\varphi=0}^{2\\pi} \\frac{\\cos\\varphi}{r(R+r\\cos\\varphi)} \\cdot r(R+r\\cos\\varphi)\\; d\\varphi\\, d\\theta\n   = \\int_0^{2\\pi} \\int_0^{2\\pi} \\cos\\varphi\\; d\\varphi\\, d\\theta.\n   \\]\n   Since \\(\\int_0^{2\\pi} \\cos\\varphi\\, d\\varphi = 0\\), the double integral equals \\(0\\).\n\nThus the total Gaussian curvature of the torus is zero, as required.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "38",
    "outer_attempt": 1,
    "topic_slug": "general_topology",
    "topic_name": "General topology",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Define the Sorgenfrey line $\\mathbb{R}_\\ell$ as the topological space whose underlying set is $\\mathbb{R}$ and whose topology is generated by the half-open intervals $[a,b)$ with $a<b$. The Sorgenfrey plane is the product space $\\mathbb{R}_\\ell \\times \\mathbb{R}_\\ell$.\n\nProve that the Sorgenfrey plane is not normal.",
            "answer": "We will prove that $\\mathbb{R}_\\ell^2$ is not normal by applying Jones' Lemma, which relates the cardinalities of a dense subset and a closed discrete subset in a normal space.\n\nFirst, we establish two key properties of $\\mathbb{R}_\\ell^2$.\n\n**1. A countable dense subset.**  \nThe set $\\mathbb{Q}^2 = \\{(p,q): p,q\\in\\mathbb{Q}\\}$ is dense in $\\mathbb{R}_\\ell^2$. Indeed, any basic open set has the form $[a,b)\\times[c,d)$. Since the rationals are dense in $\\mathbb{R}$ with the usual order, we can choose $p\\in\\mathbb{Q}\\cap[a,b)$ and $q\\in\\mathbb{Q}\\cap[c,d)$. Then $(p,q)\\in\\mathbb{Q}^2\\cap([a,b)\\times[c,d))$. Hence $\\mathbb{Q}^2$ is dense and $|\\mathbb{Q}^2| = \\aleph_0$.\n\n**2. An uncountable closed discrete subset.**  \nConsider the antidiagonal  \n$$\nL = \\{(x,-x): x\\in\\mathbb{R}\\}.\n$$  \nWe show that $L$ is closed and discrete in $\\mathbb{R}_\\ell^2$.\n\n- **Discrete:** For a fixed $x\\in\\mathbb{R}$, take the basic open set $U_x = [x, x+1)\\times[-x, -x+1)$. If $(y,-y)\\in L\\cap U_x$, then $y\\ge x$, $y<x+1$, $-y\\ge -x$, and $-y<-x+1$. The last two inequalities give $y\\le x$ and $y> x-1$. Thus $y=x$. Hence $U_x\\cap L = \\{(x,-x)\\}$, so $\\{(x,-x)\\}$ is open in the subspace topology on $L$. Therefore $L$ is discrete.\n\n- **Closed:** We show that the complement of $L$ is open. Let $(a,b)\\notin L$, so $a+b\\neq 0$. Set $\\varepsilon = |a+b|/2 > 0$ and $\\delta = \\varepsilon/2$. Consider the basic open neighbourhood $V = [a, a+\\delta)\\times[b, b+\\delta)$ of $(a,b)$. Suppose, for contradiction, that there exists $(x,-x)\\in L\\cap V$. Then $a\\le x < a+\\delta$ and $b\\le -x < b+\\delta$. Adding these inequalities yields  \n$$\na+b \\le 0 < a+b + 2\\delta = a+b + \\varepsilon.\n$$  \nIf $a+b > 0$, the left inequality $a+b\\le 0$ fails. If $a+b < 0$, then $a+b+\\varepsilon = a+b + |a+b|/2 = a+b - (a+b)/2 = (a+b)/2 < 0$, so the right inequality $0 < a+b+\\varepsilon$ fails. Thus no such $(x,-x)$ exists, so $V\\cap L = \\emptyset$. Hence $\\mathbb{R}_\\ell^2\\setminus L$ is open, i.e., $L$ is closed.\n\nClearly $|L| = \\mathfrak{c} = 2^{\\aleph_0}$.\n\n**3. Jones' Lemma.**  \nLet $X$ be a normal topological space, $D\\subseteq X$ a dense subset, and $S\\subseteq X$ a closed discrete subset. Then  \n$$\n2^{|S|} \\le 2^{|D|}.\n$$\n\n*Proof of Jones' Lemma.*  \nBecause $S$ is closed and discrete, every subset of $S$ is closed in $X$. Indeed, for each $s\\in S$ choose an open neighbourhood $U_s$ such that $U_s\\cap S = \\{s\\}$ (possible by discreteness). For any $T\\subseteq S$, the set  \n$$\nX\\setminus T = (X\\setminus S) \\cup \\bigcup_{s\\in S\\setminus T} U_s\n$$  \nis open, hence $T$ is closed. In particular, for any $T\\subseteq S$, both $T$ and $S\\setminus T$ are closed disjoint subsets of $X$.\n\nSince $X$ is normal, Urysohn's lemma furnishes a continuous function $f_T: X\\to [0,1]$ with $f_T|_T = 0$ and $f_T|_{S\\setminus T} = 1$.\n\nNow suppose $T_1,T_2\\subseteq S$ are distinct. Then there exists $s\\in S$ with, say, $s\\in T_1\\setminus T_2$. Then $f_{T_1}(s)=0$ and $f_{T_2}(s)=1$. If the restrictions $f_{T_1}|_D$ and $f_{T_2}|_D$ were equal, then because $D$ is dense and $[0,1]$ is Hausdorff, the set where two continuous functions agree is closed; hence $f_{T_1}=f_{T_2}$ on all of $X$, contradicting $f_{T_1}(s)\\neq f_{T_2}(s)$. Therefore the assignment $T\\mapsto f_T|_D$ is injective.\n\nConsequently,  \n$$\n2^{|S|} = |\\mathcal{P}(S)| \\le \\bigl|[0,1]^D\\bigr| = |[0,1]|^{|D|}.\n$$  \nThe cardinality of $[0,1]$ is $2^{\\aleph_0}$. Hence $|[0,1]|^{|D|} = (2^{\\aleph_0})^{|D|} = 2^{\\aleph_0\\cdot |D|}$. If $|D|$ is infinite, $\\aleph_0\\cdot|D| = |D|$, so this equals $2^{|D|}$. If $|D|$ is finite, then $X$ is finite (a finite dense set forces $X$ to be finite), and $S$ is finite as well; in that case $2^{|S|}\\le 2^{|D|}$ holds trivially. This completes the proof of Jones' Lemma.\n\n**4. Contradiction for the Sorgenfrey plane.**  \nAssume, for contradiction, that $\\mathbb{R}_\\ell^2$ is normal. Apply Jones' Lemma with $D = \\mathbb{Q}^2$ (dense, $|D|=\\aleph_0$) and $S = L$ (closed discrete, $|S| = \\mathfrak{c} = 2^{\\aleph_0}$). Then we would obtain  \n$$\n2^{2^{\\aleph_0}} = 2^{|S|} \\le 2^{|D|} = 2^{\\aleph_0}.\n$$  \nBut by Cantor's theorem, $2^{2^{\\aleph_0}} > 2^{\\aleph_0}$. This is a contradiction. Therefore $\\mathbb{R}_\\ell^2$ cannot be normal.\n\nThus the Sorgenfrey plane is not normal. $\\square$",
            "raw_answer": "[QUESTION]\nDefine the Sorgenfrey line $\\mathbb{R}_\\ell$ as the topological space whose underlying set is $\\mathbb{R}$ and whose topology is generated by the half-open intervals $[a,b)$ with $a<b$. The Sorgenfrey plane is the product space $\\mathbb{R}_\\ell \\times \\mathbb{R}_\\ell$.\n\nProve that the Sorgenfrey plane is not normal.\n\n[ANSWER]\nWe will prove that $\\mathbb{R}_\\ell^2$ is not normal by applying Jones' Lemma, which relates the cardinalities of a dense subset and a closed discrete subset in a normal space.\n\nFirst, we establish two key properties of $\\mathbb{R}_\\ell^2$.\n\n**1. A countable dense subset.**  \nThe set $\\mathbb{Q}^2 = \\{(p,q): p,q\\in\\mathbb{Q}\\}$ is dense in $\\mathbb{R}_\\ell^2$. Indeed, any basic open set has the form $[a,b)\\times[c,d)$. Since the rationals are dense in $\\mathbb{R}$ with the usual order, we can choose $p\\in\\mathbb{Q}\\cap[a,b)$ and $q\\in\\mathbb{Q}\\cap[c,d)$. Then $(p,q)\\in\\mathbb{Q}^2\\cap([a,b)\\times[c,d))$. Hence $\\mathbb{Q}^2$ is dense and $|\\mathbb{Q}^2| = \\aleph_0$.\n\n**2. An uncountable closed discrete subset.**  \nConsider the antidiagonal  \n\\[\nL = \\{(x,-x): x\\in\\mathbb{R}\\}.\n\\]  \nWe show that $L$ is closed and discrete in $\\mathbb{R}_\\ell^2$.\n\n- **Discrete:** For a fixed $x\\in\\mathbb{R}$, take the basic open set $U_x = [x, x+1)\\times[-x, -x+1)$. If $(y,-y)\\in L\\cap U_x$, then $y\\ge x$, $y<x+1$, $-y\\ge -x$, and $-y<-x+1$. The last two inequalities give $y\\le x$ and $y> x-1$. Thus $y=x$. Hence $U_x\\cap L = \\{(x,-x)\\}$, so $\\{(x,-x)\\}$ is open in the subspace topology on $L$. Therefore $L$ is discrete.\n\n- **Closed:** We show that the complement of $L$ is open. Let $(a,b)\\notin L$, so $a+b\\neq 0$. Set $\\varepsilon = |a+b|/2 > 0$ and $\\delta = \\varepsilon/2$. Consider the basic open neighbourhood $V = [a, a+\\delta)\\times[b, b+\\delta)$ of $(a,b)$. Suppose, for contradiction, that there exists $(x,-x)\\in L\\cap V$. Then $a\\le x < a+\\delta$ and $b\\le -x < b+\\delta$. Adding these inequalities yields  \n\\[\na+b \\le 0 < a+b + 2\\delta = a+b + \\varepsilon.\n\\]  \nIf $a+b > 0$, the left inequality $a+b\\le 0$ fails. If $a+b < 0$, then $a+b+\\varepsilon = a+b + |a+b|/2 = a+b - (a+b)/2 = (a+b)/2 < 0$, so the right inequality $0 < a+b+\\varepsilon$ fails. Thus no such $(x,-x)$ exists, so $V\\cap L = \\emptyset$. Hence $\\mathbb{R}_\\ell^2\\setminus L$ is open, i.e., $L$ is closed.\n\nClearly $|L| = \\mathfrak{c} = 2^{\\aleph_0}$.\n\n**3. Jones' Lemma.**  \nLet $X$ be a normal topological space, $D\\subseteq X$ a dense subset, and $S\\subseteq X$ a closed discrete subset. Then  \n\\[\n2^{|S|} \\le 2^{|D|}.\n\\]\n\n*Proof of Jones' Lemma.*  \nBecause $S$ is closed and discrete, every subset of $S$ is closed in $X$. Indeed, for each $s\\in S$ choose an open neighbourhood $U_s$ such that $U_s\\cap S = \\{s\\}$ (possible by discreteness). For any $T\\subseteq S$, the set  \n\\[\nX\\setminus T = (X\\setminus S) \\cup \\bigcup_{s\\in S\\setminus T} U_s\n\\]  \nis open, hence $T$ is closed. In particular, for any $T\\subseteq S$, both $T$ and $S\\setminus T$ are closed disjoint subsets of $X$.\n\nSince $X$ is normal, Urysohn's lemma furnishes a continuous function $f_T: X\\to [0,1]$ with $f_T|_T = 0$ and $f_T|_{S\\setminus T} = 1$.\n\nNow suppose $T_1,T_2\\subseteq S$ are distinct. Then there exists $s\\in S$ with, say, $s\\in T_1\\setminus T_2$. Then $f_{T_1}(s)=0$ and $f_{T_2}(s)=1$. If the restrictions $f_{T_1}|_D$ and $f_{T_2}|_D$ were equal, then because $D$ is dense and $[0,1]$ is Hausdorff, the set where two continuous functions agree is closed; hence $f_{T_1}=f_{T_2}$ on all of $X$, contradicting $f_{T_1}(s)\\neq f_{T_2}(s)$. Therefore the assignment $T\\mapsto f_T|_D$ is injective.\n\nConsequently,  \n\\[\n2^{|S|} = |\\mathcal{P}(S)| \\le \\bigl|[0,1]^D\\bigr| = |[0,1]|^{|D|}.\n\\]  \nThe cardinality of $[0,1]$ is $2^{\\aleph_0}$. Hence $|[0,1]|^{|D|} = (2^{\\aleph_0})^{|D|} = 2^{\\aleph_0\\cdot |D|}$. If $|D|$ is infinite, $\\aleph_0\\cdot|D| = |D|$, so this equals $2^{|D|}$. If $|D|$ is finite, then $X$ is finite (a finite dense set forces $X$ to be finite), and $S$ is finite as well; in that case $2^{|S|}\\le 2^{|D|}$ holds trivially. This completes the proof of Jones' Lemma.\n\n**4. Contradiction for the Sorgenfrey plane.**  \nAssume, for contradiction, that $\\mathbb{R}_\\ell^2$ is normal. Apply Jones' Lemma with $D = \\mathbb{Q}^2$ (dense, $|D|=\\aleph_0$) and $S = L$ (closed discrete, $|S| = \\mathfrak{c} = 2^{\\aleph_0}$). Then we would obtain  \n\\[\n2^{2^{\\aleph_0}} = 2^{|S|} \\le 2^{|D|} = 2^{\\aleph_0}.\n\\]  \nBut by Cantor's theorem, $2^{2^{\\aleph_0}} > 2^{\\aleph_0}$. This is a contradiction. Therefore $\\mathbb{R}_\\ell^2$ cannot be normal.\n\nThus the Sorgenfrey plane is not normal. $\\square$",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "39",
    "outer_attempt": 1,
    "topic_slug": "algebraic_topology",
    "topic_name": "Algebraic topology",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $T = S^1 \\times S^1$ be the torus, with coordinates $(z,w)$ where $|z|=|w|=1$.  \nDefine the simple closed curve $C \\subset T$ by  \n$$\nC = \\bigl\\{ (e^{4\\pi i t}, e^{2\\pi i t}) \\;\\big|\\; t \\in [0,1] \\bigr\\}.\n$$\n\nLet $M$ be the M\u00f6bius strip, constructed as the quotient space  \n$$\nM = [0,1] \\times [0,1] \\,/\\, \\sim, \\qquad \\text{where } (0,y) \\sim (1,1-y).\n$$\nDenote by $\\partial M$ the boundary of $M$; it is the image of the set  \n$\\{ (x,0) \\cup (x,1) \\mid x\\in[0,1] \\}$ under the quotient map and is homeomorphic to a circle.\n\nParameterize $\\partial M$ by  \n$$\n\\varphi(t) = [t,0] \\quad \\text{for } t\\in[0,1],\n$$\nwhere $[\\,\\cdot\\,]$ denotes the equivalence class in $M$. (Note that $\\varphi(0)=\\varphi(1)$ because $[0,0]\\sim[1,1]$, so $\\varphi$ is a closed loop.)  \nDefine an attaching map $f: \\partial M \\to C$ by $f(\\varphi(t)) = (e^{4\\pi i t}, e^{2\\pi i t})$.\n\nLet $X = T \\cup_f M$ be the space obtained by attaching $M$ to $T$ via $f$ (i.e., the quotient of the disjoint union $T \\sqcup M$ by identifying each point of $\\partial M$ with its image under $f$ in $C$).\n\nCompute the fundamental group $\\pi_1(X)$ (with basepoint chosen on the identified circle).",
            "answer": "We compute $\\pi_1(X)$ using the Seifert\u2013van Kampen theorem.\n\n\\subsection*{1. Open sets}\nChoose open sets $U$ and $V$ as follows:\n\\begin{itemize}\n  \\item $U = T \\cup N_M$, where $N_M$ is a small collar neighbourhood of $\\partial M$ in $M$ that deformation retracts onto $\\partial M$. Then $U$ deformation retracts onto $T$.\n  \\item $V = M \\cup N_T$, where $N_T$ is a small collar neighbourhood of $C$ in $T$ that deformation retracts onto $C$. Then $V$ deformation retracts onto $M$.\n\\end{itemize}\nThe intersection $U \\cap V$ is a neighbourhood of the attaching circle, which deformation retracts onto the circle $S^1 \\cong C \\cong \\partial M$. Choose the basepoint on this circle.\n\n\\subsection*{2. Fundamental groups of the pieces}\n\\paragraph{Torus.} $\\pi_1(T) \\cong \\mathbb{Z} \\times \\mathbb{Z}$. We choose generators:\n$$\na(t) = (e^{2\\pi i t}, 1), \\qquad b(t) = (1, e^{2\\pi i t}), \\quad t\\in[0,1].\n$$\nThus $\\pi_1(T) = \\langle a, b \\mid ab = ba \\rangle$.\n\n\\paragraph{M\u00f6bius strip.} The map $r: M \\to M$ defined by $r([x,y]) = [x, 1/2]$ is a deformation retraction of $M$ onto its core circle\n$$\n\\gamma(t) = [t, 1/2], \\quad t\\in[0,1].\n$$\nHence $\\pi_1(M) \\cong \\mathbb{Z}$, generated by $c = [\\gamma]$.\n\n\\paragraph{The boundary of $M$.} Under the retraction $r$, the loop $\\varphi(t)=[t,0]$ (which represents a generator of $\\pi_1(\\partial M)$) maps to\n$$\nr(\\varphi(t)) = [t, 1/2] = \\gamma(t).\n$$\nHowever, note that $\\varphi$ is not the same as $\\gamma$ because the endpoints are identified differently? Let us examine carefully.\n\nA more robust argument uses the projection $p: M \\to S^1$ given by $p([x,y]) = e^{2\\pi i x}$. This map is a homotopy equivalence; a homotopy inverse is $q: S^1 \\to M$, $q(e^{2\\pi i x}) = [x, 1/2]$. The composition $q \\circ p$ is homotopic to the identity on $M$. Now consider the inclusion $i: \\partial M \\hookrightarrow M$. The map $p \\circ i: \\partial M \\to S^1$ is a double covering: for each $x$, both $[x,0]$ and $[x,1]$ map to the same point, and going once around $\\partial M$ corresponds to going twice around the base circle. Therefore, on fundamental groups, the homomorphism induced by $i$ satisfies\n$$\n(p \\circ i)_*(\\text{generator}) = 2 \\cdot \\text{generator of } \\pi_1(S^1).\n$$\nSince $p$ is a homotopy equivalence, $p_*$ is an isomorphism, and we obtain\n$$\ni_*(\\text{generator}) = 2 c \\in \\pi_1(M).\n$$\nThus the loop $\\partial M$ represents $c^2$ in $\\pi_1(M)$.\n\n\\paragraph{The curve $C$ in $T$.} The curve $C$ is given by $\\psi(t) = (e^{4\\pi i t}, e^{2\\pi i t})$. In terms of the generators $a$ and $b$, this loop is homotopic to $a^2 b$. Indeed, the first coordinate makes two full rotations while the second makes one.\n\n\\subsection*{3. Seifert\u2013van Kampen}\nThe inclusion maps on the intersection circle induce:\n$$\ni_*: \\pi_1(U \\cap V) &\\to \\pi_1(T) \\quad \\text{sends the generator to } a^2 b,\\\\\nj_*: \\pi_1(U \\cap V) &\\to \\pi_1(M) \\quad \\text{sends the generator to } c^2.\n$$\nThe theorem gives\n$$\n\\pi_1(X) \\cong \\bigl( \\pi_1(T) * \\pi_1(M) \\bigr) \\big/ \\langle\\!\\langle i_*(g) = j_*(g) \\text{ for all } g \\in \\pi_1(U \\cap V) \\rangle\\!\\rangle.\n$$\nTaking $g$ to be the generator, we obtain the single relation $a^2 b = c^2$. Therefore,\n$$\n\\pi_1(X) \\cong \\langle a, b, c \\mid ab = ba,\\; a^2 b = c^2 \\rangle.\n$$\n\n\\subsection*{4. Simplification (optional)}\nWe may eliminate $b$ by writing $b = c^2 a^{-2}$. Substituting into the commutation relation $ab = ba$ yields\n$$\na (c^2 a^{-2}) = (c^2 a^{-2}) a \\;\\Longrightarrow\\; a c^2 a^{-2} = c^2 a^{-1} \\;\\Longrightarrow\\; a c^2 = c^2 a.\n$$\nThus an equivalent presentation is\n$$\n\\pi_1(X) \\cong \\langle a, c \\mid a c^2 = c^2 a \\rangle.\n$$\n\n\\subsection*{Conclusion}\nThe fundamental group of $X$ is\n$$\n\\pi_1(X) \\cong \\langle a, b, c \\mid ab = ba,\\; a^2 b = c^2 \\rangle,\n$$\nor equivalently $\\langle a, c \\mid a c^2 = c^2 a \\rangle$.",
            "raw_answer": "[QUESTION]\nLet \\(T = S^1 \\times S^1\\) be the torus, with coordinates \\((z,w)\\) where \\(|z|=|w|=1\\).  \nDefine the simple closed curve \\(C \\subset T\\) by  \n\\[\nC = \\bigl\\{ (e^{4\\pi i t}, e^{2\\pi i t}) \\;\\big|\\; t \\in [0,1] \\bigr\\}.\n\\]\n\nLet \\(M\\) be the M\u00f6bius strip, constructed as the quotient space  \n\\[\nM = [0,1] \\times [0,1] \\,/\\, \\sim, \\qquad \\text{where } (0,y) \\sim (1,1-y).\n\\]\nDenote by \\(\\partial M\\) the boundary of \\(M\\); it is the image of the set  \n\\(\\{ (x,0) \\cup (x,1) \\mid x\\in[0,1] \\}\\) under the quotient map and is homeomorphic to a circle.\n\nParameterize \\(\\partial M\\) by  \n\\[\n\\varphi(t) = [t,0] \\quad \\text{for } t\\in[0,1],\n\\]\nwhere \\([\\,\\cdot\\,]\\) denotes the equivalence class in \\(M\\). (Note that \\(\\varphi(0)=\\varphi(1)\\) because \\([0,0]\\sim[1,1]\\), so \\(\\varphi\\) is a closed loop.)  \nDefine an attaching map \\(f: \\partial M \\to C\\) by \\(f(\\varphi(t)) = (e^{4\\pi i t}, e^{2\\pi i t})\\).\n\nLet \\(X = T \\cup_f M\\) be the space obtained by attaching \\(M\\) to \\(T\\) via \\(f\\) (i.e., the quotient of the disjoint union \\(T \\sqcup M\\) by identifying each point of \\(\\partial M\\) with its image under \\(f\\) in \\(C\\)).\n\nCompute the fundamental group \\(\\pi_1(X)\\) (with basepoint chosen on the identified circle).\n\n[ANSWER]\nWe compute \\(\\pi_1(X)\\) using the Seifert\u2013van Kampen theorem.\n\n\\subsection*{1. Open sets}\nChoose open sets \\(U\\) and \\(V\\) as follows:\n\\begin{itemize}\n  \\item \\(U = T \\cup N_M\\), where \\(N_M\\) is a small collar neighbourhood of \\(\\partial M\\) in \\(M\\) that deformation retracts onto \\(\\partial M\\). Then \\(U\\) deformation retracts onto \\(T\\).\n  \\item \\(V = M \\cup N_T\\), where \\(N_T\\) is a small collar neighbourhood of \\(C\\) in \\(T\\) that deformation retracts onto \\(C\\). Then \\(V\\) deformation retracts onto \\(M\\).\n\\end{itemize}\nThe intersection \\(U \\cap V\\) is a neighbourhood of the attaching circle, which deformation retracts onto the circle \\(S^1 \\cong C \\cong \\partial M\\). Choose the basepoint on this circle.\n\n\\subsection*{2. Fundamental groups of the pieces}\n\\paragraph{Torus.} \\(\\pi_1(T) \\cong \\mathbb{Z} \\times \\mathbb{Z}\\). We choose generators:\n\\[\na(t) = (e^{2\\pi i t}, 1), \\qquad b(t) = (1, e^{2\\pi i t}), \\quad t\\in[0,1].\n\\]\nThus \\(\\pi_1(T) = \\langle a, b \\mid ab = ba \\rangle\\).\n\n\\paragraph{M\u00f6bius strip.} The map \\(r: M \\to M\\) defined by \\(r([x,y]) = [x, 1/2]\\) is a deformation retraction of \\(M\\) onto its core circle\n\\[\n\\gamma(t) = [t, 1/2], \\quad t\\in[0,1].\n\\]\nHence \\(\\pi_1(M) \\cong \\mathbb{Z}\\), generated by \\(c = [\\gamma]\\).\n\n\\paragraph{The boundary of \\(M\\).} Under the retraction \\(r\\), the loop \\(\\varphi(t)=[t,0]\\) (which represents a generator of \\(\\pi_1(\\partial M)\\)) maps to\n\\[\nr(\\varphi(t)) = [t, 1/2] = \\gamma(t).\n\\]\nHowever, note that \\(\\varphi\\) is not the same as \\(\\gamma\\) because the endpoints are identified differently? Let us examine carefully.\n\nA more robust argument uses the projection \\(p: M \\to S^1\\) given by \\(p([x,y]) = e^{2\\pi i x}\\). This map is a homotopy equivalence; a homotopy inverse is \\(q: S^1 \\to M\\), \\(q(e^{2\\pi i x}) = [x, 1/2]\\). The composition \\(q \\circ p\\) is homotopic to the identity on \\(M\\). Now consider the inclusion \\(i: \\partial M \\hookrightarrow M\\). The map \\(p \\circ i: \\partial M \\to S^1\\) is a double covering: for each \\(x\\), both \\([x,0]\\) and \\([x,1]\\) map to the same point, and going once around \\(\\partial M\\) corresponds to going twice around the base circle. Therefore, on fundamental groups, the homomorphism induced by \\(i\\) satisfies\n\\[\n(p \\circ i)_*(\\text{generator}) = 2 \\cdot \\text{generator of } \\pi_1(S^1).\n\\]\nSince \\(p\\) is a homotopy equivalence, \\(p_*\\) is an isomorphism, and we obtain\n\\[\ni_*(\\text{generator}) = 2 c \\in \\pi_1(M).\n\\]\nThus the loop \\(\\partial M\\) represents \\(c^2\\) in \\(\\pi_1(M)\\).\n\n\\paragraph{The curve \\(C\\) in \\(T\\).} The curve \\(C\\) is given by \\(\\psi(t) = (e^{4\\pi i t}, e^{2\\pi i t})\\). In terms of the generators \\(a\\) and \\(b\\), this loop is homotopic to \\(a^2 b\\). Indeed, the first coordinate makes two full rotations while the second makes one.\n\n\\subsection*{3. Seifert\u2013van Kampen}\nThe inclusion maps on the intersection circle induce:\n\\begin{align*}\ni_*: \\pi_1(U \\cap V) &\\to \\pi_1(T) \\quad \\text{sends the generator to } a^2 b,\\\\\nj_*: \\pi_1(U \\cap V) &\\to \\pi_1(M) \\quad \\text{sends the generator to } c^2.\n\\end{align*}\nThe theorem gives\n\\[\n\\pi_1(X) \\cong \\bigl( \\pi_1(T) * \\pi_1(M) \\bigr) \\big/ \\langle\\!\\langle i_*(g) = j_*(g) \\text{ for all } g \\in \\pi_1(U \\cap V) \\rangle\\!\\rangle.\n\\]\nTaking \\(g\\) to be the generator, we obtain the single relation \\(a^2 b = c^2\\). Therefore,\n\\[\n\\pi_1(X) \\cong \\langle a, b, c \\mid ab = ba,\\; a^2 b = c^2 \\rangle.\n\\]\n\n\\subsection*{4. Simplification (optional)}\nWe may eliminate \\(b\\) by writing \\(b = c^2 a^{-2}\\). Substituting into the commutation relation \\(ab = ba\\) yields\n\\[\na (c^2 a^{-2}) = (c^2 a^{-2}) a \\;\\Longrightarrow\\; a c^2 a^{-2} = c^2 a^{-1} \\;\\Longrightarrow\\; a c^2 = c^2 a.\n\\]\nThus an equivalent presentation is\n\\[\n\\pi_1(X) \\cong \\langle a, c \\mid a c^2 = c^2 a \\rangle.\n\\]\n\n\\subsection*{Conclusion}\nThe fundamental group of \\(X\\) is\n\\[\n\\pi_1(X) \\cong \\langle a, b, c \\mid ab = ba,\\; a^2 b = c^2 \\rangle,\n\\]\nor equivalently \\(\\langle a, c \\mid a c^2 = c^2 a \\rangle\\).",
            "evaluation": {
              "verdict": "fail",
              "ill_posed": true,
              "issues": [
                "The question is ill-posed: the given parameterization \u03c6(t)=[t,0] does not yield a closed loop because \u03c6(0)=[0,0] and \u03c6(1)=[1,0] are not equal under the provided equivalence relation (the note claiming \u03c6(0)=\u03c6(1) because [0,0]\u223c[1,1] is incorrect). The attaching map f is therefore not well-defined on the whole boundary.",
                "The answer proceeds as if the question were well-posed, without identifying this ill-posedness."
              ],
              "improvements": "First, identify that the question is ill-posed due to the inconsistent parameterization. Explain why \u03c6 is not a loop under the given identification. Do not attempt to compute \u03c01(X) under the flawed premises. If one wishes to salvage, suggest a corrected parameterization (e.g., define a loop that goes along the bottom and top edges) and then compute, but only after acknowledging the issue and clarifying the intended definitions."
            }
          }
        ],
        "status": "ill-posed"
      },
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $T$ denote the torus, represented as the quotient space of the square $[0,1]\\times[0,1]$ by identifying $(0,y)\\sim(1,y)$ and $(x,0)\\sim(x,1)$. Choose a closed disk $D\\subset T$ contained in the interior of the square (for instance, the image of a small Euclidean disk centered at $(1/2,1/2)$). Remove its interior to obtain the punctured torus $T_0 = T\\setminus\\operatorname{int}(D)$.\n\nLet $M$ be the M\u00f6bius strip, defined as the quotient of $[0,1]\\times[0,1]$ by $(0,y)\\sim(1,1-y)$. Its boundary $\\partial M$ is a circle.\n\nForm the space $X = T_0\\cup_h M$ by gluing $T_0$ and $M$ along their boundaries via a homeomorphism $h\\colon \\partial M\\to \\partial D$. (The choice of homeomorphism does not affect the answer up to isomorphism.)\n\nCompute the fundamental group $\\pi_1(X)$.",
            "answer": "We compute $\\pi_1(X)$ using the Seifert\u2013van Kampen theorem.\n\n**Step 1: Fundamental group of $T_0$.**  \nThe punctured torus $T_0$ deformation retracts onto its $1$-skeleton, which is a wedge of two circles. Concretely, let $a$ be the loop corresponding to the image of the bottom edge $\\{ (x,0) : 0\\le x\\le 1 \\}$ (traversed from left to right) and $b$ the loop corresponding to the left edge $\\{ (0,y) : 0\\le y\\le 1 \\}$ (traversed upward). After the identifications, these become two circles meeting at the basepoint (the image of $(0,0)$). The space $T_0$ retracts onto the wedge $a\\vee b$, so $\\pi_1(T_0) \\cong \\langle a,b \\rangle$, the free group on two generators. The boundary circle $\\partial D$ is homotopic to the loop that follows $a$, then $b$, then $a^{-1}$, then $b^{-1}$; i.e., it represents the commutator $[a,b] = a b a^{-1} b^{-1}$. (One way to see this is to note that the original torus $T$ is obtained from $T_0$ by attaching a $2$-cell along $\\partial D$, and the attaching map is exactly the commutator, because the standard cell structure of $T$ has one $2$-cell attached via $aba^{-1}b^{-1}$.)\n\n**Step 2: Fundamental group of $M$.**  \nThe M\u00f6bius strip $M$ deformation retracts onto its core circle $C$, which is the image of the line $\\{ (x,1/2) : 0\\le x\\le 1 \\}$ under the quotient map. Under this retraction, $\\pi_1(M) \\cong \\mathbb{Z}$, generated by $c = [C]$. The boundary $\\partial M$ is a circle that, when retracted onto $C$, winds twice around it (because the boundary consists of a single circle that is a $2$-fold cover of the core). Hence the homotopy class of $\\partial M$ in $\\pi_1(M)$ is $c^2$.\n\n**Step 3: Application of Seifert\u2013van Kampen.**  \nChoose open neighbourhoods $U$ and $V$ of $T_0$ and $M$ in $X$ that slightly thicken the boundaries so that $U\\cap V$ is an annular neighbourhood of the glued circle, which deformation retracts onto a circle representing the common boundary. Then $\\pi_1(U) \\cong \\pi_1(T_0)$, $\\pi_1(V) \\cong \\pi_1(M)$, and $\\pi_1(U\\cap V) \\cong \\mathbb{Z}$, generated by a loop $\\gamma$ that goes once around the boundary circle (with a fixed orientation). The inclusion $U\\cap V \\hookrightarrow U$ sends $\\gamma$ to the class of $\\partial D$, i.e., $[a,b]$. The inclusion $U\\cap V \\hookrightarrow V$ sends $\\gamma$ to the class of $\\partial M$, i.e., $c^2$. By the Seifert\u2013van Kampen theorem (amalgamated free product), we obtain\n$$\n\\pi_1(X) \\cong \\langle a,b,c \\mid [a,b] = c^2 \\rangle,\n$$\nwhere the relation comes from identifying the two images of $\\gamma$.\n\nThus the fundamental group of $X$ is\n$$\n\\pi_1(X) \\cong \\langle a, b, c \\mid a b a^{-1} b^{-1} = c^2 \\rangle.\n$$\n\n(One may note that this is the fundamental group of the connected sum $T^2 \\mathbin{\\#} \\mathbb{R}P^2$.)",
            "raw_answer": "[QUESTION]\nLet $T$ denote the torus, represented as the quotient space of the square $[0,1]\\times[0,1]$ by identifying $(0,y)\\sim(1,y)$ and $(x,0)\\sim(x,1)$. Choose a closed disk $D\\subset T$ contained in the interior of the square (for instance, the image of a small Euclidean disk centered at $(1/2,1/2)$). Remove its interior to obtain the punctured torus $T_0 = T\\setminus\\operatorname{int}(D)$.\n\nLet $M$ be the M\u00f6bius strip, defined as the quotient of $[0,1]\\times[0,1]$ by $(0,y)\\sim(1,1-y)$. Its boundary $\\partial M$ is a circle.\n\nForm the space $X = T_0\\cup_h M$ by gluing $T_0$ and $M$ along their boundaries via a homeomorphism $h\\colon \\partial M\\to \\partial D$. (The choice of homeomorphism does not affect the answer up to isomorphism.)\n\nCompute the fundamental group $\\pi_1(X)$.\n\n[ANSWER]\nWe compute $\\pi_1(X)$ using the Seifert\u2013van Kampen theorem.\n\n**Step 1: Fundamental group of $T_0$.**  \nThe punctured torus $T_0$ deformation retracts onto its $1$-skeleton, which is a wedge of two circles. Concretely, let $a$ be the loop corresponding to the image of the bottom edge $\\{ (x,0) : 0\\le x\\le 1 \\}$ (traversed from left to right) and $b$ the loop corresponding to the left edge $\\{ (0,y) : 0\\le y\\le 1 \\}$ (traversed upward). After the identifications, these become two circles meeting at the basepoint (the image of $(0,0)$). The space $T_0$ retracts onto the wedge $a\\vee b$, so $\\pi_1(T_0) \\cong \\langle a,b \\rangle$, the free group on two generators. The boundary circle $\\partial D$ is homotopic to the loop that follows $a$, then $b$, then $a^{-1}$, then $b^{-1}$; i.e., it represents the commutator $[a,b] = a b a^{-1} b^{-1}$. (One way to see this is to note that the original torus $T$ is obtained from $T_0$ by attaching a $2$-cell along $\\partial D$, and the attaching map is exactly the commutator, because the standard cell structure of $T$ has one $2$-cell attached via $aba^{-1}b^{-1}$.)\n\n**Step 2: Fundamental group of $M$.**  \nThe M\u00f6bius strip $M$ deformation retracts onto its core circle $C$, which is the image of the line $\\{ (x,1/2) : 0\\le x\\le 1 \\}$ under the quotient map. Under this retraction, $\\pi_1(M) \\cong \\mathbb{Z}$, generated by $c = [C]$. The boundary $\\partial M$ is a circle that, when retracted onto $C$, winds twice around it (because the boundary consists of a single circle that is a $2$-fold cover of the core). Hence the homotopy class of $\\partial M$ in $\\pi_1(M)$ is $c^2$.\n\n**Step 3: Application of Seifert\u2013van Kampen.**  \nChoose open neighbourhoods $U$ and $V$ of $T_0$ and $M$ in $X$ that slightly thicken the boundaries so that $U\\cap V$ is an annular neighbourhood of the glued circle, which deformation retracts onto a circle representing the common boundary. Then $\\pi_1(U) \\cong \\pi_1(T_0)$, $\\pi_1(V) \\cong \\pi_1(M)$, and $\\pi_1(U\\cap V) \\cong \\mathbb{Z}$, generated by a loop $\\gamma$ that goes once around the boundary circle (with a fixed orientation). The inclusion $U\\cap V \\hookrightarrow U$ sends $\\gamma$ to the class of $\\partial D$, i.e., $[a,b]$. The inclusion $U\\cap V \\hookrightarrow V$ sends $\\gamma$ to the class of $\\partial M$, i.e., $c^2$. By the Seifert\u2013van Kampen theorem (amalgamated free product), we obtain\n\\[\n\\pi_1(X) \\cong \\langle a,b,c \\mid [a,b] = c^2 \\rangle,\n\\]\nwhere the relation comes from identifying the two images of $\\gamma$.\n\nThus the fundamental group of $X$ is\n\\[\n\\pi_1(X) \\cong \\langle a, b, c \\mid a b a^{-1} b^{-1} = c^2 \\rangle.\n\\]\n\n(One may note that this is the fundamental group of the connected sum $T^2 \\mathbin{\\#} \\mathbb{R}P^2$.)",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "40",
    "outer_attempt": 1,
    "topic_slug": "manifolds_and_cell_complexes",
    "topic_name": "Manifolds and cell complexes",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $X_n$ denote the CW complex obtained by attaching a 2-cell to the circle $S^1$ via a map $f : \\partial D^2 \\to S^1$ of degree $n$, where $n \\in \\mathbb{Z}$. Determine all integers $n$ for which $X_n$ is a closed 2-manifold (i.e., a compact surface without boundary). For those values of $n$, identify the manifold up to homeomorphism.",
            "answer": "We prove that $X_n$ is a closed 2-manifold if and only if $n = \\pm 2$, and in these cases $X_n$ is homeomorphic to the real projective plane $\\mathbb{RP}^2$.\n\n**Step 1: Cell structure and Euler characteristic.**  \nThe CW complex $X_n$ has one 0\u2011cell (the base point of $S^1$), one 1\u2011cell (forming the circle), and one 2\u2011cell attached by $f$. Hence its Euler characteristic is\n$$\n\\chi(X_n) = 1 - 1 + 1 = 1.\n$$\n\n**Step 2: Necessary condition from classification of surfaces.**  \nAssume $X_n$ is a closed connected surface. By the classification of compact surfaces, the only closed surface with Euler characteristic $1$ is the real projective plane $\\mathbb{RP}^2$. (Orientable surfaces have even Euler characteristic; non\u2011orientable surfaces satisfy $\\chi = 2 - k$ where $k$ is the number of crosscaps. Setting $\\chi = 1$ forces $k = 1$, i.e., $\\mathbb{RP}^2$.) Therefore, if $X_n$ is a closed surface, it must be homeomorphic to $\\mathbb{RP}^2$.\n\n**Step 3: Fundamental group.**  \nThe 1\u2011skeleton is $S^1$, whose fundamental group is $\\mathbb{Z}$, generated by a loop $\\gamma$. Attaching the 2\u2011cell via a map of degree $n$ adds the relation $\\gamma^n = 1$. Consequently,\n$$\n\\pi_1(X_n) \\cong \n\\begin{cases}\n\\mathbb{Z}/n\\mathbb{Z}, & n \\neq 0,\\$$4pt]\n\\mathbb{Z}, & n = 0.\n\\end{cases}\n$$\nFor $\\mathbb{RP}^2$ we have $\\pi_1(\\mathbb{RP}^2) \\cong \\mathbb{Z}/2\\mathbb{Z}$. Thus, if $X_n \\cong \\mathbb{RP}^2$, we must have $|n| = 2$. (The sign does not affect the group, as $\\mathbb{Z}/2\\mathbb{Z}$ is unchanged.)\n\n**Step 4: Sufficiency \u2013 $X_{\\pm 2} \\cong \\mathbb{RP}^2$.**  \nThe real projective plane admits a standard CW decomposition: one 0\u2011cell, one 1\u2011cell, and one 2\u2011cell attached by the double covering map $g : S^1 \\to S^1,\\; g(z) = z^2$ (degree $2$). This is exactly the definition of $X_2$. Hence $X_2 \\cong \\mathbb{RP}^2$. For $n = -2$, the attaching map $z \\mapsto \\bar{z}^2$ also has degree $-2$; composing with a reflection of the disk yields a homeomorphism between $X_{-2}$ and $X_2$, so $X_{-2} \\cong \\mathbb{RP}^2$ as well.\n\n**Step 5: Why other integers fail.**  \n- $n = 0$: The attaching map is null\u2011homotopic, so $X_0$ is homotopy equivalent to $S^1 \\vee S^2$. This space is not a manifold (the wedge point has no neighbourhood homeomorphic to $\\mathbb{R}^2$).  \n- $|n| = 1$: The attaching map is a homeomorphism. Then $X_{\\pm1}$ is homeomorphic to the closed disk $D^2$, which is a manifold with boundary, not a closed manifold.  \n- $|n| \\ge 3$: Here $\\pi_1(X_n)$ is a finite cyclic group of order $|n| \\ge 3$. The only closed surfaces with finite fundamental group are $S^2$ (trivial) and $\\mathbb{RP}^2$ ($\\mathbb{Z}/2\\mathbb{Z}$). Since $\\chi(X_n)=1$ excludes $S^2$ (which has $\\chi=2$), $X_n$ cannot be a closed surface. (One may also examine the local structure: a point on the 1\u2011skeleton has a neighbourhood that is a cone on $|n|$ points; this is homeomorphic to $\\mathbb{R}^2$ only when $|n|=2$, while for $|n|=1$ it gives a half\u2011plane, and for $|n|\\ge 3$ it is not a manifold.)\n\n**Conclusion.**  \nThe integers for which $X_n$ is a closed 2\u2011manifold are $n = 2$ and $n = -2$, and in both cases $X_n \\cong \\mathbb{RP}^2$.",
            "raw_answer": "[QUESTION]\nLet \\(X_n\\) denote the CW complex obtained by attaching a 2-cell to the circle \\(S^1\\) via a map \\(f : \\partial D^2 \\to S^1\\) of degree \\(n\\), where \\(n \\in \\mathbb{Z}\\). Determine all integers \\(n\\) for which \\(X_n\\) is a closed 2-manifold (i.e., a compact surface without boundary). For those values of \\(n\\), identify the manifold up to homeomorphism.\n\n[ANSWER]\nWe prove that \\(X_n\\) is a closed 2-manifold if and only if \\(n = \\pm 2\\), and in these cases \\(X_n\\) is homeomorphic to the real projective plane \\(\\mathbb{RP}^2\\).\n\n**Step 1: Cell structure and Euler characteristic.**  \nThe CW complex \\(X_n\\) has one 0\u2011cell (the base point of \\(S^1\\)), one 1\u2011cell (forming the circle), and one 2\u2011cell attached by \\(f\\). Hence its Euler characteristic is\n\\[\n\\chi(X_n) = 1 - 1 + 1 = 1.\n\\]\n\n**Step 2: Necessary condition from classification of surfaces.**  \nAssume \\(X_n\\) is a closed connected surface. By the classification of compact surfaces, the only closed surface with Euler characteristic \\(1\\) is the real projective plane \\(\\mathbb{RP}^2\\). (Orientable surfaces have even Euler characteristic; non\u2011orientable surfaces satisfy \\(\\chi = 2 - k\\) where \\(k\\) is the number of crosscaps. Setting \\(\\chi = 1\\) forces \\(k = 1\\), i.e., \\(\\mathbb{RP}^2\\).) Therefore, if \\(X_n\\) is a closed surface, it must be homeomorphic to \\(\\mathbb{RP}^2\\).\n\n**Step 3: Fundamental group.**  \nThe 1\u2011skeleton is \\(S^1\\), whose fundamental group is \\(\\mathbb{Z}\\), generated by a loop \\(\\gamma\\). Attaching the 2\u2011cell via a map of degree \\(n\\) adds the relation \\(\\gamma^n = 1\\). Consequently,\n\\[\n\\pi_1(X_n) \\cong \n\\begin{cases}\n\\mathbb{Z}/n\\mathbb{Z}, & n \\neq 0,\\\\[4pt]\n\\mathbb{Z}, & n = 0.\n\\end{cases}\n\\]\nFor \\(\\mathbb{RP}^2\\) we have \\(\\pi_1(\\mathbb{RP}^2) \\cong \\mathbb{Z}/2\\mathbb{Z}\\). Thus, if \\(X_n \\cong \\mathbb{RP}^2\\), we must have \\(|n| = 2\\). (The sign does not affect the group, as \\(\\mathbb{Z}/2\\mathbb{Z}\\) is unchanged.)\n\n**Step 4: Sufficiency \u2013 \\(X_{\\pm 2} \\cong \\mathbb{RP}^2\\).**  \nThe real projective plane admits a standard CW decomposition: one 0\u2011cell, one 1\u2011cell, and one 2\u2011cell attached by the double covering map \\(g : S^1 \\to S^1,\\; g(z) = z^2\\) (degree \\(2\\)). This is exactly the definition of \\(X_2\\). Hence \\(X_2 \\cong \\mathbb{RP}^2\\). For \\(n = -2\\), the attaching map \\(z \\mapsto \\bar{z}^2\\) also has degree \\(-2\\); composing with a reflection of the disk yields a homeomorphism between \\(X_{-2}\\) and \\(X_2\\), so \\(X_{-2} \\cong \\mathbb{RP}^2\\) as well.\n\n**Step 5: Why other integers fail.**  \n- \\(n = 0\\): The attaching map is null\u2011homotopic, so \\(X_0\\) is homotopy equivalent to \\(S^1 \\vee S^2\\). This space is not a manifold (the wedge point has no neighbourhood homeomorphic to \\(\\mathbb{R}^2\\)).  \n- \\(|n| = 1\\): The attaching map is a homeomorphism. Then \\(X_{\\pm1}\\) is homeomorphic to the closed disk \\(D^2\\), which is a manifold with boundary, not a closed manifold.  \n- \\(|n| \\ge 3\\): Here \\(\\pi_1(X_n)\\) is a finite cyclic group of order \\(|n| \\ge 3\\). The only closed surfaces with finite fundamental group are \\(S^2\\) (trivial) and \\(\\mathbb{RP}^2\\) (\\(\\mathbb{Z}/2\\mathbb{Z}\\)). Since \\(\\chi(X_n)=1\\) excludes \\(S^2\\) (which has \\(\\chi=2\\)), \\(X_n\\) cannot be a closed surface. (One may also examine the local structure: a point on the 1\u2011skeleton has a neighbourhood that is a cone on \\(|n|\\) points; this is homeomorphic to \\(\\mathbb{R}^2\\) only when \\(|n|=2\\), while for \\(|n|=1\\) it gives a half\u2011plane, and for \\(|n|\\ge 3\\) it is not a manifold.)\n\n**Conclusion.**  \nThe integers for which \\(X_n\\) is a closed 2\u2011manifold are \\(n = 2\\) and \\(n = -2\\), and in both cases \\(X_n \\cong \\mathbb{RP}^2\\).",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "41",
    "outer_attempt": 1,
    "topic_slug": "global_analysis_on_manifolds",
    "topic_name": "Global analysis, analysis on manifolds",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $S^n$ denote the unit sphere in $\\mathbb{R}^{n+1}$ (with $n \\ge 1$). Compute the de Rham cohomology groups $H^k_{\\mathrm{dR}}(S^n)$ for all integers $k \\ge 0$. Provide a complete proof using the Mayer\u2013Vietoris sequence for de Rham cohomology.",
            "answer": "We will compute $H^k_{\\mathrm{dR}}(S^n)$ by induction on $n$. The result is:\n$$\nH^k_{\\mathrm{dR}}(S^n) \\cong \n\\begin{cases}\n\\mathbb{R} & \\text{if } k = 0 \\text{ or } k = n, \\$$2pt]\n0 & \\text{otherwise}.\n\\end{cases}\n$$\n\nWe first recall the Mayer\u2013Vietoris exact sequence for de Rham cohomology: if $M$ is a smooth manifold and $U,V$ are open subsets such that $M = U \\cup V$, then there is a long exact sequence\n$$\n\\cdots \\to H^{k-1}(U \\cap V) \\to H^k(M) \\to H^k(U) \\oplus H^k(V) \\to H^k(U \\cap V) \\to H^{k+1}(M) \\to \\cdots\n$$\n\nWe also use homotopy invariance: if two manifolds are smoothly homotopy equivalent, then their de Rham cohomology groups are isomorphic.\n\n\\medskip\n\n\\noindent \\textbf{Base case: $n = 1$.} \nTake $U = S^1 \\setminus \\{N\\}$ and $V = S^1 \\setminus \\{S\\}$, where $N$ and $S$ are the north and south poles (any two distinct points). Both $U$ and $V$ are diffeomorphic to an open interval, hence contractible. Their intersection $U \\cap V$ consists of two disjoint open intervals, each contractible, so $U \\cap V$ is homotopy equivalent to a disjoint union of two points. Thus\n$$\nH^0(U) \\cong H^0(V) \\cong \\mathbb{R},\\quad H^k(U) = H^k(V) = 0\\ \\text{for } k \\ge 1,\n$$\n$$\nH^0(U \\cap V) \\cong \\mathbb{R} \\oplus \\mathbb{R},\\quad H^k(U \\cap V) = 0\\ \\text{for } k \\ge 1.\n$$\nThe Mayer\u2013Vietoris sequence gives\n$$\n0 \\to H^0(S^1) \\to \\mathbb{R} \\oplus \\mathbb{R} \\to \\mathbb{R} \\oplus \\mathbb{R} \\to H^1(S^1) \\to 0.\n$$\nThe middle map $H^0(U) \\oplus H^0(V) \\to H^0(U \\cap V)$ is induced by $(f,g) \\mapsto f|_{U\\cap V} - g|_{U\\cap V}$. Since $U$ and $V$ are connected, $H^0(U)$ and $H^0(V)$ consist of constant functions. Let the two components of $U \\cap V$ be $A$ and $B$. The restriction of a constant function $c$ on $U$ to $U\\cap V$ gives the constant $c$ on both $A$ and $B$, similarly for $V$. Hence, identifying constants with their values, the map becomes\n$$\n(a,b) \\mapsto (a - b, a - b) \\in \\mathbb{R} \\oplus \\mathbb{R}.\n$$\nIts image is the diagonal $\\{(d,d) : d \\in \\mathbb{R}\\} \\cong \\mathbb{R}$, and its kernel is $\\{(a,a) : a \\in \\mathbb{R}\\} \\cong \\mathbb{R}$. Exactness then yields:\n\\begin{itemize}\n\\item $H^0(S^1) \\cong \\ker(\\mathbb{R}\\oplus\\mathbb{R} \\to \\mathbb{R}\\oplus\\mathbb{R}) \\cong \\mathbb{R}$.\n\\item The cokernel of the middle map is $(\\mathbb{R}\\oplus\\mathbb{R})/\\text{diagonal} \\cong \\mathbb{R}$. The map $H^0(U\\cap V) \\to H^1(S^1)$ has kernel equal to the image of the previous map (the diagonal), so it induces an injection of this cokernel into $H^1(S^1)$. Since the next map $H^1(S^1) \\to 0$ is zero, this injection is also surjective. Hence $H^1(S^1) \\cong \\mathbb{R}$.\n\\end{itemize}\nThus $H^0(S^1) \\cong \\mathbb{R}$, $H^1(S^1) \\cong \\mathbb{R}$, which matches the claimed formula (since $n=1$, $H^1$ is $\\mathbb{R}$).\n\n\\medskip\n\n\\noindent \\textbf{Inductive step.} Assume $n \\ge 2$ and that the result holds for $S^{n-1}$. \nAgain choose $U = S^n \\setminus \\{N\\}$ and $V = S^n \\setminus \\{S\\}$, where $N = (0,\\ldots,0,1)$ and $S = (0,\\ldots,0,-1)$. Stereographic projection shows that $U$ and $V$ are diffeomorphic to $\\mathbb{R}^n$, hence contractible. Therefore\n$$\nH^0(U) \\cong H^0(V) \\cong \\mathbb{R},\\quad H^k(U) = H^k(V) = 0\\ \\text{for } k \\ge 1.\n$$\nThe intersection $U \\cap V = S^n \\setminus \\{N,S\\}$ is diffeomorphic to $\\mathbb{R}^n \\setminus \\{0\\}$ (by stereographic projection from $N$, for instance). The space $\\mathbb{R}^n \\setminus \\{0\\}$ retracts onto $S^{n-1}$ via $x \\mapsto x/\\|x\\|$, so it is homotopy equivalent to $S^{n-1}$. Hence\n$$\nH^k(U \\cap V) \\cong H^k(S^{n-1}) \\quad \\text{for all } k.\n$$\nBy the induction hypothesis,\n$$\nH^k(S^{n-1}) \\cong \n\\begin{cases}\n\\mathbb{R} & \\text{if } k = 0 \\text{ or } k = n-1,\\$$2pt]\n0 & \\text{otherwise}.\n\\end{cases}\n$$\n\nNow apply the Mayer\u2013Vietoris sequence for $S^n$. We consider two parts.\n\n\\emph{Low degrees ($k=0$).} The beginning of the sequence is\n$$\n0 \\to H^0(S^n) \\to H^0(U) \\oplus H^0(V) \\to H^0(U \\cap V) \\to H^1(S^n) \\to 0.\n$$\nHere $H^0(U) \\oplus H^0(V) \\cong \\mathbb{R} \\oplus \\mathbb{R}$, and $H^0(U \\cap V) \\cong H^0(S^{n-1}) \\cong \\mathbb{R}$ (since $n-1 \\ge 1$, $S^{n-1}$ is connected). The map $H^0(U) \\oplus H^0(V) \\to H^0(U \\cap V)$ is induced by $(f,g) \\mapsto f|_{U\\cap V} - g|_{U\\cap V}$. Because $U$, $V$, and $U\\cap V$ are connected, each cohomology class is represented by a constant function. Identifying constants with their values, the map becomes\n$$\n(a,b) \\mapsto a - b \\in \\mathbb{R}.\n$$\nThis map is surjective (any real number is a difference of two constants) and its kernel is $\\{(a,a) : a \\in \\mathbb{R}\\} \\cong \\mathbb{R}$. Exactness then gives:\n\\begin{itemize}\n\\item $H^0(S^n) \\cong \\ker(\\mathbb{R}\\oplus\\mathbb{R} \\to \\mathbb{R}) \\cong \\mathbb{R}$.\n\\item Since the map $\\mathbb{R}\\oplus\\mathbb{R} \\to \\mathbb{R}$ is surjective, its image equals $H^0(U\\cap V)$. Hence the kernel of the next map $H^0(U\\cap V) \\to H^1(S^n)$ is all of $H^0(U\\cap V)$, so that map is zero. Then exactness at $H^1(S^n)$ (the map $H^1(S^n) \\to 0$ is zero) forces $H^1(S^n) = 0$.\n\\end{itemize}\nThus $H^0(S^n) \\cong \\mathbb{R}$ and $H^1(S^n) = 0$ for $n \\ge 2$.\n\n\\emph{Higher degrees ($k \\ge 1$).} For $k \\ge 1$, the relevant portion of the Mayer\u2013Vietoris sequence is\n$$\n\\cdots \\to H^k(U) \\oplus H^k(V) \\to H^k(U \\cap V) \\to H^{k+1}(S^n) \\to H^{k+1}(U) \\oplus H^{k+1}(V) \\to \\cdots\n$$\nBecause $H^k(U) = H^k(V) = 0$ for all $k \\ge 1$, this reduces to short exact sequences\n$$\n0 \\to H^k(U \\cap V) \\to H^{k+1}(S^n) \\to 0,\n$$\nwhich are isomorphisms\n$$\nH^{k+1}(S^n) \\cong H^k(U \\cap V) \\quad \\text{for all } k \\ge 1.\n$$\nUsing the homotopy equivalence $U \\cap V \\simeq S^{n-1}$, we obtain\n$$\nH^{k+1}(S^n) \\cong H^k(S^{n-1}) \\quad \\text{for all } k \\ge 1.\n$$\n\nNow we compute:\n\\begin{itemize}\n\\item For $k = 0$, we already handled $H^0$ and $H^1$.\n\\item For $2 \\le m \\le n-1$ (i.e., $m = k+1$ with $k \\ge 1$ and $k \\le n-2$), we have\n$$\nH^m(S^n) \\cong H^{m-1}(S^{n-1}).\n$$\nBy the induction hypothesis, $H^{m-1}(S^{n-1}) = 0$ because $1 \\le m-1 \\le n-2$ (since $m \\le n-1$). Hence $H^m(S^n) = 0$.\n\\item For $m = n$, take $k = n-1$ (which is $\\ge 1$ because $n \\ge 2$). Then\n$$\nH^n(S^n) \\cong H^{n-1}(U \\cap V) \\cong H^{n-1}(S^{n-1}) \\cong \\mathbb{R}.\n$$\n\\item For $m > n$, we have $k = m-1 \\ge n$. But $H^k(S^{n-1}) = 0$ for $k > n-1$ (since the top degree is $n-1$). Thus $H^m(S^n) = 0$ for $m > n$.\n\\end{itemize}\n\nCombining all cases, we have proved that for $n \\ge 2$,\n$$\nH^k_{\\mathrm{dR}}(S^n) \\cong \n\\begin{cases}\n\\mathbb{R} & k = 0 \\text{ or } k = n,\\$$2pt]\n0 & \\text{otherwise}.\n\\end{cases}\n$$\n\nThe base case $n=1$ also satisfies this pattern (with $H^1(S^1) \\cong \\mathbb{R}$). Therefore by induction the formula holds for all $n \\ge 1$.\n\n\\medskip\n\n\\noindent \\textbf{Remark.} The same result can be obtained by other methods (e.g., using the long exact sequence of the pair, or by cellular cohomology), but the Mayer\u2013Vietoris argument presented here is a standard and elementary proof in de Rham theory.",
            "raw_answer": "[QUESTION]\nLet $S^n$ denote the unit sphere in $\\mathbb{R}^{n+1}$ (with $n \\ge 1$). Compute the de Rham cohomology groups $H^k_{\\mathrm{dR}}(S^n)$ for all integers $k \\ge 0$. Provide a complete proof using the Mayer\u2013Vietoris sequence for de Rham cohomology.\n\n[ANSWER]\nWe will compute $H^k_{\\mathrm{dR}}(S^n)$ by induction on $n$. The result is:\n\\[\nH^k_{\\mathrm{dR}}(S^n) \\cong \n\\begin{cases}\n\\mathbb{R} & \\text{if } k = 0 \\text{ or } k = n, \\\\[2pt]\n0 & \\text{otherwise}.\n\\end{cases}\n\\]\n\nWe first recall the Mayer\u2013Vietoris exact sequence for de Rham cohomology: if $M$ is a smooth manifold and $U,V$ are open subsets such that $M = U \\cup V$, then there is a long exact sequence\n\\[\n\\cdots \\to H^{k-1}(U \\cap V) \\to H^k(M) \\to H^k(U) \\oplus H^k(V) \\to H^k(U \\cap V) \\to H^{k+1}(M) \\to \\cdots\n\\]\n\nWe also use homotopy invariance: if two manifolds are smoothly homotopy equivalent, then their de Rham cohomology groups are isomorphic.\n\n\\medskip\n\n\\noindent \\textbf{Base case: $n = 1$.} \nTake $U = S^1 \\setminus \\{N\\}$ and $V = S^1 \\setminus \\{S\\}$, where $N$ and $S$ are the north and south poles (any two distinct points). Both $U$ and $V$ are diffeomorphic to an open interval, hence contractible. Their intersection $U \\cap V$ consists of two disjoint open intervals, each contractible, so $U \\cap V$ is homotopy equivalent to a disjoint union of two points. Thus\n\\[\nH^0(U) \\cong H^0(V) \\cong \\mathbb{R},\\quad H^k(U) = H^k(V) = 0\\ \\text{for } k \\ge 1,\n\\]\n\\[\nH^0(U \\cap V) \\cong \\mathbb{R} \\oplus \\mathbb{R},\\quad H^k(U \\cap V) = 0\\ \\text{for } k \\ge 1.\n\\]\nThe Mayer\u2013Vietoris sequence gives\n\\[\n0 \\to H^0(S^1) \\to \\mathbb{R} \\oplus \\mathbb{R} \\to \\mathbb{R} \\oplus \\mathbb{R} \\to H^1(S^1) \\to 0.\n\\]\nThe middle map $H^0(U) \\oplus H^0(V) \\to H^0(U \\cap V)$ is induced by $(f,g) \\mapsto f|_{U\\cap V} - g|_{U\\cap V}$. Since $U$ and $V$ are connected, $H^0(U)$ and $H^0(V)$ consist of constant functions. Let the two components of $U \\cap V$ be $A$ and $B$. The restriction of a constant function $c$ on $U$ to $U\\cap V$ gives the constant $c$ on both $A$ and $B$, similarly for $V$. Hence, identifying constants with their values, the map becomes\n\\[\n(a,b) \\mapsto (a - b, a - b) \\in \\mathbb{R} \\oplus \\mathbb{R}.\n\\]\nIts image is the diagonal $\\{(d,d) : d \\in \\mathbb{R}\\} \\cong \\mathbb{R}$, and its kernel is $\\{(a,a) : a \\in \\mathbb{R}\\} \\cong \\mathbb{R}$. Exactness then yields:\n\\begin{itemize}\n\\item $H^0(S^1) \\cong \\ker(\\mathbb{R}\\oplus\\mathbb{R} \\to \\mathbb{R}\\oplus\\mathbb{R}) \\cong \\mathbb{R}$.\n\\item The cokernel of the middle map is $(\\mathbb{R}\\oplus\\mathbb{R})/\\text{diagonal} \\cong \\mathbb{R}$. The map $H^0(U\\cap V) \\to H^1(S^1)$ has kernel equal to the image of the previous map (the diagonal), so it induces an injection of this cokernel into $H^1(S^1)$. Since the next map $H^1(S^1) \\to 0$ is zero, this injection is also surjective. Hence $H^1(S^1) \\cong \\mathbb{R}$.\n\\end{itemize}\nThus $H^0(S^1) \\cong \\mathbb{R}$, $H^1(S^1) \\cong \\mathbb{R}$, which matches the claimed formula (since $n=1$, $H^1$ is $\\mathbb{R}$).\n\n\\medskip\n\n\\noindent \\textbf{Inductive step.} Assume $n \\ge 2$ and that the result holds for $S^{n-1}$. \nAgain choose $U = S^n \\setminus \\{N\\}$ and $V = S^n \\setminus \\{S\\}$, where $N = (0,\\ldots,0,1)$ and $S = (0,\\ldots,0,-1)$. Stereographic projection shows that $U$ and $V$ are diffeomorphic to $\\mathbb{R}^n$, hence contractible. Therefore\n\\[\nH^0(U) \\cong H^0(V) \\cong \\mathbb{R},\\quad H^k(U) = H^k(V) = 0\\ \\text{for } k \\ge 1.\n\\]\nThe intersection $U \\cap V = S^n \\setminus \\{N,S\\}$ is diffeomorphic to $\\mathbb{R}^n \\setminus \\{0\\}$ (by stereographic projection from $N$, for instance). The space $\\mathbb{R}^n \\setminus \\{0\\}$ retracts onto $S^{n-1}$ via $x \\mapsto x/\\|x\\|$, so it is homotopy equivalent to $S^{n-1}$. Hence\n\\[\nH^k(U \\cap V) \\cong H^k(S^{n-1}) \\quad \\text{for all } k.\n\\]\nBy the induction hypothesis,\n\\[\nH^k(S^{n-1}) \\cong \n\\begin{cases}\n\\mathbb{R} & \\text{if } k = 0 \\text{ or } k = n-1,\\\\[2pt]\n0 & \\text{otherwise}.\n\\end{cases}\n\\]\n\nNow apply the Mayer\u2013Vietoris sequence for $S^n$. We consider two parts.\n\n\\emph{Low degrees ($k=0$).} The beginning of the sequence is\n\\[\n0 \\to H^0(S^n) \\to H^0(U) \\oplus H^0(V) \\to H^0(U \\cap V) \\to H^1(S^n) \\to 0.\n\\]\nHere $H^0(U) \\oplus H^0(V) \\cong \\mathbb{R} \\oplus \\mathbb{R}$, and $H^0(U \\cap V) \\cong H^0(S^{n-1}) \\cong \\mathbb{R}$ (since $n-1 \\ge 1$, $S^{n-1}$ is connected). The map $H^0(U) \\oplus H^0(V) \\to H^0(U \\cap V)$ is induced by $(f,g) \\mapsto f|_{U\\cap V} - g|_{U\\cap V}$. Because $U$, $V$, and $U\\cap V$ are connected, each cohomology class is represented by a constant function. Identifying constants with their values, the map becomes\n\\[\n(a,b) \\mapsto a - b \\in \\mathbb{R}.\n\\]\nThis map is surjective (any real number is a difference of two constants) and its kernel is $\\{(a,a) : a \\in \\mathbb{R}\\} \\cong \\mathbb{R}$. Exactness then gives:\n\\begin{itemize}\n\\item $H^0(S^n) \\cong \\ker(\\mathbb{R}\\oplus\\mathbb{R} \\to \\mathbb{R}) \\cong \\mathbb{R}$.\n\\item Since the map $\\mathbb{R}\\oplus\\mathbb{R} \\to \\mathbb{R}$ is surjective, its image equals $H^0(U\\cap V)$. Hence the kernel of the next map $H^0(U\\cap V) \\to H^1(S^n)$ is all of $H^0(U\\cap V)$, so that map is zero. Then exactness at $H^1(S^n)$ (the map $H^1(S^n) \\to 0$ is zero) forces $H^1(S^n) = 0$.\n\\end{itemize}\nThus $H^0(S^n) \\cong \\mathbb{R}$ and $H^1(S^n) = 0$ for $n \\ge 2$.\n\n\\emph{Higher degrees ($k \\ge 1$).} For $k \\ge 1$, the relevant portion of the Mayer\u2013Vietoris sequence is\n\\[\n\\cdots \\to H^k(U) \\oplus H^k(V) \\to H^k(U \\cap V) \\to H^{k+1}(S^n) \\to H^{k+1}(U) \\oplus H^{k+1}(V) \\to \\cdots\n\\]\nBecause $H^k(U) = H^k(V) = 0$ for all $k \\ge 1$, this reduces to short exact sequences\n\\[\n0 \\to H^k(U \\cap V) \\to H^{k+1}(S^n) \\to 0,\n\\]\nwhich are isomorphisms\n\\[\nH^{k+1}(S^n) \\cong H^k(U \\cap V) \\quad \\text{for all } k \\ge 1.\n\\]\nUsing the homotopy equivalence $U \\cap V \\simeq S^{n-1}$, we obtain\n\\[\nH^{k+1}(S^n) \\cong H^k(S^{n-1}) \\quad \\text{for all } k \\ge 1.\n\\]\n\nNow we compute:\n\\begin{itemize}\n\\item For $k = 0$, we already handled $H^0$ and $H^1$.\n\\item For $2 \\le m \\le n-1$ (i.e., $m = k+1$ with $k \\ge 1$ and $k \\le n-2$), we have\n\\[\nH^m(S^n) \\cong H^{m-1}(S^{n-1}).\n\\]\nBy the induction hypothesis, $H^{m-1}(S^{n-1}) = 0$ because $1 \\le m-1 \\le n-2$ (since $m \\le n-1$). Hence $H^m(S^n) = 0$.\n\\item For $m = n$, take $k = n-1$ (which is $\\ge 1$ because $n \\ge 2$). Then\n\\[\nH^n(S^n) \\cong H^{n-1}(U \\cap V) \\cong H^{n-1}(S^{n-1}) \\cong \\mathbb{R}.\n\\]\n\\item For $m > n$, we have $k = m-1 \\ge n$. But $H^k(S^{n-1}) = 0$ for $k > n-1$ (since the top degree is $n-1$). Thus $H^m(S^n) = 0$ for $m > n$.\n\\end{itemize}\n\nCombining all cases, we have proved that for $n \\ge 2$,\n\\[\nH^k_{\\mathrm{dR}}(S^n) \\cong \n\\begin{cases}\n\\mathbb{R} & k = 0 \\text{ or } k = n,\\\\[2pt]\n0 & \\text{otherwise}.\n\\end{cases}\n\\]\n\nThe base case $n=1$ also satisfies this pattern (with $H^1(S^1) \\cong \\mathbb{R}$). Therefore by induction the formula holds for all $n \\ge 1$.\n\n\\medskip\n\n\\noindent \\textbf{Remark.} The same result can be obtained by other methods (e.g., using the long exact sequence of the pair, or by cellular cohomology), but the Mayer\u2013Vietoris argument presented here is a standard and elementary proof in de Rham theory.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "42",
    "outer_attempt": 1,
    "topic_slug": "probability_theory_and_stochastic_processes",
    "topic_name": "Probability theory and stochastic processes",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Consider an infinite sequence of independent tosses of a biased coin. Each toss results in heads (H) with probability $p$ and tails (T) with probability $q = 1-p$, where $0 < p < 1$. Let $N$ be the number of tosses required to observe the pattern HTHT for the first time (i.e., the first occurrence of four consecutive tosses equal to H, T, H, T in that order). Compute the expected value $\\mathbb{E}[N]$ as a closed-form expression in terms of $p$ (or $p$ and $q$).",
            "answer": "We model the process as a Markov chain whose state is the length of the longest suffix of the observed sequence that matches a prefix of the target pattern HTHT. The states are $0,1,2,3,4$, where state $4$ means the pattern has just been completed (absorbing). Let $E_i$ denote the expected additional tosses needed to reach state $4$ starting from state $i$. Clearly $E_4 = 0$. Initially, before any toss, we are in state $0$, so $\\mathbb{E}[N] = E_0$.\n\nWe determine the transition probabilities from each non\u2011absorbing state by considering the next toss.\n\n- **State 0** (no relevant match).  \n  If H (prob $p$), the suffix \"H\" matches the first character \u2192 state $1$.  \n  If T (prob $q$), no match \u2192 stay in state $0$.  \n  Hence  \n  $$E_0 = 1 + p E_1 + q E_0 \\quad\\Longrightarrow\\quad E_0 = \\frac{1}{p} + E_1. \\tag{1}$$\n\n- **State 1** (current suffix \"H\").  \n  If H, we obtain \"HH\". The longest prefix of HTHT that is a suffix of \"HH\" is \"H\" (length $1$) \u2192 state $1$.  \n  If T, we obtain \"HT\", which matches the first two characters \u2192 state $2$.  \n  Hence  \n  $$E_1 = 1 + p E_1 + q E_2 \\quad\\Longrightarrow\\quad E_1 = \\frac{1}{q} + E_2. \\tag{2}$$\n\n- **State 2** (current suffix \"HT\").  \n  If H, we obtain \"HTH\", matching the first three characters \u2192 state $3$.  \n  If T, we obtain \"HTT\". No non\u2011empty suffix matches a prefix of HTHT (the first character is H) \u2192 state $0$.  \n  Hence  \n  $$E_2 = 1 + p E_3 + q E_0. \\tag{3}$$\n\n- **State 3** (current suffix \"HTH\").  \n  If H, we obtain \"HTHH\". The longest matching prefix is \"H\" (length $1$) \u2192 state $1$.  \n  If T, we complete the pattern \"HTHT\" \u2192 state $4$.  \n  Hence  \n  $$E_3 = 1 + p E_1 + q\\cdot 0 = 1 + p E_1. \\tag{4}$$\n\nNow solve the system. From (1) and (2) we have  \n$$E_0 = \\frac{1}{p} + E_1, \\qquad E_2 = E_1 - \\frac{1}{q}.$$\nSubstitute these and (4) into (3):\n$$\nE_1 - \\frac{1}{q} &= 1 + p\\bigl(1 + p E_1\\bigr) + q\\left(E_1 + \\frac{1}{p}\\right) \\\\\n&= 1 + p + p^2 E_1 + q E_1 + \\frac{q}{p}.\n$$\nRearranging terms gives\n$$\nE_1 - \\frac{1}{q} - (p^2 + q)E_1 &= 1 + p + \\frac{q}{p} \\\\\nE_1\\bigl(1 - p^2 - q\\bigr) &= 1 + p + \\frac{q}{p} + \\frac{1}{q}.\n$$\nSince $1 - p^2 - q = 1 - p^2 - (1-p) = p - p^2 = p(1-p) = pq$, we obtain\n$$p q \\, E_1 = 1 + p + \\frac{q}{p} + \\frac{1}{q}. \\tag{5}$$\n\nCombine the right\u2011hand side over a common denominator $pq$:\n$$\n1 + p + \\frac{q}{p} + \\frac{1}{q}\n&= \\frac{(1+p)pq + q^2 + p}{pq} \\\\\n&= \\frac{pq + p^2 q + q^2 + p}{pq}.\n$$\nThus (5) becomes\n$$p q \\, E_1 = \\frac{pq + p^2 q + q^2 + p}{pq}\n\\quad\\Longrightarrow\\quad\n(pq)^2 E_1 = pq + p^2 q + q^2 + p.$$\nHence\n$$E_1 = \\frac{pq + p^2 q + q^2 + p}{p^2 q^2}. \\tag{6}$$\n\nNow compute $E_0$ using (1):\n$$E_0 = \\frac{1}{p} + E_1\n= \\frac{1}{p} + \\frac{pq + p^2 q + q^2 + p}{p^2 q^2}.$$\nWrite $1/p$ as $\\frac{p q^2}{p^2 q^2}$ (since $\\frac{p q^2}{p^2 q^2} = \\frac{1}{p}$). Then\n$$E_0 = \\frac{p q^2 + p q + p^2 q + q^2 + p}{p^2 q^2}.$$\n\nSimplify the numerator. Notice that $p q^2 + p^2 q = p q (q + p) = p q$ because $p+q=1$. Therefore\n$$\n\\text{Numerator} &= (p q^2 + p^2 q) + p q + q^2 + p \\\\\n&= p q + p q + q^2 + p = 2 p q + q^2 + p.\n$$\nNow substitute $q = 1-p$:\n$$\n2p(1-p) + (1-p)^2 + p\n&= 2p - 2p^2 + 1 - 2p + p^2 + p \\\\\n&= 1 + (2p - 2p + p) + (-2p^2 + p^2) \\\\\n&= 1 + p - p^2.\n$$\nThus\n$$E_0 = \\frac{1 + p - p^2}{p^2 q^2} = \\frac{1 + p - p^2}{p^2 (1-p)^2}.$$\n\nTherefore the expected number of tosses until the pattern HTHT first appears is\n$$\\boxed{\\mathbb{E}[N] = \\frac{1 + p - p^2}{p^2 (1-p)^2}}.$$\n\n(For $p=1/2$ this gives $\\mathbb{E}[N]=20$, which can be verified independently. The expectation is finite for $0<p<1$ and diverges as $p\\to0$ or $p\\to1$, consistent with intuition.)",
            "raw_answer": "[QUESTION]\nConsider an infinite sequence of independent tosses of a biased coin. Each toss results in heads (H) with probability $p$ and tails (T) with probability $q = 1-p$, where $0 < p < 1$. Let $N$ be the number of tosses required to observe the pattern HTHT for the first time (i.e., the first occurrence of four consecutive tosses equal to H, T, H, T in that order). Compute the expected value $\\mathbb{E}[N]$ as a closed-form expression in terms of $p$ (or $p$ and $q$).\n\n[ANSWER]\nWe model the process as a Markov chain whose state is the length of the longest suffix of the observed sequence that matches a prefix of the target pattern HTHT. The states are $0,1,2,3,4$, where state $4$ means the pattern has just been completed (absorbing). Let $E_i$ denote the expected additional tosses needed to reach state $4$ starting from state $i$. Clearly $E_4 = 0$. Initially, before any toss, we are in state $0$, so $\\mathbb{E}[N] = E_0$.\n\nWe determine the transition probabilities from each non\u2011absorbing state by considering the next toss.\n\n- **State 0** (no relevant match).  \n  If H (prob $p$), the suffix \"H\" matches the first character \u2192 state $1$.  \n  If T (prob $q$), no match \u2192 stay in state $0$.  \n  Hence  \n  $$E_0 = 1 + p E_1 + q E_0 \\quad\\Longrightarrow\\quad E_0 = \\frac{1}{p} + E_1. \\tag{1}$$\n\n- **State 1** (current suffix \"H\").  \n  If H, we obtain \"HH\". The longest prefix of HTHT that is a suffix of \"HH\" is \"H\" (length $1$) \u2192 state $1$.  \n  If T, we obtain \"HT\", which matches the first two characters \u2192 state $2$.  \n  Hence  \n  $$E_1 = 1 + p E_1 + q E_2 \\quad\\Longrightarrow\\quad E_1 = \\frac{1}{q} + E_2. \\tag{2}$$\n\n- **State 2** (current suffix \"HT\").  \n  If H, we obtain \"HTH\", matching the first three characters \u2192 state $3$.  \n  If T, we obtain \"HTT\". No non\u2011empty suffix matches a prefix of HTHT (the first character is H) \u2192 state $0$.  \n  Hence  \n  $$E_2 = 1 + p E_3 + q E_0. \\tag{3}$$\n\n- **State 3** (current suffix \"HTH\").  \n  If H, we obtain \"HTHH\". The longest matching prefix is \"H\" (length $1$) \u2192 state $1$.  \n  If T, we complete the pattern \"HTHT\" \u2192 state $4$.  \n  Hence  \n  $$E_3 = 1 + p E_1 + q\\cdot 0 = 1 + p E_1. \\tag{4}$$\n\nNow solve the system. From (1) and (2) we have  \n$$E_0 = \\frac{1}{p} + E_1, \\qquad E_2 = E_1 - \\frac{1}{q}.$$\nSubstitute these and (4) into (3):\n\\begin{align*}\nE_1 - \\frac{1}{q} &= 1 + p\\bigl(1 + p E_1\\bigr) + q\\left(E_1 + \\frac{1}{p}\\right) \\\\\n&= 1 + p + p^2 E_1 + q E_1 + \\frac{q}{p}.\n\\end{align*}\nRearranging terms gives\n\\begin{align*}\nE_1 - \\frac{1}{q} - (p^2 + q)E_1 &= 1 + p + \\frac{q}{p} \\\\\nE_1\\bigl(1 - p^2 - q\\bigr) &= 1 + p + \\frac{q}{p} + \\frac{1}{q}.\n\\end{align*}\nSince $1 - p^2 - q = 1 - p^2 - (1-p) = p - p^2 = p(1-p) = pq$, we obtain\n$$p q \\, E_1 = 1 + p + \\frac{q}{p} + \\frac{1}{q}. \\tag{5}$$\n\nCombine the right\u2011hand side over a common denominator $pq$:\n\\begin{align*}\n1 + p + \\frac{q}{p} + \\frac{1}{q}\n&= \\frac{(1+p)pq + q^2 + p}{pq} \\\\\n&= \\frac{pq + p^2 q + q^2 + p}{pq}.\n\\end{align*}\nThus (5) becomes\n$$p q \\, E_1 = \\frac{pq + p^2 q + q^2 + p}{pq}\n\\quad\\Longrightarrow\\quad\n(pq)^2 E_1 = pq + p^2 q + q^2 + p.$$\nHence\n$$E_1 = \\frac{pq + p^2 q + q^2 + p}{p^2 q^2}. \\tag{6}$$\n\nNow compute $E_0$ using (1):\n$$E_0 = \\frac{1}{p} + E_1\n= \\frac{1}{p} + \\frac{pq + p^2 q + q^2 + p}{p^2 q^2}.$$\nWrite $1/p$ as $\\frac{p q^2}{p^2 q^2}$ (since $\\frac{p q^2}{p^2 q^2} = \\frac{1}{p}$). Then\n$$E_0 = \\frac{p q^2 + p q + p^2 q + q^2 + p}{p^2 q^2}.$$\n\nSimplify the numerator. Notice that $p q^2 + p^2 q = p q (q + p) = p q$ because $p+q=1$. Therefore\n\\begin{align*}\n\\text{Numerator} &= (p q^2 + p^2 q) + p q + q^2 + p \\\\\n&= p q + p q + q^2 + p = 2 p q + q^2 + p.\n\\end{align*}\nNow substitute $q = 1-p$:\n\\begin{align*}\n2p(1-p) + (1-p)^2 + p\n&= 2p - 2p^2 + 1 - 2p + p^2 + p \\\\\n&= 1 + (2p - 2p + p) + (-2p^2 + p^2) \\\\\n&= 1 + p - p^2.\n\\end{align*}\nThus\n$$E_0 = \\frac{1 + p - p^2}{p^2 q^2} = \\frac{1 + p - p^2}{p^2 (1-p)^2}.$$\n\nTherefore the expected number of tosses until the pattern HTHT first appears is\n$$\\boxed{\\mathbb{E}[N] = \\frac{1 + p - p^2}{p^2 (1-p)^2}}.$$\n\n(For $p=1/2$ this gives $\\mathbb{E}[N]=20$, which can be verified independently. The expectation is finite for $0<p<1$ and diverges as $p\\to0$ or $p\\to1$, consistent with intuition.)",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "43",
    "outer_attempt": 1,
    "topic_slug": "statistics",
    "topic_name": "Statistics",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $X_1, X_2, \\dots, X_n$ be a random sample from a geometric distribution with parameter $p$ ($0 < p < 1$), i.e., \n$$\nP(X_i = k) = (1-p)^{k-1} p, \\quad k = 1,2,\\dots.\n$$\nAssume $n \\ge 2$. Find the uniformly minimum variance unbiased estimator (UMVUE) of $p^2$.",
            "answer": "We will derive the UMVUE by the Lehmann\u2013Scheff\u00e9 theorem: an unbiased estimator that is a function of a complete sufficient statistic is UMVUE.\n\n\\subsection*{1. Sufficient and complete statistic}\nThe probability mass function can be written as\n$$\nf(k;p) = p(1-p)^{k-1} = \\exp\\Bigl( k\\log(1-p) + \\log p - \\log(1-p) \\Bigr).\n$$\nThis is a one-parameter exponential family with natural parameter $\\theta = \\log(1-p)$ and sufficient statistic $T = \\sum_{i=1}^n X_i$. Since the parameter space $\\{p \\in (0,1)\\}$ corresponds to $\\theta \\in (-\\infty,0)$, which contains an open interval, the statistic $T$ is complete and sufficient for $p$.\n\n\\subsection*{2. Distribution of $T$}\nThe sum of $n$ independent geometric($p$) random variables (number of trials until first success) follows a negative binomial (Pascal) distribution: $T$ is the number of trials needed to obtain $n$ successes. Its pmf is\n$$\nP(T = t) = \\binom{t-1}{n-1} p^n (1-p)^{t-n}, \\qquad t = n, n+1, n+2, \\dots.\n$$\n\n\\subsection*{3. Finding an unbiased estimator based on $T$}\nWe seek a function $h(T)$ such that $\\operatorname{E}[h(T)] = p^2$ for all $p \\in (0,1)$. Using the pmf,\n$$\n\\sum_{t=n}^{\\infty} h(t) \\binom{t-1}{n-1} p^n (1-p)^{t-n} = p^2.\n$$\nDividing both sides by $p^n$ (with $p>0$) gives\n$$\n\\sum_{t=n}^{\\infty} h(t) \\binom{t-1}{n-1} (1-p)^{t-n} = p^{2-n}. \\tag{1}\n$$\nLet $q = 1-p$; then $p = 1-q$ and $0 \\le q < 1$. Equation (1) becomes\n$$\n\\sum_{j=0}^{\\infty} h(n+j) \\binom{n+j-1}{n-1} q^{j} = (1-q)^{2-n}. \\tag{2}\n$$\nWe treat the cases $n=2$ and $n \\ge 3$ separately.\n\n\\subsubsection*{Case $n = 2$}\nFor $n=2$, the right-hand side of (2) is $(1-q)^{0}=1$, and $\\binom{1+j}{1}=j+1$. Hence\n$$\n\\sum_{j=0}^{\\infty} h(2+j) (j+1) q^{j} = 1.\n$$\nSince the power series representation of the constant function $1$ is unique, we equate coefficients:\n$$\nj=0:&\\quad h(2) \\cdot 1 = 1 \\;\\Rightarrow\\; h(2)=1,\\\\\nj\\ge 1:&\\quad h(2+j)(j+1)=0 \\;\\Rightarrow\\; h(2+j)=0.\n$$\nThus $h(t) = \\mathbf{1}_{\\{t=2\\}}$ (the indicator function). Therefore, when $n=2$, the UMVUE for $p^2$ is\n$$\n\\hat{p^2} = I(T = 2).\n$$\n\n\\subsubsection*{Case $n \\ge 3$}\nNow $n \\ge 3$, so $2-n$ is negative. The right-hand side of (2) is $(1-q)^{2-n} = (1-q)^{-(n-2)}$. Using the binomial series for $|q|<1$,\n$$\n(1-q)^{-m} = \\sum_{j=0}^{\\infty} \\binom{m+j-1}{j} q^{j}, \\qquad m = n-2.\n$$\nThus\n$$\n(1-q)^{2-n} = \\sum_{j=0}^{\\infty} \\binom{n+j-3}{j} q^{j}. \\tag{3}\n$$\nSubstituting (3) into (2) gives\n$$\n\\sum_{j=0}^{\\infty} h(n+j) \\binom{n+j-1}{n-1} q^{j} = \\sum_{j=0}^{\\infty} \\binom{n+j-3}{j} q^{j}.\n$$\nEquating coefficients of $q^j$ yields, for every $j \\ge 0$,\n$$\nh(n+j) \\binom{n+j-1}{n-1} = \\binom{n+j-3}{j}.\n$$\nSolving for $h(n+j)$:\n$$\nh(n+j) = \\frac{ \\binom{n+j-3}{j} }{ \\binom{n+j-1}{n-1} }.\n$$\nSimplify the binomial coefficients:\n$$\n\\binom{n+j-1}{n-1} = \\frac{(n+j-1)!}{(n-1)!\\,j!}, \\qquad \n\\binom{n+j-3}{j} = \\frac{(n+j-3)!}{j!\\,(n-3)!}.\n$$\nHence\n$$\nh(n+j) = \\frac{ (n+j-3)! }{ j!\\,(n-3)! } \\cdot \\frac{ (n-1)!\\,j! }{ (n+j-1)! } = \\frac{ (n-1)! }{ (n-3)! } \\cdot \\frac{ (n+j-3)! }{ (n+j-1)! }.\n$$\nSince $(n+j-1)! = (n+j-1)(n+j-2)(n+j-3)!$, we obtain\n$$\nh(n+j) = \\frac{ (n-1)(n-2) }{ (n+j-1)(n+j-2) }.\n$$\nWriting $t = n+j$, this becomes\n$$\nh(t) = \\frac{ (n-1)(n-2) }{ (t-1)(t-2) }, \\qquad t = n, n+1, n+2, \\dots.\n$$\nTherefore, for $n \\ge 3$, the UMVUE for $p^2$ is\n$$\n\\hat{p^2} = \\frac{ (n-1)(n-2) }{ (T-1)(T-2) }.\n$$\n\n\\subsection*{4. Conclusion}\nThe UMVUE of $p^2$ is given by\n$$\n\\hat{p^2} =\n\\begin{cases}\nI(T = 2), & n = 2, \\$$6pt]\n\\dfrac{ (n-1)(n-2) }{ (T-1)(T-2) }, & n \\ge 3,\n\\end{cases}\n$$\nwhere $T = \\sum_{i=1}^n X_i$. Because $T$ is a complete sufficient statistic and $\\hat{p^2}$ is an unbiased function of $T$, it is the unique UMVUE by the Lehmann\u2013Scheff\u00e9 theorem.\n\nWe can optionally verify unbiasedness directly: for $n\\ge3$,\n$$\n\\operatorname{E}[\\hat{p^2}] = \\sum_{t=n}^{\\infty} \\frac{ (n-1)(n-2) }{ (t-1)(t-2) } \\binom{t-1}{n-1} p^n (1-p)^{t-n} = p^2,\n$$\nas follows from the derivation. For $n=2$, $\\operatorname{E}[I(T=2)] = P(T=2) = p^2$.\n\nThus the estimator is indeed UMVUE.",
            "raw_answer": "[QUESTION]\nLet $X_1, X_2, \\dots, X_n$ be a random sample from a geometric distribution with parameter $p$ ($0 < p < 1$), i.e., \n\\[\nP(X_i = k) = (1-p)^{k-1} p, \\quad k = 1,2,\\dots.\n\\]\nAssume $n \\ge 2$. Find the uniformly minimum variance unbiased estimator (UMVUE) of $p^2$.\n\n[ANSWER]\nWe will derive the UMVUE by the Lehmann\u2013Scheff\u00e9 theorem: an unbiased estimator that is a function of a complete sufficient statistic is UMVUE.\n\n\\subsection*{1. Sufficient and complete statistic}\nThe probability mass function can be written as\n\\[\nf(k;p) = p(1-p)^{k-1} = \\exp\\Bigl( k\\log(1-p) + \\log p - \\log(1-p) \\Bigr).\n\\]\nThis is a one-parameter exponential family with natural parameter $\\theta = \\log(1-p)$ and sufficient statistic $T = \\sum_{i=1}^n X_i$. Since the parameter space $\\{p \\in (0,1)\\}$ corresponds to $\\theta \\in (-\\infty,0)$, which contains an open interval, the statistic $T$ is complete and sufficient for $p$.\n\n\\subsection*{2. Distribution of $T$}\nThe sum of $n$ independent geometric($p$) random variables (number of trials until first success) follows a negative binomial (Pascal) distribution: $T$ is the number of trials needed to obtain $n$ successes. Its pmf is\n\\[\nP(T = t) = \\binom{t-1}{n-1} p^n (1-p)^{t-n}, \\qquad t = n, n+1, n+2, \\dots.\n\\]\n\n\\subsection*{3. Finding an unbiased estimator based on $T$}\nWe seek a function $h(T)$ such that $\\operatorname{E}[h(T)] = p^2$ for all $p \\in (0,1)$. Using the pmf,\n\\[\n\\sum_{t=n}^{\\infty} h(t) \\binom{t-1}{n-1} p^n (1-p)^{t-n} = p^2.\n\\]\nDividing both sides by $p^n$ (with $p>0$) gives\n\\[\n\\sum_{t=n}^{\\infty} h(t) \\binom{t-1}{n-1} (1-p)^{t-n} = p^{2-n}. \\tag{1}\n\\]\nLet $q = 1-p$; then $p = 1-q$ and $0 \\le q < 1$. Equation (1) becomes\n\\[\n\\sum_{j=0}^{\\infty} h(n+j) \\binom{n+j-1}{n-1} q^{j} = (1-q)^{2-n}. \\tag{2}\n\\]\nWe treat the cases $n=2$ and $n \\ge 3$ separately.\n\n\\subsubsection*{Case $n = 2$}\nFor $n=2$, the right-hand side of (2) is $(1-q)^{0}=1$, and $\\binom{1+j}{1}=j+1$. Hence\n\\[\n\\sum_{j=0}^{\\infty} h(2+j) (j+1) q^{j} = 1.\n\\]\nSince the power series representation of the constant function $1$ is unique, we equate coefficients:\n\\begin{align*}\nj=0:&\\quad h(2) \\cdot 1 = 1 \\;\\Rightarrow\\; h(2)=1,\\\\\nj\\ge 1:&\\quad h(2+j)(j+1)=0 \\;\\Rightarrow\\; h(2+j)=0.\n\\end{align*}\nThus $h(t) = \\mathbf{1}_{\\{t=2\\}}$ (the indicator function). Therefore, when $n=2$, the UMVUE for $p^2$ is\n\\[\n\\hat{p^2} = I(T = 2).\n\\]\n\n\\subsubsection*{Case $n \\ge 3$}\nNow $n \\ge 3$, so $2-n$ is negative. The right-hand side of (2) is $(1-q)^{2-n} = (1-q)^{-(n-2)}$. Using the binomial series for $|q|<1$,\n\\[\n(1-q)^{-m} = \\sum_{j=0}^{\\infty} \\binom{m+j-1}{j} q^{j}, \\qquad m = n-2.\n\\]\nThus\n\\[\n(1-q)^{2-n} = \\sum_{j=0}^{\\infty} \\binom{n+j-3}{j} q^{j}. \\tag{3}\n\\]\nSubstituting (3) into (2) gives\n\\[\n\\sum_{j=0}^{\\infty} h(n+j) \\binom{n+j-1}{n-1} q^{j} = \\sum_{j=0}^{\\infty} \\binom{n+j-3}{j} q^{j}.\n\\]\nEquating coefficients of $q^j$ yields, for every $j \\ge 0$,\n\\[\nh(n+j) \\binom{n+j-1}{n-1} = \\binom{n+j-3}{j}.\n\\]\nSolving for $h(n+j)$:\n\\[\nh(n+j) = \\frac{ \\binom{n+j-3}{j} }{ \\binom{n+j-1}{n-1} }.\n\\]\nSimplify the binomial coefficients:\n\\[\n\\binom{n+j-1}{n-1} = \\frac{(n+j-1)!}{(n-1)!\\,j!}, \\qquad \n\\binom{n+j-3}{j} = \\frac{(n+j-3)!}{j!\\,(n-3)!}.\n\\]\nHence\n\\[\nh(n+j) = \\frac{ (n+j-3)! }{ j!\\,(n-3)! } \\cdot \\frac{ (n-1)!\\,j! }{ (n+j-1)! } = \\frac{ (n-1)! }{ (n-3)! } \\cdot \\frac{ (n+j-3)! }{ (n+j-1)! }.\n\\]\nSince $(n+j-1)! = (n+j-1)(n+j-2)(n+j-3)!$, we obtain\n\\[\nh(n+j) = \\frac{ (n-1)(n-2) }{ (n+j-1)(n+j-2) }.\n\\]\nWriting $t = n+j$, this becomes\n\\[\nh(t) = \\frac{ (n-1)(n-2) }{ (t-1)(t-2) }, \\qquad t = n, n+1, n+2, \\dots.\n\\]\nTherefore, for $n \\ge 3$, the UMVUE for $p^2$ is\n\\[\n\\hat{p^2} = \\frac{ (n-1)(n-2) }{ (T-1)(T-2) }.\n\\]\n\n\\subsection*{4. Conclusion}\nThe UMVUE of $p^2$ is given by\n\\[\n\\hat{p^2} =\n\\begin{cases}\nI(T = 2), & n = 2, \\\\[6pt]\n\\dfrac{ (n-1)(n-2) }{ (T-1)(T-2) }, & n \\ge 3,\n\\end{cases}\n\\]\nwhere $T = \\sum_{i=1}^n X_i$. Because $T$ is a complete sufficient statistic and $\\hat{p^2}$ is an unbiased function of $T$, it is the unique UMVUE by the Lehmann\u2013Scheff\u00e9 theorem.\n\nWe can optionally verify unbiasedness directly: for $n\\ge3$,\n\\[\n\\operatorname{E}[\\hat{p^2}] = \\sum_{t=n}^{\\infty} \\frac{ (n-1)(n-2) }{ (t-1)(t-2) } \\binom{t-1}{n-1} p^n (1-p)^{t-n} = p^2,\n\\]\nas follows from the derivation. For $n=2$, $\\operatorname{E}[I(T=2)] = P(T=2) = p^2$.\n\nThus the estimator is indeed UMVUE.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "44",
    "outer_attempt": 1,
    "topic_slug": "numerical_analysis",
    "topic_name": "Numerical analysis",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $w(x)=e^{-x}$ on $[0,\\infty)$. Determine the nodes $x_1, x_2$ (with $0 < x_1 < x_2$) and weights $w_1, w_2$ such that the quadrature rule\n$$\n\\int_0^\\infty e^{-x} f(x)\\,dx \\approx w_1 f(x_1) + w_2 f(x_2)\n$$\nis exact for all polynomials $f$ of degree at most $3$. Provide the exact values in simplified radical form.",
            "answer": "We need to find $x_1, x_2 > 0$ and $w_1, w_2$ such that for any polynomial $f$ of degree $\\le 3$,\n$$\n\\int_0^\\infty e^{-x} f(x)\\,dx = w_1 f(x_1) + w_2 f(x_2).\n$$\nThe moments of the weight function are $\\mu_k = \\int_0^\\infty e^{-x} x^k\\,dx = k!$ for $k=0,1,2,\\dots$.\n\n\\subsection*{Method using orthogonal polynomials}\nFor a Gaussian quadrature rule with $n=2$ points, the nodes are the roots of the orthogonal polynomial of degree $2$ with respect to the weight $e^{-x}$ on $[0,\\infty)$. Let $p_2(x) = x^2 + \\alpha x + \\beta$ (monic). Orthogonality requires\n$$\n\\int_0^\\infty e^{-x} p_2(x) \\cdot 1 \\,dx = 0,\\qquad\n\\int_0^\\infty e^{-x} p_2(x) \\cdot x \\,dx = 0.\n$$\nCompute these integrals using the moments:\n$$\n\\int e^{-x} (x^2 + \\alpha x + \\beta)\\,dx &= \\mu_2 + \\alpha \\mu_1 + \\beta \\mu_0 = 2 + \\alpha + \\beta = 0,\\\\\n\\int e^{-x} (x^2 + \\alpha x + \\beta) x \\,dx &= \\mu_3 + \\alpha \\mu_2 + \\beta \\mu_1 = 6 + 2\\alpha + \\beta = 0.\n$$\nSolving the system:\nFrom the first equation, $\\beta = -2 - \\alpha$. Substituting into the second gives $6 + 2\\alpha -2 - \\alpha = 4 + \\alpha = 0$, so $\\alpha = -4$ and $\\beta = 2$. Hence\n$$\np_2(x) = x^2 - 4x + 2.\n$$\nIts roots are\n$$\nx_{1,2} = \\frac{4 \\pm \\sqrt{16 - 8}}{2} = \\frac{4 \\pm 2\\sqrt{2}}{2} = 2 \\pm \\sqrt{2}.\n$$\nThus we set $x_1 = 2 - \\sqrt{2}$, $x_2 = 2 + \\sqrt{2}$ (so $0 < x_1 < x_2$).\n\n\\subsection*{Determining the weights}\nThe weights are chosen so that the rule integrates the first two monomials $1$ and $x$ exactly (which already guarantees exactness for all polynomials up to degree $3$ due to the properties of Gaussian quadrature). Solve\n$$\n\\begin{cases}\nw_1 + w_2 = \\mu_0 = 1,\\\\\nw_1 x_1 + w_2 x_2 = \\mu_1 = 1.\n\\end{cases}\n$$\nSubtract $x_1$ times the first equation from the second:\n$$\nw_2 (x_2 - x_1) = 1 - x_1.\n$$\nSince $x_2 - x_1 = (2+\\sqrt{2}) - (2-\\sqrt{2}) = 2\\sqrt{2}$ and $1 - x_1 = 1 - (2-\\sqrt{2}) = \\sqrt{2} - 1$, we obtain\n$$\nw_2 = \\frac{\\sqrt{2} - 1}{2\\sqrt{2}} = \\frac{(\\sqrt{2} - 1)\\sqrt{2}}{2\\cdot 2} = \\frac{2 - \\sqrt{2}}{4}.\n$$\nSimilarly, from the first equation $w_1 = 1 - w_2 = 1 - \\frac{2 - \\sqrt{2}}{4} = \\frac{4 - (2 - \\sqrt{2})}{4} = \\frac{2 + \\sqrt{2}}{4}$.\nAlternatively, solving directly gives $w_1 = \\frac{x_2 - 1}{x_2 - x_1} = \\frac{(2+\\sqrt{2})-1}{2\\sqrt{2}} = \\frac{1+\\sqrt{2}}{2\\sqrt{2}} = \\frac{2+\\sqrt{2}}{4}$.\n\nThus the nodes and weights are:\n$$\n\\boxed{x_1 = 2 - \\sqrt{2},\\quad x_2 = 2 + \\sqrt{2},\\quad w_1 = \\frac{2 + \\sqrt{2}}{4},\\quad w_2 = \\frac{2 - \\sqrt{2}}{4}}.\n$$\n\n\\subsection*{Verification}\nOne may check that these also satisfy the moment equations for $x^2$ and $x^3$, confirming exactness for degree up to $3$.",
            "raw_answer": "[QUESTION]\nLet $w(x)=e^{-x}$ on $[0,\\infty)$. Determine the nodes $x_1, x_2$ (with $0 < x_1 < x_2$) and weights $w_1, w_2$ such that the quadrature rule\n\\[\n\\int_0^\\infty e^{-x} f(x)\\,dx \\approx w_1 f(x_1) + w_2 f(x_2)\n\\]\nis exact for all polynomials $f$ of degree at most $3$. Provide the exact values in simplified radical form.\n\n[ANSWER]\nWe need to find $x_1, x_2 > 0$ and $w_1, w_2$ such that for any polynomial $f$ of degree $\\le 3$,\n\\[\n\\int_0^\\infty e^{-x} f(x)\\,dx = w_1 f(x_1) + w_2 f(x_2).\n\\]\nThe moments of the weight function are $\\mu_k = \\int_0^\\infty e^{-x} x^k\\,dx = k!$ for $k=0,1,2,\\dots$.\n\n\\subsection*{Method using orthogonal polynomials}\nFor a Gaussian quadrature rule with $n=2$ points, the nodes are the roots of the orthogonal polynomial of degree $2$ with respect to the weight $e^{-x}$ on $[0,\\infty)$. Let $p_2(x) = x^2 + \\alpha x + \\beta$ (monic). Orthogonality requires\n\\[\n\\int_0^\\infty e^{-x} p_2(x) \\cdot 1 \\,dx = 0,\\qquad\n\\int_0^\\infty e^{-x} p_2(x) \\cdot x \\,dx = 0.\n\\]\nCompute these integrals using the moments:\n\\begin{align*}\n\\int e^{-x} (x^2 + \\alpha x + \\beta)\\,dx &= \\mu_2 + \\alpha \\mu_1 + \\beta \\mu_0 = 2 + \\alpha + \\beta = 0,\\\\\n\\int e^{-x} (x^2 + \\alpha x + \\beta) x \\,dx &= \\mu_3 + \\alpha \\mu_2 + \\beta \\mu_1 = 6 + 2\\alpha + \\beta = 0.\n\\end{align*}\nSolving the system:\nFrom the first equation, $\\beta = -2 - \\alpha$. Substituting into the second gives $6 + 2\\alpha -2 - \\alpha = 4 + \\alpha = 0$, so $\\alpha = -4$ and $\\beta = 2$. Hence\n\\[\np_2(x) = x^2 - 4x + 2.\n\\]\nIts roots are\n\\[\nx_{1,2} = \\frac{4 \\pm \\sqrt{16 - 8}}{2} = \\frac{4 \\pm 2\\sqrt{2}}{2} = 2 \\pm \\sqrt{2}.\n\\]\nThus we set $x_1 = 2 - \\sqrt{2}$, $x_2 = 2 + \\sqrt{2}$ (so $0 < x_1 < x_2$).\n\n\\subsection*{Determining the weights}\nThe weights are chosen so that the rule integrates the first two monomials $1$ and $x$ exactly (which already guarantees exactness for all polynomials up to degree $3$ due to the properties of Gaussian quadrature). Solve\n\\[\n\\begin{cases}\nw_1 + w_2 = \\mu_0 = 1,\\\\\nw_1 x_1 + w_2 x_2 = \\mu_1 = 1.\n\\end{cases}\n\\]\nSubtract $x_1$ times the first equation from the second:\n\\[\nw_2 (x_2 - x_1) = 1 - x_1.\n\\]\nSince $x_2 - x_1 = (2+\\sqrt{2}) - (2-\\sqrt{2}) = 2\\sqrt{2}$ and $1 - x_1 = 1 - (2-\\sqrt{2}) = \\sqrt{2} - 1$, we obtain\n\\[\nw_2 = \\frac{\\sqrt{2} - 1}{2\\sqrt{2}} = \\frac{(\\sqrt{2} - 1)\\sqrt{2}}{2\\cdot 2} = \\frac{2 - \\sqrt{2}}{4}.\n\\]\nSimilarly, from the first equation $w_1 = 1 - w_2 = 1 - \\frac{2 - \\sqrt{2}}{4} = \\frac{4 - (2 - \\sqrt{2})}{4} = \\frac{2 + \\sqrt{2}}{4}$.\nAlternatively, solving directly gives $w_1 = \\frac{x_2 - 1}{x_2 - x_1} = \\frac{(2+\\sqrt{2})-1}{2\\sqrt{2}} = \\frac{1+\\sqrt{2}}{2\\sqrt{2}} = \\frac{2+\\sqrt{2}}{4}$.\n\nThus the nodes and weights are:\n\\[\n\\boxed{x_1 = 2 - \\sqrt{2},\\quad x_2 = 2 + \\sqrt{2},\\quad w_1 = \\frac{2 + \\sqrt{2}}{4},\\quad w_2 = \\frac{2 - \\sqrt{2}}{4}}.\n\\]\n\n\\subsection*{Verification}\nOne may check that these also satisfy the moment equations for $x^2$ and $x^3$, confirming exactness for degree up to $3$.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "20",
    "outer_attempt": 2,
    "topic_slug": "several_complex_variables_and_analytic_spaces",
    "topic_name": "Several complex variables and analytic spaces",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Let $n \\ge 2$ be an integer. Denote by $B = \\{ z \\in \\mathbb{C}^n : \\|z\\| < 1 \\}$ the open unit ball in $\\mathbb{C}^n$, where $\\|z\\|^2 = \\sum_{i=1}^n |z_i|^2$. Let $\\Omega = B \\setminus \\{0\\}$ be the punctured ball. Prove that every holomorphic function $f: \\Omega \\to \\mathbb{C}$ extends uniquely to a holomorphic function on $B$. In other words, there exists a holomorphic function $F: B \\to \\mathbb{C}$ such that $F|_{\\Omega} = f$, and such an $F$ is unique.",
            "answer": "We prove the statement in two parts: uniqueness and existence.\n\n**Uniqueness.** Suppose $F_1, F_2: B \\to \\mathbb{C}$ are two holomorphic extensions of $f$. Then $F_1 - F_2$ is holomorphic on $B$ and vanishes on $\\Omega$. Since $\\Omega$ is dense in $B$ (every point of $B$ is a limit point of $\\Omega$), the identity theorem for several complex variables implies $F_1 \\equiv F_2$. Hence the extension, if it exists, is unique.\n\n**Existence.** Choose $r > 0$ such that the closed polydisc\n$$\n\\overline{\\Delta(0,r)} = \\{ w \\in \\mathbb{C}^n : |w_i| \\le r \\text{ for } i=1,\\dots,n \\}\n$$\nis contained in $B$. For instance, take $r = \\frac{1}{2\\sqrt{n}}$; then for any $w$ with $|w_i| \\le r$ we have $\\|w\\|^2 \\le n r^2 = \\frac{1}{4} < 1$, so indeed $\\overline{\\Delta(0,r)} \\subset B$.\n\nDefine a function $F$ on the open polydisc $\\Delta(0,r) = \\{ z : |z_i| < r \\}$ by\n$$\nF(z_1,\\dots,z_n) = \\frac{1}{2\\pi i} \\int_{|\\zeta| = r} \\frac{f(\\zeta, z_2, \\dots, z_n)}{\\zeta - z_1} \\, d\\zeta,\n\\tag{1}\n$$\nwhere the integration is over the positively oriented circle $\\{ \\zeta \\in \\mathbb{C} : |\\zeta| = r \\}$.\n\n*Step 1. $F$ is well\u2011defined and holomorphic on $\\Delta(0,r)$.*  \nFor any $(\\zeta, z_2,\\dots,z_n)$ with $|\\zeta|=r$ and $|z_j|<r$ ($j\\ge 2$), the point $(\\zeta, z_2,\\dots,z_n)$ belongs to $B$ because its coordinates are bounded by $r$, and it is not the origin because $|\\zeta|=r>0$. Hence $f$ is defined and holomorphic there. The denominator $\\zeta - z_1$ does not vanish because $|z_1|<r = |\\zeta|$. Thus the integrand is continuous in all variables and holomorphic in $(z_1,\\dots,z_n)$ for each fixed $\\zeta$. Differentiation under the integral sign (or an application of Morera\u2019s theorem) shows that $F$ is holomorphic in each variable separately. Moreover, $F$ is continuous (as an integral of a continuous family). By Osgood\u2019s lemma \u2014 a continuous function that is analytic in each variable separately is jointly analytic \u2014 $F$ is holomorphic on $\\Delta(0,r)$.\n\n*Step 2. $F$ coincides with $f$ on $\\Delta(0,r) \\setminus \\{0\\}$.*  \nFirst consider points $z = (z_1,\\dots,z_n) \\in \\Delta(0,r)$ with $(z_2,\\dots,z_n) \\neq 0$. For such $z$, the compact set\n$$\nK = \\{ (\\zeta, z_2,\\dots,z_n) : |\\zeta| \\le r \\}\n$$\nlies entirely in $\\Omega$. Indeed, if $\\zeta = 0$ then the point is $(0,z_2,\\dots,z_n)$, which is not the origin because $(z_2,\\dots,z_n) \\neq 0$; for any $\\zeta$ with $|\\zeta| \\le r$ the point belongs to $\\overline{\\Delta(0,r)} \\subset B$, and the origin is excluded as argued. Since $\\Omega$ is open, $K$ has an open neighbourhood contained in $\\Omega$, so the function $\\zeta \\mapsto f(\\zeta, z_2,\\dots,z_n)$ is holomorphic on an open set containing the closed disc $\\{ |\\zeta| \\le r \\}$. Therefore the Cauchy integral formula for one variable gives\n$$\nf(z_1, z_2, \\dots, z_n) = \\frac{1}{2\\pi i} \\int_{|\\zeta| = r} \\frac{f(\\zeta, z_2, \\dots, z_n)}{\\zeta - z_1} \\, d\\zeta = F(z).\n$$\nThus $F(z) = f(z)$ for all $z \\in \\Delta(0,r)$ with $(z_2,\\dots,z_n) \\neq 0$.\n\nThe set $U = \\{ z \\in \\Delta(0,r) : (z_2,\\dots,z_n) \\neq 0 \\}$ is dense in $\\Delta(0,r)$ (its complement is the proper complex line $z_2 = \\cdots = z_n = 0$, which has empty interior). Both $F$ and $f$ are continuous on the punctured polydisc $\\Delta(0,r) \\setminus \\{0\\}$ (holomorphic functions are continuous). Since they agree on the dense subset $U \\setminus \\{0\\}$, they must agree on all of $\\Delta(0,r) \\setminus \\{0\\}$. In particular, $F(z) = f(z)$ for every $z \\in \\Omega \\cap \\Delta(0,r)$.\n\n*Step 3. Global extension.*  \nWe now define a function $\\tilde{F}: B \\to \\mathbb{C}$ by\n$$\n\\tilde{F}(z) = \n\\begin{cases}\nF(z), & z \\in \\Delta(0,r), \\\\\nf(z), & z \\in B \\setminus \\{0\\}.\n\\end{cases}\n$$\nThe two definitions coincide on the overlap $\\Delta(0,r) \\setminus \\{0\\}$ by Step 2, so $\\tilde{F}$ is well defined. On $\\Delta(0,r)$ it is holomorphic by Step 1; on $B \\setminus \\{0\\}$ it is holomorphic because it equals $f$. Hence $\\tilde{F}$ is holomorphic on all of $B$ and restricts to $f$ on $\\Omega$. This provides the desired extension.\n\nThe proof is complete. \u220e",
            "raw_answer": "[QUESTION]\nLet $n \\ge 2$ be an integer. Denote by $B = \\{ z \\in \\mathbb{C}^n : \\|z\\| < 1 \\}$ the open unit ball in $\\mathbb{C}^n$, where $\\|z\\|^2 = \\sum_{i=1}^n |z_i|^2$. Let $\\Omega = B \\setminus \\{0\\}$ be the punctured ball. Prove that every holomorphic function $f: \\Omega \\to \\mathbb{C}$ extends uniquely to a holomorphic function on $B$. In other words, there exists a holomorphic function $F: B \\to \\mathbb{C}$ such that $F|_{\\Omega} = f$, and such an $F$ is unique.\n\n[ANSWER]\nWe prove the statement in two parts: uniqueness and existence.\n\n**Uniqueness.** Suppose $F_1, F_2: B \\to \\mathbb{C}$ are two holomorphic extensions of $f$. Then $F_1 - F_2$ is holomorphic on $B$ and vanishes on $\\Omega$. Since $\\Omega$ is dense in $B$ (every point of $B$ is a limit point of $\\Omega$), the identity theorem for several complex variables implies $F_1 \\equiv F_2$. Hence the extension, if it exists, is unique.\n\n**Existence.** Choose $r > 0$ such that the closed polydisc\n\\[\n\\overline{\\Delta(0,r)} = \\{ w \\in \\mathbb{C}^n : |w_i| \\le r \\text{ for } i=1,\\dots,n \\}\n\\]\nis contained in $B$. For instance, take $r = \\frac{1}{2\\sqrt{n}}$; then for any $w$ with $|w_i| \\le r$ we have $\\|w\\|^2 \\le n r^2 = \\frac{1}{4} < 1$, so indeed $\\overline{\\Delta(0,r)} \\subset B$.\n\nDefine a function $F$ on the open polydisc $\\Delta(0,r) = \\{ z : |z_i| < r \\}$ by\n\\[\nF(z_1,\\dots,z_n) = \\frac{1}{2\\pi i} \\int_{|\\zeta| = r} \\frac{f(\\zeta, z_2, \\dots, z_n)}{\\zeta - z_1} \\, d\\zeta,\n\\tag{1}\n\\]\nwhere the integration is over the positively oriented circle $\\{ \\zeta \\in \\mathbb{C} : |\\zeta| = r \\}$.\n\n*Step 1. $F$ is well\u2011defined and holomorphic on $\\Delta(0,r)$.*  \nFor any $(\\zeta, z_2,\\dots,z_n)$ with $|\\zeta|=r$ and $|z_j|<r$ ($j\\ge 2$), the point $(\\zeta, z_2,\\dots,z_n)$ belongs to $B$ because its coordinates are bounded by $r$, and it is not the origin because $|\\zeta|=r>0$. Hence $f$ is defined and holomorphic there. The denominator $\\zeta - z_1$ does not vanish because $|z_1|<r = |\\zeta|$. Thus the integrand is continuous in all variables and holomorphic in $(z_1,\\dots,z_n)$ for each fixed $\\zeta$. Differentiation under the integral sign (or an application of Morera\u2019s theorem) shows that $F$ is holomorphic in each variable separately. Moreover, $F$ is continuous (as an integral of a continuous family). By Osgood\u2019s lemma \u2014 a continuous function that is analytic in each variable separately is jointly analytic \u2014 $F$ is holomorphic on $\\Delta(0,r)$.\n\n*Step 2. $F$ coincides with $f$ on $\\Delta(0,r) \\setminus \\{0\\}$.*  \nFirst consider points $z = (z_1,\\dots,z_n) \\in \\Delta(0,r)$ with $(z_2,\\dots,z_n) \\neq 0$. For such $z$, the compact set\n\\[\nK = \\{ (\\zeta, z_2,\\dots,z_n) : |\\zeta| \\le r \\}\n\\]\nlies entirely in $\\Omega$. Indeed, if $\\zeta = 0$ then the point is $(0,z_2,\\dots,z_n)$, which is not the origin because $(z_2,\\dots,z_n) \\neq 0$; for any $\\zeta$ with $|\\zeta| \\le r$ the point belongs to $\\overline{\\Delta(0,r)} \\subset B$, and the origin is excluded as argued. Since $\\Omega$ is open, $K$ has an open neighbourhood contained in $\\Omega$, so the function $\\zeta \\mapsto f(\\zeta, z_2,\\dots,z_n)$ is holomorphic on an open set containing the closed disc $\\{ |\\zeta| \\le r \\}$. Therefore the Cauchy integral formula for one variable gives\n\\[\nf(z_1, z_2, \\dots, z_n) = \\frac{1}{2\\pi i} \\int_{|\\zeta| = r} \\frac{f(\\zeta, z_2, \\dots, z_n)}{\\zeta - z_1} \\, d\\zeta = F(z).\n\\]\nThus $F(z) = f(z)$ for all $z \\in \\Delta(0,r)$ with $(z_2,\\dots,z_n) \\neq 0$.\n\nThe set $U = \\{ z \\in \\Delta(0,r) : (z_2,\\dots,z_n) \\neq 0 \\}$ is dense in $\\Delta(0,r)$ (its complement is the proper complex line $z_2 = \\cdots = z_n = 0$, which has empty interior). Both $F$ and $f$ are continuous on the punctured polydisc $\\Delta(0,r) \\setminus \\{0\\}$ (holomorphic functions are continuous). Since they agree on the dense subset $U \\setminus \\{0\\}$, they must agree on all of $\\Delta(0,r) \\setminus \\{0\\}$. In particular, $F(z) = f(z)$ for every $z \\in \\Omega \\cap \\Delta(0,r)$.\n\n*Step 3. Global extension.*  \nWe now define a function $\\tilde{F}: B \\to \\mathbb{C}$ by\n\\[\n\\tilde{F}(z) = \n\\begin{cases}\nF(z), & z \\in \\Delta(0,r), \\\\\nf(z), & z \\in B \\setminus \\{0\\}.\n\\end{cases}\n\\]\nThe two definitions coincide on the overlap $\\Delta(0,r) \\setminus \\{0\\}$ by Step 2, so $\\tilde{F}$ is well defined. On $\\Delta(0,r)$ it is holomorphic by Step 1; on $B \\setminus \\{0\\}$ it is holomorphic because it equals $f$. Hence $\\tilde{F}$ is holomorphic on all of $B$ and restricts to $f$ on $\\Omega$. This provides the desired extension.\n\nThe proof is complete. \u220e",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  },
  {
    "run_id": "30",
    "outer_attempt": 2,
    "topic_slug": "integral_transforms_and_operational_calculus",
    "topic_name": "Integral transforms, operational calculus",
    "status": "succeeded",
    "generation_rounds": [
      {
        "refinement_rounds": [
          {
            "round": 1,
            "question": "Solve the following integral equation for $f(t)$:\n\n$$\nf(t) = \\sin t + \\int_0^t e^{-(t-\\tau)} f(\\tau) \\, d\\tau, \\qquad t \\ge 0.\n$$",
            "answer": "We solve using the Laplace transform. Let $\\mathcal{L}\\{f(t)\\}(s) = F(s)$. Recall that the Laplace transform of a convolution is the product of transforms: $\\mathcal{L}\\{(f*g)(t)\\}(s) = F(s) G(s)$, where $(f*g)(t) = \\int_0^t f(t-\\tau)g(\\tau)\\,d\\tau$. Taking Laplace transforms of both sides yields\n\n$$\nF(s) = \\frac{1}{s^2+1} + \\frac{1}{s+1} F(s),\n$$\n\nsince $\\mathcal{L}\\{\\sin t\\}(s) = \\frac{1}{s^2+1}$ and $\\mathcal{L}\\{e^{-t}\\}(s) = \\frac{1}{s+1}$. Solving for $F(s)$:\n\n$$\nF(s) \\left(1 - \\frac{1}{s+1}\\right) = \\frac{1}{s^2+1},\n$$\n$$\nF(s) \\cdot \\frac{s}{s+1} = \\frac{1}{s^2+1},\n$$\n$$\nF(s) = \\frac{s+1}{s(s^2+1)}.\n$$\n\nWe decompose into partial fractions:\n\n$$\n\\frac{s+1}{s(s^2+1)} = \\frac{A}{s} + \\frac{Bs+C}{s^2+1}.\n$$\n\nMultiplying by $s(s^2+1)$ gives\n\n$$\ns+1 = A(s^2+1) + (Bs+C)s = (A+B)s^2 + Cs + A.\n$$\n\nEquating coefficients:\n\n$$\n\\begin{cases}\nA+B = 0,\\\\\nC = 1,\\\\\nA = 1.\n\\end{cases}\n$$\n\nThus $A=1$, $B=-1$, $C=1$. Hence\n\n$$\nF(s) = \\frac{1}{s} + \\frac{-s+1}{s^2+1} = \\frac{1}{s} - \\frac{s}{s^2+1} + \\frac{1}{s^2+1}.\n$$\n\nNow invert each term using standard Laplace transforms:\n\n$$\n\\mathcal{L}^{-1}\\left\\{\\frac{1}{s}\\right\\} = 1,\\quad\n\\mathcal{L}^{-1}\\left\\{-\\frac{s}{s^2+1}\\right\\} = -\\cos t,\\quad\n\\mathcal{L}^{-1}\\left\\{\\frac{1}{s^2+1}\\right\\} = \\sin t.\n$$\n\nTherefore, the solution is\n\n$$\nf(t) = 1 - \\cos t + \\sin t, \\qquad t \\ge 0.\n$$\n\nWe can verify by direct substitution into the original equation. The integral term becomes\n\n$$\n\\int_0^t e^{-(t-\\tau)} (1 - \\cos \\tau + \\sin \\tau) \\, d\\tau = 1 - \\cos t,\n$$\n\nand adding $\\sin t$ yields $1 - \\cos t + \\sin t = f(t)$, confirming the result.",
            "raw_answer": "[QUESTION]\nSolve the following integral equation for \\(f(t)\\):\n\n\\[\nf(t) = \\sin t + \\int_0^t e^{-(t-\\tau)} f(\\tau) \\, d\\tau, \\qquad t \\ge 0.\n\\]\n\n[ANSWER]\nWe solve using the Laplace transform. Let \\(\\mathcal{L}\\{f(t)\\}(s) = F(s)\\). Recall that the Laplace transform of a convolution is the product of transforms: \\(\\mathcal{L}\\{(f*g)(t)\\}(s) = F(s) G(s)\\), where \\((f*g)(t) = \\int_0^t f(t-\\tau)g(\\tau)\\,d\\tau\\). Taking Laplace transforms of both sides yields\n\n\\[\nF(s) = \\frac{1}{s^2+1} + \\frac{1}{s+1} F(s),\n\\]\n\nsince \\(\\mathcal{L}\\{\\sin t\\}(s) = \\frac{1}{s^2+1}\\) and \\(\\mathcal{L}\\{e^{-t}\\}(s) = \\frac{1}{s+1}\\). Solving for \\(F(s)\\):\n\n\\[\nF(s) \\left(1 - \\frac{1}{s+1}\\right) = \\frac{1}{s^2+1},\n\\]\n\\[\nF(s) \\cdot \\frac{s}{s+1} = \\frac{1}{s^2+1},\n\\]\n\\[\nF(s) = \\frac{s+1}{s(s^2+1)}.\n\\]\n\nWe decompose into partial fractions:\n\n\\[\n\\frac{s+1}{s(s^2+1)} = \\frac{A}{s} + \\frac{Bs+C}{s^2+1}.\n\\]\n\nMultiplying by \\(s(s^2+1)\\) gives\n\n\\[\ns+1 = A(s^2+1) + (Bs+C)s = (A+B)s^2 + Cs + A.\n\\]\n\nEquating coefficients:\n\n\\[\n\\begin{cases}\nA+B = 0,\\\\\nC = 1,\\\\\nA = 1.\n\\end{cases}\n\\]\n\nThus \\(A=1\\), \\(B=-1\\), \\(C=1\\). Hence\n\n\\[\nF(s) = \\frac{1}{s} + \\frac{-s+1}{s^2+1} = \\frac{1}{s} - \\frac{s}{s^2+1} + \\frac{1}{s^2+1}.\n\\]\n\nNow invert each term using standard Laplace transforms:\n\n\\[\n\\mathcal{L}^{-1}\\left\\{\\frac{1}{s}\\right\\} = 1,\\quad\n\\mathcal{L}^{-1}\\left\\{-\\frac{s}{s^2+1}\\right\\} = -\\cos t,\\quad\n\\mathcal{L}^{-1}\\left\\{\\frac{1}{s^2+1}\\right\\} = \\sin t.\n\\]\n\nTherefore, the solution is\n\n\\[\nf(t) = 1 - \\cos t + \\sin t, \\qquad t \\ge 0.\n\\]\n\nWe can verify by direct substitution into the original equation. The integral term becomes\n\n\\[\n\\int_0^t e^{-(t-\\tau)} (1 - \\cos \\tau + \\sin \\tau) \\, d\\tau = 1 - \\cos t,\n\\]\n\nand adding \\(\\sin t\\) yields \\(1 - \\cos t + \\sin t = f(t)\\), confirming the result.",
            "evaluation": {
              "verdict": "pass",
              "ill_posed": false,
              "issues": [],
              "improvements": ""
            }
          }
        ],
        "status": "succeeded"
      }
    ]
  }
]